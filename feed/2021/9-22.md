
## 2021-9-22

### [<title>What is the Range of score values for XGBRanker predict method? - XGBoost</title>](https://discuss.xgboost.ai/t/what-is-the-range-of-score-values-for-xgbranker-predict-method/2467/3)

### [<title>What is the Range of score values for XGBRanker predict method? - XGBoost</title>](https://discuss.xgboost.ai/t/what-is-the-range-of-score-values-for-xgbranker-predict-method/2467/2)

### [<title>What is the Range of score values for XGBRanker predict method? - XGBoost</title>](https://discuss.xgboost.ai/t/what-is-the-range-of-score-values-for-xgbranker-predict-method/2467/1)

### [[2109.09819] Seriema: RDMA-based Remote Invocationwith a Case-Study on Monte-Carlo Tree Search](http://arxiv.org/abs/2109.09819)


  We introduce Seriema, a middleware that integrates RDMA-based remote
invocation, asynchronous data transfer, NUMA-aware automatic management of
registered memory, and message aggregation in idiomatic C++1x. Seriema supports
the notion that remote invocation and asynchronous data transfer are
complementary services that, when tightly-integrated, allow distributed data
structures, overlay networks, and Cloud & datacenter service applications to be
expressed effectively and naturally, resembling sequential code. In order to
evaluate the usability of Seriema, we implement a Monte-Carlo Tree Search
(MCTS) application framework, which runs distributed simulations given only a
sequential problem specification. Micro-benchmarks show that Seriema provides
remote invocations with low overhead, and that our MCTS application framework
scales well up to the number of non-hyperthreaded CPU cores while simulating
plays of the board game Hex.

    

### [[2109.10114] Virtual Reality Gaming on the Cloud: A Reality Check](http://arxiv.org/abs/2109.10114)


  Cloud virtual reality (VR) gaming traffic characteristics such as frame size,
inter-arrival time, and latency need to be carefully studied as a first step
toward scalable VR cloud service provisioning. To this end, in this paper we
analyze the behavior of VR gaming traffic and Quality of Service (QoS) when VR
rendering is conducted remotely in the cloud. We first build a VR testbed
utilizing a cloud server, a commercial VR headset, and an off-the-shelf WiFi
router. Using this testbed, we collect and process cloud VR gaming traffic data
from different games under a number of network conditions and fixed and
adaptive video encoding schemes. To analyze the application-level
characteristics such as video frame size, frame inter-arrival time, frame loss
and frame latency, we develop an interval threshold based identification method
for video frames. Based on the frame identification results, we present two
statistical models that capture the behaviour of the VR gaming video traffic.
The models can be used by researchers and practitioners to generate VR traffic
models for simulations and experiments - and are paramount in designing
advanced radio resource management (RRM) and network optimization for cloud VR
gaming services. To the best of the authors' knowledge, this is the first
measurement study and analysis conducted using a commercial cloud VR gaming
platform, and under both fixed and adaptive bitrate streaming. We make our VR
traffic data-sets publicly available for further research by the community.

    

### [[2109.10159] From MANET to people-centric networking: milestones and open research challenges](http://arxiv.org/abs/2109.10159)


  In this paper we discuss the state of the art of (mobile) multi-hop ad hoc
networking with the aim to present the current status of the research
activities and identify the consolidated research areas, with limited research
opportunities, and the hot and emerging research areas for which further
research is required. We start by briefly discussing the MANET paradigm, and
why the research on MANET protocols is now a cold research topic. Then we
analyze the active research areas. Specifically, after discussing the
wireless-network technologies we analyze four successful ad hoc networking
paradigms, mesh, opportunistic, vehicular networks, and sensor networks that
emerged from the MANET world. We also present the new research directions in
the multi-hop ad hoc networking field: people-centric networking, triggered by
the increasing penetration of the smartphones in everyday life, which is
generating a people-centric revolution in computing and communications.

    

### [[2109.10267] Artificial Intelligence Edge Applications in 5G Networks](http://arxiv.org/abs/2109.10267)


  In recent years, the 5th Generation of mobile communications has been
thoroughly researched to improve the previous 4G capabilities. As op-posed to
earlier architectures, 5G Networks provide low latency access to ser-vices with
high reliability. Additionally, they allow exploring new opportunities for
applications that need to offload computing load in the network with a
real-time response. This paper analyzes the feasibility of a real-time Computer
Vi-sion use case model in small devices using a fully deployed 5G Network. The
results show an improvement in Latency and Throughput over previous
genera-tions, and a high percentage of Availability and Reliability in the
analyzed use case.

    

### [[1905.04581] Towards an efficient and exact algorithm for dynamic dedicated path protection](http://arxiv.org/abs/1905.04581)


  We present a novel algorithm for dynamic routing with dedicated path
protection which, as the presented simulation results suggest, can be efficient
and exact. We present the algorithm in the setting of optical networks, but it
should be applicable to other networks, where services have to be protected,
and where the network resources are finite and discrete, e.g., wireless radio
or networks capable of advance resource reservation. To the best of our
knowledge, we are the first to propose an algorithm for this long-standing
fundamental problem, which can be efficient and exact, as suggested by
simulation results. The algorithm can be efficient because it can solve large
problems, and it can be exact because its results are optimal, as demonstrated
and corroborated by simulations. We offer a worst-case analysis to argue that
the search space is polynomially upper bounded. Network operations, management,
and control require efficient and exact algorithms, especially now, when
greater emphasis is placed on network performance, reliability, softwarization,
agility, and return on investment. The proposed algorithm uses our generic
Dijkstra algorithm on a search graph generated "on-the-fly" based on the input
graph. We corroborated the optimality of the results of the proposed algorithm
with brute-force enumeration for networks up to 15 nodes large. We present the
extensive simulation results of dedicated-path protection with signal
modulation constraints for elastic optical networks of 25, 50, and 100 nodes,
and with 160, 320, and 640 spectrum units. We also compare the bandwidth
blocking probability with the commonly-used edge-exclusion algorithm. We had
48,600~simulation runs with about 41 million searches.

    

### [[1906.06184] A Holistic Survey of Wireless Multipath Video Streaming](http://arxiv.org/abs/1906.06184)


  Most of today's mobile devices are equipped with multiple network interfaces
and one of the main bandwidth-hungry applications that would benefit from
multipath communications is wireless video streaming. However, most of the
current transport protocols do not match the requirements of video streaming
applications or are not designed to address relevant issues, such as delay
constraints, networks heterogeneity, and head-of-line blocking issues. This
survey provides a holistic literature review of multipath wireless video
streaming, shedding light on the different alternatives from an end-to-end
layered stack perspective, unveiling trade-offs of each approach, and
presenting a suitable taxonomy to classify the state-of-the-art. Finally, we
discuss open issues and avenues for future work.

    

### [[2109.09734] MetaMedSeg: Volumetric Meta-learning for Few-Shot Organ Segmentation](http://arxiv.org/abs/2109.09734)


  The lack of sufficient annotated image data is a common issue in medical
image segmentation. For some organs and densities, the annotation may be
scarce, leading to poor model training convergence, while other organs have
plenty of annotated data. In this work, we present MetaMedSeg, a gradient-based
meta-learning algorithm that redefines the meta-learning task for the
volumetric medical data with the goal to capture the variety between the
slices. We also explore different weighting schemes for gradients aggregation,
arguing that different tasks might have different complexity, and hence,
contribute differently to the initialization. We propose an importance-aware
weighting scheme to train our model. In the experiments, we present an
evaluation of the medical decathlon dataset by extracting 2D slices from CT and
MRI volumes of different organs and performing semantic segmentation. The
results show that our proposed volumetric task definition leads to up to 30%
improvement in terms of IoU compared to related baselines. The proposed update
rule is also shown to improve the performance for complex scenarios where the
data distribution of the target organ is very different from the source organs.

    

### [[2109.09736] Unsupervised Domain Adaptation with Semantic Consistency across Heterogeneous Modalities for MRI Prostate Lesion Segmentation](http://arxiv.org/abs/2109.09736)


  Any novel medical imaging modality that differs from previous protocols e.g.
in the number of imaging channels, introduces a new domain that is
heterogeneous from previous ones. This common medical imaging scenario is
rarely considered in the domain adaptation literature, which handles shifts
across domains of the same dimensionality. In our work we rely on stochastic
generative modeling to translate across two heterogeneous domains at pixel
space and introduce two new loss functions that promote semantic consistency.
Firstly, we introduce a semantic cycle-consistency loss in the source domain to
ensure that the translation preserves the semantics. Secondly, we introduce a
pseudo-labelling loss, where we translate target data to source, label them by
a source-domain network, and use the generated pseudo-labels to supervise the
target-domain network. Our results show that this allows us to extract
systematically better representations for the target domain. In particular, we
address the challenge of enhancing performance on VERDICT-MRI, an advanced
diffusion-weighted imaging technique, by exploiting labeled mp-MRI data. When
compared to several unsupervised domain adaptation approaches, our approach
yields substantial improvements, that consistently carry over to the
semi-supervised and supervised learning settings.

    

### [[2109.09738] An Optimal Control Framework for Joint-channel Parallel MRI Reconstruction without Coil Sensitivities](http://arxiv.org/abs/2109.09738)


  Goal: This work aims at developing a novel calibration-free fast parallel MRI
(pMRI) reconstruction method incorporate with discrete-time optimal control
framework. The reconstruction model is designed to learn a regularization that
combines channels and extracts features by leveraging the information sharing
among channels of multi-coil images. We propose to recover both magnitude and
phase information by taking advantage of structured multiplayer convolutional
networks in image and Fourier spaces. Methods: We develop a novel variational
model with a learnable objective function that integrates an adaptive
multi-coil image combination operator and effective image regularization in the
image and Fourier spaces. We cast the reconstruction network as a structured
discrete-time optimal control system, resulting in an optimal control
formulation of parameter training where the parameters of the objective
function play the role of control variables. We demonstrate that the Lagrangian
method for solving the control problem is equivalent to back-propagation,
ensuring the local convergence of the training algorithm. Results: We conduct a
large number of numerical experiments of the proposed method with comparisons
to several state-of-the-art pMRI reconstruction networks on real pMRI datasets.
The numerical results demonstrate the promising performance of the proposed
method evidently. Conclusion: The proposed method provides a general deep
network design and training framework for efficient joint-channel pMRI
reconstruction. Significance: By learning multi-coil image combination operator
and performing regularizations in both image domain and k-space domain, the
proposed method achieves a highly efficient image reconstruction network for
pMRI.

    

### [[2109.09740] Neural Distance Embeddings for Biological Sequences](http://arxiv.org/abs/2109.09740)


  The development of data-dependent heuristics and representations for
biological sequences that reflect their evolutionary distance is critical for
large-scale biological research. However, popular machine learning approaches,
based on continuous Euclidean spaces, have struggled with the discrete
combinatorial formulation of the edit distance that models evolution and the
hierarchical relationship that characterises real-world datasets. We present
Neural Distance Embeddings (NeuroSEED), a general framework to embed sequences
in geometric vector spaces, and illustrate the effectiveness of the hyperbolic
space that captures the hierarchical structure and provides an average 22%
reduction in embedding RMSE against the best competing geometry. The capacity
of the framework and the significance of these improvements are then
demonstrated devising supervised and unsupervised NeuroSEED approaches to
multiple core tasks in bioinformatics. Benchmarked with common baselines, the
proposed approaches display significant accuracy and/or runtime improvements on
real-world datasets. As an example for hierarchical clustering, the proposed
pretrained and from-scratch methods match the quality of competing baselines
with 30x and 15x runtime reduction, respectively.

    

### [[2109.09747] Multifield Cosmology with Artificial Intelligence](http://arxiv.org/abs/2109.09747)


  Astrophysical processes such as feedback from supernovae and active galactic
nuclei modify the properties and spatial distribution of dark matter, gas, and
galaxies in a poorly understood way. This uncertainty is one of the main
theoretical obstacles to extract information from cosmological surveys. We use
2,000 state-of-the-art hydrodynamic simulations from the CAMELS project
spanning a wide variety of cosmological and astrophysical models and generate
hundreds of thousands of 2-dimensional maps for 13 different fields: from dark
matter to gas and stellar properties. We use these maps to train convolutional
neural networks to extract the maximum amount of cosmological information while
marginalizing over astrophysical effects at the field level. Although our maps
only cover a small area of $(25~h^{-1}{\rm Mpc})^2$, and the different fields
are contaminated by astrophysical effects in very different ways, our networks
can infer the values of $\Omega_{\rm m}$ and $\sigma_8$ with a few percent
level precision for most of the fields. We find that the marginalization
performed by the network retains a wealth of cosmological information compared
to a model trained on maps from gravity-only N-body simulations that are not
contaminated by astrophysical effects. Finally, we train our networks on
multifields -- 2D maps that contain several fields as different colors or
channels -- and find that not only they can infer the value of all parameters
with higher accuracy than networks trained on individual fields, but they can
constrain the value of $\Omega_{\rm m}$ with higher accuracy than the maps from
the N-body simulations.

    

### [[2109.09774] Inconsistency in Conference Peer Review: Revisiting the 2014 NeurIPS Experiment](http://arxiv.org/abs/2109.09774)


  In this paper we revisit the 2014 NeurIPS experiment that examined
inconsistency in conference peer review. We determine that 50\% of the
variation in reviewer quality scores was subjective in origin. Further, with
seven years passing since the experiment we find that for \emph{accepted}
papers, there is no correlation between quality scores and impact of the paper
as measured as a function of citation count. We trace the fate of rejected
papers, recovering where these papers were eventually published. For these
papers we find a correlation between quality scores and impact. We conclude
that the reviewing process for the 2014 conference was good for identifying
poor papers, but poor for identifying good papers. We give some suggestions for
improving the reviewing process but also warn against removing the subjective
element. Finally, we suggest that the real conclusion of the experiment is that
the community should place less onus on the notion of `top-tier conference
publications' when assessing the quality of individual researchers. For NeurIPS
2021, the PCs are repeating the experiment, as well as conducting new ones.

    

### [[2109.09791] Prediction of severe thunderstorm events with ensemble deep learning and radar data](http://arxiv.org/abs/2109.09791)


  The problem of nowcasting extreme weather events can be addressed by applying
either numerical methods for the solution of dynamic model equations or
data-driven artificial intelligence algorithms. Within this latter framework,
the present paper illustrates how a deep learning method, exploiting videos of
radar reflectivity frames as input, can be used to realize a warning machine
able to sound timely alarms of possible severe thunderstorm events. From a
technical viewpoint, the computational core of this approach is the use of a
value-weighted skill score for both transforming the probabilistic outcomes of
the deep neural network into binary classification and assessing the
forecasting performances. The warning machine has been validated against
weather radar data recorded in the Liguria region, in Italy,

    

### [[2109.09798] Metamorphic Relation Prioritization for Effective Regression Testing](http://arxiv.org/abs/2109.09798)


  Metamorphic testing (MT) is widely used for testing programs that face the
oracle problem. It uses a set of metamorphic relations (MRs), which are
relations among multiple inputs and their corresponding outputs to determine
whether the program under test is faulty. Typically, MRs vary in their ability
to detect faults in the program under test, and some MRs tend to detect the
same set of faults. In this paper, we propose approaches to prioritize MRs to
improve the efficiency and effectiveness of MT for regression testing. We
present two MR prioritization approaches: (1) fault-based and (2)
coverage-based. To evaluate these MR prioritization approaches, we conduct
experiments on three complex open-source software systems. Our results show
that the MR prioritization approaches developed by us significantly outperform
the current practice of executing the source and follow-up test cases of the
MRs in an ad-hoc manner in terms of fault detection effectiveness. Further,
fault-based MR prioritization leads to reducing the number of source and
follow-up test cases that needs to be executed as well as reducing the average
time taken to detect a fault, which would result in saving time and cost during
the testing process.

    

### [[2109.09811] Improving Span Representation for Domain-adapted Coreference Resolution](http://arxiv.org/abs/2109.09811)


  Recent work has shown fine-tuning neural coreference models can produce
strong performance when adapting to different domains. However, at the same
time, this can require a large amount of annotated target examples. In this
work, we focus on supervised domain adaptation for clinical notes, proposing
the use of concept knowledge to more efficiently adapt coreference models to a
new domain. We develop methods to improve the span representations via (1) a
retrofitting loss to incentivize span representations to satisfy a
knowledge-based distance function and (2) a scaffolding loss to guide the
recovery of knowledge from the span representation. By integrating these
losses, our model is able to improve our baseline precision and F-1 score. In
particular, we show that incorporating knowledge with end-to-end coreference
models results in better performance on the most challenging, domain-specific
spans.

    

### [[2109.09817] Molecular Energy Learning Using Alternative Blackbox Matrix-Matrix Multiplication Algorithm for Exact Gaussian Process](http://arxiv.org/abs/2109.09817)


  We present an application of the blackbox matrix-matrix multiplication (BBMM)
algorithm to scale up the Gaussian Process (GP) training of molecular energies
in the molecular-orbital based machine learning (MOB-ML) framework. An
alternative implementation of BBMM (AltBBMM) is also proposed to train more
efficiently (over four-fold speedup) with the same accuracy and transferability
as the original BBMM implementation. The training of MOB-ML was limited to 220
molecules, and BBMM and AltBBMM scale the training of MOB-ML up by over 30
times to 6500 molecules (more than a million pair energies). The accuracy and
transferability of both algorithms are examined on the benchmark datasets of
organic molecules with 7 and 13 heavy atoms. These lower-scaling
implementations of the GP preserve the state-of-the-art learning efficiency in
the low-data regime while extending it to the large-data regime with better
accuracy than other available machine learning works on molecular energies.

    

### [[2109.09824] Well Googled is Half Done: Multimodal Forecasting of New Fashion Product Sales with Image-based Google Trends](http://arxiv.org/abs/2109.09824)


  This paper investigates the effectiveness of systematically probing Google
Trendsagainst textual translations of visual aspects as exogenous knowledge to
predict the sales of brand-new fashion items, where past sales data is not
available, but only an image and few metadata are available. In particular, we
propose GTM-Transformer, standing for Google Trends Multimodal Transformer,
whose encoder works on the representation of the exogenous time series, while
the decoder forecasts the sales using the Google Trends encoding, and the
available visual and metadata information. Our model works in a
non-autoregressive manner, avoiding the compounding effect of the first-step
errors. As a second contribution, we present the VISUELLE dataset, which is the
first publicly available dataset for the task of new fashion product sales
forecasting, containing the sales of 5577 new products sold between 2016-2019,
derived from genuine historical data ofNunalie, an Italian fast-fashion
company. Our dataset is equipped with images of products, metadata, related
sales, and associated Google Trends. We use VISUELLE to compare our approach
against state-of-the-art alternatives and numerous baselines, showing that
GTM-Transformer is the most accurate in terms of both percentage and absolute
error. It is worth noting that the addition of exogenous knowledge boosts the
forecasting accuracy by 1.5% WAPE wise, showing the importance of exploiting
Google Trends. The code and dataset are both available at
this https URL.

    

### [[2109.09825] Data Augmentation Methods for Anaphoric Zero Pronouns](http://arxiv.org/abs/2109.09825)


  In pro-drop language like Arabic, Chinese, Italian, Japanese, Spanish, and
many others, unrealized (null) arguments in certain syntactic positions can
refer to a previously introduced entity, and are thus called anaphoric zero
pronouns. The existing resources for studying anaphoric zero pronoun
interpretation are however still limited. In this paper, we use five data
augmentation methods to generate and detect anaphoric zero pronouns
automatically. We use the augmented data as additional training materials for
two anaphoric zero pronoun systems for Arabic. Our experimental results show
that data augmentation improves the performance of the two systems, surpassing
the state-of-the-art results.

    

### [[2109.09828] iRNN: Integer-only Recurrent Neural Network](http://arxiv.org/abs/2109.09828)


  Recurrent neural networks (RNN) are used in many real-world text and speech
applications. They include complex modules such as recurrence,
exponential-based activation, gate interaction, unfoldable normalization,
bi-directional dependence, and attention. The interaction between these
elements prevents running them on integer-only operations without a significant
performance drop. Deploying RNNs that include layer normalization and attention
on integer-only arithmetic is still an open problem. We present a
quantization-aware training method for obtaining a highly accurate integer-only
recurrent neural network (iRNN). Our approach supports layer normalization,
attention, and an adaptive piecewise linear approximation of activations, to
serve a wide range of RNNs on various applications. The proposed method is
proven to work on RNN-based language models and automatic speech recognition.
Our iRNN maintains similar performance as its full-precision counterpart, their
deployment on smartphones improves the runtime performance by $2\times$, and
reduces the model size by $4\times$.

    

### [[2109.09829] Towards Energy-Efficient and Secure Edge AI: A Cross-Layer Framework](http://arxiv.org/abs/2109.09829)


  The security and privacy concerns along with the amount of data that is
required to be processed on regular basis has pushed processing to the edge of
the computing systems. Deploying advanced Neural Networks (NN), such as deep
neural networks (DNNs) and spiking neural networks (SNNs), that offer
state-of-the-art results on resource-constrained edge devices is challenging
due to the stringent memory and power/energy constraints. Moreover, these
systems are required to maintain correct functionality under diverse security
and reliability threats. This paper first discusses existing approaches to
address energy efficiency, reliability, and security issues at different system
layers, i.e., hardware (HW) and software (SW). Afterward, we discuss how to
further improve the performance (latency) and the energy efficiency of Edge AI
systems through HW/SW-level optimizations, such as pruning, quantization, and
approximation. To address reliability threats (like permanent and transient
faults), we highlight cost-effective mitigation techniques, like fault-aware
training and mapping. Moreover, we briefly discuss effective detection and
protection techniques to address security threats (like model and data
corruption). Towards the end, we discuss how these techniques can be combined
in an integrated cross-layer framework for realizing robust and
energy-efficient Edge AI systems.

    

### [[2109.09831] SMAC3: A Versatile Bayesian Optimization Package for Hyperparameter Optimization](http://arxiv.org/abs/2109.09831)


  Algorithm parameters, in particular hyperparameters of machine learning
algorithms, can substantially impact their performance. To support users in
determining well-performing hyperparameter configurations for their algorithms,
datasets and applications at hand, SMAC3 offers a robust and flexible framework
for Bayesian Optimization, which can improve performance within a few
evaluations. It offers several facades and pre-sets for typical use cases, such
as optimizing hyperparameters, solving low dimensional continuous (artificial)
global optimization problems and configuring algorithms to perform well across
multiple problem instances. The SMAC3 package is available under a permissive
BSD-license at this https URL.

    

### [[2109.09832] Weak Signals in the Mobility Landscape: Car Sharing in Ten European Cities](http://arxiv.org/abs/2109.09832)


  Car sharing is one the pillars of a smart transportation infrastructure, as
it is expected to reduce traffic congestion, parking demands and pollution in
our cities. From the point of view of demand modelling, car sharing is a weak
signal in the city landscape: only a small percentage of the population uses
it, and thus it is difficult to study reliably with traditional techniques such
as households travel diaries. In this work, we depart from these traditional
approaches and we leverage web-based, digital records about vehicle
availability in 10 European cities for one of the major active car sharing
operators. We discuss which sociodemographic and urban activity indicators are
associated with variations in car sharing demand, which forecasting approach
(among the most popular in the related literature) is better suited to predict
pickup and drop-off events, and how the spatio-temporal information about
vehicle availability can be used to infer how different zones in a city are
used by customers. We conclude the paper by presenting a direct application of
the analysis of the dataset, aimed at identifying where to locate maintenance
facilities within the car sharing operation area.

    

### [[2109.09833] Revisiting the Characteristics of Stochastic Gradient Noise and Dynamics](http://arxiv.org/abs/2109.09833)


  In this paper, we characterize the noise of stochastic gradients and analyze
the noise-induced dynamics during training deep neural networks by
gradient-based optimizers. Specifically, we firstly show that the stochastic
gradient noise possesses finite variance, and therefore the classical Central
Limit Theorem (CLT) applies; this indicates that the gradient noise is
asymptotically Gaussian. Such an asymptotic result validates the wide-accepted
assumption of Gaussian noise. We clarify that the recently observed phenomenon
of heavy tails within gradient noise may not be intrinsic properties, but the
consequence of insufficient mini-batch size; the gradient noise, which is a sum
of limited i.i.d. random variables, has not reached the asymptotic regime of
CLT, thus deviates from Gaussian. We quantitatively measure the goodness of
Gaussian approximation of the noise, which supports our conclusion. Secondly,
we analyze the noise-induced dynamics of stochastic gradient descent using the
Langevin equation, granting for momentum hyperparameter in the optimizer with a
physical interpretation. We then proceed to demonstrate the existence of the
steady-state distribution of stochastic gradient descent and approximate the
distribution at a small learning rate.

    

### [[2109.09847] Fast TreeSHAP: Accelerating SHAP Value Computation for Trees](http://arxiv.org/abs/2109.09847)


  SHAP (SHapley Additive exPlanation) values are one of the leading tools for
interpreting machine learning models, with strong theoretical guarantees
(consistency, local accuracy) and a wide availability of implementations and
use cases. Even though computing SHAP values takes exponential time in general,
TreeSHAP takes polynomial time on tree-based models. While the speedup is
significant, TreeSHAP can still dominate the computation time of industry-level
machine learning solutions on datasets with millions or more entries, causing
delays in post-hoc model diagnosis and interpretation service. In this paper we
present two new algorithms, Fast TreeSHAP v1 and v2, designed to improve the
computational efficiency of TreeSHAP for large datasets. We empirically find
that Fast TreeSHAP v1 is 1.5x faster than TreeSHAP while keeping the memory
cost unchanged. Similarly, Fast TreeSHAP v2 is 2.5x faster than TreeSHAP, at
the cost of a slightly higher memory usage, thanks to the pre-computation of
expensive TreeSHAP steps. We also show that Fast TreeSHAP v2 is well-suited for
multi-time model interpretations, resulting in as high as 3x faster explanation
of newly incoming samples.

    

### [[2109.09855] Reinforcement Learning for Finite-Horizon Restless Multi-Armed Multi-Action Bandits](http://arxiv.org/abs/2109.09855)


  We study a finite-horizon restless multi-armed bandit problem with multiple
actions, dubbed R(MA)^2B. The state of each arm evolves according to a
controlled Markov decision process (MDP), and the reward of pulling an arm
depends on both the current state of the corresponding MDP and the action
taken. The goal is to sequentially choose actions for arms so as to maximize
the expected value of the cumulative rewards collected. Since finding the
optimal policy is typically intractable, we propose a computationally appealing
index policy which we call Occupancy-Measured-Reward Index Policy. Our policy
is well-defined even if the underlying MDPs are not indexable. We prove that it
is asymptotically optimal when the activation budget and number of arms are
scaled up, while keeping their ratio as a constant. For the case when the
system parameters are unknown, we develop a learning algorithm. Our learning
algorithm uses the principle of optimism in the face of uncertainty and further
uses a generative model in order to fully exploit the structure of
Occupancy-Measured-Reward Index Policy. We call it the R(MA)^2B-UCB algorithm.
As compared with the existing algorithms, R(MA)^2B-UCB performs close to an
offline optimum policy, and also achieves a sub-linear regret with a low
computational complexity. Experimental results show that R(MA)^2B-UCB
outperforms the existing algorithms in both regret and run time.

    

### [[2109.09856] SFFDD: Deep Neural Network with Enriched Features for Failure Prediction with Its Application to Computer Disk Driver](http://arxiv.org/abs/2109.09856)


  A classification technique incorporating a novel feature derivation method is
proposed for predicting failure of a system or device with multivariate time
series sensor data. We treat the multivariate time series sensor data as images
for both visualization and computation. Failure follows various patterns which
are closely related to the root causes. Different predefined transformations
are applied on the original sensors data to better characterize the failure
patterns. In addition to feature derivation, ensemble method is used to further
improve the performance. In addition, a general algorithm architecture of deep
neural network is proposed to handle multiple types of data with less manual
feature engineering. We apply the proposed method on the early predict failure
of computer disk drive in order to improve storage systems availability and
avoid data loss. The classification accuracy is largely improved with the
enriched features, named smart features.

    

### [[2109.09868] ApproxIFER: A Model-Agnostic Approach to Resilient and Robust Prediction Serving Systems](http://arxiv.org/abs/2109.09868)


  Due to the surge of cloud-assisted AI services, the problem of designing
resilient prediction serving systems that can effectively cope with
stragglers/failures and minimize response delays has attracted much interest.
The common approach for tackling this problem is replication which assigns the
same prediction task to multiple workers. This approach, however, is very
inefficient and incurs significant resource overheads. Hence, a learning-based
approach known as parity model (ParM) has been recently proposed which learns
models that can generate parities for a group of predictions in order to
reconstruct the predictions of the slow/failed workers. While this
learning-based approach is more resource-efficient than replication, it is
tailored to the specific model hosted by the cloud and is particularly suitable
for a small number of queries (typically less than four) and tolerating very
few (mostly one) number of stragglers. Moreover, ParM does not handle Byzantine
adversarial workers. We propose a different approach, named Approximate Coded
Inference (ApproxIFER), that does not require training of any parity models,
hence it is agnostic to the model hosted by the cloud and can be readily
applied to different data domains and model architectures. Compared with
earlier works, ApproxIFER can handle a general number of stragglers and scales
significantly better with the number of queries. Furthermore, ApproxIFER is
robust against Byzantine workers. Our extensive experiments on a large number
of datasets and model architectures also show significant accuracy improvement
by up to 58% over the parity model approaches.

    

### [[2109.09869] Robustness Analysis of Deep Learning Frameworks on Mobile Platforms](http://arxiv.org/abs/2109.09869)


  With the recent increase in the computational power of modern mobile devices,
machine learning-based heavy tasks such as face detection and speech
recognition are now integral parts of such devices. This requires frameworks to
execute machine learning models (e.g., Deep Neural Networks) on mobile devices.
Although there exist studies on the accuracy and performance of these
frameworks, the quality of on-device deep learning frameworks, in terms of
their robustness, has not been systematically studied yet. In this paper, we
empirically compare two on-device deep learning frameworks with three
adversarial attacks on three different model architectures. We also use both
the quantized and unquantized variants for each architecture. The results show
that, in general, neither of the deep learning frameworks is better than the
other in terms of robustness, and there is not a significant difference between
the PC and mobile frameworks either. However, in cases like Boundary attack,
mobile version is more robust than PC. In addition, quantization improves
robustness in all cases when moving from PC to mobile.

    

### [[2109.09876] Context-Specific Representation Abstraction for Deep Option Learning](http://arxiv.org/abs/2109.09876)


  Hierarchical reinforcement learning has focused on discovering temporally
extended actions, such as options, that can provide benefits in problems
requiring extensive exploration. One promising approach that learns these
options end-to-end is the option-critic (OC) framework. We examine and show in
this paper that OC does not decompose a problem into simpler sub-problems, but
instead increases the size of the search over policy space with each option
considering the entire state space during learning. This issue can result in
practical limitations of this method, including sample inefficient learning. To
address this problem, we introduce Context-Specific Representation Abstraction
for Deep Option Learning (CRADOL), a new framework that considers both temporal
abstraction and context-specific representation abstraction to effectively
reduce the size of the search over policy space. Specifically, our method
learns a factored belief state representation that enables each option to learn
a policy over only a subsection of the state space. We test our method against
hierarchical, non-hierarchical, and modular recurrent neural network baselines,
demonstrating significant sample efficiency improvements in challenging
partially observable environments.

    

### [[2109.09888] Chemical-Reaction-Aware Molecule Representation Learning](http://arxiv.org/abs/2109.09888)


  Molecule representation learning (MRL) methods aim to embed molecules into a
real vector space. However, existing SMILES-based (Simplified Molecular-Input
Line-Entry System) or GNN-based (Graph Neural Networks) MRL methods either take
SMILES strings as input that have difficulty in encoding molecule structure
information, or over-emphasize the importance of GNN architectures but neglect
their generalization ability. Here we propose using chemical reactions to
assist learning molecule representation. The key idea of our approach is to
preserve the equivalence of molecules with respect to chemical reactions in the
embedding space, i.e., forcing the sum of reactant embeddings and the sum of
product embeddings to be equal for each chemical equation. This constraint is
proven effective to 1) keep the embedding space well-organized and 2) improve
the generalization ability of molecule embeddings. Moreover, our model can use
any GNN as the molecule encoder and is thus agnostic to GNN architectures.
Experimental results demonstrate that our method achieves state-of-the-art
performance in a variety of downstream tasks, e.g., 17.4% absolute Hit@1 gain
in chemical reaction prediction, 2.3% absolute AUC gain in molecule property
prediction, and 18.5% relative RMSE gain in graph-edit-distance prediction,
respectively, over the best baseline method. The code is available at
this https URL.

    

### [[2109.09889] A Simple Unified Framework for Anomaly Detection in Deep Reinforcement Learning](http://arxiv.org/abs/2109.09889)


  Abnormal states in deep reinforcement learning~(RL) are states that are
beyond the scope of an RL policy. Such states may make the RL system unsafe and
impede its deployment in real scenarios. In this paper, we propose a simple yet
effective anomaly detection framework for deep RL algorithms that
simultaneously considers random, adversarial and out-of-distribution~(OOD)
state outliers. In particular, we attain the class-conditional distributions
for each action class under the Gaussian assumption, and rely on these
distributions to discriminate between inliers and outliers based on Mahalanobis
Distance~(MD) and Robust Mahalanobis Distance. We conduct extensive experiments
on Atari games that verify the effectiveness of our detection strategies. To
the best of our knowledge, we present the first in-detail study of statistical
and adversarial anomaly detection in deep RL algorithms. This simple unified
anomaly detection paves the way towards deploying safe RL systems in real-world
applications.

    

### [[2109.09901] Modelling Adversarial Noise for Adversarial Defense](http://arxiv.org/abs/2109.09901)


  Deep neural networks have been demonstrated to be vulnerable to adversarial
noise, promoting the development of defenses against adversarial attacks.
Traditionally, adversarial defenses typically focus on directly exploiting
adversarial examples to remove adversarial noise or train an adversarially
robust target model. Motivated by that the relationship between adversarial
data and natural data can help infer clean data from adversarial data to obtain
the final correct prediction, in this paper, we study to model adversarial
noise to learn the transition relationship in the label space for using
adversarial labels to improve adversarial accuracy. Specifically, we introduce
a transition matrix to relate adversarial labels and true labels. By exploiting
the transition matrix, we can directly infer clean labels from adversarial
labels. Then, we propose to employ a deep neural network (i.e., transition
network) to model the instance-dependent transition matrix from adversarial
noise. In addition, we conduct joint adversarial training on the target model
and the transition network to achieve optimal performance. Empirical
evaluations on benchmark datasets demonstrate that our method could
significantly improve adversarial accuracy in comparison to state-of-the-art
methods.

    

### [[2109.09910] Demonstration-Efficient Guided Policy Search via Imitation of Robust Tube MPC](http://arxiv.org/abs/2109.09910)


  We propose a demonstration-efficient strategy to compress a computationally
expensive Model Predictive Controller (MPC) into a more computationally
efficient representation based on a deep neural network and Imitation Learning
(IL). By generating a Robust Tube variant (RTMPC) of the MPC and leveraging
properties from the tube, we introduce a data augmentation method that enables
high demonstration-efficiency, being capable to compensate the distribution
shifts typically encountered in IL. Our approach opens the possibility of
zero-shot transfer from a single demonstration collected in a nominal domain,
such as a simulation or a robot in a lab/controlled environment, to a domain
with bounded model errors/perturbations. Numerical and experimental evaluations
performed on a trajectory tracking MPC for a quadrotor show that our method
outperforms strategies commonly employed in IL, such as DAgger and Domain
Randomization, in terms of demonstration-efficiency and robustness to
perturbations unseen during training.

    

### [[2109.09917] Meta-Model Structure Selection: Building Polynomial NARX Model for Regression and Classification](http://arxiv.org/abs/2109.09917)


  This work presents a new meta-heuristic approach to select the structure of
polynomial NARX models for regression and classification problems. The method
takes into account the complexity of the model and the contribution of each
term to build parsimonious models by proposing a new cost function formulation.
The robustness of the new algorithm is tested on several simulated and
experimental system with different nonlinear characteristics. The obtained
results show that the proposed algorithm is capable of identifying the correct
model, for cases where the proper model structure is known, and determine
parsimonious models for experimental data even for those systems for which
traditional and contemporary methods habitually fails. The new algorithm is
validated over classical methods such as the FROLS and recent randomized
approaches.

    

### [[2109.09939] IgNet. A Super-precise Convolutional Neural Network](http://arxiv.org/abs/2109.09939)


  Convolutional neural networks (CNN) are known to be an effective means to
detect and analyze images. Their power is essentially based on the ability to
extract out images common features. There exist, however, images involving
unique, irregular features or details. Such is a collection of unusual children
drawings reflecting the kids imagination and individuality. These drawings were
analyzed by means of a CNN constructed by means of Keras-TensorFlow. The same
problem - on a significantly higher level - was solved with newly developed
family of networks called IgNet that is described in this paper. It proved able
to learn by 100 % all the categorical characteristics of the drawings. In the
case of a regression task (learning the young artists ages) IgNet performed
with an error of no more than 0.4 %. The principles are discussed of IgNet
design that made it possible to reach such substantial results with rather
simple network topology.

    

### [[2109.09946] Identifying biases in legal data: An algorithmic fairness perspective](http://arxiv.org/abs/2109.09946)


  The need to address representation biases and sentencing disparities in legal
case data has long been recognized. Here, we study the problem of identifying
and measuring biases in large-scale legal case data from an algorithmic
fairness perspective. Our approach utilizes two regression models: A baseline
that represents the decisions of a "typical" judge as given by the data and a
"fair" judge that applies one of three fairness concepts. Comparing the
decisions of the "typical" judge and the "fair" judge allows for quantifying
biases across demographic groups, as we demonstrate in four case studies on
criminal data from Cook County (Illinois).

    

### [[2109.09948] Neural networks with trainable matrix activation functions](http://arxiv.org/abs/2109.09948)


  The training process of neural networks usually optimize weights and bias
parameters of linear transformations, while nonlinear activation functions are
pre-specified and fixed. This work develops a systematic approach to
constructing matrix activation functions whose entries are generalized from
ReLU. The activation is based on matrix-vector multiplications using only
scalar multiplications and comparisons. The proposed activation functions
depend on parameters that are trained along with the weights and bias vectors.
Neural networks based on this approach are simple and efficient and are shown
to be robust in numerical experiments.

    

### [[2109.09958] FakeWake: Understanding and Mitigating Fake Wake-up Words of Voice Assistants](http://arxiv.org/abs/2109.09958)


  In the area of Internet of Things (IoT) voice assistants have become an
important interface to operate smart speakers, smartphones, and even
automobiles. To save power and protect user privacy, voice assistants send
commands to the cloud only if a small set of pre-registered wake-up words are
detected. However, voice assistants are shown to be vulnerable to the FakeWake
phenomena, whereby they are inadvertently triggered by innocent-sounding fuzzy
words. In this paper, we present a systematic investigation of the FakeWake
phenomena from three aspects. To start with, we design the first fuzzy word
generator to automatically and efficiently produce fuzzy words instead of
searching through a swarm of audio materials. We manage to generate 965 fuzzy
words covering 8 most popular English and Chinese smart speakers. To explain
the causes underlying the FakeWake phenomena, we construct an interpretable
tree-based decision model, which reveals phonetic features that contribute to
false acceptance of fuzzy words by wake-up word detectors. Finally, we propose
remedies to mitigate the effect of FakeWake. The results show that the
strengthened models are not only resilient to fuzzy words but also achieve
better overall performance on original training datasets.

    

### [[2109.09961] Non-parametric Kernel-Based Estimation of Probability Distributions for Precipitation Modeling](http://arxiv.org/abs/2109.09961)


  The probability distribution of precipitation amount strongly depends on
geography, climate zone, and time scale considered. Closed-form parametric
probability distributions are not sufficiently flexible to provide accurate and
universal models for precipitation amount over different time scales. In this
paper we derive non-parametric estimates of the cumulative distribution
function (CDF) of precipitation amount for wet time intervals. The CDF
estimates are obtained by integrating the kernel density estimator leading to
semi-explicit CDF expressions for different kernel functions. We investigate
kernel-based CDF estimation with an adaptive plug-in bandwidth (KCDE), using
both synthetic data sets and reanalysis precipitation data from the island of
Crete (Greece). We show that KCDE provides better estimates of the probability
distribution than the standard empirical (staircase) estimate and kernel-based
estimates that use the normal reference bandwidth. We also demonstrate that
KCDE enables the simulation of non-parametric precipitation amount
distributions by means of the inverse transform sampling method.

    

### [[2109.09974] Learning Adaptive Control for SE(3) Hamiltonian Dynamics](http://arxiv.org/abs/2109.09974)


  Fast adaptive control is a critical component for reliable robot autonomy in
rapidly changing operational conditions. While a robot dynamics model may be
obtained from first principles or learned from data, updating its parameters is
often too slow for online adaptation to environment changes. This motivates the
use of machine learning techniques to learn disturbance descriptors from
trajectory data offline as well as the design of adaptive control to estimate
and compensate the disturbances online. This paper develops adaptive geometric
control for rigid-body systems, such as ground, aerial, and underwater
vehicles, that satisfy Hamilton's equations of motion over the SE(3) manifold.
Our design consists of an offline system identification stage, followed by an
online adaptive control stage. In the first stage, we learn a Hamiltonian model
of the system dynamics using a neural ordinary differential equation (ODE)
network trained from state-control trajectory data with different disturbance
realizations. The disturbances are modeled as a linear combination of nonlinear
descriptors. In the second stage, we design a trajectory tracking controller
with disturbance compensation from an energy-based perspective. An adaptive
control law is employed to adjust the disturbance model online proportional to
the geometric tracking errors on the SE(3) manifold. We verify our adaptive
geometric controller for trajectory tracking on a fully-actuated pendulum and
an under-actuated quadrotor.

    

### [[2109.09975] Fast nonlinear risk assessment for autonomous vehicles using learned conditional probabilistic models of agent futures](http://arxiv.org/abs/2109.09975)


  This paper presents fast non-sampling based methods to assess the risk for
trajectories of autonomous vehicles when probabilistic predictions of other
agents' futures are generated by deep neural networks (DNNs). The presented
methods address a wide range of representations for uncertain predictions
including both Gaussian and non-Gaussian mixture models to predict both agent
positions and control inputs conditioned on the scene contexts. We show that
the problem of risk assessment when Gaussian mixture models (GMMs) of agent
positions are learned can be solved rapidly to arbitrary levels of accuracy
with existing numerical methods. To address the problem of risk assessment for
non-Gaussian mixture models of agent position, we propose finding upper bounds
on risk using nonlinear Chebyshev's Inequality and sums-of-squares (SOS)
programming; they are both of interest as the former is much faster while the
latter can be arbitrarily tight. These approaches only require higher order
statistical moments of agent positions to determine upper bounds on risk. To
perform risk assessment when models are learned for agent control inputs as
opposed to positions, we propagate the moments of uncertain control inputs
through the nonlinear motion dynamics to obtain the exact moments of uncertain
position over the planning horizon. To this end, we construct deterministic
linear dynamical systems that govern the exact time evolution of the moments of
uncertain position in the presence of uncertain control inputs. The presented
methods are demonstrated on realistic predictions from DNNs trained on the
Argoverse and CARLA datasets and are shown to be effective for rapidly
assessing the probability of low probability events.

    

### [[2109.09988] Signal Classification using Smooth Coefficients of Multiple wavelets](http://arxiv.org/abs/2109.09988)


  Classification of time series signals has become an important construct and
has many practical applications. With existing classifiers we may be able to
accurately classify signals, however that accuracy may decline if using a
reduced number of attributes. Transforming the data then undertaking reduction
in dimensionality may improve the quality of the data analysis, decrease time
required for classification and simplify models. We propose an approach, which
chooses suitable wavelets to transform the data, then combines the output from
these transforms to construct a dataset to then apply ensemble classifiers to.
We demonstrate this on different data sets, across different classifiers and
use differing evaluation methods. Our experimental results demonstrate the
effectiveness of the proposed technique, compared to the approaches that use
either raw signal data or a single wavelet transform.

    

### [[2109.10004] Vaccine allocation policy optimization and budget sharing mechanism using Thompson sampling](http://arxiv.org/abs/2109.10004)


  The optimal allocation of vaccines to population subgroups over time is a
challenging health care management problem. In the context of a pandemic, the
interaction between vaccination policies adopted by multiple agents and the
cooperation (or lack thereof) creates a complex environment that affects the
global transmission dynamics of the disease. In this study, we take the
perspective of decision-making agents that aim to minimize the size of their
susceptible populations and must allocate vaccine under limited supply. We
assume that vaccine efficiency rates are unknown to agents and we propose an
optimization policy based on Thompson sampling to learn mean vaccine efficiency
rates over time. Furthermore, we develop a budget-balanced resource sharing
mechanism to promote cooperation among agents. We apply the proposed framework
to the COVID-19 pandemic. We use a raster model of the world where agents
represent the main countries worldwide and interact in a global mobility
network to generate multiple problem instances. Our numerical results show that
the proposed vaccine allocation policy achieves a larger reduction in the
number of susceptible individuals, infections and deaths globally compared to a
population-based policy. In addition, we show that, under a fixed global
vaccine allocation budget, most countries can reduce their national number of
infections and deaths by sharing their budget with countries with which they
have a relatively high mobility exchange. The proposed framework can be used to
improve policy-making in health care management by national and global health
authorities.

    

### [[2109.10011] Unsupervised Abstract Reasoning for Raven's Problem Matrices](http://arxiv.org/abs/2109.10011)


  Raven's Progressive Matrices (RPM) is highly correlated with human
intelligence, and it has been widely used to measure the abstract reasoning
ability of humans. In this paper, to study the abstract reasoning capability of
deep neural networks, we propose the first unsupervised learning method for
solving RPM problems. Since the ground truth labels are not allowed, we design
a pseudo target based on the prior constraints of the RPM formulation to
approximate the ground truth label, which effectively converts the unsupervised
learning strategy into a supervised one. However, the correct answer is wrongly
labelled by the pseudo target, and thus the noisy contrast will lead to
inaccurate model training. To alleviate this issue, we propose to improve the
model performance with negative answers. Moreover, we develop a
decentralization method to adapt the feature representation to different RPM
problems. Extensive experiments on three datasets demonstrate that our method
even outperforms some of the supervised approaches. Our code is available at
this https URL.

    

### [[2109.10020] Online Multi-horizon Transaction Metric Estimation with Multi-modal Learning in Payment Networks](http://arxiv.org/abs/2109.10020)


  Predicting metrics associated with entities' transnational behavior within
payment processing networks is essential for system monitoring. Multivariate
time series, aggregated from the past transaction history, can provide valuable
insights for such prediction. The general multivariate time series prediction
problem has been well studied and applied across several domains, including
manufacturing, medical, and entomology. However, new domain-related challenges
associated with the data such as concept drift and multi-modality have surfaced
in addition to the real-time requirements of handling the payment transaction
data at scale. In this work, we study the problem of multivariate time series
prediction for estimating transaction metrics associated with entities in the
payment transaction database. We propose a model with five unique components to
estimate the transaction metrics from multi-modality data. Four of these
components capture interaction, temporal, scale, and shape perspectives, and
the fifth component fuses these perspectives together. We also propose a hybrid
offline/online training scheme to address concept drift in the data and fulfill
the real-time requirements. Combining the estimation model with a graphical
user interface, the prototype transaction metric estimation system has
demonstrated its potential benefit as a tool for improving a payment processing
company's system monitoring capability.

    

### [[2109.10021] Stabilizing Elastic Weight Consolidation method in practical ML tasks and using weight importances for neural network pruning](http://arxiv.org/abs/2109.10021)


  This paper is devoted to the features of the practical application of Elastic
Weight Consolidation method. Here we will more rigorously compare the known
methodologies for calculating the importance of weights when applied to
networks with fully connected and convolutional layers. We will also point out
the problems that arise when applying the Elastic Weight Consolidation method
in multilayer neural networks with convolutional layers and self-attention
layers, and propose method to overcome these problems. In addition, we will
notice an interesting fact about the use of various types of weight importance
in the neural network pruning task.

    

### [[2109.10024] Self-Supervised Action-Space Prediction for Automated Driving](http://arxiv.org/abs/2109.10024)


  Making informed driving decisions requires reliable prediction of other
vehicles' trajectories. In this paper, we present a novel learned multi-modal
trajectory prediction architecture for automated driving. It achieves
kinematically feasible predictions by casting the learning problem into the
space of accelerations and steering angles -- by performing action-space
prediction, we can leverage valuable model knowledge. Additionally, the
dimensionality of the action manifold is lower than that of the state manifold,
whose intrinsically correlated states are more difficult to capture in a
learned manner. For the purpose of action-space prediction, we present the
simple Feed-Forward Action-Space Prediction (FFW-ASP) architecture. Then, we
build on this notion and introduce the novel Self-Supervised Action-Space
Prediction (SSP-ASP) architecture that outputs future environment context
features in addition to trajectories. A key element in the self-supervised
architecture is that, based on an observed action history and past context
features, future context features are predicted prior to future trajectories.
The proposed methods are evaluated on real-world datasets containing urban
intersections and roundabouts, and show accurate predictions, outperforming
state-of-the-art for kinematically feasible predictions in several prediction
metrics.

    

### [[2109.10034] Learning offline: memory replay in biological and artificial reinforcement learning](http://arxiv.org/abs/2109.10034)


  Learning to act in an environment to maximise rewards is among the brain's
key functions. This process has often been conceptualised within the framework
of reinforcement learning, which has also gained prominence in machine learning
and artificial intelligence (AI) as a way to optimise decision-making. A common
aspect of both biological and machine reinforcement learning is the
reactivation of previously experienced episodes, referred to as replay. Replay
is important for memory consolidation in biological neural networks, and is key
to stabilising learning in deep neural networks. Here, we review recent
developments concerning the functional roles of replay in the fields of
neuroscience and AI. Complementary progress suggests how replay might support
learning processes, including generalisation and continual learning, affording
opportunities to transfer knowledge across the two fields to advance the
understanding of biological and artificial learning and memory.

    

### [[2109.10047] Search For Deep Graph Neural Networks](http://arxiv.org/abs/2109.10047)


  Current GNN-oriented NAS methods focus on the search for different layer
aggregate components with shallow and simple architectures, which are limited
by the 'over-smooth' problem. To further explore the benefits from structural
diversity and depth of GNN architectures, we propose a GNN generation pipeline
with a novel two-stage search space, which aims at automatically generating
high-performance while transferable deep GNN models in a block-wise manner.
Meanwhile, to alleviate the 'over-smooth' problem, we incorporate multiple
flexible residual connection in our search space and apply identity mapping in
the basic GNN layers. For the search algorithm, we use deep-q-learning with
epsilon-greedy exploration strategy and reward reshaping. Extensive experiments
on real-world datasets show that our generated GNN models outperforms existing
manually designed and NAS-based ones.

    

### [[2109.10053] Towards a Fairness-Aware Scoring System for Algorithmic Decision-Making](http://arxiv.org/abs/2109.10053)


  Scoring systems, as simple classification models, have significant advantages
in interpretability and transparency when making predictions. It facilitates
humans' decision-making by allowing them to make a quick prediction by hand
through adding and subtracting a few point scores and thus has been widely used
in various fields such as medical diagnosis of Intensive Care Units. However,
the (un)fairness issues in these models have long been criticized, and the use
of biased data in the construction of score systems heightens this concern. In
this paper, we proposed a general framework to create data-driven
fairness-aware scoring systems. Our approach is first to develop a social
welfare function that incorporates both efficiency and equity. Then, we
translate the social welfare maximization problem in economics into the
empirical risk minimization task in the machine learning community to derive a
fairness-aware scoring system with the help of mixed integer programming. We
show that the proposed framework provides practitioners or policymakers great
flexibility to select their desired fairness requirements and also allows them
to customize their own requirements by imposing various operational
constraints. Experimental evidence on several real data sets verifies that the
proposed scoring system can achieve the optimal welfare of stakeholders and
balance the interpretability, fairness, and efficiency issues.

    

### [[2109.10057] LOTR: Face Landmark Localization Using Localization Transformer](http://arxiv.org/abs/2109.10057)


  This paper presents a novel Transformer-based facial landmark localization
network named Localization Transformer (LOTR). The proposed framework is a
direct coordinate regression approach leveraging a Transformer network to
better utilize the spatial information in the feature map. An LOTR model
consists of three main modules: 1) a visual backbone that converts an input
image into a feature map, 2) a Transformer module that improves the feature
representation from the visual backbone, and 3) a landmark prediction head that
directly predicts the landmark coordinates from the Transformer's
representation. Given cropped-and-aligned face images, the proposed LOTR can be
trained end-to-end without requiring any post-processing steps. This paper also
introduces the smooth-Wing loss function, which addresses the gradient
discontinuity of the Wing loss, leading to better convergence than standard
loss functions such as L1, L2, and Wing loss. Experimental results on the JD
landmark dataset provided by the First Grand Challenge of 106-Point Facial
Landmark Localization indicate the superiority of LOTR over the existing
methods on the leaderboard and two recent heatmap-based approaches.

    

### [[2109.10061] Graph Neural Networks for Graph Drawing](http://arxiv.org/abs/2109.10061)


  Graph Drawing techniques have been developed in the last few years with the
purpose of producing aesthetically pleasing node-link layouts. Recently, the
employment of differentiable loss functions has paved the road to the massive
usage of Gradient Descent and related optimization algorithms. In this paper,
we propose a novel framework for the development of Graph Neural Drawers (GND),
machines that rely on neural computation for constructing efficient and complex
maps. GND are Graph Neural Networks (GNNs) whose learning process can be driven
by any provided loss function, such as the ones commonly employed in Graph
Drawing. Moreover, we prove that this mechanism can be guided by loss functions
computed by means of Feedforward Neural Networks, on the basis of supervision
hints that express beauty properties, like the minimization of crossing edges.
In this context, we show that GNNs can nicely be enriched by positional
features to deal also with unlabelled vertexes. We provide a proof-of-concept
by constructing a loss function for the edge-crossing and provide quantitative
and qualitative comparisons among different GNN models working under the
proposed framework.

    

### [[2109.10072] Scenario generation for market risk models using generative neural networks](http://arxiv.org/abs/2109.10072)


  In this research, we show how to expand existing approaches of generative
adversarial networks (GANs) being used as economic scenario generators (ESG) to
a whole internal model - with enough risk factors to model the full band-width
of investments for an insurance company and for a one year horizon as required
in Solvency 2. For validation of this approach as well as for optimisation of
the GAN architecture, we develop new performance measures and provide a
consistent, data-driven framework. Finally, we demonstrate that the results of
a GAN-based ESG are similar to regulatory approved internal models in Europe.
Therefore, GAN-based models can be seen as an assumption-free data-driven
alternative way of market risk modelling.

    

### [[2109.10078] Learning Interpretable Concept Groups in CNNs](http://arxiv.org/abs/2109.10078)


  We propose a novel training methodology -- Concept Group Learning (CGL) --
that encourages training of interpretable CNN filters by partitioning filters
in each layer into concept groups, each of which is trained to learn a single
visual concept. We achieve this through a novel regularization strategy that
forces filters in the same group to be active in similar image regions for a
given layer. We additionally use a regularizer to encourage a sparse weighting
of the concept groups in each layer so that a few concept groups can have
greater importance than others. We quantitatively evaluate CGL's model
interpretability using standard interpretability evaluation techniques and find
that our method increases interpretability scores in most cases. Qualitatively
we compare the image regions that are most active under filters learned using
CGL versus filters learned without CGL and find that CGL activation regions
more strongly concentrate around semantically relevant features.

    

### [[2109.10080] NADE: A Benchmark for Robust Adverse Drug Events Extraction in Face of Negations](http://arxiv.org/abs/2109.10080)


  Adverse Drug Event (ADE) extraction mod-els can rapidly examine large
collections of so-cial media texts, detecting mentions of drug-related adverse
reactions and trigger medicalinvestigations. However, despite the recent
ad-vances in NLP, it is currently unknown if suchmodels are robust in face
ofnegation, which ispervasive across language this http URL this paper we
evaluate three state-of-the-artsystems, showing their fragility against
nega-tion, and then we introduce two possible strate-gies to increase the
robustness of these mod-els: a pipeline approach, relying on a
specificcomponent for negation detection; an augmen-tation of an ADE extraction
dataset to artifi-cially create negated samples and further trainthe models.We
show that both strategies bring significantincreases in performance, lowering
the num-ber of spurious entities predicted by the mod-els. Our dataset and code
will be publicly re-leased to encourage research on the topic.

    

### [[2109.10082] DeepTimeAnomalyViz: A Tool for Visualizing and Post-processing Deep Learning Anomaly Detection Results for Industrial Time-Series](http://arxiv.org/abs/2109.10082)


  Industrial processes are monitored by a large number of various sensors that
produce time-series data. Deep Learning offers a possibility to create anomaly
detection methods that can aid in preventing malfunctions and increasing
efficiency. But creating such a solution can be a complicated task, with
factors such as inference speed, amount of available data, number of sensors,
and many more, influencing the feasibility of such implementation. We introduce
the DeTAVIZ interface, which is a web browser based visualization tool for
quick exploration and assessment of feasibility of DL based anomaly detection
in a given problem. Provided with a pool of pretrained models and simulation
results, DeTAVIZ allows the user to easily and quickly iterate through multiple
post processing options and compare different models, and allows for manual
optimisation towards a chosen metric.

    

### [[2109.10096] Transferability of Graph Neural Networks: an Extended Graphon Approach](http://arxiv.org/abs/2109.10096)


  We study spectral graph convolutional neural networks (GCNNs), where filters
are defined as continuous functions of the graph shift operator (GSO) through
functional calculus. A spectral GCNN is not tailored to one specific graph and
can be transferred between different graphs. It is hence important to study the
GCNN transferability: the capacity of the network to have approximately the
same repercussion on different graphs that represent the same phenomenon.
Transferability ensures that GCNNs trained on certain graphs generalize if the
graphs in the test set represent the same phenomena as the graphs in the
training set. In this paper, we consider a model of transferability based on
graphon analysis. Graphons are limit objects of graphs, and, in the graph
paradigm, two graphs represent the same phenomenon if both approximate the same
graphon. Our main contributions can be summarized as follows: 1) we prove that
any fixed GCNN with continuous filters is transferable under graphs that
approximate the same graphon, 2) we prove transferability for graphs that
approximate unbounded graphon shift operators, which are defined in this paper,
and, 3) we obtain non-asymptotic approximation results, proving linear
stability of GCNNs. This extends current state-of-the-art results which show
asymptotic transferability for polynomial filters under graphs that approximate
bounded graphons.

    

### [[2109.10100] A Novel Structured Natural Gradient Descent for Deep Learning](http://arxiv.org/abs/2109.10100)


  Natural gradient descent (NGD) provided deep insights and powerful tools to
deep neural networks. However the computation of Fisher information matrix
becomes more and more difficult as the network structure turns large and
complex. This paper proposes a new optimization method whose main idea is to
accurately replace the natural gradient optimization by reconstructing the
network. More specifically, we reconstruct the structure of the deep neural
network, and optimize the new network using traditional gradient descent (GD).
The reconstructed network achieves the effect of the optimization way with
natural gradient descent. Experimental results show that our optimization
method can accelerate the convergence of deep network models and achieve better
performance than GD while sharing its computational simplicity.

    

### [[2109.10115] StereOBJ-1M: Large-scale Stereo Image Dataset for 6D Object Pose Estimation](http://arxiv.org/abs/2109.10115)


  We present a large-scale stereo RGB image object pose estimation dataset
named the $\textbf{StereOBJ-1M}$ dataset. The dataset is designed to address
challenging cases such as object transparency, translucency, and specular
reflection, in addition to the common challenges of occlusion, symmetry, and
variations in illumination and environments. In order to collect data of
sufficient scale for modern deep learning models, we propose a novel method for
efficiently annotating pose data in a multi-view fashion that allows data
capturing in complex and flexible environments. Fully annotated with 6D object
poses, our dataset contains over 396K frames and over 1.5M annotations of 18
objects recorded in 183 scenes constructed in 11 different environments. The 18
objects include 8 symmetric objects, 7 transparent objects, and 8 reflective
objects. We benchmark two state-of-the-art pose estimation frameworks on
StereOBJ-1M as baselines for future work. We also propose a novel object-level
pose optimization method for computing 6D pose from keypoint predictions in
multiple images.

    

### [[2109.10119] mGNN: Generalizing the Graph Neural Networks to the Multilayer Case](http://arxiv.org/abs/2109.10119)


  Networks are a powerful tool to model complex systems, and the definition of
many Graph Neural Networks (GNN), Deep Learning algorithms that can handle
networks, has opened a new way to approach many real-world problems that would
be hardly or even untractable. In this paper, we propose mGNN, a framework
meant to generalize GNNs to the case of multi-layer networks, i.e., networks
that can model multiple kinds of interactions and relations between nodes. Our
approach is general (i.e., not task specific) and has the advantage of
extending any type of GNN without any computational overhead. We test the
framework into three different tasks (node and network classification, link
prediction) to validate it.

    

### [[2109.10123] Survey on Semantic Stereo Matching / Semantic Depth Estimation](http://arxiv.org/abs/2109.10123)


  Stereo matching is one of the widely used techniques for inferring depth from
stereo images owing to its robustness and speed. It has become one of the major
topics of research since it finds its applications in autonomous driving,
robotic navigation, 3D reconstruction, and many other fields. Finding pixel
correspondences in non-textured, occluded and reflective areas is the major
challenge in stereo matching. Recent developments have shown that semantic cues
from image segmentation can be used to improve the results of stereo matching.
Many deep neural network architectures have been proposed to leverage the
advantages of semantic segmentation in stereo matching. This paper aims to give
a comparison among the state of art networks both in terms of accuracy and in
terms of speed which are of higher importance in real-time applications.

    

### [[2109.10127] KDFNet: Learning Keypoint Distance Field for 6D Object Pose Estimation](http://arxiv.org/abs/2109.10127)


  We present KDFNet, a novel method for 6D object pose estimation from RGB
images. To handle occlusion, many recent works have proposed to localize 2D
keypoints through pixel-wise voting and solve a Perspective-n-Point (PnP)
problem for pose estimation, which achieves leading performance. However, such
voting process is direction-based and cannot handle long and thin objects where
the direction intersections cannot be robustly found. To address this problem,
we propose a novel continuous representation called Keypoint Distance Field
(KDF) for projected 2D keypoint locations. Formulated as a 2D array, each
element of the KDF stores the 2D Euclidean distance between the corresponding
image pixel and a specified projected 2D keypoint. We use a fully convolutional
neural network to regress the KDF for each keypoint. Using this KDF encoding of
projected object keypoint locations, we propose to use a distance-based voting
scheme to localize the keypoints by calculating circle intersections in a
RANSAC fashion. We validate the design choices of our framework by extensive
ablation experiments. Our proposed method achieves state-of-the-art performance
on Occlusion LINEMOD dataset with an average ADD(-S) accuracy of 50.3% and TOD
dataset mug subset with an average ADD accuracy of 75.72%. Extensive
experiments and visualizations demonstrate that the proposed method is able to
robustly estimate the 6D pose in challenging scenarios including occlusion.

    

### [[2109.10135] Self-supervised Representation Learning for Reliable Robotic Monitoring of Fruit Anomalies](http://arxiv.org/abs/2109.10135)


  Data augmentation can be a simple yet powerful tool for autonomous robots to
fully utilise available data for self-supervised identification of atypical
scenes or objects. State-of-the-art augmentation methods arbitrarily embed
structural peculiarity in focal objects on typical images so that classifying
these artefacts can provide guidance for learning representations for the
detection of anomalous visual inputs. In this paper, however, we argue that
learning such structure-sensitive representations can be a suboptimal approach
to some classes of anomaly (e.g., unhealthy fruits) which are better recognised
by a different type of visual element such as "colour". We thus propose Channel
Randomisation as a novel data augmentation method for restricting neural
network models to learn encoding of "colour irregularity" whilst predicting
channel-randomised images to ultimately build reliable fruit-monitoring robots
identifying atypical fruit qualities. Our experiments show that (1) the
colour-based alternative can better learn representations for consistently
accurate identification of fruit anomalies in various fruit species, and (2)
validation accuracy can be monitored for early stopping of training due to
positive correlation between the colour-learning task and fruit anomaly
detection. Moreover, the proposed approach is evaluated on a new anomaly
dataset Riseholme-2021, consisting of 3:5K strawberry images collected from a
mobile robot, which we share with the community to encourage active
agri-robotics research.

    

### [[2109.10162] Learning low-degree functions from a logarithmic number of random queries](http://arxiv.org/abs/2109.10162)


  We prove that for any integer $n\in\mathbb{N}$, $d\in\{1,\ldots,n\}$ and any
$\varepsilon,\delta\in(0,1)$, a bounded function $f:\{-1,1\}^n\to[-1,1]$ of
degree at most $d$ can be learned with probability at least $1-\delta$ and
$L_2$-error $\varepsilon$ using $\log(\tfrac{n}{\delta})\,\varepsilon^{-d-1}
C^{d^{3/2}\sqrt{\log d}}$ random queries for a universal finite constant $C>1$.

    

### [[2109.10173] Long-Term Exploration in Persistent MDPs](http://arxiv.org/abs/2109.10173)


  Exploration is an essential part of reinforcement learning, which restricts
the quality of learned policy. Hard-exploration environments are defined by
huge state space and sparse rewards. In such conditions, an exhaustive
exploration of the environment is often impossible, and the successful training
of an agent requires a lot of interaction steps. In this paper, we propose an
exploration method called Rollback-Explore (RbExplore), which utilizes the
concept of the persistent Markov decision process, in which agents during
training can roll back to visited states. We test our algorithm in the
hard-exploration Prince of Persia game, without rewards and domain knowledge.
At all used levels of the game, our agent outperforms or shows comparable
results with state-of-the-art curiosity methods with knowledge-based intrinsic
motivation: ICM and RND. An implementation of RbExplore can be found at
this https URL.

    

### [[2109.10217] Shape Inference and Grammar Induction for Example-based Procedural Generation](http://arxiv.org/abs/2109.10217)


  Designers increasingly rely on procedural generation for automatic generation
of content in various industries. These techniques require extensive knowledge
of the desired content, and about how to actually implement such procedural
methods. Algorithms for learning interpretable generative models from example
content could alleviate both difficulties. We propose SIGI, a novel method for
inferring shapes and inducing a shape grammar from grid-based 3D building
examples. This interpretable grammar is well-suited for co-creative design.
Applied to Minecraft buildings, we show how the shape grammar can be used to
automatically generate new buildings in a similar style.

    

### [[2109.10219] Adaptive Reliability Analysis for Multi-fidelity Models using a Collective Learning Strategy](http://arxiv.org/abs/2109.10219)


  In many fields of science and engineering, models with different fidelities
are available. Physical experiments or detailed simulations that accurately
capture the behavior of the system are regarded as high-fidelity models with
low model uncertainty, however, they are expensive to run. On the other hand,
simplified physical experiments or numerical models are seen as low-fidelity
models that are cheaper to evaluate. Although low-fidelity models are often not
suitable for direct use in reliability analysis due to their low accuracy, they
can offer information about the trend of the high-fidelity model thus providing
the opportunity to explore the design space at a low cost. This study presents
a new approach called adaptive multi-fidelity Gaussian process for reliability
analysis (AMGPRA). Contrary to selecting training points and information
sources in two separate stages as done in state-of-the-art mfEGRA method, the
proposed approach finds the optimal training point and information source
simultaneously using the novel collective learning function (CLF). CLF is able
to assess the global impact of a candidate training point from an information
source and it accommodates any learning function that satisfies a certain
profile. In this context, CLF provides a new direction for quantifying the
impact of new training points and can be easily extended with new learning
functions to adapt to different reliability problems. The performance of the
proposed method is demonstrated by three mathematical examples and one
engineering problem concerning the wind reliability of transmission towers. It
is shown that the proposed method achieves similar or higher accuracy with
reduced computational costs compared to state-of-the-art single and
multi-fidelity methods. A key application of AMGPRA is high-fidelity fragility
modeling using complex and costly physics-based computational models.

    

### [[2109.10224] Clinical Validation of Single-Chamber Model-Based Algorithms Used to Estimate Respiratory Compliance](http://arxiv.org/abs/2109.10224)


  Non-invasive estimation of respiratory physiology using computational
algorithms promises to be a valuable technique for future clinicians to detect
detrimental changes in patient pathophysiology. However, few clinical
algorithms used to non-invasively analyze lung physiology have undergone
rigorous validation in a clinical setting, and are often validated either using
mechanical devices, or with small clinical validation datasets using 2-8
patients. This work aims to improve this situation by first, establishing an
open, and clinically validated dataset comprising data from both mechanical
lungs and nearly 40,000 breaths from 18 intubated patients. Next, we use this
data to evaluate 15 different algorithms that use the "single chamber" model of
estimating respiratory compliance. We evaluate these algorithms under varying
clinical scenarios patients typically experience during hospitalization. In
particular, we explore algorithm performance under four different types of
patient ventilator asynchrony. We also analyze algorithms under varying
ventilation modes to benchmark algorithm performance and to determine if
ventilation mode has any impact on the algorithm. Our approach yields several
advances by 1) showing which specific algorithms work best clinically under
varying mode and asynchrony scenarios, 2) developing a simple mathematical
method to reduce variance in algorithmic results, and 3) presenting additional
insights about single-chamber model algorithms. We hope that our paper,
approach, dataset, and software framework can thus be used by future
researchers to improve their work and allow future integration of "single
chamber" algorithms into clinical practice.

    

### [[2109.10252] Audiomer: A Convolutional Transformer for Keyword Spotting](http://arxiv.org/abs/2109.10252)


  Transformers have seen an unprecedented rise in Natural Language Processing
and Computer Vision tasks. However, in audio tasks, they are either infeasible
to train due to extremely large sequence length of audio waveforms or reach
competitive performance after feature extraction through Fourier-based methods,
incurring a loss-floor. In this work, we introduce an architecture, Audiomer,
where we combine 1D Residual Networks with Performer Attention to achieve
state-of-the-art performance in Keyword Spotting with raw audio waveforms,
out-performing all previous methods while also being computationally cheaper,
much more parameter and data-efficient. Audiomer allows for deployment in
compute-constrained devices and training on smaller datasets.

    

### [[2109.10253] Short-term traffic prediction using physics-aware neural networks](http://arxiv.org/abs/2109.10253)


  In this work, we propose an algorithm performing short-term predictions of
the flux of vehicles on a stretch of road, using past measurements of the flux.
This algorithm is based on a physics-aware recurrent neural network. A
discretization of a macroscopic traffic flow model (using the so-called Traffic
Reaction Model) is embedded in the architecture of the network and yields flux
predictions based on estimated and predicted space-time dependent traffic
parameters. These parameters are themselves obtained using a succession of LSTM
ans simple recurrent neural networks. Besides, on top of the predictions, the
algorithm yields a smoothing of its inputs which is also physically-constrained
by the macroscopic traffic flow model. The algorithm is tested on raw flux
measurements obtained from loop detectors.

    

### [[2109.10254] Uncertainty Toolbox: an Open-Source Library for Assessing, Visualizing, and Improving Uncertainty Quantification](http://arxiv.org/abs/2109.10254)


  With increasing deployment of machine learning systems in various real-world
tasks, there is a greater need for accurate quantification of predictive
uncertainty. While the common goal in uncertainty quantification (UQ) in
machine learning is to approximate the true distribution of the target data,
many works in UQ tend to be disjoint in the evaluation metrics utilized, and
disparate implementations for each metric lead to numerical results that are
not directly comparable across different works. To address this, we introduce
Uncertainty Toolbox, an open-source python library that helps to assess,
visualize, and improve UQ. Uncertainty Toolbox additionally provides
pedagogical resources, such as a glossary of key terms and an organized
collection of key paper references. We hope that this toolbox is useful for
accelerating and uniting research efforts in uncertainty in machine learning.

    

### [[2109.10258] Discovery of temporal structure intricacy in arterial blood pressure waveforms representing acuity of liver transplant and forecasting short term surgical outcome via unsupervised manifold learning](http://arxiv.org/abs/2109.10258)


  Background: Arterial blood pressure (ABP) waveform evolves across each
consecutive pulse during the liver transplant surgery. We hypothesized that the
quantification of the waveform evolution reflects 1) the acuity of the
recipient undergoing liver transplant and 2) the intraoperative dynamics that
forecasts short-term surgical outcomes. Methods: In this prospective
observational single cohort study on living donor liver transplant surgery, we
extracted the waveform morphological evolution from the ABP data with the
unsupervised manifold learning waveform analysis. Two quantitative indices,
trend movement and fluctuation movement, were developed to represent the
slow-varying and fast-varying dynamics respectively. We investigated the
associations with the liver disease acuity represented with the Model for
End-Stage Liver Disease (MELD) score and the primary outcomes, the early
allograft failure (EAF), as well as the recently developed EAF scores,
including the Liver Graft Assessment Following Transplantation (L-GrAFT) score,
the Early Allograft Failure Simplified Estimation (EASE) score, and the Model
for Early Allograft Function (MEAF) score. Results: Sixty recipients were
enrolled. The presurgical trend movement was correlated with the MELD scores.
It decreased in the anhepatic phase. The neohepatic trend movement correlated
with the L-GrAFT scores, the EASE score, and the MEAF score. Regarding the
constituent of the EAF scores, the trend movement most correlated with the
postoperative day 7 bilirubin. Conclusions: The ABP waveform evolution
intricacy in the presurgical phase reflects recipients' acuity condition while
that in the neohepatic phase reveal the short-term surgical outcome calculated
from laboratory data in postoperative day 7-10. The waveform evolution reflects
the intraoperative contribution to the early outcome.

    

### [[2109.10259] AutoGCL: Automated Graph Contrastive Learning via Learnable View Generators](http://arxiv.org/abs/2109.10259)


  Contrastive learning has been widely applied to graph representation
learning, where the view generators play a vital role in generating effective
contrastive samples. Most of the existing contrastive learning methods employ
pre-defined view generation methods, e.g., node drop or edge perturbation,
which usually cannot adapt to input data or preserve the original semantic
structures well. To address this issue, we propose a novel framework named
Automated Graph Contrastive Learning (AutoGCL) in this paper. Specifically,
AutoGCL employs a set of learnable graph view generators orchestrated by an
auto augmentation strategy, where every graph view generator learns a
probability distribution of graphs conditioned by the input. While the graph
view generators in AutoGCL preserve the most representative structures of the
original graph in generation of every contrastive sample, the auto augmentation
learns policies to introduce adequate augmentation variances in the whole
contrastive learning procedure. Furthermore, AutoGCL adopts a joint training
strategy to train the learnable view generators, the graph encoder, and the
classifier in an end-to-end manner, resulting in topological heterogeneity yet
semantic similarity in the generation of contrastive samples. Extensive
experiments on semi-supervised learning, unsupervised learning, and transfer
learning demonstrate the superiority of our AutoGCL framework over the
state-of-the-arts in graph contrastive learning. In addition, the visualization
results further confirm that the learnable view generators can deliver more
compact and semantically meaningful contrastive samples compared against the
existing view generation methods.

    

### [[2109.10262] Generalized Optimization: A First Step Towards Category Theoretic Learning Theory](http://arxiv.org/abs/2109.10262)


  The Cartesian reverse derivative is a categorical generalization of
reverse-mode automatic differentiation. We use this operator to generalize
several optimization algorithms, including a straightforward generalization of
gradient descent and a novel generalization of Newton's method. We then explore
which properties of these algorithms are preserved in this generalized setting.
First, we show that the transformation invariances of these algorithms are
preserved: while generalized Newton's method is invariant to all invertible
linear transformations, generalized gradient descent is invariant only to
orthogonal linear transformations. Next, we show that we can express the change
in loss of generalized gradient descent with an inner product-like expression,
thereby generalizing the non-increasing and convergence properties of the
gradient descent optimization flow. Finally, we include several numerical
experiments to illustrate the ideas in the paper and demonstrate how we can use
them to optimize polynomial functions over an ordered ring.

    

### [[2109.10266] Comparison of single and multitask learning for predicting cognitive decline based on MRI data](http://arxiv.org/abs/2109.10266)


  The Alzheimer's Disease Assessment Scale-Cognitive subscale (ADAS-Cog) is a
neuropsychological tool that has been designed to assess the severity of
cognitive symptoms of dementia. Personalized prediction of the changes in
ADAS-Cog scores could help in timing therapeutic interventions in dementia and
at-risk populations. In the present work, we compared single and multitask
learning approaches to predict the changes in ADAS-Cog scores based on
T1-weighted anatomical magnetic resonance imaging (MRI). In contrast to most
machine learning-based prediction methods ADAS-Cog changes, we stratified the
subjects based on their baseline diagnoses and evaluated the prediction
performances in each group. Our experiments indicated a positive relationship
between the predicted and observed ADAS-Cog score changes in each diagnostic
group, suggesting that T1-weighted MRI has a predictive value for evaluating
cognitive decline in the entire AD continuum. We further studied whether
correction of the differences in the magnetic field strength of MRI would
improve the ADAS-Cog score prediction. The partial least square-based domain
adaptation slightly improved the prediction performance, but the improvement
was marginal. In summary, this study demonstrated that ADAS-Cog change could
be, to some extent, predicted based on anatomical MRI. Based on this study, the
recommended method for learning the predictive models is a single-task
regularized linear regression due to its simplicity and good performance. It
appears important to combine the training data across all subject groups for
the most effective predictive models.

    

### [[2109.10279] Multiblock-Networks: A Neural Network Analog to Component Based Methods for Multi-Source Data](http://arxiv.org/abs/2109.10279)


  Training predictive models on datasets from multiple sources is a common, yet
challenging setup in applied machine learning. Even though model interpretation
has attracted more attention in recent years, many modeling approaches still
focus mainly on performance. To further improve the interpretability of machine
learning models, we suggest the adoption of concepts and tools from the
well-established framework of component based multiblock analysis, also known
as chemometrics. Nevertheless, artificial neural networks provide greater
flexibility in model architecture and thus, often deliver superior predictive
performance. In this study, we propose a setup to transfer the concepts of
component based statistical models, including multiblock variants of principal
component regression and partial least squares regression, to neural network
architectures. Thereby, we combine the flexibility of neural networks with the
concepts for interpreting block relevance in multiblock methods. In two use
cases we demonstrate how the concept can be implemented in practice, and
compare it to both common feed-forward neural networks without blocks, as well
as statistical component based multiblock methods. Our results underline that
multiblock networks allow for basic model interpretation while matching the
performance of ordinary feed-forward neural networks.

    

### [[2109.10298] Assured Neural Network Architectures for Control and Identification of Nonlinear Systems](http://arxiv.org/abs/2109.10298)


  In this paper, we consider the problem of automatically designing a Rectified
Linear Unit (ReLU) Neural Network (NN) architecture (number of layers and
number of neurons per layer) with the assurance that it is sufficiently
parametrized to control a nonlinear system; i.e. control the system to satisfy
a given formal specification. This is unlike current techniques, which provide
no assurances on the resultant architecture. Moreover, our approach requires
only limited knowledge of the underlying nonlinear system and specification. We
assume only that the specification can be satisfied by a Lipschitz-continuous
controller with a known bound on its Lipschitz constant; the specific
controller need not be known. From this assumption, we bound the number of
affine functions needed to construct a Continuous Piecewise Affine (CPWA)
function that can approximate any Lipschitz-continuous controller that
satisfies the specification. Then we connect this CPWA to a NN architecture
using the authors' recent results on the Two-Level Lattice (TLL) NN
architecture; the TLL architecture was shown to be parameterized by the number
of affine functions present in the CPWA function it realizes.

    

### [[2109.10304] Learning PAC-Bayes Priors for Probabilistic Neural Networks](http://arxiv.org/abs/2109.10304)


  Recent works have investigated deep learning models trained by optimising
PAC-Bayes bounds, with priors that are learnt on subsets of the data. This
combination has been shown to lead not only to accurate classifiers, but also
to remarkably tight risk certificates, bearing promise towards self-certified
learning (i.e. use all the data to learn a predictor and certify its quality).
In this work, we empirically investigate the role of the prior. We experiment
on 6 datasets with different strategies and amounts of data to learn
data-dependent PAC-Bayes priors, and we compare them in terms of their effect
on test performance of the learnt predictors and tightness of their risk
certificate. We ask what is the optimal amount of data which should be
allocated for building the prior and show that the optimum may be dataset
dependent. We demonstrate that using a small percentage of the prior-building
data for validation of the prior leads to promising results. We include a
comparison of underparameterised and overparameterised models, along with an
empirical study of different training objectives and regularisation strategies
to learn the prior distribution.

    

### [[2109.10312] Example-Driven Model-Based Reinforcement Learning for Solving Long-Horizon Visuomotor Tasks](http://arxiv.org/abs/2109.10312)


  In this paper, we study the problem of learning a repertoire of low-level
skills from raw images that can be sequenced to complete long-horizon
visuomotor tasks. Reinforcement learning (RL) is a promising approach for
acquiring short-horizon skills autonomously. However, the focus of RL
algorithms has largely been on the success of those individual skills, more so
than learning and grounding a large repertoire of skills that can be sequenced
to complete extended multi-stage tasks. The latter demands robustness and
persistence, as errors in skills can compound over time, and may require the
robot to have a number of primitive skills in its repertoire, rather than just
one. To this end, we introduce EMBR, a model-based RL method for learning
primitive skills that are suitable for completing long-horizon visuomotor
tasks. EMBR learns and plans using a learned model, critic, and success
classifier, where the success classifier serves both as a reward function for
RL and as a grounding mechanism to continuously detect if the robot should
retry a skill when unsuccessful or under perturbations. Further, the learned
model is task-agnostic and trained using data from all skills, enabling the
robot to efficiently learn a number of distinct primitives. These visuomotor
primitive skills and their associated pre- and post-conditions can then be
directly combined with off-the-shelf symbolic planners to complete long-horizon
tasks. On a Franka Emika robot arm, we find that EMBR enables the robot to
complete three long-horizon visuomotor tasks at 85% success rate, such as
organizing an office desk, a file cabinet, and drawers, which require
sequencing up to 12 skills, involve 14 unique learned primitives, and demand
generalization to novel objects.

    

### [[2109.10317] Introduction to Neural Network Verification](http://arxiv.org/abs/2109.10317)


  Deep learning has transformed the way we think of software and what it can
do. But deep neural networks are fragile and their behaviors are often
surprising. In many settings, we need to provide formal guarantees on the
safety, security, correctness, or robustness of neural networks. This book
covers foundational ideas from formal verification and their adaptation to
reasoning about neural networks and deep learning.

    

### [[2109.10319] Consistency of spectral clustering for directed network community detection](http://arxiv.org/abs/2109.10319)


  Directed networks appear in various areas, such as biology, sociology,
physiology and computer science. However, at present, most network analysis
ignores the direction. In this paper, we construct a spectral clustering method
based on the singular decomposition of the adjacency matrix to detect community
in directed stochastic block model (DiSBM). By considering a sparsity
parameter, under some mild conditions, we show the proposed approach can
consistently recover hidden row and column communities for different scaling of
degrees.
By considering the degree heterogeneity of both row and column nodes, we
further establish a theoretical framework for directed degree corrected
stochastic block model (DiDCSBM). We show that the spectral clustering method
stably yields consistent community detection for row clusters and column
clusters under mild constraints on the degree heterogeneity. Our theoretical
results under DiSBM and DiDCSBM provide some innovations on some special
directed networks, such as directed network with balanced clusters, directed
network with nodes enjoying similar degrees, and the directed Erdös-Rényi
graph. Furthermore, our theoretical results under DiDCSBM are consistent with
those under DiSBM when DiDCSBM degenerates to DiSBM.

    

### [[2109.10322] CondNet: Conditional Classifier for Scene Segmentation](http://arxiv.org/abs/2109.10322)


  The fully convolutional network (FCN) has achieved tremendous success in
dense visual recognition tasks, such as scene segmentation. The last layer of
FCN is typically a global classifier (1x1 convolution) to recognize each pixel
to a semantic label. We empirically show that this global classifier, ignoring
the intra-class distinction, may lead to sub-optimal results.
In this work, we present a conditional classifier to replace the traditional
global classifier, where the kernels of the classifier are generated
dynamically conditioned on the input. The main advantages of the new classifier
consist of: (i) it attends on the intra-class distinction, leading to stronger
dense recognition capability; (ii) the conditional classifier is simple and
flexible to be integrated into almost arbitrary FCN architectures to improve
the prediction. Extensive experiments demonstrate that the proposed classifier
performs favourably against the traditional classifier on the FCN architecture.
The framework equipped with the conditional classifier (called CondNet)
achieves new state-of-the-art performances on two datasets. The code and models
are available at this https URL.

    

### [[2109.10329] Homography augumented momentum constrastive learning for SAR image retrieval](http://arxiv.org/abs/2109.10329)


  Deep learning-based image retrieval has been emphasized in computer vision.
Representation embedding extracted by deep neural networks (DNNs) not only aims
at containing semantic information of the image, but also can manage
large-scale image retrieval tasks. In this work, we propose a deep
learning-based image retrieval approach using homography transformation
augmented contrastive learning to perform large-scale synthetic aperture radar
(SAR) image search tasks. Moreover, we propose a training method for the DNNs
induced by contrastive learning that does not require any labeling procedure.
This may enable tractability of large-scale datasets with relative ease.
Finally, we verify the performance of the proposed method by conducting
experiments on the polarimetric SAR image datasets.

    

### [[2109.10341] Multilingual Document-Level Translation Enables Zero-Shot Transfer From Sentences to Documents](http://arxiv.org/abs/2109.10341)


  Document-level neural machine translation (DocNMT) delivers coherent
translations by incorporating cross-sentence context. However, for most
language pairs there's a shortage of parallel documents, although parallel
sentences are readily available. In this paper, we study whether and how
contextual modeling in DocNMT is transferable from sentences to documents in a
zero-shot fashion (i.e. no parallel documents for student languages) through
multilingual modeling. Using simple concatenation-based DocNMT, we explore the
effect of 3 factors on multilingual transfer: the number of document-supervised
teacher languages, the data schedule for parallel documents at training, and
the data condition of parallel documents (genuine vs. backtranslated). Our
experiments on Europarl-7 and IWSLT-10 datasets show the feasibility of
multilingual transfer for DocNMT, particularly on document-specific metrics. We
observe that more teacher languages and adequate data schedule both contribute
to better transfer quality. Surprisingly, the transfer is less sensitive to the
data condition and multilingual DocNMT achieves comparable performance with
both back-translated and genuine document pairs.

    

### [[2109.10346] Relation-Guided Pre-Training for Open-Domain Question Answering](http://arxiv.org/abs/2109.10346)


  Answering complex open-domain questions requires understanding the latent
relations between involving entities. However, we found that the existing QA
datasets are extremely imbalanced in some types of relations, which hurts the
generalization performance over questions with long-tail relations. To remedy
this problem, in this paper, we propose a Relation-Guided Pre-Training
(RGPT-QA) framework. We first generate a relational QA dataset covering a wide
range of relations from both the Wikidata triplets and Wikipedia hyperlinks. We
then pre-train a QA model to infer the latent relations from the question, and
then conduct extractive QA to get the target answer entity. We demonstrate that
by pretraining with propoed RGPT-QA techique, the popular open-domain QA model,
Dense Passage Retriever (DPR), achieves 2.2%, 2.4%, and 6.3% absolute
improvement in Exact Match accuracy on Natural Questions, TriviaQA, and
WebQuestions. Particularly, we show that RGPT-QA improves significantly on
questions with long-tail relations

    

### [[1905.10029] Power up! Robust Graph Convolutional Network via Graph Powering](http://arxiv.org/abs/1905.10029)


  Graph convolutional networks (GCNs) are powerful tools for graph-structured
data. However, they have been recently shown to be vulnerable to topological
attacks. To enhance adversarial robustness, we go beyond spectral graph theory
to robust graph theory. By challenging the classical graph Laplacian, we
propose a new convolution operator that is provably robust in the spectral
domain and is incorporated in the GCN architecture to improve expressivity and
interpretability. By extending the original graph to a sequence of graphs, we
also propose a robust training paradigm that encourages transferability across
graphs that span a range of spatial and spectral characteristics. The proposed
approaches are demonstrated in extensive experiments to simultaneously improve
performance in both benign and adversarial situations.

    

### [[2001.02112] Multitask learning over graphs: An Approach for Distributed, Streaming Machine Learning](http://arxiv.org/abs/2001.02112)


  The problem of learning simultaneously several related tasks has received
considerable attention in several domains, especially in machine learning with
the so-called multitask learning problem or learning to learn problem [1], [2].
Multitask learning is an approach to inductive transfer learning (using what is
learned for one problem to assist in another problem) and helps improve
generalization performance relative to learning each task separately by using
the domain information contained in the training signals of related tasks as an
inductive bias. Several strategies have been derived within this community
under the assumption that all data are available beforehand at a fusion center.
However, recent years have witnessed an increasing ability to collect data in a
distributed and streaming manner. This requires the design of new strategies
for learning jointly multiple tasks from streaming data over distributed (or
networked) systems. This article provides an overview of multitask strategies
for learning and adaptation over networks. The working hypothesis for these
strategies is that agents are allowed to cooperate with each other in order to
learn distinct, though related tasks. The article shows how cooperation steers
the network limiting point and how different cooperation rules allow to promote
different task relatedness models. It also explains how and when cooperation
over multitask networks outperforms non-cooperative strategies.

    

### [[2002.02851] On the Estimation of Information Measures of Continuous Distributions](http://arxiv.org/abs/2002.02851)


  The estimation of information measures of continuous distributions based on
samples is a fundamental problem in statistics and machine learning. In this
paper, we analyze estimates of differential entropy in $K$-dimensional
Euclidean space, computed from a finite number of samples, when the probability
density function belongs to a predetermined convex family $\mathcal{P}$. First,
estimating differential entropy to any accuracy is shown to be infeasible if
the differential entropy of densities in $\mathcal{P}$ is unbounded, clearly
showing the necessity of additional assumptions. Subsequently, we investigate
sufficient conditions that enable confidence bounds for the estimation of
differential entropy. In particular, we provide confidence bounds for simple
histogram based estimation of differential entropy from a fixed number of
samples, assuming that the probability density function is Lipschitz continuous
with known Lipschitz constant and known, bounded support. Our focus is on
differential entropy, but we provide examples that show that similar results
hold for mutual information and relative entropy as well.

    

### [[2003.05738] IG-RL: Inductive Graph Reinforcement Learning for Massive-Scale Traffic Signal Control](http://arxiv.org/abs/2003.05738)


  Scaling adaptive traffic-signal control involves dealing with combinatorial
state and action spaces. Multi-agent reinforcement learning attempts to address
this challenge by distributing control to specialized agents. However,
specialization hinders generalization and transferability, and the
computational graphs underlying neural-networks architectures -- dominating in
the multi-agent setting -- do not offer the flexibility to handle an arbitrary
number of entities which changes both between road networks, and over time as
vehicles traverse the network. We introduce Inductive Graph Reinforcement
Learning (IG-RL) based on graph-convolutional networks which adapts to the
structure of any road network, to learn detailed representations of
traffic-controllers and their surroundings. Our decentralized approach enables
learning of a transferable-adaptive-traffic-signal-control policy. After being
trained on an arbitrary set of road networks, our model can generalize to new
road networks, traffic distributions, and traffic regimes, with no additional
training and a constant number of parameters, enabling greater scalability
compared to prior methods. Furthermore, our approach can exploit the
granularity of available data by capturing the (dynamic) demand at both the
lane and the vehicle levels. The proposed method is tested on both road
networks and traffic settings never experienced during training. We compare
IG-RL to multi-agent reinforcement learning and domain-specific baselines. In
both synthetic road networks and in a larger experiment involving the control
of the 3,971 traffic signals of Manhattan, we show that different
instantiations of IG-RL outperform baselines.

    

### [[2003.09603] Dynamic Sampling and Selective Masking for Communication-Efficient Federated Learning](http://arxiv.org/abs/2003.09603)


  Federated learning (FL) is a novel machine learning setting that enables
on-device intelligence via decentralized training and federated optimization.
Deep neural networks' rapid development facilitates the learning techniques for
modeling complex problems and emerges into federated deep learning under the
federated setting. However, the tremendous amount of model parameters burdens
the communication network with a high load of transportation. This paper
introduces two approaches for improving communication efficiency by dynamic
sampling and top-$k$ selective masking. The former controls the fraction of
selected client models dynamically, while the latter selects parameters with
top-$k$ largest values of difference for federated updating. Experiments on
convolutional image classification and recurrent language modeling are
conducted on three public datasets to show our proposed methods' effectiveness.

    

### [[2004.14364] Informed Sampling for Diversity in Concept-to-Text NLG](http://arxiv.org/abs/2004.14364)


  Deep-learning models for language generation tasks tend to produce repetitive
output. Various methods have been proposed to encourage lexical diversity
during decoding, but this often comes at a cost to the perceived fluency and
adequacy of the output. In this work, we propose to ameliorate this cost by
using an Imitation Learning approach to explore the level of diversity that a
language generation model can reliably produce. Specifically, we augment the
decoding process with a meta-classifier trained to distinguish which words at
any given timestep will lead to high-quality output. We focus our experiments
on concept-to-text generation where models are sensitive to the inclusion of
irrelevant words due to the strict relation between input and output. Our
analysis shows that previous methods for diversity underperform in this
setting, while human evaluation suggests that our proposed method achieves a
high level of diversity with minimal effect to the output's fluency and
adequacy.

    

### [[2004.14427] Whittle index based Q-learning for restless bandits with average reward](http://arxiv.org/abs/2004.14427)


  A novel reinforcement learning algorithm is introduced for multiarmed
restless bandits with average reward, using the paradigms of Q-learning and
Whittle index. Specifically, we leverage the structure of the Whittle index
policy to reduce the search space of Q-learning, resulting in major
computational gains. Rigorous convergence analysis is provided, supported by
numerical experiments. The numerical experiments show excellent empirical
performance of the proposed scheme.

    

### [[2004.14487] Teaching Cameras to Feel: Estimating Tactile Physical Properties of Surfaces From Images](http://arxiv.org/abs/2004.14487)


  The connection between visual input and tactile sensing is critical for
object manipulation tasks such as grasping and pushing. In this work, we
introduce the challenging task of estimating a set of tactile physical
properties from visual information. We aim to build a model that learns the
complex mapping between visual information and tactile physical properties. We
construct a first of its kind image-tactile dataset with over 400 multiview
image sequences and the corresponding tactile properties. A total of fifteen
tactile physical properties across categories including friction, compliance,
adhesion, texture, and thermal conductance are measured and then estimated by
our models. We develop a cross-modal framework comprised of an adversarial
objective and a novel visuo-tactile joint classification loss. Additionally, we
develop a neural architecture search framework capable of selecting optimal
combinations of viewing angles for estimating a given physical property.

    

### [[2005.11079] Graph Random Neural Network for Semi-Supervised Learning on Graphs](http://arxiv.org/abs/2005.11079)


  We study the problem of semi-supervised learning on graphs, for which graph
neural networks (GNNs) have been extensively explored. However, most existing
GNNs inherently suffer from the limitations of over-smoothing, non-robustness,
and weak-generalization when labeled nodes are scarce. In this paper, we
propose a simple yet effective framework -- GRAPH RANDOM NEURAL NETWORKS
(GRAND) -- to address these issues. In GRAND, we first design a random
propagation strategy to perform graph data augmentation. Then we leverage
consistency regularization to optimize the prediction consistency of unlabeled
nodes across different data augmentations. Extensive experiments on graph
benchmark datasets suggest that GRAND significantly outperforms
state-of-the-art GNN baselines on semi-supervised node classification. Finally,
we show that GRAND mitigates the issues of over-smoothing and non-robustness,
exhibiting better generalization behavior than existing GNNs. The source code
of GRAND is publicly available at this https URL.

    

### [[2007.10144] Competing Bandits: The Perils of Exploration Under Competition](http://arxiv.org/abs/2007.10144)


  Most online platforms strive to learn from interactions with users, and many
engage in exploration: making potentially suboptimal choices for the sake of
acquiring new information. We study the interplay between exploration and
competition: how such platforms balance the exploration for learning and the
competition for users. Here users play three distinct roles: they are customers
that generate revenue, they are sources of data for learning, and they are
self-interested agents which choose among the competing platforms.
We consider a stylized duopoly model in which two firms face the same
multi-armed bandit problem. Users arrive one by one and choose between the two
firms, so that each firm makes progress on its bandit problem only if it is
chosen. Through a mix of theoretical results and numerical simulations, we
study whether and to what extent competition incentivizes the adoption of
better bandit algorithms, and whether it leads to welfare increases for users.
We find that stark competition induces firms to commit to a "greedy" bandit
algorithm that leads to low welfare. However, weakening competition by
providing firms with some "free" users incentivizes better exploration
strategies and increases welfare. We investigate two channels for weakening the
competition: relaxing the rationality of users and giving one firm a
first-mover advantage. Our findings are closely related to the "competition vs.
innovation" relationship, and elucidate the first-mover advantage in the
digital economy.

    

### [[2009.05076] Utterance Clustering Using Stereo Audio Channels](http://arxiv.org/abs/2009.05076)


  Utterance clustering is one of the actively researched topics in audio signal
processing and machine learning. This study aims to improve the performance of
utterance clustering by processing multichannel (stereo) audio signals.
Processed audio signals were generated by combining left- and right-channel
audio signals in a few different ways and then extracted embedded features
(also called d-vectors) from those processed audio signals. This study applied
the Gaussian mixture model for supervised utterance clustering. In the training
phase, a parameter sharing Gaussian mixture model was conducted to train the
model for each speaker. In the testing phase, the speaker with the maximum
likelihood was selected as the detected speaker. Results of experiments with
real audio recordings of multi-person discussion sessions showed that the
proposed method that used multichannel audio signals achieved significantly
better performance than a conventional method with mono audio signals in more
complicated conditions.

    

### [[2009.13267] Energy-Based Reranking: Improving Neural Machine Translation Using Energy-Based Models](http://arxiv.org/abs/2009.13267)


  The discrepancy between maximum likelihood estimation (MLE) and task measures
such as BLEU score has been studied before for autoregressive neural machine
translation (NMT) and resulted in alternative training algorithms (Ranzato et
al., 2016; Norouzi et al., 2016; Shen et al., 2016; Wu et al., 2018). However,
MLE training remains the de facto approach for autoregressive NMT because of
its computational efficiency and stability. Despite this mismatch between the
training objective and task measure, we notice that the samples drawn from an
MLE-based trained NMT support the desired distribution -- there are samples
with much higher BLEU score comparing to the beam decoding output. To benefit
from this observation, we train an energy-based model to mimic the behavior of
the task measure (i.e., the energy-based model assigns lower energy to samples
with higher BLEU score), which is resulted in a re-ranking algorithm based on
the samples drawn from NMT: energy-based re-ranking (EBR). We use both marginal
energy models (over target sentence) and joint energy models (over both source
and target sentences). Our EBR with the joint energy model consistently
improves the performance of the Transformer-based NMT: +4 BLEU points on
IWSLT'14 German-English, +3.0 BELU points on Sinhala-English, +1.2 BLEU on
WMT'16 English-German tasks.

    

### [[2010.05784] Deep Distributionally Robust Learning for Calibrated Uncertainties under Domain Shift](http://arxiv.org/abs/2010.05784)


  We propose a deep distributionally robust learning framework for calibrated
uncertainties under domain shifts. We consider cases where the source
(training) distribution differs significantly from the target (test)
distribution. In addition to the standard class predictor, our framework
contains a binary domain classifier which estimates the density ratio between
the source and target domains. We incorporate both with neural networks and
train them end-to-end. The framework is demonstrated to generate calibrated
uncertainties that benefit many downstream tasks, including unsupervised domain
adaptation (UDA) and semi-supervised learning (SSL) where methods such as
self-training and FixMatch use uncertainties to select confident pseudo-labels.
Our experiments show that the introduction of DRL to these methods leads to
significant improvements in cross-domain performance. We also demonstrate that
the produced density ratio estimates show agreement with the human selection
frequencies, suggesting a match with the human perceived uncertainties. The
source code of this work will be made publicly available.

    

### [[2011.02073] MBB: Model-Based Baseline for Efficient Reinforcement Learning](http://arxiv.org/abs/2011.02073)


  Model-free reinforcement learning (RL) is capable of learning control
policies for high-dimensional, complex robotic tasks, but tends to be
data-inefficient. Model-based RL tends to be more data-efficient but often
suffers from learning a high-dimensional model that is good enough for policy
improvement. This limits its use to learning simple models for restrictive
domains. Optimal control generates solutions without collecting any data,
assuming an accurate model of the system and environment is known, which is
often true in many control theory applications. However, optimal control cannot
be scaled to problems with a high-dimensional state space. In this paper, we
propose a novel approach to alleviate data inefficiency of model-free RL in
high-dimensional problems by warm-starting the learning process using a
lower-dimensional model-based solution. Particularly, we initialize a baseline
function for the high-dimensional RL problem via supervision from a
lower-dimensional value function, which can be obtained by solving a
lower-dimensional problem with a known, approximate model using "classical"
techniques such as value iteration or optimal control. Therefore, our approach
implicitly exploits the model priors from simplified problem space to
facilitate the policy learning in high-dimensional RL tasks. We demonstrate our
approach on two representative robotic learning tasks and observe significant
improvement in policy performance and learning efficiency. We also evaluate our
method empirically with a third task.

    

### [[2011.11152] Understanding and Scheduling Weight Decay](http://arxiv.org/abs/2011.11152)


  Weight decay is a popular and even necessary regularization technique for
training deep neural networks that generalize well. Previous work usually
interpreted weight decay as a Gaussian prior from the Bayesian perspective.
However, weight decay sometimes shows mysterious behaviors beyond the
conventional understanding. For example, the optimal weight decay value tends
to be zero given long enough training time. Moreover, existing work typically
failed to recognize the importance of scheduling weight decay during training.
Our work aims at theoretically understanding novel behaviors of weight decay
and designing schedulers for weight decay in deep learning. This paper mainly
has three contributions. First, we propose a novel theoretical interpretation
of weight decay from the perspective of learning dynamics. Second, we propose a
novel weight-decay linear scaling rule for large-batch training that
proportionally increases weight decay rather than the learning rate as the
batch size increases. Third, we provide an effective learning-rate-aware
scheduler for weight decay, called the Stable Weight Decay (SWD) method, which,
to the best of our knowledge, is the first practical design for weight decay
scheduling. In our various experiments, the SWD method often makes improvements
over $L_{2}$ Regularization and Decoupled Weight Decay.

    

### [[2011.11421] Deep Directed Information-Based Learning for Privacy-Preserving Smart Meter Data Release](http://arxiv.org/abs/2011.11421)


  The explosion of data collection has raised serious privacy concerns in users
due to the possibility that sharing data may also reveal sensitive information.
The main goal of a privacy-preserving mechanism is to prevent a malicious third
party from inferring sensitive information while keeping the shared data
useful. In this paper, we study this problem in the context of time series data
and smart meters (SMs) power consumption measurements in particular. Although
Mutual Information (MI) between private and released variables has been used as
a common information-theoretic privacy measure, it fails to capture the causal
time dependencies present in the power consumption time series data. To
overcome this limitation, we introduce the Directed Information (DI) as a more
meaningful measure of privacy in the considered setting and propose a novel
loss function. The optimization is then performed using an adversarial
framework where two Recurrent Neural Networks (RNNs), referred to as the
releaser and the adversary, are trained with opposite goals. Our empirical
studies on real-world data sets from SMs measurements in the worst-case
scenario where an attacker has access to all the training data set used by the
releaser, validate the proposed method and show the existing trade-offs between
privacy and utility.

    

### [[2012.15059] Ensembles of Localised Models for Time Series Forecasting](http://arxiv.org/abs/2012.15059)


  With large quantities of data typically available nowadays, forecasting
models that are trained across sets of time series, known as Global Forecasting
Models (GFM), are regularly outperforming traditional univariate forecasting
models that work on isolated series. As GFMs usually share the same set of
parameters across all time series, they often have the problem of not being
localised enough to a particular series, especially in situations where
datasets are heterogeneous. We study how ensembling techniques can be used with
generic GFMs and univariate models to solve this issue. Our work systematises
and compares relevant current approaches, namely clustering series and training
separate submodels per cluster, the so-called ensemble of specialists approach,
and building heterogeneous ensembles of global and local models. We fill some
gaps in the existing GFM localisation approaches, in particular by
incorporating varied clustering techniques such as feature-based clustering,
distance-based clustering and random clustering, and generalise them to use
different underlying GFM model types. We then propose a new methodology of
clustered ensembles where we train multiple GFMs on different clusters of
series, obtained by changing the number of clusters and cluster seeds. Using
Feed-forward Neural Networks, Recurrent Neural Networks, and Pooled Regression
models as the underlying GFMs, in our evaluation on eight publicly available
datasets, the proposed models are able to achieve significantly higher accuracy
than baseline GFM models and univariate forecasting methods.

    

### [[2102.00063] Recurrent Localization Networks applied to the Lippmann-Schwinger Equation](http://arxiv.org/abs/2102.00063)


  The bulk of computational approaches for modeling physical systems in
materials science derive from either analytical (i.e. physics based) or
data-driven (i.e. machine-learning based) origins. In order to combine the
strengths of these two approaches, we advance a novel machine learning approach
for solving equations of the generalized Lippmann-Schwinger (L-S) type. In this
paradigm, a given problem is converted into an equivalent L-S equation and
solved as an optimization problem, where the optimization procedure is
calibrated to the problem at hand. As part of a learning-based loop unrolling,
we use a recurrent convolutional neural network to iteratively solve the
governing equations for a field of interest. This architecture leverages the
generalizability and computational efficiency of machine learning approaches,
but also permits a physics-based interpretation. We demonstrate our learning
approach on the two-phase elastic localization problem, where it achieves
excellent accuracy on the predictions of the local (i.e., voxel-level) elastic
strains. Since numerous governing equations can be converted into an equivalent
L-S form, the proposed architecture has potential applications across a range
of multiscale materials phenomena.

    

### [[2102.04140] Quantifying and Mitigating Privacy Risks of Contrastive Learning](http://arxiv.org/abs/2102.04140)


  Data is the key factor to drive the development of machine learning (ML)
during the past decade. However, high-quality data, in particular labeled data,
is often hard and expensive to collect. To leverage large-scale unlabeled data,
self-supervised learning, represented by contrastive learning, is introduced.
The objective of contrastive learning is to map different views derived from a
training sample (e.g., through data augmentation) closer in their
representation space, while different views derived from different samples more
distant. In this way, a contrastive model learns to generate informative
representations for data samples, which are then used to perform downstream ML
tasks. Recent research has shown that machine learning models are vulnerable to
various privacy attacks. However, most of the current efforts concentrate on
models trained with supervised learning. Meanwhile, data samples' informative
representations learned with contrastive learning may cause severe privacy
risks as well.
In this paper, we perform the first privacy analysis of contrastive learning
through the lens of membership inference and attribute inference. Our
experimental results show that contrastive models trained on image datasets are
less vulnerable to membership inference attacks but more vulnerable to
attribute inference attacks compared to supervised models. The former is due to
the fact that contrastive models are less prone to overfitting, while the
latter is caused by contrastive models' capability of representing data samples
expressively. To remedy this situation, we propose the first privacy-preserving
contrastive learning mechanism, Talos, relying on adversarial training.
Empirical results show that Talos can successfully mitigate attribute inference
risks for contrastive models while maintaining their membership privacy and
model utility.

    

### [[2102.04394] Learning with Density Matrices and Random Features](http://arxiv.org/abs/2102.04394)


  A density matrix describes the statistical state of a quantum system. It is a
powerful formalism to represent both the quantum and classical uncertainty of
quantum systems and to express different statistical operations such as
measurement, system combination and expectations as linear algebra operations.
This paper explores how density matrices can be used as a building block to
build machine learning models exploiting their ability to straightforwardly
combine linear algebra and probability. One of the main results of the paper is
to show that density matrices coupled with random Fourier features could
approximate arbitrary probability distributions over $\mathbb{R}^n$. Based on
this finding the paper builds different models for density estimation,
classification and regression. These models are differentiable, so it is
possible to integrate them with other differentiable components, such as deep
learning architectures and to learn their parameters using gradient-based
optimization. In addition, the paper presents optimization-less training
strategies based on estimation and model averaging. The models are evaluated in
benchmark tasks and the results are reported and discussed.

    

### [[2102.07767] Communication-efficient Distributed Cooperative Learning with Compressed Beliefs](http://arxiv.org/abs/2102.07767)


  We study the problem of distributed cooperative learning, where a group of
agents seeks to agree on a set of hypotheses that best describes a sequence of
private observations. In the scenario where the set of hypotheses is large, we
propose a belief update rule where agents share compressed (either sparse or
quantized) beliefs with an arbitrary positive compression rate. Our algorithm
leverages a unified communication rule that enables agents to access
wide-ranging compression operators as black-box modules. We prove the almost
sure asymptotic exponential convergence of beliefs around the set of optimal
hypotheses. Additionally, we show a non-asymptotic, explicit, and linear
concentration rate in probability of the beliefs on the optimal hypothesis set.
We provide numerical experiments to illustrate the communication benefits of
our method. The simulation results show that the number of transmitted bits can
be reduced to 5-10% of the non-compressed method in the studied scenarios.

    

### [[2102.08633] Open-Retrieval Conversational Machine Reading](http://arxiv.org/abs/2102.08633)


  In conversational machine reading, systems need to interpret natural language
rules, answer high-level questions such as "May I qualify for VA health care
benefits?", and ask follow-up clarification questions whose answer is necessary
to answer the original question. However, existing works assume the rule text
is provided for each user question, which neglects the essential retrieval step
in real scenarios. In this work, we propose and investigate an open-retrieval
setting of conversational machine reading. In the open-retrieval setting, the
relevant rule texts are unknown so that a system needs to retrieve
question-relevant evidence from a collection of rule texts, and answer users'
high-level questions according to multiple retrieved rule texts in a
conversational manner. We propose MUDERN, a Multi-passage Discourse-aware
Entailment Reasoning Network which extracts conditions in the rule texts
through discourse segmentation, conducts multi-passage entailment reasoning to
answer user questions directly, or asks clarification follow-up questions to
inquiry more information. On our created OR-ShARC dataset, MUDERN achieves the
state-of-the-art performance, outperforming existing single-passage
conversational machine reading models as well as a new multi-passage
conversational machine reading baseline by a large margin. In addition, we
conduct in-depth analyses to provide new insights into this new setting and our
model.

    

### [[2102.10106] Mine Your Own vieW: Self-Supervised Learning Through Across-Sample Prediction](http://arxiv.org/abs/2102.10106)


  State-of-the-art methods for self-supervised learning (SSL) build
representations by maximizing the similarity between different transformed
"views" of a sample. Without sufficient diversity in the transformations used
to create views, however, it can be difficult to overcome nuisance variables in
the data and build rich representations. This motivates the use of the dataset
itself to find similar, yet distinct, samples to serve as views for one
another. In this paper, we introduce Mine Your Own vieW (MYOW), a new approach
for self-supervised learning that looks within the dataset to define diverse
targets for prediction. The idea behind our approach is to actively mine views,
finding samples that are neighbors in the representation space of the network,
and then predict, from one sample's latent representation, the representation
of a nearby sample. After showing the promise of MYOW on benchmarks used in
computer vision, we highlight the power of this idea in a novel application in
neuroscience where SSL has yet to be applied. When tested on multi-unit neural
recordings, we find that MYOW outperforms other self-supervised approaches in
all examples (in some cases by more than 10%), and often surpasses the
supervised baseline. With MYOW, we show that it is possible to harness the
diversity of the data to build rich views and leverage self-supervision in new
domains where augmentations are limited or unknown.

    

### [[2104.03630] A Simple Geometric Method for Cross-Lingual Linguistic Transformations with Pre-trained Autoencoders](http://arxiv.org/abs/2104.03630)


  Powerful sentence encoders trained for multiple languages are on the rise.
These systems are capable of embedding a wide range of linguistic properties
into vector representations. While explicit probing tasks can be used to verify
the presence of specific linguistic properties, it is unclear whether the
vector representations can be manipulated to indirectly steer such properties.
For efficient learning, we investigate the use of a geometric mapping in
embedding space to transform linguistic properties, without any tuning of the
pre-trained sentence encoder or decoder. We validate our approach on three
linguistic properties using a pre-trained multilingual autoencoder and analyze
the results in both monolingual and cross-lingual settings.

    

### [[2105.04580] Towards Discovery and Attribution of Open-world GAN Generated Images](http://arxiv.org/abs/2105.04580)


  With the recent progress in Generative Adversarial Networks (GANs), it is
imperative for media and visual forensics to develop detectors which can
identify and attribute images to the model generating them. Existing works have
shown to attribute images to their corresponding GAN sources with high
accuracy. However, these works are limited to a closed set scenario, failing to
generalize to GANs unseen during train time and are therefore, not scalable
with a steady influx of new GANs. We present an iterative algorithm for
discovering images generated from previously unseen GANs by exploiting the fact
that all GANs leave distinct fingerprints on their generated images. Our
algorithm consists of multiple components including network training,
out-of-distribution detection, clustering, merge and refine steps. Through
extensive experiments, we show that our algorithm discovers unseen GANs with
high accuracy and also generalizes to GANs trained on unseen real datasets. We
additionally apply our algorithm to attribution and discovery of GANs in an
online fashion as well as to the more standard task of real/fake detection. Our
experiments demonstrate the effectiveness of our approach to discover new GANs
and can be used in an open-world setup.

    

### [[2105.11844] CI-dataset and DetDSCI methodology for detecting too small and too large critical infrastructures in satellite images: Airports and electrical substations as case study](http://arxiv.org/abs/2105.11844)


  The detection of critical infrastructures in large territories represented by
aerial and satellite images is of high importance in several fields such as in
security, anomaly detection, land use planning and land use change detection.
However, the detection of such infrastructures is complex as they have highly
variable shapes and sizes, i.e., some infrastructures, such as electrical
substations, are too small while others, such as airports, are too large.
Besides, airports can have a surface area either small or too large with
completely different shapes, which makes its correct detection challenging. As
far as we know, these limitations have not been tackled yet in previous works.
This paper presents (1) a smart Critical Infrastructure dataset, named
CI-dataset, organised into two scales, small and large scales critical
infrastructures and (2) a two-level resolution-independent critical
infrastructure detection (DetDSCI) methodology that first determines the
spatial resolution of the input image using a classification model, then
analyses the image using the appropriate detector for that spatial resolution.
The present study targets two representative classes, airports and electrical
substations. Our experiments show that DetDSCI methodology achieves up to
37,53% F1 improvement with respect to Faster R-CNN, one of the most influential
detection models.

    

### [[2105.14367] Deconvolutional Density Network: Modeling Free-Form Conditional Distributions](http://arxiv.org/abs/2105.14367)


  Conditional density estimation (CDE) is the task of estimating the
probability of an event conditioned on some inputs. A neural network (NN) can
be used to compute the output distribution for continuous-domain, but it is
difficult to explicitly approximate a free-form one without knowing the
information of its general form a priori. In order to fit an arbitrary
conditional distribution, discretizing the continuous domain into bins is an
effective strategy, as long as we have sufficiently narrow bins and very large
data. However, collecting enough data is often hard to reach and falls far
short of that ideal in many circumstances, especially in multivariate CDE for
the curse of dimensionality. In this paper, we demonstrate the benefits of
modeling free-form conditional distributions using a deconvolution-based neural
net framework, coping with data deficiency problems in discretization. It has
the advantage of being flexible but also takes advantage of the hierarchical
smoothness offered by the deconvolution layers. We compare our method to a
number of other density-estimation approaches and show that our Deconvolutional
Density Network (DDN) outperforms the competing methods on many univariate and
multivariate tasks.

    

### [[2106.04452] 3KG: Contrastive Learning of 12-Lead Electrocardiograms using Physiologically-Inspired Augmentations](http://arxiv.org/abs/2106.04452)


  We propose 3KG, a physiologically-inspired contrastive learning approach that
generates views using 3D augmentations of the 12-lead electrocardiogram. We
evaluate representation quality by fine-tuning a linear layer for the
downstream task of 23-class diagnosis on the PhysioNet 2020 challenge training
data and find that 3KG achieves a $9.1\%$ increase in mean AUC over the best
self-supervised baseline when trained on $1\%$ of labeled data. Our empirical
analysis shows that combining spatial and temporal augmentations produces the
strongest representations. In addition, we investigate the effect of this
physiologically-inspired pretraining on downstream performance on different
disease subgroups and find that 3KG makes the greatest gains for conduction and
rhythm abnormalities. Our method allows for flexibility in incorporating other
self-supervised strategies and highlights the potential for similar
modality-specific augmentations for other biomedical signals.

    

### [[2106.09700] Scientific Language Models for Biomedical Knowledge Base Completion: An Empirical Study](http://arxiv.org/abs/2106.09700)


  Biomedical knowledge graphs (KGs) hold rich information on entities such as
diseases, drugs, and genes. Predicting missing links in these graphs can boost
many important applications, such as drug design and repurposing. Recent work
has shown that general-domain language models (LMs) can serve as "soft" KGs,
and that they can be fine-tuned for the task of KG completion. In this work, we
study scientific LMs for KG completion, exploring whether we can tap into their
latent knowledge to enhance biomedical link prediction. We evaluate several
domain-specific LMs, fine-tuning them on datasets centered on drugs and
diseases that we represent as KGs and enrich with textual entity descriptions.
We integrate the LM-based models with KG embedding models, using a router
method that learns to assign each input example to either type of model and
provides a substantial boost in performance. Finally, we demonstrate the
advantage of LM models in the inductive setting with novel scientific entities.
Our datasets and code are made publicly available.

    

### [[2109.09533] Modeling Annotation Uncertainty with Gaussian Heatmaps in Landmark Localization](http://arxiv.org/abs/2109.09533)


  In landmark localization, due to ambiguities in defining their exact
position, landmark annotations may suffer from large observer variabilities,
which result in uncertain annotations. To model the annotation ambiguities of
the training dataset, we propose to learn anisotropic Gaussian parameters
modeling the shape of the target heatmap during optimization. Furthermore, our
method models the prediction uncertainty of individual samples by fitting
anisotropic Gaussian functions to the predicted heatmaps during inference.
Besides state-of-the-art results, our experiments on datasets of hand
radiographs and lateral cephalograms also show that Gaussian functions are
correlated with both localization accuracy and observer variability. As a final
experiment, we show the importance of integrating the uncertainty into decision
making by measuring the influence of the predicted location uncertainty on the
classification of anatomical abnormalities in lateral cephalograms.

    

### [[2109.09607] Description of Corner Cases in Automated Driving: Goals and Challenges](http://arxiv.org/abs/2109.09607)


  Scaling the distribution of automated vehicles requires handling various
unexpected and possibly dangerous situations, termed corner cases (CC). Since
many modules of automated driving systems are based on machine learning (ML),
CC are an essential part of the data for their development. However, there is
only a limited amount of CC data in large-scale data collections, which makes
them challenging in the context of ML. With a better understanding of CC,
offline applications, e.g., dataset analysis, and online methods, e.g.,
improved performance of automated driving systems, can be improved. While there
are knowledge-based descriptions and taxonomies for CC, there is little
research on machine-interpretable descriptions. In this extended abstract, we
will give a brief overview of the challenges and goals of such a description.

    

### [[2109.09628] Advancing Self-supervised Monocular Depth Learning with Sparse LiDAR](http://arxiv.org/abs/2109.09628)


  Self-supervised monocular depth prediction provides a cost-effective solution
to obtain the 3D location of each pixel. However, the existing approaches
usually lead to unsatisfactory accuracy, which is critical for autonomous
robots. In this paper, we propose a novel two-stage network to advance the
self-supervised monocular dense depth learning by leveraging low-cost sparse
(e.g. 4-beam) LiDAR. Unlike the existing methods that use sparse LiDAR mainly
in a manner of time-consuming iterative post-processing, our model fuses
monocular image features and sparse LiDAR features to predict initial depth
maps. Then, an efficient feed-forward refine network is further designed to
correct the errors in these initial depth maps in pseudo-3D space with
real-time performance. Extensive experiments show that our proposed model
significantly outperforms all the state-of-the-art self-supervised methods, as
well as the sparse-LiDAR-based methods on both self-supervised monocular depth
prediction and completion tasks. With the accurate dense depth prediction, our
model outperforms the state-of-the-art sparse-LiDAR-based method
(Pseudo-LiDAR++) by more than 68% for the downstream task monocular 3D object
detection on the KITTI Leaderboard.

    

### [[2109.09658] FUTURE-AI: Guiding Principles and Consensus Recommendations for Trustworthy Artificial Intelligence in Future Medical Imaging](http://arxiv.org/abs/2109.09658)


  The recent advancements in artificial intelligence (AI) combined with the
extensive amount of data generated by today's clinical systems, has led to the
development of imaging AI solutions across the whole value chain of medical
imaging, including image reconstruction, medical image segmentation,
image-based diagnosis and treatment planning. Notwithstanding the successes and
future potential of AI in medical imaging, many stakeholders are concerned of
the potential risks and ethical implications of imaging AI solutions, which are
perceived as complex, opaque, and difficult to comprehend, utilise, and trust
in critical clinical applications. Despite these concerns and risks, there are
currently no concrete guidelines and best practices for guiding future AI
developments in medical imaging towards increased trust, safety and adoption.
To bridge this gap, this paper introduces a careful selection of guiding
principles drawn from the accumulated experiences, consensus, and best
practices from five large European projects on AI in Health Imaging. These
guiding principles are named FUTURE-AI and its building blocks consist of (i)
Fairness, (ii) Universality, (iii) Traceability, (iv) Usability, (v) Robustness
and (vi) Explainability. In a step-by-step approach, these guidelines are
further translated into a framework of concrete recommendations for specifying,
developing, evaluating, and deploying technically, clinically and ethically
trustworthy AI solutions into clinical practice.

    

### [[2109.09670] Reproducibility Study: Comparing Rewinding and Fine-tuning in Neural Network Pruning](http://arxiv.org/abs/2109.09670)


  Scope of reproducibility: We are reproducing Comparing Rewinding and
Fine-tuning in Neural Networks from arXiv:2003.02389. In this work the authors
compare three different approaches to retraining neural networks after pruning:
1) fine-tuning, 2) rewinding weights as in arXiv:1803.03635 and 3) a new,
original method involving learning rate rewinding, building upon Lottery Ticket
Hypothesis. We reproduce the results of all three approaches, but we focus on
verifying their approach, learning rate rewinding, since it is newly proposed
and is described as a universal alternative to other methods.
We used CIFAR10 for most reproductions along with additional experiments on
the larger CIFAR100, which extends the results originally provided by the
authors. We have also extended the list of tested network architectures to
include Wide ResNets. The new experiments led us to discover the limitations of
learning rate rewinding which can worsen pruning results on large
architectures.
Results: We were able to reproduce the exact results reported by the authors
in all originally reported scenarios. However, extended results on larger Wide
Residual Networks have demonstrated the limitations of the newly proposed
learning rate rewinding -- we observed a previously unreported accuracy
degradation for low sparsity ranges. Nevertheless, the general conclusion of
the paper still holds and was indeed reproduced.

    

### [[2109.09690] Trust Your Robots! Predictive Uncertainty Estimation of Neural Networks with Sparse Gaussian Processes](http://arxiv.org/abs/2109.09690)


  This paper presents a probabilistic framework to obtain both reliable and
fast uncertainty estimates for predictions with Deep Neural Networks (DNNs).
Our main contribution is a practical and principled combination of DNNs with
sparse Gaussian Processes (GPs). We prove theoretically that DNNs can be seen
as a special case of sparse GPs, namely mixtures of GP experts (MoE-GP), and we
devise a learning algorithm that brings the derived theory into practice. In
experiments from two different robotic tasks -- inverse dynamics of a
manipulator and object detection on a micro-aerial vehicle (MAV) -- we show the
effectiveness of our approach in terms of predictive uncertainty, improved
scalability, and run-time efficiency on a Jetson TX2. We thus argue that our
approach can pave the way towards reliable and fast robot learning systems with
uncertainty awareness.

    

### [[2109.09703] Learning to Forecast Dynamical Systems from Streaming Data](http://arxiv.org/abs/2109.09703)


  Kernel analog forecasting (KAF) is a powerful methodology for data-driven,
non-parametric forecasting of dynamically generated time series data. This
approach has a rigorous foundation in Koopman operator theory and it produces
good forecasts in practice, but it suffers from the heavy computational costs
common to kernel methods. This paper proposes a streaming algorithm for KAF
that only requires a single pass over the training data. This algorithm
dramatically reduces the costs of training and prediction without sacrificing
forecasting skill. Computational experiments demonstrate that the streaming KAF
method can successfully forecast several classes of dynamical systems
(periodic, quasi-periodic, and chaotic) in both data-scarce and data-rich
regimes. The overall methodology may have wider interest as a new template for
streaming kernel regression.

    

### [[2109.09705] Neural forecasting at scale](http://arxiv.org/abs/2109.09705)


  We study the problem of efficiently scaling ensemble-based deep neural
networks for time series (TS) forecasting on a large set of time series.
Current state-of-the-art deep ensemble models have high memory and
computational requirements, hampering their use to forecast millions of TS in
practical scenarios. We propose N-BEATS(P), a global multivariate variant of
the N-BEATS model designed to allow simultaneous training of multiple
univariate TS forecasting models. Our model addresses the practical limitations
of related models, reducing the training time by half and memory requirement by
a factor of 5, while keeping the same level of accuracy. We have performed
multiple experiments detailing the various ways to train our model and have
obtained results that demonstrate its capacity to support zero-shot TS
forecasting, i.e., to train a neural network on a source TS dataset and deploy
it on a different target TS dataset without retraining, which provides an
efficient and reliable solution to forecast at scale even in difficult
forecasting conditions.

    

### [[2007.05303] Multi-future Merchant Transaction Prediction](http://arxiv.org/abs/2007.05303)


  The multivariate time series generated from merchant transaction history can
provide critical insights for payment processing companies. The capability of
predicting merchants' future is crucial for fraud detection and recommendation
systems. Conventionally, this problem is formulated to predict one multivariate
time series under the multi-horizon setting. However, real-world applications
often require more than one future trend prediction considering the
uncertainties, where more than one multivariate time series needs to be
predicted. This problem is called multi-future prediction. In this work, we
combine the two research directions and propose to study this new problem:
multi-future, multi-horizon and multivariate time series prediction. This
problem is crucial as it has broad use cases in the financial industry to
reduce the risk while improving user experience by providing alternative
futures. This problem is also challenging as now we not only need to capture
the patterns and insights from the past but also train a model that has a
strong inference capability to project multiple possible outcomes. To solve
this problem, we propose a new model using convolutional neural networks and a
simple yet effective encoder-decoder structure to learn the time series pattern
from multiple perspectives. We use experiments on real-world merchant
transaction data to demonstrate the effectiveness of our proposed model. We
also provide extensive discussions on different model design choices in our
experimental section.

    

### [[2011.02602] Merchant Category Identification Using Credit Card Transactions](http://arxiv.org/abs/2011.02602)


  Digital payment volume has proliferated in recent years with the rapid growth
of small businesses and online shops. When processing these digital
transactions, recognizing each merchant's real identity (i.e., business type)
is vital to ensure the integrity of payment processing systems. Conventionally,
this problem is formulated as a time series classification problem solely using
the merchant transaction history. However, with the large scale of the data,
and changing behaviors of merchants and consumers over time, it is extremely
challenging to achieve satisfying performance from off-the-shelf classification
methods. In this work, we approach this problem from a multi-modal learning
perspective, where we use not only the merchant time series data but also the
information of merchant-merchant relationship (i.e., affinity) to verify the
self-reported business type (i.e., merchant category) of a given merchant.
Specifically, we design two individual encoders, where one is responsible for
encoding temporal information and the other is responsible for affinity
information, and a mechanism to fuse the outputs of the two encoders to
accomplish the identification task. Our experiments on real-world credit card
transaction data between 71,668 merchants and 433,772,755 customers have
demonstrated the effectiveness and efficiency of the proposed model.

    

### [[2109.09300] Feature Correlation Aggregation: on the Path to Better Graph Neural Networks](http://arxiv.org/abs/2109.09300)


  Prior to the introduction of Graph Neural Networks (GNNs), modeling and
analyzing irregular data, particularly graphs, was thought to be the Achilles'
heel of deep learning. The core concept of GNNs is to find a representation by
recursively aggregating the representations of a central node and those of its
neighbors. The core concept of GNNs is to find a representation by recursively
aggregating the representations of a central node and those of its neighbor,
and its success has been demonstrated by many GNNs' designs. However, most of
them only focus on using the first-order information between a node and its
neighbors. In this paper, we introduce a central node permutation variant
function through a frustratingly simple and innocent-looking modification to
the core operation of a GNN, namely the Feature cOrrelation aGgregation (FOG)
module which learns the second-order information from feature correlation
between a node and its neighbors in the pipeline. By adding FOG into existing
variants of GNNs, we empirically verify this second-order information
complements the features generated by original GNNs across a broad set of
benchmarks. A tangible boost in performance of the model is observed where the
model surpasses previous state-of-the-art results by a significant margin while
employing fewer parameters. (e.g., 33.116% improvement on a real-world
molecular dataset using graph convolutional networks).

    

### [[2109.09821] Encrypted Data Processing](http://arxiv.org/abs/2109.09821)


  In this paper, we present a comprehensive architecture for confidential
computing, which we show to be general purpose and quite efficient. It executes
the application as is, without any added burden or discipline requirements from
the application developers. Furthermore, it does not require the trust of
system software at the computing server and does not impose any added burden on
the communication subsystem. The proposed Encrypted Data Processing (EDAP)
architecture accomplishes confidentiality, authenticity, and freshness of the
key-based cryptographic data protection by adopting data encryption with a
multi-level key protection scheme. It guarantees that the user data is visible
only in non-privileged mode to a designated program trusted by the data owner
on a designated hardware, thus protecting the data from an untrusted hardware,
hypervisor, OS, or other users' applications. The cryptographic keys and
protocols used for achieving these confidential computing requirements are
described in a use case example. Encrypting and decrypting data in an
EDAP-enabled processor can lead to performance degradation as it adds cycle
time to the overall execution. However, our simulation result shows that the
slowdown is only 6% on average across a collection of commercial workloads when
the data encryption engine is placed between the L1 and L2 cache. We
demonstrate that the EDAP architecture is valuable and practicable in the
modern cloud environment for confidential computing. EDAP delivers a zero trust
model of computing where the user software does not trust system software and
vice versa.

    

### [[2104.05119] BurstLink: Techniques for Energy-Efficient Conventional and Virtual Reality Video Display](http://arxiv.org/abs/2104.05119)


  Conventional planar video streaming is the most popular application in mobile
systems and the rapid growth of 360 video content and virtual reality (VR)
devices are accelerating the adoption of VR video streaming. Unfortunately,
video streaming consumes significant system energy due to the high power
consumption of the system components (e.g., DRAM, display interfaces, and
display panel) involved in this process.
We propose BurstLink, a novel system-level technique that improves the energy
efficiency of planar and VR video streaming. BurstLink is based on two key
ideas. First, BurstLink directly transfers a decoded video frame from the host
system to the display panel, bypassing the host DRAM. To this end, we extend
the display panel with a double remote frame buffer (DRFB), instead of the
DRAM's double frame buffer, so that the system can directly update the DRFB
with a new frame while updating the panel's pixels with the current frame
stored in the DRFB. Second, BurstLink transfers a complete decoded frame to the
display panel in a single burst, using the maximum bandwidth of modern display
interfaces. Unlike conventional systems where the frame transfer rate is
limited by the pixel-update throughput of the display panel, BurstLink can
always take full advantage of the high bandwidth of modern display interfaces
by decoupling the frame transfer from the pixel update as enabled by the DRFB.
This direct and burst frame transfer of BurstLink significantly reduces energy
consumption in video display by reducing access to the host DRAM and increasing
the system's residency at idle power states.
We evaluate BurstLink using an analytical power model that we rigorously
validate on a real modern mobile system. Our evaluation shows that BurstLink
reduces system energy consumption for 4K planar and VR video streaming by 41%
and 33%, respectively.

    

### [[2104.06968] Blockchain Machine: A Network-Attached Hardware Accelerator for Hyperledger Fabric](http://arxiv.org/abs/2104.06968)


  In this paper, we demonstrate how Hyperledger Fabric, one of the most popular
permissioned blockchains, can benefit from network-attached acceleration. The
scalability and peak performance of Fabric is primarily limited by the
bottlenecks present in its block validation/commit phase. We propose Blockchain
Machine, a hardware accelerator coupled with a hardware-friendly communication
protocol, to act as the validator peer. It can be adapted to applications and
their smart contracts, and is targeted for a server with network-attached FPGA
acceleration card. The Blockchain Machine retrieves blocks and their
transactions in hardware directly from the network interface, which are then
validated through a configurable and efficient block-level and
transaction-level pipeline. The validation results are then transferred to the
host CPU where non-bottleneck operations are executed. From our implementation
integrated with Fabric v1.4 LTS, we observed up to 12x speedup in block
validation when compared to software-only validator peer, with commit
throughput of up to 68,900 tps. Our work provides an acceleration platform that
will foster further research on hardware acceleration of permissioned
blockchains.

    

### [[2109.09812] GPGPU-Parallel Re-indexing of Triangle Meshes with Duplicate-Vertex and Unused-Vertex Removal](http://arxiv.org/abs/2109.09812)


  We describe a simple yet highly parallel method for re-indexing "indexed"
data sets like triangle meshes or unstructured-mesh data sets -- which is
useful for operations such as removing duplicate or un-used vertices, merging
different meshes, etc. In particlar, our method is parallel and GPU-friendly in
the sense that it all its steps are either trivially parallel, or use
GPU-parallel primitives like sorting, prefix-sum; thus making it well suited
for highly parallel architectures like GPUs.

    

### [[2109.09966] PoRCH: A Novel Consensus Mechanism for Blockchain-Enabled Future SCADA Systems in Smart Grids and Industry 4.0](http://arxiv.org/abs/2109.09966)


  Smart Grids and Industry 4.0 (I4.0) are neither a dream nor a near-future
thing anymore, rather it is happening now. The integration of more and more
embedded systems and IoT devices is pushing smart grids and I4.0 forward at a
breakneck speed. To cope up with this, the modification of age-old SCADA
(Supervisory Control and Data Acquisition) systems in terms of
decentralization, near-real-time operation, security, and privacy is necessary.
In this context, blockchain technology has the potential of providing not only
these essential features of the data acquisition process of future SCADA
systems but also many other useful add-ons. On the other side, it is evident
that various type of security breach tends to take place more during any
economic turmoil. These can cause even more serious devastation to the global
economy and human life. Thus, it is necessary to make our industries robust,
automated, and resilient with secured and immutable data acquiring systems.
This paper deals with the implementation scopes of blockchain in the data
acquisition part of SCADA systems in the area of the smart grid and I4.0. There
are several consensus mechanisms to support blockchain integration in the field
of cryptocurrencies, vehicular networks, healthcare systems, e-commerce, etc.
But little attention has been paid to developing efficient and
easy-to-implement consensus mechanisms in the field of blockchain-enabled SCADA
systems. From this perspective, a novel consensus mechanism, which we call
PoRCH (Proof of Random Count in Hashes), with a customized mining node
selection scheme has been proposed in this paper. Also, a small-scale prototype
of a blockchain-enabled data acquisition system has been developed. The
performance evaluation of the implemented prototype shows the benefits of
blockchain technology.

    

### [[2109.10302] MITOSIS: Practically Scaling Permissioned Blockchains](http://arxiv.org/abs/2109.10302)


  Scalability remains one of the biggest challenges to the adoption of
permissioned blockchain technologies for large-scale deployments. Permissioned
blockchains typically exhibit low latencies, compared to permissionless
deployments -- however at the cost of poor scalability. Various solutions were
proposed to capture "the best of both worlds", targeting low latency and high
scalability simultaneously, the most prominent technique being blockchain
sharding. However, most existing sharding proposals exploit features of the
permissionless model and are therefore restricted to cryptocurrency
applications.
We present MITOSIS, a novel approach to practically improve scalability of
permissioned blockchains. Our system allows the dynamic creation of
blockchains, as more participants join the system, to meet practical
scalability requirements. Crucially, it enables the division of an existing
blockchain (and its participants) into two -- reminiscent of mitosis, the
biological process of cell division. MITOSIS inherits the low latency of
permissioned blockchains while preserving high throughput via parallel
processing. Newly created chains in our system are fully autonomous, can choose
their own consensus protocol, and yet they can interact with each other to
share information and assets -- meeting high levels of interoperability. We
analyse the security of MITOSIS and evaluate experimentally the performance of
our solution when instantiated over Hyperledger Fabric. Our results show that
MITOSIS can be ported with little modifications and manageable overhead to
existing permissioned blockchains, such as Hyperledger Fabric.

    

### [[1909.09771] Multithreaded Filtering Preconditioner for Diffusion Equation on Structured Grid](http://arxiv.org/abs/1909.09771)


  A parallel and nested version of a frequency filtering preconditioner is
proposed for linear systems corresponding to diffusion equation on a structured
grid. The proposed preconditioner is found to be robust with respect to jumps
in the diffusion coefficients. The storage requirement for the preconditioner
is O(N),where N is number of rows of matrix, hence, a fairly large problem of
size more than 42 million unknowns has been solved on a quad core machine with
64GB RAM. The parallelism is achieved using twisted factorization and SIMD
operations. The preconditioner achieves a speedup of 3.3 times on a quad core
processor clocked at 4.2 GHz, and compared to a well known algebraic multigrid
method, it is significantly faster in both setup and solve times for diffusion
equations with jumps.

    

### [[2008.02710] Red Light Green Light Method for Solving Large Markov Chains](http://arxiv.org/abs/2008.02710)


  Discrete-time discrete-state finite Markov chains are versatile mathematical
models for a wide range of real-life stochastic processes. One of most common
tasks in studies of Markov chains is computation of the stationary
distribution. Without loss of generality, and drawing our motivation from
applications to large networks, we interpret this problem as one of computing
the stationary distribution of a random walk on a graph. We propose a new
controlled, easily distributed algorithm for this task, briefly summarized as
follows: at the beginning, each node receives a fixed amount of cash (positive
or negative), and at each iteration, some nodes receive `green light' to
distribute their wealth or debt proportionally to the transition probabilities
of the Markov chain; the stationary probability of a node is computed as a
ratio of the cash distributed by this node to the total cash distributed by all
nodes together. Our method includes as special cases a wide range of known,
very different, and previously disconnected methods including power iterations,
Gauss-Southwell, and online distributed algorithms. We prove exponential
convergence of our method, demonstrate its high efficiency, and derive
scheduling strategies for the green-light, that achieve convergence rate faster
than state-of-the-art algorithms.

    

### [[2109.09807] I Know You Can't See Me: Dynamic Occlusion-Aware Safety Validation of Strategic Planners for Autonomous Vehicles Using Hypergames](http://arxiv.org/abs/2109.09807)


  A particular challenge for both autonomous and human driving is dealing with
risk associated with dynamic occlusion, i.e., occlusion caused by other
vehicles in traffic. Based on the theory of hypergames, we develop a novel
multi-agent dynamic occlusion risk (DOR) measure for assessing situational risk
in dynamic occlusion scenarios. Furthermore, we present a white-box,
scenario-based, accelerated safety validation framework for assessing safety of
strategic planners in AV. Based on evaluation over a large naturalistic
database, our proposed validation method achieves a 4000% speedup compared to
direct validation on naturalistic data, a more diverse coverage, and ability to
generalize beyond the dataset and generate commonly observed dynamic occlusion
crashes in traffic in an automated manner.

    

### [[2109.09809] Counterfactual Instances Explain Little](http://arxiv.org/abs/2109.09809)


  In many applications, it is important to be able to explain the decisions of
machine learning systems. An increasingly popular approach has been to seek to
provide \emph{counterfactual instance explanations}. These specify close
possible worlds in which, contrary to the facts, a person receives their
desired decision from the machine learning system. This paper will draw on
literature from the philosophy of science to argue that a satisfactory
explanation must consist of both counterfactual instances and a causal equation
(or system of equations) that support the counterfactual instances. We will
show that counterfactual instances by themselves explain little. We will
further illustrate how explainable AI methods that provide both causal
equations and counterfactual instances can successfully explain machine
learning predictions.

    

### [[2109.09844] Assessing clinical utility of Machine Learning and Artificial Intelligence approaches to analyze speech recordings in Multiple Sclerosis: A Pilot Study](http://arxiv.org/abs/2109.09844)


  Background: An early diagnosis together with an accurate disease progression
monitoring of multiple sclerosis is an important component of successful
disease management. Prior studies have established that multiple sclerosis is
correlated with speech discrepancies. Early research using objective acoustic
measurements has discovered measurable dysarthria.
Objective: To determine the potential clinical utility of machine learning
and deep learning/AI approaches for the aiding of diagnosis, biomarker
extraction and progression monitoring of multiple sclerosis using speech
recordings.
Methods: A corpus of 65 MS-positive and 66 healthy individuals reading the
same text aloud was used for targeted acoustic feature extraction utilizing
automatic phoneme segmentation. A series of binary classification models was
trained, tuned, and evaluated regarding their Accuracy and area-under-curve.
Results: The Random Forest model performed best, achieving an Accuracy of
0.82 on the validation dataset and an area-under-curve of 0.76 across 5 k-fold
cycles on the training dataset. 5 out of 7 acoustic features were statistically
significant.
Conclusion: Machine learning and artificial intelligence in automatic
analyses of voice recordings for aiding MS diagnosis and progression tracking
seems promising. Further clinical validation of these methods and their mapping
onto multiple sclerosis progression is needed, as well as a validating utility
for English-speaking populations.

    

### [[2109.09861] Generalized dynamic cognitive hierarchy models for strategic driving behavior](http://arxiv.org/abs/2109.09861)


  While there has been an increasing focus on the use of game theoretic models
for autonomous driving, empirical evidence shows that there are still open
questions around dealing with the challenges of common knowledge assumptions as
well as modeling bounded rationality. To address some of these practical
challenges, we develop a framework of generalized dynamic cognitive hierarchy
for both modelling naturalistic human driving behavior as well as behavior
planning for autonomous vehicles (AV). This framework is built upon a rich
model of level-0 behavior through the use of automata strategies, an
interpretable notion of bounded rationality through safety and maneuver
satisficing, and a robust response for planning. Based on evaluation on two
large naturalistic datasets as well as simulation of critical traffic
scenarios, we show that i) automata strategies are well suited for level-0
behavior in a dynamic level-k framework, and ii) the proposed robust response
to a heterogeneous population of strategic and non-strategic reasoners can be
an effective approach for game theoretic planning in AV.

    

### [[2109.09862] Language Identification with a Reciprocal Rank Classifier](http://arxiv.org/abs/2109.09862)


  Language identification is a critical component of language processing
pipelines (Jauhiainen et al.,2019) and is not a solved problem in real-world
settings. We present a lightweight and effective language identifier that is
robust to changes of domain and to the absence of copious training data.
The key idea for classification is that the reciprocal of the rank in a
frequency table makes an effective additive feature score, hence the term
Reciprocal Rank Classifier (RRC). The key finding for language classification
is that ranked lists of words and frequencies of characters form a sufficient
and robust representation of the regularities of key languages and their
orthographies.
We test this on two 22-language data sets and demonstrate zero-effort domain
adaptation from a Wikipedia training set to a Twitter test set. When trained on
Wikipedia but applied to Twitter the macro-averaged F1-score of a
conventionally trained SVM classifier drops from 90.9% to 77.7%. By contrast,
the macro F1-score of RRC drops only from 93.1% to 90.6%. These classifiers are
compared with those from fastText and langid. The RRC performs better than
these established systems in most experiments, especially on short Wikipedia
texts and Twitter.
The RRC classifier can be improved for particular domains and conversational
situations by adding words to the ranked lists. Using new terms learned from
such conversations, we demonstrate a further 7.9% increase in accuracy of
sample message classification, and 1.7% increase for conversation
classification. Surprisingly, this made results on Twitter data slightly worse.
The RRC classifier is available as an open source Python package
(this https URL).

    

### [[2109.09904] Symbols as a Lingua Franca for Bridging Human-AI Chasm for Explainable and Advisable AI Systems](http://arxiv.org/abs/2109.09904)


  Despite the surprising power of many modern AI systems that often learn their
own representations, there is significant discontent about their inscrutability
and the attendant problems in their ability to interact with humans. While
alternatives such as neuro-symbolic approaches have been proposed, there is a
lack of consensus on what they are about. There are often two independent
motivations (i) symbols as a lingua franca for human-AI interaction and (ii)
symbols as (system-produced) abstractions use in its internal reasoning. The
jury is still out on whether AI systems will need to use symbols in their
internal reasoning to achieve general intelligence capabilities. Whatever the
answer there is, the need for (human-understandable) symbols in human-AI
interaction seems quite compelling. Symbols, like emotions, may well not be
sine qua non for intelligence per se, but they will be crucial for AI systems
to interact with us humans--as we can neither turn off our emotions nor get by
without our symbols. In particular, in many human-designed domains, humans
would be interested in providing explicit (symbolic) knowledge and advice--and
expect machine explanations in kind. This alone requires AI systems to at least
do their I/O in symbolic terms. In this blue sky paper, we argue this point of
view, and discuss research directions that need to be pursued to allow for this
type of human-AI interaction.

    

### [[2109.09906] Audio Interval Retrieval using Convolutional Neural Networks](http://arxiv.org/abs/2109.09906)


  Modern streaming services are increasingly labeling videos based on their
visual or audio content. This typically augments the use of technologies such
as AI and ML by allowing to use natural speech for searching by keywords and
video descriptions. Prior research has successfully provided a number of
solutions for speech to text, in the case of a human speech, but this article
aims to investigate possible solutions to retrieve sound events based on a
natural language query, and estimate how effective and accurate they are. In
this study, we specifically focus on the YamNet, AlexNet, and ResNet-50
pre-trained models to automatically classify audio samples using their
respective melspectrograms into a number of predefined classes. The predefined
classes can represent sounds associated with actions within a video fragment.
Two tests are conducted to evaluate the performance of the models on two
separate problems: audio classification and intervals retrieval based on a
natural language query. Results show that the benchmarked models are comparable
in terms of performance, with YamNet slightly outperforming the other two
models. YamNet was able to classify single fixed-size audio samples with 92.7%
accuracy and 68.75% precision while its average accuracy on intervals retrieval
was 71.62% and precision was 41.95%. The investigated method may be embedded
into an automated event marking architecture for streaming services.

    

### [[2109.09960] Enforcing Mutual Consistency of Hard Regions for Semi-supervised Medical Image Segmentation](http://arxiv.org/abs/2109.09960)


  In this paper, we proposed a novel mutual consistency network (MC-Net+) to
effectively exploit the unlabeled hard regions for semi-supervised medical
image segmentation. The MC-Net+ model is motivated by the observation that deep
models trained with limited annotations are prone to output highly uncertain
and easily mis-classified predictions in the ambiguous regions (e.g. adhesive
edges or thin branches) for the image segmentation task. Leveraging these
region-level challenging samples can make the semi-supervised segmentation
model training more effective. Therefore, our proposed MC-Net+ model consists
of two new designs. First, the model contains one shared encoder and multiple
sightly different decoders (i.e. using different up-sampling strategies). The
statistical discrepancy of multiple decoders' outputs is computed to denote the
model's uncertainty, which indicates the unlabeled hard regions. Second, a new
mutual consistency constraint is enforced between one decoder's probability
output and other decoders' soft pseudo labels. In this way, we minimize the
model's uncertainty during training and force the model to generate invariant
and low-entropy results in such challenging areas of unlabeled data, in order
to learn a generalized feature representation. We compared the segmentation
results of the MC-Net+ with five state-of-the-art semi-supervised approaches on
three public medical datasets. Extension experiments with two common
semi-supervised settings demonstrate the superior performance of our model over
other existing methods, which sets a new state of the art for semi-supervised
medical image segmentation.

    

### [[2109.09968] Generalization in Text-based Games via Hierarchical Reinforcement Learning](http://arxiv.org/abs/2109.09968)


  Deep reinforcement learning provides a promising approach for text-based
games in studying natural language communication between humans and artificial
agents. However, the generalization still remains a big challenge as the agents
depend critically on the complexity and variety of training tasks. In this
paper, we address this problem by introducing a hierarchical framework built
upon the knowledge graph-based RL agent. In the high level, a meta-policy is
executed to decompose the whole game into a set of subtasks specified by
textual goals, and select one of them based on the KG. Then a sub-policy in the
low level is executed to conduct goal-conditioned reinforcement learning. We
carry out experiments on games with various difficulty levels and show that the
proposed method enjoys favorable generalizability.

    

### [[2109.10007] Generating Local Maps of Science using Deep Bibliographic Coupling](http://arxiv.org/abs/2109.10007)


  Bibliographic and co-citation coupling are two analytical methods widely used
to measure the degree of similarity between scientific papers. These approaches
are intuitive, easy to put into practice, and computationally cheap. Moreover,
they have been used to generate a map of science, allowing visualizing research
field interactions. Nonetheless, these methods do not work unless two papers
share a standard reference, limiting the two papers usability with no direct
connection. In this work, we propose to extend bibliographic coupling to the
deep neighborhood, by using graph diffusion methods. This method allows
defining similarity between any two papers, making it possible to generate a
local map of science, highlighting field organization.

    

### [[2109.10016] CONQUER: Contextual Query-aware Ranking for Video Corpus Moment Retrieval](http://arxiv.org/abs/2109.10016)


  This paper tackles a recently proposed Video Corpus Moment Retrieval task.
This task is essential because advanced video retrieval applications should
enable users to retrieve a precise moment from a large video corpus. We propose
a novel CONtextual QUery-awarE Ranking~(CONQUER) model for effective moment
localization and ranking. CONQUER explores query context for multi-modal fusion
and representation learning in two different steps. The first step derives
fusion weights for the adaptive combination of multi-modal video content. The
second step performs bi-directional attention to tightly couple video and query
as a single joint representation for moment localization. As query context is
fully engaged in video representation learning, from feature fusion to
transformation, the resulting feature is user-centered and has a larger
capacity in capturing multi-modal signals specific to query. We conduct studies
on two datasets, TVR for closed-world TV episodes and DiDeMo for open-world
user-generated videos, to investigate the potential advantages of fusing video
and query online as a joint representation for moment retrieval.

    

### [[2109.10065] Comparison of Neural Network based Soft Computing Techniques for Electromagnetic Modeling of a Microstrip Patch Antenna](http://arxiv.org/abs/2109.10065)


  This paper presents the comparison of various neural networks and algorithms
based on accuracy, quickness, and consistency for antenna modelling. Using
Nntool by MATLAB, 22 different combinations of networks and training algorithms
are used to predict the dimensions of a rectangular microstrip antenna using
dielectric constant, height of substrate, and frequency of operation as input.
Comparison and characterization of networks is done based on accuracy, mean
square error, and training time. Algorithms, on the other hand, are analyzed by
their accuracy, speed, reliability, and smoothness in the training process.
Finally, these results are analyzed, and recommendations are made for each
neural network and algorithm based on uses, advantages, and disadvantages. For
example, it is observed that Reduced Radial Bias network is the most accurate
network and Scaled Conjugate Gradient is the most reliable algorithm for
electromagnetic modelling. This paper will help a researcher find the optimum
network and algorithm directly without doing time-taking experimentation.

    

### [[2109.10085] Heterogeneous Ensemble for ESG Ratings Prediction](http://arxiv.org/abs/2109.10085)


  Over the past years, topics ranging from climate change to human rights have
seen increasing importance for investment decisions. Hence, investors (asset
managers and asset owners) who wanted to incorporate these issues started to
assess companies based on how they handle such topics. For this assessment,
investors rely on specialized rating agencies that issue ratings along the
environmental, social and governance (ESG) dimensions. Such ratings allow them
to make investment decisions in favor of sustainability. However, rating
agencies base their analysis on subjective assessment of sustainability
reports, not provided by every company. Furthermore, due to human labor
involved, rating agencies are currently facing the challenge to scale up the
coverage in a timely manner.
In order to alleviate these challenges and contribute to the overall goal of
supporting sustainability, we propose a heterogeneous ensemble model to predict
ESG ratings using fundamental data. This model is based on feedforward neural
network, CatBoost and XGBoost ensemble members. Given the public availability
of fundamental data, the proposed method would allow cost-efficient and
scalable creation of initial ESG ratings (also for companies without
sustainability reporting). Using our approach we are able to explain 54% of the
variation in ratings R2 using fundamental data and outperform prior work in
this area.

    

### [[2109.10086] SPLADE v2: Sparse Lexical and Expansion Model for Information Retrieval](http://arxiv.org/abs/2109.10086)


  In neural Information Retrieval (IR), ongoing research is directed towards
improving the first retriever in ranking pipelines. Learning dense embeddings
to conduct retrieval using efficient approximate nearest neighbors methods has
proven to work well. Meanwhile, there has been a growing interest in learning
\emph{sparse} representations for documents and queries, that could inherit
from the desirable properties of bag-of-words models such as the exact matching
of terms and the efficiency of inverted indexes. Introduced recently, the
SPLADE model provides highly sparse representations and competitive results
with respect to state-of-the-art dense and sparse approaches. In this paper, we
build on SPLADE and propose several significant improvements in terms of
effectiveness and/or efficiency. More specifically, we modify the pooling
mechanism, benchmark a model solely based on document expansion, and introduce
models trained with distillation. We also report results on the BEIR benchmark.
Overall, SPLADE is considerably improved with more than $9$\% gains on NDCG@10
on TREC DL 2019, leading to state-of-the-art results on the BEIR benchmark.

    

### [[2109.10106] Distributed Mission Planning of Complex Tasks for Heterogeneous Multi-Robot Teams](http://arxiv.org/abs/2109.10106)


  In this paper, we propose a distributed multi-stage optimization method for
planning complex missions for heterogeneous multi-robot teams. This class of
problems involves tasks that can be executed in different ways and are
associated with cross-schedule dependencies that constrain the schedules of the
different robots in the system. The proposed approach involves a
multi-objective heuristic search of the mission, represented as a hierarchical
tree that defines the mission goal. This procedure outputs several favorable
ways to fulfill the mission, which directly feed into the next stage of the
method. We propose a distributed metaheuristic based on evolutionary
computation to allocate tasks and generate schedules for the set of chosen
decompositions. The method is evaluated in a simulation setup of an automated
greenhouse use case, where we demonstrate the method's ability to adapt the
planning strategy depending on the available robots and the given optimization
criteria.

    

### [[2109.10129] Learning General Optimal Policies with Graph Neural Networks: Expressive Power, Transparency, and Limits](http://arxiv.org/abs/2109.10129)


  It has been recently shown that general policies for many classical planning
domains can be expressed and learned in terms of a pool of features defined
from the domain predicates using a description logic grammar. At the same time,
most description logics correspond to a fragment of $k$-variable counting logic
($C_k$) for $k=2$, that has been shown to provide a tight characterization of
the expressive power of graph neural networks. In this work, we make use of
these results to understand the power and limits of using graph neural networks
(GNNs) for learning optimal general policies over a number of tractable
planning domains where such policies are known to exist. For this, we train a
simple GNN in a supervised manner to approximate the optimal value function
$V^{*}(s)$ of a number of sample states $s$. As predicted by the theory, it is
observed that general optimal policies are obtained in domains where general
optimal value functions can be defined with $C_2$ features but not in those
requiring more expressive $C_3$ features. In addition, it is observed that the
features learned are in close correspondence with the features needed to
express $V^{*}$ in closed form. The theory and the analysis of the domains let
us understand the features that are actually learned as well as those that
cannot be learned in this way, and let us move in a principled manner from a
combinatorial optimization approach to learning general policies to a
potentially, more robust and scalable approach based on deep learning.

    

### [[2109.10149] Interpretable Directed Diversity: Leveraging Model Explanations for Iterative Crowd Ideation](http://arxiv.org/abs/2109.10149)


  Feedback can help crowdworkers to improve their ideations. However, current
feedback methods require human assessment from facilitators or peers. This is
not scalable to large crowds. We propose Interpretable Directed Diversity to
automatically predict ideation quality and diversity scores, and provide AI
explanations - Attribution, Contrastive Attribution, and Counterfactual
Suggestions - for deeper feedback on why ideations were scored (low), and how
to get higher scores. These explanations provide multi-faceted feedback as
users iteratively improve their ideation. We conducted think aloud and
controlled user studies to understand how various explanations are used, and
evaluated whether explanations improve ideation diversity and quality. Users
appreciated that explanation feedback helped focus their efforts and provided
directions for improvement. This resulted in explanations improving diversity
compared to no feedback or feedback with predictions only. Hence, our approach
opens opportunities for explainable AI towards scalable and rich feedback for
iterative crowd ideation.

    

### [[2109.10187] Oriented Object Detection in Aerial Images Based on Area Ratio of Parallelogram](http://arxiv.org/abs/2109.10187)


  Rotated object detection is a challenging task in aerial images as the object
in aerial images are displayed in arbitrary directions and usually densely
packed. Although considerable progress has been made, there are still
challenges that existing regression-based rotation detectors suffer the problem
of discontinuous boundaries, which is directly caused by angular periodicity or
corner ordering. In this paper, we propose a simple effective framework to
address the above challenges. Instead of directly regressing the five
parameters (coordinates of the central point, width, height, and rotation
angle) or the four vertices, we use the area ratio of parallelogram (ARP) to
accurately describe a multi-oriented object. Specifically, we regress
coordinates of center point, height and width of minimum circumscribed
rectangle of oriented object and three area ratios {\lambda}_1, {\lambda}_2 and
{\lambda}_3. This may facilitate the offset learning and avoid the issue of
angular periodicity or label points sequence for oriented objects. To further
remedy the confusion issue nearly horizontal objects, we employ the area ratio
between the object and its horizontal bounding box (minimum circumscribed
rectangle) to guide the selection of horizontal or oriented detection for each
object. We also propose a rotation efficient IoU loss (R-EIoU) to connect the
horizontal bounding box with the three area ratios and improve the accurate for
the rotating bounding box. Experimental results on three remote sensing
datasets including HRSC2016, DOTA and UCAS-AOD and scene text including
ICDAR2015 show that our method achieves superior detection performance compared
with many state-of-the-art approaches. The code and model will be coming with
paper published.

    

### [[2109.10199] Design and implementation of a parsimonious neuromorphic PID for onboard altitude control for MAVs using neuromorphic processors](http://arxiv.org/abs/2109.10199)


  The great promises of neuromorphic sensing and processing for robotics have
led researchers and engineers to investigate novel models for robust and
reliable control of autonomous robots (navigation, obstacle detection and
avoidance, etc.), especially for quadrotors in challenging contexts such as
drone racing and aggressive maneuvers. Using spiking neural networks, these
models can be run on neuromorphic hardware to benefit from outstanding update
rates and high energy efficiency. Yet, low-level controllers are often
neglected and remain outside of the neuromorphic loop. Designing low-level
neuromorphic controllers is crucial to remove the standard PID, and therefore
benefit from all the advantages of closing the neuromorphic loop. In this
paper, we propose a parsimonious and adjustable neuromorphic PID controller,
endowed with a minimal number of 93 neurons sparsely connected to achieve
autonomous, onboard altitude control of a quadrotor equipped with Intel's Loihi
neuromorphic chip. We successfully demonstrate the robustness of our proposed
network in a set of experiments where the quadrotor is requested to reach a
target altitude from take-off. Our results confirm the suitability of such
low-level neuromorphic controllers, ultimately with a very high update
frequency.

    

### [[2109.10200] Off-line approximate dynamic programming for the vehicle routing problem with stochastic customers and demands via decentralized decision-making](http://arxiv.org/abs/2109.10200)


  This paper studies a stochastic variant of the vehicle routing problem (VRP)
where both customer locations and demands are uncertain. In particular,
potential customers are not restricted to a predefined customer set but are
continuously spatially distributed in a given service area. The objective is to
maximize the served demands while fulfilling vehicle capacities and time
restrictions. We call this problem the VRP with stochastic customers and
demands (VRPSCD). For this problem, we first propose a Markov Decision Process
(MDP) formulation representing the classical centralized decision-making
perspective where one decision-maker establishes the routes of all vehicles.
While the resulting formulation turns out to be intractable, it provides us
with the ground to develop a new MDP formulation of the VRPSCD representing a
decentralized decision-making framework, where vehicles autonomously establish
their own routes. This new formulation allows us to develop several strategies
to reduce the dimension of the state and action spaces, resulting in a
considerably more tractable problem. We solve the decentralized problem via
Reinforcement Learning, and in particular, we develop a Q-learning algorithm
featuring state-of-the-art acceleration techniques such as Replay Memory and
Double Q Network. Computational results show that our method considerably
outperforms two commonly adopted benchmark policies (random and heuristic).
Moreover, when comparing with existing literature, we show that our approach
can compete with specialized methods developed for the particular case of the
VRPSCD where customer locations and expected demands are known in advance.
Finally, we show that the value functions and policies obtained by our
algorithm can be easily embedded in Rollout algorithms, thus further improving
their performances.

    

### [[2109.10231] SalienTrack: providing salient information for semi-automated self-tracking feedback with model explanations](http://arxiv.org/abs/2109.10231)


  Self-tracking can improve people's awareness of their unhealthy behaviors to
provide insights towards behavior change. Prior work has explored how
self-trackers reflect on their logged data, but it remains unclear how much
they learn from the tracking feedback, and which information is more useful.
Indeed, the feedback can still be overwhelming, and making it concise can
improve learning by increasing focus and reducing interpretation burden. We
conducted a field study of mobile food logging with two feedback modes (manual
journaling and automatic annotation of food images) and identified learning
differences regarding nutrition, assessment, behavioral, and contextual
information. We propose a Self-Tracking Feedback Saliency Framework to define
when to provide feedback, on which specific information, why those details, and
how to present them (as manual inquiry or automatic feedback). We propose
SalienTrack to implement these requirements. Using the data collected from the
user study, we trained a machine learning model to predict whether a user would
learn from each tracked event. Using explainable AI (XAI) techniques, we
identified the most salient features per instance and why they lead to positive
learning outcomes. We discuss implications for learnability in self-tracking,
and how adding model explainability expands opportunities for improving
feedback experience.

    

### [[2109.10246] Does Vision-and-Language Pretraining Improve Lexical Grounding?](http://arxiv.org/abs/2109.10246)


  Linguistic representations derived from text alone have been criticized for
their lack of grounding, i.e., connecting words to their meanings in the
physical world. Vision-and-Language (VL) models, trained jointly on text and
image or video data, have been offered as a response to such criticisms.
However, while VL pretraining has shown success on multimodal tasks such as
visual question answering, it is not yet known how the internal linguistic
representations themselves compare to their text-only counterparts. This paper
compares the semantic representations learned via VL vs. text-only pretraining
for two recent VL models using a suite of analyses (clustering, probing, and
performance on a commonsense question answering task) in a language-only
setting. We find that the multimodal models fail to significantly outperform
the text-only variants, suggesting that future work is required if multimodal
pretraining is to be pursued as a means of improving NLP in general.

    

### [[2109.10285] Early and Revocable Time Series Classification](http://arxiv.org/abs/2109.10285)


  Many approaches have been proposed for early classification of time series in
light of itssignificance in a wide range of applications including healthcare,
transportation and fi-nance. Until now, the early classification problem has
been dealt with by considering onlyirrevocable decisions. This paper introduces
a new problem calledearly and revocabletimeseries classification, where the
decision maker can revoke its earlier decisions based on thenew available
measurements. In order to formalize and tackle this problem, we propose anew
cost-based framework and derive two new approaches from it. The first approach
doesnot consider explicitly the cost of changing decision, while the second one
does. Exten-sive experiments are conducted to evaluate these approaches on a
large benchmark of realdatasets. The empirical results obtained convincingly
show (i) that the ability of revok-ing decisions significantly improves
performance over the irrevocable regime, and (ii) thattaking into account the
cost of changing decision brings even better results in
general.Keywords:revocable decisions, cost estimation, online decision making

    

### [[2109.10303] Computing Complexity-aware Plans Using Kolmogorov Complexity](http://arxiv.org/abs/2109.10303)


  In this paper, we introduce complexity-aware planning for finite-horizon
deterministic finite automata with rewards as outputs, based on Kolmogorov
complexity. Kolmogorov complexity is considered since it can detect
computational regularities of deterministic optimal policies. We present a
planning objective yielding an explicit trade-off between a policy's
performance and complexity. It is proven that maximising this objective is
non-trivial in the sense that dynamic programming is infeasible. We present two
algorithms obtaining low-complexity policies, where the first algorithm obtains
a low-complexity optimal policy, and the second algorithm finds a policy
maximising performance while maintaining local (stage-wise) complexity
constraints. We evaluate the algorithms on a simple navigation task for a
mobile robot, where our algorithms yield low-complexity policies that concur
with intuition.

    

### [[2105.15033] DiaKG: an Annotated Diabetes Dataset for Medical Knowledge Graph Construction](http://arxiv.org/abs/2105.15033)


  Knowledge Graph has been proven effective in modeling structured information
and conceptual knowledge, especially in the medical domain. However, the lack
of high-quality annotated corpora remains a crucial problem for advancing the
research and applications on this task. In order to accelerate the research for
domain-specific knowledge graphs in the medical domain, we introduce DiaKG, a
high-quality Chinese dataset for Diabetes knowledge graph, which contains
22,050 entities and 6,890 relations in total. We implement recent typical
methods for Named Entity Recognition and Relation Extraction as a benchmark to
evaluate the proposed dataset thoroughly. Empirical results show that the DiaKG
is challenging for most existing methods and further analysis is conducted to
discuss future research direction for improvements. We hope the release of this
dataset can assist the construction of diabetes knowledge graphs and facilitate
AI-based applications.

    

### [[2109.09941] The Theoretical Limit of Radar Target Detection](http://arxiv.org/abs/2109.09941)


  In the field of radar target detection, the false alarm and detection
probabilities are used as the universal indicator for detection performance
evaluation so far, such as Neyman Person detector. In this paper, inspired by
the thoughts of Shannon's information theory, the new system model introducing
the target existent state variable v into a general radar system model is
established for target detection in the presence of complex white Gaussian
noise. The equivalent detection channel and the posterior probability
distribution are derived based on the priori statistical characteristic of the
noise, target scattering and existent state. The detection performance is
measured by the false alarm and detection probabilities and the detection
information that is defined as the mutual information between received signal
and existent state. The false alarm theorem is proved that false alarm
probability is equal to the prior probability of the target existence if the
observation interval is large enough and the theorem is the basis for the
performance comparison proposed detector with Neyman-Person detector. The
sampling a posterior probability detector is proposed, and its performance is
measured by the empirical detection information. The target detection theorem
is proved that the detection information is the limit of the detection
performance, that is, the detection information is achievable and the empirical
detection information of any detector is no greater than the detection
information. Simulation results verify the correctness of the false alarm and
the target detection theorems, and show that the performance of the sampling a
posterior probability detector is asymptotically optimal and outperforms other
detectors. In addition, the detector is more favorable to detect the dim
targets under the detection information than other detectors.

    

### [[2007.09946] Program algebra for random access machine programs](http://arxiv.org/abs/2007.09946)


  This paper presents an algebraic theory of instruction sequences with
instructions for a random access machine (RAM) as basic instructions, the
behaviours produced by the instruction sequences concerned under execution, and
the interaction between such behaviours and RAM memories. This theory provides
a setting for the development of theory in areas such as computational
complexity and analysis of algorithms that distinguishes itself by offering the
possibility of equational reasoning to establish whether an instruction
sequence computes a given function and being more general than the setting
provided by any known version of the RAM model of computation. In this setting,
a semi-realistic version of the RAM model of computation and a bit-oriented
time complexity measure for this version are introduced. Under the time measure
concerned, semi-realistic RAMs can be simulated by multi-tape Turing machines
with quadratic time overhead.

    