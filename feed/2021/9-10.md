
## 2021-9-10

### [<title>专注于武汉开餐饮发票-武汉本地宝 - DockOne.io</title>](http://dockone.io/question/1224210)

### [<title>专注于北京开酒店住宿增值税发票-开票服务大厅-北京本地宝 - DockOne.io</title>](http://dockone.io/question/1224209)

### [<title>清远开医院诊断证明(代开医院康复证明 - DockOne.io</title>](http://dockone.io/question/1224208)

### [<title>专注于北京开酒店住宿抵扣发票-开票服务大厅-北京本地宝 - DockOne.io</title>](http://dockone.io/question/1224207)

### [<title>专注于南京开餐饮发票-南京本地宝 - DockOne.io</title>](http://dockone.io/question/1224206)

### [<title>江门代开医院免军训证明【1.55电-81.22-薇8381】屡 - DockOne.io</title>](http://dockone.io/question/1224205)

### [<title>肇庆代开医院免军训证明【1.55电-81.22-薇8381】参 - DockOne.io</title>](http://dockone.io/question/1224204)

### [<title>专注于苏州开餐饮发票-苏州本地宝 - DockOne.io</title>](http://dockone.io/question/1224203)

### [<title>专注于北京开酒店住宿专用发票-开票服务大厅-北京本地宝 - DockOne.io</title>](http://dockone.io/question/1224202)

### [<title>宣威开医院诊断证明(代开检查报告单 - DockOne.io</title>](http://dockone.io/question/1224201)

### [<title>郑州开医院诊断证明(代开医院病例 - DockOne.io</title>](http://dockone.io/question/1224199)

### [<title>专注于宁波开餐饮发票-宁波本地宝 - DockOne.io</title>](http://dockone.io/question/1224200)

### [<title>专注于北京开住宿费增值税发票-开票服务大厅-北京本地宝 - DockOne.io</title>](http://dockone.io/question/1224198)

### [<title>湛江代开医院免军训证明【1.55电-81.22-薇8381】识 - DockOne.io</title>](http://dockone.io/question/1224197)

### [<title>韶关代开医院免军训证明【1.55电-81.22-薇8381】于 - DockOne.io</title>](http://dockone.io/question/1224196)

### [<title>专注于郑州开餐饮发票-郑州本地宝 - DockOne.io</title>](http://dockone.io/question/1224195)

### [<title>专注于北京开住宿费抵扣发票-开票服务大厅-北京本地宝 - DockOne.io</title>](http://dockone.io/question/1224194)

### [<title>专注于北京开住宿费专用发票-开票服务大厅-北京本地宝 - DockOne.io</title>](http://dockone.io/question/1224193)

### [<title>益阳开医院诊断证明(代开医院康复证明 - DockOne.io</title>](http://dockone.io/question/1224192)

### [<title>专注于重庆开餐饮发票-重庆本地宝 - DockOne.io</title>](http://dockone.io/question/1224191)

### [[2109.03999] System Optimization in Synchronous Federated Training: A Survey](http://arxiv.org/abs/2109.03999)


  The unprecedented demand for collaborative machine learning in a
privacy-preserving manner gives rise to a novel machine learning paradigm
called federated learning (FL). Given a sufficient level of privacy guarantees,
the practicality of an FL system mainly depends on its time-to-accuracy
performance during the training process. Despite bearing some resemblance with
traditional distributed training, FL has four distinct challenges that
complicate the optimization towards shorter time-to-accuracy: information
deficiency, coupling for contrasting factors, client heterogeneity, and huge
configuration space. Motivated by the need for inspiring related research, in
this paper we survey highly relevant attempts in the FL literature and organize
them by the related training phases in the standard workflow: selection,
configuration, and reporting. We also review exploratory work including
measurement studies and benchmarking tools to friendly support FL developers.
Although a few survey articles on FL already exist, our work differs from them
in terms of the focus, classification, and implications.

    

### [[2109.04117] Machine Learning-Enabled Data Rate Prediction for 5G NSA Vehicle-to-Cloud Communications](http://arxiv.org/abs/2109.04117)


  In order to satisfy the ever-growing Quality of Service (QoS) requirements of
innovative services, cellular communication networks are constantly evolving.
Recently, the 5G NonStandalone (NSA) mode has been deployed as an intermediate
strategy to deliver high-speed connectivity to early adopters of 5G by
incorporating Long Term Evolution (LTE) network infrastructure. In addition to
the technological advancements, novel communication paradigms such as
anticipatory mobile networking aim to achieve a more intelligent usage of the
available network resources through exploitation of context knowledge. For this
purpose, novel methods for proactive prediction of the end-to-end behavior are
seen as key enablers. In this paper, we present a first empirical analysis of
client-based end-to-end data rate prediction for 5G NSA vehicle-to-cloud
communications. Although this operation mode is characterized by massive
fluctuations of the observed data rate, the results show that conventional
machine learning methods can utilize locally acquirable measurements for
achieving comparably accurate estimations of the end-to-end behavior.

    

### [[2109.03818] Online Learning for Cooperative Multi-Player Multi-Armed Bandits](http://arxiv.org/abs/2109.03818)


  We introduce a framework for decentralized online learning for multi-armed
bandits (MAB) with multiple cooperative players. The reward obtained by the
players in each round depends on the actions taken by all the players. It's a
team setting, and the objective is common. Information asymmetry is what makes
the problem interesting and challenging. We consider three types of information
asymmetry: action information asymmetry when the actions of the players can't
be observed but the rewards received are common; reward information asymmetry
when the actions of the other players are observable but rewards received are
IID from the same distribution; and when we have both action and reward
information asymmetry. For the first setting, we propose a UCB-inspired
algorithm that achieves $O(\log T)$ regret whether the rewards are IID or
Markovian. For the second section, we offer an environment such that the
algorithm given for the first setting gives linear regret. For the third
setting, we show that a variation of the `explore then commit' algorithm
achieves almost log regret.

    

### [[2109.03819] Powering Comparative Classification with Sentiment Analysis via Domain Adaptive Knowledge Transfer](http://arxiv.org/abs/2109.03819)


  We study Comparative Preference Classification (CPC) which aims at predicting
whether a preference comparison exists between two entities in a given sentence
and, if so, which entity is preferred over the other. High-quality CPC models
can significantly benefit applications such as comparative question answering
and review-based recommendations. Among the existing approaches, non-deep
learning methods suffer from inferior performances. The state-of-the-art graph
neural network-based ED-GAT (Ma et al., 2020) only considers syntactic
information while ignoring the critical semantic relations and the sentiments
to the compared entities. We proposed sentiment Analysis Enhanced COmparative
Network (SAECON) which improves CPC ac-curacy with a sentiment analyzer that
learns sentiments to individual entities via domain adaptive knowledge
transfer. Experiments on the CompSent-19 (Panchenko et al., 2019) dataset
present a significant improvement on the F1 scores over the best existing CPC
approaches.

    

### [[2109.03820] Tom: Leveraging trend of the observed gradients for faster convergence](http://arxiv.org/abs/2109.03820)


  The success of deep learning can be attributed to various factors such as
increase in computational power, large datasets, deep convolutional neural
networks, optimizers etc. Particularly, the choice of optimizer affects the
generalization, convergence rate, and training stability. Stochastic Gradient
Descent (SGD) is a first order iterative optimizer that updates the gradient
uniformly for all parameters. This uniform update may not be suitable across
the entire training phase. A rudimentary solution for this is to employ a
fine-tuned learning rate scheduler which decreases learning rate as a function
of iteration. To eliminate the dependency of learning rate schedulers, adaptive
gradient optimizers such as AdaGrad, AdaDelta, RMSProp, Adam employ a
parameter-wise scaling term for learning rate which is a function of the
gradient itself. We propose Tom (Trend over Momentum) optimizer, which is a
novel variant of Adam that takes into account of the trend which is observed
for the gradients in the loss landscape traversed by the neural network. In the
proposed Tom optimizer, an additional smoothing equation is introduced to
address the trend observed during the process of optimization. The smoothing
parameter introduced for the trend requires no tuning and can be used with
default values. Experimental results for classification datasets such as
CIFAR-10, CIFAR-100 and CINIC-10 image datasets show that Tom outperforms
Adagrad, Adadelta, RMSProp and Adam in terms of both accuracy and has a faster
convergence. The source code is publicly made available at
this https URL


### [[2109.03821] Recommend for a Reason: Unlocking the Power of Unsupervised Aspect-Sentiment Co-Extraction](http://arxiv.org/abs/2109.03821)


  Compliments and concerns in reviews are valuable for understanding users'
shopping interests and their opinions with respect to specific aspects of
certain items. Existing review-based recommenders favor large and complex
language encoders that can only learn latent and uninterpretable text
representations. They lack explicit user attention and item property modeling,
which however could provide valuable information beyond the ability to
recommend items. Therefore, we propose a tightly coupled two-stage approach,
including an Aspect-Sentiment Pair Extractor (ASPE) and an
Attention-Property-aware Rating Estimator (APRE). Unsupervised ASPE mines
Aspect-Sentiment pairs (AS-pairs) and APRE predicts ratings using AS-pairs as
concrete aspect-level evidence. Extensive experiments on seven real-world
Amazon Review Datasets demonstrate that ASPE can effectively extract AS-pairs
which enable APRE to deliver superior accuracy over the leading baselines.

    

### [[2109.03839] Mean-Square Analysis with An Application to Optimal Dimension Dependence of Langevin Monte Carlo](http://arxiv.org/abs/2109.03839)


  Sampling algorithms based on discretizations of Stochastic Differential
Equations (SDEs) compose a rich and popular subset of MCMC methods. This work
provides a general framework for the non-asymptotic analysis of sampling error
in 2-Wasserstein distance, which also leads to a bound of mixing time. The
method applies to any consistent discretization of contractive SDEs. When
applied to Langevin Monte Carlo algorithm, it establishes
$\tilde{\mathcal{O}}\left( \frac{\sqrt{d}}{\epsilon} \right)$ mixing time,
without warm start, under the common log-smooth and log-strongly-convex
conditions, plus a growth condition on the 3rd-order derivative of the
potential of target measures at infinity. This bound improves the best
previously known $\tilde{\mathcal{O}}\left( \frac{d}{\epsilon} \right)$ result
and is optimal (in terms of order) in both dimension $d$ and accuracy tolerance
$\epsilon$ for target measures satisfying the aforementioned assumptions. Our
theoretical analysis is further validated by numerical experiments.

    

### [[2109.03848] Knowledge mining of unstructured information: application to cyber-domain](http://arxiv.org/abs/2109.03848)


  Cyber intelligence is widely and abundantly available in numerous open online
sources with reports on vulnerabilities and incidents. This constant stream of
noisy information requires new tools and techniques if it is to be used for the
benefit of analysts and investigators in various organizations. In this paper
we present and implement a novel knowledge graph and knowledge mining framework
for extracting relevant information from free-form text about incidents in the
cyber domain. Our framework includes a machine learning based pipeline as well
as crawling methods for generating graphs of entities, attackers and the
related information with our non-technical cyber ontology. We test our
framework on publicly available cyber incident datasets to evaluate the
accuracy of our knowledge mining methods as well as the usefulness of the
framework in the use of cyber analysts. Our results show analyzing the
knowledge graph constructed using the novel framework, an analyst can infer
additional information from the current cyber landscape in terms of risk to
various entities and the propagation of risk between industries and countries.
Expanding the framework to accommodate more technical and operational level
information can increase the accuracy and explainability of trends and risk in
the knowledge graph.

    

### [[2109.03856] Local Augmentation for Graph Neural Networks](http://arxiv.org/abs/2109.03856)


  Data augmentation has been widely used in image data and linguistic data but
remains under-explored on graph-structured data. Existing methods focus on
augmenting the graph data from a global perspective and largely fall into two
genres: structural manipulation and adversarial training with feature noise
injection. However, the structural manipulation approach suffers information
loss issues while the adversarial training approach may downgrade the feature
quality by injecting noise. In this work, we introduce the local augmentation,
which enhances node features by its local subgraph structures. Specifically, we
model the data argumentation as a feature generation process. Given the central
node's feature, our local augmentation approach learns the conditional
distribution of its neighbors' features and generates the neighbors' optimal
feature to boost the performance of downstream tasks. Based on the local
augmentation, we further design a novel framework: LA-GNN, which can apply to
any GNN models in a plug-and-play manner. Extensive experiments and analyses
show that local augmentation consistently yields performance improvement for
various GNN architectures across a diverse set of benchmarks. Code is available
at this https URL.

    

### [[2109.03857] Robust Optimal Classification Trees Against Adversarial Examples](http://arxiv.org/abs/2109.03857)


  Decision trees are a popular choice of explainable model, but just like
neural networks, they suffer from adversarial examples. Existing algorithms for
fitting decision trees robust against adversarial examples are greedy
heuristics and lack approximation guarantees. In this paper we propose ROCT, a
collection of methods to train decision trees that are optimally robust against
user-specified attack models. We show that the min-max optimization problem
that arises in adversarial learning can be solved using a single minimization
formulation for decision trees with 0-1 loss. We propose such formulations in
Mixed-Integer Linear Programming and Maximum Satisfiability, which widely
available solvers can optimize. We also present a method that determines the
upper bound on adversarial accuracy for any model using bipartite matching. Our
experimental results demonstrate that the existing heuristics achieve close to
optimal scores while ROCT achieves state-of-the-art scores.

    

### [[2109.03859] Leveraging Code Clones and Natural Language Processing for Log Statement Prediction](http://arxiv.org/abs/2109.03859)


  Software developers embed logging statements inside the source code as an
imperative duty in modern software development as log files are necessary for
tracking down runtime system issues and troubleshooting system management
tasks. Prior research has emphasized the importance of logging statements in
the operation and debugging of software systems. However, the current logging
process is mostly manual and ad hoc, and thus, proper placement and content of
logging statements remain as challenges. To overcome these challenges, methods
that aim to automate log placement and log content, i.e., 'where, what, and how
to log', are of high interest. Thus, we propose to accomplish the goal of this
research, that is "to predict the log statements by utilizing source code
clones and natural language processing (NLP)", as these approaches provide
additional context and advantage for log prediction. We pursue the following
four research objectives: (RO1) investigate whether source code clones can be
leveraged for log statement location prediction, (RO2) propose a clone-based
approach for log statement prediction, (RO3) predict log statement's
description with code-clone and NLP models, and (RO4) examine approaches to
automatically predict additional details of the log statement, such as its
verbosity level and variables. For this purpose, we perform an experimental
analysis on seven open-source java projects, extract their method-level code
clones, investigate their attributes, and utilize them for log location and
description prediction. Our work demonstrates the effectiveness of log-aware
clone detection for automated log location and description prediction and
outperforms the prior work.

    

### [[2109.03862] Juvenile state hypothesis: What we can learn from lottery ticket hypothesis researches?](http://arxiv.org/abs/2109.03862)


  The proposition of lottery ticket hypothesis revealed the relationship
between network structure and initialization parameters and the learning
potential of neural networks. The original lottery ticket hypothesis performs
pruning and weight resetting after training convergence, exposing it to the
problem of forgotten learning knowledge and potential high cost of training.
Therefore, we propose a strategy that combines the idea of neural network
structure search with a pruning algorithm to alleviate this problem. This
algorithm searches and extends the network structure on existing winning ticket
sub-network to producing new winning ticket recursively. This allows the
training and pruning process to continue without compromising performance. A
new winning ticket sub-network with deeper network structure, better
generalization ability and better test performance can be obtained in this
recursive manner. This method can solve: the difficulty of training or
performance degradation of the sub-networks after pruning, the forgetting of
the weights of the original lottery ticket hypothesis and the difficulty of
generating winning ticket sub-network when the final network structure is not
given. We validate this strategy on the MNIST and CIFAR-10 datasets. And after
relating it to similar biological phenomena and relevant lottery ticket
hypothesis studies in recent years, we will further propose a new hypothesis to
discuss which factors that can keep a network juvenile, i.e., those possible
factors that influence the learning potential or generalization performance of
a neural network during training.

    

### [[2109.03866] Learning the hypotheses space from data through a U-curve algorithm: a statistically consistent complexity regularizer for Model Selection](http://arxiv.org/abs/2109.03866)


  This paper proposes a data-driven systematic, consistent and non-exhaustive
approach to Model Selection, that is an extension of the classical agnostic PAC
learning model. In this approach, learning problems are modeled not only by a
hypothesis space $\mathcal{H}$, but also by a Learning Space
$\mathbb{L}(\mathcal{H})$, a poset of subspaces of $\mathcal{H}$, which covers
$\mathcal{H}$ and satisfies a property regarding the VC dimension of related
subspaces, that is a suitable algebraic search space for Model Selection
algorithms. Our main contributions are a data-driven general learning algorithm
to perform regularized Model Selection on $\mathbb{L}(\mathcal{H})$ and a
framework under which one can, theoretically, better estimate a target
hypothesis with a given sample size by properly modeling
$\mathbb{L}(\mathcal{H})$ and employing high computational power. A remarkable
consequence of this approach are conditions under which a non-exhaustive search
of $\mathbb{L}(\mathcal{H})$ can return an optimal solution. The results of
this paper lead to a practical property of Machine Learning, that the lack of
experimental data may be mitigated by a high computational capacity. In a
context of continuous popularization of computational power, this property may
help understand why Machine Learning has become so important, even where data
is expensive and hard to get.

    

### [[2109.03867] LSB: Local Self-Balancing MCMC in Discrete Spaces](http://arxiv.org/abs/2109.03867)


  Markov Chain Monte Carlo (MCMC) methods are promising solutions to sample
from target distributions in high dimensions. While MCMC methods enjoy nice
theoretical properties, like guaranteed convergence and mixing to the true
target, in practice their sampling efficiency depends on the choice of the
proposal distribution and the target at hand. This work considers using machine
learning to adapt the proposal distribution to the target, in order to improve
the sampling efficiency in the purely discrete domain. Specifically, (i) it
proposes a new parametrization for a family of proposal distributions, called
locally balanced proposals, (ii) it defines an objective function based on
mutual information and (iii) it devises a learning procedure to adapt the
parameters of the proposal to the target, thus achieving fast convergence and
fast mixing. We call the resulting sampler as the Locally Self-Balancing
Sampler (LSB). We show through experimental analysis on the Ising model and
Bayesian networks that LSB is indeed able to improve the efficiency over a
state-of-the-art sampler based on locally balanced proposals, thus reducing the
number of iterations required to converge, while achieving comparable mixing
performance.

    

### [[2109.03874] Initialization for Nonnegative Matrix Factorization: a Comprehensive Review](http://arxiv.org/abs/2109.03874)


  Non-negative matrix factorization (NMF) has become a popular method for
representing meaningful data by extracting a non-negative basis feature from an
observed non-negative data matrix. Some of the unique features of this method
in identifying hidden data put this method amongst the powerful methods in the
machine learning area. The NMF is a known non-convex optimization problem and
the initial point has a significant effect on finding an efficient local
solution. In this paper, we investigate the most popular initialization
procedures proposed for NMF so far. We describe each method and present some of
their advantages and disadvantages. Finally, some numerical results to
illustrate the performance of each algorithm are presented.

    

### [[2109.03882] On the estimation of discrete choice models to capture irrational customer behaviors](http://arxiv.org/abs/2109.03882)


  The Random Utility Maximization model is by far the most adopted framework to
estimate consumer choice behavior. However, behavioral economics has provided
strong empirical evidence of irrational choice behavior, such as halo effects,
that are incompatible with this framework. Models belonging to the Random
Utility Maximization family may therefore not accurately capture such
irrational behavior. Hence, more general choice models, overcoming such
limitations, have been proposed. However, the flexibility of such models comes
at the price of increased risk of overfitting. As such, estimating such models
remains a challenge. In this work, we propose an estimation method for the
recently proposed Generalized Stochastic Preference choice model, which
subsumes the family of Random Utility Maximization models and is capable of
capturing halo effects. Specifically, we show how to use partially-ranked
preferences to efficiently model rational and irrational customer types from
transaction data. Our estimation procedure is based on column generation, where
relevant customer types are efficiently extracted by expanding a tree-like data
structure containing the customer behaviors. Further, we propose a new
dominance rule among customer types whose effect is to prioritize low orders of
interactions among products. An extensive set of experiments assesses the
predictive accuracy of the proposed approach. Our results show that accounting
for irrational preferences can boost predictive accuracy by 12.5% on average,
when tested on a real-world dataset from a large chain of grocery and drug
stores.

    

### [[2109.03890] Model Explanations via the Axiomatic Causal Lens](http://arxiv.org/abs/2109.03890)


  Explaining the decisions of black-box models has been a central theme in the
study of trustworthy ML. Numerous measures have been proposed in the
literature; however, none of them have been able to adopt a provably causal
take on explainability. Building upon Halpern and Pearl's formal definition of
a causal explanation, we derive an analogous set of axioms for the
classification setting, and use them to derive three explanation measures. Our
first measure is a natural adaptation of Chockler and Halpern's notion of
causal responsibility, whereas the other two correspond to existing
game-theoretic influence measures. We present an axiomatic treatment for our
proposed indices, showing that they can be uniquely characterized by a set of
desirable properties. We compliment this with computational analysis, providing
probabilistic approximation schemes for all of our proposed measures. Thus, our
work is the first to formally bridge the gap between model explanations,
game-theoretic influence, and causal analysis.

    

### [[2109.03891] SORNet: Spatial Object-Centric Representations for Sequential Manipulation](http://arxiv.org/abs/2109.03891)


  Sequential manipulation tasks require a robot to perceive the state of an
environment and plan a sequence of actions leading to a desired goal state,
where the ability to reason about spatial relationships among object entities
from raw sensor inputs is crucial. Prior works relying on explicit state
estimation or end-to-end learning struggle with novel objects. In this work, we
propose SORNet (Spatial Object-Centric Representation Network), which extracts
object-centric representations from RGB images conditioned on canonical views
of the objects of interest. We show that the object embeddings learned by
SORNet generalize zero-shot to unseen object entities on three spatial
reasoning tasks: spatial relationship classification, skill precondition
classification and relative direction regression, significantly outperforming
baselines. Further, we present real-world robotic experiments demonstrating the
usage of the learned object embeddings in task planning for sequential
manipulation.

    

### [[2109.03892] Retrieve, Caption, Generate: Visual Grounding for Enhancing Commonsense in Text Generation Models](http://arxiv.org/abs/2109.03892)


  We investigate the use of multimodal information contained in images as an
effective method for enhancing the commonsense of Transformer models for text
generation. We perform experiments using BART and T5 on concept-to-text
generation, specifically the task of generative commonsense reasoning, or
CommonGen. We call our approach VisCTG: Visually Grounded Concept-to-Text
Generation. VisCTG involves captioning images representing appropriate everyday
scenarios, and using these captions to enrich and steer the generation process.
Comprehensive evaluation and analysis demonstrate that VisCTG noticeably
improves model performance while successfully addressing several issues of the
baseline generations, including poor commonsense, fluency, and specificity.

    

### [[2109.03900] Machine learning modeling of family wide enzyme-substrate specificity screens](http://arxiv.org/abs/2109.03900)


  Biocatalysis is a promising approach to sustainably synthesize
pharmaceuticals, complex natural products, and commodity chemicals at scale.
However, the adoption of biocatalysis is limited by our ability to select
enzymes that will catalyze their natural chemical transformation on non-natural
substrates. While machine learning and in silico directed evolution are
well-posed for this predictive modeling challenge, efforts to date have
primarily aimed to increase activity against a single known substrate, rather
than to identify enzymes capable of acting on new substrates of interest. To
address this need, we curate 6 different high-quality enzyme family screens
from the literature that each measure multiple enzymes against multiple
substrates. We compare machine learning-based compound-protein interaction
(CPI) modeling approaches from the literature used for predicting drug-target
interactions. Surprisingly, comparing these interaction-based models against
collections of independent (single task) enzyme-only or substrate-only models
reveals that current CPI approaches are incapable of learning interactions
between compounds and proteins in the current family level data regime. We
further validate this observation by demonstrating that our no-interaction
baseline can outperform CPI-based models from the literature used to guide the
discovery of kinase inhibitors. Given the high performance of non-interaction
based models, we introduce a new structure-based strategy for pooling residue
representations across a protein sequence. Altogether, this work motivates a
principled path forward in order to build and evaluate meaningful predictive
models for biocatalysis and other drug discovery applications.

    

### [[2109.03902] Simplified Quantum Algorithm for the Oracle Identification Problem](http://arxiv.org/abs/2109.03902)


  In the oracle identification problem we have oracle access to bits of an
unknown string $x$ of length $n$, with the promise that it belongs to a known
set $C\subseteq\{0,1\}^n$. The goal is to identify $x$ using as few queries to
the oracle as possible. We develop a quantum query algorithm for this problem
with query complexity $O\left(\sqrt{\frac{n\log M }{\log(n/\log M)+1}}\right)$,
where $M$ is the size of $C$. This bound is already derived by Kothari in 2014,
for which we provide a more elegant simpler proof.

    

### [[2109.03930] Matrix Completion of World Trade](http://arxiv.org/abs/2109.03930)


  This work applies Matrix Completion (MC) -- a class of machine-learning
methods commonly used in the context of recommendation systems -- to analyse
economic complexity. MC is applied to reconstruct the Revealed Comparative
Advantage (RCA) matrix, whose elements express the relative advantage of
countries in given classes of products, as evidenced by yearly trade flows. A
high-accuracy binary classifier is derived from the application of MC, with the
aim of discriminating between elements of the RCA matrix that are,
respectively, higher or lower than one. We introduce a novel Matrix cOmpletion
iNdex of Economic complexitY (MONEY) based on MC, which is related to the
predictability of countries' RCA (the lower the predictability, the higher the
complexity). Differently from previously-developed indices of economic
complexity, the MONEY index takes into account the various singular vectors of
the matrix reconstructed by MC, whereas other indices are based only on one/two
eigenvectors of a suitable symmetric matrix, derived from the RCA matrix.
Finally, MC is compared with a state-of-the-art economic complexity index
(GENEPY). We show that the false positive rate per country of a binary
classifier constructed starting from the average entry-wise output of MC can be
used as a proxy of GENEPY.

    

### [[2109.03941] Unsupervised Pre-training with Structured Knowledge for Improving Natural Language Inference](http://arxiv.org/abs/2109.03941)


  While recent research on natural language inference has considerably
benefited from large annotated datasets, the amount of inference-related
knowledge (including commonsense) provided in the annotated data is still
rather limited. There have been two lines of approaches that can be used to
further address the limitation: (1) unsupervised pretraining can leverage
knowledge in much larger unstructured text data; (2) structured (often
human-curated) knowledge has started to be considered in neural-network-based
models for NLI. An immediate question is whether these two approaches
complement each other, or how to develop models that can bring together their
advantages. In this paper, we propose models that leverage structured knowledge
in different components of pre-trained models. Our results show that the
proposed models perform better than previous BERT-based state-of-the-art
models. Although our models are proposed for NLI, they can be easily extended
to other sentence or sentence-pair classification problems.

    

### [[2109.03947] SensiX++: Bringing MLOPs and Multi-tenant Model Serving to Sensory Edge Devices](http://arxiv.org/abs/2109.03947)


  We present SensiX++ - a multi-tenant runtime for adaptive model execution
with integrated MLOps on edge devices, e.g., a camera, a microphone, or IoT
sensors. SensiX++ operates on two fundamental principles - highly modular
componentisation to externalise data operations with clear abstractions and
document-centric manifestation for system-wide orchestration. First, a data
coordinator manages the lifecycle of sensors and serves models with correct
data through automated transformations. Next, a resource-aware model server
executes multiple models in isolation through model abstraction, pipeline
automation and feature sharing. An adaptive scheduler then orchestrates the
best-effort executions of multiple models across heterogeneous accelerators,
balancing latency and throughput. Finally, microservices with REST APIs serve
synthesised model predictions, system statistics, and continuous deployment.
Collectively, these components enable SensiX++ to serve multiple models
efficiently with fine-grained control on edge devices while minimising data
operation redundancy, managing data and device heterogeneity, reducing resource
contention and removing manual MLOps. We benchmark SensiX++ with ten different
vision and acoustics models across various multi-tenant configurations on
different edge accelerators (Jetson AGX and Coral TPU) designed for sensory
devices. We report on the overall throughput and quantified benefits of various
automation components of SensiX++ and demonstrate its efficacy to significantly
reduce operational complexity and lower the effort to deploy, upgrade,
reconfigure and serve embedded models on edge devices.

    

### [[2109.03951] Learning the Physics of Particle Transport via Transformers](http://arxiv.org/abs/2109.03951)


  Particle physics simulations are the cornerstone of nuclear engineering
applications. Among them radiotherapy (RT) is crucial for society, with 50% of
cancer patients receiving radiation treatments. For the most precise targeting
of tumors, next generation RT treatments aim for real-time correction during
radiation delivery, necessitating particle transport algorithms that yield
precise dose distributions in sub-second times even in highly heterogeneous
patient geometries. This is infeasible with currently available, purely physics
based simulations. In this study, we present a data-driven dose calculation
algorithm predicting the dose deposited by mono-energetic proton beams for
arbitrary energies and patient geometries. Our approach frames particle
transport as sequence modeling, where convolutional layers extract important
spatial features into tokens and the transformer self-attention mechanism
routes information between such tokens in the sequence and a beam energy token.
We train our network and evaluate prediction accuracy using computationally
expensive but accurate Monte Carlo (MC) simulations, considered the gold
standard in particle physics. Our proposed model is 33 times faster than
current clinical analytic pencil beam algorithms, improving upon their accuracy
in the most heterogeneous and challenging geometries. With a relative error of
0.34% and very high gamma pass rate of 99.59% (1%, 3 mm), it also greatly
outperforms the only published similar data-driven proton dose algorithm, even
at a finer grid resolution. Offering MC precision 400 times faster, our model
could overcome a major obstacle that has so far prohibited real-time adaptive
proton treatments and significantly increase cancer treatment efficacy. Its
potential to model physics interactions of other particles could also boost
heavy ion treatment planning procedures limited by the speed of traditional
methods.

    

### [[2109.03955] NU:BRIEF -- A Privacy-aware Newsletter Personalization Engine for Publishers](http://arxiv.org/abs/2109.03955)


  Newsletters have (re-) emerged as a powerful tool for publishers to engage
with their readers directly and more effectively. Despite the diversity in
their audiences, publishers' newsletters remain largely a one-size-fits-all
offering, which is suboptimal. In this paper, we present NU:BRIEF, a web
application for publishers that enables them to personalize their newsletters
without harvesting personal data. Personalized newsletters build a habit and
become a great conversion tool for publishers, providing an alternative
readers-generated revenue model to a declining ad/clickbait-centered business
model.

    

### [[2109.03956] AdjointNet: Constraining machine learning models with physics-based codes](http://arxiv.org/abs/2109.03956)


  Physics-informed Machine Learning has recently become attractive for learning
physical parameters and features from simulation and observation data. However,
most existing methods do not ensure that the physics, such as balance laws
(e.g., mass, momentum, energy conservation), are constrained. Some recent works
(e.g., physics-informed neural networks) softly enforce physics constraints by
including partial differential equation (PDE)-based loss functions but need
re-discretization of the PDEs using auto-differentiation. Training these neural
nets on observational data showed that one could solve forward and inverse
problems in one shot. They evaluate the state variables and the parameters in a
PDE. This re-discretization of PDEs is not necessarily an attractive option for
domain scientists that work with physics-based codes that have been developed
for decades with sophisticated discretization techniques to solve complex
process models and advanced equations of state. This paper proposes a physics
constrained machine learning framework, AdjointNet, allowing domain scientists
to embed their physics code in neural network training workflows. This
embedding ensures that physics is constrained everywhere in the domain.
Additionally, the mathematical properties such as consistency, stability, and
convergence vital to the numerical solution of a PDE are still satisfied. We
show that the proposed AdjointNet framework can be used for parameter
estimation (and uncertainty quantification by extension) and experimental
design using active learning. The applicability of our framework is
demonstrated for four flow cases. Results show that AdjointNet-based inversion
can estimate process model parameters with reasonable accuracy. These examples
demonstrate the applicability of using existing software with no changes in
source code to perform accurate and reliable inversion of model parameters.

    

### [[2109.03966] Sensitive Samples Revisited: Detecting Neural Network Attacks Using Constraint Solvers](http://arxiv.org/abs/2109.03966)


  Neural Networks are used today in numerous security- and safety-relevant
domains and are, as such, a popular target of attacks that subvert their
classification capabilities, by manipulating the network parameters. Prior work
has introduced sensitive samples -- inputs highly sensitive to parameter
changes -- to detect such manipulations, and proposed a gradient ascent-based
approach to compute them. In this paper we offer an alternative, using symbolic
constraint solvers. We model the network and a formal specification of a
sensitive sample in the language of the solver and ask for a solution. This
approach supports a rich class of queries, corresponding, for instance, to the
presence of certain types of attacks. Unlike earlier techniques, our approach
does not depend on convex search domains, or on the suitability of a starting
point for the search. We address the performance limitations of constraint
solvers by partitioning the search space for the solver, and exploring the
partitions according to a balanced schedule that still retains completeness of
the search. We demonstrate the impact of the use of solvers in terms of
functionality and search efficiency, using a case study for the detection of
Trojan attacks on Neural Networks.

    

### [[2109.03970] PowerGym: A Reinforcement Learning Environment for Volt-Var Control in Power Distribution Systems](http://arxiv.org/abs/2109.03970)


  We introduce PowerGym, an open-source reinforcement learning environment for
Volt-Var control in power distribution systems. Following OpenAI Gym APIs,
PowerGym targets minimizing power loss and voltage violations under physical
networked constraints. PowerGym provides four distribution systems (13Bus,
34Bus, 123Bus, and 8500Node) based on IEEE benchmark systems and design
variants for various control difficulties. To foster generalization, PowerGym
offers a detailed customization guide for users working with their distribution
systems. As a demonstration, we examine state-of-the-art reinforcement learning
algorithms in PowerGym and validate the environment by studying controller
behaviors.

    

### [[2109.03973] Iterated Vector Fields and Conservatism, with Applications to Federated Learning](http://arxiv.org/abs/2109.03973)


  We study iterated vector fields and investigate whether they are
conservative, in the sense that they are the gradient of some scalar-valued
function. We analyze the conservatism of various iterated vector fields,
including gradient vector fields associated to loss functions of generalized
linear models. We relate this study to optimization and derive novel
convergence results for federated learning algorithms. In particular, we show
that for certain classes of functions (including non-convex functions),
federated averaging is equivalent to gradient descent on a surrogate loss
function. Finally, we discuss a variety of open questions spanning topics in
geometry, dynamical systems, and optimization.

    

### [[2109.03974] Constants of Motion: The Antidote to Chaos in Optimization and Game Dynamics](http://arxiv.org/abs/2109.03974)


  Several recent works in online optimization and game dynamics have
established strong negative complexity results including the formal emergence
of instability and chaos even in small such settings, e.g., $2\times 2$ games.
These results motivate the following question: Which methodological tools can
guarantee the regularity of such dynamics and how can we apply them in standard
settings of interest such as discrete-time first-order optimization dynamics?
We show how proving the existence of invariant functions, i.e., constant of
motions, is a fundamental contribution in this direction and establish a
plethora of such positive results (e.g. gradient descent, multiplicative
weights update, alternating gradient descent and manifold gradient descent)
both in optimization as well as in game settings. At a technical level, for
some conservation laws we provide an explicit and concise closed form, whereas
for other ones we present non-constructive proofs using tools from dynamical
systems.

    

### [[2109.03975] Where Did You Learn That From? Surprising Effectiveness of Membership Inference Attacks Against Temporally Correlated Data in Deep Reinforcement Learning](http://arxiv.org/abs/2109.03975)


  While significant research advances have been made in the field of deep
reinforcement learning, a major challenge to widespread industrial adoption of
deep reinforcement learning that has recently surfaced but little explored is
the potential vulnerability to privacy breaches. In particular, there have been
no concrete adversarial attack strategies in literature tailored for studying
the vulnerability of deep reinforcement learning algorithms to membership
inference attacks. To address this gap, we propose an adversarial attack
framework tailored for testing the vulnerability of deep reinforcement learning
algorithms to membership inference attacks. More specifically, we design a
series of experiments to investigate the impact of temporal correlation, which
naturally exists in reinforcement learning training data, on the probability of
information leakage. Furthermore, we study the differences in the performance
of \emph{collective} and \emph{individual} membership attacks against deep
reinforcement learning algorithms. Experimental results show that the proposed
adversarial attack framework is surprisingly effective at inferring the data
used during deep reinforcement training with an accuracy exceeding $84\%$ in
individual and $97\%$ in collective mode on two different control tasks in
OpenAI Gym, which raises serious privacy concerns in the deployment of models
resulting from deep reinforcement learning. Moreover, we show that the learning
state of a reinforcement learning algorithm significantly influences the level
of the privacy breach.

    

### [[2109.03989] Detecting Attacks on IoT Devices using Featureless 1D-CNN](http://arxiv.org/abs/2109.03989)


  The generalization of deep learning has helped us, in the past, address
challenges such as malware identification and anomaly detection in the network
security domain. However, as effective as it is, scarcity of memory and
processing power makes it difficult to perform these tasks in Internet of
Things (IoT) devices. This research finds an easy way out of this bottleneck by
depreciating the need for feature engineering and subsequent processing in
machine learning techniques. In this study, we introduce a Featureless machine
learning process to perform anomaly detection. It uses unprocessed byte streams
of packets as training data. Featureless machine learning enables a low cost
and low memory time-series analysis of network traffic. It benefits from
eliminating the significant investment in subject matter experts and the time
required for feature engineering.

    

### [[2109.03991] The challenge of reproducible ML: an empirical study on the impact of bugs](http://arxiv.org/abs/2109.03991)


  Reproducibility is a crucial requirement in scientific research. When results
of research studies and scientific papers have been found difficult or
impossible to reproduce, we face a challenge which is called reproducibility
crisis. Although the demand for reproducibility in Machine Learning (ML) is
acknowledged in the literature, a main barrier is inherent non-determinism in
ML training and inference. In this paper, we establish the fundamental factors
that cause non-determinism in ML systems. A framework, ReproduceML, is then
introduced for deterministic evaluation of ML experiments in a real, controlled
environment. ReproduceML allows researchers to investigate software
configuration effects on ML training and inference. Using ReproduceML, we run a
case study: investigation of the impact of bugs inside ML libraries on
performance of ML experiments. This study attempts to quantify the impact that
the occurrence of bugs in a popular ML framework, PyTorch, has on the
performance of trained models. To do so, a comprehensive methodology is
proposed to collect buggy versions of ML libraries and run deterministic ML
experiments using ReproduceML. Our initial finding is that there is no evidence
based on our limited dataset to show that bugs which occurred in PyTorch do
affect the performance of trained models. The proposed methodology as well as
ReproduceML can be employed for further research on non-determinism and bugs.

    

### [[2109.03992] Stationary Density Estimation of Itô Diffusions Using Deep Learning](http://arxiv.org/abs/2109.03992)


  In this paper, we consider the density estimation problem associated with the
stationary measure of ergodic Itô diffusions from a discrete-time series that
approximate the solutions of the stochastic differential equations. To take an
advantage of the characterization of density function through the stationary
solution of a parabolic-type Fokker-Planck PDE, we proceed as follows. First,
we employ deep neural networks to approximate the drift and diffusion terms of
the SDE by solving appropriate supervised learning tasks. Subsequently, we
solve a steady-state Fokker-Plank equation associated with the estimated drift
and diffusion coefficients with a neural-network-based least-squares method. We
establish the convergence of the proposed scheme under appropriate mathematical
assumptions, accounting for the generalization errors induced by regressing the
drift and diffusion coefficients, and the PDE solvers. This theoretical study
relies on a recent perturbation theory of Markov chain result that shows a
linear dependence of the density estimation to the error in estimating the
drift term, and generalization error results of nonparametric regression and of
PDE regression solution obtained with neural-network models. The effectiveness
of this method is reflected by numerical simulations of a two-dimensional
Student's t distribution and a 20-dimensional Langevin dynamics.

    

### [[2109.04001] Deep Reinforcement Learning for Equal Risk Pricing and Hedging under Dynamic Expectile Risk Measures](http://arxiv.org/abs/2109.04001)


  Recently equal risk pricing, a framework for fair derivative pricing, was
extended to consider dynamic risk measures. However, all current
implementations either employ a static risk measure that violates time
consistency, or are based on traditional dynamic programming solution schemes
that are impracticable in problems with a large number of underlying assets
(due to the curse of dimensionality) or with incomplete asset dynamics
information. In this paper, we extend for the first time a famous off-policy
deterministic actor-critic deep reinforcement learning (ACRL) algorithm to the
problem of solving a risk averse Markov decision process that models risk using
a time consistent recursive expectile risk measure. This new ACRL algorithm
allows us to identify high quality time consistent hedging policies (and equal
risk prices) for options, such as basket options, that cannot be handled using
traditional methods, or in context where only historical trajectories of the
underlying assets are available. Our numerical experiments, which involve both
a simple vanilla option and a more exotic basket option, confirm that the new
ACRL algorithm can produce 1) in simple environments, nearly optimal hedging
policies, and highly accurate prices, simultaneously for a range of maturities
2) in complex environments, good quality policies and prices using reasonable
amount of computing resources; and 3) overall, hedging strategies that actually
outperform the strategies produced using static risk measures when the risk is
evaluated at later points of time.

    

### [[2109.04007] MaterialsAtlas.org: A Materials Informatics Web App Platform for Materials Discovery and Survey of State-of-the-Art](http://arxiv.org/abs/2109.04007)


  The availability and easy access of large scale experimental and
computational materials data have enabled the emergence of accelerated
development of algorithms and models for materials property prediction,
structure prediction, and generative design of materials. However, lack of
user-friendly materials informatics web servers has severely constrained the
wide adoption of such tools in the daily practice of materials screening,
tinkering, and design space exploration by materials scientists. Herein we
first survey current materials informatics web apps and then propose and
develop this http URL, a web based materials informatics toolbox for
materials discovery, which includes a variety of routinely needed tools for
exploratory materials discovery, including materials composition and structure
check (e.g. for neutrality, electronegativity balance, dynamic stability,
Pauling rules), materials property prediction (e.g. band gap, elastic moduli,
hardness, thermal conductivity), and search for hypothetical materials. These
user-friendly tools can be freely accessed at \url{this http URL}. We
argue that such materials informatics apps should be widely developed by the
community to speed up the materials discovery processes.

    

### [[2109.04010] Popularity Adjusted Block Models are Generalized Random Dot Product Graphs](http://arxiv.org/abs/2109.04010)


  We connect two random graph models, the Popularity Adjusted Block Model
(PABM) and the Generalized Random Dot Product Graph (GRDPG), by demonstrating
that the PABM is a special case of the GRDPG in which communities correspond to
mutually orthogonal subspaces of latent vectors. This insight allows us to
construct new algorithms for community detection and parameter estimation for
the PABM, as well as improve an existing algorithm that relies on Sparse
Subspace Clustering. Using established asymptotic properties of Adjacency
Spectral Embedding for the GRDPG, we derive asymptotic properties of these
algorithms. In particular, we demonstrate that the absolute number of community
detection errors tends to zero as the number of graph vertices tends to
infinity. Simulation experiments illustrate these properties.

    

### [[2109.04015] Generation, augmentation, and alignment: A pseudo-source domain based method for source-free domain adaptation](http://arxiv.org/abs/2109.04015)


  Conventional unsupervised domain adaptation (UDA) methods need to access both
labeled source samples and unlabeled target samples simultaneously to train the
model. While in some scenarios, the source samples are not available for the
target domain due to data privacy and safety. To overcome this challenge,
recently, source-free domain adaptation (SFDA) has attracted the attention of
researchers, where both a trained source model and unlabeled target samples are
given. Existing SFDA methods either adopt a pseudo-label based strategy or
generate more samples. However, these methods do not explicitly reduce the
distribution shift across domains, which is the key to a good adaptation.
Although there are no source samples available, fortunately, we find that some
target samples are very similar to the source domain and can be used to
approximate the source domain. This approximated domain is denoted as the
pseudo-source domain. In this paper, inspired by this observation, we propose a
novel method based on the pseudo-source domain. The proposed method firstly
generates and augments the pseudo-source domain, and then employs distribution
alignment with four novel losses based on pseudo-label based strategy. Among
them, a domain adversarial loss is introduced between the pseudo-source domain
the remaining target domain to reduce the distribution shift. The results on
three real-world datasets verify the effectiveness of the proposed method.

    

### [[2109.04020] Distributionally Robust Multilingual Machine Translation](http://arxiv.org/abs/2109.04020)


  Multilingual neural machine translation (MNMT) learns to translate multiple
language pairs with a single model, potentially improving both the accuracy and
the memory-efficiency of deployed models. However, the heavy data imbalance
between languages hinders the model from performing uniformly across language
pairs. In this paper, we propose a new learning objective for MNMT based on
distributionally robust optimization, which minimizes the worst-case expected
loss over the set of language pairs. We further show how to practically
optimize this objective for large translation corpora using an iterated best
response scheme, which is both effective and incurs negligible additional
computational cost compared to standard empirical risk minimization. We perform
extensive experiments on three sets of languages from two datasets and show
that our method consistently outperforms strong baseline methods in terms of
average and per-language performance under both many-to-one and one-to-many
translation settings.

    

### [[2109.04024] On the Approximation of Cooperative Heterogeneous Multi-Agent Reinforcement Learning (MARL) using Mean Field Control (MFC)](http://arxiv.org/abs/2109.04024)


  Mean field control (MFC) is an effective way to mitigate the curse of
dimensionality of cooperative multi-agent reinforcement learning (MARL)
problems. This work considers a collection of $N_{\mathrm{pop}}$ heterogeneous
agents that can be segregated into $K$ classes such that the $k$-th class
contains $N_k$ homogeneous agents. We aim to prove approximation guarantees of
the MARL problem for this heterogeneous system by its corresponding MFC
problem. We consider three scenarios where the reward and transition dynamics
of all agents are respectively taken to be functions of $(1)$ joint state and
action distributions across all classes, $(2)$ individual distributions of each
class, and $(3)$ marginal distributions of the entire population. We show that,
in these cases, the $K$-class MARL problem can be approximated by MFC with
errors given as
$e_1=\mathcal{O}(\frac{\sqrt{|\mathcal{X}||\mathcal{U}|}}{N_{\mathrm{pop}}}\sum_{k}\sqrt{N_k})$,
$e_2=\mathcal{O}(\sqrt{|\mathcal{X}||\mathcal{U}|}\sum_{k}\frac{1}{\sqrt{N_k}})$
and
$e_3=\mathcal{O}\left(\sqrt{|\mathcal{X}||\mathcal{U}|}\left[\frac{A}{N_{\mathrm{pop}}}\sum_{k\in[K]}\sqrt{N_k}+\frac{B}{\sqrt{N_{\mathrm{pop}}}}\right]\right)$,
respectively, where $A, B$ are some constants and $|\mathcal{X}|,|\mathcal{U}|$
are the sizes of state and action spaces of each agent. Finally, we design a
Natural Policy Gradient (NPG) based algorithm that, in the three cases stated
above, can converge to an optimal MARL policy within $\mathcal{O}(e_j)$ error
with a sample complexity of $\mathcal{O}(e_j^{-3})$, $j\in\{1,2,3\}$,
respectively.

    

### [[2109.04029] Automated Security Assessment for the Internet of Things](http://arxiv.org/abs/2109.04029)


  Internet of Things (IoT) based applications face an increasing number of
potential security risks, which need to be systematically assessed and
addressed. Expert-based manual assessment of IoT security is a predominant
approach, which is usually inefficient. To address this problem, we propose an
automated security assessment framework for IoT networks. Our framework first
leverages machine learning and natural language processing to analyze
vulnerability descriptions for predicting vulnerability metrics. The predicted
metrics are then input into a two-layered graphical security model, which
consists of an attack graph at the upper layer to present the network
connectivity and an attack tree for each node in the network at the bottom
layer to depict the vulnerability information. This security model
automatically assesses the security of the IoT network by capturing potential
attack paths. We evaluate the viability of our approach using a
proof-of-concept smart building system model which contains a variety of
real-world IoT devices and potential vulnerabilities. Our evaluation of the
proposed framework demonstrates its effectiveness in terms of automatically
predicting the vulnerability metrics of new vulnerabilities with more than 90%
accuracy, on average, and identifying the most vulnerable attack paths within
an IoT network. The produced assessment results can serve as a guideline for
cybersecurity professionals to take further actions and mitigate risks in a
timely manner.

    

### [[2109.04030] Bag of Tricks for Optimizing Transformer Efficiency](http://arxiv.org/abs/2109.04030)


  Improving Transformer efficiency has become increasingly attractive recently.
A wide range of methods has been proposed, e.g., pruning, quantization, new
architectures and etc. But these methods are either sophisticated in
implementation or dependent on hardware. In this paper, we show that the
efficiency of Transformer can be improved by combining some simple and
hardware-agnostic methods, including tuning hyper-parameters, better design
choices and training strategies. On the WMT news translation tasks, we improve
the inference efficiency of a strong Transformer system by 3.80X on CPU and
2.52X on GPU. The code is publicly available at
this https URL.

    

### [[2109.04033] Versions of Gradient Temporal Difference Learning](http://arxiv.org/abs/2109.04033)


  Sutton, Szepesvári and Maei introduced the first gradient
temporal-difference (GTD) learning algorithms compatible with both linear
function approximation and off-policy training. The goal of this paper is (a)
to propose some variants of GTDs with extensive comparative analysis and (b) to
establish new theoretical analysis frameworks for the GTDs. These variants are
based on convex-concave saddle-point interpretations of GTDs, which effectively
unify all the GTDs into a single framework, and provide simple stability
analysis based on recent results on primal-dual gradient dynamics. Finally,
numerical comparative analysis is given to evaluate these approaches.

    

### [[2109.04053] Table-based Fact Verification with Salience-aware Learning](http://arxiv.org/abs/2109.04053)


  Tables provide valuable knowledge that can be used to verify textual
statements. While a number of works have considered table-based fact
verification, direct alignments of tabular data with tokens in textual
statements are rarely available. Moreover, training a generalized fact
verification model requires abundant labeled training data. In this paper, we
propose a novel system to address these problems. Inspired by counterfactual
causality, our system identifies token-level salience in the statement with
probing-based salience estimation. Salience estimation allows enhanced learning
of fact verification from two perspectives. From one perspective, our system
conducts masked salient token prediction to enhance the model for alignment and
reasoning between the table and the statement. From the other perspective, our
system applies salience-aware data augmentation to generate a more diverse set
of training instances by replacing non-salient terms. Experimental results on
TabFact show the effective improvement by the proposed salience-aware learning
techniques, leading to the new SOTA performance on the benchmark. Our code is
publicly available at this https URL .

    

### [[2109.04081] DeepEMO: Deep Learning for Speech Emotion Recognition](http://arxiv.org/abs/2109.04081)


  We proposed the industry level deep learning approach for speech emotion
recognition task. In industry, carefully proposed deep transfer learning
technology shows real results due to mostly low amount of training data
availability, machine training cost, and specialized learning on dedicated AI
tasks. The proposed speech recognition framework, called DeepEMO, consists of
two main pipelines such that preprocessing to extract efficient main features
and deep transfer learning model to train and recognize. Main source code is in
this https URL repository

    

### [[2109.04086] Mapping Research Topics in Software Testing: A Bibliometric Analysis](http://arxiv.org/abs/2109.04086)


  In this study, we apply co-word analysis - a text mining technique based on
the co-occurrence of terms - to map the topology of software testing research
topics, with the goal of providing current and prospective researchers with a
map, and observations about the evolution, of the software testing field. Our
analysis enables the mapping of software testing research into clusters of
connected topics, from which emerge a total of 16 high-level research themes
and a further 18 subthemes. This map also suggests topics that are growing in
importance, including topics related to web and mobile applications and
artificial intelligence. Exploration of author and country-based collaboration
patterns offers similar insight into the implicit and explicit factors that
influence collaboration and suggests emerging sources of collaboration for
future work. We make our observations - and the underlying mapping of research
topics and research collaborations - available so that researchers can gain a
deeper understanding of the topology of the software testing field, inspiration
regarding new areas and connections to explore, and collaborators who will
broaden their perspectives.

    

### [[2109.04094] An Experimental Study of Class Imbalance in Federated Learning](http://arxiv.org/abs/2109.04094)


  Federated learning is a distributed machine learning paradigm that trains a
global model for prediction based on a number of local models at clients while
local data privacy is preserved. Class imbalance is believed to be one of the
factors that degrades the global model performance. However, there has been
very little research on if and how class imbalance can affect the global
performance. class imbalance in federated learning is much more complex than
that in traditional non-distributed machine learning, due to different class
imbalance situations at local clients. Class imbalance needs to be re-defined
in distributed learning environments. In this paper, first, we propose two new
metrics to define class imbalance -- the global class imbalance degree (MID)
and the local difference of class imbalance among clients (WCS). Then, we
conduct extensive experiments to analyze the impact of class imbalance on the
global performance in various scenarios based on our definition. Our results
show that a higher MID and a larger WCS degrade more the performance of the
global model. Besides, WCS is shown to slow down the convergence of the global
model by misdirecting the optimization.

    

### [[2109.04101] TimeTraveler: Reinforcement Learning for Temporal Knowledge Graph Forecasting](http://arxiv.org/abs/2109.04101)


  Temporal knowledge graph (TKG) reasoning is a crucial task that has gained
increasing research interest in recent years. Most existing methods focus on
reasoning at past timestamps to complete the missing facts, and there are only
a few works of reasoning on known TKGs to forecast future facts. Compared with
the completion task, the forecasting task is more difficult that faces two main
challenges: (1) how to effectively model the time information to handle future
timestamps? (2) how to make inductive inference to handle previously unseen
entities that emerge over time? To address these challenges, we propose the
first reinforcement learning method for forecasting. Specifically, the agent
travels on historical knowledge graph snapshots to search for the answer. Our
method defines a relative time encoding function to capture the timespan
information, and we design a novel time-shaped reward based on Dirichlet
distribution to guide the model learning. Furthermore, we propose a novel
representation method for unseen entities to improve the inductive inference
ability of the model. We evaluate our method for this link prediction task at
future timestamps. Extensive experiments on four benchmark datasets demonstrate
substantial performance improvement meanwhile with higher explainability, less
calculation, and fewer parameters when compared with existing state-of-the-art
methods.

    

### [[2109.04114] Fixing exposure bias with imitation learning needs powerful oracles](http://arxiv.org/abs/2109.04114)


  We apply imitation learning (IL) to tackle the NMT exposure bias problem with
error-correcting oracles, and evaluate an SMT lattice-based oracle which,
despite its excellent performance in an unconstrained oracle translation task,
turned out to be too pruned and idiosyncratic to serve as the oracle for IL.

    

### [[2109.04115] AutoSmart: An Efficient and Automatic Machine Learning framework for Temporal Relational Data](http://arxiv.org/abs/2109.04115)


  Temporal relational data, perhaps the most commonly used data type in
industrial machine learning applications, needs labor-intensive feature
engineering and data analyzing for giving precise model predictions. An
automatic machine learning framework is needed to ease the manual efforts in
fine-tuning the models so that the experts can focus more on other problems
that really need humans' engagement such as problem definition, deployment, and
business services. However, there are three main challenges for building
automatic solutions for temporal relational data: 1) how to effectively and
automatically mining useful information from the multiple tables and the
relations from them? 2) how to be self-adjustable to control the time and
memory consumption within a certain budget? and 3) how to give generic
solutions to a wide range of tasks? In this work, we propose our solution that
successfully addresses the above issues in an end-to-end automatic way. The
proposed framework, AutoSmart, is the winning solution to the KDD Cup 2019 of
the AutoML Track, which is one of the largest AutoML competition to date (860
teams with around 4,955 submissions). The framework includes automatic data
processing, table merging, feature engineering, and model tuning, with a
time\&memory controller for efficiently and automatically formulating the
models. The proposed framework outperforms the baseline solution significantly
on several datasets in various domains.

    

### [[2109.04149] DROP: Deep relocating option policy for optimal ride-hailing vehicle repositioning](http://arxiv.org/abs/2109.04149)


  In a ride-hailing system, an optimal relocation of vacant vehicles can
significantly reduce fleet idling time and balance the supply-demand
distribution, enhancing system efficiency and promoting driver satisfaction and
retention. Model-free deep reinforcement learning (DRL) has been shown to
dynamically learn the relocating policy by actively interacting with the
intrinsic dynamics in large-scale ride-hailing systems. However, the issues of
sparse reward signals and unbalanced demand and supply distribution place
critical barriers in developing effective DRL models. Conventional exploration
strategy (e.g., the $\epsilon$-greedy) may barely work under such an
environment because of dithering in low-demand regions distant from
high-revenue regions. This study proposes the deep relocating option policy
(DROP) that supervises vehicle agents to escape from oversupply areas and
effectively relocate to potentially underserved areas. We propose to learn the
Laplacian embedding of a time-expanded relocation graph, as an approximation
representation of the system relocation policy. The embedding generates
task-agnostic signals, which in combination with task-dependent signals,
constitute the pseudo-reward function for generating DROPs. We present a
hierarchical learning framework that trains a high-level relocation policy and
a set of low-level DROPs. The effectiveness of our approach is demonstrated
using a custom-built high-fidelity simulator with real-world trip record data.
We report that DROP significantly improves baseline models with 15.7% more
hourly revenue and can effectively resolve the dithering issue in low-demand
areas.

    

### [[2109.04150] Self-supervised Reinforcement Learning with Independently Controllable Subgoals](http://arxiv.org/abs/2109.04150)


  To successfully tackle challenging manipulation tasks, autonomous agents must
learn a diverse set of skills and how to combine them. Recently,
self-supervised agents that set their own abstract goals by exploiting the
discovered structure in the environment were shown to perform well on many
different tasks. In particular, some of them were applied to learn basic
manipulation skills in compositional multi-object environments. However, these
methods learn skills without taking the dependencies between objects into
account. Thus, the learned skills are difficult to combine in realistic
environments. We propose a novel self-supervised agent that estimates relations
between environment components and uses them to independently control different
parts of the environment state. In addition, the estimated relations between
objects can be used to decompose a complex goal into a compatible sequence of
subgoals. We show that, by using this framework, an agent can efficiently and
automatically learn manipulation tasks in multi-object environments with
different relations between objects.

    

### [[2109.04153] Single Image 3D Object Estimation with Primitive Graph Networks](http://arxiv.org/abs/2109.04153)


  Reconstructing 3D object from a single image (RGB or depth) is a fundamental
problem in visual scene understanding and yet remains challenging due to its
ill-posed nature and complexity in real-world scenes. To address those
challenges, we adopt a primitive-based representation for 3D object, and
propose a two-stage graph network for primitive-based 3D object estimation,
which consists of a sequential proposal module and a graph reasoning module.
Given a 2D image, our proposal module first generates a sequence of 3D
primitives from input image with local feature attention. Then the graph
reasoning module performs joint reasoning on a primitive graph to capture the
global shape context for each primitive. Such a framework is capable of taking
into account rich geometry and semantic constraints during 3D structure
recovery, producing 3D objects with more coherent structure even under
challenging viewing conditions. We train the entire graph neural network in a
stage-wise strategy and evaluate it on three benchmarks: Pix3D, ModelNet and
NYU Depth V2. Extensive experiments show that our approach outperforms the
previous state of the arts with a considerable margin.

    

### [[2109.04160] Compositional Affinity Propagation: When Clusters Have Compositional Structure](http://arxiv.org/abs/2109.04160)


  We consider a new kind of clustering problem in which clusters need not be
independent of each other, but rather can have compositional relationships with
other clusters (e.g., an image set consists of rectangles, circles, as well as
combinations of rectangles and circles). This task is motivated by recent work
in few-shot learning on compositional embedding models that structure the
embedding space to distinguish the label sets, not just the individual labels,
assigned to the examples. To tackle this clustering problem, we propose a new
algorithm called Compositional Affinity Propagation (CAP). In contrast to
standard Affinity Propagation as well as other algorithms for multi-view and
hierarchical clustering, CAP can deduce compositionality among clusters
automatically. We show promising results, compared to several existing
clustering algorithms, on the MultiMNIST, OmniGlot, and LibriSpeech datasets.
Our work has applications to multi-object image recognition and speaker
diarization with simultaneous speech from multiple speakers.

    

### [[2109.04173] Relating Graph Neural Networks to Structural Causal Models](http://arxiv.org/abs/2109.04173)


  Causality can be described in terms of a structural causal model (SCM) that
carries information on the variables of interest and their mechanistic
relations. For most processes of interest the underlying SCM will only be
partially observable, thus causal inference tries to leverage any exposed
information. Graph neural networks (GNN) as universal approximators on
structured input pose a viable candidate for causal learning, suggesting a
tighter integration with SCM. To this effect we present a theoretical analysis
from first principles that establishes a novel connection between GNN and SCM
while providing an extended view on general neural-causal models. We then
establish a new model class for GNN-based causal inference that is necessary
and sufficient for causal effect identification. Our empirical illustration on
simulations and standard benchmarks validate our theoretical proofs.

    

### [[2109.04188] Towards Fully Automated Segmentation of Rat Cardiac MRI by Leveraging Deep Learning Frameworks](http://arxiv.org/abs/2109.04188)


  Automated segmentation of human cardiac magnetic resonance datasets has been
steadily improving during recent years. However, these methods are not directly
applicable in preclinical context due to limited datasets and lower image
resolution. Successful application of deep architectures for rat cardiac
segmentation, although of critical importance for preclinical evaluation of
cardiac function, has to our knowledge not yet been reported. We developed
segmentation models that expand on the standard U-Net architecture and
evaluated separate models for systole and diastole phases, 2MSA, and one model
for all timepoints, 1MSA. Furthermore, we calibrated model outputs using a
Gaussian Process (GP)-based prior to improve phase selection. Resulting models
approach human performance in terms of left ventricular segmentation quality
and ejection fraction (EF) estimation in both 1MSA and 2MSA settings
(Sørensen-Dice score 0.91 +/- 0.072 and 0.93 +/- 0.032, respectively). 2MSA
achieved a mean absolute difference between estimated and reference EF of 3.5
+/- 2.5 %, while 1MSA resulted in 4.1 +/- 3.0 %. Applying Gaussian Processes to
1MSA allows to automate the selection of systole and diastole phases. Combined
with a novel cardiac phase selection strategy, our work presents an important
first step towards a fully automated segmentation pipeline in the context of
rat cardiac analysis.

    

### [[2109.04202] IMG2SMI: Translating Molecular Structure Images to Simplified Molecular-input Line-entry System](http://arxiv.org/abs/2109.04202)


  Like many scientific fields, new chemistry literature has grown at a
staggering pace, with thousands of papers released every month. A large portion
of chemistry literature focuses on new molecules and reactions between
molecules. Most vital information is conveyed through 2-D images of molecules,
representing the underlying molecules or reactions described. In order to
ensure reproducible and machine-readable molecule representations, text-based
molecule descriptors like SMILES and SELFIES were created. These text-based
molecule representations provide molecule generation but are unfortunately
rarely present in published literature. In the absence of molecule descriptors,
the generation of molecule descriptors from the 2-D images present in the
literature is necessary to understand chemistry literature at scale. Successful
methods such as Optical Structure Recognition Application (OSRA), and
ChemSchematicResolver are able to extract the locations of molecules structures
in chemistry papers and infer molecular descriptions and reactions. While
effective, existing systems expect chemists to correct outputs, making them
unsuitable for unsupervised large-scale data mining. Leveraging the task
formulation of image captioning introduced by DECIMER, we introduce IMG2SMI, a
model which leverages Deep Residual Networks for image feature extraction and
an encoder-decoder Transformer layers for molecule description generation.
Unlike previous Neural Network-based systems, IMG2SMI builds around the task of
molecule description generation, which enables IMG2SMI to outperform OSRA-based
systems by 163% in molecule similarity prediction as measured by the molecular
MACCS Fingerprint Tanimoto Similarity. Additionally, to facilitate further
research on this task, we release a new molecule prediction dataset. including
81 million molecules for molecule description generation

    

### [[2109.04206] QUINT: Node embedding using network hashing](http://arxiv.org/abs/2109.04206)


  Representation learning using network embedding has received tremendous
attention due to its efficacy to solve downstream tasks. Popular embedding
methods (such as deepwalk, node2vec, LINE) are based on a neural architecture,
thus unable to scale on large networks both in terms of time and space usage.
Recently, we proposed BinSketch, a sketching technique for compressing binary
vectors to binary vectors. In this paper, we show how to extend BinSketch and
use it for network hashing. Our proposal named QUINT is built upon BinSketch,
and it embeds nodes of a sparse network onto a low-dimensional space using
simple bi-wise operations. QUINT is the first of its kind that provides
tremendous gain in terms of speed and space usage without compromising much on
the accuracy of the downstream tasks. Extensive experiments are conducted to
compare QUINT with seven state-of-the-art network embedding methods for two end
tasks - link prediction and node classification. We observe huge performance
gain for QUINT in terms of speedup (up to 7000x) and space saving (up to 800x)
due to its bit-wise nature to obtain node embedding. Moreover, QUINT is a
consistent top-performer for both the tasks among the baselines across all the
datasets. Our empirical observations are backed by rigorous theoretical
analysis to justify the effectiveness of QUINT. In particular, we prove that
QUINT retains enough structural information which can be used further to
approximate many topological properties of networks with high confidence.

    

### [[2109.04226] Incentivizing an Unknown Crowd](http://arxiv.org/abs/2109.04226)


  Motivated by the common strategic activities in crowdsourcing labeling, we
study the problem of sequential eliciting information without verification
(EIWV) for workers with a heterogeneous and unknown crowd. We propose a
reinforcement learning-based approach that is effective against a wide range of
settings including potential irrationality and collusion among workers. With
the aid of a costly oracle and the inference method, our approach dynamically
decides the oracle calls and gains robustness even under the presence of
frequent collusion activities. Extensive experiments show the advantage of our
approach. Our results also present the first comprehensive experiments of EIWV
on large-scale real datasets and the first thorough study of the effects of
environmental variables.

    

### [[2109.04228] Coordinate Descent Methods for DC Minimization](http://arxiv.org/abs/2109.04228)


  Difference-of-Convex (DC) minimization, referring to the problem of
minimizing the difference of two convex functions, has been found rich
applications in statistical learning and studied extensively for decades.
However, existing methods are primarily based on multi-stage convex relaxation,
only leading to weak optimality of critical points. This paper proposes a
coordinate descent method for minimizing DC functions based on sequential
nonconvex approximation. Our approach iteratively solves a nonconvex
one-dimensional subproblem globally, and it is guaranteed to converge to a
coordinate-wise stationary point. We prove that this new optimality condition
is always stronger than the critical point condition and the directional point
condition when the objective function is weakly convex. For comparisons, we
also include a naive variant of coordinate descent methods based on sequential
convex approximation in our study. When the objective function satisfies an
additional regularity condition called \emph{sharpness}, coordinate descent
methods with an appropriate initialization converge \emph{linearly} to the
optimal solution set. Also, for many applications of interest, we show that the
nonconvex one-dimensional subproblem can be computed exactly and efficiently
using a breakpoint searching method. We present some discussions and extensions
of our proposed method. Finally, we have conducted extensive experiments on
several statistical learning tasks to show the superiority of our approach.
Keywords: Coordinate Descent, DC Minimization, DC Programming,
Difference-of-Convex Programs, Nonconvex Optimization, Sparse Optimization,
Binary Optimization.

    

### [[2109.04230] A Systematic Approach to Group Fairness in Automated Decision Making](http://arxiv.org/abs/2109.04230)


  While the field of algorithmic fairness has brought forth many ways to
measure and improve the fairness of machine learning models, these findings are
still not widely used in practice. We suspect that one reason for this is that
the field of algorithmic fairness came up with a lot of definitions of
fairness, which are difficult to navigate. The goal of this paper is to provide
data scientists with an accessible introduction to group fairness metrics and
to give some insight into the philosophical reasoning for caring about these
metrics. We will do this by considering in which sense socio-demographic groups
are compared for making a statement on fairness.

    

### [[2109.04235] EEGDnet: Fusing Non-Local and Local Self-Similarity for 1-D EEG Signal Denoising with 2-D Transformer](http://arxiv.org/abs/2109.04235)


  Electroencephalogram (EEG) has shown a useful approach to produce a
brain-computer interface (BCI). One-dimensional (1-D) EEG signal is yet easily
disturbed by certain artifacts (a.k.a. noise) due to the high temporal
resolution. Thus, it is crucial to remove the noise in received EEG signal.
Recently, deep learning-based EEG signal denoising approaches have achieved
impressive performance compared with traditional ones. It is well known that
the characteristics of self-similarity (including non-local and local ones) of
data (e.g., natural images and time-domain signals) are widely leveraged for
denoising. However, existing deep learning-based EEG signal denoising methods
ignore either the non-local self-similarity (e.g., 1-D convolutional neural
network) or local one (e.g., fully connected network and recurrent neural
network). To address this issue, we propose a novel 1-D EEG signal denoising
network with 2-D transformer, namely EEGDnet. Specifically, we comprehensively
take into account the non-local and local self-similarity of EEG signal through
the transformer module. By fusing non-local self-similarity in self-attention
blocks and local self-similarity in feed forward blocks, the negative impact
caused by noises and outliers can be reduced significantly. Extensive
experiments show that, compared with other state-of-the-art models, EEGDnet
achieves much better performance in terms of both quantitative and qualitative
metrics.

    

### [[2109.04236] ECQ$^{\text{x}}$: Explainability-Driven Quantization for Low-Bit and Sparse DNNs](http://arxiv.org/abs/2109.04236)


  The remarkable success of deep neural networks (DNNs) in various applications
is accompanied by a significant increase in network parameters and arithmetic
operations. Such increases in memory and computational demands make deep
learning prohibitive for resource-constrained hardware platforms such as mobile
devices. Recent efforts aim to reduce these overheads, while preserving model
performance as much as possible, and include parameter reduction techniques,
parameter quantization, and lossless compression techniques.
In this chapter, we develop and describe a novel quantization paradigm for
DNNs: Our method leverages concepts of explainable AI (XAI) and concepts of
information theory: Instead of assigning weight values based on their distances
to the quantization clusters, the assignment function additionally considers
weight relevances obtained from Layer-wise Relevance Propagation (LRP) and the
information content of the clusters (entropy optimization). The ultimate goal
is to preserve the most relevant weights in quantization clusters of highest
information content.
Experimental results show that this novel Entropy-Constrained and
XAI-adjusted Quantization (ECQ$^{\text{x}}$) method generates ultra
low-precision (2-5 bit) and simultaneously sparse neural networks while
maintaining or even improving model performance. Due to reduced parameter
precision and high number of zero-elements, the rendered networks are highly
compressible in terms of file size, up to $103\times$ compared to the
full-precision unquantized DNN model. Our approach was evaluated on different
types of models and datasets (including Google Speech Commands and CIFAR-10)
and compared with previous work.

    

### [[2109.04240] MetaXT: Meta Cross-Task Transfer between Disparate Label Spaces](http://arxiv.org/abs/2109.04240)


  Albeit the universal representational power of pre-trained language models,
adapting them onto a specific NLP task still requires a considerably large
amount of labeled data. Effective task fine-tuning meets challenges when only a
few labeled examples are present for the task. In this paper, we aim to the
address of the problem of few shot task learning by exploiting and transferring
from a different task which admits a related but disparate label space.
Specifically, we devise a label transfer network (LTN) to transform the labels
from source task to the target task of interest for training. Both the LTN and
the model for task prediction are learned via a bi-level optimization
framework, which we term as MetaXT. MetaXT offers a principled solution to best
adapt a pre-trained language model to the target task by transferring knowledge
from the source task. Empirical evaluations on cross-task transfer settings for
four NLP tasks, from two different types of label space disparities,
demonstrate the effectiveness of MetaXT, especially when the labeled data in
the target task is limited.

    

### [[2109.04244] Supervised Linear Dimension-Reduction Methods: Review, Extensions, and Comparisons](http://arxiv.org/abs/2109.04244)


  Principal component analysis (PCA) is a well-known linear dimension-reduction
method that has been widely used in data analysis and modeling. It is an
unsupervised learning technique that identifies a suitable linear subspace for
the input variable that contains maximal variation and preserves as much
information as possible. PCA has also been used in prediction models where the
original, high-dimensional space of predictors is reduced to a smaller, more
manageable, set before conducting regression analysis. However, this approach
does not incorporate information in the response during the dimension-reduction
stage and hence can have poor predictive performance. To address this concern,
several supervised linear dimension-reduction techniques have been proposed in
the literature. This paper reviews selected techniques, extends some of them,
and compares their performance through simulations. Two of these techniques,
partial least squares (PLS) and least-squares PCA (LSPCA), consistently
outperform the others in this study.

    

### [[2109.04247] DAE : Discriminatory Auto-Encoder for multivariate time-series anomaly detection in air transportation](http://arxiv.org/abs/2109.04247)


  The Automatic Dependent Surveillance Broadcast protocol is one of the latest
compulsory advances in air surveillance. While it supports the tracking of the
ever-growing number of aircraft in the air, it also introduces cybersecurity
issues that must be mitigated e.g., false data injection attacks where an
attacker emits fake surveillance information. The recent data sources and tools
available to obtain flight tracking records allow the researchers to create
datasets and develop Machine Learning models capable of detecting such
anomalies in En-Route trajectories. In this context, we propose a novel
multivariate anomaly detection model called Discriminatory Auto-Encoder (DAE).
It uses the baseline of a regular LSTM-based auto-encoder but with several
decoders, each getting data of a specific flight phase (e.g. climbing, cruising
or descending) during its this http URL illustrate the DAE's efficiency, an
evaluation dataset was created using real-life anomalies as well as
realistically crafted ones, with which the DAE as well as three anomaly
detection models from the literature were evaluated. Results show that the DAE
achieves better results in both accuracy and speed of detection. The dataset,
the models implementations and the evaluation results are available in an
online repository, thereby enabling replicability and facilitating future
experiments.

    

### [[2109.04253] Dubhe: Towards Data Unbiasedness with Homomorphic Encryption in Federated Learning Client Selection](http://arxiv.org/abs/2109.04253)


  Federated learning (FL) is a distributed machine learning paradigm that
allows clients to collaboratively train a model over their own local data. FL
promises the privacy of clients and its security can be strengthened by
cryptographic methods such as additively homomorphic encryption (HE). However,
the efficiency of FL could seriously suffer from the statistical heterogeneity
in both the data distribution discrepancy among clients and the global
distribution skewness. We mathematically demonstrate the cause of performance
degradation in FL and examine the performance of FL over various datasets. To
tackle the statistical heterogeneity problem, we propose a pluggable
system-level client selection method named Dubhe, which allows clients to
proactively participate in training, meanwhile preserving their privacy with
the assistance of HE. Experimental results show that Dubhe is comparable with
the optimal greedy method on the classification accuracy, with negligible
encryption and communication overhead.

    

### [[2109.04255] Optimal Reservoir Operations using Long Short-Term Memory Network](http://arxiv.org/abs/2109.04255)


  A reliable forecast of inflows to the reservoir is a key factor in the
optimal operation of reservoirs. Real-time operation of the reservoir based on
forecasts of inflows can lead to substantial economic gains. However, the
forecast of inflow is an intricate task as it has to incorporate the impacts of
climate and hydrological changes. Therefore, the major objective of the present
work is to develop a novel approach based on long short-term memory (LSTM) for
the forecast of inflows. Real-time inflow forecast, in other words, daily
inflow at the reservoir helps in efficient operation of water resources. Also,
daily variations in the release can be monitored efficiently and the
reliability of operation is improved. This work proposes a naive anomaly
detection algorithm baseline based on LSTM. In other words, a strong baseline
to forecast flood and drought for any deep learning-based prediction model. The
practicality of the approach has been demonstrated using the observed daily
data of the past 20 years from Bhakra Dam in India. The results of the
simulations conducted herein clearly indicate the supremacy of the LSTM
approach over the traditional methods of forecasting. Although, experiments are
run on data from Bhakra Dam Reservoir in India, LSTM model, and anomaly
detection algorithm are general purpose and can be applied to any basin with
minimal changes. A distinct practical advantage of the LSTM method presented
herein is that it can adequately simulate non-stationarity and non-linearity in
the historical data.

    

### [[2109.04257] GNisi: A graph network for reconstructing Ising models from multivariate binarized data](http://arxiv.org/abs/2109.04257)


  Ising models are a simple generative approach to describing interacting
binary variables. They have proven useful in a number of biological settings
because they enable one to represent observed many-body correlations as the
separable consequence of many direct, pairwise statistical interactions. The
inference of Ising models from data can be computationally very challenging and
often one must be satisfied with numerical approximations or limited precision.
In this paper we present a novel method for the determination of Ising
parameters from data, called GNisi, which uses a Graph Neural network trained
on known Ising models in order to construct the parameters for unseen data. We
show that GNisi is more accurate than the existing state of the art software,
and we illustrate our method by applying GNisi to gene expression data.

    

### [[2109.04260] Online Enhanced Semantic Hashing: Towards Effective and Efficient Retrieval for Streaming Multi-Modal Data](http://arxiv.org/abs/2109.04260)


  With the vigorous development of multimedia equipment and applications,
efficient retrieval of large-scale multi-modal data has become a trendy
research topic. Thereinto, hashing has become a prevalent choice due to its
retrieval efficiency and low storage cost. Although multi-modal hashing has
drawn lots of attention in recent years, there still remain some problems. The
first point is that existing methods are mainly designed in batch mode and not
able to efficiently handle streaming multi-modal data. The second point is that
all existing online multi-modal hashing methods fail to effectively handle
unseen new classes which come continuously with streaming data chunks. In this
paper, we propose a new model, termed Online enhAnced SemantIc haShing (OASIS).
We design novel semantic-enhanced representation for data, which could help
handle the new coming classes, and thereby construct the enhanced semantic
objective function. An efficient and effective discrete online optimization
algorithm is further proposed for OASIS. Extensive experiments show that our
method can exceed the state-of-the-art models. For good reproducibility and
benefiting the community, our code and data are already available in
supplementary material and will be made publicly available.

    

### [[2109.04261] Memory semantization through perturbed and adversarial dreaming](http://arxiv.org/abs/2109.04261)


  Classical theories of memory consolidation emphasize the importance of replay
in extracting semantic information from episodic memories. However, the
characteristic creative nature of dreams suggests that memory semantization may
go beyond merely replaying previous experiences. We propose that
rapid-eye-movement (REM) dreaming is essential for efficient memory
semantization by randomly combining episodic memories to create new, virtual
sensory experiences. We support this hypothesis by implementing a cortical
architecture with hierarchically organized feedforward and feedback pathways,
inspired by generative adversarial networks (GANs). Learning in our model is
organized across three different global brain states mimicking wakefulness,
non-REM (NREM) and REM sleep, optimizing different, but complementary objective
functions. We train the model in an unsupervised fashion on standard datasets
of natural images and evaluate the quality of the learned representations. Our
results suggest that adversarial dreaming during REM sleep is essential for
extracting memory contents, while perturbed dreaming during NREM sleep improves
robustness of the latent representation to noisy sensory inputs. The model
provides a new computational perspective on sleep states, memory replay and
dreams and suggests a cortical implementation of GANs.

    

### [[2109.04266] An objective function for order preserving hierarchical clustering](http://arxiv.org/abs/2109.04266)


  We present an objective function for similarity based hierarchical clustering
of partially ordered data that preserves the partial order in the sense that if
$x \leq y$, and if $[x]$ and $[y]$ are the respective clusters of $x$ and $y$,
then there is an order relation $\leq'$ on the clusters for which $[x] \leq'
|y]$. The model distinguishes itself from existing methods and models for
clustering of ordered data in that the order relation and the similarity are
combined to obtain an optimal hierarchical clustering seeking to satisfy both,
and that the order relation is equipped with a pairwise level of comparability
in the range $[0,1]$. In particular, if the similarity and the order relation
are not aligned, then order preservation may have to yield in favor of
clustering. Finding an optimal solution is NP-hard, so we provide a polynomial
time approximation algorithm, with a relative performance guarantee of
$O(\log^{3/2}n)$, based on successive applications of directed sparsest cut.
The model is an extension of the Dasgupta cost function for divisive
hierarchical clustering.

    

### [[2109.04270] Toward a Perspectivist Turn in Ground Truthing for Predictive Computing](http://arxiv.org/abs/2109.04270)


  Most Artificial Intelligence applications are based on supervised machine
learning (ML), which ultimately grounds on manually annotated data. The
annotation process is often performed in terms of a majority vote and this has
been proved to be often problematic, as highlighted by recent studies on the
evaluation of ML models. In this article we describe and advocate for a
different paradigm, which we call data perspectivism, which moves away from
traditional gold standard datasets, towards the adoption of methods that
integrate the opinions and perspectives of the human subjects involved in the
knowledge representation step of ML processes. Drawing on previous works which
inspired our proposal we describe the potential of our proposal for not only
the more subjective tasks (e.g. those related to human language) but also to
tasks commonly understood as objective (e.g. medical decision making), and
present the main advantages of adopting a perspectivist stance in ML, as well
as possible disadvantages, and various ways in which such a stance can be
implemented in practice. Finally, we share a set of recommendations and outline
a research agenda to advance the perspectivist stance in ML.

    

### [[2109.04282] Cartography Active Learning](http://arxiv.org/abs/2109.04282)


  We propose Cartography Active Learning (CAL), a novel Active Learning (AL)
algorithm that exploits the behavior of the model on individual instances
during training as a proxy to find the most informative instances for labeling.
CAL is inspired by data maps, which were recently proposed to derive insights
into dataset quality (Swayamdipta et al., 2020). We compare our method on
popular text classification tasks to commonly used AL strategies, which instead
rely on post-training behavior. We demonstrate that CAL is competitive to other
common AL methods, showing that training dynamics derived from small seed data
can be successfully used for AL. We provide insights into our new AL method by
analyzing batch-level statistics utilizing the data maps. Our results further
show that CAL results in a more data-efficient learning strategy, achieving
comparable or better results with considerably less training data.

    

### [[2109.04284] Towards Robust Cross-domain Image Understanding with Unsupervised Noise Removal](http://arxiv.org/abs/2109.04284)


  Deep learning models usually require a large amount of labeled data to
achieve satisfactory performance. In multimedia analysis, domain adaptation
studies the problem of cross-domain knowledge transfer from a label rich source
domain to a label scarce target domain, thus potentially alleviates the
annotation requirement for deep learning models. However, we find that
contemporary domain adaptation methods for cross-domain image understanding
perform poorly when source domain is noisy. Weakly Supervised Domain Adaptation
(WSDA) studies the domain adaptation problem under the scenario where source
data can be noisy. Prior methods on WSDA remove noisy source data and align the
marginal distribution across domains without considering the fine-grained
semantic structure in the embedding space, which have the problem of class
misalignment, e.g., features of cats in the target domain might be mapped near
features of dogs in the source domain. In this paper, we propose a novel
method, termed Noise Tolerant Domain Adaptation, for WSDA. Specifically, we
adopt the cluster assumption and learn cluster discriminatively with class
prototypes in the embedding space. We propose to leverage the location
information of the data points in the embedding space and model the location
information with a Gaussian mixture model to identify noisy source data. We
then design a network which incorporates the Gaussian mixture noise model as a
sub-module for unsupervised noise removal and propose a novel cluster-level
adversarial adaptation method which aligns unlabeled target data with the less
noisy class prototypes for mapping the semantic structure across domains. We
conduct extensive experiments to evaluate the effectiveness of our method on
both general images and medical images from COVID-19 and e-commerce datasets.
The results show that our method significantly outperforms state-of-the-art
WSDA methods.

    

### [[2109.04286] NTS-NOTEARS: Learning Nonparametric Temporal DAGs With Time-Series Data and Prior Knowledge](http://arxiv.org/abs/2109.04286)


  We propose a score-based DAG structure learning method for time-series data
that captures linear, nonlinear, lagged and instantaneous relations among
variables while ensuring acyclicity throughout the entire graph. The proposed
method extends nonparametric NOTEARS, a recent continuous optimization approach
for learning nonparametric instantaneous DAGs. The proposed method is faster
than constraint-based methods using nonlinear conditional independence tests.
We also promote the use of optimization constraints to incorporate prior
knowledge into the structure learning process. A broad set of experiments with
simulated data demonstrates that the proposed method discovers better DAG
structures than several recent comparison methods. We also evaluate the
proposed method on complex real-world data acquired from NHL ice hockey games
containing a mixture of continuous and discrete variables. The code is
available at this https URL.

    

### [[2109.04298] Quantum Machine Learning for Finance](http://arxiv.org/abs/2109.04298)


  Quantum computers are expected to surpass the computational capabilities of
classical computers during this decade, and achieve disruptive impact on
numerous industry sectors, particularly finance. In fact, finance is estimated
to be the first industry sector to benefit from Quantum Computing not only in
the medium and long terms, but even in the short term. This review paper
presents the state of the art of quantum algorithms for financial applications,
with particular focus to those use cases that can be solved via Machine
Learning.

    

### [[2109.04300] Energy Attack: On Transferring Adversarial Examples](http://arxiv.org/abs/2109.04300)


  In this work we propose Energy Attack, a transfer-based black-box
$L_\infty$-adversarial attack. The attack is parameter-free and does not
require gradient approximation. In particular, we first obtain white-box
adversarial perturbations of a surrogate model and divide these perturbations
into small patches. Then we extract the unit component vectors and eigenvalues
of these patches with principal component analysis (PCA). Base on the
eigenvalues, we can model the energy distribution of adversarial perturbations.
We then perform black-box attacks by sampling from the perturbation patches
according to their energy distribution, and tiling the sampled patches to form
a full-size adversarial perturbation. This can be done without the available
access to victim models. Extensive experiments well demonstrate that the
proposed Energy Attack achieves state-of-the-art performance in black-box
attacks on various models and several datasets. Moreover, the extracted
distribution is able to transfer among different model architectures and
different datasets, and is therefore intrinsic to vision architectures.

    

### [[2109.04301] On the use of Wasserstein metric in topological clustering of distributional data](http://arxiv.org/abs/2109.04301)


  This paper deals with a clustering algorithm for histogram data based on a
Self-Organizing Map (SOM) learning. It combines a dimension reduction by SOM
and the clustering of the data in a reduced space. Related to the kind of data,
a suitable dissimilarity measure between distributions is introduced: the $L_2$
Wasserstein distance. Moreover, the number of clusters is not fixed in advance
but it is automatically found according to a local data density estimation in
the original space. Applications on synthetic and real data sets corroborate
the proposed strategy.

    

### [[2109.04304] DAE-PINN: A Physics-Informed Neural Network Model for Simulating Differential-Algebraic Equations with Application to Power Networks](http://arxiv.org/abs/2109.04304)


  Deep learning-based surrogate modeling is becoming a promising approach for
learning and simulating dynamical systems. Deep-learning methods, however, find
very challenging learning stiff dynamics. In this paper, we develop DAE-PINN,
the first effective deep-learning framework for learning and simulating the
solution trajectories of nonlinear differential-algebraic equations (DAE),
which present a form of infinite stiffness and describe, for example, the
dynamics of power networks. Our DAE-PINN bases its effectiveness on the synergy
between implicit Runge-Kutta time-stepping schemes (designed specifically for
solving DAEs) and physics-informed neural networks (PINN) (deep neural networks
that we train to satisfy the dynamics of the underlying problem). Furthermore,
our framework (i) enforces the neural network to satisfy the DAEs as
(approximate) hard constraints using a penalty-based method and (ii) enables
simulating DAEs for long-time horizons. We showcase the effectiveness and
accuracy of DAE-PINN by learning and simulating the solution trajectories of a
three-bus power network.

    

### [[2109.04306] Social Media Monitoring for IoT Cyber-Threats](http://arxiv.org/abs/2109.04306)


  The rapid development of IoT applications and their use in various fields of
everyday life has resulted in an escalated number of different possible
cyber-threats, and has consequently raised the need of securing IoT devices.
Collecting Cyber-Threat Intelligence (e.g., zero-day vulnerabilities or
trending exploits) from various online sources and utilizing it to proactively
secure IoT systems or prepare mitigation scenarios has proven to be a promising
direction. In this work, we focus on social media monitoring and investigate
real-time Cyber-Threat Intelligence detection from the Twitter stream.
Initially, we compare and extensively evaluate six different machine-learning
based classification alternatives trained with vulnerability descriptions and
tested with real-world data from the Twitter stream to identify the
best-fitting solution. Subsequently, based on our findings, we propose a novel
social media monitoring system tailored to the IoT domain; the system allows
users to identify recent/trending vulnerabilities and exploits on IoT devices.
Finally, to aid research on the field and support the reproducibility of our
results we publicly release all annotated datasets created during this process.

    

### [[2109.04307] OPIRL: Sample Efficient Off-Policy Inverse Reinforcement Learning via Distribution Matching](http://arxiv.org/abs/2109.04307)


  Inverse Reinforcement Learning (IRL) is attractive in scenarios where reward
engineering can be tedious. However, prior IRL algorithms use on-policy
transitions, which require intensive sampling from the current policy for
stable and optimal performance. This limits IRL applications in the real world,
where environment interactions can become highly expensive. To tackle this
problem, we present Off-Policy Inverse Reinforcement Learning (OPIRL), which
(1) adopts off-policy data distribution instead of on-policy and enables
significant reduction of the number of interactions with the environment, (2)
learns a stationary reward function that is transferable with high
generalization capabilities on changing dynamics, and (3) leverages
mode-covering behavior for faster convergence. We demonstrate that our method
is considerably more sample efficient and generalizes to novel environments
through the experiments. Our method achieves better or comparable results on
policy performance baselines with significantly fewer interactions.
Furthermore, we empirically show that the recovered reward function generalizes
to different tasks where prior arts are prone to fail.

    

### [[2109.04312] MATE: Multi-view Attention for Table Transformer Efficiency](http://arxiv.org/abs/2109.04312)


  This work presents a sparse-attention Transformer architecture for modeling
documents that contain large tables. Tables are ubiquitous on the web, and are
rich in information. However, more than 20% of relational tables on the web
have 20 or more rows (Cafarella et al., 2008), and these large tables present a
challenge for current Transformer models, which are typically limited to 512
tokens. Here we propose MATE, a novel Transformer architecture designed to
model the structure of web tables. MATE uses sparse attention in a way that
allows heads to efficiently attend to either rows or columns in a table. This
architecture scales linearly with respect to speed and memory, and can handle
documents containing more than 8000 tokens with current accelerators. MATE also
has a more appropriate inductive bias for tabular data, and sets a new
state-of-the-art for three table reasoning datasets. For HybridQA (Chen et al.,
2020b), a dataset that involves large documents containing tables, we improve
the best prior result by 19 points.

    

### [[2109.04316] Accounting for Variations in Speech Emotion Recognition with Nonparametric Hierarchical Neural Network](http://arxiv.org/abs/2109.04316)


  In recent years, deep-learning-based speech emotion recognition models have
outperformed classical machine learning models. Previously, neural network
designs, such as Multitask Learning, have accounted for variations in emotional
expressions due to demographic and contextual factors. However, existing models
face a few constraints: 1) they rely on a clear definition of domains (e.g.
gender, noise condition, etc.) and the availability of domain labels; 2) they
often attempt to learn domain-invariant features while emotion expressions can
be domain-specific. In the present study, we propose the Nonparametric
Hierarchical Neural Network (NHNN), a lightweight hierarchical neural network
model based on Bayesian nonparametric clustering. In comparison to Multitask
Learning approaches, the proposed model does not require domain/task labels. In
our experiments, the NHNN models generally outperform the models with similar
levels of complexity and state-of-the-art models in within-corpus and
cross-corpus tests. Through clustering analysis, we show that the NHNN models
are able to learn group-specific features and bridge the performance gap
between groups.

    

### [[2109.04318] Estimation of Corporate Greenhouse Gas Emissions via Machine Learning](http://arxiv.org/abs/2109.04318)


  As an important step to fulfill the Paris Agreement and achieve net-zero
emissions by 2050, the European Commission adopted the most ambitious package
of climate impact measures in April 2021 to improve the flow of capital towards
sustainable activities. For these and other international measures to be
successful, reliable data is key. The ability to see the carbon footprint of
companies around the world will be critical for investors to comply with the
measures. However, with only a small portion of companies volunteering to
disclose their greenhouse gas (GHG) emissions, it is nearly impossible for
investors to align their investment strategies with the measures. By training a
machine learning model on disclosed GHG emissions, we are able to estimate the
emissions of other companies globally who do not disclose their emissions. In
this paper, we show that our model provides accurate estimates of corporate GHG
emissions to investors such that they are able to align their investments with
the regulatory measures and achieve net-zero goals.

    

### [[2109.04319] Translate & Fill: Improving Zero-Shot Multilingual Semantic Parsing with Synthetic Data](http://arxiv.org/abs/2109.04319)


  While multilingual pretrained language models (LMs) fine-tuned on a single
language have shown substantial cross-lingual task transfer capabilities, there
is still a wide performance gap in semantic parsing tasks when target language
supervision is available. In this paper, we propose a novel Translate-and-Fill
(TaF) method to produce silver training data for a multilingual semantic
parser. This method simplifies the popular Translate-Align-Project (TAP)
pipeline and consists of a sequence-to-sequence filler model that constructs a
full parse conditioned on an utterance and a view of the same parse. Our filler
is trained on English data only but can accurately complete instances in other
languages (i.e., translations of the English training utterances), in a
zero-shot fashion. Experimental results on three multilingual semantic parsing
datasets show that data augmentation with TaF reaches accuracies competitive
with similar systems which rely on traditional alignment techniques.

    

### [[2109.04320] COLUMBUS: Automated Discovery of New Multi-Level Features for Domain Generalization via Knowledge Corruption](http://arxiv.org/abs/2109.04320)


  Machine learning models that can generalize to unseen domains are essential
when applied in real-world scenarios involving strong domain shifts. We address
the challenging domain generalization (DG) problem, where a model trained on a
set of source domains is expected to generalize well in unseen domains without
any exposure to their data. The main challenge of DG is that the features
learned from the source domains are not necessarily present in the unseen
target domains, leading to performance deterioration. We assume that learning a
richer set of features is crucial to improve the transfer to a wider set of
unknown domains. For this reason, we propose COLUMBUS, a method that enforces
new feature discovery via a targeted corruption of the most relevant input and
multi-level representations of the data. We conduct an extensive empirical
evaluation to demonstrate the effectiveness of the proposed approach which
achieves new state-of-the-art results by outperforming 18 DG algorithms on
multiple DG benchmark datasets in the DomainBed framework.

    

### [[2109.04323] Adaptive importance sampling for seismic fragility curve estimation](http://arxiv.org/abs/2109.04323)


  As part of Probabilistic Risk Assessment studies, it is necessary to study
the fragility of mechanical and civil engineered structures when subjected to
seismic loads. This risk can be measured with fragility curves, which express
the probability of failure of the structure conditionally to a seismic
intensity measure. The estimation of fragility curves relies on time-consuming
numerical simulations, so that careful experimental design is required in order
to gain the maximum information on the structure's fragility with a limited
number of code evaluations. We propose and implement an active learning
methodology based on adaptive importance sampling in order to reduce the
variance of the training loss. The efficiency of the proposed method in terms
of bias, standard deviation and prediction interval coverage are theoretically
and numerically characterized.

    

### [[2109.04325] Learning Opinion Summarizers by Selecting Informative Reviews](http://arxiv.org/abs/2109.04325)


  Opinion summarization has been traditionally approached with unsupervised,
weakly-supervised and few-shot learning techniques. In this work, we collect a
large dataset of summaries paired with user reviews for over 31,000 products,
enabling supervised training. However, the number of reviews per product is
large (320 on average), making summarization - and especially training a
summarizer - impractical. Moreover, the content of many reviews is not
reflected in the human-written summaries, and, thus, the summarizer trained on
random review subsets hallucinates. In order to deal with both of these
challenges, we formulate the task as jointly learning to select informative
subsets of reviews and summarizing the opinions expressed in these subsets. The
choice of the review subset is treated as a latent variable, predicted by a
small and simple selector. The subset is then fed into a more powerful
summarizer. For joint training, we use amortized variational inference and
policy gradient methods. Our experiments demonstrate the importance of
selecting informative reviews resulting in improved quality of summaries and
reduced hallucinations.

    

### [[2109.04335] UCTransNet: Rethinking the Skip Connections in U-Net from a Channel-wise Perspective with Transformer](http://arxiv.org/abs/2109.04335)


  Most recent semantic segmentation methods adopt a U-Net framework with an
encoder-decoder architecture. It is still challenging for U-Net with a simple
skip connection scheme to model the global multi-scale context: 1) Not each
skip connection setting is effective due to the issue of incompatible feature
sets of encoder and decoder stage, even some skip connection negatively
influence the segmentation performance; 2) The original U-Net is worse than the
one without any skip connection on some datasets. Based on our findings, we
propose a new segmentation framework, named UCTransNet (with a proposed CTrans
module in U-Net), from the channel perspective with attention mechanism.
Specifically, the CTrans module is an alternate of the U-Net skip connections,
which consists of a sub-module to conduct the multi-scale Channel Cross fusion
with Transformer (named CCT) and a sub-module Channel-wise Cross-Attention
(named CCA) to guide the fused multi-scale channel-wise information to
effectively connect to the decoder features for eliminating the ambiguity.
Hence, the proposed connection consisting of the CCT and CCA is able to replace
the original skip connection to solve the semantic gaps for an accurate
automatic medical image segmentation. The experimental results suggest that our
UCTransNet produces more precise segmentation performance and achieves
consistent improvements over the state-of-the-art for semantic segmentation
across different datasets and conventional architectures involving transformer
or U-shaped framework. Code: this https URL.

    

### [[2109.04351] NeuralFMU: Towards Structural Integration of FMUs into Neural Networks](http://arxiv.org/abs/2109.04351)


  This paper covers two major subjects: First, the presentation of a new
open-source library called FMI.jl for integrating FMI into the Julia
programming environment by providing the possibility to load, parameterize and
simulate FMUs. Further, an extension to this library called FMIFlux.jl is
introduced, that allows the integration of FMUs into a neural network topology
to obtain a NeuralFMU. This structural combination of an industry typical
black-box model and a data-driven machine learning model combines the different
advantages of both modeling approaches in one single development environment.
This allows for the usage of advanced data driven modeling techniques for
physical effects that are difficult to model based on first principles.

    

### [[2109.04352] PhysGNN: A Physics-Driven Graph Neural Network Based Model for Predicting Soft Tissue Deformation in Image-Guided Neurosurgery](http://arxiv.org/abs/2109.04352)


  Correctly capturing intraoperative brain shift in image-guided neurosurgical
procedures is a critical task for aligning preoperative data with
intraoperative geometry, ensuring effective surgical navigation and optimal
surgical precision. While the finite element method (FEM) is a proven technique
to effectively approximate soft tissue deformation through biomechanical
formulations, their degree of success boils down to a trade-off between
accuracy and speed. To circumvent this problem, the most recent works in this
domain have proposed leveraging data-driven models obtained by training various
machine learning algorithms, e.g. random forests, artificial neural networks
(ANNs), with the results of finite element analysis (FEA) to speed up tissue
deformation approximations by prediction. These methods, however, do not
account for the structure of the finite element (FE) mesh during training that
provides information on node connectivities as well as the distance between
them, which can aid with approximating tissue deformation based on the
proximity of force load points with the rest of the mesh nodes. Therefore, this
work proposes a novel framework, PhysGNN, a data-driven model that approximates
the solution of FEA by leveraging graph neural networks (GNNs), which are
capable of accounting for the mesh structural information and inductive
learning over unstructured grids and complex topological structures.
Empirically, we demonstrate that the proposed architecture, PhysGNN, promises
accurate and fast soft tissue deformation approximations while remaining
computationally feasible, suitable for neurosurgical settings.

    

### [[2109.04353] Cross DQN: Cross Deep Q Network for Ads Allocation in Feed](http://arxiv.org/abs/2109.04353)


  E-commerce platforms usually display a mixed list of ads and organic items in
feed. One key problem is to allocate the limited slots in the feed to maximize
the overall revenue as well as improve user experience, which requires a good
model for user preference. Instead of modeling the influence of individual
items on user behaviors, the arrangement signal models the influence of the
arrangement of items and may lead to a better allocation strategy. However,
most of previous strategies fail to model such a signal and therefore result in
suboptimal performance. To this end, we propose Cross Deep Q Network (Cross
DQN) to extract the arrangement signal by crossing the embeddings of different
items and processing the crossed sequence in the feed. Our model results in
higher revenue and better user experience than state-of-the-art baselines in
offline experiments. Moreover, our model demonstrates a significant improvement
in the online A/B test and has been fully deployed on Meituan feed to serve
more than 300 millions of customers.

    

### [[2109.04356] Assessing Machine Learning Approaches to Address IoT Sensor Drift](http://arxiv.org/abs/2109.04356)


  The proliferation of IoT sensors and their deployment in various industries
and applications has brought about numerous analysis opportunities in this Big
Data era. However, drift of those sensor measurements poses major challenges to
automate data analysis and the ability to effectively train and deploy models
on a continuous basis. In this paper we study and test several approaches from
the literature with regard to their ability to cope with and adapt to sensor
drift under realistic conditions. Most of these approaches are recent and thus
are representative of the current state-of-the-art. The testing was performed
on a publicly available gas sensor dataset exhibiting drift over time. The
results show substantial drops in sensing performance due to sensor drift in
spite of the approaches. We then discuss several issues identified with current
approaches and outline directions for future research to tackle them.

    

### [[2109.04361] MutualGraphNet: A novel model for motor imagery classification](http://arxiv.org/abs/2109.04361)


  Motor imagery classification is of great significance to humans with mobility
impairments, and how to extract and utilize the effective features from motor
imagery electroencephalogram(EEG) channels has always been the focus of
attention. There are many different methods for the motor imagery
classification, but the limited understanding on human brain requires more
effective methods for extracting the features of EEG data. Graph neural
networks(GNNs) have demonstrated its effectiveness in classifying graph
structures; and the use of GNN provides new possibilities for brain structure
connection feature extraction. In this paper we propose a novel graph neural
network based on the mutual information of the raw EEG channels called
MutualGraphNet. We use the mutual information as the adjacency matrix combined
with the spatial temporal graph convolution network(ST-GCN) could extract the
transition rules of the motor imagery electroencephalogram(EEG) channels data
more effectively. Experiments are conducted on motor imagery EEG data set and
we compare our model with the current state-of-the-art approaches and the
results suggest that MutualGraphNet is robust enough to learn the interpretable
features and outperforms the current state-of-the-art methods.

    

### [[2109.04364] Detection of Epileptic Seizures on EEG Signals Using ANFIS Classifier, Autoencoders and Fuzzy Entropies](http://arxiv.org/abs/2109.04364)


  Epilepsy is one of the most crucial neurological disorders, and its early
diagnosis will help the clinicians to provide accurate treatment for the
patients. The electroencephalogram (EEG) signals are widely used for epileptic
seizures detection, which provides specialists with substantial information
about the functioning of the brain. In this paper, a novel diagnostic procedure
using fuzzy theory and deep learning techniques are introduced. The proposed
method is evaluated on the Bonn University dataset with six classification
combinations and also on the Freiburg dataset. The tunable-Q wavelet transform
(TQWT) is employed to decompose the EEG signals into different sub-bands. In
the feature extraction step, 13 different fuzzy entropies are calculated from
different sub-bands of TQWT, and their computational complexities are
calculated to help researchers choose the best feature sets. In the following,
an autoencoder (AE) with six layers is employed for dimensionality reduction.
Finally, the standard adaptive neuro-fuzzy inference system (ANFIS), and also
its variants with grasshopper optimization algorithm (ANFIS-GOA), particle
swarm optimization (ANFIS-PSO), and breeding swarm optimization (ANFIS-BS)
methods are used for classification. Using our proposed method, ANFIS-BS method
has obtained an accuracy of 99.74% in classifying into two classes and an
accuracy of 99.46% in ternary classification on the Bonn dataset and 99.28% on
the Freiburg dataset, reaching state-of-the-art performances on both of them.

    

### [[2109.04367] Multi-granularity Textual Adversarial Attack with Behavior Cloning](http://arxiv.org/abs/2109.04367)


  Recently, the textual adversarial attack models become increasingly popular
due to their successful in estimating the robustness of NLP models. However,
existing works have obvious deficiencies. (1) They usually consider only a
single granularity of modification strategies (e.g. word-level or
sentence-level), which is insufficient to explore the holistic textual space
for generation; (2) They need to query victim models hundreds of times to make
a successful attack, which is highly inefficient in practice. To address such
problems, in this paper we propose MAYA, a Multi-grAnularitY Attack model to
effectively generate high-quality adversarial samples with fewer queries to
victim models. Furthermore, we propose a reinforcement-learning based method to
train a multi-granularity attack agent through behavior cloning with the expert
knowledge from our MAYA algorithm to further reduce the query times.
Additionally, we also adapt the agent to attack black-box models that only
output labels without confidence scores. We conduct comprehensive experiments
to evaluate our attack models by attacking BiLSTM, BERT and RoBERTa in two
different black-box attack settings and three benchmark datasets. Experimental
results show that our models achieve overall better attacking performance and
produce more fluent and grammatical adversarial samples compared to baseline
models. Besides, our adversarial attack agent significantly reduces the query
times in both attack settings. Our codes are released at
this https URL.

    

### [[2109.04378] Dynamic Modeling of Hand-Object Interactions via Tactile Sensing](http://arxiv.org/abs/2109.04378)


  Tactile sensing is critical for humans to perform everyday tasks. While
significant progress has been made in analyzing object grasping from vision, it
remains unclear how we can utilize tactile sensing to reason about and model
the dynamics of hand-object interactions. In this work, we employ a
high-resolution tactile glove to perform four different interactive activities
on a diversified set of objects. We build our model on a cross-modal learning
framework and generate the labels using a visual processing pipeline to
supervise the tactile model, which can then be used on its own during the test
time. The tactile model aims to predict the 3d locations of both the hand and
the object purely from the touch data by combining a predictive model and a
contrastive learning module. This framework can reason about the interaction
patterns from the tactile data, hallucinate the changes in the environment,
estimate the uncertainty of the prediction, and generalize to unseen objects.
We also provide detailed ablation studies regarding different system designs as
well as visualizations of the predicted trajectories. This work takes a step on
dynamics modeling in hand-object interactions from dense tactile sensing, which
opens the door for future applications in activity learning, human-computer
interactions, and imitation learning for robotics.

    

### [[2109.04386] ErfAct: Non-monotonic smooth trainable Activation Functions](http://arxiv.org/abs/2109.04386)


  An activation function is a crucial component of a neural network that
introduces non-linearity in the network. The state-of-the-art performance of a
neural network depends on the perfect choice of an activation function. We
propose two novel non-monotonic smooth trainable activation functions, called
ErfAct-1 and ErfAct-2. Experiments suggest that the proposed functions improve
the network performance significantly compared to the widely used activations
like ReLU, Swish, and Mish. Replacing ReLU by ErfAct-1 and ErfAct-2, we have
5.21% and 5.04% improvement for top-1 accuracy on PreactResNet-34 network in
CIFAR100 dataset, 2.58% and 2.76% improvement for top-1 accuracy on
PreactResNet-34 network in CIFAR10 dataset, 1.0%, and 1.0% improvement on mean
average precision (mAP) on SSD300 model in Pascal VOC dataset.

    

### [[2109.04392] Fair Conformal Predictors for Applications in Medical Imaging](http://arxiv.org/abs/2109.04392)


  Deep learning has the potential to augment many components of the clinical
workflow, such as medical image interpretation. However, the translation of
these black box algorithms into clinical practice has been marred by the
relative lack of transparency compared to conventional machine learning
methods, hindering in clinician trust in the systems for critical medical
decision-making. Specifically, common deep learning approaches do not have
intuitive ways of expressing uncertainty with respect to cases that might
require further human review. Furthermore, the possibility of algorithmic bias
has caused hesitancy regarding the use of developed algorithms in clinical
settings. To these ends, we explore how conformal methods can complement deep
learning models by providing both clinically intuitive way (by means of
confidence prediction sets) of expressing model uncertainty as well as
facilitating model transparency in clinical workflows. In this paper, we
conduct a field survey with clinicians to assess clinical use-cases of
conformal predictions. Next, we conduct experiments with a mammographic breast
density and dermatology photography datasets to demonstrate the utility of
conformal predictions in "rule-in" and "rule-out" disease scenarios. Further,
we show that conformal predictors can be used to equalize coverage with respect
to patient demographics such as race and skin tone. We find that a conformal
predictions to be a promising framework with potential to increase clinical
usability and transparency for better collaboration between deep learning
algorithms and clinicians.

    

### [[2109.04399] Gradual (In)Compatibility of Fairness Criteria](http://arxiv.org/abs/2109.04399)


  Impossibility results show that important fairness measures (independence,
separation, sufficiency) cannot be satisfied at the same time under reasonable
assumptions. This paper explores whether we can satisfy and/or improve these
fairness measures simultaneously to a certain degree. We introduce
information-theoretic formulations of the fairness measures and define degrees
of fairness based on these formulations. The information-theoretic formulations
suggest unexplored theoretical relations between the three fairness measures.
In the experimental part, we use the information-theoretic expressions as
regularizers to obtain fairness-regularized predictors for three standard
datasets. Our experiments show that a) fairness regularization directly
increases fairness measures, in line with existing work, and b) some fairness
regularizations indirectly increase other fairness measures, as suggested by
our theoretical findings. This establishes that it is possible to increase the
degree to which some fairness measures are satisfied at the same time -- some
fairness measures are gradually compatible.

    

### [[2109.04400] Cross-lingual Transfer for Text Classification with Dictionary-based Heterogeneous Graph](http://arxiv.org/abs/2109.04400)


  In cross-lingual text classification, it is required that task-specific
training data in high-resource source languages are available, where the task
is identical to that of a low-resource target language. However, collecting
such training data can be infeasible because of the labeling cost, task
characteristics, and privacy concerns. This paper proposes an alternative
solution that uses only task-independent word embeddings of high-resource
languages and bilingual dictionaries. First, we construct a dictionary-based
heterogeneous graph (DHG) from bilingual dictionaries. This opens the
possibility to use graph neural networks for cross-lingual transfer. The
remaining challenge is the heterogeneity of DHG because multiple languages are
considered. To address this challenge, we propose dictionary-based
heterogeneous graph neural network (DHGNet) that effectively handles the
heterogeneity of DHG by two-step aggregations, which are word-level and
language-level aggregations. Experimental results demonstrate that our method
outperforms pretrained models even though it does not access to large corpora.
Furthermore, it can perform well even though dictionaries contain many
incorrect translations. Its robustness allows the usage of a wider range of
dictionaries such as an automatically constructed dictionary and crowdsourced
dictionary, which are convenient for real-world applications.

    

### [[2109.04404] All Bark and No Bite: Rogue Dimensions in Transformer Language Models Obscure Representational Quality](http://arxiv.org/abs/2109.04404)


  Similarity measures are a vital tool for understanding how language models
represent and process language. Standard representational similarity measures
such as cosine similarity and Euclidean distance have been successfully used in
static word embedding models to understand how words cluster in semantic space.
Recently, these measures have been applied to embeddings from contextualized
models such as BERT and GPT-2. In this work, we call into question the
informativity of such measures for contextualized language models. We find that
a small number of rogue dimensions, often just 1-3, dominate these measures.
Moreover, we find a striking mismatch between the dimensions that dominate
similarity measures and those which are important to the behavior of the model.
We show that simple postprocessing techniques such as standardization are able
to correct for rogue dimensions and reveal underlying representational quality.
We argue that accounting for rogue dimensions is essential for any
similarity-based analysis of contextual language models.

    

### [[2109.04408] Learning from Uneven Training Data: Unlabeled, Single Label, and Multiple Labels](http://arxiv.org/abs/2109.04408)


  Training NLP systems typically assumes access to annotated data that has a
single human label per example. Given imperfect labeling from annotators and
inherent ambiguity of language, we hypothesize that single label is not
sufficient to learn the spectrum of language interpretation. We explore new
label annotation distribution schemes, assigning multiple labels per example
for a small subset of training examples. Introducing such multi label examples
at the cost of annotating fewer examples brings clear gains on natural language
inference task and entity typing task, even when we simply first train with a
single label data and then fine tune with multi label examples. Extending a
MixUp data augmentation framework, we propose a learning algorithm that can
learn from uneven training examples (with zero, one, or multiple labels). This
algorithm efficiently combines signals from uneven training data and brings
additional gains in low annotation budget and cross domain settings. Together,
our method achieves consistent gains in both accuracy and label distribution
metrics in two tasks, suggesting training with uneven training data can be
beneficial for many NLP tasks.

    

### [[2109.04432] Detecting and Mitigating Test-time Failure Risks via Model-agnostic Uncertainty Learning](http://arxiv.org/abs/2109.04432)


  Reliably predicting potential failure risks of machine learning (ML) systems
when deployed with production data is a crucial aspect of trustworthy AI. This
paper introduces Risk Advisor, a novel post-hoc meta-learner for estimating
failure risks and predictive uncertainties of any already-trained black-box
classification model. In addition to providing a risk score, the Risk Advisor
decomposes the uncertainty estimates into aleatoric and epistemic uncertainty
components, thus giving informative insights into the sources of uncertainty
inducing the failures. Consequently, Risk Advisor can distinguish between
failures caused by data variability, data shifts and model limitations and
advise on mitigation actions (e.g., collecting more data to counter data
shift). Extensive experiments on various families of black-box classification
models and on real-world and synthetic datasets covering common ML failure
scenarios show that the Risk Advisor reliably predicts deployment-time failure
risks in all the scenarios, and outperforms strong baselines.

    

### [[2109.04433] Extreme Bandits using Robust Statistics](http://arxiv.org/abs/2109.04433)


  We consider a multi-armed bandit problem motivated by situations where only
the extreme values, as opposed to expected values in the classical bandit
setting, are of interest. We propose distribution free algorithms using robust
statistics and characterize the statistical properties. We show that the
provided algorithms achieve vanishing extremal regret under weaker conditions
than existing algorithms. Performance of the algorithms is demonstrated for the
finite-sample setting using numerical experiments. The results show superior
performance of the proposed algorithms compared to the well known algorithms.

    

### [[2109.04442] fGOT: Graph Distances based on Filters and Optimal Transport](http://arxiv.org/abs/2109.04442)


  Graph comparison deals with identifying similarities and dissimilarities
between graphs. A major obstacle is the unknown alignment of graphs, as well as
the lack of accurate and inexpensive comparison metrics. In this work we
introduce the filter graph distance. It is an optimal transport based distance
which drives graph comparison through the probability distribution of filtered
graph signals. This creates a highly flexible distance, capable of prioritising
different spectral information in observed graphs, offering a wide range of
choices for a comparison metric. We tackle the problem of graph alignment by
computing graph permutations that minimise our new filter distances, which
implicitly solves the graph comparison problem. We then propose a new
approximate cost function that circumvents many computational difficulties
inherent to graph comparison and permits the exploitation of fast algorithms
such as mirror gradient descent, without grossly sacrificing the performance.
We finally propose a novel algorithm derived from a stochastic version of
mirror gradient descent, which accommodates the non-convexity of the alignment
problem, offering a good trade-off between performance accuracy and speed. The
experiments on graph alignment and classification show that the flexibility
gained through filter graph distances can have a significant impact on
performance, while the difference in speed offered by the approximation cost
makes the framework applicable in practical settings.

    

### [[2109.04443] HintedBT: Augmenting Back-Translation with Quality and Transliteration Hints](http://arxiv.org/abs/2109.04443)


  Back-translation (BT) of target monolingual corpora is a widely used data
augmentation strategy for neural machine translation (NMT), especially for
low-resource language pairs. To improve effectiveness of the available BT data,
we introduce HintedBT -- a family of techniques which provides hints (through
tags) to the encoder and decoder. First, we propose a novel method of using
both high and low quality BT data by providing hints (as source tags on the
encoder) to the model about the quality of each source-target pair. We don't
filter out low quality data but instead show that these hints enable the model
to learn effectively from noisy data. Second, we address the problem of
predicting whether a source token needs to be translated or transliterated to
the target language, which is common in cross-script translation tasks (i.e.,
where source and target do not share the written script). For such cases, we
propose training the model with additional hints (as target tags on the
decoder) that provide information about the operation required on the source
(translation or both translation and transliteration). We conduct experiments
and detailed analyses on standard WMT benchmarks for three cross-script
low/medium-resource language pairs: {Hindi,Gujarati,Tamil}-to-English. Our
methods compare favorably with five strong and well established baselines. We
show that using these hints, both separately and together, significantly
improves translation quality and leads to state-of-the-art performance in all
three language pairs in corresponding bilingual settings.

    

### [[2109.04447] Modeling Massive Spatial Datasets Using a Conjugate Bayesian Linear Regression Framework](http://arxiv.org/abs/2109.04447)


  Geographic Information Systems (GIS) and related technologies have generated
substantial interest among statisticians with regard to scalable methodologies
for analyzing large spatial datasets. A variety of scalable spatial process
models have been proposed that can be easily embedded within a hierarchical
modeling framework to carry out Bayesian inference. While the focus of
statistical research has mostly been directed toward innovative and more
complex model development, relatively limited attention has been accorded to
approaches for easily implementable scalable hierarchical models for the
practicing scientist or spatial analyst. This article discusses how
point-referenced spatial process models can be cast as a conjugate Bayesian
linear regression that can rapidly deliver inference on spatial processes. The
approach allows exact sampling directly (avoids iterative algorithms such as
Markov chain Monte Carlo) from the joint posterior distribution of regression
parameters, the latent process and the predictive random variables, and can be
easily implemented on statistical programming environments such as R.

    

### [[2109.04456] NEAT: Neural Attention Fields for End-to-End Autonomous Driving](http://arxiv.org/abs/2109.04456)


  Efficient reasoning about the semantic, spatial, and temporal structure of a
scene is a crucial prerequisite for autonomous driving. We present NEural
ATtention fields (NEAT), a novel representation that enables such reasoning for
end-to-end imitation learning models. NEAT is a continuous function which maps
locations in Bird's Eye View (BEV) scene coordinates to waypoints and
semantics, using intermediate attention maps to iteratively compress
high-dimensional 2D image features into a compact representation. This allows
our model to selectively attend to relevant regions in the input while ignoring
information irrelevant to the driving task, effectively associating the images
with the BEV representation. In a new evaluation setting involving adverse
environmental conditions and challenging scenarios, NEAT outperforms several
strong baselines and achieves driving scores on par with the privileged CARLA
expert used to generate its training data. Furthermore, visualizing the
attention maps for models with NEAT intermediate representations provides
improved interpretability.

    

### [[2109.04459] SONIC: A Sparse Neural Network Inference Accelerator with Silicon Photonics for Energy-Efficient Deep Learning](http://arxiv.org/abs/2109.04459)


  Sparse neural networks can greatly facilitate the deployment of neural
networks on resource-constrained platforms as they offer compact model sizes
while retaining inference accuracy. Because of the sparsity in parameter
matrices, sparse neural networks can, in principle, be exploited in accelerator
architectures for improved energy-efficiency and latency. However, to realize
these improvements in practice, there is a need to explore sparsity-aware
hardware-software co-design. In this paper, we propose a novel silicon
photonics-based sparse neural network inference accelerator called SONIC. Our
experimental analysis shows that SONIC can achieve up to 5.8x better
performance-per-watt and 8.4x lower energy-per-bit than state-of-the-art sparse
electronic neural network accelerators; and up to 13.8x better
performance-per-watt and 27.6x lower energy-per-bit than the best known
photonic neural network accelerators.

    

### [[2109.04460] Protein Folding Neural Networks Are Not Robust](http://arxiv.org/abs/2109.04460)


  Deep neural networks such as AlphaFold and RoseTTAFold predict remarkably
accurate structures of proteins compared to other algorithmic approaches. It is
known that biologically small perturbations in the protein sequence do not lead
to drastic changes in the protein structure. In this paper, we demonstrate that
RoseTTAFold does not exhibit such a robustness despite its high accuracy, and
biologically small perturbations for some input sequences result in radically
different predicted protein structures. This raises the challenge of detecting
when these predicted protein structures cannot be trusted. We define the
robustness measure for the predicted structure of a protein sequence to be the
inverse of the root-mean-square distance (RMSD) in the predicted structure and
the structure of its adversarially perturbed sequence. We use adversarial
attack methods to create adversarial protein sequences, and show that the RMSD
in the predicted protein structure ranges from 0.119Å to 34.162Å when
the adversarial perturbations are bounded by 20 units in the BLOSUM62 distance.
This demonstrates very high variance in the robustness measure of the predicted
structures. We show that the magnitude of the correlation (0.917) between our
robustness measure and the RMSD between the predicted structure and the ground
truth is high, that is, the predictions with low robustness measure cannot be
trusted. This is the first paper demonstrating the susceptibility of
RoseTTAFold to adversarial attacks.

    

### [[2109.04463] Neural Latents Benchmark '21: Evaluating latent variable models of neural population activity](http://arxiv.org/abs/2109.04463)


  Advances in neural recording present increasing opportunities to study neural
activity in unprecedented detail. Latent variable models (LVMs) are promising
tools for analyzing this rich activity across diverse neural systems and
behaviors, as LVMs do not depend on known relationships between the activity
and external experimental variables. However, progress in latent variable
modeling is currently impeded by a lack of standardization, resulting in
methods being developed and compared in an ad hoc manner. To coordinate these
modeling efforts, we introduce a benchmark suite for latent variable modeling
of neural population activity. We curate four datasets of neural spiking
activity from cognitive, sensory, and motor areas to promote models that apply
to the wide variety of activity seen across these areas. We identify
unsupervised evaluation as a common framework for evaluating models across
datasets, and apply several baselines that demonstrate benchmark diversity. We
release this benchmark through EvalAI. this http URL


### [[2109.04467] Mining Points of Interest via Address Embeddings: An Unsupervised Approach](http://arxiv.org/abs/2109.04467)


  Digital maps are commonly used across the globe for exploring places that
users are interested in, commonly referred to as points of interest (PoI). In
online food delivery platforms, PoIs could represent any major private
compounds where customers could order from such as hospitals, residential
complexes, office complexes, educational institutes and hostels. In this work,
we propose an end-to-end unsupervised system design for obtaining polygon
representations of PoIs (PoI polygons) from address locations and address
texts. We preprocess the address texts using locality names and generate
embeddings for the address texts using a deep learning-based architecture, viz.
RoBERTa, trained on our internal address dataset. The PoI candidates are
identified by jointly clustering the anonymised customer phone GPS locations
(obtained during address onboarding) and the embeddings of the address texts.
The final list of PoI polygons is obtained from these PoI candidates using
novel post-processing steps. This algorithm identified 74.8 % more PoIs than
those obtained using the Mummidi-Krumm baseline algorithm run on our internal
dataset. The proposed algorithm achieves a median area precision of 98 %, a
median area recall of 8 %, and a median F-score of 0.15. In order to improve
the recall of the algorithmic polygons, we post-process them using building
footprint polygons from the OpenStreetMap (OSM) database. The post-processing
algorithm involves reshaping the algorithmic polygon using intersecting
polygons and closed private roads from the OSM database, and accounting for
intersection with public roads on the OSM database. We achieve a median area
recall of 70 %, a median area precision of 69 %, and a median F-score of 0.69
on these post-processed polygons.

    

### [[2109.04468] Leveraging Local Domains for Image-to-Image Translation](http://arxiv.org/abs/2109.04468)


  Image-to-image (i2i) networks struggle to capture local changes because they
do not affect the global scene structure. For example, translating from highway
scenes to offroad, i2i networks easily focus on global color features but
ignore obvious traits for humans like the absence of lane markings. In this
paper, we leverage human knowledge about spatial domain characteristics which
we refer to as 'local domains' and demonstrate its benefit for image-to-image
translation. Relying on a simple geometrical guidance, we train a patch-based
GAN on few source data and hallucinate a new unseen domain which subsequently
eases transfer learning to target. We experiment on three tasks ranging from
unstructured environments to adverse weather. Our comprehensive evaluation
setting shows we are able to generate realistic translations, with minimal
priors, and training only on a few images. Furthermore, when trained on our
translations images we show that all tested proxy tasks are significantly
improved, without ever seeing target domain at training.

    

### [[1901.09018] Provably efficient RL with Rich Observations via Latent State Decoding](http://arxiv.org/abs/1901.09018)


  We study the exploration problem in episodic MDPs with rich observations
generated from a small number of latent states. Under certain identifiability
assumptions, we demonstrate how to estimate a mapping from the observations to
latent states inductively through a sequence of regression and clustering steps
-- where previously decoded latent states provide labels for later regression
problems -- and use it to construct good exploration policies. We provide
finite-sample guarantees on the quality of the learned state decoding function
and exploration policies, and complement our theory with an empirical
evaluation on a class of hard exploration problems. Our method exponentially
improves over $Q$-learning with naïve exploration, even when $Q$-learning has
cheating access to latent states.

    

### [[1909.12205] Adaptive Binary-Ternary Quantization](http://arxiv.org/abs/1909.12205)


  Neural network models are resource hungry. It is difficult to deploy such
deep networks on devices with limited resources, like smart wearables,
cellphones, drones, and autonomous vehicles. Low bit quantization such as
binary and ternary quantization is a common approach to alleviate this resource
requirements. Ternary quantization provides a more flexible model and
outperforms binary quantization in terms of accuracy, however doubles the
memory footprint and increases the computational cost. Contrary to these
approaches, mixed quantized models allow a trade-off between accuracy and
memory footprint. In such models, quantization depth is often chosen manually,
or is tuned using a separate optimization routine. The latter requires training
a quantized network multiple times. Here, we propose an adaptive combination of
binary and ternary quantization, namely Smart Quantization (SQ), in which the
quantization depth is modified directly via a regularization function, so that
the model is trained only once. Our experimental results show that the proposed
method adapts quantization depth successfully while keeping the model accuracy
high on MNIST and CIFAR10 benchmarks.

    

### [[1911.03063] Is a Classification Procedure Good Enough? A Goodness-of-Fit Assessment Tool for Classification Learning](http://arxiv.org/abs/1911.03063)


  In recent years, many non-traditional classification methods, such as Random
Forest, Boosting, and neural network, have been widely used in applications.
Their performance is typically measured in terms of classification accuracy.
While the classification error rate and the like are important, they do not
address a fundamental question: Is the classification method underfitted? To
our best knowledge, there is no existing method that can assess the
goodness-of-fit of a general classification procedure. Indeed, the lack of a
parametric assumption makes it challenging to construct proper tests. To
overcome this difficulty, we propose a methodology called BAGofT that splits
the data into a training set and a validation set. First, the classification
procedure to assess is applied to the training set, which is also used to
adaptively find a data grouping that reveals the most severe regions of
underfitting. Then, based on this grouping, we calculate a test statistic by
comparing the estimated success probabilities and the actual observed responses
from the validation set. The data splitting guarantees that the size of the
test is controlled under the null hypothesis, and the power of the test goes to
one as the sample size increases under the alternative hypothesis. For testing
parametric classification models, the BAGofT has a broader scope than the
existing methods since it is not restricted to specific parametric models
(e.g., logistic regression). Extensive simulation studies show the utility of
the BAGofT when assessing general classification procedures and its strengths
over some existing methods when testing parametric classification models.

    

### [[1911.03437] SMART: Robust and Efficient Fine-Tuning for Pre-trained Natural Language Models through Principled Regularized Optimization](http://arxiv.org/abs/1911.03437)


  Transfer learning has fundamentally changed the landscape of natural language
processing (NLP) research. Many existing state-of-the-art models are first
pre-trained on a large text corpus and then fine-tuned on downstream tasks.
However, due to limited data resources from downstream tasks and the extremely
large capacity of pre-trained models, aggressive fine-tuning often causes the
adapted model to overfit the data of downstream tasks and forget the knowledge
of the pre-trained model. To address the above issue in a more principled
manner, we propose a new computational framework for robust and efficient
fine-tuning for pre-trained language models. Specifically, our proposed
framework contains two important ingredients: 1. Smoothness-inducing
regularization, which effectively manages the capacity of the model; 2. Bregman
proximal point optimization, which is a class of trust-region methods and can
prevent knowledge forgetting. Our experiments demonstrate that our proposed
method achieves the state-of-the-art performance on multiple NLP benchmarks.

    

### [[2003.05285] A Supervised Machine Learning Model For Imputing Missing Boarding Stops In Smart Card Data](http://arxiv.org/abs/2003.05285)


  Public transport has become an essential part of urban existence with
increased population densities and environmental awareness. Large quantities of
data are currently generated, allowing for more robust methods to understand
travel behavior by harvesting smart card usage. However, public transport
datasets suffer from data integrity problems; boarding stop information may be
missing due to imperfect acquirement processes or inadequate reporting. We
developed a supervised machine learning method to impute missing boarding stops
based on ordinal classification using GTFS timetable, smart card, and
geospatial datasets. A new metric, Pareto Accuracy, is suggested to evaluate
algorithms where classes have an ordinal nature. Results are based on a case
study in the city of Beer Sheva, Israel, consisting of one month of smart card
data. We show that our proposed method is robust to irregular travelers and
significantly outperforms well-known imputation methods without the need to
mine any additional datasets. Validation of data from another Israeli city
using transfer learning shows the presented model is general and context-free.
The implications for transportation planning and travel behavior research are
further discussed.

    

### [[2004.12488] Order preserving hierarchical agglomerative clustering](http://arxiv.org/abs/2004.12488)


  Partial orders and directed acyclic graphs are commonly recurring data
structures that arise naturally in numerous domains and applications and are
used to represent ordered relations between entities in the domains. Examples
are task dependencies in a project plan, transaction order in distributed
ledgers and execution sequences of tasks in computer programs, just to mention
a few. We study the problem of order preserving hierarchical clustering of this
kind of ordered data. That is, if we have $a < b$ in the original data and
denote their respective clusters by $[a]$ and $[b]$, then we shall have $[a] <
[b]$ in the produced clustering. The clustering is similarity based and uses
standard linkage functions, such as single- and complete linkage, and is an
extension of classical hierarchical clustering.
To achieve this, we define the output from running classical hierarchical
clustering on strictly ordered data to be partial dendrograms; sub-trees of
classical dendrograms with several connected components. We then construct an
embedding of partial dendrograms over a set into the family of ultrametrics
over the same set. An optimal hierarchical clustering is defined as the partial
dendrogram corresponding to the ultrametric closest to the original
dissimilarity measure, measured in the p-norm. Thus, the method is a
combination of classical hierarchical clustering and ultrametric fitting.
A reference implementation is employed for experiments on both synthetic
random data and real world data from a database of machine parts. When compared
to existing methods, the experiments show that our method excels both in
cluster quality and order preservation.

    

### [[2004.13002] A Black-box Adversarial Attack Strategy with Adjustable Sparsity and Generalizability for Deep Image Classifiers](http://arxiv.org/abs/2004.13002)


  Constructing adversarial perturbations for deep neural networks is an
important direction of research. Crafting image-dependent adversarial
perturbations using white-box feedback has hitherto been the norm for such
adversarial attacks. However, black-box attacks are much more practical for
real-world applications. Universal perturbations applicable across multiple
images are gaining popularity due to their innate generalizability. There have
also been efforts to restrict the perturbations to a few pixels in the image.
This helps to retain visual similarity with the original images making such
attacks hard to detect. This paper marks an important step which combines all
these directions of research. We propose the DEceit algorithm for constructing
effective universal pixel-restricted perturbations using only black-box
feedback from the target network. We conduct empirical investigations using the
ImageNet validation set on the state-of-the-art deep neural classifiers by
varying the number of pixels to be perturbed from a meagre 10 pixels to as high
as all pixels in the image. We find that perturbing only about 10% of the
pixels in an image using DEceit achieves a commendable and highly transferable
Fooling Rate while retaining the visual quality. We further demonstrate that
DEceit can be successfully applied to image dependent attacks as well. In both
sets of experiments, we outperformed several state-of-the-art methods.

    

### [[2008.01511] A divide-and-conquer algorithm for quantum state preparation](http://arxiv.org/abs/2008.01511)


  Advantages in several fields of research and industry are expected with the
rise of quantum computers. However, the computational cost to load classical
data in quantum computers can impose restrictions on possible quantum speedups.
Known algorithms to create arbitrary quantum states require quantum circuits
with depth O(N) to load an N-dimensional vector. Here, we show that it is
possible to load an N-dimensional vector with a quantum circuit with
polylogarithmic depth and entangled information in ancillary qubits. Results
show that we can efficiently load data in quantum devices using a
divide-and-conquer strategy to exchange computational time for space. We
demonstrate a proof of concept on a real quantum device and present two
applications for quantum machine learning. We expect that this new loading
strategy allows the quantum speedup of tasks that require to load a significant
volume of information to quantum devices.

    

### [[2008.12537] The UU-test for Statistical Modeling of Unimodal Data](http://arxiv.org/abs/2008.12537)


  Deciding on the unimodality of a dataset is an important problem in data
analysis and statistical modeling. It allows to obtain knowledge about the
structure of the dataset, ie. whether data points have been generated by a
probability distribution with a single or more than one peaks. Such knowledge
is very useful for several data analysis problems, such as for deciding on the
number of clusters and determining unimodal projections. We propose a technique
called UU-test (Unimodal Uniform test) to decide on the unimodality of a
one-dimensional dataset. The method operates on the empirical cumulative
density function (ecdf) of the dataset. It attempts to build a piecewise linear
approximation of the ecdf that is unimodal and models the data sufficiently in
the sense that the data corresponding to each linear segment follows the
uniform distribution. A unique feature of this approach is that in the case of
unimodality, it also provides a statistical model of the data in the form of a
Uniform Mixture Model. We present experimental results in order to assess the
ability of the method to decide on unimodality and perform comparisons with the
well-known dip-test approach. In addition, in the case of unimodal datasets we
evaluate the Uniform Mixture Models provided by the proposed method using the
test set log-likelihood and the two-sample Kolmogorov-Smirnov (KS) test.

    

### [[2011.04558] Spectral clustering on spherical coordinates under the degree-corrected stochastic blockmodel](http://arxiv.org/abs/2011.04558)


  Spectral clustering is a popular method for community detection in network
graphs: starting from a matrix representation of the graph, the nodes are
clustered on a low dimensional projection obtained from a truncated spectral
decomposition of the matrix. Estimating correctly the number of communities and
the dimension of the reduced latent space is critical for good performance of
spectral clustering algorithms. Furthermore, many real-world graphs, such as
enterprise computer networks studied in cyber-security applications, often
display heterogeneous within-community degree distributions. Such heterogeneous
degree distributions are usually not well captured by standard spectral
clustering algorithms. In this article, a novel spectral clustering algorithm
is proposed for community detection under the degree-corrected stochastic
blockmodel. The proposed method is based on a transformation of the spectral
embedding to spherical coordinates, and a novel modelling assumption in the
transformed space. The method allows for simultaneous and automated selection
of the number of communities and the latent dimension for spectral embeddings
of graphs with uneven node degrees. Results show improved performance over
competing methods in representing computer networks.

    

### [[2011.09769] Data-Driven Robust Optimization using Unsupervised Deep Learning](http://arxiv.org/abs/2011.09769)


  Robust optimization has been established as a leading methodology to approach
decision problems under uncertainty. To derive a robust optimization model, a
central ingredient is to identify a suitable model for uncertainty, which is
called the uncertainty set. An ongoing challenge in the recent literature is to
derive uncertainty sets from given historical data that result in solutions
that are robust regarding future scenarios. In this paper we use an
unsupervised deep learning method to learn and extract hidden structures from
data, leading to non-convex uncertainty sets and better robust solutions. We
prove that most of the classical uncertainty classes are special cases of our
derived sets and that optimizing over them is strongly NP-hard. Nevertheless,
we show that the trained neural networks can be integrated into a robust
optimization model by formulating the adversarial problem as a convex quadratic
mixed-integer program. This allows us to derive robust solutions through an
iterative scenario generation process. In our computational experiments, we
compare this approach to a similar approach using kernel-based support vector
clustering. We find that uncertainty sets derived by the unsupervised deep
learning method find a better description of data and lead to robust solutions
that outperform the comparison method both with respect to objective value and
feasibility.

    

### [[2011.15122] Deep controlled learning of MDP policies with an application to lost-sales inventory control](http://arxiv.org/abs/2011.15122)


  Recent literature established that neural networks can represent good
policies across a range of stochastic dynamic models in supply chain and
logistics. We incorporate variance reduction techniques in a newly proposed
algorithm, to overcome limitations of the model-free algorithms typically
employed to learn such neural network policies. For the classical lost sales
inventory model, the algorithm learns neural network policies that are superior
to those learned using model-free algorithms, while outperforming the best
heuristic benchmarks by an order of magnitude. The algorithm is an interesting
candidate to apply to other stochastic dynamic problems in supply chain and
logistics, because the ideas in its development are generic.

    

### [[2012.01789] Distributed Thompson Sampling](http://arxiv.org/abs/2012.01789)


  We study a cooperative multi-agent multi-armed bandits with M agents and K
arms. The goal of the agents is to minimized the cumulative regret. We adapt a
traditional Thompson Sampling algoirthm under the distributed setting. However,
with agent's ability to communicate, we note that communication may further
reduce the upper bound of the regret for a distributed Thompson Sampling
approach. To further improve the performance of distributed Thompson Sampling,
we propose a distributed Elimination based Thompson Sampling algorithm that
allow the agents to learn collaboratively. We analyse the algorithm under
Bernoulli reward and derived a problem dependent upper bound on the cumulative
regret.

    

### [[2012.02164] People Still Care About Facts: Twitter Users Engage More with Factual Discourse than Misinformation--A Comparison Between COVID and General Narratives on Twitter](http://arxiv.org/abs/2012.02164)


  Misinformation entails the dissemination of falsehoods that leads to the slow
fracturing of society via decreased trust in democratic processes,
institutions, and science. The public has grown aware of the role of social
media as a superspreader of untrustworthy information, where even pandemics
have not been immune. In this paper, we focus on COVID-19 misinformation and
examine a subset of 2.1M tweets to understand misinformation as a function of
engagement, tweet content (COVID-19- vs. non-COVID-19-related), and veracity
(misleading or factual). Using correlation analysis, we show the most relevant
feature subsets among over 126 features that most heavily correlate with
misinformation or facts. We found that (i) factual tweets, regardless of
whether COVID-related, were more engaging than misinformation tweets; and (ii)
features that most heavily correlated with engagement varied depending on the
veracity and content of the tweet.

    

### [[2012.07913] Quantizing data for distributed learning](http://arxiv.org/abs/2012.07913)


  We consider machine learning applications that train a model by leveraging
data distributed over a trusted network, where communication constraints can
create a performance bottleneck. A number of recent approaches propose to
overcome this bottleneck through compression of gradient updates. However, as
models become larger, so does the size of the gradient updates. In this paper,
we propose an alternate approach to learn from distributed data that quantizes
data instead of gradients, and can support learning over applications where the
size of gradient updates is prohibitive. Our approach leverages the dependency
of the computed gradient on data samples, which lie in a much smaller space in
order to perform the quantization in the smaller dimension data space. At the
cost of an extra gradient computation, the gradient estimate can be refined by
conveying the difference between the gradient at the quantized data point and
the original gradient using a small number of bits. Lastly, in order to save
communication, our approach adds a layer that decides whether to transmit a
quantized data sample or not based on its importance for learning. We analyze
the convergence of the proposed approach for smooth convex and non-convex
objective functions and show that we can achieve order optimal convergence
rates with communication that mostly depends on the data rather than the model
(gradient) dimension. We use our proposed algorithm to train ResNet models on
the CIFAR-10 and ImageNet datasets, and show that we can achieve an order of
magnitude savings over gradient compression methods. These communication
savings come at the cost of increasing computation at the learning agent, and
thus our approach is beneficial in scenarios where communication load is the
main problem.

    

### [[2012.08181] Fast-Convergent Dynamics for Distributed Allocation of Resources Over Switching Sparse Networks with Quantized Communication Links](http://arxiv.org/abs/2012.08181)


  This paper proposes networked dynamics to solve resource allocation problems
over time-varying multi-agent networks. The state of each agent represents the
amount of used resources (or produced utilities) while the total amount of
resources is fixed. The idea is to optimally allocate the resources among the
group of agents by minimizing the overall cost function subject to fixed sum of
resources. Each agents' information is restricted to its own state and cost
function and those of its immediate in-neighbors. This is motivated by
distributed applications such as mobile edge-computing, economic dispatch over
smart grids, and multi-agent coverage control. This work provides a fast
convergent solution (in comparison with linear dynamics) while considering
relaxed network connectivity with quantized communication links. The proposed
dynamics reaches optimal solution over switching (possibly disconnected)
undirected networks as far as their union over some bounded non-overlapping
time-intervals has a spanning-tree. We prove feasibility of the solution,
uniqueness of the optimal state, and convergence to the optimal value under the
proposed dynamics, where the analysis is applicable to similar 1st-order
allocation dynamics with strongly sign-preserving nonlinearities, such as
actuator saturation.

    

### [[2012.14838] The Price is (Probably) Right: Learning Market Equilibria from Samples](http://arxiv.org/abs/2012.14838)


  Equilibrium computation in markets usually considers settings where player
valuation functions are known. We consider the setting where player valuations
are unknown; using a PAC learning-theoretic framework, we analyze some classes
of common valuation functions, and provide algorithms which output direct PAC
equilibrium allocations, not estimates based on attempting to learn valuation
functions. Since there exist trivial PAC market outcomes with an unbounded
worst-case efficiency loss, we lower-bound the efficiency of our algorithms.
While the efficiency loss under general distributions is rather high, we show
that in some cases (e.g., unit-demand valuations), it is possible to find a PAC
market equilibrium with significantly better utility.

    

### [[2101.09298] Safe Learning Reference Governor: Theory and Application to Fuel Truck Rollover Avoidance](http://arxiv.org/abs/2101.09298)


  This paper proposes a learning reference governor (LRG) approach to enforce
state and control constraints in systems for which an accurate model is
unavailable, and this approach enables the reference governor to gradually
improve command tracking performance through learning while enforcing the
constraints during learning and after learning is completed. The learning can
be performed either on a black-box type model of the system or directly on the
hardware. After introducing the LRG algorithm and outlining its theoretical
properties, this paper investigates LRG application to fuel truck (tank truck)
rollover avoidance. Through simulations based on a fuel truck model that
accounts for liquid fuel sloshing effects, we show that the proposed LRG can
effectively protect fuel trucks from rollover accidents under various operating
conditions.

    

### [[2101.12365] Sharp Bounds on the Approximation Rates, Metric Entropy, and $n$-widths of Shallow Neural Networks](http://arxiv.org/abs/2101.12365)


  In this article, we study approximation properties of the variation spaces
corresponding to shallow neural networks with a variety of activation
functions. We introduce two main tools for estimating the metric entropy,
approximation rates, and $n$-widths of these spaces. First, we introduce the
notion of a smoothly parameterized dictionary and give upper bounds on the
non-linear approximation rates, metric entropy and $n$-widths of their absolute
convex hull. The upper bounds depend upon the order of smoothness of the
parameterization. This result is applied to dictionaries of ridge functions
corresponding to shallow neural networks, and they improve upon existing
results in many cases. Next, we provide a method for lower bounding the metric
entropy and $n$-widths of variation spaces which contain certain classes of
ridge functions. This result gives sharp lower bounds on the
$L^2$-approximation rates, metric entropy, and $n$-widths for variation spaces
corresponding to neural networks with a range of important activation
functions, including ReLU$^k$, sigmoidal activation functions with bounded
variation, and the B-spline activation functions.

    

### [[2101.12699] Exploring Deep Neural Networks via Layer-Peeled Model: Minority Collapse in Imbalanced Training](http://arxiv.org/abs/2101.12699)


  In this paper, we introduce the \textit{Layer-Peeled Model}, a nonconvex yet
analytically tractable optimization program, in a quest to better understand
deep neural networks that are trained for a sufficiently long time. As the name
suggests, this new model is derived by isolating the topmost layer from the
remainder of the neural network, followed by imposing certain constraints
separately on the two parts of the network. We demonstrate that the
Layer-Peeled Model, albeit simple, inherits many characteristics of
well-trained neural networks, thereby offering an effective tool for explaining
and predicting common empirical patterns of deep learning training. First, when
working on class-balanced datasets, we prove that any solution to this model
forms a simplex equiangular tight frame, which in part explains the recently
discovered phenomenon of neural collapse \cite{papyan2020prevalence}. More
importantly, when moving to the imbalanced case, our analysis of the
Layer-Peeled Model reveals a hitherto unknown phenomenon that we term
\textit{Minority Collapse}, which fundamentally limits the performance of deep
learning models on the minority classes. In addition, we use the Layer-Peeled
Model to gain insights into how to mitigate Minority Collapse. Interestingly,
this phenomenon is first predicted by the Layer-Peeled Model before being
confirmed by our computational experiments.

    

### [[2102.05174] On the Hardness of PAC-learning stabilizer States with Noise](http://arxiv.org/abs/2102.05174)


  We consider the problem of learning stabilizer states with noise in the
Probably Approximately Correct (PAC) framework of Aaronson (2007) for learning
quantum states. In the noiseless setting, an algorithm for this problem was
recently given by Rocchetto (2018), but the noisy case was left open. Motivated
by approaches to noise tolerance from classical learning theory, we introduce
the Statistical Query (SQ) model for PAC-learning quantum states, and prove
that algorithms in this model are indeed resilient to common forms of noise,
including classification and depolarizing noise. We prove an exponential lower
bound on learning stabilizer states in the SQ model. Even outside the SQ model,
we prove that learning stabilizer states with noise is in general as hard as
Learning Parity with Noise (LPN) using classical examples. Our results position
the problem of learning stabilizer states as a natural quantum analogue of the
classical problem of learning parities: easy in the noiseless setting, but
seemingly intractable even with simple forms of noise.

    

### [[2102.09858] ISCL: Interdependent Self-Cooperative Learning for Unpaired Image Denoising](http://arxiv.org/abs/2102.09858)


  With the advent of advances in self-supervised learning, paired clean-noisy
data are no longer required in deep learning-based image denoising. However,
existing blind denoising methods still require the assumption with regard to
noise characteristics, such as zero-mean noise distribution and pixel-wise
noise-signal independence; this hinders wide adaptation of the method in the
medical domain. On the other hand, unpaired learning can overcome limitations
related to the assumption on noise characteristics, which makes it more
feasible for collecting the training data in real-world scenarios. In this
paper, we propose a novel image denoising scheme, Interdependent
Self-Cooperative Learning (ISCL), that leverages unpaired learning by combining
cyclic adversarial learning with self-supervised residual learning. Unlike the
existing unpaired image denoising methods relying on matching data
distributions in different domains, the two architectures in ISCL, designed for
different tasks, complement each other and boost the learning process. To
assess the performance of the proposed method, we conducted extensive
experiments in various biomedical image degradation scenarios, such as noise
caused by physical characteristics of electron microscopy (EM) devices (film
and charging noise), and structural noise found in low-dose computer tomography
(CT). We demonstrate that the image quality of our method is superior to
conventional and current state-of-the-art deep learning-based image denoising
methods, including supervised learning.

    

### [[2103.03817] Proactive and AoI-aware Failure Recovery for Stateful NFV-enabled Zero-Touch 6G Networks: Model-Free DRL Approach](http://arxiv.org/abs/2103.03817)


  In this paper, we propose a Zero-Touch, deep reinforcement learning
(DRL)-based Proactive Failure Recovery framework called ZT-PFR for stateful
network function virtualization (NFV)-enabled networks. To this end, we
formulate a resource-efficient optimization problem minimizing the network cost
function including resource cost and wrong decision penalty. As a solution, we
propose state-of-the-art DRL-based methods such as soft-actor-critic (SAC) and
proximal-policy-optimization (PPO). In addition, to train and test our DRL
agents, we propose a novel impending failure model. Moreover, to keep network
status information at an acceptable freshness level for appropriate
decision-making, we apply the concept of age of information to strike a balance
between the event and scheduling-based monitoring. Several key systems and DRL
algorithm design insights for ZT-PFR are drawn from our analysis and simulation
results. For example, we use a hybrid neural network, consisting long
short-term memory layers in the DRL agents

    

### [[2103.05245] Learning Dependencies in Distributed Cloud Applications to Identify and Localize Anomalies](http://arxiv.org/abs/2103.05245)


  Operation and maintenance of large distributed cloud applications can quickly
become unmanageably complex, putting human operators under immense stress when
problems occur. Utilizing machine learning for identification and localization
of anomalies in such systems supports human experts and enables fast
mitigation. However, due to the various inter-dependencies of system
components, anomalies do not only affect their origin but propagate through the
distributed system. Taking this into account, we present Arvalus and its
variant D-Arvalus, a neural graph transformation method that models system
components as nodes and their dependencies and placement as edges to improve
the identification and localization of anomalies. Given a series of metric
KPIs, our method predicts the most likely system state - either normal or an
anomaly class - and performs localization when an anomaly is detected. During
our experiments, we simulate a distributed cloud application deployment and
synthetically inject anomalies. The evaluation shows the generally good
prediction performance of Arvalus and reveals the advantage of D-Arvalus which
incorporates information about system component dependencies.

    

### [[2103.12827] Fisher Task Distance and Its Applications in Transfer Learning and Neural Architecture Search](http://arxiv.org/abs/2103.12827)


  We formulate an asymmetric (or non-commutative) distance between tasks based
on Fisher Information Matrices. We provide proof of consistency for our
distance through theorems and experiments on various classification tasks. We
then apply our proposed measure of task distance in transfer learning on visual
tasks in the Taskonomy dataset. Additionally, we show how the proposed distance
between a target task and a set of baseline tasks can be used to reduce the
neural architecture search space for the target task. The complexity reduction
in search space for task-specific architectures is achieved by building on the
optimized architectures for similar tasks instead of doing a full search
without using this side information. Experimental results demonstrate the
efficacy of the proposed approach and its improvements over other methods.

    

### [[2103.14222] Adversarial Attacks are Reversible with Natural Supervision](http://arxiv.org/abs/2103.14222)


  We find that images contain intrinsic structure that enables the reversal of
many adversarial attacks. Attack vectors cause not only image classifiers to
fail, but also collaterally disrupt incidental structure in the image. We
demonstrate that modifying the attacked image to restore the natural structure
will reverse many types of attacks, providing a defense. Experiments
demonstrate significantly improved robustness for several state-of-the-art
models across the CIFAR-10, CIFAR-100, SVHN, and ImageNet datasets. Our results
show that our defense is still effective even if the attacker is aware of the
defense mechanism. Since our defense is deployed during inference instead of
training, it is compatible with pre-trained networks as well as most other
defenses. Our results suggest deep networks are vulnerable to adversarial
examples partly because their representations do not enforce the natural
structure of images.

    

### [[2104.00245] High-Dimensional Differentially-Private EM Algorithm: Methods and Near-Optimal Statistical Guarantees](http://arxiv.org/abs/2104.00245)


  In this paper, we develop a general framework to design differentially
private expectation-maximization (EM) algorithms in high-dimensional latent
variable models, based on the noisy iterative hard-thresholding. We derive the
statistical guarantees of the proposed framework and apply it to three specific
models: Gaussian mixture, mixture of regression, and regression with missing
covariates. In each model, we establish the near-optimal rate of convergence
with differential privacy constraints, and show the proposed algorithm is
minimax rate optimal up to logarithm factors. The technical tools developed for
the high-dimensional setting are then extended to the classic low-dimensional
latent variable models, and we propose a near rate-optimal EM algorithm with
differential privacy guarantees in this setting. Simulation studies and real
data analysis are conducted to support our results.

    

### [[2104.01002] HAConvGNN: Hierarchical Attention Based Convolutional Graph Neural Network for Code Documentation Generation in Jupyter Notebooks](http://arxiv.org/abs/2104.01002)


  Jupyter notebook allows data scientists to write machine learning code
together with its documentation in cells. In this paper, we propose a new task
of code documentation generation (CDG) for computational notebooks. In contrast
to the previous CDG tasks which focus on generating documentation for single
code snippets, in a computational notebook, one documentation in a markdown
cell often corresponds to multiple code cells, and these code cells have an
inherent structure. We proposed a new model (HAConvGNN) that uses a
hierarchical attention mechanism to consider the relevant code cells and the
relevant code tokens information when generating the documentation. Tested on a
new corpus constructed from well-documented Kaggle notebooks, we show that our
model outperforms other baseline models.

    

### [[2104.07705] How to Train BERT with an Academic Budget](http://arxiv.org/abs/2104.07705)


  While large language models a la BERT are used ubiquitously in NLP,
pretraining them is considered a luxury that only a few well-funded industry
labs can afford. How can one train such models with a more modest budget? We
present a recipe for pretraining a masked language model in 24 hours using a
single low-end deep learning server. We demonstrate that through a combination
of software optimizations, design choices, and hyperparameter tuning, it is
possible to produce models that are competitive with BERT-base on GLUE tasks at
a fraction of the original pretraining cost.

    

### [[2104.08027] Fast, Effective, and Self-Supervised: Transforming Masked Language Models into Universal Lexical and Sentence Encoders](http://arxiv.org/abs/2104.08027)


  Pretrained Masked Language Models (MLMs) have revolutionised NLP in recent
years. However, previous work has indicated that off-the-shelf MLMs are not
effective as universal lexical or sentence encoders without further
task-specific fine-tuning on NLI, sentence similarity, or paraphrasing tasks
using annotated task data. In this work, we demonstrate that it is possible to
turn MLMs into effective universal lexical and sentence encoders even without
any additional data and without any supervision. We propose an extremely
simple, fast and effective contrastive learning technique, termed Mirror-BERT,
which converts MLMs (e.g., BERT and RoBERTa) into such encoders in 20-30
seconds without any additional external knowledge. Mirror-BERT relies on fully
identical or slightly modified string pairs as positive (i.e., synonymous)
fine-tuning examples, and aims to maximise their similarity during identity
fine-tuning. We report huge gains over off-the-shelf MLMs with Mirror-BERT in
both lexical-level and sentence-level tasks, across different domains and
different languages. Notably, in the standard sentence semantic similarity
(STS) tasks, our self-supervised Mirror-BERT model even matches the performance
of the task-tuned Sentence-BERT models from prior work. Finally, we delve
deeper into the inner workings of MLMs, and suggest some evidence on why this
simple approach can yield effective universal lexical and sentence encoders.

    

### [[2104.08164] Editing Factual Knowledge in Language Models](http://arxiv.org/abs/2104.08164)


  The factual knowledge acquired during pre-training and stored in the
parameters of Language Models (LMs) can be useful in downstream tasks (e.g.,
question answering or textual inference). However, some facts can be
incorrectly induced or become obsolete over time. We present KnowledgeEditor, a
method which can be used to edit this knowledge and, thus, fix 'bugs' or
unexpected predictions without the need for expensive re-training or
fine-tuning. Besides being computationally efficient, KnowledgeEditordoes not
require any modifications in LM pre-training (e.g., the use of meta-learning).
In our approach, we train a hyper-network with constrained optimization to
modify a fact without affecting the rest of the knowledge; the trained
hyper-network is then used to predict the weight update at test time. We show
KnowledgeEditor's efficacy with two popular architectures and
knowledge-intensive tasks: i) a BERT model fine-tuned for fact-checking, and
ii) a sequence-to-sequence BART model for question answering. With our method,
changing a prediction on the specific wording of a query tends to result in a
consistent change in predictions also for its paraphrases. We show that this
can be further encouraged by exploiting (e.g., automatically-generated)
paraphrases during training. Interestingly, our hyper-network can be regarded
as a 'probe' revealing which components need to be changed to manipulate
factual knowledge; our analysis shows that the updates tend to be concentrated
on a small subset of components. Source code available at
this https URL


### [[2104.08801] Back-Training excels Self-Training at Unsupervised Domain Adaptation of Question Generation and Passage Retrieval](http://arxiv.org/abs/2104.08801)


  In this work, we introduce back-training, an alternative to self-training for
unsupervised domain adaptation (UDA) from source to target domain. While
self-training generates synthetic training data where natural inputs are
aligned with noisy outputs, back-training results in natural outputs aligned
with noisy inputs. This significantly reduces the gap between the target domain
and synthetic data distribution, and reduces model overfitting to the source
domain. We run UDA experiments on question generation and passage retrieval
from the \textit{Natural Questions} domain to machine learning and biomedical
domains. We find that back-training vastly outperforms self-training by a mean
improvement of 7.8 BLEU-4 points on generation, and 17.6\% top-20 retrieval
accuracy across both domains. We further propose consistency filters to remove
low-quality synthetic data before training. We also release a new
domain-adaptation dataset- \textit{MLQuestions} containing 35K unaligned
questions, 50K unaligned passages, and 3K aligned question-passage pairs.

    

### [[2104.08803] Consistent Accelerated Inference via Confident Adaptive Transformers](http://arxiv.org/abs/2104.08803)


  We develop a novel approach for confidently accelerating inference in the
large and expensive multilayer Transformers that are now ubiquitous in natural
language processing (NLP). Amortized or approximate computational methods
increase efficiency, but can come with unpredictable performance costs. In this
work, we present CATs -- Confident Adaptive Transformers -- in which we
simultaneously increase computational efficiency, while guaranteeing a
specifiable degree of consistency with the original model with high confidence.
Our method trains additional prediction heads on top of intermediate layers,
and dynamically decides when to stop allocating computational effort to each
input using a meta consistency classifier. To calibrate our early prediction
stopping rule, we formulate a unique extension of conformal prediction. We
demonstrate the effectiveness of this approach on four classification and
regression tasks.

    

### [[2104.09785] Model-predictive control and reinforcement learning in multi-energy system case studies](http://arxiv.org/abs/2104.09785)


  Model-predictive-control (MPC) offers an optimal control technique to
establish and ensure that the total operation cost of multi-energy systems
remains at a minimum while fulfilling all system constraints. However, this
method presumes an adequate model of the underlying system dynamics, which is
prone to modelling errors and is not necessarily adaptive. This has an
associated initial and ongoing project-specific engineering cost. In this
paper, we present an on- and off-policy multi-objective reinforcement learning
(RL) approach, that does not assume a model a priori, benchmarking this against
a linear MPC (LMPC - to reflect current practice, though non-linear MPC
performs better) - both derived from the general optimal control problem,
highlighting their differences and similarities. In a simple multi-energy
system (MES) configuration case study, we show that a twin delayed deep
deterministic policy gradient (TD3) RL agent offers potential to match and
outperform the perfect foresight LMPC benchmark (101.5%). This while the
realistic LMPC, i.e. imperfect predictions, only achieves 98%. While in a more
complex MES system configuration, the RL agent's performance is generally lower
(94.6%), yet still better than the realistic LMPC (88.9%). In both case
studies, the RL agents outperformed the realistic LMPC after a training period
of 2 years using quarterly interactions with the environment. We conclude that
reinforcement learning is a viable optimal control technique for multi-energy
systems given adequate constraint handling and pre-training, to avoid unsafe
interactions and long training periods, as is proposed in fundamental future
work.

    

### [[2104.12210] Generative Adversarial Network: Some Analytical Perspectives](http://arxiv.org/abs/2104.12210)


  Ever since its debut, generative adversarial networks (GANs) have attracted
tremendous amount of attention. Over the past years, different variations of
GANs models have been developed and tailored to different applications in
practice. Meanwhile, some issues regarding the performance and training of GANs
have been noticed and investigated from various theoretical perspectives. This
subchapter will start from an introduction of GANs from an analytical
perspective, then move on to the training of GANs via SDE approximations and
finally discuss some applications of GANs in computing high dimensional MFGs as
well as tackling mathematical finance problems.

    

### [[2105.08667] Image Cropping on Twitter: Fairness Metrics, their Limitations, and the Importance of Representation, Design, and Agency](http://arxiv.org/abs/2105.08667)


  Twitter uses machine learning to crop images, where crops are centered around
the part predicted to be the most salient. In fall 2020, Twitter users raised
concerns that the automated image cropping system on Twitter favored
light-skinned over dark-skinned individuals, as well as concerns that the
system favored cropping woman's bodies instead of their heads. In order to
address these concerns, we conduct an extensive analysis using formalized group
fairness metrics. We find systematic disparities in cropping and identify
contributing factors, including the fact that the cropping based on the single
most salient point can amplify the disparities because of an effect we term
argmax bias. However, we demonstrate that formalized fairness metrics and
quantitative analysis on their own are insufficient for capturing the risk of
representational harm in automatic cropping. We suggest the removal of
saliency-based cropping in favor of a solution that better preserves user
agency. For developing a new solution that sufficiently address concerns
related to representational harm, our critique motivates a combination of
quantitative and qualitative methods that include human-centered design.

    

### [[2105.12697] Intriguing Parameters of Structural Causal Models](http://arxiv.org/abs/2105.12697)


  In recent years there has been a lot of focus on adversarial attacks,
especially on deep neural networks. Here, we argue that they are more general
in nature and can easily affect a larger class of models, e.g., any
differentiable perturbed optimizers. We further show that such attacks can be
determined by the hidden confounders in a domain, thus drawing a novel
connection between such attacks and causality. Establishing this causal
perspective is characterized by the influence of the structural causal model's
data generating process on the subsequent optimization thereby exhibiting
intriguing parameters of the former. We reveal the existence of such parameters
for three combinatorial optimization problems, namely linear assignment,
shortest path and a real world problem of energy systems. Our empirical
examination also unveils worrisome consequences of these attacks on
differentiable perturbed optimizers thereby highlighting the criticality of our
findings.

    

### [[2105.14694] Combining resampling and reweighting for faithful stochastic optimization](http://arxiv.org/abs/2105.14694)


  Many machine learning and data science tasks require solving non-convex
optimization problems. When the loss function is a sum of multiple terms, a
popular method is the stochastic gradient descent. Viewed as a process for
sampling the loss function landscape, the stochastic gradient descent is known
to prefer flat minima. Though this is desired for certain optimization problems
such as in deep learning, it causes issues when the goal is to find the global
minimum, especially if the global minimum resides in a sharp valley.
Illustrated with a simple motivating example, we show that the fundamental
reason is that the difference in the Lipschitz constants of multiple terms in
the loss function causes stochastic gradient descent to experience different
variances at different minima. In order to mitigate this effect and perform
faithful optimization, we propose a combined resampling-reweighting scheme to
balance the variance at local minima and extend to general loss functions. We
explain from the numerical stability perspective how the proposed scheme is
more likely to select the true global minimum, and the local convergence
analysis perspective how it converges to a minimum faster when compared with
the vanilla stochastic gradient descent. Experiments from robust statistics and
computational chemistry are provided to demonstrate the theoretical findings.

    

### [[2105.15010] QueryNet: An Attack Framework with Surrogates Carrying Multiple Identities](http://arxiv.org/abs/2105.15010)


  Deep Neural Networks (DNNs) are acknowledged as vulnerable to adversarial
attacks, while the existing black-box attacks require extensive queries on the
victim DNN to achieve high success rates. For query-efficiency, surrogate
models of the victim are adopted as transferable attackers in consideration of
their Gradient Similarity (GS), i.e., surrogates' attack gradients are similar
to the victim's ones to some extent. However, it is generally neglected to
exploit their similarity on outputs, namely the Prediction Similarity (PS), to
filter out inefficient queries. To jointly utilize and also optimize
surrogates' GS and PS, we develop QueryNet, an efficient attack network that
can significantly reduce queries. QueryNet crafts several transferable
Adversarial Examples (AEs) by surrogates, and then decides also by surrogates
on the most promising AE, which is then sent to query the victim. That is to
say, in QueryNet, surrogates are not only exploited as transferable attackers,
but also as transferability evaluators for AEs. The AEs are generated using
surrogates' GS and evaluated based on their PS, and therefore, the query
results could be back-propagated to optimize surrogates' parameters and also
their architectures, enhancing both the GS and the PS. QueryNet has significant
query-efficiency, i.e., reduces queries by averagely about an order of
magnitude compared to recent SOTA methods according to our comprehensive and
real-world experiments: 11 victims (including 2 commercial models) on
MNIST/CIFAR10/ImageNet, allowing only 8-bit image queries, and no access to the
victim's training data.

    

### [[2106.03353] Understanding Neural Code Intelligence Through Program Simplification](http://arxiv.org/abs/2106.03353)


  A wide range of code intelligence (CI) tools, powered by deep neural
networks, have been developed recently to improve programming productivity and
perform program analysis. To reliably use such tools, developers often need to
reason about the behavior of the underlying models and the factors that affect
them. This is especially challenging for tools backed by deep neural networks.
Various methods have tried to reduce this opacity in the vein of
"transparent/interpretable-AI". However, these approaches are often specific to
a particular set of network architectures, even requiring access to the
network's parameters. This makes them difficult to use for the average
programmer, which hinders the reliable adoption of neural CI systems. In this
paper, we propose a simple, model-agnostic approach to identify critical input
features for models in CI systems, by drawing on software debugging research,
specifically delta debugging. Our approach, SIVAND, uses simplification
techniques that reduce the size of input programs of a CI model while
preserving the predictions of the model. We show that this approach yields
remarkably small outputs and is broadly applicable across many model
architectures and problem domains. We find that the models in our experiments
often rely heavily on just a few syntactic features in input programs. We
believe that SIVAND's extracted features may help understand neural CI systems'
predictions and learned behavior.

    

### [[2106.10251] Active Offline Policy Selection](http://arxiv.org/abs/2106.10251)


  This paper addresses the problem of policy selection in domains with abundant
logged data, but with a very restricted interaction budget. Solving this
problem would enable safe evaluation and deployment of offline reinforcement
learning policies in industry, robotics, and recommendation domains among
others. Several off-policy evaluation (OPE) techniques have been proposed to
assess the value of policies using only logged data. However, there is still a
big gap between the evaluation by OPE and the full online evaluation in the
real environment. At the same time, large amount of online interactions is
often not feasible in practice. To overcome this problem, we introduce
\emph{active offline policy selection} -- a novel sequential decision approach
that combines logged data with online interaction to identify the best policy.
This approach uses OPE estimates to warm start the online evaluation. Then, in
order to utilize the limited environment interactions wisely, it relies on a
Bayesian optimization method, with a kernel function that represents policy
similarity, to decide which policy to evaluate next. We use multiple benchmarks
with a large number of candidate policies to show that the proposed approach
improves upon state-of-the-art OPE estimates and pure online policy evaluation.

    

### [[2106.14997] Sharp Lower Bounds on the Approximation Rate of Shallow Neural Networks](http://arxiv.org/abs/2106.14997)


  We consider the approximation rates of shallow neural networks with respect
to the variation norm. Upper bounds on these rates have been established for
sigmoidal and ReLU activation functions, but it has remained an important open
problem whether these rates are sharp. In this article, we provide a solution
to this problem by proving sharp lower bounds on the approximation rates for
shallow neural networks, which are obtained by lower bounding the $L^2$-metric
entropy of the convex hull of the neural network basis functions. In addition,
our methods also give sharp lower bounds on the Kolmogorov $n$-widths of this
convex hull, which show that the variation spaces corresponding to shallow
neural networks cannot be efficiently approximated by linear methods. These
lower bounds apply to both sigmoidal activation functions with bounded
variation and to activation functions which are a power of the ReLU. Our
results also quantify how much stronger the Barron spectral norm is than the
variation norm and, combined with previous results, give the asymptotics of the
$L^\infty$-metric entropy up to logarithmic factors in the case of the ReLU
activation function.

    

### [[2108.10097] Graph Attention Multi-Layer Perceptron](http://arxiv.org/abs/2108.10097)


  Graph neural networks (GNNs) have recently achieved state-of-the-art
performance in many graph-based applications. Despite the high expressive
power, they typically need to perform an expensive recursive neighborhood
expansion in multiple training epochs and face a scalability issue. Moreover,
most of them are inflexible since they are restricted to fixed-hop
neighborhoods and insensitive to actual receptive field demands for different
nodes. We circumvent these limitations by introducing a scalable and flexible
Graph Attention Multilayer Perceptron (GAMLP). With the separation of the
non-linear transformation and feature propagation, GAMLP significantly improves
the scalability and efficiency by performing the propagation procedure in a
pre-compute manner. With three principled receptive field attention, each node
in GAMLP is flexible and adaptive in leveraging the propagated features over
the different sizes of reception field. We conduct extensive evaluations on the
three large open graph benchmarks (e.g., ogbn-papers100M, ogbn-products and
ogbn-mag), demonstrating that GAMLP not only achieves the state-of-art
performance, but also additionally provide high scalability and efficiency.

    

### [[2012.09632] From Weakly Supervised Learning to Biquality Learning: an Introduction](http://arxiv.org/abs/2012.09632)


  The field of Weakly Supervised Learning (WSL) has recently seen a surge of
popularity, with numerous papers addressing different types of "supervision
deficiencies". In WSL use cases, a variety of situations exists where the
collected "information" is imperfect. The paradigm of WSL attempts to list and
cover these problems with associated solutions. In this paper, we review the
research progress on WSL with the aim to make it as a brief introduction to
this field. We present the three axis of WSL cube and an overview of most of
all the elements of their facets. We propose three measurable quantities that
acts as coordinates in the previously defined cube namely: Quality,
Adaptability and Quantity of information. Thus we suggest that Biquality
Learning framework can be defined as a plan of the WSL cube and propose to
re-discover previously unrelated patches in WSL literature as a unified
Biquality Learning literature.

    

### [[2109.03934] Resistive Neural Hardware Accelerators](http://arxiv.org/abs/2109.03934)


  Deep Neural Networks (DNNs), as a subset of Machine Learning (ML) techniques,
entail that real-world data can be learned and that decisions can be made in
real-time. However, their wide adoption is hindered by a number of software and
hardware limitations. The existing general-purpose hardware platforms used to
accelerate DNNs are facing new challenges associated with the growing amount of
data and are exponentially increasing the complexity of computations. An
emerging non-volatile memory (NVM) devices and processing-in-memory (PIM)
paradigm is creating a new hardware architecture generation with increased
computing and storage capabilities. In particular, the shift towards
ReRAM-based in-memory computing has great potential in the implementation of
area and power efficient inference and in training large-scale neural network
architectures. These can accelerate the process of the IoT-enabled AI
technologies entering our daily life. In this survey, we review the
state-of-the-art ReRAM-based DNN many-core accelerators, and their superiority
compared to CMOS counterparts was shown. The review covers different aspects of
hardware and software realization of DNN accelerators, their present
limitations, and future prospectives. In particular, comparison of the
accelerators shows the need for the introduction of new performance metrics and
benchmarking standards. In addition, the major concerns regarding the efficient
design of accelerators include a lack of accuracy in simulation tools for
software and hardware co-design.

    

### [[2109.04179] Optimal Mapping for Near-Term Quantum Architectures based on Rydberg Atoms](http://arxiv.org/abs/2109.04179)


  Quantum algorithms promise quadratic or exponential speedups for applications
in cryptography, chemistry and material sciences. The topologies of today's
quantum computers offer limited connectivity, leading to significant overheads
for implementing such quantum algorithms. One-dimensional topology
displacements that remedy these limits have been recently demonstrated for
architectures based on Rydberg atoms, and they are possible in principle in
photonic and ion trap architectures. We present the first optimal quantum
circuit-to-architecture mapping algorithm that exploits such one-dimensional
topology displacements. We benchmark our method on quantum circuits with up to
15 qubits and investigate the improvements compared with conventional mapping
based on inserting swap gates into the quantum circuits. Depending on
underlying technology parameters, our approach can decrease the quantum circuit
depth by up to 58% and increase the fidelity by up to 29%. We also study
runtime and fidelity requirements on one-dimensional displacements and swap
gates to derive conditions under which one-dimensional topology displacements
provide benefits.

    

### [[2104.05532] GhostMinion: A Strictness-Ordered Cache System for Spectre Mitigation](http://arxiv.org/abs/2104.05532)


  Out-of-order speculation, a technique ubiquitous since the early 1990s,
remains a fundamental security flaw. Via attacks such as Spectre and Meltdown,
an attacker can trick a victim, in an otherwise entirely correct program, into
leaking its secrets through the effects of misspeculated execution, in a way
that is entirely invisible to the programmer's model. This has serious
implications for application sandboxing and inter-process communication.
Designing efficient mitigations, that preserve the performance of
out-of-order execution, has been a challenge. The speculation-hiding techniques
in the literature have been shown to not close such channels comprehensively,
allowing adversaries to redesign attacks. Strong, precise guarantees are
necessary, but at the same time mitigations must achieve high performance to be
adopted. We present Strictness Ordering, a new constraint system that shows how
we can comprehensively eliminate transient side channel attacks, while still
allowing complex speculation and data forwarding between speculative
instructions. We then present GhostMinion, a cache modification built using a
variety of new techniques designed to provide Strictness Order at only 2.5%
overhead.

    

### [[2109.03877] Computational Polarization: An Information-theoretic Method for Resilient Computing](http://arxiv.org/abs/2109.03877)


  We introduce an error resilient distributed computing method based on an
extension of the channel polarization phenomenon to distributed algorithms. The
method leverages an algorithmic split operation that transforms two identical
compute nodes to slow and fast workers, which parallels the channel split
operation in Polar Codes. This operation preserves the average runtime,
analogous to the conservation of Shannon capacity in channel polarization. By
leveraging a recursive construction in a similar spirit to the Fast Fourier
Transform, this method synthesizes virtual compute nodes with dispersed return
time distributions, which we call computational polarization. We show that the
runtime distributions form a functional martingale processes, identify their
limiting distributions in closed-form expressions together with non-asymptotic
convergence rates, and prove strong convergence results in Banach spaces. We
provide an information-theoretic lower bound on the overall runtime of any
coded computation method and show that the computational polarization approach
asymptotically achieves the optimal runtime for computing linear functions. An
important advantage is the near linear time decoding procedure, which is
significantly cheaper than Maximum Distance Separable codes.

    

### [[2109.03901] Renovation of EdgeCloudSim: An Efficient Discrete-Event Approach](http://arxiv.org/abs/2109.03901)


  Due to the growing popularity of the Internet of Things, edge computing
concept has been widely studied to relieve the load on the original cloud and
networks while improving the service quality for end-users. To simulate such a
complex environment involving edge and cloud computing, EdgeCloudSim has been
widely adopted. However, it suffers from certain efficiency and scalability
issues due to the ignorance of the deficiency in the originally adopted data
structures and maintenance strategies. Specifically, it generates all events at
beginning of the simulation and stores unnecessary historical information, both
result in unnecessarily high complexity for search operations. In this work, by
fixing the mismatches on the concept of discrete-event simulation, we propose
enhancement of EdgeCloudSim which improves not only the runtime efficiency of
simulation, but also the flexibility and scalability. Through extensive
experiments with statistical methods, we show that the enhancement does not
affect the expressiveness of simulations while obtaining 2 orders of magnitude
speedup, especially when the device count is large.

    

### [[2109.03913] BMS: Secure Decentralized Reconfiguration for Blockchain and BFT Systems](http://arxiv.org/abs/2109.03913)


  Reconfiguration of long-lived blockchain and Byzantine fault-tolerant (BFT)
systems poses fundamental security challenges. In case of state-of-the-art
Proof-of-Stake (PoS) blockchains, stake reconfiguration enables so-called
long-range attacks, which can lead to forks. Similarly, permissioned blockchain
systems, typically based on BFT, reconfigure internally, which makes them
susceptible to a similar "I still work here" attack.
In this work, we propose BMS (Blockchain/BFT Membership Service) offering a
secure and dynamic reconfiguration service for BFT and blockchain systems,
preventing long-range and similar attacks. In particular: (1) we propose a root
BMS for permissioned blockchains, implemented as an Ethereum smart contract and
evaluate it reconfiguring the recently proposed Mir-BFT protocol, (2) we
discuss how our BMS extends to PoS blockchains and how it can reduce PoS stake
unbonding time from weeks/months to the order of minutes, and (3) we discuss
possible extensions of BMS to hierarchical deployments as well as to multiple
root BMSs.

    

### [[2109.04067] Towards Sustainable Energy-Efficient Data Centers in Africa](http://arxiv.org/abs/2109.04067)


  Developing nations are particularly susceptible to the adverse effects of
global warming. By 2040, 14 percent of global emissions will come from data
centers. This paper presents early findings in the use AI and digital twins to
model and optimize data center operations.

    

### [[2109.04142] An Effective Parallel Program Debugging Approach Based on Timing Annotation](http://arxiv.org/abs/2109.04142)


  We propose an effective parallel program debugging approach based on the
timing annotation technique. With prevalent multi-core platforms, parallel
programming is required to fully utilize the computing power. However, the
non-determinism property and the associated concurrency bugs are notorious and
remain to be great challenge to designers. We hence propose an effective
program debugging approach using the timing annotation technique derived from
the deterministic Multi-Core Instruction Set Simulation (MCISS) technology. We
hence construct a deterministic execution environment for parallel program
debugging and devise a few unique, effective and easy-to-use parallel debugging
functions. We modify QEMU and GDB to implement and demonstrate our proposed
idea. The usage of our debugger is almost identical to the conventional GDB
debugger. Therefore, users may learn how to use the tool seamlessly.

    

### [[2109.04269] Asynchronous Federated Learning on Heterogeneous Devices: A Survey](http://arxiv.org/abs/2109.04269)


  Federated learning (FL) is experiencing a fast booming with the wave of
distributed machine learning and ever-increasing privacy concerns. In the FL
paradigm, global model aggregation is handled by a centralized aggregate server
based on local updated gradients trained on local nodes, which mitigates
privacy leakage caused by the collection of sensitive information. With the
increased computing and communicating capabilities of edge and IoT devices,
applying FL on heterogeneous devices to train machine learning models becomes a
trend. The synchronous aggregation strategy in the classic FL paradigm cannot
effectively use the resources, especially on heterogeneous devices, due to its
waiting for straggler devices before aggregation in each training round.
Furthermore, in real-world scenarios, the disparity of data dispersed on
devices (i.e. data heterogeneity) downgrades the accuracy of models. As a
result, many asynchronous FL (AFL) paradigms are presented in various
application scenarios to improve efficiency, performance, privacy, and
security. This survey comprehensively analyzes and summarizes existing variants
of AFL according to a novel classification mechanism, including device
heterogeneity, data heterogeneity, privacy and security on heterogeneous
devices, and applications on heterogeneous devices. Finally, this survey
reveals rising challenges and presents potentially promising research
directions in this under-investigated field.

    

### [[2102.11960] Design and Analysis of a Logless Dynamic Reconfiguration Protocol](http://arxiv.org/abs/2102.11960)


  Distributed replication systems based on the replicated state machine model
have become ubiquitous as the foundation of modern database systems. To ensure
availability in the presence of faults, these systems must be able to
dynamically replace failed nodes with healthy ones via dynamic reconfiguration.
MongoDB is a document oriented database with a distributed replication
mechanism derived from the Raft protocol. In this paper, we present
MongoRaftReconfig, a novel dynamic reconfiguration protocol for the MongoDB
replication system. MongoRaftReconfig utilizes a logless approach to managing
configuration state and decouples the processing of configuration changes from
the main database operation log. The protocol's design was influenced by
engineering constraints faced when attempting to redesign an unsafe, legacy
reconfiguration mechanism that existed previously in MongoDB. We provide a
safety proof of MongoRaftReconfig, along with a formal specification in TLA+.
To our knowledge, this is the first published safety proof and formal
specification of a reconfiguration protocol for a Raft-based system. We also
present results from model checking its safety properties on finite protocol
instances. Finally, we discuss the conceptual novelties of MongoRaftReconfig,
how it can be understood as an optimized and generalized version of the single
server reconfiguration algorithm of Raft, and present an experimental
evaluation of how its optimizations can provide performance benefits for
reconfigurations.

    

### [[2105.11236] Parallel Finite Volume Code for Plasma with Unstructured Adaptive Mesh Refinement](http://arxiv.org/abs/2105.11236)


  The present paper describes a parallel unstructured-mesh Plasma simulation
code based on Finite Volume method. The code dynamically refines and coarses
mesh for accurate resolution of the different features regarding the electron
density. Our purpose is to examine the performance of a new Parallel Adaptive
Mesh Refinement (PAMR) procedure introduced on the ADAPT platform, which
resolves of a relatively complicated system coupling the flow partial
differential equations to the Poisson's equation. The implementation deals with
the MUMPS parallel multi-frontal direct solver and mesh partitioning methods
using METIS to improve the performance of the framework. The standard MPI is
used to establish communication between processors. Performance analysis of the
PAMR procedure shows the efficiency and the potential of the method for the
propagation equations of ionization waves.

    

### [[2105.12880] The Petascale DTN Project: High Performance Data Transfer for HPC Facilities](http://arxiv.org/abs/2105.12880)


  The movement of large-scale (tens of Terabytes and larger) data sets between
high performance computing (HPC) facilities is an important and increasingly
critical capability. A growing number of scientific collaborations rely on HPC
facilities for tasks which either require large-scale data sets as input or
produce large-scale data sets as output. In order to enable the transfer of
these data sets as needed by the scientific community, HPC facilities must
design and deploy the appropriate data transfer capabilities to allow users to
do data placement at scale.
This paper describes the Petascale DTN Project, an effort undertaken by four
HPC facilities, which succeeded in achieving routine data transfer rates of
over 1PB/week between the facilities. We describe the design and configuration
of the Data Transfer Node (DTN) clusters used for large-scale data transfers at
these facilities, the software tools used, and the performance tuning that
enabled this capability.

    

### [[2109.03861] Recurrent Neural Network Controllers Synthesis with Stability Guarantees for Partially Observed Systems](http://arxiv.org/abs/2109.03861)


  Neural network controllers have become popular in control tasks thanks to
their flexibility and expressivity. Stability is a crucial property for
safety-critical dynamical systems, while stabilization of partially observed
systems, in many cases, requires controllers to retain and process long-term
memories of the past. We consider the important class of recurrent neural
networks (RNN) as dynamic controllers for nonlinear uncertain
partially-observed systems, and derive convex stability conditions based on
integral quadratic constraints, S-lemma and sequential convexification. To
ensure stability during the learning and control process, we propose a
projected policy gradient method that iteratively enforces the stability
conditions in the reparametrized space taking advantage of mild additional
information on system dynamics. Numerical experiments show that our method
learns stabilizing controllers while using fewer samples and achieving higher
final performance compared with policy gradient.

    

### [[2109.03918] Quality-Diversity Meta-Evolution: customising behaviour spaces to a meta-objective](http://arxiv.org/abs/2109.03918)


  Quality-Diversity (QD) algorithms evolve behaviourally diverse and
high-performing solutions. To illuminate the elite solutions for a space of
behaviours, QD algorithms require the definition of a suitable behaviour space.
If the behaviour space is high-dimensional, a suitable dimensionality reduction
technique is required to maintain a limited number of behavioural niches. While
current methodologies for automated behaviour spaces focus on changing the
geometry or on unsupervised learning, there remains a need for customising
behavioural diversity to a particular meta-objective specified by the end-user.
In the newly emerging framework of QD Meta-Evolution, or QD-Meta for short, one
evolves a population of QD algorithms, each with different algorithmic and
representational characteristics, to optimise the algorithms and their
resulting archives to a user-defined meta-objective. Despite promising results
compared to traditional QD algorithms, QD-Meta has yet to be compared to
state-of-the-art behaviour space automation methods such as Centroidal Voronoi
Tessellations Multi-dimensional Archive of Phenotypic Elites Algorithm
(CVT-MAP-Elites) and Autonomous Robots Realising their Abilities (AURORA). This
paper performs an empirical study of QD-Meta on function optimisation and
multilegged robot locomotion benchmarks. Results demonstrate that QD-Meta
archives provide improved average performance and faster adaptation to a priori
unknown changes to the environment when compared to CVT-MAP-Elites and AURORA.
A qualitative analysis shows how the resulting archives are tailored to the
meta-objectives provided by the end-user.

    

### [[2109.03939] What's Hidden in a One-layer Randomly Weighted Transformer?](http://arxiv.org/abs/2109.03939)


  We demonstrate that, hidden within one-layer randomly weighted neural
networks, there exist subnetworks that can achieve impressive performance,
without ever modifying the weight initializations, on machine translation
tasks. To find subnetworks for one-layer randomly weighted neural networks, we
apply different binary masks to the same weight matrix to generate different
layers. Hidden within a one-layer randomly weighted Transformer, we find that
subnetworks that can achieve 29.45/17.29 BLEU on IWSLT14/WMT14. Using a fixed
pre-trained embedding layer, the previously found subnetworks are smaller than,
but can match 98%/92% (34.14/25.24 BLEU) of the performance of, a trained
Transformer small/base on IWSLT14/WMT14. Furthermore, we demonstrate the
effectiveness of larger and deeper transformers in this setting, as well as the
impact of different initialization methods. We released the source code at
this https URL.

    

### [[2109.03952] Attributing Fair Decisions with Attention Interventions](http://arxiv.org/abs/2109.03952)


  The widespread use of Artificial Intelligence (AI) in consequential domains,
such as healthcare and parole decision-making systems, has drawn intense
scrutiny on the fairness of these methods. However, ensuring fairness is often
insufficient as the rationale for a contentious decision needs to be audited,
understood, and defended. We propose that the attention mechanism can be used
to ensure fair outcomes while simultaneously providing feature attributions to
account for how a decision was made. Toward this goal, we design an
attention-based model that can be leveraged as an attribution framework. It can
identify features responsible for both performance and fairness of the model
through attention interventions and attention weight manipulation. Using this
attribution framework, we then design a post-processing bias mitigation
strategy and compare it with a suite of baselines. We demonstrate the
versatility of our approach by conducting experiments on two distinct data
types, tabular and textual.

    

### [[2109.03958] TrAISformer-A generative transformer for AIS trajectory prediction](http://arxiv.org/abs/2109.03958)


  Modelling trajectory in general, and vessel trajectory in particular, is a
difficult task because of the multimodal and complex nature of motion data. In
this paper, we present TrAISformer-a novel deep learning architecture that can
forecast vessel positions using AIS (Automatic Identification System)
observations. We address the multimodality by introducing a discrete
representation of AIS data and re-frame the prediction, which is originally a
regression problem, as a classification problem. The model encodes complex
movement patterns in AIS data in high-dimensional vectors, then applies a
transformer to extract useful long-term correlations from sequences of those
embeddings to sample future vessel positions. Experimental results on real,
public AIS data demonstrate that TrAISformer significantly outperforms
state-of-the-art methods.

    

### [[2109.04004] OpenClinicalAI: enabling AI to diagnose diseases in real-world clinical settings](http://arxiv.org/abs/2109.04004)


  This paper quantitatively reveals the state-of-the-art and
state-of-the-practice AI systems only achieve acceptable performance on the
stringent conditions that all categories of subjects are known, which we call
closed clinical settings, but fail to work in real-world clinical settings.
Compared to the diagnosis task in the closed setting, real-world clinical
settings pose severe challenges, and we must treat them differently. We build a
clinical AI benchmark named Clinical AIBench to set up real-world clinical
settings to facilitate researches. We propose an open, dynamic machine learning
framework and develop an AI system named OpenClinicalAI to diagnose diseases in
real-world clinical settings. The first versions of Clinical AIBench and
OpenClinicalAI target Alzheimer's disease. In the real-world clinical setting,
OpenClinicalAI significantly outperforms the state-of-the-art AI system. In
addition, OpenClinicalAI develops personalized diagnosis strategies to avoid
unnecessary testing and seamlessly collaborates with clinicians. It is
promising to be embedded in the current medical systems to improve medical
services.

    

### [[2109.04037] Trust-ya: design of a multiplayer game for the study of small group processes](http://arxiv.org/abs/2109.04037)


  This paper presents the design of a cooperative multi-player betting game,
Trust-ya, as a model of some elements of status processes in human groups. The
game is designed to elicit status-driven leader-follower behaviours as a means
to observe and influence social hierarchy. It involves a Bach/Stravinsky game
of deference in a group, in which people on each turn can either invest with
another player or hope someone invests with them. Players who receive
investment capital are able to gamble for payoffs from a central pool which
then can be shared back with those who invested (but a portion of it may be
kept, including all of it). The bigger gambles (people with more investors) get
bigger payoffs. Thus, there is a natural tendency for players to coalesce as
investors around a 'leader' who gambles, but who also shares sufficiently from
their winnings to keep the investors 'hanging on'. The 'leader' will want to
keep as much as possible for themselves, however. The game is played
anonymously, but a set of 'status symbols' can be purchased which have no value
in the game itself, but can serve as a 'cheap talk' communication device with
other players. This paper introduces the game, relates it to status theory in
social psychology, and shows some simple simulated and human experiments that
demonstrate how the game can be used to study status processes and dynamics in
human groups.

    

### [[2109.04047] ACP++: Action Co-occurrence Priors for Human-Object Interaction Detection](http://arxiv.org/abs/2109.04047)


  A common problem in the task of human-object interaction (HOI) detection is
that numerous HOI classes have only a small number of labeled examples,
resulting in training sets with a long-tailed distribution. The lack of
positive labels can lead to low classification accuracy for these classes.
Towards addressing this issue, we observe that there exist natural correlations
and anti-correlations among human-object interactions. In this paper, we model
the correlations as action co-occurrence matrices and present techniques to
learn these priors and leverage them for more effective training, especially on
rare classes. The efficacy of our approach is demonstrated experimentally,
where the performance of our approach consistently improves over the
state-of-the-art methods on both of the two leading HOI detection benchmark
datasets, HICO-Det and V-COCO.

    

### [[2109.04049] BeamTransformer: Microphone Array-based Overlapping Speech Detection](http://arxiv.org/abs/2109.04049)


  We propose BeamTransformer, an efficient architecture to leverage
beamformer's edge in spatial filtering and transformer's capability in context
sequence modeling. BeamTransformer seeks to optimize modeling of sequential
relationship among signals from different spatial direction. Overlapping speech
detection is one of the tasks where such optimization is favorable. In this
paper we effectively apply BeamTransformer to detect overlapping segments.
Comparing to single-channel approach, BeamTransformer exceeds in learning to
identify the relationship among different beam sequences and hence able to make
predictions not only from the acoustic signals but also the localization of the
source. The results indicate that a successful incorporation of microphone
array signals can lead to remarkable gains. Moreover, BeamTransformer takes one
step further, as speech from overlapped speakers have been internally separated
into different beams.

    

### [[2109.04082] Risk-Averse Decision Making Under Uncertainty](http://arxiv.org/abs/2109.04082)


  A large class of decision making under uncertainty problems can be described
via Markov decision processes (MDPs) or partially observable MDPs (POMDPs),
with application to artificial intelligence and operations research, among
others. Traditionally, policy synthesis techniques are proposed such that a
total expected cost or reward is minimized or maximized. However, optimality in
the total expected cost sense is only reasonable if system behavior in the
large number of runs is of interest, which has limited the use of such policies
in practical mission-critical scenarios, wherein large deviations from the
expected behavior may lead to mission failure. In this paper, we consider the
problem of designing policies for MDPs and POMDPs with objectives and
constraints in terms of dynamic coherent risk measures, which we refer to as
the constrained risk-averse problem. For MDPs, we reformulate the problem into
a infsup problem via the Lagrangian framework and propose an optimization-based
method to synthesize Markovian policies. For MDPs, we demonstrate that the
formulated optimization problems are in the form of difference convex programs
(DCPs) and can be solved by the disciplined convex-concave programming (DCCP)
framework. We show that these results generalize linear programs for
constrained MDPs with total discounted expected costs and constraints. For
POMDPs, we show that, if the coherent risk measures can be defined as a Markov
risk transition mapping, an infinite-dimensional optimization can be used to
design Markovian belief-based policies. For stochastic finite-state controllers
(FSCs), we show that the latter optimization simplifies to a
(finite-dimensional) DCP and can be solved by the DCCP framework. We
incorporate these DCPs in a policy iteration algorithm to design risk-averse
FSCs for POMDPs.

    

### [[2109.04083] User Tampering in Reinforcement Learning Recommender Systems](http://arxiv.org/abs/2109.04083)


  This paper provides the first formalisation and empirical demonstration of a
particular safety concern in reinforcement learning (RL)-based news and social
media recommendation algorithms. This safety concern is what we call "user
tampering" -- a phenomenon whereby an RL-based recommender system may
manipulate a media user's opinions, preferences and beliefs via its
recommendations as part of a policy to increase long-term user engagement. We
provide a simulation study of a media recommendation problem constrained to the
recommendation of political content, and demonstrate that a Q-learning
algorithm consistently learns to exploit its opportunities to 'polarise'
simulated 'users' with its early recommendations in order to have more
consistent success with later recommendations catering to that polarisation.
Finally, we argue that given our findings, designing an RL-based recommender
system which cannot learn to exploit user tampering requires making the metric
for the recommender's success independent of observable signals of user
engagement, and thus that a media recommendation system built solely with RL is
necessarily either unsafe, or almost certainly commercially unviable.

    

### [[2109.04096] A Three-Stage Learning Framework for Low-Resource Knowledge-Grounded Dialogue Generation](http://arxiv.org/abs/2109.04096)


  Neural conversation models have shown great potentials towards generating
fluent and informative responses by introducing external background knowledge.
Nevertheless, it is laborious to construct such knowledge-grounded dialogues,
and existing models usually perform poorly when transfer to new domains with
limited training samples. Therefore, building a knowledge-grounded dialogue
system under the low-resource setting is a still crucial issue. In this paper,
we propose a novel three-stage learning framework based on weakly supervised
learning which benefits from large scale ungrounded dialogues and unstructured
knowledge base. To better cooperate with this framework, we devise a variant of
Transformer with decoupled decoder which facilitates the disentangled learning
of response generation and knowledge incorporation. Evaluation results on two
benchmarks indicate that our approach can outperform other state-of-the-art
methods with less training data, and even in zero-resource scenario, our
approach still performs well.

    

### [[2109.04100] Taming Self-Supervised Learning for Presentation Attack Detection: In-Image De-Folding and Out-of-Image De-Mixing](http://arxiv.org/abs/2109.04100)


  Biometric systems are vulnerable to the Presentation Attacks (PA) performed
using various Presentation Attack Instruments (PAIs). Even though there are
numerous Presentation Attack Detection (PAD) techniques based on both deep
learning and hand-crafted features, the generalization of PAD for unknown PAI
is still a challenging problem. The common problem with existing deep
learning-based PAD techniques is that they may struggle with local optima,
resulting in weak generalization against different PAs. In this work, we
propose to use self-supervised learning to find a reasonable initialization
against local trap, so as to improve the generalization ability in detecting
PAs on the biometric system.The proposed method, denoted as IF-OM, is based on
a global-local view coupled with De-Folding and De-Mixing to derive the
task-specific representation for PAD.During De-Folding, the proposed technique
will learn region-specific features to represent samples in a local pattern by
explicitly maximizing cycle consistency. While, De-Mixing drives detectors to
obtain the instance-specific features with global information for more
comprehensive representation by maximizing topological consistency. Extensive
experimental results show that the proposed method can achieve significant
improvements in terms of both face and fingerprint PAD in more complicated and
hybrid datasets, when compared with the state-of-the-art methods. Specifically,
when training in CASIA-FASD and Idiap Replay-Attack, the proposed method can
achieve 18.60% Equal Error Rate (EER) in OULU-NPU and MSU-MFSD, exceeding
baseline performance by 9.54%. Code will be made publicly available.

    

### [[2109.04108] MapRE: An Effective Semantic Mapping Approach for Low-resource Relation Extraction](http://arxiv.org/abs/2109.04108)


  Neural relation extraction models have shown promising results in recent
years; however, the model performance drops dramatically given only a few
training samples. Recent works try leveraging the advance in few-shot learning
to solve the low resource problem, where they train label-agnostic models to
directly compare the semantic similarities among context sentences in the
embedding space. However, the label-aware information, i.e., the relation label
that contains the semantic knowledge of the relation itself, is often neglected
for prediction. In this work, we propose a framework considering both
label-agnostic and label-aware semantic mapping information for low resource
relation extraction. We show that incorporating the above two types of mapping
information in both pretraining and fine-tuning can significantly improve the
model performance on low-resource relation extraction tasks.

    

### [[2109.04137] Fusing task-oriented and open-domain dialogues in conversational agents](http://arxiv.org/abs/2109.04137)


  The goal of building intelligent dialogue systems has largely been
\textit{separately} pursued under two paradigms: task-oriented dialogue (TOD)
systems, which perform goal-oriented functions, and open-domain dialogue (ODD)
systems, which focus on non-goal-oriented chitchat. The two dialogue modes can
potentially be intertwined together seamlessly in the same conversation, as
easily done by a friendly human assistant. Such ability is desirable in
conversational agents, as the integration makes them more accessible and
useful. Our paper addresses this problem of fusing TODs and ODDs in multi-turn
dialogues. Based on the popular TOD dataset MultiWOZ, we build a new dataset
FusedChat, by rewriting the existing TOD turns and adding new ODD turns. This
procedure constructs conversation sessions containing exchanges from both
dialogue modes. It features inter-mode contextual dependency, i.e., the
dialogue turns from the two modes depend on each other. Rich dependency
patterns including co-reference and ellipsis are features. The new dataset,
with 60k new human-written ODD turns and 5k re-written TOD turns, offers a
benchmark to test a dialogue model's ability to perform inter-mode
conversations. This is a more challenging task since the model has to determine
the appropriate dialogue mode and generate the response based on the inter-mode
context. But such models would better mimic human-level conversation
capabilities. We evaluate baseline models on this task, including
\textit{classification-based} two-stage models and \textit{two-in-one} fused
models. We publicly release FusedChat and the baselines to propel future work
on inter-mode dialogue systems this https URL.

    

### [[2109.04139] Robot Localization and Navigation through Predictive Processing using LiDAR](http://arxiv.org/abs/2109.04139)


  Knowing the position of the robot in the world is crucial for navigation.
Nowadays, Bayesian filters, such as Kalman and particle-based, are standard
approaches in mobile robotics. Recently, end-to-end learning has allowed for
scaling-up to high-dimensional inputs and improved generalization. However,
there are still limitations to providing reliable laser navigation. Here we
show a proof-of-concept of the predictive processing-inspired approach to
perception applied for localization and navigation using laser sensors, without
the need for odometry. We learn the generative model of the laser through
self-supervised learning and perform both online state-estimation and
navigation through stochastic gradient descent on the variational free-energy
bound. We evaluated the algorithm on a mobile robot (TIAGo Base) with a laser
sensor (SICK) in Gazebo. Results showed improved state-estimation performance
when comparing to a state-of-the-art particle filter in the absence of
odometry. Furthermore, conversely to standard Bayesian estimation approaches
our method also enables the robot to navigate when providing the desired goal
by inferring the actions that minimize the prediction error.

    

### [[2109.04144] Avoiding Inference Heuristics in Few-shot Prompt-based Finetuning](http://arxiv.org/abs/2109.04144)


  Recent prompt-based approaches allow pretrained language models to achieve
strong performances on few-shot finetuning by reformulating downstream tasks as
a language modeling problem. In this work, we demonstrate that, despite its
advantages on low data regimes, finetuned prompt-based models for sentence pair
classification tasks still suffer from a common pitfall of adopting inference
heuristics based on lexical overlap, e.g., models incorrectly assuming a
sentence pair is of the same meaning because they consist of the same set of
words. Interestingly, we find that this particular inference heuristic is
significantly less present in the zero-shot evaluation of the prompt-based
model, indicating how finetuning can be destructive to useful knowledge learned
during the pretraining. We then show that adding a regularization that
preserves pretraining weights is effective in mitigating this destructive
tendency of few-shot finetuning. Our evaluation on three datasets demonstrates
promising improvements on the three corresponding challenge datasets used to
diagnose the inference heuristics.

    

### [[2109.04152] Lexico-semantic and affective modelling of Spanish poetry: A semi-supervised learning approach](http://arxiv.org/abs/2109.04152)


  Text classification tasks have improved substantially during the last years
by the usage of transformers. However, the majority of researches focus on
prose texts, with poetry receiving less attention, specially for Spanish
language. In this paper, we propose a semi-supervised learning approach for
inferring 21 psychological categories evoked by a corpus of 4572 sonnets, along
with 10 affective and lexico-semantic multiclass ones. The subset of poems used
for training an evaluation includes 270 sonnets. With our approach, we achieve
an AUC beyond 0.7 for 76% of the psychological categories, and an AUC over 0.65
for 60% on the multiclass ones. The sonnets are modelled using transformers,
through sentence embeddings, along with lexico-semantic and affective features,
obtained by using external lexicons. Consequently, we see that this approach
provides an AUC increase of up to 0.12, as opposed to using transformers alone.

    

### [[2109.04155] Deep Active Inference for Pixel-Based Discrete Control: Evaluation on the Car Racing Problem](http://arxiv.org/abs/2109.04155)


  Despite the potential of active inference for visual-based control, learning
the model and the preferences (priors) while interacting with the environment
is challenging. Here, we study the performance of a deep active inference
(dAIF) agent on OpenAI's car racing benchmark, where there is no access to the
car's state. The agent learns to encode the world's state from high-dimensional
input through unsupervised representation learning. State inference and control
are learned end-to-end by optimizing the expected free energy. Results show
that our model achieves comparable performance to deep Q-learning. However,
vanilla dAIF does not reach state-of-the-art performance compared to other
world model approaches. Hence, we discuss the current model implementation's
limitations and potential architectures to overcome them.

    

### [[2109.04171] From Philosophy to Interfaces: an Explanatory Method and a Tool Inspired by Achinstein's Theory of Explanation](http://arxiv.org/abs/2109.04171)


  We propose a new method for explanations in Artificial Intelligence (AI) and
a tool to test its expressive power within a user interface. In order to bridge
the gap between philosophy and human-computer interfaces, we show a new
approach for the generation of interactive explanations based on a
sophisticated pipeline of AI algorithms for structuring natural language
documents into knowledge graphs, answering questions effectively and
satisfactorily. Among the mainstream philosophical theories of explanation we
identified one that in our view is more easily applicable as a practical model
for user-centric tools: Achinstein's Theory of Explanation. With this work we
aim to prove that the theory proposed by Achinstein can be actually adapted for
being implemented into a concrete software application, as an interactive
process answering questions. To this end we found a way to handle the generic
(archetypal) questions that implicitly characterise an explanatory processes as
preliminary overviews rather than as answers to explicit questions, as commonly
understood. To show the expressive power of this approach we designed and
implemented a pipeline of AI algorithms for the generation of interactive
explanations under the form of overviews, focusing on this aspect of
explanations rather than on existing interfaces and presentation logic layers
for question answering. We tested our hypothesis on a well-known XAI-powered
credit approval system by IBM, comparing CEM, a static explanatory tool for
post-hoc explanations, with an extension we developed adding interactive
explanations based on our model. The results of the user study, involving more
than 100 participants, showed that our proposed solution produced a
statistically relevant improvement on effectiveness (U=931.0, p=0.036) over the
baseline, thus giving evidence in favour of our theory.

    

### [[2109.04176] Towards Transferable Adversarial Attacks on Vision Transformers](http://arxiv.org/abs/2109.04176)


  Vision transformers (ViTs) have demonstrated impressive performance on a
series of computer vision tasks, yet they still suffer from adversarial
examples. In this paper, we posit that adversarial attacks on transformers
should be specially tailored for their architecture, jointly considering both
patches and self-attention, in order to achieve high transferability. More
specifically, we introduce a dual attack framework, which contains a Pay No
Attention (PNA) attack and a PatchOut attack, to improve the transferability of
adversarial samples across different ViTs. We show that skipping the gradients
of attention during backpropagation can generate adversarial examples with high
transferability. In addition, adversarial perturbations generated by optimizing
randomly sampled subsets of patches at each iteration achieve higher attack
success rates than attacks using all patches. We evaluate the transferability
of attacks on state-of-the-art ViTs, CNNs and robustly trained CNNs. The
results of these experiments demonstrate that the proposed dual attack can
greatly boost transferability between ViTs and from ViTs to CNNs. In addition,
the proposed method can easily be combined with existing transfer methods to
boost performance.

    

### [[2109.04197] A distillation-based approach integrating continual learning and federated learning for pervasive services](http://arxiv.org/abs/2109.04197)


  Federated Learning, a new machine learning paradigm enhancing the use of edge
devices, is receiving a lot of attention in the pervasive community to support
the development of smart services. Nevertheless, this approach still needs to
be adapted to the specificity of the pervasive domain. In particular, issues
related to continual learning need to be addressed. In this paper, we present a
distillation-based approach dealing with catastrophic forgetting in federated
learning scenario. Specifically, Human Activity Recognition tasks are used as a
demonstration domain.

    

### [[2109.04200] Double-Scale Self-Supervised Hypergraph Learning for Group Recommendation](http://arxiv.org/abs/2109.04200)


  With the prevalence of social media, there has recently been a proliferation
of recommenders that shift their focus from individual modeling to group
recommendation. Since the group preference is a mixture of various
predilections from group members, the fundamental challenge of group
recommendation is to model the correlations among members. Existing methods
mostly adopt heuristic or attention-based preference aggregation strategies to
synthesize group preferences. However, these models mainly focus on the
pairwise connections of users and ignore the complex high-order interactions
within and beyond groups. Besides, group recommendation suffers seriously from
the problem of data sparsity due to severely sparse group-item interactions. In
this paper, we propose a self-supervised hypergraph learning framework for
group recommendation to achieve two goals: (1) capturing the intra- and
inter-group interactions among users; (2) alleviating the data sparsity issue
with the raw data itself. Technically, for (1), a hierarchical hypergraph
convolutional network based on the user- and group-level hypergraphs is
developed to model the complex tuplewise correlations among users within and
beyond groups. For (2), we design a double-scale node dropout strategy to
create self-supervision signals that can regularize user representations with
different granularities against the sparsity issue. The experimental analysis
on multiple benchmark datasets demonstrates the superiority of the proposed
model and also elucidates the rationality of the hypergraph modeling and the
double-scale self-supervision.

    

### [[2109.04205] DAN: Decentralized Attention-based Neural Network to Solve the MinMax Multiple Traveling Salesman Problem](http://arxiv.org/abs/2109.04205)


  The multiple traveling salesman problem (mTSP) is a well-known NP-hard
problem with numerous real-world applications. In particular, this work
addresses MinMax mTSP, where the objective is to minimize the max tour length
(sum of Euclidean distances) among all agents. The mTSP is normally considered
as a combinatorial optimization problem, but due to its computational
complexity, search-based exact and heuristic algorithms become inefficient as
the number of cities increases. Encouraged by the recent developments in deep
reinforcement learning (dRL), this work considers the mTSP as a cooperative
task and introduces a decentralized attention-based neural network method to
solve the MinMax mTSP, named DAN. In DAN, agents learn fully decentralized
policies to collaboratively construct a tour, by predicting the future
decisions of other agents. Our model relies on the Transformer architecture,
and is trained using multi-agent RL with parameter sharing, which provides
natural scalability to the numbers of agents and cities. We experimentally
demonstrate our model on small- to large-scale mTSP instances, which involve 50
to 1000 cities and 5 to 20 agents, and compare against state-of-the-art
baselines. For small-scale problems (fewer than 100 cities), DAN is able to
closely match the performance of the best solver available (OR Tools, a
meta-heuristic solver) given the same computation time budget. In larger-scale
instances, DAN outperforms both conventional and dRL-based solvers, while
keeping computation times low, and exhibits enhanced collaboration among
agents.

    

### [[2109.04223] KELM: Knowledge Enhanced Pre-Trained Language Representations with Message Passing on Hierarchical Relational Graphs](http://arxiv.org/abs/2109.04223)


  Incorporating factual knowledge into pre-trained language models (PLM) such
as BERT is an emerging trend in recent NLP studies. However, most of the
existing methods combine the external knowledge integration module with a
modified pre-training loss and re-implement the pre-training process on the
large-scale corpus. Re-pretraining these models is usually resource-consuming,
and difficult to adapt to another domain with a different knowledge graph (KG).
Besides, those works either cannot embed knowledge context dynamically
according to textual context or struggle with the knowledge ambiguity issue. In
this paper, we propose a novel knowledge-aware language model framework based
on fine-tuning process, which equips PLM with a unified knowledge-enhanced text
graph that contains both text and multi-relational sub-graphs extracted from
KG. We design a hierarchical relational-graph-based message passing mechanism,
which can allow the representations of injected KG and text to mutually update
each other and can dynamically select ambiguous mentioned entities that share
the same text. Our empirical results show that our model can efficiently
incorporate world knowledge from KGs into existing language models such as
BERT, and achieve significant improvement on the machine reading comprehension
(MRC) task compared with other knowledge-enhanced models.

    

### [[2109.04321] Smoothed Contrastive Learning for Unsupervised Sentence Embedding](http://arxiv.org/abs/2109.04321)


  Contrastive learning has been gradually applied to learn high-quality
unsupervised sentence embedding. Among the previous un-supervised methods, the
latest state-of-the-art method, as far as we know, is unsupervised SimCSE
(unsup-SimCSE). Unsup-SimCSE uses the InfoNCE1loss function in the training
stage by pulling semantically similar sentences together and pushing apart
dis-similar ones.Theoretically, we expect to use larger batches in unsup-SimCSE
to get more adequate comparisons among samples and avoid overfitting. However,
increasing the batch size does not always lead to improvements, but instead
even lead to performance degradation when the batch size exceeds a threshold.
Through statistical observation, we find that this is probably due to the
introduction of low-confidence negative pairs after in-creasing the batch size.
To alleviate this problem, we introduce a simple smoothing strategy upon the
InfoNCE loss function, termedGaussian Smoothing InfoNCE
(GS-InfoNCE).Specifically, we add random Gaussian noise vectors as negative
samples, which act asa smoothing of the negative sample space.Though being
simple, the proposed smooth-ing strategy brings substantial improvements to
unsup-SimCSE. We evaluate GS-InfoNCEon the standard semantic text similarity
(STS)task. GS-InfoNCE outperforms the state-of-the-art unsup-SimCSE by an
average Spear-man correlation of 1.38%, 0.72%, 1.17% and0.28% on the base of
BERT-base, BERT-large,RoBERTa-base and RoBERTa-large, respectively.

    

### [[2109.04343] Eliciting Information with Partial Signals in Repeated Games](http://arxiv.org/abs/2109.04343)


  We consider an information elicitation game where the center needs the agent
to self-report her actual usage of a service and charges her a payment
accordingly. The center can only observe a partial signal, representing part of
the agent's true consumption, that is generated randomly from a publicly known
distribution. The agent can report any information, as long as it does not
contradict the signal, and the center issues a payment based on the reported
information. Such problems find application in prosumer pricing, tax filing,
etc., when the agent's actual consumption of a service is masked from the
center and verification of the submitted reports is impractical. The key
difference between the current problem and classic information elicitation
problems is that the agent gets to observe the full signal and act
strategically, but the center can only see the partial signal. For this
seemingly impossible problem, we propose a penalty mechanism that elicits
truthful self-reports in a repeated game. In particular, besides charging the
agent the reported value, the mechanism charges a penalty proportional to her
inconsistent reports. We show how a combination of the penalty rate and the
length of the game incentivizes the agent to be truthful for the entire game, a
phenomenon we call "fear of tomorrow verification". We show how approximate
results for arbitrary distributions can be obtained by analyzing Bernoulli
distributions. We extend our mechanism to a multi-agent cost sharing setting
and give equilibrium results.

    

### [[2109.04344] EvilModel 2.0: Hiding Malware Inside of Neural Network Models](http://arxiv.org/abs/2109.04344)


  While artificial intelligence (AI) is widely applied in various areas, it is
also being used maliciously. It is necessary to study and predict AI-powered
attacks to prevent them in advance. Turning neural network models into
stegomalware is a malicious use of AI, which utilizes the features of neural
network models to hide malware while maintaining the performance of the models.
However, the existing methods have a low malware embedding rate and a high
impact on the model performance, making it not practical. Therefore, by
analyzing the composition of the neural network models, this paper proposes new
methods to embed malware in models with high capacity and no service quality
degradation. We used 19 malware samples and 10 mainstream models to build 550
malware-embedded models and analyzed the models' performance on ImageNet
dataset. A new evaluation method that combines the embedding rate, the model
performance impact and the embedding effort is proposed to evaluate the
existing methods. This paper also designs a trigger and proposes an application
scenario in attack tasks combining EvilModel with WannaCry. This paper further
studies the relationship between neural network models' embedding capacity and
the model structure, layer and size. With the widespread application of
artificial intelligence, utilizing neural networks for attacks is becoming a
forwarding trend. We hope this work can provide a reference scenario for the
defense of neural network-assisted attacks.

    

### [[2109.04360] Measuring Uncertainty in Signal Fingerprinting with Gaussian Processes Going Deep](http://arxiv.org/abs/2109.04360)


  In indoor positioning, signal fluctuation is highly location-dependent.
However, signal uncertainty is one critical yet commonly overlooked dimension
of the radio signal to be fingerprinted. This paper reviews the commonly used
Gaussian Processes (GP) for probabilistic positioning and points out the
pitfall of using GP to model signal fingerprint uncertainty. This paper also
proposes Deep Gaussian Processes (DGP) as a more informative alternative to
address the issue. How DGP better measures uncertainty in signal fingerprinting
is evaluated via simulated and realistically collected datasets.

    

### [[2109.04380] ESimCSE: Enhanced Sample Building Method for Contrastive Learning of Unsupervised Sentence Embedding](http://arxiv.org/abs/2109.04380)


  Contrastive learning has been attracting much attention for learning
unsupervised sentence embeddings. The current state-of-the-art unsupervised
method is the unsupervised SimCSE (unsup-SimCSE). Unsup-SimCSE takes dropout as
a minimal data augmentation method, and passes the same input sentence to a
pre-trained Transformer encoder (with dropout turned on) twice to obtain the
two corresponding embeddings to build a positive pair. As the length
information of a sentence will generally be encoded into the sentence
embeddings due to the usage of position embedding in Transformer, each positive
pair in unsup-SimCSE actually contains the same length information. And thus
unsup-SimCSE trained with these positive pairs is probably biased, which would
tend to consider that sentences of the same or similar length are more similar
in semantics. Through statistical observations, we find that unsup-SimCSE does
have such a problem. To alleviate it, we apply a simple repetition operation to
modify the input sentence, and then pass the input sentence and its modified
counterpart to the pre-trained Transformer encoder, respectively, to get the
positive pair. Additionally, we draw inspiration from the community of computer
vision and introduce a momentum contrast, enlarging the number of negative
pairs without additional calculations. The proposed two modifications are
applied on positive and negative pairs separately, and build a new sentence
embedding method, termed Enhanced Unsup-SimCSE (ESimCSE). We evaluate the
proposed ESimCSE on several benchmark datasets w.r.t the semantic text
similarity (STS) task. Experimental results show that ESimCSE outperforms the
state-of-the-art unsup-SimCSE by an average Spearman correlation of 2.02% on
BERT-base.

    

### [[2109.04398] Neural-IMLS: Learning Implicit Moving Least-Squares for Surface Reconstruction from Unoriented Point clouds](http://arxiv.org/abs/2109.04398)


  Surface reconstruction from noisy, non-uniformly, and unoriented point clouds
is a fascinating yet difficult problem in computer vision and computer
graphics. In this paper, we propose Neural-IMLS, a novel approach that learning
noise-resistant signed distance function (SDF) for reconstruction. Instead of
explicitly learning priors with the ground-truth signed distance values, our
method learns the SDF from raw point clouds directly in a self-supervised
fashion by minimizing the loss between the couple of SDFs, one obtained by the
implicit moving least-square function (IMLS) and the other by our network.
Finally, a watertight and smooth 2-manifold triangle mesh is yielded by running
Marching Cubes. We conduct extensive experiments on various benchmarks to
demonstrate the performance of Neural-IMLS, especially for point clouds with
noise.

    

### [[1712.04182] A Generic Model for Swarm Intelligence and Its Validations](http://arxiv.org/abs/1712.04182)


  The modeling of emergent swarm intelligence constitutes a major challenge and
it has been tacked in a number of different ways. However, existing approaches
fail to capture the nature of swarm intelligence and they are either too
abstract for practical application or not generic enough to describe the
various types of emergence phenomena. In this paper, a contradiction-centric
model for swarm intelligence is proposed, in which individuals determine their
behaviors based on their internal contradictions whilst they associate and
interact to update their contradictions. The model hypothesizes that 1) the
emergence of swarm intelligence is rooted in the development of individuals'
internal contradictions and the interactions taking place between individuals
and the environment, and 2) swarm intelligence is essentially a combinative
reflection of the configurations of individuals' internal contradictions and
the distributions of these contradictions across individuals. The model is
formally described and five swarm intelligence systems are studied to
illustrate its broad applicability. The studies confirm the generic character
of the model and its effectiveness for describing the emergence of various
kinds of swarm intelligence; and they also demonstrate that the model is
straightforward to apply, without the need for complicated computations.

    

### [[2009.02995] Collaborative Management of Benchmark Instances and their Attributes](http://arxiv.org/abs/2009.02995)


  Experimental evaluation is an integral part in the design process of
algorithms. Publicly available benchmark instances are widely used to evaluate
methods in SAT solving. For the interpretation of results and the design of
algorithm portfolios their attributes are crucial. Capturing the interrelation
of benchmark instances and their attributes is considerably simplified through
our specification of a benchmark instance identifier. Thus, our tool increases
the availability of both by providing means to manage and retrieve benchmark
instances by their attributes and vice versa. Like this, it facilitates the
design and analysis of SAT experiments and the exchange of results.

    

### [[2010.06196] Mathematical Word Problem Generation from Commonsense Knowledge Graph and Equations](http://arxiv.org/abs/2010.06196)


  There is an increasing interest in the use of mathematical word problem (MWP)
generation in educational assessment. Different from standard natural question
generation, MWP generation needs to maintain the underlying mathematical
operations between quantities and variables, while at the same time ensuring
the relevance between the output and the given topic. To address above problem,
we develop an end-to-end neural model to generate diverse MWPs in real-world
scenarios from commonsense knowledge graph and equations. The proposed model
(1) learns both representations from edge-enhanced Levi graphs of symbolic
equations and commonsense knowledge; (2) automatically fuses equation and
commonsense knowledge information via a self-planning module when generating
the MWPs. Experiments on an educational gold-standard set and a large-scale
generated MWP set show that our approach is superior on the MWP generation
task, and it outperforms the SOTA models in terms of both automatic evaluation
metrics, i.e., BLEU-4, ROUGE-L, Self-BLEU, and human evaluation metrics, i.e.,
equation relevance, topic relevance, and language coherence. To encourage
reproducible results, we make our code and MWP dataset public available at
\url{this https URL}.

    

### [[2010.14693] AM-RRT*: Informed Sampling-based Planning with Assisting Metric](http://arxiv.org/abs/2010.14693)


  In this paper, we present a new algorithm that extends RRT* and RT-RRT* for
online path planning in complex, dynamic environments. Sampling-based
approaches often perform poorly in environments with narrow passages, a feature
common to many indoor applications of mobile robots as well as computer games.
Our method extends RRT-based sampling methods to enable the use of an assisting
distance metric to improve performance in environments with obstacles. This
assisting metric, which can be any metric that has better properties than the
Euclidean metric when line of sight is blocked, is used in combination with the
standard Euclidean metric in such a way that the algorithm can reap benefits
from the assisting metric while maintaining the desirable properties of
previous RRT variants - namely probabilistic completeness in tree coverage and
asymptotic optimality in path length. We also introduce a new method of
targeted rewiring, aimed at shortening search times and path lengths in tasks
where the goal shifts repeatedly. We demonstrate that our method offers
considerable improvements over existing multi-query planners such as RT-RRT*
when using diffusion distance as an assisting metric; finding near-optimal
paths with a decrease in search time of several orders of magnitude.
Experimental results show planning times reduced by 99.5% and path lengths by
9.8% over existing real-time RRT planners in a variety of environments.

    

### [[2102.11090] Position Information in Transformers: An Overview](http://arxiv.org/abs/2102.11090)


  Transformers are arguably the main workhorse in recent Natural Language
Processing research. By definition a Transformer is invariant with respect to
reordering of the input. However, language is inherently sequential and word
order is essential to the semantics and syntax of an utterance. In this
article, we provide an overview and theoretical comparison of existing methods
to incorporate position information into Transformer models. The objectives of
this survey are to (1) showcase that position information in Transformer is a
vibrant and extensive research area; (2) enable the reader to compare existing
methods by providing a unified notation and systematization of different
approaches along important model dimensions; (3) indicate what characteristics
of an application should be taken into account when selecting a position
encoding; (4) provide stimuli for future research.

    

### [[2104.06751] Is Multi-Hop Reasoning Really Explainable? Towards Benchmarking Reasoning Interpretability](http://arxiv.org/abs/2104.06751)


  Multi-hop reasoning has been widely studied in recent years to obtain more
interpretable link prediction. However, we find in experiments that many paths
given by these models are actually unreasonable, while little works have been
done on interpretability evaluation for them. In this paper, we propose a
unified framework to quantitatively evaluate the interpretability of multi-hop
reasoning models so as to advance their development. In specific, we define
three metrics including path recall, local interpretability, and global
interpretability for evaluation, and design an approximate strategy to
calculate them using the interpretability scores of rules. Furthermore, we
manually annotate all possible rules and establish a Benchmark to detect the
Interpretability of Multi-hop Reasoning (BIMR). In experiments, we run nine
baselines on our benchmark. The experimental results show that the
interpretability of current multi-hop reasoning models is less satisfactory and
is still far from the upper bound given by our benchmark. Moreover, the
rule-based models outperform the multi-hop reasoning models in terms of
performance and interpretability, which points to a direction for future
research, i.e., we should investigate how to better incorporate rule
information into the multi-hop reasoning model. Our codes and datasets can be
obtained from this https URL.

    

### [[2104.08825] Flexible Generation of Natural Language Deductions](http://arxiv.org/abs/2104.08825)


  An interpretable system for open-domain reasoning needs to express its
reasoning process in a transparent form. Natural language is an attractive
representation for this purpose -- it is both highly expressive and easy for
humans to understand. However, manipulating natural language statements in
logically consistent ways is hard: models must cope with variation in how
meaning is expressed while remaining precise. In this paper, we describe
ParaPattern, a method for building models to generate deductive inferences from
diverse natural language inputs without direct human supervision. We train
BART-based models (Lewis et al., 2020) to generate the result of applying a
particular logical operation to one or more premise statements. Crucially, we
develop a largely automated pipeline for constructing suitable training
examples from Wikipedia. We evaluate our models using out-of-domain sentence
compositions from the QASC (Khot et al., 2020) and EntailmentBank (Dalvi et
al., 2021) datasets as well as targeted perturbation sets. Our results show
that our models are substantially more accurate and flexible than baseline
systems. ParaPattern achieves 85% validity on examples of the 'substitution'
operation from EntailmentBank without the use of any in-domain training data,
matching the performance of a model fine-tuned for EntailmentBank. The full
source code for our method is publicly available.

    

### [[2005.10091] Label Efficient Visual Abstractions for Autonomous Driving](http://arxiv.org/abs/2005.10091)


  It is well known that semantic segmentation can be used as an effective
intermediate representation for learning driving policies. However, the task of
street scene semantic segmentation requires expensive annotations. Furthermore,
segmentation algorithms are often trained irrespective of the actual driving
task, using auxiliary image-space loss functions which are not guaranteed to
maximize driving metrics such as safety or distance traveled per intervention.
In this work, we seek to quantify the impact of reducing segmentation
annotation costs on learned behavior cloning agents. We analyze several
segmentation-based intermediate representations. We use these visual
abstractions to systematically study the trade-off between annotation
efficiency and driving performance, i.e., the types of classes labeled, the
number of image samples used to learn the visual abstraction model, and their
granularity (e.g., object masks vs. 2D bounding boxes). Our analysis uncovers
several practical insights into how segmentation-based visual abstractions can
be exploited in a more label efficient manner. Surprisingly, we find that
state-of-the-art driving performance can be achieved with orders of magnitude
reduction in annotation cost. Beyond label efficiency, we find several
additional training benefits when leveraging visual abstractions, such as a
significant reduction in the variance of the learned policy when compared to
state-of-the-art end-to-end driving models.

    

### [[2109.04148] Automatic Timing-Coherent Transactor Generation for Mixed-level Simulations](http://arxiv.org/abs/2109.04148)


  In this paper we extend the concept of the traditional transactor, which
focuses on correct content transfer, to a new timing-coherent transactor that
also accurately aligns the timing of each transaction boundary so that
designers can perform precise concurrent system behavior analysis in
mixed-abstraction-level system simulations which are essential to increasingly
complex system designs. To streamline the process, we also developed an
automatic approach for timing-coherent transactor generation. Our approach is
actually applied in mixed-level simulations and the results show that it
achieves 100% timing accuracy while the conventional approach produces results
of 25% to 44% error rate.

    

### [[2109.04196] Failure Analysis of Hadoop Schedulers using an Integration of Model Checking and Simulation](http://arxiv.org/abs/2109.04196)


  The Hadoop scheduler is a centerpiece of Hadoop, the leading processing
framework for data-intensive applications in the cloud. Given the impact of
failures on the performance of applications running on Hadoop, testing and
verifying the performance of the Hadoop scheduler is critical. Existing
approaches such as performance simulation and analytical modeling are
inadequate because they are not able to ascertain a complete verification of a
Hadoop scheduler. This is due to the wide range of constraints and aspects
involved in Hadoop. In this paper, we propose a novel methodology that
integrates and combines simulation and model checking techniques to perform a
formal verification of Hadoop schedulers, focusing on the following properties:
schedulability, fairness and resources-deadlock freeness. We use the CSP
language to formally describe a Hadoop scheduler, and the PAT model checker to
verify its properties. Next, we use the proposed formal model to analyze the
scheduler of OpenCloud, a Hadoop-based cluster that simulates the Hadoop load,
in order to illustrate the usability and benefits of our work. Results show
that our proposed methodology can help identify several tasks failures (up to
78%) early on, i.e., before the tasks are executed on the cluster.

    

### [[2109.03950] Study of the Subtyping Machine of Nominal Subtyping with Variance (full version)](http://arxiv.org/abs/2109.03950)


  This is a study of the computing power of the subtyping machine behind
Kennedy and Pierce's nominal subtyping with variance. We depict the lattice of
fragments of Kennedy and Pierce's type system and characterize their computing
power in terms of regular, context-free, deterministic, and non-deterministic
tree languages. Based on the theory, we present Treetop -- a generator of C#
implementations of subtyping machines. The software artifact constitutes the
first feasible (yet POC) fluent API generator to support context-free API
protocols in a decidable type system fragment.

    

### [[2109.04258] A Derivative-based Parser Generator for Visibly Pushdown Grammars](http://arxiv.org/abs/2109.04258)


  In this paper, we present a derivative-based, functional recognizer and
parser generator for visibly pushdown grammars. The generated parser accepts
ambiguous grammars and produces a parse forest containing all valid parse trees
for an input string in linear time. Each parse tree in the forest can then be
extracted also in linear time. Besides the parser generator, to allow more
flexible forms of the visibly pushdown grammars, we also present a translator
that converts a tagged CFG to a visibly pushdown grammar in a sound way, and
the parse trees of the tagged CFG are further produced by running the semantic
actions embedded in the parse trees of the translated visibly pushdown grammar.
The performance of the parser is compared with a popular parsing tool ANTLR and
other popular hand-crafted parsers. The correctness of the core parsing
algorithm is formally verified in the proof assistant Coq.

    

### [[2009.10207] Synthesizing Inductive Lemmas for Reasoning with First-Order Logic with Least Fixpoints](http://arxiv.org/abs/2009.10207)


  Recursively defined linked datastructures embedded in a pointer-based heap
and their properties are naturally expressed in pure first-order logic with
least fixpoint definitions (FO+lfp) combined with background theories. However,
automated reasoning for such logics has not seen much progress. Such logics,
unlike pure FOL, do not even admit complete procedures, let alone decidable
ones. In this paper, we undertake a foundational study of automatically finding
proofs that use induction to reason in these logics. By treating proofs as pure
FO proofs that are punctuated by declarations of induction lemmas, we separate
proofs into deductively reasoned components and statements of lemmas that need
to be synthesized. While humans divine such lemmas with intuition, we propose a
technique that guides the synthesis of such lemmas using counterexamples that
are finite first-order models that witness the help required for proving a goal
theorem as well as non-provability and invalidity of lemmas. We develop
relatively complete procedures for synthesizing lemmas for powerful FO+lfp
logics. We implement our procedures and evaluate them over a class of theorems
involving heap datastructures that require inductive proofs.

    

### [[2012.01067] Making Weak Memory Models Fair](http://arxiv.org/abs/2012.01067)


  Liveness properties, such as termination, of even the simplest shared-memory
concurrent programs under sequential consistency typically require some
fairness assumptions about the scheduler. Under weak memory models, we observe
that the standard notions of thread fairness are insufficient, and an
additional fairness property, which we call memory fairness, is needed. In this
paper, we propose a uniform definition for memory fairness that can be
integrated into any declarative memory model enforcing acyclicity of the union
of the program order and the reads-from relation. For the well-known models,
SC, x86-TSO, RA, and StrongCOH, that have equivalent operational and
declarative presentations, we show that our declarative memory fairness
condition is equivalent to an intuitive model-specific operational notion of
memory fairness, which requires the memory system to fairly execute its
internal propagation steps. Our fairness condition preserves the correctness of
local transformations and the compilation scheme from RC11 to x86-TSO, and also
enables the first formal proofs of termination of mutual exclusion lock
implementations under declarative weak memory models.

    

### [[2104.10274] Rich Specifications for Ethereum Smart Contract Verification](http://arxiv.org/abs/2104.10274)


  Smart contracts are programs that execute inside blockchains such as Ethereum
to manipulate digital assets. Since bugs in smart contracts may lead to
substantial financial losses, there is considerable interest in formally
proving their correctness. However, the specification and verification of smart
contracts faces challenges that do not arise in other application domains.
Smart contracts frequently interact with unverified, potentially adversarial
outside code, which substantially weakens the assumptions that formal analyses
can (soundly) make. Moreover, the core functionality of smart contracts is to
manipulate and transfer resources; describing this functionality concisely
requires dedicated specification support. Current reasoning techniques do not
fully address these challenges, being restricted in their scope or
expressiveness (in particular, in the presence of re-entrant calls), and
offering limited means of expressing the resource transfers a contract
performs.
In this paper, we present a novel specification methodology tailored to the
domain of smart contracts. Our specification constructs and associated
reasoning technique are the first to enable: (1) sound and precise reasoning in
the presence of unverified code and arbitrary re-entrancy, (2) modular
reasoning about collaborating smart contracts, and (3) domain-specific
specifications based on resources and resource transfers, which allow
expressing a contract's behavior in intuitive and concise ways and exclude
typical errors by default. We have implemented our approach in 2vyper, an
SMT-based automated verification tool for Ethereum smart contracts written in
the Vyper language, and demonstrated its effectiveness in succinctly capturing
and verifying strong correctness guarantees for real-world contracts.

    