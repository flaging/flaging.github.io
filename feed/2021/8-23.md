
## 2021-8-23

### [<title>关于昆明住宿手撕发票-百度文库ts - DockOne.io</title>](http://dockone.io/question/1092437)

### [<title>专注于重庆设备维修发票-百度知道 - DockOne.io</title>](http://dockone.io/question/1092436)

### [<title>专注于天津设备维修发票-百度知道 - DockOne.io</title>](http://dockone.io/question/1092435)

### [<title>关于南昌住宿手撕发票-百度文库ct - DockOne.io</title>](http://dockone.io/question/1092434)

### [<title>关于石家庄酒店专用发票-百度经验sd - DockOne.io</title>](http://dockone.io/question/1092433)

### [<title>关于济南酒店专用发票-百度经验mj - DockOne.io</title>](http://dockone.io/question/1092432)

### [<title>专注于宁波设备维修发票-百度知道 - DockOne.io</title>](http://dockone.io/question/1092431)

### [<title>关于福州住宿手撕发票-百度文库jd - DockOne.io</title>](http://dockone.io/question/1092430)

### [<title>关于沈阳酒店专用发票-百度经验as - DockOne.io</title>](http://dockone.io/question/1092427)

### [<title>关于惠州住宿手撕发票-百度文库oi - DockOne.io</title>](http://dockone.io/question/1092428)

### [<title>专注于杭州设备维修发票-百度知道 - DockOne.io</title>](http://dockone.io/question/1092429)

### [<title>关于长春酒店专用发票-百度经验mf - DockOne.io</title>](http://dockone.io/question/1092426)

### [<title>关于佛山住宿手撕发票-百度文库mo - DockOne.io</title>](http://dockone.io/question/1092425)

### [<title>专注于成都设备维修发票-百度知道 - DockOne.io</title>](http://dockone.io/question/1092424)

### [<title>专注于浙江设备维修发票-百度知道 - DockOne.io</title>](http://dockone.io/question/1092423)

### [<title>关于东莞住宿手撕发票-百度文库lk - DockOne.io</title>](http://dockone.io/question/1092422)

### [<title>关于海口酒店专用发票-百度经验my - DockOne.io</title>](http://dockone.io/question/1092421)

### [<title>关于三亚酒店专用发票-百度经验sr - DockOne.io</title>](http://dockone.io/question/1092420)

### [<title>专注于四川设备维修发票-百度知道 - DockOne.io</title>](http://dockone.io/question/1092419)

### [<title>关于青岛住宿手撕发票-百度文库hp - DockOne.io</title>](http://dockone.io/question/1092418)

### [[2108.09026] Federated Distributionally Robust Optimization for Phase Configuration of RISs](http://arxiv.org/abs/2108.09026)


  In this article, we study the problem of robust reconfigurable intelligent
surface (RIS)-aided downlink communication over heterogeneous RIS types in the
supervised learning setting. By modeling downlink communication over
heterogeneous RIS designs as different workers that learn how to optimize phase
configurations in a distributed manner, we solve this distributed learning
problem using a distributionally robust formulation in a
communication-efficient manner, while establishing its rate of convergence. By
doing so, we ensure that the global model performance of the worst-case worker
is close to the performance of other workers. Simulation results show that our
proposed algorithm requires fewer communication rounds (about 50% lesser) to
achieve the same worst-case distribution test accuracy compared to competitive
baselines.

    

### [[2108.09040] A Quantitative Framework for Network Resilience Evaluation using Dynamic Bayesian Network](http://arxiv.org/abs/2108.09040)


  Measuring and evaluating network resilience has become an important aspect
since the network is vulnerable to both uncertain disturbances and malicious
attacks. Networked systems are often composed of many dynamic components and
change over time, which makes it difficult for existing methods to access the
changeable situation of network resilience. This paper establishes a novel
quantitative framework for evaluating network resilience using the Dynamic
Bayesian Network. The proposed framework can be used to evaluate the network's
multi-stage resilience processes when suffering various attacks and recoveries.
First, we define the dynamic capacities of network components and establish the
network's five core resilience capabilities to describe the resilient
networking stages including preparation, resistance, adaptation, recovery, and
evolution; the five core resilience capabilities consist of rapid response
capability, sustained resistance capability, continuous running capability,
rapid convergence capability, and dynamic evolution capability. Then, we employ
a two-time slices approach based on the Dynamic Bayesian Network to quantify
five crucial performances of network resilience based on core capabilities
proposed above. The proposed approach can ensure the time continuity of
resilience evaluation in time-varying networks. Finally, our proposed
evaluation framework is applied to different attacks and recovery conditions in
typical simulations and real-world network topology. Results and comparisons
with extant studies indicate that the proposed method can achieve a more
accurate and comprehensive evaluation and can be applied to network scenarios
under various attack and recovery intensities.

    

### [[2108.09044] Towards A Simple and Efficient VDTN Routing Protocol for Data Collection in Smart Cities](http://arxiv.org/abs/2108.09044)


  Smart cities today can utilize Vehicular Delay Tolerant Networks (VDTN) to
collect data from connected-objects in the environment for various
delay-tolerant applications. They can take advantage of the available
Intelligent Transportation Systems (ITS) infrastructures to deliver data to the
central server. The system can also exploit multiple and diverse mobility
patterns found in cities, such as privately owned cars, taxis, public buses,
and trams, along with their Vehicle-to-Everything (V2X) communications
capabilities. In the envisioned convergence between the ITS and V2X, we believe
that a simple and efficient routing protocol can be deployed for the
delay-tolerant data delivery, contrary to the implementation of optimized
solutions that might be resource-demanding and difficult to standardize. In
this paper, we analyzed the performances of four baseline VDTN routing
protocols, namely: Direct Delivery, First Contact, Epidemic, and Spray & Wait,
to understand their strengths and weaknesses. Our simulation results
highlighted the trade-off between distinct approaches used by those protocols
and pointed out some gaps that can be refined. This study provides new
interesting ideas and arguments towards developing a simple, efficient, and
high-performing routing protocol for data collection in smart cities.

    

### [[2108.09103] Mobility-Aware Cluster Federated Learning in Hierarchical Wireless Networks](http://arxiv.org/abs/2108.09103)


  Implementing federated learning (FL) algorithms in wireless networks has
garnered a wide range of attention. However, few works have considered the
impact of user mobility on the learning performance. To fill this research gap,
firstly, we develop a theoretical model to characterize the hierarchical
federated learning (HFL) algorithm in wireless networks where the mobile users
may roam across multiple edge access points, leading to incompletion of
inconsistent FL training. Secondly, we provide the convergence analysis of HFL
with user mobility. Our analysis proves that the learning performance of HFL
deteriorates drastically with highly-mobile users. And this decline in the
learning performance will be exacerbated with small number of participants and
large data distribution divergences among local data of users. To circumvent
these issues, we propose a mobility-aware cluster federated learning (MACFL)
algorithm by redesigning the access mechanism, local update rule and model
aggregation scheme. Finally, we provide experiments to evaluate the learning
performance of HFL and our MACFL. The results show that our MACFL can enhance
the learning performance, especially for three different cases, namely, the
case of users with non-independent and identical distribution data, the case of
users with high mobility, and the cases with a small number of users.

    

### [[2108.09157] User Localization Based on Call Detail Records](http://arxiv.org/abs/2108.09157)


  Understanding human mobility is essential for many fields, including
transportation planning. Currently, surveys are the primary source for such
analysis. However, in the recent past, many researchers have focused on Call
Detail Records (CDR) for identifying travel patterns. CDRs have shown
correlation to human mobility behavior. However, one of the main issues in
using CDR data is that it is difficult to identify the precise location of the
user due to the low spacial resolution of the data and other artifacts such as
the load sharing effect. Existing approaches have certain limitations. Previous
studies using CDRs do not consider the transmit power of cell towers when
localizing the users and use an oversimplified approach to identify load
sharing effects. Furthermore, they consider the entire population of users as
one group neglecting the differences in mobility patterns of different segments
of users. This research introduces a novel methodology to user position
localization from CDRs through improved detection of load sharing effects, by
taking the transmit power into account, and segmenting the users into distinct
groups for the purpose of learning any parameters of the model. Moreover, this
research uses several methods to address the existing limitations and validate
the generated results using nearly 4 billion CDR data points with travel survey
data and voluntarily collected mobile data.

    

### [[2108.09176] Controller Placement in SDN-enabled 5G Satellite-Terrestrial Networks](http://arxiv.org/abs/2108.09176)


  SDN-enabled Integrated satellite-terrestrial networks (ISTNs), can provide
several advantages including global seamless coverage, high reliability, low
latency, etc. and can be a key enabler towards next generation networks. To
deal with the complexity of the control and management of the integrated
network, leveraging the concept of software-defined networking (SDN) will be
helpful. In this regard, the SDN controller placement problem in SDN-enabled
ISTNs becomes of paramount importance. In this paper, we formulate an
optimization problem for the SDN controller placement with the objective of
minimizing the average failure probability of SDN control paths to ensure the
SDN switches receive the instructions in the most reliable fashion.
Simultaneously, we aim at deploying the SDN controllers close to the satellite
gateways to ensure the connection between the two layers occurs with the lowest
latency. We first model the problem as a mixed integer linear program (MILP).
To reduce the time complexity of the MILP model, we use submodular optimization
techniques to generate near-optimal solutions in a time-efficient manner.
Finally, we verify the effectiveness of our approach by means of simulation,
showing that the approximation method results in a reasonable optimality gap
with respect to the exact MILP solution.

    

### [[2108.09199] An Adaptable Deep Learning-Based Intrusion Detection System to Zero-Day Attacks](http://arxiv.org/abs/2108.09199)


  The intrusion detection system (IDS) is an essential element of security
monitoring in computer networks. An IDS distinguishes the malicious traffic
from the benign one and determines the attack types targeting the assets of the
organization. The main challenge of an IDS is facing new (i.e., zero-day)
attacks and separating them from benign traffic and existing types of attacks.
Along with the power of the deep learning-based IDSes in auto-extracting
high-level features and its independence from the time-consuming and costly
signature extraction process, the mentioned challenge still exists in this new
generation of IDSes.
In this paper, we propose a framework for deep learning-based IDSes
addressing new attacks. This framework is the first approach using both deep
novelty-based classifiers besides the traditional clustering based on the
specialized layer of deep structures, in the security scope. Additionally, we
introduce DOC++ as a newer version of DOC as a deep novelty-based classifier.
We also employ the Deep Intrusion Detection (DID) framework for the
preprocessing phase, which improves the ability of deep learning algorithms to
detect content-based attacks. We compare four different algorithms (including
DOC, DOC++, OpenMax, and AutoSVM) as the novelty classifier of the framework
and use both the CIC-IDS2017 and CSE-CIC-IDS2018 datasets for the evaluation.
Our results show that DOC++ is the best implementation of the open set
recognition module. Besides, the completeness and homogeneity of the clustering
and post-training phase prove that this model is good enough for the supervised
labeling and updating phase.

    

### [[2108.08846] Personalized next-best action recommendation with multi-party interaction learning for automated decision-making](http://arxiv.org/abs/2108.08846)


  Automated next-best action recommendation for each customer in a sequential,
dynamic and interactive context has been widely needed in natural, social and
business decision-making. Personalized next-best action recommendation must
involve past, current and future customer demographics and circumstances
(states) and behaviors, long-range sequential interactions between customers
and decision-makers, multi-sequence interactions between states, behaviors and
actions, and their reactions to their counterpart's actions. No existing
modeling theories and tools, including Markovian decision processes, user and
behavior modeling, deep sequential modeling, and personalized sequential
recommendation, can quantify such complex decision-making on a personal level.
We take a data-driven approach to learn the next-best actions for personalized
decision-making by a reinforced coupled recurrent neural network (CRN). CRN
represents multiple coupled dynamic sequences of a customer's historical and
current states, responses to decision-makers' actions, decision rewards to
actions, and learns long-term multi-sequence interactions between parties
(customer and decision-maker). Next-best actions are then recommended on each
customer at a time point to change their state for an optimal decision-making
objective. Our study demonstrates the potential of personalized deep learning
of multi-sequence interactions and automated dynamic intervention for
personalized decision-making in complex systems.

    

### [[2108.08868] MOFit: A Framework to reduce Obesity using Machine learning and IoT](http://arxiv.org/abs/2108.08868)


  From the past few years, due to advancements in technologies, the sedentary
living style in urban areas is at its peak. This results in individuals getting
a victim of obesity at an early age. There are various health impacts of
obesity like Diabetes, Heart disease, Blood pressure problems, and many more.
Machine learning from the past few years is showing its implications in all
expertise like forecasting, healthcare, medical imaging, sentiment analysis,
etc. In this work, we aim to provide a framework that uses machine learning
algorithms namely, Random Forest, Decision Tree, XGBoost, Extra Trees, and KNN
to train models that would help predict obesity levels (Classification),
Bodyweight, and fat percentage levels (Regression) using various parameters. We
also applied and compared various hyperparameter optimization (HPO) algorithms
such as Genetic algorithm, Random Search, Grid Search, Optuna to further
improve the accuracy of the models. The website framework contains various
other features like making customizable Diet plans, workout plans, and a
dashboard to track the progress. The framework is built using the Python Flask.
Furthermore, a weighing scale using the Internet of Things (IoT) is also
integrated into the framework to track calories and macronutrients from food
intake.

    

### [[2108.08870] Topo2vec: Topography Embedding Using the Fractal Effect](http://arxiv.org/abs/2108.08870)


  Recent advances in deep learning have transformed many fields by introducing
generic embedding spaces, capable of achieving great predictive performance
with minimal labeling effort. The geology field has not yet met such success.
In this work, we introduce an extension for self-supervised learning techniques
tailored for exploiting the fractal-effect in remote-sensing images. The
fractal-effect assumes that the same structures (for example rivers, peaks and
saddles) will appear in all scales. We demonstrate our method's effectiveness
on elevation data, we also use the effect in inference. We perform an extensive
analysis on several classification tasks and emphasize its effectiveness in
detecting the same class on different scales. To the best of our knowledge, it
is the first attempt to build a generic representation for topographic images.

    

### [[2108.08871] Structure Learning for Directed Trees](http://arxiv.org/abs/2108.08871)


  Knowing the causal structure of a system is of fundamental interest in many
areas of science and can aid the design of prediction algorithms that work well
under manipulations to the system. The causal structure becomes identifiable
from the observational distribution under certain restrictions. To learn the
structure from data, score-based methods evaluate different graphs according to
the quality of their fits. However, for large nonlinear models, these rely on
heuristic optimization approaches with no general guarantees of recovering the
true causal structure. In this paper, we consider structure learning of
directed trees. We propose a fast and scalable method based on Chu-Liu-Edmonds'
algorithm we call causal additive trees (CAT). For the case of Gaussian errors,
we prove consistency in an asymptotic regime with a vanishing identifiability
gap. We also introduce a method for testing substructure hypotheses with
asymptotic family-wise error rate control that is valid post-selection and in
unidentified settings. Furthermore, we study the identifiability gap, which
quantifies how much better the true causal model fits the observational
distribution, and prove that it is lower bounded by local properties of the
causal model. Simulation studies demonstrate the favorable performance of CAT
compared to competing structure learning methods.

    

### [[2108.08875] Comparing concepts of quantum and classical neural network models for image classification task](http://arxiv.org/abs/2108.08875)


  While quantum architectures are still under development, when available, they
will only be able to process quantum data when machine learning algorithms can
only process numerical data. Therefore, in the issues of classification or
regression, it is necessary to simulate and study quantum systems that will
transfer the numerical input data to a quantum form and enable quantum
computers to use the available methods of machine learning. This material
includes the results of experiments on training and performance of a hybrid
quantum-classical neural network developed for the problem of classification of
handwritten digits from the MNIST data set. The comparative results of two
models: classical and quantum neural networks of a similar number of training
parameters, indicate that the quantum network, although its simulation is
time-consuming, overcomes the classical network (it has better convergence and
achieves higher training and testing accuracy).

    

### [[2108.08876] Deep Learning-based Spacecraft Relative Navigation Methods: A Survey](http://arxiv.org/abs/2108.08876)


  Autonomous spacecraft relative navigation technology has been planned for and
applied to many famous space missions. The development of on-board electronics
systems has enabled the use of vision-based and LiDAR-based methods to achieve
better performances. Meanwhile, deep learning has reached great success in
different areas, especially in computer vision, which has also attracted the
attention of space researchers. However, spacecraft navigation differs from
ground tasks due to high reliability requirements but lack of large datasets.
This survey aims to systematically investigate the current deep learning-based
autonomous spacecraft relative navigation methods, focusing on concrete orbital
applications such as spacecraft rendezvous and landing on small bodies or the
Moon. The fundamental characteristics, primary motivations, and contributions
of deep learning-based relative navigation algorithms are first summarised from
three perspectives of spacecraft rendezvous, asteroid exploration, and terrain
navigation. Furthermore, popular visual tracking benchmarks and their
respective properties are compared and summarised. Finally, potential
applications are discussed, along with expected impediments.

    

### [[2108.08887] Risk Bounds and Calibration for a Smart Predict-then-Optimize Method](http://arxiv.org/abs/2108.08887)


  The predict-then-optimize framework is fundamental in practical stochastic
decision-making problems: first predict unknown parameters of an optimization
model, then solve the problem using the predicted values. A natural loss
function in this setting is defined by measuring the decision error induced by
the predicted parameters, which was named the Smart Predict-then-Optimize (SPO)
loss by Elmachtoub and Grigas [arXiv:1710.08005]. Since the SPO loss is
typically nonconvex and possibly discontinuous, Elmachtoub and Grigas
[arXiv:1710.08005] introduced a convex surrogate, called the SPO+ loss, that
importantly accounts for the underlying structure of the optimization model. In
this paper, we greatly expand upon the consistency results for the SPO+ loss
provided by Elmachtoub and Grigas [arXiv:1710.08005]. We develop risk bounds
and uniform calibration results for the SPO+ loss relative to the SPO loss,
which provide a quantitative way to transfer the excess surrogate risk to
excess true risk. By combining our risk bounds with generalization bounds, we
show that the empirical minimizer of the SPO+ loss achieves low excess true
risk with high probability. We first demonstrate these results in the case when
the feasible region of the underlying optimization problem is a polyhedron, and
then we show that the results can be strengthened substantially when the
feasible region is a level set of a strongly convex function. We perform
experiments to empirically demonstrate the strength of the SPO+ surrogate, as
compared to standard $\ell_1$ and squared $\ell_2$ prediction error losses, on
portfolio allocation and cost-sensitive multi-class classification problems.

    

### [[2108.08890] Local Latin Hypercube Refinement for Multi-objective Design Uncertainty Optimization](http://arxiv.org/abs/2108.08890)


  Optimizing the reliability and the robustness of a design is important but
often unaffordable due to high sample requirements. Surrogate models based on
statistical and machine learning methods are used to increase the sample
efficiency. However, for higher dimensional or multi-modal systems, surrogate
models may also require a large amount of samples to achieve good results. We
propose a sequential sampling strategy for the surrogate based solution of
multi-objective reliability based robust design optimization problems. Proposed
local Latin hypercube refinement (LoLHR) strategy is model-agnostic and can be
combined with any surrogate model because there is no free lunch but possibly a
budget one. The proposed method is compared to stationary sampling as well as
other proposed strategies from the literature. Gaussian process and support
vector regression are both used as surrogate models. Empirical evidence is
presented, showing that LoLHR achieves on average better results compared to
other surrogate based strategies on the tested examples.

    

### [[2108.08891] Neural TMDlayer: Modeling Instantaneous flow of features via SDE Generators](http://arxiv.org/abs/2108.08891)


  We study how stochastic differential equation (SDE) based ideas can inspire
new modifications to existing algorithms for a set of problems in computer
vision. Loosely speaking, our formulation is related to both explicit and
implicit strategies for data augmentation and group equivariance, but is
derived from new results in the SDE literature on estimating infinitesimal
generators of a class of stochastic processes. If and when there is nominal
agreement between the needs of an application/task and the inherent properties
and behavior of the types of processes that we can efficiently handle, we
obtain a very simple and efficient plug-in layer that can be incorporated
within any existing network architecture, with minimal modification and only a
few additional parameters. We show promising experiments on a number of vision
tasks including few shot learning, point cloud transformers and deep
variational segmentation obtaining efficiency or performance improvements.

    

### [[2108.08895] Segmentation of Lungs COVID Infected Regions by Attention Mechanism and Synthetic Data](http://arxiv.org/abs/2108.08895)


  Coronavirus has caused hundreds of thousands of deaths. Fatalities could
decrease if every patient could get suitable treatment by the healthcare
system. Machine learning, especially computer vision methods based on deep
learning, can help healthcare professionals diagnose and treat COVID-19
infected cases more efficiently. Hence, infected patients can get better
service from the healthcare system and decrease the number of deaths caused by
the coronavirus. This research proposes a method for segmenting infected lung
regions in a CT image. For this purpose, a convolutional neural network with an
attention mechanism is used to detect infected areas with complex patterns.
Attention blocks improve the segmentation accuracy by focusing on informative
parts of the image. Furthermore, a generative adversarial network generates
synthetic images for data augmentation and expansion of small available
datasets. Experimental results show the superiority of the proposed method
compared to some existing procedures.

    

### [[2108.08903] SIAM: Chiplet-based Scalable In-Memory Acceleration with Mesh for Deep Neural Networks](http://arxiv.org/abs/2108.08903)


  In-memory computing (IMC) on a monolithic chip for deep learning faces
dramatic challenges on area, yield, and on-chip interconnection cost due to the
ever-increasing model sizes. 2.5D integration or chiplet-based architectures
interconnect multiple small chips (i.e., chiplets) to form a large computing
system, presenting a feasible solution beyond a monolithic IMC architecture to
accelerate large deep learning models. This paper presents a new benchmarking
simulator, SIAM, to evaluate the performance of chiplet-based IMC architectures
and explore the potential of such a paradigm shift in IMC architecture design.
SIAM integrates device, circuit, architecture, network-on-chip (NoC),
network-on-package (NoP), and DRAM access models to realize an end-to-end
system. SIAM is scalable in its support of a wide range of deep neural networks
(DNNs), customizable to various network structures and configurations, and
capable of efficient design space exploration. We demonstrate the flexibility,
scalability, and simulation speed of SIAM by benchmarking different
state-of-the-art DNNs with CIFAR-10, CIFAR-100, and ImageNet datasets. We
further calibrate the simulation results with a published silicon result,
SIMBA. The chiplet-based IMC architecture obtained through SIAM shows
130$\times$ and 72$\times$ improvement in energy-efficiency for ResNet-50 on
the ImageNet dataset compared to Nvidia V100 and T4 GPUs.

    

### [[2108.08905] Statistical Learning to Operationalize a Domain Agnostic Data Quality Scoring](http://arxiv.org/abs/2108.08905)


  Data is expanding at an unimaginable rate, and with this development comes
the responsibility of the quality of data. Data Quality refers to the relevance
of the information present and helps in various operations like decision making
and planning in a particular organization. Mostly data quality is measured on
an ad-hoc basis, and hence none of the developed concepts provide any practical
application. The current empirical study was undertaken to formulate a concrete
automated data quality platform to assess the quality of incoming dataset and
generate a quality label, score and comprehensive report. We utilize various
datasets from this http URL, opendata.nhs and Demographics and Health Surveys
(DHS) Program to observe the variations in the quality score and formulate a
label using Principal Component Analysis(PCA). The results of the current
empirical study revealed a metric that encompasses nine quality ingredients,
namely provenance, dataset characteristics, uniformity, metadata coupling,
percentage of missing cells and duplicate rows, skewness of data, the ratio of
inconsistencies of categorical columns, and correlation between these
attributes. The study also provides an illustrative case study and validation
of the metric following Mutation Testing approaches. This research study
provides an automated platform which takes an incoming dataset and metadata to
provide the DQ score, report and label. The results of this study would be
useful to data scientists as the value of this quality label would instill
confidence before deploying the data for his/her respective practical
application.

    

### [[2108.08910] Achieving on-Mobile Real-Time Super-Resolution with Neural Architecture and Pruning Search](http://arxiv.org/abs/2108.08910)


  Though recent years have witnessed remarkable progress in single image
super-resolution (SISR) tasks with the prosperous development of deep neural
networks (DNNs), the deep learning methods are confronted with the computation
and memory consumption issues in practice, especially for resource-limited
platforms such as mobile devices. To overcome the challenge and facilitate the
real-time deployment of SISR tasks on mobile, we combine neural architecture
search with pruning search and propose an automatic search framework that
derives sparse super-resolution (SR) models with high image quality while
satisfying the real-time inference requirement. To decrease the search cost, we
leverage the weight sharing strategy by introducing a supernet and decouple the
search problem into three stages, including supernet construction,
compiler-aware architecture and pruning search, and compiler-aware pruning
ratio search. With the proposed framework, we are the first to achieve
real-time SR inference (with only tens of milliseconds per frame) for
implementing 720p resolution with competitive image quality (in terms of PSNR
and SSIM) on mobile platforms (Samsung Galaxy S20).

    

### [[2108.08911] Explainable Deep Reinforcement Learning Using Introspection in a Non-episodic Task](http://arxiv.org/abs/2108.08911)


  Explainable reinforcement learning allows artificial agents to explain their
behavior in a human-like manner aiming at non-expert end-users. An efficient
alternative of creating explanations is to use an introspection-based method
that transforms Q-values into probabilities of success used as the base to
explain the agent's decision-making process. This approach has been effectively
used in episodic and discrete scenarios, however, to compute the probability of
success in non-episodic and more complex environments has not been addressed
yet. In this work, we adapt the introspection method to be used in a
non-episodic task and try it in a continuous Atari game scenario solved with
the Rainbow algorithm. Our initial results show that the probability of success
can be computed directly from the Q-values for all possible actions.

    

### [[2108.08920] Detection of Illicit Drug Trafficking Events on Instagram: A Deep Multimodal Multilabel Learning Approach](http://arxiv.org/abs/2108.08920)


  Social media such as Instagram and Twitter have become important platforms
for marketing and selling illicit drugs. Detection of online illicit drug
trafficking has become critical to combat the online trade of illicit drugs.
However, the legal status often varies spatially and temporally; even for the
same drug, federal and state legislation can have different regulations about
its legality. Meanwhile, more drug trafficking events are disguised as a novel
form of advertising commenting leading to information heterogeneity.
Accordingly, accurate detection of illicit drug trafficking events (IDTEs) from
social media has become even more challenging. In this work, we conduct the
first systematic study on fine-grained detection of IDTEs on Instagram. We
propose to take a deep multimodal multilabel learning (DMML) approach to detect
IDTEs and demonstrate its effectiveness on a newly constructed dataset called
multimodal IDTE(MM-IDTE). Specifically, our model takes text and image data as
the input and combines multimodal information to predict multiple labels of
illicit drugs. Inspired by the success of BERT, we have developed a
self-supervised multimodal bidirectional transformer by jointly fine-tuning
pretrained text and image encoders. We have constructed a large-scale dataset
MM-IDTE with manually annotated multiple drug labels to support fine-grained
detection of illicit drugs. Extensive experimental results on the MM-IDTE
dataset show that the proposed DMML methodology can accurately detect IDTEs
even in the presence of special characters and style changes attempting to
evade detection.

    

### [[2108.08930] Cross-Silo Federated Learning for Multi-Tier Networks with Vertical and Horizontal Data Partitioning](http://arxiv.org/abs/2108.08930)


  We consider federated learning in tiered communication networks. Our network
model consists of a set of silos, each holding a vertical partition of the
data. Each silo contains a hub and a set of clients, with the silo's vertical
data shard partitioned horizontally across its clients. We propose Tiered
Decentralized Coordinate Descent (TDCD), a communication-efficient
decentralized training algorithm for such two-tiered networks. To reduce
communication overhead, the clients in each silo perform multiple local
gradient steps before sharing updates with their hub. Each hub adjusts its
coordinates by averaging its workers' updates, and then hubs exchange
intermediate updates with one another. We present a theoretical analysis of our
algorithm and show the dependence of the convergence rate on the number of
vertical partitions, the number of local updates, and the number of clients in
each hub. We further validate our approach empirically via simulation-based
experiments using a variety of datasets and objectives.

    

### [[2108.08931] Augmenting Implicit Neural Shape Representations with Explicit Deformation Fields](http://arxiv.org/abs/2108.08931)


  Implicit neural representation is a recent approach to learn shape
collections as zero level-sets of neural networks, where each shape is
represented by a latent code. So far, the focus has been shape reconstruction,
while shape generalization was mostly left to generic encoder-decoder or
auto-decoder regularization.
In this paper we advocate deformation-aware regularization for implicit
neural representations, aiming at producing plausible deformations as latent
code changes. The challenge is that implicit representations do not capture
correspondences between different shapes, which makes it difficult to represent
and regularize their deformations. Thus, we propose to pair the implicit
representation of the shapes with an explicit, piecewise linear deformation
field, learned as an auxiliary function. We demonstrate that, by regularizing
these deformation fields, we can encourage the implicit neural representation
to induce natural deformations in the learned shape space, such as
as-rigid-as-possible deformations.

    

### [[2108.08946] A Framework for Neural Topic Modeling of Text Corpora](http://arxiv.org/abs/2108.08946)


  Topic Modeling refers to the problem of discovering the main topics that have
occurred in corpora of textual data, with solutions finding crucial
applications in numerous fields. In this work, inspired by the recent
advancements in the Natural Language Processing domain, we introduce FAME, an
open-source framework enabling an efficient mechanism of extracting and
incorporating textual features and utilizing them in discovering topics and
clustering text documents that are semantically similar in a corpus. These
features range from traditional approaches (e.g., frequency-based) to the most
recent auto-encoding embeddings from transformer-based language models such as
BERT model family. To demonstrate the effectiveness of this library, we
conducted experiments on the well-known News-Group dataset. The library is
available online.

    

### [[2108.08952] Mitigating Greenhouse Gas Emissions Through Generative Adversarial Networks Based Wildfire Prediction](http://arxiv.org/abs/2108.08952)


  Over the past decade, the number of wildfire has increased significantly
around the world, especially in the State of California. The high-level
concentration of greenhouse gas (GHG) emitted by wildfires aggravates global
warming that further increases the risk of more fires. Therefore, an accurate
prediction of wildfire occurrence greatly helps in preventing large-scale and
long-lasting wildfires and reducing the consequent GHG emissions. Various
methods have been explored for wildfire risk prediction. However, the complex
correlations among a lot of natural and human factors and wildfire ignition
make the prediction task very challenging. In this paper, we develop a deep
learning based data augmentation approach for wildfire risk prediction. We
build a dataset consisting of diverse features responsible for fire ignition
and utilize a conditional tabular generative adversarial network to explore the
underlying patterns between the target value of risk levels and all involved
features. For fair and comprehensive comparisons, we compare our proposed
scheme with five other baseline methods where the former outperformed most of
them. To corroborate the robustness, we have also tested the performance of our
method with another dataset that also resulted in better efficiency. By
adopting the proposed method, we can take preventive strategies of wildfire
mitigation to reduce global GHG emissions.

    

### [[2108.08956] Semi-supervised learning for medical image classification using imbalanced training data](http://arxiv.org/abs/2108.08956)


  Medical image classification is often challenging for two reasons: a lack of
labelled examples due to expensive and time-consuming annotation protocols, and
imbalanced class labels due to the relative scarcity of disease-positive
individuals in the wider population. Semi-supervised learning (SSL) methods
exist for dealing with a lack of labels, but they generally do not address the
problem of class imbalance. In this study we propose Adaptive Blended
Consistency Loss (ABCL), a drop-in replacement for consistency loss in
perturbation-based SSL methods. ABCL counteracts data skew by adaptively mixing
the target class distribution of the consistency loss in accordance with class
frequency. Our experiments with ABCL reveal improvements to unweighted average
recall on two different imbalanced medical image classification datasets when
compared with existing consistency losses that are not designed to counteract
class imbalance.

    

### [[2108.08960] Plug and Play, Model-Based Reinforcement Learning](http://arxiv.org/abs/2108.08960)


  Sample-efficient generalisation of reinforcement learning approaches have
always been a challenge, especially, for complex scenes with many components.
In this work, we introduce Plug and Play Markov Decision Processes, an
object-based representation that allows zero-shot integration of new objects
from known object classes. This is achieved by representing the global
transition dynamics as a union of local transition functions, each with respect
to one active object in the scene. Transition dynamics from an object class can
be pre-learnt and thus would be ready to use in a new environment. Each active
object is also endowed with its reward function. Since there is no central
reward function, addition or removal of objects can be handled efficiently by
only updating the reward functions of objects involved. A new transfer learning
mechanism is also proposed to adapt reward function in such cases. Experiments
show that our representation can achieve sample-efficiency in a variety of
set-ups.

    

### [[2108.08972] Application of Adversarial Examples to Physical ECG Signals](http://arxiv.org/abs/2108.08972)


  This work aims to assess the reality and feasibility of the adversarial
attack against cardiac diagnosis system powered by machine learning algorithms.
To this end, we introduce adversarial beats, which are adversarial
perturbations tailored specifically against electrocardiograms (ECGs)
beat-by-beat classification system. We first formulate an algorithm to generate
adversarial examples for the ECG classification neural network model, and study
its attack success rate. Next, to evaluate its feasibility in a physical
environment, we mount a hardware attack by designing a malicious signal
generator which injects adversarial beats into ECG sensor readings. To the best
of our knowledge, our work is the first in evaluating the proficiency of
adversarial examples for ECGs in a physical setup. Our real-world experiments
demonstrate that adversarial beats successfully manipulated the diagnosis
results 3-5 times out of 40 attempts throughout the course of 2 minutes.
Finally, we discuss the overall feasibility and impact of the attack, by
clearly defining motives and constraints of expected attackers along with our
experimental results.

    

### [[2108.08976] ASAT: Adaptively Scaled Adversarial Training in Time Series](http://arxiv.org/abs/2108.08976)


  Adversarial training is a method for enhancing neural networks to improve the
robustness against adversarial examples. Besides the security concerns of
potential adversarial examples, adversarial training can also improve the
performance of the neural networks, train robust neural networks, and provide
interpretability for neural networks. In this work, we take the first step to
introduce adversarial training in time series analysis by taking the finance
field as an example. Rethinking existing researches of adversarial training, we
propose the adaptively scaled adversarial training (ASAT) in time series
analysis, by treating data at different time slots with time-dependent
importance weights. Experimental results show that the proposed ASAT can
improve both the accuracy and the adversarial robustness of neural networks.
Besides enhancing neural networks, we also propose the dimension-wise
adversarial sensitivity indicator to probe the sensitivities and importance of
input dimensions. With the proposed indicator, we can explain the decision
bases of black box neural networks.

    

### [[2108.08977] CloudShield: Real-time Anomaly Detection in the Cloud](http://arxiv.org/abs/2108.08977)


  In cloud computing, it is desirable if suspicious activities can be detected
by automatic anomaly detection systems. Although anomaly detection has been
investigated in the past, it remains unsolved in cloud computing. Challenges
are: characterizing the normal behavior of a cloud server, distinguishing
between benign and malicious anomalies (attacks), and preventing alert fatigue
due to false alarms.
We propose CloudShield, a practical and generalizable real-time anomaly and
attack detection system for cloud computing. Cloudshield uses a general,
pretrained deep learning model with different cloud workloads, to predict the
normal behavior and provide real-time and continuous detection by examining the
model reconstruction error distributions. Once an anomaly is detected, to
reduce alert fatigue, CloudShield automatically distinguishes between benign
programs, known attacks, and zero-day attacks, by examining the prediction
error distributions. We evaluate the proposed CloudShield on representative
cloud benchmarks. Our evaluation shows that CloudShield, using model
pretraining, can apply to a wide scope of cloud workloads. Especially, we
observe that CloudShield can detect the recently proposed speculative execution
attacks, e.g., Spectre and Meltdown attacks, in milliseconds. Furthermore, we
show that CloudShield accurately differentiates and prioritizes known attacks,
and potential zero-day attacks, from benign programs. Thus, it significantly
reduces false alarms by up to 99.0%.

    

### [[2108.08988] Twitter User Representation using Weakly Supervised Graph Embedding](http://arxiv.org/abs/2108.08988)


  Social media platforms provide convenient means for users to participate in
multiple online activities on various contents and create fast widespread
interactions. However, this rapidly growing access has also increased the
diverse information, and characterizing user types to understand people's
lifestyle decisions shared in social media is challenging. In this paper, we
propose a weakly supervised graph embedding based framework for understanding
user types. We evaluate the user embedding learned using weak supervision over
well-being related tweets from Twitter, focusing on 'Yoga', 'Keto diet'.
Experiments on real-world datasets demonstrate that the proposed framework
outperforms the baselines for detecting user types. Finally, we illustrate data
analysis on different types of users (e.g., practitioner vs. promotional) from
our dataset. While we focus on lifestyle-related tweets (i.e., yoga, keto), our
method for constructing user representation readily generalizes to other
domains.

    

### [[2108.08990] Few Shot Activity Recognition Using Variational Inference](http://arxiv.org/abs/2108.08990)


  There has been a remarkable progress in learning a model which could
recognise novel classes with only a few labeled examples in the last few years.
Few-shot learning (FSL) for action recognition is a challenging task of
recognising novel action categories which are represented by few instances in
the training data. We propose a novel variational inference based architectural
framework (HF-AR) for few shot activity recognition. Our framework leverages
volume-preserving Householder Flow to learn a flexible posterior distribution
of the novel classes. This results in better performance as compared to
state-of-the-art few shot approaches for human activity recognition. approach
consists of base model and an adapter model. Our architecture consists of a
base model and an adapter model. The base model is trained on seen classes and
it computes an embedding that represent the spatial and temporal insights
extracted from the input video, e.g. combination of Resnet-152 and LSTM based
encoder-decoder model. The adapter model applies a series of Householder
transformations to compute a flexible posterior distribution that lends higher
accuracy in the few shot approach. Extensive experiments on three well-known
datasets: UCF101, HMDB51 and Something-Something-V2, demonstrate similar or
better performance on 1-shot and 5-shot classification as compared to
state-of-the-art few shot approaches that use only RGB frame sequence as input.
To the best of our knowledge, we are the first to explore variational inference
along with householder transformations to capture the full rank covariance
matrix of posterior distribution, for few shot learning in activity
recognition.

    

### [[2108.08993] Distributionally Robust Learning](http://arxiv.org/abs/2108.08993)


  This monograph develops a comprehensive statistical learning framework that
is robust to (distributional) perturbations in the data using Distributionally
Robust Optimization (DRO) under the Wasserstein metric. Beginning with
fundamental properties of the Wasserstein metric and the DRO formulation, we
explore duality to arrive at tractable formulations and develop finite-sample,
as well as asymptotic, performance guarantees. We consider a series of learning
problems, including (i) distributionally robust linear regression; (ii)
distributionally robust regression with group structure in the predictors;
(iii) distributionally robust multi-output regression and multiclass
classification, (iv) optimal decision making that combines distributionally
robust regression with nearest-neighbor estimation; (v) distributionally robust
semi-supervised learning, and (vi) distributionally robust reinforcement
learning. A tractable DRO relaxation for each problem is being derived,
establishing a connection between robustness and regularization, and obtaining
bounds on the prediction and estimation errors of the solution. Beyond theory,
we include numerical experiments and case studies using synthetic and real
data. The real data experiments are all associated with various health
informatics problems, an application area which provided the initial impetus
for this work.

    

### [[2108.08995] Discriminative Domain-Invariant Adversarial Network for Deep Domain Generalization](http://arxiv.org/abs/2108.08995)


  Domain generalization approaches aim to learn a domain invariant prediction
model for unknown target domains from multiple training source domains with
different distributions. Significant efforts have recently been committed to
broad domain generalization, which is a challenging and topical problem in
machine learning and computer vision communities. Most previous domain
generalization approaches assume that the conditional distribution across the
domains remain the same across the source domains and learn a domain invariant
model by minimizing the marginal distributions. However, the assumption of a
stable conditional distribution of the training source domains does not really
hold in practice. The hyperplane learned from the source domains will easily
misclassify samples scattered at the boundary of clusters or far from their
corresponding class centres. To address the above two drawbacks, we propose a
discriminative domain-invariant adversarial network (DDIAN) for domain
generalization. The discriminativeness of the features are guaranteed through a
discriminative feature module and domain-invariant features are guaranteed
through the global domain and local sub-domain alignment modules. Extensive
experiments on several benchmarks show that DDIAN achieves better prediction on
unseen target data during training compared to state-of-the-art domain
generalization approaches.

    

### [[2108.08999] Deep Sequence Modeling: Development and Applications in Asset Pricing](http://arxiv.org/abs/2108.08999)


  We predict asset returns and measure risk premia using a prominent technique
from artificial intelligence -- deep sequence modeling. Because asset returns
often exhibit sequential dependence that may not be effectively captured by
conventional time series models, sequence modeling offers a promising path with
its data-driven approach and superior performance. In this paper, we first
overview the development of deep sequence models, introduce their applications
in asset pricing, and discuss their advantages and limitations. We then perform
a comparative analysis of these methods using data on U.S. equities. We
demonstrate how sequence modeling benefits investors in general through
incorporating complex historical path dependence, and that Long- and Short-term
Memory (LSTM) based models tend to have the best out-of-sample performance.

    

### [[2108.09020] Online Continual Learning with Natural Distribution Shifts: An Empirical Study with Visual Data](http://arxiv.org/abs/2108.09020)


  Continual learning is the problem of learning and retaining knowledge through
time over multiple tasks and environments. Research has primarily focused on
the incremental classification setting, where new tasks/classes are added at
discrete time intervals. Such an "offline" setting does not evaluate the
ability of agents to learn effectively and efficiently, since an agent can
perform multiple learning epochs without any time limitation when a task is
added. We argue that "online" continual learning, where data is a single
continuous stream without task boundaries, enables evaluating both information
retention and online learning efficacy. In online continual learning, each
incoming small batch of data is first used for testing and then added to the
training set, making the problem truly online. Trained models are later
evaluated on historical data to assess information retention. We introduce a
new benchmark for online continual visual learning that exhibits large scale
and natural distribution shifts. Through a large-scale analysis, we identify
critical and previously unobserved phenomena of gradient-based optimization in
continual learning, and propose effective strategies for improving
gradient-based online continual learning with real data. The source code and
dataset are available in: this https URL.

    

### [[2108.09033] UnSplit: Data-Oblivious Model Inversion, Model Stealing, and Label Inference Attacks Against Split Learning](http://arxiv.org/abs/2108.09033)


  Training deep neural networks requires large scale data, which often forces
users to work in a distributed or outsourced setting, accompanied with privacy
concerns. Split learning framework aims to address this concern by splitting up
the model among the client and the server. The idea is that since the server
does not have access to client's part of the model, the scheme supposedly
provides privacy. We show that this is not true via two novel attacks. (1) We
show that an honest-but-curious split learning server, equipped only with the
knowledge of the client neural network architecture, can recover the input
samples and also obtain a functionally similar model to the client model,
without the client being able to detect the attack. (2) Furthermore, we show
that if split learning is used naively to protect the training labels, the
honest-but-curious server can infer the labels with perfect accuracy. We test
our attacks using three benchmark datasets and investigate various properties
of the overall system that affect the attacks' effectiveness. Our results show
that plaintext split learning paradigm can pose serious security risks and
provide no more than a false sense of security.

    

### [[2108.09034] AdvDrop: Adversarial Attack to DNNs by Dropping Information](http://arxiv.org/abs/2108.09034)


  Human can easily recognize visual objects with lost information: even losing
most details with only contour reserved, e.g. cartoon. However, in terms of
visual perception of Deep Neural Networks (DNNs), the ability for recognizing
abstract objects (visual objects with lost information) is still a challenge.
In this work, we investigate this issue from an adversarial viewpoint: will the
performance of DNNs decrease even for the images only losing a little
information? Towards this end, we propose a novel adversarial attack, named
\textit{AdvDrop}, which crafts adversarial examples by dropping existing
information of images. Previously, most adversarial attacks add extra
disturbing information on clean images explicitly. Opposite to previous works,
our proposed work explores the adversarial robustness of DNN models in a novel
perspective by dropping imperceptible details to craft adversarial examples. We
demonstrate the effectiveness of \textit{AdvDrop} by extensive experiments, and
show that this new type of adversarial examples is more difficult to be
defended by current defense systems.

    

### [[2108.09038] Is it Time to Replace CNNs with Transformers for Medical Images?](http://arxiv.org/abs/2108.09038)


  Convolutional Neural Networks (CNNs) have reigned for a decade as the de
facto approach to automated medical image diagnosis. Recently, vision
transformers (ViTs) have appeared as a competitive alternative to CNNs,
yielding similar levels of performance while possessing several interesting
properties that could prove beneficial for medical imaging tasks. In this work,
we explore whether it is time to move to transformer-based models or if we
should keep working with CNNs - can we trivially switch to transformers? If so,
what are the advantages and drawbacks of switching to ViTs for medical image
diagnosis? We consider these questions in a series of experiments on three
mainstream medical image datasets. Our findings show that, while CNNs perform
better when trained from scratch, off-the-shelf vision transformers using
default hyperparameters are on par with CNNs when pretrained on ImageNet, and
outperform their CNN counterparts when pretrained using self-supervision.

    

### [[2108.09052] SplitGuard: Detecting and Mitigating Training-Hijacking Attacks in Split Learning](http://arxiv.org/abs/2108.09052)


  Distributed deep learning frameworks, such as split learning, have recently
been proposed to enable a group of participants to collaboratively train a deep
neural network without sharing their raw data. Split learning in particular
achieves this goal by dividing a neural network between a client and a server
so that the client computes the initial set of layers, and the server computes
the rest. However, this method introduces a unique attack vector for a
malicious server attempting to steal the client's private data: the server can
direct the client model towards learning a task of its choice. With a concrete
example already proposed, such training-hijacking attacks present a significant
risk for the data privacy of split learning clients.
In this paper, we propose SplitGuard, a method by which a split learning
client can detect whether it is being targeted by a training-hijacking attack
or not. We experimentally evaluate its effectiveness, and discuss in detail
various points related to its use. We conclude that SplitGuard can effectively
detect training-hijacking attacks while minimizing the amount of information
recovered by the adversaries.

    

### [[2108.09076] PASTO: Strategic Parameter Optimization in Recommendation Systems -- Probabilistic is Better than Deterministic](http://arxiv.org/abs/2108.09076)


  Real-world recommendation systems often consist of two phases. In the first
phase, multiple predictive models produce the probability of different
immediate user actions. In the second phase, these predictions are aggregated
according to a set of 'strategic parameters' to meet a diverse set of business
goals, such as longer user engagement, higher revenue potential, or more
community/network interactions. In addition to building accurate predictive
models, it is also crucial to optimize this set of 'strategic parameters' so
that primary goals are optimized while secondary guardrails are not hurt. In
this setting with multiple and constrained goals, this paper discovers that a
probabilistic strategic parameter regime can achieve better value compared to
the standard regime of finding a single deterministic parameter. The new
probabilistic regime is to learn the best distribution over strategic parameter
choices and sample one strategic parameter from the distribution when each user
visits the platform. To pursue the optimal probabilistic solution, we formulate
the problem into a stochastic compositional optimization problem, in which the
unbiased stochastic gradient is unavailable. Our approach is applied in a
popular social network platform with hundreds of millions of daily users and
achieves +0.22% lift of user engagement in a recommendation task and +1.7% lift
in revenue in an advertising optimization scenario comparing to using the best
deterministic parameter strategy.

    

### [[2108.09081] FedSkel: Efficient Federated Learning on Heterogeneous Systems with Skeleton Gradients Update](http://arxiv.org/abs/2108.09081)


  Federated learning aims to protect users' privacy while performing data
analysis from different participants. However, it is challenging to guarantee
the training efficiency on heterogeneous systems due to the various
computational capabilities and communication bottlenecks. In this work, we
propose FedSkel to enable computation-efficient and communication-efficient
federated learning on edge devices by only updating the model's essential
parts, named skeleton networks. FedSkel is evaluated on real edge devices with
imbalanced datasets. Experimental results show that it could achieve up to
5.52$\times$ speedups for CONV layers' back-propagation, 1.82$\times$ speedups
for the whole training process, and reduce 64.8% communication cost, with
negligible accuracy loss.

    

### [[2108.09091] DL-Traff: Survey and Benchmark of Deep Learning Models for Urban Traffic Prediction](http://arxiv.org/abs/2108.09091)


  Nowadays, with the rapid development of IoT (Internet of Things) and CPS
(Cyber-Physical Systems) technologies, big spatiotemporal data are being
generated from mobile phones, car navigation systems, and traffic sensors. By
leveraging state-of-the-art deep learning technologies on such data, urban
traffic prediction has drawn a lot of attention in AI and Intelligent
Transportation System community. The problem can be uniformly modeled with a 3D
tensor (T, N, C), where T denotes the total time steps, N denotes the size of
the spatial domain (i.e., mesh-grids or graph-nodes), and C denotes the
channels of information. According to the specific modeling strategy, the
state-of-the-art deep learning models can be divided into three categories:
grid-based, graph-based, and multivariate time-series models. In this study, we
first synthetically review the deep traffic models as well as the widely used
datasets, then build a standard benchmark to comprehensively evaluate their
performances with the same settings and metrics. Our study named DL-Traff is
implemented with two most popular deep learning frameworks, i.e., TensorFlow
and PyTorch, which is already publicly available as two GitHub repositories
this https URL and
this https URL. With DL-Traff, we hope to
deliver a useful resource to researchers who are interested in spatiotemporal
data analysis.

    

### [[2108.09093] Towards Understanding the Generative Capability of Adversarially Robust Classifiers](http://arxiv.org/abs/2108.09093)


  Recently, some works found an interesting phenomenon that adversarially
robust classifiers can generate good images comparable to generative models. We
investigate this phenomenon from an energy perspective and provide a novel
explanation. We reformulate adversarial example generation, adversarial
training, and image generation in terms of an energy function. We find that
adversarial training contributes to obtaining an energy function that is flat
and has low energy around the real data, which is the key for generative
capability. Based on our new understanding, we further propose a better
adversarial training method, Joint Energy Adversarial Training (JEAT), which
can generate high-quality images and achieve new state-of-the-art robustness
under a wide range of attacks. The Inception Score of the images (CIFAR-10)
generated by JEAT is 8.80, much better than original robust classifiers (7.50).
In particular, we achieve new state-of-the-art robustness on CIFAR-10 (from
57.20% to 62.04%) and CIFAR-100 (from 30.03% to 30.18%) without extra training
data.

    

### [[2108.09098] A fuzzy-rough uncertainty measure to discover bias encoded explicitly or implicitly in features of structured pattern classification datasets](http://arxiv.org/abs/2108.09098)


  The need to measure bias encoded in tabular data that are used to solve
pattern recognition problems is widely recognized by academia, legislators and
enterprises alike. In previous work, we proposed a bias quantification measure,
called fuzzy-rough uncer-tainty, which relies on the fuzzy-rough set theory.
The intuition dictates that protected features should not change the
fuzzy-rough boundary regions of a decision class significantly. The extent to
which this happens is a proxy for bias expressed as uncertainty in
adecision-making context. Our measure's main advantage is that it does not
depend on any machine learning prediction model but adistance function. In this
paper, we extend our study by exploring the existence of bias encoded
implicitly in non-protected featuresas defined by the correlation between
protected and unprotected attributes. This analysis leads to four scenarios
that domain experts should evaluate before deciding how to tackle bias. In
addition, we conduct a sensitivity analysis to determine the fuzzy operatorsand
distance function that best capture change in the boundary regions.

    

### [[2108.09105] Airbert: In-domain Pretraining for Vision-and-Language Navigation](http://arxiv.org/abs/2108.09105)


  Vision-and-language navigation (VLN) aims to enable embodied agents to
navigate in realistic environments using natural language instructions. Given
the scarcity of domain-specific training data and the high diversity of image
and language inputs, the generalization of VLN agents to unseen environments
remains challenging. Recent methods explore pretraining to improve
generalization, however, the use of generic image-caption datasets or existing
small-scale VLN environments is suboptimal and results in limited improvements.
In this work, we introduce BnB, a large-scale and diverse in-domain VLN
dataset. We first collect image-caption (IC) pairs from hundreds of thousands
of listings from online rental marketplaces. Using IC pairs we next propose
automatic strategies to generate millions of VLN path-instruction (PI) pairs.
We further propose a shuffling loss that improves the learning of temporal
order inside PI pairs. We use BnB pretrain our Airbert model that can be
adapted to discriminative and generative settings and show that it outperforms
state of the art for Room-to-Room (R2R) navigation and Remote Referring
Expression (REVERIE) benchmarks. Moreover, our in-domain pretraining
significantly increases performance on a challenging few-shot VLN evaluation,
where we train the model only on VLN instructions from a few houses.

    

### [[2108.09126] Lessons from the Clustering Analysis of a Search Space: A Centroid-based Approach to Initializing NAS](http://arxiv.org/abs/2108.09126)


  Lots of effort in neural architecture search (NAS) research has been
dedicated to algorithmic development, aiming at designing more efficient and
less costly methods. Nonetheless, the investigation of the initialization of
these techniques remain scare, and currently most NAS methodologies rely on
stochastic initialization procedures, because acquiring information prior to
search is costly. However, the recent availability of NAS benchmarks have
enabled low computational resources prototyping. In this study, we propose to
accelerate a NAS algorithm using a data-driven initialization technique,
leveraging the availability of NAS benchmarks. Particularly, we proposed a
two-step methodology. First, a calibrated clustering analysis of the search
space is performed. Second, the centroids are extracted and used to initialize
a NAS algorithm. We tested our proposal using Aging Evolution, an evolutionary
algorithm, on NAS-bench-101. The results show that, compared to a random
initialization, a faster convergence and a better performance of the final
solution is achieved.

    

### [[2108.09127] TabGNN: Multiplex Graph Neural Network for Tabular Data Prediction](http://arxiv.org/abs/2108.09127)


  Tabular data prediction (TDP) is one of the most popular industrial
applications, and various methods have been designed to improve the prediction
performance. However, existing works mainly focus on feature interactions and
ignore sample relations, e.g., users with the same education level might have a
similar ability to repay the debt. In this work, by explicitly and
systematically modeling sample relations, we propose a novel framework TabGNN
based on recently popular graph neural networks (GNN). Specifically, we firstly
construct a multiplex graph to model the multifaceted sample relations, and
then design a multiplex graph neural network to learn enhanced representation
for each sample. To integrate TabGNN with the tabular solution in our company,
we concatenate the learned embeddings and the original ones, which are then fed
to prediction models inside the solution. Experiments on eleven TDP datasets
from various domains, including classification and regression ones, show that
TabGNN can consistently improve the performance compared to the tabular
solution AutoFE in 4Paradigm.

    

### [[2108.09128] Semi-supervised Network Embedding with Differentiable Deep Quantisation](http://arxiv.org/abs/2108.09128)


  Learning accurate low-dimensional embeddings for a network is a crucial task
as it facilitates many downstream network analytics tasks. For large networks,
the trained embeddings often require a significant amount of space to store,
making storage and processing a challenge. Building on our previous work on
semi-supervised network embedding, we develop d-SNEQ, a differentiable
DNN-based quantisation method for network embedding. d-SNEQ incorporates a rank
loss to equip the learned quantisation codes with rich high-order information
and is able to substantially compress the size of trained embeddings, thus
reducing storage footprint and accelerating retrieval speed. We also propose a
new evaluation metric, path prediction, to fairly and more directly evaluate
model performance on the preservation of high-order information. Our evaluation
on four real-world networks of diverse characteristics shows that d-SNEQ
outperforms a number of state-of-the-art embedding methods in link prediction,
path prediction, node classification, and node recommendation while being far
more space- and time-efficient.

    

### [[2108.09131] Combination of Transfer Learning, Recursive Learning and Ensemble Learning for Multi-Day Ahead COVID-19 Cases Prediction in India using Gated Recurrent Unit Networks](http://arxiv.org/abs/2108.09131)


  The current COVID-19 pandemic has put a huge challenge on the Indian health
infrastructure. With more and more people getting affected during the second
wave, the hospitals were over-burdened, running out of supplies and oxygen. In
this scenario, prediction of the number of COVID-19 cases beforehand might have
helped in the better utilization of limited resources and supplies. This
manuscript deals with the prediction of new COVID-19 cases, new deaths and
total active cases for multiple days in advance. The proposed method uses gated
recurrent unit networks as the main predicting model. A study is conducted by
building four models that are pre-trained on the data from four different
countries (United States of America, Brazil, Spain and Bangladesh) and are
fine-tuned or retrained on India's data. Since the four countries chosen have
experienced different types of infection curves, the pre-training provides a
transfer learning to the models incorporating diverse situations into account.
Each of the four models then give a multiple days ahead predictions using
recursive learning method for the Indian test data. The final prediction comes
from an ensemble of the predictions of the combination of different models.
This method with two countries, Spain and Brazil, is seen to achieve the best
performance amongst all the combinations as well as compared to other
traditional regression models.

    

### [[2108.09133] Estimation of Convex Polytopes for Automatic Discovery of Charge State Transitions in Quantum Dot Arrays](http://arxiv.org/abs/2108.09133)


  In spin based quantum dot arrays, a leading technology for quantum
computation applications, material or fabrication imprecisions affect the
behaviour of the device, which is compensated via tuning parameters. Automatic
tuning of these device parameters constitutes a formidable challenge for
machine-learning. Here, we present the first practical algorithm for
controlling the transition of electrons in a spin qubit array. We exploit a
connection to computational geometry and phrase the task as estimating a convex
polytope from measurements.
Our proposed algorithm uses active learning, to find the count, shapes and
sizes of all facets of a given polytope. We test our algorithm on artifical
polytopes as well as a real 2x2 spin qubit array. Our results show that we can
reliably find the facets of the polytope, including small facets with sizes on
the order of the measurement precision. We discuss the implications of the
NP-hardness of the underlying estimation problem and outline design
considerations, limitations and tuning strategies for controlling future
large-scale spin qubit devices.

    

### [[2108.09134] Accelerating Federated Learning with a Global Biased Optimiser](http://arxiv.org/abs/2108.09134)


  Federated Learning (FL) is a recent development in the field of machine
learning that collaboratively trains models without the training data leaving
client devices, in order to preserve data-privacy. In realistic settings, the
total training set is distributed over clients in a highly non-Independent and
Identically Distributed (non-IID) fashion, which has been shown extensively to
harm FL convergence speed and final model performance. We propose a novel,
generalised approach for applying adaptive optimisation techniques to FL with
the Federated Global Biased Optimiser (FedGBO) algorithm. FedGBO accelerates FL
by applying a set of global biased optimiser values during the local training
phase of FL, which helps to reduce `client-drift' from non-IID data, whilst
also benefiting from adaptive momentum/learning-rate methods. We show that the
FedGBO update with a generic optimiser can be viewed as a centralised update
with biased gradients and optimiser update, and use this theoretical framework
to prove the convergence of FedGBO using momentum-Stochastic Gradient Descent.
We also perform extensive experiments using 4 realistic benchmark FL datasets
and 3 popular adaptive optimisers to compare the performance of different
adaptive-FL approaches, demonstrating that FedGBO has highly competitive
performance considering its low communication and computation costs, and
providing highly practical insights for the use of adaptive optimisation in FL.

    

### [[2108.09136] Unsupervised Domain-adaptive Hash for Networks](http://arxiv.org/abs/2108.09136)


  Abundant real-world data can be naturally represented by large-scale
networks, which demands efficient and effective learning algorithms. At the
same time, labels may only be available for some networks, which demands these
algorithms to be able to adapt to unlabeled networks. Domain-adaptive hash
learning has enjoyed considerable success in the computer vision community in
many practical tasks due to its lower cost in both retrieval time and storage
footprint. However, it has not been applied to multiple-domain networks. In
this work, we bridge this gap by developing an unsupervised domain-adaptive
hash learning method for networks, dubbed UDAH. Specifically, we develop four
{task-specific yet correlated} components: (1) network structure preservation
via a hard groupwise contrastive loss, (2) relaxation-free supervised hashing,
(3) cross-domain intersected discriminators, and (4) semantic center alignment.
We conduct a wide range of experiments to evaluate the effectiveness and
efficiency of our method on a range of tasks including link prediction, node
classification, and neighbor recommendation. Our evaluation results demonstrate
that our model achieves better performance than the state-of-the-art
conventional discrete embedding methods over all the tasks.

    

### [[2108.09141] Reinforcement Learning to Optimize Lifetime Value in Cold-Start Recommendation](http://arxiv.org/abs/2108.09141)


  Recommender system plays a crucial role in modern E-commerce platform. Due to
the lack of historical interactions between users and items, cold-start
recommendation is a challenging problem. In order to alleviate the cold-start
issue, most existing methods introduce content and contextual information as
the auxiliary information. Nevertheless, these methods assume the recommended
items behave steadily over time, while in a typical E-commerce scenario, items
generally have very different performances throughout their life period. In
such a situation, it would be beneficial to consider the long-term return from
the item perspective, which is usually ignored in conventional methods.
Reinforcement learning (RL) naturally fits such a long-term optimization
problem, in which the recommender could identify high potential items,
proactively allocate more user impressions to boost their growth, therefore
improve the multi-period cumulative gains. Inspired by this idea, we model the
process as a Partially Observable and Controllable Markov Decision Process
(POC-MDP), and propose an actor-critic RL framework (RL-LTV) to incorporate the
item lifetime values (LTV) into the recommendation. In RL-LTV, the critic
studies historical trajectories of items and predict the future LTV of fresh
item, while the actor suggests a score-based policy which maximizes the future
LTV expectation. Scores suggested by the actor are then combined with classical
ranking scores in a dual-rank framework, therefore the recommendation is
balanced with the LTV consideration. Our method outperforms the strong live
baseline with a relative improvement of 8.67% and 18.03% on IPV and GMV of
cold-start items, on one of the largest E-commerce platform.

    

### [[2108.09151] Group-based Distinctive Image Captioning with Memory Attention](http://arxiv.org/abs/2108.09151)


  Describing images using natural language is widely known as image captioning,
which has made consistent progress due to the development of computer vision
and natural language generation techniques. Though conventional captioning
models achieve high accuracy based on popular metrics, i.e., BLEU, CIDEr, and
SPICE, the ability of captions to distinguish the target image from other
similar images is under-explored. To generate distinctive captions, a few
pioneers employ contrastive learning or re-weighted the ground-truth captions,
which focuses on one single input image. However, the relationships between
objects in a similar image group (e.g., items or properties within the same
album or fine-grained events) are neglected. In this paper, we improve the
distinctiveness of image captions using a Group-based Distinctive Captioning
Model (GdisCap), which compares each image with other images in one similar
group and highlights the uniqueness of each image. In particular, we propose a
group-based memory attention (GMA) module, which stores object features that
are unique among the image group (i.e., with low similarity to objects in other
images). These unique object features are highlighted when generating captions,
resulting in more distinctive captions. Furthermore, the distinctive words in
the ground-truth captions are selected to supervise the language decoder and
GMA. Finally, we propose a new evaluation metric, distinctive word rate
(DisWordRate) to measure the distinctiveness of captions. Quantitative results
indicate that the proposed method significantly improves the distinctiveness of
several baseline models, and achieves the state-of-the-art performance on both
accuracy and distinctiveness. Results of a user study agree with the
quantitative evaluation and demonstrate the rationality of the new metric
DisWordRate.

    

### [[2108.09154] Contrastive Representations for Label Noise Require Fine-Tuning](http://arxiv.org/abs/2108.09154)


  In this paper we show that the combination of a Contrastive representation
with a label noise-robust classification head requires fine-tuning the
representation in order to achieve state-of-the-art performances. Since
fine-tuned representations are shown to outperform frozen ones, one can
conclude that noise-robust classification heads are indeed able to promote
meaningful representations if provided with a suitable starting point.
Experiments are conducted to draw a comprehensive picture of performances by
featuring six methods and nine noise instances of three different kinds (none,
symmetric, and asymmetric). In presence of noise the experiments show that fine
tuning of Contrastive representation allows the six methods to achieve better
results than end-to-end learning and represent a new reference compare to the
recent state of art. Results are also remarkable stable versus the noise level.

    

### [[2108.09159] VAE-CE: Visual Contrastive Explanation using Disentangled VAEs](http://arxiv.org/abs/2108.09159)


  The goal of a classification model is to assign the correct labels to data.
In most cases, this data is not fully described by the given set of labels.
Often a rich set of meaningful concepts exist in the domain that can much more
precisely describe each datapoint. Such concepts can also be highly useful for
interpreting the model's classifications. In this paper we propose a model,
denoted as Variational Autoencoder-based Contrastive Explanation (VAE-CE), that
represents data with high-level concepts and uses this representation for both
classification and generating explanations. The explanations are produced in a
contrastive manner, conveying why a datapoint is assigned to one class rather
than an alternative class. An explanation is specified as a set of
transformations of the input datapoint, with each step depicting a concept
changing towards the contrastive class. We build the model using a disentangled
VAE, extended with a new supervised method for disentangling individual
dimensions. An analysis on synthetic data and MNIST shows that the approaches
to both disentanglement and explanation provide benefits over other methods.

    

### [[2108.09160] State-Of-The-Art Algorithms For Low-Rank Dynamic Mode Decomposition](http://arxiv.org/abs/2108.09160)


  This technical note reviews sate-of-the-art algorithms for linear
approximation of high-dimensional dynamical systems using low-rank dynamic mode
decomposition (DMD). While repeating several parts of our article "low-rank
dynamic mode decomposition: an exact and tractable solution", this work
provides additional details useful for building a comprehensive picture of
state-of-the-art methods.

    

### [[2108.09187] Quantization Backdoors to Deep Learning Models](http://arxiv.org/abs/2108.09187)


  There is currently a burgeoning demand for deploying deep learning (DL)
models on ubiquitous edge Internet of Things devices attributing to their low
latency and high privacy preservation. However, DL models are often large in
size and require large-scale computation, which prevents them from being placed
directly onto IoT devices where resources are constrained and 32-bit
floating-point operations are unavailable. Model quantization is a pragmatic
solution, which enables DL deployment on mobile devices and embedded systems by
effortlessly post-quantizing a large high-precision model into a small
low-precision model while retaining the model inference accuracy.
This work reveals that the standard quantization operation can be abused to
activate a backdoor. We demonstrate that a full-precision backdoored model that
does not have any backdoor effect in the presence of a trigger -- as the
backdoor is dormant -- can be activated by the default TensorFlow-Lite
quantization, the only product-ready quantization framework to date. We
ascertain that all trained float-32 backdoored models exhibit no backdoor
effect even in the presence of trigger inputs. State-of-the-art frontend
detection approaches, such as Neural Cleanse and STRIP, fail to identify the
backdoor in the float-32 models. When each of the float-32 models is converted
into an int-8 format model through the standard TFLite post-training
quantization, the backdoor is activated in the quantized model, which shows a
stable attack success rate close to 100% upon inputs with the trigger, while
behaves normally upon non-trigger inputs. This work highlights that a stealthy
security threat occurs when end users utilize the on-device post-training model
quantization toolkits, informing security researchers of cross-platform
overhaul of DL models post quantization even if they pass frontend inspections.

    

### [[2108.09203] Parsing Birdsong with Deep Audio Embeddings](http://arxiv.org/abs/2108.09203)


  Monitoring of bird populations has played a vital role in conservation
efforts and in understanding biodiversity loss. The automation of this process
has been facilitated by both sensing technologies, such as passive acoustic
monitoring, and accompanying analytical tools, such as deep learning. However,
machine learning models frequently have difficulty generalizing to examples not
encountered in the training data. In our work, we present a semi-supervised
approach to identify characteristic calls and environmental noise. We utilize
several methods to learn a latent representation of audio samples, including a
convolutional autoencoder and two pre-trained networks, and group the resulting
embeddings for a domain expert to identify cluster labels. We show that our
approach can improve classification precision and provide insight into the
latent structure of environmental acoustic datasets.

    

### [[2108.09262] Optimal Order Simple Regret for Gaussian Process Bandits](http://arxiv.org/abs/2108.09262)


  Consider the sequential optimization of a continuous, possibly non-convex,
and expensive to evaluate objective function $f$. The problem can be cast as a
Gaussian Process (GP) bandit where $f$ lives in a reproducing kernel Hilbert
space (RKHS). The state of the art analysis of several learning algorithms
shows a significant gap between the lower and upper bounds on the simple regret
performance. When $N$ is the number of exploration trials and $\gamma_N$ is the
maximal information gain, we prove an $\tilde{\mathcal{O}}(\sqrt{\gamma_N/N})$
bound on the simple regret performance of a pure exploration algorithm that is
significantly tighter than the existing bounds. We show that this bound is
order optimal up to logarithmic factors for the cases where a lower bound on
regret is known. To establish these results, we prove novel and sharp
confidence intervals for GP models applicable to RKHS elements which may be of
broader interest.

    

### [[2108.09264] Practical and Fast Momentum-Based Power Methods](http://arxiv.org/abs/2108.09264)


  The power method is a classical algorithm with broad applications in machine
learning tasks, including streaming PCA, spectral clustering, and low-rank
matrix approximation. The distilled purpose of the vanilla power method is to
determine the largest eigenvalue (in absolute modulus) and its eigenvector of a
matrix. A momentum-based scheme can be used to accelerate the power method, but
achieving an optimal convergence rate with existing algorithms critically
relies on additional spectral information that is unavailable at run-time, and
sub-optimal initializations can result in divergence. In this paper, we provide
a pair of novel momentum-based power methods, which we call the delayed
momentum power method (DMPower) and a streaming variant, the delayed momentum
streaming method (DMStream). Our methods leverage inexact deflation and are
capable of achieving near-optimal convergence with far less restrictive
hyperparameter requirements. We provide convergence analyses for both
algorithms through the lens of perturbation theory. Further, we experimentally
demonstrate that DMPower routinely outperforms the vanilla power method and
that both algorithms match the convergence speed of an oracle running existing
accelerated methods with perfect spectral knowledge.

    

### [[2108.09265] Efficient Online Estimation of Causal Effects by Deciding What to Observe](http://arxiv.org/abs/2108.09265)


  Researchers often face data fusion problems, where multiple data sources are
available, each capturing a distinct subset of variables. While problem
formulations typically take the data as given, in practice, data acquisition
can be an ongoing process. In this paper, we aim to estimate any functional of
a probabilistic model (e.g., a causal effect) as efficiently as possible, by
deciding, at each time, which data source to query. We propose online moment
selection (OMS), a framework in which structural assumptions are encoded as
moment conditions. The optimal action at each step depends, in part, on the
very moments that identify the functional of interest. Our algorithms balance
exploration with choosing the best action as suggested by current estimates of
the moments. We propose two selection strategies: (1) explore-then-commit
(OMS-ETC) and (2) explore-then-greedy (OMS-ETG), proving that both achieve zero
asymptotic regret as assessed by MSE. We instantiate our setup for average
treatment effect estimation, where structural assumptions are given by a causal
graph and data sources may include subsets of mediators, confounders, and
instrumental variables.

    

### [[2108.09275] A Recommender System for Scientific Datasets and Analysis Pipelines](http://arxiv.org/abs/2108.09275)


  Scientific datasets and analysis pipelines are increasingly being shared
publicly in the interest of open science. However, mechanisms are lacking to
reliably identify which pipelines and datasets can appropriately be used
together. Given the increasing number of high-quality public datasets and
pipelines, this lack of clear compatibility threatens the findability and
reusability of these resources. We investigate the feasibility of a
collaborative filtering system to recommend pipelines and datasets based on
provenance records from previous executions. We evaluate our system using
datasets and pipelines extracted from the Canadian Open Neuroscience Platform,
a national initiative for open neuroscience. The recommendations provided by
our system (AUC$=0.83$) are significantly better than chance and outperform
recommendations made by domain experts using their previous knowledge as well
as pipeline and dataset descriptions (AUC$=0.63$). In particular, domain
experts often neglect low-level technical aspects of a pipeline-dataset
interaction, such as the level of pre-processing, which are captured by a
provenance-based system. We conclude that provenance-based pipeline and dataset
recommenders are feasible and beneficial to the sharing and usage of
open-science resources. Future work will focus on the collection of more
comprehensive provenance traces, and on deploying the system in production.

    

### [[2108.09277] MHealth: An Artificial Intelligence Oriented Mobile Application for Personal Healthcare Support](http://arxiv.org/abs/2108.09277)


  Main objective of this study is to introduce an expert system-based mHealth
application that takes Artificial Intelligence support by considering
previously introduced solutions from the literature and employing possible
requirements for a better solution. Thanks to that research study, a mobile
software system having Artificial Intelligence support and providing dynamic
support against the common health problems in daily life was designed-developed
and it was evaluated via survey and diagnosis-based evaluation tasks.
Evaluation tasks indicated positive outcomes for the mHealth system.

    

### [[2108.09292] Network-wide link travel time and station waiting time estimation using automatic fare collection data: A computational graph approach](http://arxiv.org/abs/2108.09292)


  Urban rail transit (URT) system plays a dominating role in many megacities
like Beijing and Hong Kong. Due to its important role and complex nature, it is
always in great need for public agencies to better understand the performance
of the URT system. This paper focuses on an essential and hard problem to
estimate the network-wide link travel time and station waiting time using the
automatic fare collection (AFC) data in the URT system, which is beneficial to
better understand the system-wide real-time operation state. The emerging
data-driven techniques, such as computational graph (CG) models in the machine
learning field, provide a new solution for solving this problem. In this study,
we first formulate a data-driven estimation optimization framework to estimate
the link travel time and station waiting time. Then, we cast the estimation
optimization model into a CG framework to solve the optimization problem and
obtain the estimation results. The methodology is verified on a synthetic URT
network and applied to a real-world URT network using the synthetic and
real-world AFC data, respectively. Results show the robustness and
effectiveness of the CG-based framework. To the best of our knowledge, this is
the first time that the CG is applied to the URT. This study can provide
critical insights to better understand the operational state in URT.

    

### [[1806.05438] Stochastic Gradient Descent with Exponential Convergence Rates of Expected Classification Errors](http://arxiv.org/abs/1806.05438)


  We consider stochastic gradient descent and its averaging variant for binary
classification problems in a reproducing kernel Hilbert space. In the
traditional analysis using a consistency property of loss functions, it is
known that the expected classification error converges more slowly than the
expected risk even when assuming a low-noise condition on the conditional label
probabilities. Consequently, the resulting rate is sublinear. Therefore, it is
important to consider whether much faster convergence of the expected
classification error can be achieved. In recent research, an exponential
convergence rate for stochastic gradient descent was shown under a strong
low-noise condition but provided theoretical analysis was limited to the
squared loss function, which is somewhat inadequate for binary classification
tasks. In this paper, we show an exponential convergence of the expected
classification error in the final phase of the stochastic gradient descent for
a wide class of differentiable convex loss functions under similar assumptions.
As for the averaged stochastic gradient descent, we show that the same
convergence rate holds from the early phase of training. In experiments, we
verify our analyses on the $L_2$-regularized logistic regression.

    

### [[1810.10167] Nonconvex and Nonsmooth Sparse Optimization via Adaptively Iterative Reweighted Methods](http://arxiv.org/abs/1810.10167)


  We propose a general formulation of nonconvex and nonsmooth sparse
optimization problems with convex set constraint, which can take into account
most existing types of nonconvex sparsity-inducing terms, bringing strong
applicability to a wide range of applications. We design a general algorithmic
framework of iteratively reweighted algorithms for solving the proposed
nonconvex and nonsmooth sparse optimization problems, which solves a sequence
of weighted convex regularization problems with adaptively updated weights.
First-order optimality condition is derived and global convergence results are
provided under loose assumptions, making our theoretical results a practical
tool for analyzing a family of various reweighted algorithms. The effectiveness
and efficiency of our proposed formulation and the algorithms are demonstrated
in numerical experiments on various sparse optimization problems.

    

### [[1911.05496] Temporal Graph Kernels for Classifying Dissemination Processes](http://arxiv.org/abs/1911.05496)


  Many real-world graphs or networks are temporal, e.g., in a social network
persons only interact at specific points in time. This information directs
dissemination processes on the network, such as the spread of rumors, fake
news, or diseases. However, the current state-of-the-art methods for supervised
graph classification are designed mainly for static graphs and may not be able
to capture temporal information. Hence, they are not powerful enough to
distinguish between graphs modeling different dissemination processes. To
address this, we introduce a framework to lift standard graph kernels to the
temporal domain. Specifically, we explore three different approaches and
investigate the trade-offs between loss of temporal information and efficiency.
Moreover, to handle large-scale graphs, we propose stochastic variants of our
kernels with provable approximation guarantees. We evaluate our methods on a
wide range of real-world social networks. Our methods beat static kernels by a
large margin in terms of accuracy while still being scalable to large graphs
and data sets. Hence, we confirm that taking temporal information into account
is crucial for the successful classification of dissemination processes.

    

### [[2003.12725] A Graph to Graphs Framework for Retrosynthesis Prediction](http://arxiv.org/abs/2003.12725)


  A fundamental problem in computational chemistry is to find a set of
reactants to synthesize a target molecule, a.k.a. retrosynthesis prediction.
Existing state-of-the-art methods rely on matching the target molecule with a
large set of reaction templates, which are very computationally expensive and
also suffer from the problem of coverage. In this paper, we propose a novel
template-free approach called G2Gs by transforming a target molecular graph
into a set of reactant molecular graphs. G2Gs first splits the target molecular
graph into a set of synthons by identifying the reaction centers, and then
translates the synthons to the final reactant graphs via a variational graph
translation framework. Experimental results show that G2Gs significantly
outperforms existing template-free approaches by up to 63% in terms of the
top-1 accuracy and achieves a performance close to that of state-of-the-art
template based approaches, but does not require domain knowledge and is much
more scalable.

    

### [[2004.06373] Minority Oversampling for Imbalanced Time Series Classification](http://arxiv.org/abs/2004.06373)


  Many important real-world applications involve time-series data with skewed
distribution. Compared to conventional imbalance learning problems, the
classification of imbalanced time-series data is more challenging due to high
dimensionality and high inter-variable correlation. This paper proposes a
structure preserving Oversampling method to combat the High-dimensional
Imbalanced Time-series classification (OHIT). OHIT first leverages a
density-ratio based shared nearest neighbor clustering algorithm to capture the
modes of minority class in high-dimensional space. It then for each mode
applies the shrinkage technique of large-dimensional covariance matrix to
obtain accurate and reliable covariance structure. Finally, OHIT generates the
structure-preserving synthetic samples based on multivariate Gaussian
distribution by using the estimated covariance matrices. Experimental results
on several publicly available time-series datasets (including unimodal and
multimodal) demonstrate the superiority of OHIT against the state-of-the-art
oversampling algorithms in terms of F1, G-mean, and AUC.

    

### [[2006.06500] Rethinking the Truly Unsupervised Image-to-Image Translation](http://arxiv.org/abs/2006.06500)


  Every recent image-to-image translation model inherently requires either
image-level (i.e. input-output pairs) or set-level (i.e. domain labels)
supervision. However, even set-level supervision can be a severe bottleneck for
data collection in practice. In this paper, we tackle image-to-image
translation in a fully unsupervised setting, i.e., neither paired images nor
domain labels. To this end, we propose a truly unsupervised image-to-image
translation model (TUNIT) that simultaneously learns to separate image domains
and translates input images into the estimated domains. Experimental results
show that our model achieves comparable or even better performance than the
set-level supervised model trained with full labels, generalizes well on
various datasets, and is robust against the choice of hyperparameters (e.g. the
preset number of pseudo domains). Furthermore, TUNIT can be easily extended to
semi-supervised learning with a few labeled data.

    

### [[2008.09657] GraphReach: Position-Aware Graph Neural Network using Reachability Estimations](http://arxiv.org/abs/2008.09657)


  Majority of the existing graph neural networks (GNN) learn node embeddings
that encode their local neighborhoods but not their positions. Consequently,
two nodes that are vastly distant but located in similar local neighborhoods
map to similar embeddings in those networks. This limitation prevents accurate
performance in predictive tasks that rely on position information. In this
paper, we develop GraphReach, a position-aware inductive GNN that captures the
global positions of nodes through reachability estimations with respect to a
set of anchor nodes. The anchors are strategically selected so that
reachability estimations across all the nodes are maximized. We show that this
combinatorial anchor selection problem is NP-hard and, consequently, develop a
greedy (1-1/e) approximation heuristic. Empirical evaluation against
state-of-the-art GNN architectures reveal that GraphReach provides up to 40%
relative improvement in accuracy. In addition, it is more robust to adversarial
attacks.

    

### [[2008.10327] Knowledge-Empowered Representation Learning for Chinese Medical Reading Comprehension: Task, Model and Resources](http://arxiv.org/abs/2008.10327)


  Machine Reading Comprehension (MRC) aims to extract answers to questions
given a passage. It has been widely studied recently, especially in open
domains. However, few efforts have been made on closed-domain MRC, mainly due
to the lack of large-scale training data. In this paper, we introduce a
multi-target MRC task for the medical domain, whose goal is to predict answers
to medical questions and the corresponding support sentences from medical
information sources simultaneously, in order to ensure the high reliability of
medical knowledge serving. A high-quality dataset is manually constructed for
the purpose, named Multi-task Chinese Medical MRC dataset (CMedMRC), with
detailed analysis conducted. We further propose the Chinese medical BERT model
for the task (CMedBERT), which fuses medical knowledge into pre-trained
language models by the dynamic fusion mechanism of heterogeneous features and
the multi-task learning strategy. Experiments show that CMedBERT consistently
outperforms strong baselines by fusing context-aware and knowledge-aware token
representations.

    

### [[2009.13562] STRATA: Simple, Gradient-Free Attacks for Models of Code](http://arxiv.org/abs/2009.13562)


  Neural networks are well-known to be vulnerable to imperceptible
perturbations in the input, called adversarial examples, that result in
misclassification. Generating adversarial examples for source code poses an
additional challenge compared to the domains of images and natural language,
because source code perturbations must retain the functional meaning of the
code. We identify a striking relationship between token frequency statistics
and learned token embeddings: the L2 norm of learned token embeddings increases
with the frequency of the token except for the highest-frequnecy tokens. We
leverage this relationship to construct a simple and efficient gradient-free
method for generating state-of-the-art adversarial examples on models of code.
Our method empirically outperforms competing gradient-based methods with less
information and less computational effort.

    

### [[2009.13586] Apollo: An Adaptive Parameter-wise Diagonal Quasi-Newton Method for Nonconvex Stochastic Optimization](http://arxiv.org/abs/2009.13586)


  In this paper, we introduce Apollo, a quasi-Newton method for nonconvex
stochastic optimization, which dynamically incorporates the curvature of the
loss function by approximating the Hessian via a diagonal matrix. Importantly,
the update and storage of the diagonal approximation of Hessian is as efficient
as adaptive first-order optimization methods with linear complexity for both
time and memory. To handle nonconvexity, we replace the Hessian with its
rectified absolute value, which is guaranteed to be positive-definite.
Experiments on three tasks of vision and language show that Apollo achieves
significant improvements over other stochastic optimization methods, including
SGD and variants of Adam, in term of both convergence speed and generalization
performance. The implementation of the algorithm is available at
this https URL.

    

### [[2010.04444] Jointly-Learned State-Action Embedding for Efficient Reinforcement Learning](http://arxiv.org/abs/2010.04444)


  While reinforcement learning has achieved considerable successes in recent
years, state-of-the-art models are often still limited by the size of state and
action spaces. Model-free reinforcement learning approaches use some form of
state representations and the latest work has explored embedding techniques for
actions, both with the aim of achieving better generalization and
applicability. However, these approaches consider only states or actions,
ignoring the interaction between them when generating embedded representations.
In this work, we establish the theoretical foundations for the validity of
training a reinforcement learning agent using embedded states and actions. We
then propose a new approach for jointly learning embeddings for states and
actions that combines aspects of model-free and model-based reinforcement
learning, which can be applied in both discrete and continuous domains.
Specifically, we use a model of the environment to obtain embeddings for states
and actions and present a generic architecture that leverages these to learn a
policy. In this way, the embedded representations obtained via our approach
enable better generalization over both states and actions by capturing
similarities in the embedding spaces. Evaluations of our approach on several
gaming, robotic control, and recommender systems show it significantly
outperforms state-of-the-art models in both discrete/continuous domains with
large state/action spaces, thus confirming its efficacy.

    

### [[2011.04297] Knowledge Distillation for Singing Voice Detection](http://arxiv.org/abs/2011.04297)


  Singing Voice Detection (SVD) has been an active area of research in music
information retrieval (MIR). Currently, two deep neural network-based methods,
one based on CNN and the other on RNN, exist in literature that learn optimized
features for the voice detection (VD) task and achieve state-of-the-art
performance on common datasets. Both these models have a huge number of
parameters (1.4M for CNN and 65.7K for RNN) and hence not suitable for
deployment on devices like smartphones or embedded sensors with limited
capacity in terms of memory and computation power. The most popular method to
address this issue is known as knowledge distillation in deep learning
literature (in addition to model compression) where a large pre-trained network
known as the teacher is used to train a smaller student network. Given the wide
applications of SVD in music information retrieval, to the best of our
knowledge, model compression for practical deployment has not yet been
explored. In this paper, efforts have been made to investigate this issue using
both conventional as well as ensemble knowledge distillation techniques.

    

### [[2011.13322] Spatio-Temporal Inception Graph Convolutional Networks for Skeleton-Based Action Recognition](http://arxiv.org/abs/2011.13322)


  Skeleton-based human action recognition has attracted much attention with the
prevalence of accessible depth sensors. Recently, graph convolutional networks
(GCNs) have been widely used for this task due to their powerful capability to
model graph data. The topology of the adjacency graph is a key factor for
modeling the correlations of the input skeletons. Thus, previous methods mainly
focus on the design/learning of the graph topology. But once the topology is
learned, only a single-scale feature and one transformation exist in each layer
of the networks. Many insights, such as multi-scale information and multiple
sets of transformations, that have been proven to be very effective in
convolutional neural networks (CNNs), have not been investigated in GCNs. The
reason is that, due to the gap between graph-structured skeleton data and
conventional image/video data, it is very challenging to embed these insights
into GCNs. To overcome this gap, we reinvent the split-transform-merge strategy
in GCNs for skeleton sequence processing. Specifically, we design a simple and
highly modularized graph convolutional network architecture for skeleton-based
action recognition. Our network is constructed by repeating a building block
that aggregates multi-granularity information from both the spatial and
temporal paths. Extensive experiments demonstrate that our network outperforms
state-of-the-art methods by a significant margin with only 1/5 of the
parameters and 1/10 of the FLOPs. Code is available at
this https URL.

    

### [[2011.15045] Unsupervised Deep Video Denoising](http://arxiv.org/abs/2011.15045)


  Deep convolutional neural networks (CNNs) for video denoising are typically
trained with supervision, assuming the availability of clean videos. However,
in many applications, such as microscopy, noiseless videos are not available.
To address this, we propose an Unsupervised Deep Video Denoiser (UDVD), a CNN
architecture designed to be trained exclusively with noisy data. The
performance of UDVD is comparable to the supervised state-of-the-art, even when
trained only on a single short noisy video. We demonstrate the promise of our
approach in real-world imaging applications by denoising raw video,
fluorescence-microscopy and electron-microscopy data. In contrast to many
current approaches to video denoising, UDVD does not require explicit motion
compensation. This is advantageous because motion compensation is
computationally expensive, and can be unreliable when the input data are noisy.
A gradient-based analysis reveals that UDVD automatically adapts to local
motion in the input noisy videos. Thus, the network learns to perform implicit
motion compensation, even though it is only trained for denoising.

    

### [[2012.02671] Learning in two-player games between transparent opponents](http://arxiv.org/abs/2012.02671)


  We consider a scenario in which two reinforcement learning agents repeatedly
play a matrix game against each other and update their parameters after each
round. The agents' decision-making is transparent to each other, which allows
each agent to predict how their opponent will play against them. To prevent an
infinite regress of both agents recursively predicting each other indefinitely,
each agent is required to give an opponent-independent response with some
probability at least epsilon. Transparency also allows each agent to anticipate
and shape the other agent's gradient step, i.e. to move to regions of parameter
space in which the opponent's gradient points in a direction favourable to
them. We study the resulting dynamics experimentally, using two algorithms from
previous literature (LOLA and SOS) for opponent-aware learning. We find that
the combination of mutually transparent decision-making and opponent-aware
learning robustly leads to mutual cooperation in a single-shot prisoner's
dilemma. In a game of chicken, in which both agents try to manoeuvre their
opponent towards their preferred equilibrium, converging to a mutually
beneficial outcome turns out to be much harder, and opponent-aware learning can
even lead to worst-case outcomes for both agents. This highlights the need to
develop opponent-aware learning algorithms that achieve acceptable outcomes in
social dilemmas involving an equilibrium selection problem.

    

### [[2012.06387] TARA: Training and Representation Alteration for AI Fairness and Domain Generalization](http://arxiv.org/abs/2012.06387)


  We propose a novel method for enforcing AI fairness with respect to protected
or sensitive factors. This method uses a dual strategy performing training and
representation alteration (TARA) for the mitigation of prominent causes of AI
bias by including: a) the use of representation learning alteration via
adversarial independence to suppress the bias-inducing dependence of the data
representation from protected factors; and b) training set alteration via
intelligent augmentation to address bias-causing data imbalance, by using
generative models that allow the fine control of sensitive factors related to
underrepresented populations via domain adaptation and latent space
manipulation. When testing our methods on image analytics, experiments
demonstrate that TARA significantly or fully debiases baseline models while
outperforming competing debiasing methods that have the same amount of
information, e.g., with (% overall accuracy, % accuracy gap) = (78.8, 0.5) vs.
the baseline method's score of (71.8, 10.5) for EyePACS, and (73.7, 11.8) vs.
(69.1, 21.7) for CelebA. Furthermore, recognizing certain limitations in
current metrics used for assessing debiasing performance, we propose novel
conjunctive debiasing metrics. Our experiments also demonstrate the ability of
these novel metrics in assessing the Pareto efficiency of the proposed methods.

    

### [[2012.09432] On the experimental feasibility of quantum state reconstruction via machine learning](http://arxiv.org/abs/2012.09432)


  We determine the resource scaling of machine learning-based quantum state
reconstruction methods, in terms of inference and training, for systems of up
to four qubits when constrained to pure states. Further, we examine system
performance in the low-count regime, likely to be encountered in the tomography
of high-dimensional systems. Finally, we implement our quantum state
reconstruction method on an IBM Q quantum computer, and compare against both
unconstrained and constrained MLE state reconstruction.

    

### [[2012.10053] Instance Space Analysis for the Car Sequencing Problem](http://arxiv.org/abs/2012.10053)


  We investigate an important research question for solving the car sequencing
problem, that is, which characteristics make an instance hard to solve? To do
so, we carry out an instance space analysis for the car sequencing problem, by
extracting a vector of problem features to characterize an instance. In order
to visualize the instance space, the feature vectors are projected onto a
two-dimensional space using dimensionality reduction techniques. The resulting
two-dimensional visualizations provide new insights into the characteristics of
the instances used for testing and how these characteristics influence the
behaviours of an optimization algorithm. This analysis guides us in
constructing a new set of benchmark instances with a range of instance
properties. We demonstrate that these new instances are more diverse than the
previous benchmarks, including some instances that are significantly more
difficult to solve. We introduce two new algorithms for solving the car
sequencing problem and compare them with four existing methods from the
literature. Our new algorithms are shown to perform competitively for this
problem but no single algorithm can outperform all others over all instances.
This observation motivates us to build an algorithm selection model based on
machine learning, to identify the niche in the instance space that an algorithm
is expected to perform well on. Our analysis helps to understand problem
hardness and select an appropriate algorithm for solving a given car sequencing
problem instance.

    

### [[2012.11717] Social NCE: Contrastive Learning of Socially-aware Motion Representations](http://arxiv.org/abs/2012.11717)


  Learning socially-aware motion representations is at the core of recent
advances in multi-agent problems, such as human motion forecasting and robot
navigation in crowds. Despite promising progress, existing representations
learned with neural networks still struggle to generalize in closed-loop
predictions (e.g., output colliding trajectories). This issue largely arises
from the non-i.i.d. nature of sequential prediction in conjunction with
ill-distributed training data. Intuitively, if the training data only comes
from human behaviors in safe spaces, i.e., from "positive" examples, it is
difficult for learning algorithms to capture the notion of "negative" examples
like collisions. In this work, we aim to address this issue by explicitly
modeling negative examples through self-supervision: (i) we introduce a social
contrastive loss that regularizes the extracted motion representation by
discerning the ground-truth positive events from synthetic negative ones; (ii)
we construct informative negative samples based on our prior knowledge of rare
but dangerous circumstances. Our method substantially reduces the collision
rates of recent trajectory forecasting, behavioral cloning and reinforcement
learning algorithms, outperforming state-of-the-art methods on several
benchmarks. Our code is available at this https URL.

    

### [[2012.15115] Joint Verification and Reranking for Open Fact Checking Over Tables](http://arxiv.org/abs/2012.15115)


  Structured information is an important knowledge source for automatic
verification of factual claims. Nevertheless, the majority of existing research
into this task has focused on textual data, and the few recent inquiries into
structured data have been for the closed-domain setting where appropriate
evidence for each claim is assumed to have already been retrieved. In this
paper, we investigate verification over structured data in the open-domain
setting, introducing a joint reranking-and-verification model which fuses
evidence documents in the verification component. Our open-domain model
achieves performance comparable to the closed-domain state-of-the-art on the
TabFact dataset, and demonstrates performance gains from the inclusion of
multiple tables as well as a significant improvement over a heuristic retrieval
baseline.

    

### [[2101.11653] List-Decodable Coded Computing: Breaking the Adversarial Toleration Barrier](http://arxiv.org/abs/2101.11653)


  We consider the problem of coded computing, where a computational task is
performed in a distributed fashion in the presence of adversarial workers. We
propose techniques to break the adversarial toleration threshold barrier
previously known in coded computing. More specifically, we leverage
list-decoding techniques for folded Reed-Solomon codes and propose novel
algorithms to recover the correct codeword using side information. In the coded
computing setting, we show how the master node can perform certain carefully
designed extra computations to obtain the side information. The workload of
computing this side information is negligible compared to the computations done
by each worker. This side information is then utilized to prune the output of
the list decoder and uniquely recover the true outcome. We further propose
folded Lagrange coded computing (FLCC) to incorporate the developed techniques
into a specific coded computing setting. Our results show that FLCC outperforms
LCC by breaking the barrier on the number of adversaries that can be tolerated.
In particular, the corresponding threshold in FLCC is improved by a factor of
two asymptotically compared to that of LCC.

    

### [[2102.02988] AutoPilot: Automating SoC Design Space Exploration for SWaP Constrained Autonomous UAVs](http://arxiv.org/abs/2102.02988)


  Building domain-specific accelerators for autonomous unmanned aerial vehicles
(UAVs) is challenging due to a lack of systematic methodology for designing
onboard compute. Balancing a computing system for a UAV requires considering
both the cyber (e.g., sensor rate, compute performance) and physical (e.g.,
payload weight) characteristics that affect overall performance. Iterating over
the many component choices results in a combinatorial explosion of the number
of possible combinations: from 10s of thousands to billions, depending on
implementation details. Manually selecting combinations of these components is
tedious and expensive. To navigate the {cyber-physical design space}
efficiently, we introduce \emph{AutoPilot}, a framework that automates
full-system UAV co-design. AutoPilot uses Bayesian optimization to navigate a
large design space and automatically select a combination of autonomy algorithm
and hardware accelerator while considering the cross-product effect of other
cyber and physical UAV components. We show that the AutoPilot methodology
consistently outperforms general-purpose hardware selections like Xavier NX and
Jetson TX2, as well as dedicated hardware accelerators built for autonomous
UAVs, across a range of representative scenarios (three different UAV types and
three deployment environments). Designs generated by AutoPilot increase the
number of missions on average by up to 2.25x, 1.62x, and 1.43x for nano, micro,
and mini-UAVs respectively over baselines. Our work demonstrates the need for
holistic full-UAV co-design to achieve maximum overall UAV performance and the
need for automated flows to simplify the design process for autonomous
cyber-physical systems.

    

### [[2102.10196] Quantifying Variational Approximation for the Log-Partition Function](http://arxiv.org/abs/2102.10196)


  Variational approximation, such as mean-field (MF) and tree-reweighted (TRW),
provide a computationally efficient approximation of the log-partition function
for a generic graphical model. TRW provably provides an upper bound, but the
approximation ratio is generally not quantified.
As the primary contribution of this work, we provide an approach to quantify
the approximation ratio through the property of the underlying graph structure.
Specifically, we argue that (a variant of) TRW produces an estimate that is
within factor $\frac{1}{\sqrt{\kappa(G)}}$ of the true log-partition function
for any discrete pairwise graphical model over graph $G$, where $\kappa(G) \in
(0,1]$ captures how far $G$ is from tree structure with $\kappa(G) = 1$ for
trees and $2/N$ for the complete graph over $N$ vertices. As a consequence, the
approximation ratio is $1$ for trees, $\sqrt{(d+1)/2}$ for any graph with
maximum average degree $d$, and $\stackrel{\beta\to\infty}{\approx}
1+1/(2\beta)$ for graphs with girth (shortest cycle) at least $\beta \log N$.
In general, $\kappa(G)$ is the solution of a max-min problem associated with
$G$ that can be evaluated in polynomial time for any graph.
Using samples from the uniform distribution over the spanning trees of G, we
provide a near linear-time variant that achieves an approximation ratio equal
to the inverse of square-root of minimal (across edges) effective resistance of
the graph. We connect our results to the graph partition-based approximation
method and thus provide a unified perspective.
Keywords: variational inference, log-partition function, spanning tree
polytope, minimum effective resistance, min-max spanning tree, local inference

    

### [[2103.03078] Defending Medical Image Diagnostics against Privacy Attacks using Generative Methods](http://arxiv.org/abs/2103.03078)


  Machine learning (ML) models used in medical imaging diagnostics can be
vulnerable to a variety of privacy attacks, including membership inference
attacks, that lead to violations of regulations governing the use of medical
data and threaten to compromise their effective deployment in the clinic. In
contrast to most recent work in privacy-aware ML that has been focused on model
alteration and post-processing steps, we propose here a novel and complementary
scheme that enhances the security of medical data by controlling the data
sharing process. We develop and evaluate a privacy defense protocol based on
using a generative adversarial network (GAN) that allows a medical data sourcer
(e.g. a hospital) to provide an external agent (a modeler) a proxy dataset
synthesized from the original images, so that the resulting diagnostic systems
made available to model consumers is rendered resilient to privacy attackers.
We validate the proposed method on retinal diagnostics AI used for diabetic
retinopathy that bears the risk of possibly leaking private information. To
incorporate concerns of both privacy advocates and modelers, we introduce a
metric to evaluate privacy and utility performance in combination, and
demonstrate, using these novel and classical metrics, that our approach, by
itself or in conjunction with other defenses, provides state of the art (SOTA)
performance for defending against privacy attacks.

    

### [[2103.12095] Am I fit for this physical activity? Neural embedding of physical conditioning from inertial sensors](http://arxiv.org/abs/2103.12095)


  Inertial Measurement Unit (IMU) sensors are present in everyday devices such
as smartphones and fitness watches. As a result, the array of health-related
research and applications that tap onto this data has been growing, but little
attention has been devoted to the prediction of an individual's heart rate (HR)
from IMU data, when undergoing a physical activity. Would that be even
possible? If so, this could be used to design personalized sets of aerobic
exercises, for instance. In this work, we show that it is viable to obtain
accurate HR predictions from IMU data using Recurrent Neural Networks, provided
only access to HR and IMU data from a short-lived, previously executed
activity. We propose a novel method for initializing an RNN's hidden state
vectors, using a specialized network that attempts to extract an embedding of
the physical conditioning (PCE) of a subject. We show that using a
discriminator in the training phase to help the model learn whether two PCEs
belong to the same individual further reduces the prediction error. We evaluate
the proposed model when predicting the HR of 23 subjects performing a variety
of physical activities from IMU data available in public datasets (PAMAP2,
PPG-DaLiA). For comparison, we use as baselines the only model specifically
proposed for this task and an adapted state-of-the-art model for Human Activity
Recognition (HAR), a closely related task. Our method, PCE-LSTM, yields over
10% lower mean absolute error. We demonstrate empirically that this error
reduction is in part due to the use of the PCE. Last, we use the two datasets
(PPG-DaLiA, WESAD) to show that PCE-LSTM can also be successfully applied when
photoplethysmography (PPG) sensors are available, outperforming the
state-of-the-art deep learning baselines by more than 30%.

    

### [[2103.14023] AgentFormer: Agent-Aware Transformers for Socio-Temporal Multi-Agent Forecasting](http://arxiv.org/abs/2103.14023)


  Predicting accurate future trajectories of multiple agents is essential for
autonomous systems, but is challenging due to the complex agent interaction and
the uncertainty in each agent's future behavior. Forecasting multi-agent
trajectories requires modeling two key dimensions: (1) time dimension, where we
model the influence of past agent states over future states; (2) social
dimension, where we model how the state of each agent affects others. Most
prior methods model these two dimensions separately, e.g., first using a
temporal model to summarize features over time for each agent independently and
then modeling the interaction of the summarized features with a social model.
This approach is suboptimal since independent feature encoding over either the
time or social dimension can result in a loss of information. Instead, we would
prefer a method that allows an agent's state at one time to directly affect
another agent's state at a future time. To this end, we propose a new
Transformer, AgentFormer, that jointly models the time and social dimensions.
The model leverages a sequence representation of multi-agent trajectories by
flattening trajectory features across time and agents. Since standard attention
operations disregard the agent identity of each element in the sequence,
AgentFormer uses a novel agent-aware attention mechanism that preserves agent
identities by attending to elements of the same agent differently than elements
of other agents. Based on AgentFormer, we propose a stochastic multi-agent
trajectory prediction model that can attend to features of any agent at any
previous timestep when inferring an agent's future position. The latent intent
of all agents is also jointly modeled, allowing the stochasticity in one
agent's behavior to affect other agents. Our method significantly improves the
state of the art on well-established pedestrian and autonomous driving
datasets.

    

### [[2104.00742] Confidence Calibration for Domain Generalization under Covariate Shift](http://arxiv.org/abs/2104.00742)


  Existing calibration algorithms address the problem of covariate shift via
unsupervised domain adaptation. However, these methods suffer from the
following limitations: 1) they require unlabeled data from the target domain,
which may not be available at the stage of calibration in real-world
applications and 2) their performance depends heavily on the disparity between
the distributions of the source and target domains. To address these two
limitations, we present novel calibration solutions via domain generalization.
Our core idea is to leverage multiple calibration domains to reduce the
effective distribution disparity between the target and calibration domains for
improved calibration transfer without needing any data from the target domain.
We provide theoretical justification and empirical experimental results to
demonstrate the effectiveness of our proposed algorithms. Compared against
state-of-the-art calibration methods designed for domain adaptation, we observe
a decrease of 8.86 percentage points in expected calibration error or,
equivalently, an increase of 35 percentage points in improvement ratio for
multi-class classification on the Office-Home dataset.

    

### [[2105.06421] Using Self-Supervised Auxiliary Tasks to Improve Fine-Grained Facial Representation](http://arxiv.org/abs/2105.06421)


  Over the past few years, best SSL methods, gradually moved from the pre-text
task learning to the Contrastive learning. But contrastive methods have some
drawbacks which could not be solved completely, such as performing poor on
fine-grained visual tasks compare to supervised learning methods. In this
study, at first, the impact of ImageNet pre-training on fine-grained Facial
Expression Recognition (FER) was tested. It could be seen from the results that
training from scratch is better than ImageNet fine-tuning at stronger
augmentation levels. After that, a framework was proposed for standard
Supervised Learning (SL), called Hybrid Multi-Task Learning (HMTL) which merged
Self-Supervised as auxiliary task to the SL training setting. Leveraging
Self-Supervised Learning (SSL) can gain additional information from input data
than labels which can help the main fine-grained SL task. It is been
investigated how this method could be used for FER by designing two customized
version of common pre-text techniques, Jigsaw puzzling and in-painting. The
state-of-the-art was reached on AffectNet via two types of HMTL, without
utilizing pre-training on additional datasets. Moreover, we showed the
difference between SS pre-training and HMTL to demonstrate superiority of
proposed method. Furthermore, the impact of proposed method was shown on two
other fine-grained facial tasks, Head Poses estimation and Gender Recognition,
which concluded to reduce in error rate by 11% and 1% respectively.

    

### [[2105.10368] Development and evaluation of an Explainable Prediction Model for Chronic Kidney Disease Patients based on Ensemble Trees](http://arxiv.org/abs/2105.10368)


  Currently, Chronic Kidney Disease (CKD) is experiencing a globally increasing
incidence and high cost to health systems. A delayed recognition implies
premature mortality due to progressive loss of kidney function. The employment
of data mining to discover subtle patterns in CKD indicators would contribute
achieving early diagnosis. This work presents the development and evaluation of
an explainable prediction model that would support clinicians in the early
diagnosis of CKD patients. The model development is based on a data management
pipeline that detects the best combination of ensemble trees algorithms and
features selected concerning classification performance. The results obtained
through the pipeline equals the performance of the best CKD prediction models
identified in the literature. Furthermore, the main contribution of the paper
involves an explainability-driven approach that allows selecting the best
prediction model maintaining a balance between accuracy and explainability.
Therefore, the most balanced explainable prediction model of CKD implements an
XGBoost classifier over a group of 4 features (packed cell value, specific
gravity, albumin, and hypertension), achieving an accuracy of 98.9% and 97.5%
with cross-validation technique and with new unseen data respectively. In
addition, by analysing the model's explainability by means of different
post-hoc techniques, the packed cell value and the specific gravity are
determined as the most relevant features that influence the prediction results
of the model. This small number of feature selected results in a reduced cost
of the early diagnosis of CKD implying a promising solution for developing
countries.

    

### [[2106.08801] PRASEMap: A Probabilistic Reasoning and Semantic Embedding based Knowledge Graph Alignment System](http://arxiv.org/abs/2106.08801)


  Knowledge Graph (KG) alignment aims at finding equivalent entities and
relations (i.e., mappings) between two KGs. The existing approaches utilize
either reasoning-based or semantic embedding-based techniques, but few studies
explore their combination. In this demonstration, we present PRASEMap, an
unsupervised KG alignment system that iteratively computes the Mappings with
both Probabilistic Reasoning (PR) And Semantic Embedding (SE) techniques.
PRASEMap can support various embedding-based KG alignment approaches as the SE
module, and enables easy human computer interaction that additionally provides
an option for users to feed the mapping annotations back to the system for
better results. The demonstration showcases these features via a stand-alone
Web application with user friendly interfaces. The demo is available at
this https URL.

    

### [[2106.13199] A Deep Learning Approach to Private Data Sharing of Medical Images Using Conditional GANs](http://arxiv.org/abs/2106.13199)


  Sharing data from clinical studies can facilitate innovative data-driven
research and ultimately lead to better public health. However, sharing
biomedical data can put sensitive personal information at risk. This is usually
solved by anonymization, which is a slow and expensive process. An alternative
to anonymization is sharing a synthetic dataset that bears a behaviour similar
to the real data but preserves privacy. As part of the collaboration between
Novartis and the Oxford Big Data Institute, we generate a synthetic dataset
based on COSENTYX (secukinumab) Ankylosing Spondylitis clinical study. We apply
an Auxiliary Classifier GAN to generate synthetic MRIs of vertebral units. The
images are conditioned on the VU location (cervical, thoracic and lumbar). In
this paper, we present a method for generating a synthetic dataset and conduct
an in-depth analysis on its properties along three key metrics: image fidelity,
sample diversity and dataset privacy.

    

### [[2108.09011] MARS: Nano-Power Battery-free Wireless Interfaces for Touch, Swipe and Speech Input](http://arxiv.org/abs/2108.09011)


  Augmenting everyday surfaces with interaction sensing capability that is
maintenance-free, low-cost (about $1), and in an appropriate form factor is a
challenge with current technologies. MARS (Multi-channel Ambiently-powered
Realtime Sensing) enables battery-free sensing and wireless communication of
touch, swipe, and speech interactions by combining a nanowatt programmable
oscillator with frequency-shifted analog backscatter communication. A
zero-threshold voltage field-effect transistor (FET) is used to create an
oscillator with a low startup voltage (about 500 mV) and current (< 2uA), whose
frequency can be affected through changes in inductance or capacitance from the
user interactions. Multiple MARS systems can operate in the same environment by
tuning each oscillator circuit to a different frequency range. The nanowatt
power budget allows the system to be powered directly through ambient energy
sources like photodiodes or thermoelectric generators. We differentiate MARS
from previous systems based on power requirements, cost, and part count and
explore different interaction and activity sensing scenarios suitable for
indoor environments.

    

### [[2108.09073] From Research to Proof-of-Concept: Analysis of a Deployment of FPGAs on a Commercial Search Engine](http://arxiv.org/abs/2108.09073)


  FPGAs are quickly becoming available in the cloud as a one more heterogeneous
processing element complementing CPUs and GPUs. There are many reports in the
literature showing the potential for FPGAs to accelerate a wide variety of
algorithms, which combined with their growing availability, would seem to also
indicate a widespread use in many applications. Unfortunately, there is not
much published research exploring what it takes to integrate an FPGA into an
existing application in a cost-effective way and keeping the algorithmic
performance advantages. Building on recent results exploring how to employ
FPGAs to improve the search engines used in the travel industry, this paper
analyses the end-to-end performance of the search engine when using FPGAs, as
well as the necessary changes to the software and the cost of such deployments.
The results provide important insights on current FPGA deployments and what
needs to be done to make FPGAs more widely used. For instance, the large
potential performance gains provided by an FPGA are greatly diminished in
practice if the application cannot submit request in the most optimal way,
something that is not always possible and might require significant changes to
the application. Similarly, some existing cloud deployments turn out to use a
very imbalanced architecture: a powerful FPGA connected to a not so powerful
CPU. The result is that the CPU cannot generate enough load for the FPGA, which
potentially eliminates all performance gains and might even result in a more
expensive system. In this paper, we report on an extensive study and
development effort to incorporate FPGAs into a search engine and analyse the
issues encountered and their practical impact. We expect that these results
will inform the development and deployment of FPGAs in the future by providing
important insights on the end-to-end integration of FPGAs within existing
systems.

    

### [[2108.09249] Mining Secure Behavior of Hardware Designs](http://arxiv.org/abs/2108.09249)


  Specification mining offers a solution by automating security specification
for hardware. Specification miners use a form of machine learning to specify
behaviors of a system by studying a system in execution. However, specification
mining was first developed for use with software. Complex hardware designs
offer unique challenges for this technique. Further, specification miners
traditionally capture functional specifications without a notion of security,
and may not use the specification logics necessary to describe some security
requirements.
This work demonstrates specification mining for hardware security. On CISC
architectures such as x86, I demonstrate that a miner partitioning the design
state space along control signals discovers a specification that includes
manually defined properties and, if followed, would secure CPU designs against
Memory Sinkhole and SYSRET privilege escalation. For temporal properties, I
demonstrate that a miner using security specific linear temporal logic (LTL)
templates for specification detection may find properties that, if followed,
would secure designs against historical documented security vulnerabilities and
against potential future attacks targeting system initialization. For
information--flow hyperproperties, I demonstrate that a miner may use
Information Flow Tracking (IFT) to develop output properties containing
designer specified information--flow security properties as well as properties
that demonstrate a design does not contain certain Common Weakness Enumerations
(CWEs).

    

### [[2108.08845] PyParSVD: A streaming, distributed and randomized singular-value-decomposition library](http://arxiv.org/abs/2108.08845)


  We introduce PyParSVD\footnote{this https URL}, a
Python library that implements a streaming, distributed and randomized
algorithm for the singular value decomposition. To demonstrate its
effectiveness, we extract coherent structures from scientific data. Futhermore,
we show weak scaling assessments on up to 256 nodes of the Theta machine at
Argonne Leadership Computing Facility, demonstrating potential for large-scale
data analyses of practical data sets.

    

### [[2108.08953] Distributed Transformations of Hamiltonian Shapes based on Line Moves](http://arxiv.org/abs/2108.08953)


  We consider a discrete system of $n$ simple indistinguishable devices, called
\emph{agents}, forming a \emph{connected} shape $S_I$ on a two-dimensional
square grid. Agents are equipped with a linear-strength mechanism, called a
\emph{line move}, by which an agent can push a whole line of consecutive agents
in one of the four directions in a single time-step. We study the problem of
transforming an initial shape $S_I$ into a given target shape $S_F$ via a
finite sequence of line moves in a distributed model, where each agent can
observe the states of nearby agents in a Moore neighbourhood. Our main
contribution is the first distributed connectivity-preserving transformation
that exploits line moves within a total of $O(n \log_2 n)$ moves, which is
asymptotically equivalent to that of the best-known centralised
transformations. The algorithm solves the \emph{line formation problem} that
allows agents to form a final straight line $S_L$, starting from any shape $
S_I $, whose \emph{associated graph} contains a Hamiltonian path.

    

### [[2108.09101] Abduction of trap invariants in parameterized systems](http://arxiv.org/abs/2108.09101)


  In a previous paper we have presented a CEGAR approach for the verification
of parameterized systems with an arbitrary number of processes organized in an
array or a ring. The technique is based on the iterative computation of
parameterized invariants, i.e., infinite families of invariants for the
infinitely many instances of the system. Safety properties are proved by
checking that every global configuration of the system satisfying all
parameterized invariants also satisfies the property; we have shown that this
check can be reduced to the satisfiability problem for Monadic Second Order on
words, which is decidable.
A strong limitation of the approach is that processes can only have a fixed
number of variables with a fixed finite range. In particular, they cannot use
variables with range [0,N-1], where N is the number of processes, which appear
in many standard distributed algorithms. In this paper, we extend our technique
to this case. While conducting the check whether a safety property is inductive
assuming a computed set of invariants becomes undecidable, we show how to
reduce it to checking satisfiability of a first-order formula. We report on
experiments showing that automatic first-order theorem provers can still
perform this check for a collection of non-trivial examples. Additionally, we
can give small sets of readable invariants for these checks.

    

### [[2108.09250] Centralised Connectivity-Preserving Transformations for Programmable Matter: A Minimal Seed Approach](http://arxiv.org/abs/2108.09250)


  We study a model of programmable matter systems consisting of $n$ devices
lying on a 2-dimensional square grid which are able to perform the minimal
mechanical operation of rotating around each other. The goal is to transform an
initial shape A into a target shape B. We investigate the class of shapes which
can be constructed in such a scenario under the additional constraint of
maintaining global connectivity at all times. We focus on the scenario of
transforming nice shapes, a class of shapes consisting of a central line $L$
where for all nodes $u$ in $S$ either $u \in L$ or $u$ is connected to $L$ by a
line of nodes perpendicular to $L$. We prove that by introducing a minimal
3-node seed it is possible for the canonical shape of a line of $n$ nodes to be
transformed into a nice shape of $n-1$ nodes. We use this to show that a 4-node
seed enables the transformation of nice shapes of size $n$ into any other nice
shape of size $n$ in $O(n^2)$ time. We leave as an open problem the expansion
of the class of shapes which can be constructed using such a seed to include
those derived from nice shapes.

    

### [[2108.09282] The n-ary Initial Literal and Literal Shuffle](http://arxiv.org/abs/2108.09282)


  The literal and the initial literal shuffle have been introduced to model the
behavior of two synchronized processes. However, it is not possible to describe
the synchronization of multiple processes. Furthermore, both restricted forms
of shuffling are not associative. Here, we extend the literal shuffle and the
initial literal shuffle to multiple arguments. We also introduce iterated
versions, much different from the iterated ones previously introduced for the
binary literal and initial literal shuffle. We investigate formal properties,
and show that in terms of expressive power, in a full trio, they coincide with
the general shuffle. Furthermore, we look at closure properties with respect to
the regular, context-free, context-sensitive, recursive and recursively
enumerable languages for all operations introduced. Then, we investigate
various decision problems motivated by analogous problems for the (ordinary)
shuffle operation. Most problems we look at are tractable, but we also identify
one intractable decision problem.

    

### [[2102.02867] The Discrepancy Attack on Polyshard-ed Blockchains](http://arxiv.org/abs/2102.02867)


  Sharding, i.e. splitting the miners or validators to form and run several
subchains in parallel, is known as one of the main solutions to the scalability
problem of blockchains. The drawback is that as the number of miners expanding
each subchain becomes small, it becomes vulnerable to security attacks. To
solve this problem, a framework, named as \textit{Polyshard}, has been proposed
in which each validator verifies a coded combination of the blocks introduced
by different subchains, thus helping to protect the security of all subchains.
In this paper, we introduce an attack on Polyshard, called \textit{the
discrepancy} attack, which is the result of malicious nodes controlling a few
subchains and dispersing different blocks to different nodes. We show that this
attack undermines the security of Polyshard and is undetectable in its current
setting.

    

### [[2103.01503] Coded Computing via Binary Linear Codes: Designs and Performance Limits](http://arxiv.org/abs/2103.01503)


  We consider the problem of coded distributed computing where a large linear
computational job, such as a matrix multiplication, is divided into $k$ smaller
tasks, encoded using an $(n,k)$ linear code, and performed over $n$ distributed
nodes. The goal is to reduce the average execution time of the computational
job. We provide a connection between the problem of characterizing the average
execution time of a coded distributed computing system and the problem of
analyzing the error probability of codes of length $n$ used over erasure
channels. Accordingly, we present closed-form expressions for the execution
time using binary random linear codes and the best execution time any
linear-coded distributed computing system can achieve. It is also shown that
there exist \textit{good} binary linear codes that not only attain
(asymptotically) the best performance that any linear code (not necessarily
binary) can achieve but also are numerically stable against the inevitable
rounding errors in practice. We then develop a low-complexity algorithm for
decoding Reed-Muller (RM) codes over erasure channels. Our decoder only
involves additions, subtractions, {and inversion of relatively small matrices
of dimensions at most $\log n+1$}, and enables coded computation over
real-valued data. Extensive numerical analysis of the fundamental results as
well as RM- and polar-coded computing schemes demonstrate the excellence of the
RM-coded computation in achieving close-to-optimal performance while having a
low-complexity decoding and explicit construction. The proposed framework in
this paper enables efficient designs of distributed computing systems given the
rich literature in the channel coding theory.

    

### [[2108.08996] Weakly-supervised Joint Anomaly Detection and Classification](http://arxiv.org/abs/2108.08996)


  Anomaly activities such as robbery, explosion, accidents, etc. need immediate
actions for preventing loss of human life and property in real world
surveillance systems. Although the recent automation in surveillance systems
are capable of detecting the anomalies, but they still need human efforts for
categorizing the anomalies and taking necessary preventive actions. This is due
to the lack of methodology performing both anomaly detection and classification
for real world scenarios. Thinking of a fully automatized surveillance system,
which is capable of both detecting and classifying the anomalies that need
immediate actions, a joint anomaly detection and classification method is a
pressing need. The task of joint detection and classification of anomalies
becomes challenging due to the unavailability of dense annotated videos
pertaining to anomalous classes, which is a crucial factor for training modern
deep architecture. Furthermore, doing it through manual human effort seems
impossible. Thus, we propose a method that jointly handles the anomaly
detection and classification in a single framework by adopting a
weakly-supervised learning paradigm. In weakly-supervised learning instead of
dense temporal annotations, only video-level labels are sufficient for
learning. The proposed model is validated on a large-scale publicly available
UCF-Crime dataset, achieving state-of-the-art results.

    

### [[2108.09003] Explainable Reinforcement Learning for Broad-XAI: A Conceptual Framework and Survey](http://arxiv.org/abs/2108.09003)


  Broad Explainable Artificial Intelligence moves away from interpreting
individual decisions based on a single datum and aims to provide integrated
explanations from multiple machine learning algorithms into a coherent
explanation of an agent's behaviour that is aligned to the communication needs
of the explainee. Reinforcement Learning (RL) methods, we propose, provide a
potential backbone for the cognitive model required for the development of
Broad-XAI. RL represents a suite of approaches that have had increasing success
in solving a range of sequential decision-making problems. However, these
algorithms all operate as black-box problem solvers, where they obfuscate their
decision-making policy through a complex array of values and functions.
EXplainable RL (XRL) is relatively recent field of research that aims to
develop techniques to extract concepts from the agent's: perception of the
environment; intrinsic/extrinsic motivations/beliefs; Q-values, goals and
objectives. This paper aims to introduce a conceptual framework, called the
Causal XRL Framework (CXF), that unifies the current XRL research and uses RL
as a backbone to the development of Broad-XAI. Additionally, we recognise that
RL methods have the ability to incorporate a range of technologies to allow
agents to adapt to their environment. CXF is designed for the incorporation of
many standard RL extensions and integrated with external ontologies and
communication facilities so that the agent can answer questions that explain
outcomes and justify its decisions.

    

### [[2108.09023] Single Underwater Image Enhancement Using an Analysis-Synthesis Network](http://arxiv.org/abs/2108.09023)


  Most deep models for underwater image enhancement resort to training on
synthetic datasets based on underwater image formation models. Although
promising performances have been achieved, they are still limited by two
problems: (1) existing underwater image synthesis models have an intrinsic
limitation, in which the homogeneous ambient light is usually randomly
generated and many important dependencies are ignored, and thus the synthesized
training data cannot adequately express characteristics of real underwater
environments; (2) most of deep models disregard lots of favorable underwater
priors and heavily rely on training data, which extensively limits their
application ranges. To address these limitations, a new underwater synthetic
dataset is first established, in which a revised ambient light synthesis
equation is embedded. The revised equation explicitly defines the complex
mathematical relationship among intensity values of the ambient light in RGB
channels and many dependencies such as surface-object depth, water types, etc,
which helps to better simulate real underwater scene appearances. Secondly, a
unified framework is proposed, named ANA-SYN, which can effectively enhance
underwater images under collaborations of priors (underwater domain knowledge)
and data information (underwater distortion distribution). The proposed
framework includes an analysis network and a synthesis network, one for priors
exploration and another for priors integration. To exploit more accurate
priors, the significance of each prior for the input image is explored in the
analysis network and an adaptive weighting module is designed to dynamically
recalibrate them. Meanwhile, a novel prior guidance module is introduced in the
synthesis network, which effectively aggregates the prior and data features and
thus provides better hybrid information to perform the more reasonable image
enhancement.

    

### [[2108.09241] Open Relation Modeling: Learning to Define Relations between Entities](http://arxiv.org/abs/2108.09241)


  Relations between entities can be represented by different instances, e.g., a
sentence containing both entities or a fact in a Knowledge Graph (KG). However,
these instances may not well capture the general relations between entities,
may be difficult to understand by humans, even may not be found due to the
incompleteness of the knowledge source.
In this paper, we introduce the Open Relation Modeling task - given two
entities, generate a coherent sentence describing the relation between them. To
solve this task, we propose to teach machines to generate definition-like
relation descriptions by letting them learn from definitions of entities.
Specifically, we fine-tune Pre-trained Language Models (PLMs) to produce
definitions conditioned on extracted entity pairs. To help PLMs reason between
entities and provide additional relational knowledge to PLMs for open relation
modeling, we incorporate reasoning paths in KGs and include a reasoning path
selection mechanism. We show that PLMs can select interpretable and informative
reasoning paths by confidence estimation, and the selected path can guide PLMs
to generate better relation descriptions. Experimental results show that our
model can generate concise but informative relation descriptions that capture
the representative characteristics of entities and relations.

    

### [[2108.09293] An Empirical Cybersecurity Evaluation of GitHub Copilot's Code Contributions](http://arxiv.org/abs/2108.09293)


  There is burgeoning interest in designing AI-based systems to assist humans
in designing computing systems, including tools that automatically generate
computer code. The most notable of these comes in the form of the first
self-described `AI pair programmer', GitHub Copilot, a language model trained
over open-source GitHub code. However, code often contains bugs - and so, given
the vast quantity of unvetted code that Copilot has processed, it is certain
that the language model will have learned from exploitable, buggy code. This
raises concerns on the security of Copilot's code contributions. In this work,
we systematically investigate the prevalence and conditions that can cause
GitHub Copilot to recommend insecure code. To perform this analysis we prompt
Copilot to generate code in scenarios relevant to high-risk CWEs (e.g. those
from MITRE's "Top 25" list). We explore Copilot's performance on three distinct
code generation axes -- examining how it performs given diversity of
weaknesses, diversity of prompts, and diversity of domains. In total, we
produce 89 different scenarios for Copilot to complete, producing 1,692
programs. Of these, we found approximately 40% to be vulnerable.

    

### [[2011.02912] Causal Expectation-Maximisation](http://arxiv.org/abs/2011.02912)


  Structural causal models are the fundamental modelling unit in Pearl's causal
theory; in principle they allow us to solve any causal inference query, such as
causal effects or counterfactuals. But they most often contain latent variables
that limit their application to special settings. In this paper we introduce
the causal EM algorithm that aims at reconstructing the uncertainty about the
latent variables; based on this, causal inference can approximately be solved
via standard algorithms for Bayesian networks. The result is, for the first
time, a completely general method to solve causal inference queries, be they
identifiable or not (in which case we deliver bounds), on semi-Markovian
structural causal models with categorical variables. We show empirically that
the approximation we provide becomes accurate in a fair number of EM runs. We
discuss the application of the causal EM to a real medical problem. Finally, we
show that causal inference is NP-hard also in models characterised by
polytree-shaped graphs; this supports developing approximate approaches to
causal inference.

    

### [[2103.08504] Distance Metric-Based Learning with Interpolated Latent Features for Location Classification in Endoscopy Image and Video](http://arxiv.org/abs/2103.08504)


  Conventional Endoscopy (CE) and Wireless Capsule Endoscopy (WCE) are known
tools for diagnosing gastrointestinal (GI) tract disorders. Detecting the
anatomical location of GI tract can help clinicians to determine a more
appropriate treatment plan, can reduce repetitive endoscopy and is important in
drug-delivery. There are few research that address detecting anatomical
location of WCE and CE images using classification, mainly because of
difficulty in collecting data and anotating them. In this study, we present a
few-shot learning method based on distance metric learning which combines
transfer-learning and manifold mixup scheme for localizing endoscopy frames and
can be trained on few samples. The manifold mixup process improves few-shot
learning by increasing the number of training epochs while reducing
overfitting, as well as providing more accurate decision boundaries. A dataset
is collected from 10 different anatomical positions of human GI tract. Two
models were trained using only 78 CE and 27 WCE annotated frames to predict the
location of 25700 and 1825 video frames from CE and WCE, respectively. In
addition, we performed subjective evaluation using nine gastroenterologists to
show the necessaity of having an AI system for localization. Various ablation
studies and interpretations are performed to show the importance of each step,
such effect of transfer-learning approach, and impact of manifold mixup on
performance. The proposed method is also compared with various methods trained
on categorical cross-entropy loss and produced better results which show that
proposed method has potential to be used for endoscopy image classification.

    

### [[2103.08508] Stack of discriminative autoencoders for multiclass anomaly detection in endoscopy images](http://arxiv.org/abs/2103.08508)


  Wireless Capsule Endoscopy (WCE) helps physicians examine the
gastrointestinal (GI) tract noninvasively. There are few studies that address
pathological assessment of endoscopy images in multiclass classification and
most of them are based on binary anomaly detection or aim to detect a specific
type of anomaly. Multiclass anomaly detection is challenging, especially when
the dataset is poorly sampled or imbalanced. Many available datasets in
endoscopy field, such as KID2, suffer from an imbalance issue, which makes it
difficult to train a high-performance model. Additionally, increasing the
number of classes makes classification more difficult. We proposed a multiclass
classification algorithm that is extensible to any number of classes and can
handle an imbalance issue. The proposed method uses multiple autoencoders where
each one is trained on one class to extract features with the most
discrimination from other classes. The loss function of autoencoders is set
based on reconstruction, compactness, distance from other classes, and
Kullback-Leibler (KL) divergence. The extracted features are clustered and then
classified using an ensemble of support vector data descriptors. A total of
1,778 normal, 227 inflammation, 303 vascular, and 44 polyp images from the KID2
dataset are used for evaluation. The entire algorithm ran 5 times and achieved
F1-score of 96.3 +- 0.2% and 85.0 +- 0.4% on the test set for binary and
multiclass anomaly detection, respectively. The impact of each step of the
algorithm was investigated by various ablation studies and the results were
compared with published works. The suggested approach is a competitive option
for detecting multiclass anomalies in the GI field.

    

### [<title>[dask] Is distributed training globally "data parallel" and locally "feature parallel"? - XGBoost</title>](https://discuss.xgboost.ai/t/dask-is-distributed-training-globally-data-parallel-and-locally-feature-parallel/1929/12)

### [<title>[dask] Is distributed training globally "data parallel" and locally "feature parallel"? - XGBoost</title>](https://discuss.xgboost.ai/t/dask-is-distributed-training-globally-data-parallel-and-locally-feature-parallel/1929/11)

### [<title>[dask] Is distributed training globally "data parallel" and locally "feature parallel"? - XGBoost</title>](https://discuss.xgboost.ai/t/dask-is-distributed-training-globally-data-parallel-and-locally-feature-parallel/1929/10)