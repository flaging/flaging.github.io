
## 2021-7-7

### [[2106.15113] An Efficient Cervical Whole Slide Image Analysis Framework Based on Multi-scale Semantic and Spatial Deep Features](http://arxiv.org/abs/2106.15113)


  Digital gigapixel whole slide image (WSI) is widely used in clinical
diagnosis, and automated WSI analysis is key for computer-aided diagnosis.
Currently, analyzing the integrated descriptor of probabilities or feature maps
from massive local patches encoded by ResNet classifier is the main manner for
WSI-level prediction. Feature representations of the sparse and tiny lesion
cells in cervical slides, however, are still challengeable for the
under-promoted upstream encoders, while the unused spatial representations of
cervical cells are the available features to supply the semantics analysis. As
well as patches sampling with overlap and repetitive processing incur the
inefficiency and the unpredictable side effect. This study designs a novel
inline connection network (InCNet) by enriching the multi-scale connectivity to
build the lightweight model named You Only Look Cytopathology Once (YOLCO) with
the additional supervision of spatial information. The proposed model allows
the input size enlarged to megapixel that can stitch the WSI without any
overlap by the average repeats decreased from $10^3\sim10^4$ to $10^1\sim10^2$
for collecting features and predictions at two scales. Based on Transformer for
classifying the integrated multi-scale multi-task features, the experimental
results appear $0.872$ AUC score better and $2.51\times$ faster than the best
conventional method in WSI classification on multicohort datasets of 2,019
slides from four scanning devices.

    