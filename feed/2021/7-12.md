
## 2021-7-12

### [<title>关于南昌哪里开具广告发票 - 百度经验 - DockOne.io</title>](http://dockone.io/question/586866)

### [<title>关于苏州如何开具加油费发票 - 百度知道 - DockOne.io</title>](http://dockone.io/question/586865)

### [<title>关于福州哪里开具广告发票 - 百度经验 - DockOne.io</title>](http://dockone.io/question/586864)

### [<title>关于惠州哪里开具广告发票 - 百度经验 - DockOne.io</title>](http://dockone.io/question/586863)

### [<title>关于宁波如何开具加油费发票 - 百度知道 - DockOne.io</title>](http://dockone.io/question/586862)

### [<title>关于郑州如何开具加油费发票 - 百度知道 - DockOne.io</title>](http://dockone.io/question/586861)

### [<title>关于佛山哪里开具广告发票 - 百度经验 - DockOne.io</title>](http://dockone.io/question/586860)

### [<title>关于东莞哪里开具广告发票 - 百度经验 - DockOne.io</title>](http://dockone.io/question/586859)

### [<title>关于重庆如何开具加油费发票 - 百度知道 - DockOne.io</title>](http://dockone.io/question/586858)

### [<title>关于天津如何开具加油费发票 - 百度知道 - DockOne.io</title>](http://dockone.io/question/586857)

### [<title>关于青岛哪里开具广告发票 - 百度经验 - DockOne.io</title>](http://dockone.io/question/586856)

### [<title>关于杭州如何开具加油费发票 - 百度知道 - DockOne.io</title>](http://dockone.io/question/586855)

### [<title>关于成都如何开具加油费发票 - 百度知道 - DockOne.io</title>](http://dockone.io/question/586854)

### [<title>关于南宁哪里开具广告发票 - 百度经验 - DockOne.io</title>](http://dockone.io/question/586853)

### [<title>关于厦门哪里开具广告发票 - 百度经验 - DockOne.io</title>](http://dockone.io/question/586852)

### [<title>关于广州如何开具加油费发票 - 百度知道 - DockOne.io</title>](http://dockone.io/question/586851)

### [<title>关于贵阳哪里开具广告发票 - 百度经验 - DockOne.io</title>](http://dockone.io/question/586850)

### [<title>关于深圳如何开具加油费发票 - 百度知道 - DockOne.io</title>](http://dockone.io/question/586849)

### [<title>关于兰州哪里开具广告发票 - 百度经验 - DockOne.io</title>](http://dockone.io/question/586848)

### [<title>关于北京如何开具加油费发票 - 百度知道 - DockOne.io</title>](http://dockone.io/question/586847)

### [<title>Set base_score in Learning API Python - XGBoost</title>](https://discuss.xgboost.ai/t/set-base-score-in-learning-api-python/1604/3)

### [[2107.04128] Evolution of Target Localization in Wireless Sensor Network (WSN): A Review](http://arxiv.org/abs/2107.04128)


  Wireless Sensor Network holds a pivotal position and gained a lot of
attention from researchers in recent years. Sensor nodes have been used in vast
applications such as environment monitoring, security purpose applications, and
target tracking. This latter comprises of detection and monitoring of the
target movement. In this paper, we explore in detail well-known target tracking
techniques. The existing techniques are evaluated using metrics such as network
topology, target recovery, energy efficiency, and security. We also discuss
some of the challenges that affect the performance of tracking schemes.
Furthermore, a thorough analysis is performed on existing techniques and future
directions are explored.

    

### [[2107.04207] QoS-Aware Load Balancing in Wireless Networks using Clipped Double Q-Learning](http://arxiv.org/abs/2107.04207)


  In recent years, long-term evolution (LTE) and 5G NR (5th Generation New
Radio) technologies have showed great potential to utilize Machine Learning
(ML) algorithms in optimizing their operations, both thanks to the availability
of fine-grained data from the field, as well as the need arising from growing
complexity of networks. The aforementioned complexity sparked mobile operators'
attention as a way to reduce the capital expenditures (CAPEX) and the
operational (OPEX) expenditures of their networks through network management
automation (NMA). NMA falls under the umbrella of Self-Organizing Networks
(SON) in which 3GPP has identified some challenges and opportunities in load
balancing mechanisms for the Radio Access Networks (RANs). In the context of
machine learning and load balancing, several studies have focused on maximizing
the overall network throughput or the resource block utilization (RBU). In this
paper, we propose a novel Clipped Double Q-Learning (CDQL)-based load balancing
approach considering resource block utilization, latency and the Channel
Quality Indicator (CQI). We compare our proposal with a traditional handover
algorithm and a resource block utilization based handover mechanism. Simulation
results reveal that our scheme is able to improve throughput, latency, jitter
and packet loss ratio in comparison to the baseline algorithms.

    

### [[2107.04328] BEAT: Blockchain-Enabled Accountable and Transparent Network Sharing in 6G](http://arxiv.org/abs/2107.04328)


  Infrastructure sharing is a widely discussed and implemented approach and is
successfully adopted in telecommunications networks today. In practice, it is
implemented through prior negotiated Service Level Agreements (SLAs) between
the parties involved. However, it is recognised that these agreements are
difficult to negotiate, monitor and enforce. For future 6G networks, resource
and infrastructure sharing is expected to play an even greater role. It will be
a crucial technique for reducing overall infrastructure costs and increasing
operational efficiencies for operators. More efficient SLA mechanisms are thus
crucial to the success of future networks.
In this work, we present "BEAT", an automated, transparent and accountable
end-to-end architecture for network sharing based on blockchain and smart
contracts. This work focuses on a particular type of blockchain, Permissioned
Distributed Ledger (PDL), due to its permissioned nature allowing for
industry-compliant SLAs with stringent governance. Our architecture can be
implemented with minimal hardware changes and with minimal overheads.

    

### [[2107.04436] Large Scale Measurement on the Adoption of Encrypted DNS](http://arxiv.org/abs/2107.04436)


  Several encryption proposals for DNS have been presented since 2016, but
their adoption was not comprehensively studied yet. This research measured the
current adoption of DoH (DNS over HTTPS), DoT (DNS over TLS), and DoQ (DNS over
QUIC) for five months at the beginning of 2021 by three different organizations
with global coverage. By comparing the total values, amount of requests per
user, and the seasonality of the traffic, it was possible to obtain the current
adoption trends. Moreover, we actively scanned the Internet for still-unknown
working DoH servers and we compared them with a novel curated list of
well-known DoH servers. We conclude that despite growing in 2020, during the
first five months of 2021 there was statistically significant evidence that the
average amount of Internet traffic for DoH, DoT and DoQ remained stationary.
However, we found that the amount of, still unknown and ready to use, DoH
servers grew 4 times. These measurements suggest that even though the amount of
encrypted DNS is currently not growing, there may probably be more connections
soon to those unknown DoH servers for benign and malicious purposes.

    

### [[2107.04464] A First Look at Class Incremental Learning in Deep Learning Mobile Traffic Classification](http://arxiv.org/abs/2107.04464)


  The recent popularity growth of Deep Learning (DL) re-ignited the interest
towards traffic classification, with several studies demonstrating the accuracy
of DL-based classifiers to identify Internet applications' traffic. Even with
the aid of hardware accelerators (GPUs, TPUs), DL model training remains
expensive, and limits the ability to operate frequent model updates necessary
to fit to the ever evolving nature of Internet traffic, and mobile traffic in
particular. To address this pain point, in this work we explore Incremental
Learning (IL) techniques to add new classes to models without a full
retraining, hence speeding up model's updates cycle. We consider iCarl, a state
of the art IL method, and MIRAGE-2019, a public dataset with traffic from 40
Android apps, aiming to understand "if there is a case for incremental learning
in traffic classification". By dissecting iCarl internals, we discuss ways to
improve its design, contributing a revised version, namely iCarl+. Despite our
analysis reveals their infancy, IL techniques are a promising research area on
the roadmap towards automated DL-based traffic analysis systems.

    

### [[2107.04526] A Dual-Connection based Handover Scheme for Ultra-Dense Millimeter-Wave Cellular Networks](http://arxiv.org/abs/2107.04526)


  Mobile users in an ultra-dense millimeter-wave cellular network experience
handover events more frequently than in conventional networks, which results in
increased service interruption time and performance degradation due to
blockages. Multi-connectivity has been proposed to resolve this, and it also
extends the coverage of millimeter-wave communications. In this paper, we
propose a dual-connection based handover scheme for mobile UEs in an
environment where they are connected simultaneously with two millimeter-wave
cells to overcome frequent handover problems. This scheme allows a mobile UE to
choose its serving link between the two mmWave connections according to the
measured SINRs and then the corresponding base stations may forward duplicate
packets to the UE. We compare our dual-connection based scheme with a
conventional single-connection based scheme through ns-3 simulation. The
simulation results show that the proposed scheme significantly reduces handover
rate and delay. Therefore, we argue that the dual-connection based scheme helps
mobile users achieve performance goals they require in ultra-dense cellular
environments.

    

### [[2012.05266] Optimising cost vs accuracy of decentralised analytics in fog computing environments](http://arxiv.org/abs/2012.05266)


  The exponential growth of devices and data at the edges of the Internet is
rising scalability and privacy concerns on approaches based exclusively on
remote cloud platforms. Data gravity, a fundamental concept in Fog Computing,
points towards decentralisation of computation for data analysis, as a viable
alternative to address those concerns. Decentralising AI tasks on several
cooperative devices means identifying the optimal set of locations or
Collection Points (CP for short) to use, in the continuum between full
centralisation (i.e., all data on a single device) and full decentralisation
(i.e., data on source locations). We propose an analytical framework able to
find the optimal operating point in this continuum, linking the accuracy of the
learning task with the corresponding network and computational cost for moving
data and running the distributed training at the CPs. We show through
simulations that the model accurately predicts the optimal trade-off, quite
often an intermediate point between full centralisation and full
decentralisation, showing also a significant cost saving w.r.t. both of them.
Finally, the analytical model admits closed-form or numeric solutions, making
it not only a performance evaluation instrument but also a design tool to
configure a given distributed learning task optimally before its deployment.

    

### [[2107.04050] Efficient Model-Based Multi-Agent Mean-Field Reinforcement Learning](http://arxiv.org/abs/2107.04050)


  Learning in multi-agent systems is highly challenging due to the inherent
complexity introduced by agents' interactions. We tackle systems with a huge
population of interacting agents (e.g., swarms) via Mean-Field Control (MFC).
MFC considers an asymptotically infinite population of identical agents that
aim to collaboratively maximize the collective reward. Specifically, we
consider the case of unknown system dynamics where the goal is to
simultaneously optimize for the rewards and learn from experience. We propose
an efficient model-based reinforcement learning algorithm
$\text{M}^3\text{-UCRL}$ that runs in episodes and provably solves this
problem. $\text{M}^3\text{-UCRL}$ uses upper-confidence bounds to balance
exploration and exploitation during policy learning. Our main theoretical
contributions are the first general regret bounds for model-based RL for MFC,
obtained via a novel mean-field type analysis. $\text{M}^3\text{-UCRL}$ can be
instantiated with different models such as neural networks or Gaussian
Processes, and effectively combined with neural network policy learning. We
empirically demonstrate the convergence of $\text{M}^3\text{-UCRL}$ on the
swarm motion problem of controlling an infinite population of agents seeking to
maximize location-dependent reward and avoid congested areas.

    

### [[2107.04055] 3D RegNet: Deep Learning Model for COVID-19 Diagnosis on Chest CT Image](http://arxiv.org/abs/2107.04055)


  In this paper, a 3D-RegNet-based neural network is proposed for diagnosing
the physical condition of patients with coronavirus (Covid-19) infection. In
the application of clinical medicine, lung CT images are utilized by
practitioners to determine whether a patient is infected with coronavirus.
However, there are some laybacks can be considered regarding to this diagnostic
method, such as time consuming and low accuracy. As a relatively large organ of
human body, important spatial features would be lost if the lungs were
diagnosed utilizing two dimensional slice image. Therefore, in this paper, a
deep learning model with 3D image was designed. The 3D image as input data was
comprised of two-dimensional pulmonary image sequence and from which relevant
coronavirus infection 3D features were extracted and classified. The results
show that the test set of the 3D model, the result: f1 score of 0.8379 and AUC
value of 0.8807 have been achieved.

    

### [[2107.04057] Machine Learning for Stuttering Identification: Review, Challenges & Future Directions](http://arxiv.org/abs/2107.04057)


  Stuttering is a speech disorder during which the flow of speech is
interrupted by involuntary pauses and repetition of sounds. Stuttering
identification is an interesting interdisciplinary domain research problem
which involves pathology, psychology, acoustics, and signal processing that
makes it hard and complicated to detect. Recent developments in machine and
deep learning have dramatically revolutionized speech domain, however minimal
attention has been given to stuttering identification. This work fills the gap
by trying to bring researchers together from interdisciplinary fields. In this
paper, we review comprehensively acoustic features, statistical and deep
learning based stuttering/disfluency classification methods. We also present
several challenges and possible future directions.

    

### [[2107.04061] Scaling Gaussian Processes with Derivative Information Using Variational Inference](http://arxiv.org/abs/2107.04061)


  Gaussian processes with derivative information are useful in many settings
where derivative information is available, including numerous Bayesian
optimization and regression tasks that arise in the natural sciences.
Incorporating derivative observations, however, comes with a dominating
$O(N^3D^3)$ computational cost when training on $N$ points in $D$ input
dimensions. This is intractable for even moderately sized problems. While
recent work has addressed this intractability in the low-$D$ setting, the
high-$N$, high-$D$ setting is still unexplored and of great value, particularly
as machine learning problems increasingly become high dimensional. In this
paper, we introduce methods to achieve fully scalable Gaussian process
regression with derivatives using variational inference. Analogous to the use
of inducing values to sparsify the labels of a training set, we introduce the
concept of inducing directional derivatives to sparsify the partial derivative
information of a training set. This enables us to construct a variational
posterior that incorporates derivative information but whose size depends
neither on the full dataset size $N$ nor the full dimensionality $D$. We
demonstrate the full scalability of our approach on a variety of tasks, ranging
from a high dimensional stellarator fusion regression task to training graph
convolutional neural networks on Pubmed using Bayesian optimization.
Surprisingly, we find that our approach can improve regression performance even
in settings where only label data is available.

    

### [[2107.04062] Comparison of 2D vs. 3D U-Net Organ Segmentation in abdominal 3D CT images](http://arxiv.org/abs/2107.04062)


  A two-step concept for 3D segmentation on 5 abdominal organs inside
volumetric CT images is presented. First each relevant organ's volume of
interest is extracted as bounding box. The extracted volume acts as input for a
second stage, wherein two compared U-Nets with different architectural
dimensions re-construct an organ segmentation as label mask. In this work, we
focus on comparing 2D U-Nets vs. 3D U-Net counterparts. Our initial results
indicate Dice improvements of about 6\% at maximum. In this study to our
surprise, liver and kidneys for instance were tackled significantly better
using the faster and GPU-memory saving 2D U-Nets. For other abdominal key
organs, there were no significant differences, but we observe highly
significant advantages for the 2D U-Net in terms of GPU computational efforts
for all organs under study.

    

### [[2107.04071] A Triangle Inequality for Cosine Similarity](http://arxiv.org/abs/2107.04071)


  Similarity search is a fundamental problem for many data analysis techniques.
Many efficient search techniques rely on the triangle inequality of metrics,
which allows pruning parts of the search space based on transitive bounds on
distances. Recently, Cosine similarity has become a popular alternative choice
to the standard Euclidean metric, in particular in the context of textual data
and neural network embeddings. Unfortunately, Cosine similarity is not metric
and does not satisfy the standard triangle inequality. Instead, many search
techniques for Cosine rely on approximation techniques such as locality
sensitive hashing. In this paper, we derive a triangle inequality for Cosine
similarity that is suitable for efficient similarity search with many standard
search structures (such as the VP-tree, Cover-tree, and M-tree); show that this
bound is tight and discuss fast approximations for it. We hope that this spurs
new research on accelerating exact similarity search for cosine similarity, and
possible other similarity measures beyond the existing work for distance
metrics.

    

### [[2107.04074] Accelerating Spherical k-Means](http://arxiv.org/abs/2107.04074)


  Spherical k-means is a widely used clustering algorithm for sparse and
high-dimensional data such as document vectors. While several improvements and
accelerations have been introduced for the original k-means algorithm, not all
easily translate to the spherical variant: Many acceleration techniques, such
as the algorithms of Elkan and Hamerly, rely on the triangle inequality of
Euclidean distances. However, spherical k-means uses Cosine similarities
instead of distances for computational efficiency. In this paper, we
incorporate the Elkan and Hamerly accelerations to the spherical k-means
algorithm working directly with the Cosines instead of Euclidean distances to
obtain a substantial speedup and evaluate these spherical accelerations on real
data.

    

### [[2107.04086] Robust Counterfactual Explanations on Graph Neural Networks](http://arxiv.org/abs/2107.04086)


  Massive deployment of Graph Neural Networks (GNNs) in high-stake applications
generates a strong demand for explanations that are robust to noise and align
well with human intuition. Most existing methods generate explanations by
identifying a subgraph of an input graph that has a strong correlation with the
prediction. These explanations are not robust to noise because independently
optimizing the correlation for a single input can easily overfit noise.
Moreover, they do not align well with human intuition because removing an
identified subgraph from an input graph does not necessarily change the
prediction result. In this paper, we propose a novel method to generate robust
counterfactual explanations on GNNs by explicitly modelling the common decision
logic of GNNs on similar input graphs. Our explanations are naturally robust to
noise because they are produced from the common decision boundaries of a GNN
that govern the predictions of many similar input graphs. The explanations also
align well with human intuition because removing the set of edges identified by
an explanation from the input graph changes the prediction significantly.
Exhaustive experiments on many public datasets demonstrate the superior
performance of our method.

    

### [[2107.04091] Ensembles of Randomized NNs for Pattern-based Time Series Forecasting](http://arxiv.org/abs/2107.04091)


  In this work, we propose an ensemble forecasting approach based on randomized
neural networks. Improved randomized learning streamlines the fitting abilities
of individual learners by generating network parameters in accordance with the
data and target function features. A pattern-based representation of time
series makes the proposed approach suitable for forecasting time series with
multiple seasonality. We propose six strategies for controlling the diversity
of ensemble members. Case studies conducted on four real-world forecasting
problems verified the effectiveness and superior performance of the proposed
ensemble forecasting approach. It outperformed statistical models as well as
state-of-the-art machine learning models in terms of forecasting accuracy. The
proposed approach has several advantages: fast and easy training, simple
architecture, ease of implementation, high accuracy and the ability to deal
with nonstationarity and multiple seasonality in time series.

    

### [[2107.04092] Even Faster SNN Simulation with Lazy+Event-driven Plasticity and Shared Atomics](http://arxiv.org/abs/2107.04092)


  We present two novel optimizations that accelerate clock-based spiking neural
network (SNN) simulators. The first one targets spike timing dependent
plasticity (STDP). It combines lazy- with event-driven plasticity and
efficiently facilitates the computation of pre- and post-synaptic spikes using
bitfields and integer intrinsics. It offers higher bandwidth than event-driven
plasticity alone and achieves a 1.5x-2x speedup over our closest competitor.
The second optimization targets spike delivery. We partition our graph
representation in a way that bounds the number of neurons that need be updated
at any given time which allows us to perform said update in shared memory
instead of global memory. This is 2x-2.5x faster than our closest competitor.
Both optimizations represent the final evolutionary stages of years of
iteration on STDP and spike delivery inside "Spice" (/spaIk/), our state of the
art SNN simulator. The proposed optimizations are not exclusive to our graph
representation or pipeline but are applicable to a multitude of simulator
designs. We evaluate our performance on three well-established models and
compare ourselves against three other state of the art simulators.

    

### [[2107.04119] Quantitative Evaluation of Explainable Graph Neural Networks for Molecular Property Prediction](http://arxiv.org/abs/2107.04119)


  Advances in machine learning have led to graph neural network-based methods
for drug discovery, yielding promising results in molecular design, chemical
synthesis planning, and molecular property prediction. However, current graph
neural networks (GNNs) remain of limited acceptance in drug discovery is
limited due to their lack of interpretability. Although this major weakness has
been mitigated by the development of explainable artificial intelligence (XAI)
techniques, the "ground truth" assignment in most explainable tasks ultimately
rests with subjective judgments by humans so that the quality of model
interpretation is hard to evaluate in quantity. In this work, we first build
three levels of benchmark datasets to quantitatively assess the
interpretability of the state-of-the-art GNN models. Then we implemented recent
XAI methods in combination with different GNN algorithms to highlight the
benefits, limitations, and future opportunities for drug discovery. As a
result, GradInput and IG generally provide the best model interpretability for
GNNs, especially when combined with GraphNet and CMPNN. The integrated and
developed XAI package is fully open-sourced and can be used by practitioners to
train new models on other drug discovery tasks.

    

### [[2107.04126] Many Objective Bayesian Optimization](http://arxiv.org/abs/2107.04126)


  Some real problems require the evaluation of expensive and noisy objective
functions. Moreover, the analytical expression of these objective functions may
be unknown. These functions are known as black-boxes, for example, estimating
the generalization error of a machine learning algorithm and computing its
prediction time in terms of its hyper-parameters. Multi-objective Bayesian
optimization (MOBO) is a set of methods that has been successfully applied for
the simultaneous optimization of black-boxes. Concretely, BO methods rely on a
probabilistic model of the objective functions, typically a Gaussian process.
This model generates a predictive distribution of the objectives. However, MOBO
methods have problems when the number of objectives in a multi-objective
optimization problem are 3 or more, which is the many objective setting. In
particular, the BO process is more costly as more objectives are considered,
computing the quality of the solution via the hyper-volume is also more costly
and, most importantly, we have to evaluate every objective function, wasting
expensive computational, economic or other resources. However, as more
objectives are involved in the optimization problem, it is highly probable that
some of them are redundant and not add information about the problem solution.
A measure that represents how similar are GP predictive distributions is
proposed. We also propose a many objective Bayesian optimization algorithm that
uses this metric to determine whether two objectives are redundant. The
algorithm stops evaluating one of them if the similarity is found, saving
resources and not hurting the performance of the multi-objective BO algorithm.
We show empirical evidence in a set of toy, synthetic, benchmark and real
experiments that GPs predictive distributions of the effectiveness of the
metric and the algorithm.

    

### [[2107.04127] Multitask Multi-database Emotion Recognition](http://arxiv.org/abs/2107.04127)


  In this work, we introduce our submission to the 2nd Affective Behavior
Analysis in-the-wild (ABAW) 2021 competition. We train a unified deep learning
model on multi-databases to perform two tasks: seven basic facial expressions
prediction and valence-arousal estimation. Since these databases do not
contains labels for all the two tasks, we have applied the distillation
knowledge technique to train two networks: one teacher and one student model.
The student model will be trained using both ground truth labels and soft
labels derived from the pretrained teacher model. During the training, we add
one more task, which is the combination of the two mentioned tasks, for better
exploiting inter-task correlations. We also exploit the sharing videos between
the two tasks of the AffWild2 database that is used in the competition, to
further improve the performance of the network. Experiment results shows that
the network have achieved promising results on the validation set of the
AffWild2 database. Code and pretrained model are publicly available at
this https URL


### [[2107.04129] Fedlearn-Algo: A flexible open-source privacy-preserving machine learning platform](http://arxiv.org/abs/2107.04129)


  In this paper, we present Fedlearn-Algo, an open-source privacy preserving
machine learning platform. We use this platform to demonstrate our research and
development results on privacy preserving machine learning algorithms. As the
first batch of novel FL algorithm examples, we release vertical federated
kernel binary classification model and vertical federated random forest model.
They have been tested to be more efficient than existing vertical federated
learning models in our practice. Besides the novel FL algorithm examples, we
also release a machine communication module. The uniform data transfer
interface supports transfering widely used data formats between machines. We
will maintain this platform by adding more functional modules and algorithm
examples.

    

### [[2107.04139] Learning to Delegate for Large-scale Vehicle Routing](http://arxiv.org/abs/2107.04139)


  Vehicle routing problems (VRPs) are a class of combinatorial problems with
wide practical applications. While previous heuristic or learning-based works
achieve decent solutions on small problem instances of up to 100 customers,
their performance does not scale to large problems. This article presents a
novel learning-augmented local search algorithm to solve large-scale VRP. The
method iteratively improves the solution by identifying appropriate subproblems
and $\textit{delegating}$ their improvement to a black box subsolver. At each
step, we leverage spatial locality to consider only a linear number of
subproblems, rather than exponential. We frame subproblem selection as a
regression problem and train a Transformer on a generated training set of
problem instances. We show that our method achieves state-of-the-art
performance, with a speed-up of up to 15 times over strong baselines, on VRPs
with sizes ranging from 500 to 3000.

    

### [[2107.04144] Does Form Follow Function? An Empirical Exploration of the Impact of Deep Neural Network Architecture Design on Hardware-Specific Acceleration](http://arxiv.org/abs/2107.04144)


  The fine-grained relationship between form and function with respect to deep
neural network architecture design and hardware-specific acceleration is one
area that is not well studied in the research literature, with form often
dictated by accuracy as opposed to hardware function. In this study, a
comprehensive empirical exploration is conducted to investigate the impact of
deep neural network architecture design on the degree of inference speedup that
can be achieved via hardware-specific acceleration. More specifically, we
empirically study the impact of a variety of commonly used macro-architecture
design patterns across different architectural depths through the lens of
OpenVINO microprocessor-specific and GPU-specific acceleration. Experimental
results showed that while leveraging hardware-specific acceleration achieved an
average inference speed-up of 380%, the degree of inference speed-up varied
drastically depending on the macro-architecture design pattern, with the
greatest speedup achieved on the depthwise bottleneck convolution design
pattern at 550%. Furthermore, we conduct an in-depth exploration of the
correlation between FLOPs requirement, level 3 cache efficacy, and network
latency with increasing architectural depth and width. Finally, we analyze the
inference time reductions using hardware-specific acceleration when compared to
native deep learning frameworks across a wide variety of hand-crafted deep
convolutional neural network architecture designs as well as ones found via
neural architecture search strategies. We found that the DARTS-derived
architecture to benefit from the greatest improvement from hardware-specific
software acceleration (1200%) while the depthwise bottleneck convolution-based
MobileNet-V2 to have the lowest overall inference time of around 2.4 ms.

    

### [[2107.04150] MCMC Variational Inference via Uncorrected Hamiltonian Annealing](http://arxiv.org/abs/2107.04150)


  Given an unnormalized target distribution we want to obtain approximate
samples from it and a tight lower bound on its (log) normalization constant log
Z. Annealed Importance Sampling (AIS) with Hamiltonian MCMC is a powerful
method that can be used to do this. Its main drawback is that it uses
non-differentiable transition kernels, which makes tuning its many parameters
hard. We propose a framework to use an AIS-like procedure with Uncorrected
Hamiltonian MCMC, called Uncorrected Hamiltonian Annealing. Our method leads to
tight and differentiable lower bounds on log Z. We show empirically that our
method yields better performances than other competing approaches, and that the
ability to tune its parameters using reparameterization gradients may lead to
large performance improvements.

    

### [[2107.04154] On lattice-free boosted MMI training of HMM and CTC-based full-context ASR models](http://arxiv.org/abs/2107.04154)


  Hybrid automatic speech recognition (ASR) models are typically sequentially
trained with CTC or LF-MMI criteria. However, they have vastly different
legacies and are usually implemented in different frameworks. In this paper, by
decoupling the concepts of modeling units and label topologies and building
proper numerator/denominator graphs accordingly, we establish a generalized
framework for hybrid acoustic modeling (AM). In this framework, we show that
LF-MMI is a powerful training criterion applicable to both limited-context and
full-context models, for wordpiece/mono-char/bi-char/chenone units, with both
HMM/CTC topologies. From this framework, we propose three novel training
schemes: chenone(ch)/wordpiece(wp)-CTC-bMMI, and wordpiece(wp)-HMM-bMMI with
different advantages in training performance, decoding efficiency and decoding
time-stamp accuracy. The advantages of different training schemes are evaluated
comprehensively on Librispeech, and wp-CTC-bMMI and ch-CTC-bMMI are evaluated
on two real world ASR tasks to show their effectiveness. Besides, we also show
bi-char(bc) HMM-MMI models can serve as better alignment models than
traditional non-neural GMM-HMMs.

    

### [[2107.04163] Towards Robust Active Feature Acquisition](http://arxiv.org/abs/2107.04163)


  Truly intelligent systems are expected to make critical decisions with
incomplete and uncertain data. Active feature acquisition (AFA), where features
are sequentially acquired to improve the prediction, is a step towards this
goal. However, current AFA models all deal with a small set of candidate
features and have difficulty scaling to a large feature space. Moreover, they
are ignorant about the valid domains where they can predict confidently, thus
they can be vulnerable to out-of-distribution (OOD) inputs. In order to remedy
these deficiencies and bring AFA models closer to practical use, we propose
several techniques to advance the current AFA approaches. Our framework can
easily handle a large number of features using a hierarchical acquisition
policy and is more robust to OOD inputs with the help of an OOD detector for
partially observed data. Extensive experiments demonstrate the efficacy of our
framework over strong baselines.

    

### [[2107.04174] EasyCom: An Augmented Reality Dataset to Support Algorithms for Easy Communication in Noisy Environments](http://arxiv.org/abs/2107.04174)


  Augmented Reality (AR) as a platform has the potential to facilitate the
reduction of the cocktail party effect. Future AR headsets could potentially
leverage information from an array of sensors spanning many different
modalities. Training and testing signal processing and machine learning
algorithms on tasks such as beam-forming and speech enhancement require high
quality representative data. To the best of the author's knowledge, as of
publication there are no available datasets that contain synchronized
egocentric multi-channel audio and video with dynamic movement and
conversations in a noisy environment. In this work, we describe, evaluate and
release a dataset that contains over 5 hours of multi-modal data useful for
training and testing algorithms for the application of improving conversations
for an AR glasses wearer. We provide speech intelligibility, quality and
signal-to-noise ratio improvement results for a baseline method and show
improvements across all tested metrics. The dataset we are releasing contains
AR glasses egocentric multi-channel microphone array audio, wide field-of-view
RGB video, speech source pose, headset microphone audio, annotated voice
activity, speech transcriptions, head bounding boxes, target of speech and
source identification labels. We have created and are releasing this dataset to
facilitate research in multi-modal AR solutions to the cocktail party problem.

    

### [[2107.04184] Greedy structure learning from data that contains systematic missing values](http://arxiv.org/abs/2107.04184)


  Learning from data that contain missing values represents a common phenomenon
in many domains. Relatively few Bayesian Network structure learning algorithms
account for missing data, and those that do tend to rely on standard approaches
that assume missing data are missing at random, such as the
Expectation-Maximisation algorithm. Because missing data are often systematic,
there is a need for more pragmatic methods that can effectively deal with data
sets containing missing values not missing at random. The absence of approaches
that deal with systematic missing data impedes the application of BN structure
learning methods to real-world problems where missingness are not random. This
paper describes three variants of greedy search structure learning that utilise
pairwise deletion and inverse probability weighting to maximally leverage the
observed data and to limit potential bias caused by missing values. The first
two of the variants can be viewed as sub-versions of the third and best
performing variant, but are important in their own in illustrating the
successive improvements in learning accuracy. The empirical investigations show
that the proposed approach outperforms the commonly used and state-of-the-art
Structural EM algorithm, both in terms of learning accuracy and efficiency, as
well as both when data are missing at random and not at random.

    

### [[2107.04189] Personalized Federated Learning over non-IID Data for Indoor Localization](http://arxiv.org/abs/2107.04189)


  Localization and tracking of objects using data-driven methods is a popular
topic due to the complexity in characterizing the physics of wireless channel
propagation models. In these modeling approaches, data needs to be gathered to
accurately train models, at the same time that user's privacy is maintained. An
appealing scheme to cooperatively achieve these goals is known as Federated
Learning (FL). A challenge in FL schemes is the presence of non-independent and
identically distributed (non-IID) data, caused by unevenly exploration of
different areas. In this paper, we consider the use of recent FL schemes to
train a set of personalized models that are then optimally fused through
Bayesian rules, which makes it appropriate in the context of indoor
localization.

    

### [[2107.04191] Structured Model Pruning of Convolutional Networks on Tensor Processing Units](http://arxiv.org/abs/2107.04191)


  The deployment of convolutional neural networks is often hindered by high
computational and storage requirements. Structured model pruning is a promising
approach to alleviate these requirements. Using the VGG-16 model as an example,
we measure the accuracy-efficiency trade-off for various structured model
pruning methods and datasets (CIFAR-10 and ImageNet) on Tensor Processing Units
(TPUs). To measure the actual performance of models, we develop a structured
model pruning library for TensorFlow2 to modify models in place (instead of
adding mask layers). We show that structured model pruning can significantly
improve model memory usage and speed on TPUs without losing accuracy,
especially for small datasets (e.g., CIFAR-10).

    

### [[2107.04193] Probabilistic Trajectory Prediction with Structural Constraints](http://arxiv.org/abs/2107.04193)


  This work addresses the problem of predicting the motion trajectories of
dynamic objects in the environment. Recent advances in predicting motion
patterns often rely on machine learning techniques to extrapolate motion
patterns from observed trajectories, with no mechanism to directly incorporate
known rules. We propose a novel framework, which combines probabilistic
learning and constrained trajectory optimisation. The learning component of our
framework provides a distribution over future motion trajectories conditioned
on observed past coordinates. This distribution is then used as a prior to a
constrained optimisation problem which enforces chance constraints on the
trajectory distribution. This results in constraint-compliant trajectory
distributions which closely resemble the prior. In particular, we focus our
investigation on collision constraints, such that extrapolated future
trajectory distributions conform to the environment structure. We empirically
demonstrate on real-world and simulated datasets the ability of our framework
to learn complex probabilistic motion trajectories for motion data, while
directly enforcing constraints to improve generalisability, producing more
robust and higher quality trajectory distributions.

    

### [[2107.04197] REX: Revisiting Budgeted Training with an Improved Schedule](http://arxiv.org/abs/2107.04197)


  Deep learning practitioners often operate on a computational and monetary
budget. Thus, it is critical to design optimization algorithms that perform
well under any budget. The linear learning rate schedule is considered the best
budget-aware schedule, as it outperforms most other schedules in the low budget
regime. On the other hand, learning rate schedules -- such as the
\texttt{30-60-90} step schedule -- are known to achieve high performance when
the model can be trained for many epochs. Yet, it is often not known a priori
whether one's budget will be large or small; thus, the optimal choice of
learning rate schedule is made on a case-by-case basis. In this paper, we frame
the learning rate schedule selection problem as a combination of $i)$ selecting
a profile (i.e., the continuous function that models the learning rate
schedule), and $ii)$ choosing a sampling rate (i.e., how frequently the
learning rate is updated/sampled from this profile). We propose a novel profile
and sampling rate combination called the Reflected Exponential (REX) schedule,
which we evaluate across seven different experimental settings with both SGD
and Adam optimizers. REX outperforms the linear schedule in the low budget
regime, while matching or exceeding the performance of several state-of-the-art
learning rate schedules (linear, step, exponential, cosine, step decay on
plateau, and OneCycle) in both high and low budget regimes. Furthermore, REX
requires no added computation, storage, or hyperparameters.

    

### [[2107.04200] Safe Exploration by Solving Early Terminated MDP](http://arxiv.org/abs/2107.04200)


  Safe exploration is crucial for the real-world application of reinforcement
learning (RL). Previous works consider the safe exploration problem as
Constrained Markov Decision Process (CMDP), where the policies are being
optimized under constraints. However, when encountering any potential dangers,
human tends to stop immediately and rarely learns to behave safely in danger.
Motivated by human learning, we introduce a new approach to address safe RL
problems under the framework of Early Terminated MDP (ET-MDP). We first define
the ET-MDP as an unconstrained MDP with the same optimal value function as its
corresponding CMDP. An off-policy algorithm based on context models is then
proposed to solve the ET-MDP, which thereby solves the corresponding CMDP with
better asymptotic performance and improved learning efficiency. Experiments on
various CMDP tasks show a substantial improvement over previous methods that
directly solve CMDP.

    

### [[2107.04205] On the Variance of the Fisher Information for Deep Learning](http://arxiv.org/abs/2107.04205)


  The Fisher information matrix (FIM) has been applied to the realm of deep
learning. It is closely related to the loss landscape, the variance of the
parameters, second order optimization, and deep learning theory. The exact FIM
is either unavailable in closed form or too expensive to compute. In practice,
it is almost always estimated based on empirical samples. We investigate two
such estimators based on two equivalent representations of the FIM. They are
both unbiased and consistent with respect to the underlying "true" FIM. Their
estimation quality is characterized by their variance given in closed form. We
bound their variances and analyze how the parametric structure of a deep neural
network can impact the variance. We discuss the meaning of this variance
measure and our bounds in the context of deep learning.

    

### [[2107.04212] Measuring and Improving Model-Moderator Collaboration using Uncertainty Estimation](http://arxiv.org/abs/2107.04212)


  Content moderation is often performed by a collaboration between humans and
machine learning models. However, it is not well understood how to design the
collaborative process so as to maximize the combined moderator-model system
performance. This work presents a rigorous study of this problem, focusing on
an approach that incorporates model uncertainty into the collaborative process.
First, we introduce principled metrics to describe the performance of the
collaborative system under capacity constraints on the human moderator,
quantifying how efficiently the combined system utilizes human decisions. Using
these metrics, we conduct a large benchmark study evaluating the performance of
state-of-the-art uncertainty models under different collaborative review
strategies. We find that an uncertainty-based strategy consistently outperforms
the widely used strategy based on toxicity scores, and moreover that the choice
of review strategy drastically changes the overall system performance. Our
results demonstrate the importance of rigorous metrics for understanding and
developing effective moderator-model systems for content moderation, as well as
the utility of uncertainty estimation in this domain.

    

### [[2107.04226] Multi-path Convolutional Neural Networks Efficiently Improve Feature Extraction in Continuous Adventitious Lung Sound Detection](http://arxiv.org/abs/2107.04226)


  We previously established a large lung sound database, HF_Lung_V2 (Lung_V2).
We trained convolutional-bidirectional gated recurrent unit (CNN-BiGRU)
networks for detecting inhalation, exhalation, continuous adventitious sound
(CAS) and discontinuous adventitious sound at the recording level on the basis
of Lung_V2. However, the performance of CAS detection was poor due to many
reasons, one of which is the highly diversified CAS patterns. To make the
original CNN-BiGRU model learn the CAS patterns more effectively and not cause
too much computing burden, three strategies involving minimal modifications of
the network architecture of the CNN layers were investigated: (1) making the
CNN layers a bit deeper by using the residual blocks, (2) making the CNN layers
a bit wider by increasing the number of CNN kernels, and (3) separating the
feature input into multiple paths (the model was denoted by Multi-path
CNN-BiGRU). The performance of CAS segment and event detection were evaluated.
Results showed that improvement in CAS detection was observed among all the
proposed architecture-modified models. The F1 score for CAS event detection of
the proposed models increased from 0.445 to 0.491-0.530, which was deemed
significant. However, the Multi-path CNN-BiGRU model outperformed the other
models in terms of the number of winning titles (five) in total nine evaluation
metrics. In addition, the Multi-path CNN-BiGRU model did not cause extra
computing burden (0.97-fold inference time) compared to the original CNN-BiGRU
model. Conclusively, the Multi-path CNN layers can efficiently improve the
effectiveness of feature extraction and subsequently result in better CAS
detection.

    

### [[2107.04229] Improved Breath Phase and Continuous Adventitious Sound Detection in Lung and Tracheal Sound Using Mixed Set Training and Domain Adaptation](http://arxiv.org/abs/2107.04229)


  Previously, we established a lung sound database, HF_Lung_V2 and proposed
convolutional bidirectional gated recurrent unit (CNN-BiGRU) models with
adequate ability for inhalation, exhalation, continuous adventitious sound
(CAS), and discontinuous adventitious sound detection in the lung sound. In
this study, we proceeded to build a tracheal sound database, HF_Tracheal_V1,
containing 11107 of 15-second tracheal sound recordings, 23087 inhalation
labels, 16728 exhalation labels, and 6874 CAS labels. The tracheal sound in
HF_Tracheal_V1 and the lung sound in HF_Lung_V2 were either combined or used
alone to train the CNN-BiGRU models for respective lung and tracheal sound
analysis. Different training strategies were investigated and compared: (1)
using full training (training from scratch) to train the lung sound models
using lung sound alone and train the tracheal sound models using tracheal sound
alone, (2) using a mixed set that contains both the lung and tracheal sound to
train the models, and (3) using domain adaptation that finetuned the
pre-trained lung sound models with the tracheal sound data and vice versa.
Results showed that the models trained only by lung sound performed poorly in
the tracheal sound analysis and vice versa. However, the mixed set training and
domain adaptation can improve the performance of exhalation and CAS detection
in the lung sound, and inhalation, exhalation, and CAS detection in the
tracheal sound compared to positive controls (lung models trained only by lung
sound and vice versa). Especially, a model derived from the mixed set training
prevails in the situation of killing two birds with one stone.

    

### [[2107.04231] Exploring Dropout Discriminator for Domain Adaptation](http://arxiv.org/abs/2107.04231)


  Adaptation of a classifier to new domains is one of the challenging problems
in machine learning. This has been addressed using many deep and non-deep
learning based methods. Among the methodologies used, that of adversarial
learning is widely applied to solve many deep learning problems along with
domain adaptation. These methods are based on a discriminator that ensures
source and target distributions are close. However, here we suggest that rather
than using a point estimate obtaining by a single discriminator, it would be
useful if a distribution based on ensembles of discriminators could be used to
bridge this gap. This could be achieved using multiple classifiers or using
traditional ensemble methods. In contrast, we suggest that a Monte Carlo
dropout based ensemble discriminator could suffice to obtain the distribution
based discriminator. Specifically, we propose a curriculum based dropout
discriminator that gradually increases the variance of the sample based
distribution and the corresponding reverse gradients are used to align the
source and target feature representations. An ensemble of discriminators helps
the model to learn the data distribution efficiently. It also provides a better
gradient estimates to train the feature extractor. The detailed results and
thorough ablation analysis show that our model outperforms state-of-the-art
results.

    

### [[2107.04235] Training a Deep Neural Network via Policy Gradients for Blind Source Separation in Polyphonic Music Recordings](http://arxiv.org/abs/2107.04235)


  We propose a method for the blind separation of sounds of musical instruments
in audio signals. We describe the individual tones via a parametric model,
training a dictionary to capture the relative amplitudes of the harmonics. The
model parameters are predicted via a U-Net, which is a type of deep neural
network. The network is trained without ground truth information, based on the
difference between the model prediction and the individual STFT time frames.
Since some of the model parameters do not yield a useful backpropagation
gradient, we model them stochastically and employ the policy gradient instead.
To provide phase information and account for inaccuracies in the
dictionary-based representation, we also let the network output a direct
prediction, which we then use to resynthesize the audio signals for the
individual instruments. Due to the flexibility of the neural network,
inharmonicity can be incorporated seamlessly and no preprocessing of the input
spectra is required. Our algorithm yields high-quality separation results with
particularly low interference on a variety of different audio samples, both
acoustic and synthetic, provided that the sample contains enough data for the
training and that the spectral characteristics of the musical instruments are
sufficiently stable to be approximated by the dictionary.

    

### [[2107.04239] A Survey on Low-Resource Neural Machine Translation](http://arxiv.org/abs/2107.04239)


  Neural approaches have achieved state-of-the-art accuracy on machine
translation but suffer from the high cost of collecting large scale parallel
data. Thus, a lot of research has been conducted for neural machine translation
(NMT) with very limited parallel data, i.e., the low-resource setting. In this
paper, we provide a survey for low-resource NMT and classify related works into
three categories according to the auxiliary data they used: (1) exploiting
monolingual data of source and/or target languages, (2) exploiting data from
auxiliary languages, and (3) exploiting multi-modal data. We hope that our
survey can help researchers to better understand this field and inspire them to
design better algorithms, and help industry practitioners to choose appropriate
algorithms for their applications.

    

### [[2107.04240] Deep Image Synthesis from Intuitive User Input: A Review and Perspectives](http://arxiv.org/abs/2107.04240)


  In many applications of computer graphics, art and design, it is desirable
for a user to provide intuitive non-image input, such as text, sketch, stroke,
graph or layout, and have a computer system automatically generate
photo-realistic images that adhere to the input content. While classic works
that allow such automatic image content generation have followed a framework of
image retrieval and composition, recent advances in deep generative models such
as generative adversarial networks (GANs), variational autoencoders (VAEs), and
flow-based methods have enabled more powerful and versatile image generation
tasks. This paper reviews recent works for image synthesis given intuitive user
input, covering advances in input versatility, image generation methodology,
benchmark datasets, and evaluation metrics. This motivates new perspectives on
input representation and interactivity, cross pollination between major image
generation paradigms, and evaluation and comparison of generation methods.

    

### [[2107.04265] Sensitivity analysis in differentially private machine learning using hybrid automatic differentiation](http://arxiv.org/abs/2107.04265)


  In recent years, formal methods of privacy protection such as differential
privacy (DP), capable of deployment to data-driven tasks such as machine
learning (ML), have emerged. Reconciling large-scale ML with the closed-form
reasoning required for the principled analysis of individual privacy loss
requires the introduction of new tools for automatic sensitivity analysis and
for tracking an individual's data and their features through the flow of
computation. For this purpose, we introduce a novel \textit{hybrid} automatic
differentiation (AD) system which combines the efficiency of reverse-mode AD
with an ability to obtain a closed-form expression for any given quantity in
the computational graph. This enables modelling the sensitivity of arbitrary
differentiable function compositions, such as the training of neural networks
on private data. We demonstrate our approach by analysing the individual DP
guarantees of statistical database queries. Moreover, we investigate the
application of our technique to the training of DP neural networks. Our
approach can enable the principled reasoning about privacy loss in the setting
of data processing, and further the development of automatic sensitivity
analysis and privacy budgeting systems.

    

### [[2107.04271] FedAdapt: Adaptive Offloading for IoT Devices in Federated Learning](http://arxiv.org/abs/2107.04271)


  Applying Federated Learning (FL) on Internet-of-Things devices is
necessitated by the large volumes of data they produce and growing concerns of
data privacy. However, there are three challenges that need to be addressed to
make FL efficient: (i) execute on devices with limited computational
capabilities, (ii) account for stragglers due to computational heterogeneity of
devices, and (iii) adapt to the changing network bandwidths. This paper
presents FedAdapt, an adaptive offloading FL framework to mitigate the
aforementioned challenges. FedAdapt accelerates local training in
computationally constrained devices by leveraging layer offloading of deep
neural networks (DNNs) to servers. Further, FedAdapt adopts reinforcement
learning-based optimization and clustering to adaptively identify which layers
of the DNN should be offloaded for each individual device on to a server to
tackle the challenges of computational heterogeneity and changing network
bandwidth. Experimental studies are carried out on a lab-based testbed
comprising five IoT devices. By offloading a DNN from the device to the server
FedAdapt reduces the training time of a typical IoT device by over half
compared to classic FL. The training time of extreme stragglers and the overall
training time can be reduced by up to 57%. Furthermore, with changing network
bandwidth, FedAdapt is demonstrated to reduce the training time by up to 40%
when compared to classic FL, without sacrificing accuracy. FedAdapt can be
downloaded from this https URL.

    

### [[2107.04292] UniRE: A Unified Label Space for Entity Relation Extraction](http://arxiv.org/abs/2107.04292)


  Many joint entity relation extraction models setup two separated label spaces
for the two sub-tasks (i.e., entity detection and relation classification). We
argue that this setting may hinder the information interaction between entities
and relations. In this work, we propose to eliminate the different treatment on
the two sub-tasks' label spaces. The input of our model is a table containing
all word pairs from a sentence. Entities and relations are represented by
squares and rectangles in the table. We apply a unified classifier to predict
each cell's label, which unifies the learning of two sub-tasks. For testing, an
effective (yet fast) approximate decoder is proposed for finding squares and
rectangles from tables. Experiments on three benchmarks (ACE04, ACE05, SciERC)
show that, using only half the number of parameters, our model achieves
competitive accuracy with the best extractor, and is faster.

    

### [[2107.04296] Differentially private training of neural networks with Langevin dynamics forcalibrated predictive uncertainty](http://arxiv.org/abs/2107.04296)


  We show that differentially private stochastic gradient descent (DP-SGD) can
yield poorly calibrated, overconfident deep learning models. This represents a
serious issue for safety-critical applications, e.g. in medical diagnosis. We
highlight and exploit parallels between stochastic gradient Langevin dynamics,
a scalable Bayesian inference technique for training deep neural networks, and
DP-SGD, in order to train differentially private, Bayesian neural networks with
minor adjustments to the original (DP-SGD) algorithm. Our approach provides
considerably more reliable uncertainty estimates than DP-SGD, as demonstrated
empirically by a reduction in expected calibration error (MNIST $\sim{5}$-fold,
Pediatric Pneumonia Dataset $\sim{2}$-fold).

    

### [[2107.04309] Understanding surrogate explanations: the interplay between complexity, fidelity and coverage](http://arxiv.org/abs/2107.04309)


  This paper analyses the fundamental ingredients behind surrogate explanations
to provide a better understanding of their inner workings. We start our
exposition by considering global surrogates, describing the trade-off between
complexity of the surrogate and fidelity to the black-box being modelled. We
show that transitioning from global to local - reducing coverage - allows for
more favourable conditions on the Pareto frontier of fidelity-complexity of a
surrogate. We discuss the interplay between complexity, fidelity and coverage,
and consider how different user needs can lead to problem formulations where
these are either constraints or penalties. We also present experiments that
demonstrate how the local surrogate interpretability procedure can be made
interactive and lead to better explanations.

    

### [[2107.04312] Autoencoder-driven Spiral Representation Learning for Gravitational Wave Surrogate Modelling](http://arxiv.org/abs/2107.04312)


  Recently, artificial neural networks have been gaining momentum in the field
of gravitational wave astronomy, for example in surrogate modelling of
computationally expensive waveform models for binary black hole inspiral and
merger. Surrogate modelling yields fast and accurate approximations of
gravitational waves and neural networks have been used in the final step of
interpolating the coefficients of the surrogate model for arbitrary waveforms
outside the training sample. We investigate the existence of underlying
structures in the empirical interpolation coefficients using autoencoders. We
demonstrate that when the coefficient space is compressed to only two
dimensions, a spiral structure appears, wherein the spiral angle is linearly
related to the mass ratio. Based on this finding, we design a spiral module
with learnable parameters, that is used as the first layer in a neural network,
which learns to map the input space to the coefficients. The spiral module is
evaluated on multiple neural network architectures and consistently achieves
better speed-accuracy trade-off than baseline models. A thorough experimental
study is conducted and the final result is a surrogate model which can evaluate
millions of input parameters in a single forward pass in under 1ms on a desktop
GPU, while the mismatch between the corresponding generated waveforms and the
ground-truth waveforms is better than the compared baseline methods. We
anticipate the existence of analogous underlying structures and corresponding
computational gains also in the case of spinning black hole binaries.

    

### [[2107.04320] IDRLnet: A Physics-Informed Neural Network Library](http://arxiv.org/abs/2107.04320)


  Physics Informed Neural Network (PINN) is a scientific computing framework
used to solve both forward and inverse problems modeled by Partial Differential
Equations (PDEs). This paper introduces IDRLnet, a Python toolbox for modeling
and solving problems through PINN systematically. IDRLnet constructs the
framework for a wide range of PINN algorithms and applications. It provides a
structured way to incorporate geometric objects, data sources, artificial
neural networks, loss metrics, and optimizers within Python. Furthermore, it
provides functionality to solve noisy inverse problems, variational
minimization, and integral differential equations. New PINN variants can be
integrated into the framework easily. Source code, tutorials, and documentation
are available at \url{this https URL}.

    

### [[2107.04333] Attend2Pack: Bin Packing through Deep Reinforcement Learning with Attention](http://arxiv.org/abs/2107.04333)


  This paper seeks to tackle the bin packing problem (BPP) through a learning
perspective. Building on self-attention-based encoding and deep reinforcement
learning algorithms, we propose a new end-to-end learning model for this task
of interest. By decomposing the combinatorial action space, as well as
utilizing a new training technique denoted as prioritized oversampling, which
is a general scheme to speed up on-policy learning, we achieve state-of-the-art
performance in a range of experimental settings. Moreover, although the
proposed approach attend2pack targets offline-BPP, we strip our method down to
the strict online-BPP setting where it is also able to achieve state-of-the-art
performance. With a set of ablation studies as well as comparisons against a
range of previous works, we hope to offer as a valid baseline approach to this
field of study.

    

### [[2107.04346] Generalization of the Change of Variables Formula with Applications to Residual Flows](http://arxiv.org/abs/2107.04346)


  Normalizing flows leverage the Change of Variables Formula (CVF) to define
flexible density models. Yet, the requirement of smooth transformations
(diffeomorphisms) in the CVF poses a significant challenge in the construction
of these models. To enlarge the design space of flows, we introduce
$\mathcal{L}$-diffeomorphisms as generalized transformations which may violate
these requirements on zero Lebesgue-measure sets. This relaxation allows e.g.
the use of non-smooth activation functions such as ReLU. Finally, we apply the
obtained results to planar, radial, and contractive residual flows.

    

### [[2107.04357] Graph-based Deep Generative Modelling for Document Layout Generation](http://arxiv.org/abs/2107.04357)


  One of the major prerequisites for any deep learning approach is the
availability of large-scale training data. When dealing with scanned document
images in real world scenarios, the principal information of its content is
stored in the layout itself. In this work, we have proposed an automated deep
generative model using Graph Neural Networks (GNNs) to generate synthetic data
with highly variable and plausible document layouts that can be used to train
document interpretation systems, in this case, specially in digital mailroom
applications. It is also the first graph-based approach for document layout
generation task experimented on administrative document images, in this case,
invoices.

    

### [[2107.04367] Lithography Hotspot Detection via Heterogeneous Federated Learning with Local Adaptation](http://arxiv.org/abs/2107.04367)


  As technology scaling is approaching the physical limit, lithography hotspot
detection has become an essential task in design for manufacturability. While
the deployment of pattern matching or machine learning in hotspot detection can
help save significant simulation time, such methods typically demand for
non-trivial quality data to build the model, which most design houses are short
of. Moreover, the design houses are also unwilling to directly share such data
with the other houses to build a unified model, which can be ineffective for
the design house with unique design patterns due to data insufficiency. On the
other hand, with data homogeneity in each design house, the locally trained
models can be easily over-fitted, losing generalization ability and robustness.
In this paper, we propose a heterogeneous federated learning framework for
lithography hotspot detection that can address the aforementioned issues. On
one hand, the framework can build a more robust centralized global sub-model
through heterogeneous knowledge sharing while keeping local data private. On
the other hand, the global sub-model can be combined with a local sub-model to
better adapt to local data heterogeneity. The experimental results show that
the proposed framework can overcome the challenge of non-independent and
identically distributed (non-IID) data and heterogeneous communication to
achieve very high performance in comparison to other state-of-the-art methods
while guaranteeing a good convergence rate in various scenarios.

    

### [[2107.04369] Multi-headed Neural Ensemble Search](http://arxiv.org/abs/2107.04369)


  Ensembles of CNN models trained with different seeds (also known as Deep
Ensembles) are known to achieve superior performance over a single copy of the
CNN. Neural Ensemble Search (NES) can further boost performance by adding
architectural diversity. However, the scope of NES remains prohibitive under
limited computational resources. In this work, we extend NES to multi-headed
ensembles, which consist of a shared backbone attached to multiple prediction
heads. Unlike Deep Ensembles, these multi-headed ensembles can be trained end
to end, which enables us to leverage one-shot NAS methods to optimize an
ensemble objective. With extensive empirical evaluations, we demonstrate that
multi-headed ensemble search finds robust ensembles 3 times faster, while
having comparable performance to other ensemble search methods, in both
predictive performance and uncertainty calibration.

    

### [[2107.04380] Model compression as constrained optimization, with application to neural nets. Part V: combining compressions](http://arxiv.org/abs/2107.04380)


  Model compression is generally performed by using quantization, low-rank
approximation or pruning, for which various algorithms have been researched in
recent years. One fundamental question is: what types of compression work
better for a given model? Or even better: can we improve by combining
compressions in a suitable way? We formulate this generally as a problem of
optimizing the loss but where the weights are constrained to equal an additive
combination of separately compressed parts; and we give an algorithm to learn
the corresponding parts' parameters. Experimentally with deep neural nets, we
observe that 1) we can find significantly better models in the
error-compression space, indicating that different compression types have
complementary benefits, and 2) the best type of combination depends exquisitely
on the type of neural net. For example, we can compress ResNets and AlexNet
using only 1 bit per weight without error degradation at the cost of adding a
few floating point weights. However, VGG nets can be better compressed by
combining low-rank with a few floating point weights.

    

### [[2107.04381] Specialists Outperform Generalists in Ensemble Classification](http://arxiv.org/abs/2107.04381)


  Consider an ensemble of $k$ individual classifiers whose accuracies are
known. Upon receiving a test point, each of the classifiers outputs a predicted
label and a confidence in its prediction for this particular test point. In
this paper, we address the question of whether we can determine the accuracy of
the ensemble. Surprisingly, even when classifiers are combined in the
statistically optimal way in this setting, the accuracy of the resulting
ensemble classifier cannot be computed from the accuracies of the individual
classifiers-as would be the case in the standard setting of confidence weighted
majority voting. We prove tight upper and lower bounds on the ensemble
accuracy. We explicitly construct the individual classifiers that attain the
upper and lower bounds: specialists and generalists. Our theoretical results
have very practical consequences: (1) If we use ensemble methods and have the
choice to construct our individual (independent) classifiers from scratch, then
we should aim for specialist classifiers rather than generalists. (2) Our
bounds can be used to determine how many classifiers are at least required to
achieve a desired ensemble accuracy. Finally, we improve our bounds by
considering the mutual information between the true label and the individual
classifier's output.

    

### [[2107.04382] Bib2Auth: Deep Learning Approach for Author Disambiguation using Bibliographic Data](http://arxiv.org/abs/2107.04382)


  Author name ambiguity remains a critical open problem in digital libraries
due to synonymy and homonymy of names. In this paper, we propose a novel
approach to link author names to their real-world entities by relying on their
co-authorship pattern and area of research. Our supervised deep learning model
identifies an author by capturing his/her relationship with his/her co-authors
and area of research, which is represented by the titles and sources of the
target author's publications. These attributes are encoded by their semantic
and symbolic representations. To this end, Bib2Auth uses ~ 22K bibliographic
records from the DBLP repository and is trained with each pair of co-authors.
The extensive experiments have proved the capability of the approach to
distinguish between authors sharing the same name and recognize authors with
different name variations. Bib2Auth has shown good performance on a relatively
large dataset, which qualifies it to be directly integrated into bibliographic
indices.

    

### [[2107.04384] Continual Learning in the Teacher-Student Setup: Impact of Task Similarity](http://arxiv.org/abs/2107.04384)


  Continual learning-the ability to learn many tasks in sequence-is critical
for artificial learning systems. Yet standard training methods for deep
networks often suffer from catastrophic forgetting, where learning new tasks
erases knowledge of earlier tasks. While catastrophic forgetting labels the
problem, the theoretical reasons for interference between tasks remain unclear.
Here, we attempt to narrow this gap between theory and practice by studying
continual learning in the teacher-student setup. We extend previous analytical
work on two-layer networks in the teacher-student setup to multiple teachers.
Using each teacher to represent a different task, we investigate how the
relationship between teachers affects the amount of forgetting and transfer
exhibited by the student when the task switches. In line with recent work, we
find that when tasks depend on similar features, intermediate task similarity
leads to greatest forgetting. However, feature similarity is only one way in
which tasks may be related. The teacher-student approach allows us to
disentangle task similarity at the level of readouts (hidden-to-output weights)
and features (input-to-hidden weights). We find a complex interplay between
both types of similarity, initial transfer/forgetting rates, maximum
transfer/forgetting, and long-term transfer/forgetting. Together, these results
help illuminate the diverse factors contributing to catastrophic forgetting.

    

### [[2107.04388] Hoechst Is All You Need: LymphocyteClassification with Deep Learning](http://arxiv.org/abs/2107.04388)


  Multiplex immunofluorescence and immunohistochemistry benefit patients by
allowing cancer pathologists to identify several proteins expressed on the
surface of cells, enabling cell classification, better understanding of the
tumour micro-environment, more accurate diagnoses, prognoses, and tailored
immunotherapy based on the immune status of individual patients. However, they
are expensive and time consuming processes which require complex staining and
imaging techniques by expert technicians. Hoechst staining is much cheaper and
easier to perform, but is not typically used in this case as it binds to DNA
rather than to the proteins targeted by immunofluorescent techniques, and it
was not previously thought possible to differentiate cells expressing these
proteins based only on DNA morphology. In this work we show otherwise, training
a deep convolutional neural network to identify cells expressing three proteins
(T lymphocyte markers CD3 and CD8, and the B lymphocyte marker CD20) with
greater than 90% precision and recall, from Hoechst 33342 stained tissue only.
Our model learns previously unknown morphological features associated with
expression of these proteins which can be used to accurately differentiate
lymphocyte subtypes for use in key prognostic metrics such as assessment of
immune cell infiltration,and thereby predict and improve patient outcomes
without the need for costly multiplex immunofluorescence.

    

### [[2107.04401] Improving Model Robustness with Latent Distribution Locally and Globally](http://arxiv.org/abs/2107.04401)


  In this work, we consider model robustness of deep neural networks against
adversarial attacks from a global manifold perspective. Leveraging both the
local and global latent information, we propose a novel adversarial training
method through robust optimization, and a tractable way to generate Latent
Manifold Adversarial Examples (LMAEs) via an adversarial game between a
discriminator and a classifier. The proposed adversarial training with latent
distribution (ATLD) method defends against adversarial attacks by crafting
LMAEs with the latent manifold in an unsupervised manner. ATLD preserves the
local and global information of latent manifold and promises improved
robustness against adversarial attacks. To verify the effectiveness of our
proposed method, we conduct extensive experiments over different datasets
(e.g., CIFAR-10, CIFAR-100, SVHN) with different adversarial attacks (e.g.,
PGD, CW), and show that our method substantially outperforms the
state-of-the-art (e.g., Feature Scattering) in adversarial robustness by a
large accuracy margin. The source codes are available at
this https URL.

    

### [[2107.04419] Form2Seq : A Framework for Higher-Order Form Structure Extraction](http://arxiv.org/abs/2107.04419)


  Document structure extraction has been a widely researched area for decades
with recent works performing it as a semantic segmentation task over document
images using fully-convolution networks. Such methods are limited by image
resolution due to which they fail to disambiguate structures in dense regions
which appear commonly in forms. To mitigate this, we propose Form2Seq, a novel
sequence-to-sequence (Seq2Seq) inspired framework for structure extraction
using text, with a specific focus on forms, which leverages relative spatial
arrangement of structures. We discuss two tasks; 1) Classification of low-level
constituent elements (TextBlock and empty fillable Widget) into ten types such
as field captions, list items, and others; 2) Grouping lower-level elements
into higher-order constructs, such as Text Fields, ChoiceFields and
ChoiceGroups, used as information collection mechanism in forms. To achieve
this, we arrange the constituent elements linearly in natural reading order,
feed their spatial and textual representations to Seq2Seq framework, which
sequentially outputs prediction of each element depending on the final task. We
modify Seq2Seq for grouping task and discuss improvements obtained through
cascaded end-to-end training of two tasks versus training in isolation.
Experimental results show the effectiveness of our text-based approach
achieving an accuracy of 90% on classification task and an F1 of 75.82, 86.01,
61.63 on groups discussed above respectively, outperforming segmentation
baselines. Further we show our framework achieves state of the results for
table structure recognition on ICDAR 2013 dataset.

    

### [[2107.04422] Likelihood ratio-based policy gradient methods for distorted risk measures: A non-asymptotic analysis](http://arxiv.org/abs/2107.04422)


  We propose policy-gradient algorithms for solving the problem of control in a
risk-sensitive reinforcement learning (RL) context. The objective of our
algorithm is to maximize the distorted risk measure (DRM) of the cumulative
reward in an episodic Markov decision process (MDP). We derive a variant of the
policy gradient theorem that caters to the DRM objective. Using this theorem in
conjunction with a likelihood ratio (LR) based gradient estimation scheme, we
propose policy gradient algorithms for optimizing DRM in both on-policy and
off-policy RL settings. We derive non-asymptotic bounds that establish the
convergence of our algorithms to an approximate stationary point of the DRM
objective.

    

### [[2107.04423] Multiaccurate Proxies for Downstream Fairness](http://arxiv.org/abs/2107.04423)


  We study the problem of training a model that must obey demographic fairness
conditions when the sensitive features are not available at training time -- in
other words, how can we train a model to be fair by race when we don't have
data about race? We adopt a fairness pipeline perspective, in which an
"upstream" learner that does have access to the sensitive features will learn a
proxy model for these features from the other attributes. The goal of the proxy
is to allow a general "downstream" learner -- with minimal assumptions on their
prediction task -- to be able to use the proxy to train a model that is fair
with respect to the true sensitive features. We show that obeying multiaccuracy
constraints with respect to the downstream model class suffices for this
purpose, and provide sample- and oracle efficient-algorithms and generalization
bounds for learning such proxies. In general, multiaccuracy can be much easier
to satisfy than classification accuracy, and can be satisfied even when the
sensitive features are hard to predict.

    

### [[2107.04427] How to choose an Explainability Method? Towards a Methodical Implementation of XAI in Practice](http://arxiv.org/abs/2107.04427)


  Explainability is becoming an important requirement for organizations that
make use of automated decision-making due to regulatory initiatives and a shift
in public awareness. Various and significantly different algorithmic methods to
provide this explainability have been introduced in the field, but the existing
literature in the machine learning community has paid little attention to the
stakeholder whose needs are rather studied in the human-computer interface
community. Therefore, organizations that want or need to provide this
explainability are confronted with the selection of an appropriate method for
their use case. In this paper, we argue there is a need for a methodology to
bridge the gap between stakeholder needs and explanation methods. We present
our ongoing work on creating this methodology to help data scientists in the
process of providing explainability to stakeholders. In particular, our
contributions include documents used to characterize XAI methods and user
requirements (shown in Appendix), which our methodology builds upon.

    

### [[2107.04435] Learning to Detect Adversarial Examples Based on Class Scores](http://arxiv.org/abs/2107.04435)


  Given the increasing threat of adversarial attacks on deep neural networks
(DNNs), research on efficient detection methods is more important than ever. In
this work, we take a closer look at adversarial attack detection based on the
class scores of an already trained classification model. We propose to train a
support vector machine (SVM) on the class scores to detect adversarial
examples. Our method is able to detect adversarial examples generated by
various attacks, and can be easily adopted to a plethora of deep classification
models. We show that our approach yields an improved detection rate compared to
an existing method, whilst being easy to implement. We perform an extensive
empirical analysis on different deep classification models, investigating
various state-of-the-art adversarial attacks. Moreover, we observe that our
proposed method is better at detecting a combination of adversarial attacks.
This work indicates the potential of detecting various adversarial attacks
simply by using the class scores of an already trained classification model.

    

### [[2107.04438] A Comparison of Contextual and Non-Contextual Preference Ranking for Set Addition Problems](http://arxiv.org/abs/2107.04438)


  In this paper, we study the problem of evaluating the addition of elements to
a set. This problem is difficult, because it can, in the general case, not be
reduced to unconditional preferences between the choices. Therefore, we model
preferences based on the context of the decision. We discuss and compare two
different Siamese network architectures for this task: a twin network that
compares the two sets resulting after the addition, and a triplet network that
models the contribution of each candidate to the existing set. We evaluate the
two settings on a real-world task; learning human card preferences for deck
building in the collectible card game Magic: The Gathering. We show that the
triplet approach achieves a better result than the twin network and that both
outperform previous results on this task.

    

### [[2107.04457] Aligning an optical interferometer with beam divergence control and continuous action space](http://arxiv.org/abs/2107.04457)


  Reinforcement learning is finding its way to real-world problem application,
transferring from simulated environments to physical setups. In this work, we
implement vision-based alignment of an optical Mach-Zehnder interferometer with
a confocal telescope in one arm, which controls the diameter and divergence of
the corresponding beam. We use a continuous action space; exponential scaling
enables us to handle actions within a range of over two orders of magnitude.
Our agent trains only in a simulated environment with domain randomizations. In
an experimental evaluation, the agent significantly outperforms an existing
solution and a human expert.

    

### [[2107.04458] Understanding the Distributions of Aggregation Layers in Deep Neural Networks](http://arxiv.org/abs/2107.04458)


  The process of aggregation is ubiquitous in almost all deep nets models. It
functions as an important mechanism for consolidating deep features into a more
compact representation, whilst increasing robustness to overfitting and
providing spatial invariance in deep nets. In particular, the proximity of
global aggregation layers to the output layers of DNNs mean that aggregated
features have a direct influence on the performance of a deep net. A better
understanding of this relationship can be obtained using information theoretic
methods. However, this requires the knowledge of the distributions of the
activations of aggregation layers. To achieve this, we propose a novel
mathematical formulation for analytically modelling the probability
distributions of output values of layers involved with deep feature
aggregation. An important outcome is our ability to analytically predict the
KL-divergence of output nodes in a DNN. We also experimentally verify our
theoretical predictions against empirical observations across a range of
different classification tasks and datasets.

    

### [[2107.04462] Redescription Model Mining](http://arxiv.org/abs/2107.04462)


  This paper introduces Redescription Model Mining, a novel approach to
identify interpretable patterns across two datasets that share only a subset of
attributes and have no common instances. In particular, Redescription Model
Mining aims to find pairs of describable data subsets -- one for each dataset
-- that induce similar exceptional models with respect to a prespecified model
class. To achieve this, we combine two previously separate research areas:
Exceptional Model Mining and Redescription Mining. For this new problem
setting, we develop interestingness measures to select promising patterns,
propose efficient algorithms, and demonstrate their potential on synthetic and
real-world data. Uncovered patterns can hint at common underlying phenomena
that manifest themselves across datasets, enabling the discovery of possible
associations between (combinations of) attributes that do not appear in the
same dataset.

    

### [[2107.04470] Adversarial Domain Adaptation with Self-Training for EEG-based Sleep Stage Classification](http://arxiv.org/abs/2107.04470)


  Sleep staging is of great importance in the diagnosis and treatment of sleep
disorders. Recently, numerous data driven deep learning models have been
proposed for automatic sleep staging. They mainly rely on the assumption that
training and testing data are drawn from the same distribution which may not
hold in real-world scenarios. Unsupervised domain adaption (UDA) has been
recently developed to handle this domain shift problem. However, previous UDA
methods applied for sleep staging has two main limitations. First, they rely on
a totally shared model for the domain alignment, which may lose the
domain-specific information during feature extraction. Second, they only align
the source and target distributions globally without considering the class
information in the target domain, which hinders the classification performance
of the model. In this work, we propose a novel adversarial learning framework
to tackle the domain shift problem in the unlabeled target domain. First, we
develop unshared attention mechanisms to preserve the domain-specific features
in the source and target domains. Second, we design a self-training strategy to
align the fine-grained class distributions for the source and target domains
via target domain pseudo labels. We also propose dual distinct classifiers to
increase the robustness and quality of the pseudo labels. The experimental
results on six cross-domain scenarios validate the efficacy of our proposed
framework for sleep staging and its advantage over state-of-the-art UDA
methods.

    

### [[2107.04479] Convergence analysis for gradient flows in the training of artificial neural networks with ReLU activation](http://arxiv.org/abs/2107.04479)


  Gradient descent (GD) type optimization schemes are the standard methods to
train artificial neural networks (ANNs) with rectified linear unit (ReLU)
activation. Such schemes can be considered as discretizations of gradient flows
(GFs) associated to the training of ANNs with ReLU activation and most of the
key difficulties in the mathematical convergence analysis of GD type
optimization schemes in the training of ANNs with ReLU activation seem to be
already present in the dynamics of the corresponding GF differential equations.
It is the key subject of this work to analyze such GF differential equations in
the training of ANNs with ReLU activation and three layers (one input layer,
one hidden layer, and one output layer). In particular, in this article we
prove in the case where the target function is possibly multi-dimensional and
continuous and in the case where the probability distribution of the input data
is absolutely continuous with respect to the Lebesgue measure that the risk of
every bounded GF trajectory converges to the risk of a critical point. In
addition, in this article we show in the case of a 1-dimensional affine linear
target function and in the case where the probability distribution of the input
data coincides with the standard uniform distribution that the risk of every
bounded GF trajectory converges to zero if the initial risk is sufficiently
small. Finally, in the special situation where there is only one neuron on the
hidden layer (1-dimensional hidden layer) we strengthen the above named result
for affine linear target functions by proving that that the risk of every (not
necessarily bounded) GF trajectory converges to zero if the initial risk is
sufficiently small.

    

### [[2107.04485] Adversarial Mixture Density Networks: Learning to Drive Safely from Collision Data](http://arxiv.org/abs/2107.04485)


  Imitation learning has been widely used to learn control policies for
autonomous driving based on pre-recorded data. However, imitation learning
based policies have been shown to be susceptible to compounding errors when
encountering states outside of the training distribution. Further, these agents
have been demonstrated to be easily exploitable by adversarial road users
aiming to create collisions. To overcome these shortcomings, we introduce
Adversarial Mixture Density Networks (AMDN), which learns two distributions
from separate datasets. The first is a distribution of safe actions learned
from a dataset of naturalistic human driving. The second is a distribution
representing unsafe actions likely to lead to collision, learned from a dataset
of collisions. During training, we leverage these two distributions to provide
an additional loss based on the similarity of the two distributions. By
penalising the safe action distribution based on its similarity to the unsafe
action distribution when training on the collision dataset, a more robust and
safe control policy is obtained. We demonstrate the proposed AMDN approach in a
vehicle following use-case, and evaluate under naturalistic and adversarial
testing environments. We show that despite its simplicity, AMDN provides
significant benefits for the safety of the learned control policy, when
compared to pure imitation learning or standard mixture density network
approaches.

    

### [[2107.04487] ARC: Adversarially Robust Control Policies for Autonomous Vehicles](http://arxiv.org/abs/2107.04487)


  Deep neural networks have demonstrated their capability to learn control
policies for a variety of tasks. However, these neural network-based policies
have been shown to be susceptible to exploitation by adversarial agents.
Therefore, there is a need to develop techniques to learn control policies that
are robust against adversaries. We introduce Adversarially Robust Control
(ARC), which trains the protagonist policy and the adversarial policy
end-to-end on the same loss. The aim of the protagonist is to maximise this
loss, whilst the adversary is attempting to minimise it. We demonstrate the
proposed ARC training in a highway driving scenario, where the protagonist
controls the follower vehicle whilst the adversary controls the lead vehicle.
By training the protagonist against an ensemble of adversaries, it learns a
significantly more robust control policy, which generalises to a variety of
adversarial strategies. The approach is shown to reduce the amount of
collisions against new adversaries by up to 90.25%, compared to the original
policy. Moreover, by utilising an auxiliary distillation loss, we show that the
fine-tuned control policy shows no drop in performance across its original
training distribution.

    

### [[2107.04491] Offline reinforcement learning with uncertainty for treatment strategies in sepsis](http://arxiv.org/abs/2107.04491)


  Guideline-based treatment for sepsis and septic shock is difficult because
sepsis is a disparate range of life-threatening organ dysfunctions whose
pathophysiology is not fully understood. Early intervention in sepsis is
crucial for patient outcome, yet those interventions have adverse effects and
are frequently overadministered. Greater personalization is necessary, as no
single action is suitable for all patients. We present a novel application of
reinforcement learning in which we identify optimal recommendations for sepsis
treatment from data, estimate their confidence level, and identify treatment
options infrequently observed in training data. Rather than a single
recommendation, our method can present several treatment options. We examine
learned policies and discover that reinforcement learning is biased against
aggressive intervention due to the confounding relationship between mortality
and level of treatment received. We mitigate this bias using subspace learning,
and develop methodology that can yield more accurate learning policies across
healthcare applications.

    

### [[2107.04497] Batch Inverse-Variance Weighting: Deep Heteroscedastic Regression](http://arxiv.org/abs/2107.04497)


  Heteroscedastic regression is the task of supervised learning where each
label is subject to noise from a different distribution. This noise can be
caused by the labelling process, and impacts negatively the performance of the
learning algorithm as it violates the i.i.d. assumptions. In many situations
however, the labelling process is able to estimate the variance of such
distribution for each label, which can be used as an additional information to
mitigate this impact. We adapt an inverse-variance weighted mean square error,
based on the Gauss-Markov theorem, for parameter optimization on neural
networks. We introduce Batch Inverse-Variance, a loss function which is robust
to near-ground truth samples, and allows to control the effective learning
rate. Our experimental results show that BIV improves significantly the
performance of the networks on two noisy datasets, compared to L2 loss,
inverse-variance weighting, as well as a filtering-based baseline.

    

### [[2107.04512] Using Machine Translation to Localize Task Oriented NLG Output](http://arxiv.org/abs/2107.04512)


  One of the challenges in a task oriented natural language application like
the Google Assistant, Siri, or Alexa is to localize the output to many
languages. This paper explores doing this by applying machine translation to
the English output. Using machine translation is very scalable, as it can work
with any English output and can handle dynamic text, but otherwise the problem
is a poor fit. The required quality bar is close to perfection, the range of
sentences is extremely narrow, and the sentences are often very different than
the ones in the machine translation training data. This combination of
requirements is novel in the field of domain adaptation for machine
translation. We are able to reach the required quality bar by building on
existing ideas and adding new ones: finetuning on in-domain translations,
adding sentences from the Web, adding semantic annotations, and using automatic
error detection. The paper shares our approach and results, together with a
distillation model to serve the translation models at scale.

    

### [[2107.04518] Optimal Gradient-based Algorithms for Non-concave Bandit Optimization](http://arxiv.org/abs/2107.04518)


  Bandit problems with linear or concave reward have been extensively studied,
but relatively few works have studied bandits with non-concave reward. This
work considers a large family of bandit problems where the unknown underlying
reward function is non-concave, including the low-rank generalized linear
bandit problems and two-layer neural network with polynomial activation bandit
problem. For the low-rank generalized linear bandit problem, we provide a
minimax-optimal algorithm in the dimension, refuting both conjectures in
[LMT21, JWWN19]. Our algorithms are based on a unified zeroth-order
optimization paradigm that applies in great generality and attains optimal
rates in several structured polynomial settings (in the dimension). We further
demonstrate the applicability of our algorithms in RL in the generative model
setting, resulting in improved sample complexity over prior approaches.
Finally, we show that the standard optimistic algorithms (e.g., UCB) are
sub-optimal by dimension factors. In the neural net setting (with polynomial
activation functions) with noiseless reward, we provide a bandit algorithm with
sample complexity equal to the intrinsic algebraic dimension. Again, we show
that optimistic approaches have worse sample complexity, polynomial in the
extrinsic dimension (which could be exponentially worse in the polynomial
degree).

    

### [[2107.04520] Online Adaptation to Label Distribution Shift](http://arxiv.org/abs/2107.04520)


  Machine learning models often encounter distribution shifts when deployed in
the real world. In this paper, we focus on adaptation to label distribution
shift in the online setting, where the test-time label distribution is
continually changing and the model must dynamically adapt to it without
observing the true label. Leveraging a novel analysis, we show that the lack of
true label does not hinder estimation of the expected test loss, which enables
the reduction of online label shift adaptation to conventional online learning.
Informed by this observation, we propose adaptation algorithms inspired by
classical online learning techniques such as Follow The Leader (FTL) and Online
Gradient Descent (OGD) and derive their regret bounds. We empirically verify
our findings under both simulated and real world label distribution shifts and
show that OGD is particularly effective and robust to a variety of challenging
label shift scenarios.

    

### [[2107.04522] Group-Node Attention for Community Evolution Prediction](http://arxiv.org/abs/2107.04522)


  Communities in social networks evolve over time as people enter and leave the
network and their activity behaviors shift. The task of predicting structural
changes in communities over time is known as community evolution prediction.
Existing work in this area has focused on the development of frameworks for
defining events while using traditional classification methods to perform the
actual prediction. We present a novel graph neural network for predicting
community evolution events from structural and temporal information. The model
(GNAN) includes a group-node attention component which enables support for
variable-sized inputs and learned representation of groups based on member and
neighbor node features. A comparative evaluation with standard baseline methods
is performed and we demonstrate that our model outperforms the baselines.
Additionally, we show the effects of network trends on model performance.

    

### [[2107.04527] BayesSimIG: Scalable Parameter Inference for Adaptive Domain Randomization with IsaacGym](http://arxiv.org/abs/2107.04527)


  BayesSim is a statistical technique for domain randomization in reinforcement
learning based on likelihood-free inference of simulation parameters. This
paper outlines BayesSimIG: a library that provides an implementation of
BayesSim integrated with the recently released NVIDIA IsaacGym. This
combination allows large-scale parameter inference with end-to-end GPU
acceleration. Both inference and simulation get GPU speedup, with support for
running more than 10K parallel simulation environments for complex robotics
tasks that can have more than 100 simulation parameters to estimate. BayesSimIG
provides an integration with TensorBoard to easily visualize slices of
high-dimensional posteriors. The library is built in a modular way to support
research experiments with novel ways to collect and process the trajectories
from the parallel IsaacGym environments.

    

### [[2107.04533] Behavior Self-Organization Supports Task Inference for Continual Robot Learning](http://arxiv.org/abs/2107.04533)


  Recent advances in robot learning have enabled robots to become increasingly
better at mastering a predefined set of tasks. On the other hand, as humans, we
have the ability to learn a growing set of tasks over our lifetime. Continual
robot learning is an emerging research direction with the goal of endowing
robots with this ability. In order to learn new tasks over time, the robot
first needs to infer the task at hand. Task inference, however, has received
little attention in the multi-task learning literature. In this paper, we
propose a novel approach to continual learning of robotic control tasks. Our
approach performs unsupervised learning of behavior embeddings by incrementally
self-organizing demonstrated behaviors. Task inference is made by finding the
nearest behavior embedding to a demonstrated behavior, which is used together
with the environment state as input to a multi-task policy trained with
reinforcement learning to optimize performance over tasks. Unlike previous
approaches, our approach makes no assumptions about task distribution and
requires no task exploration to infer tasks. We evaluate our approach in
experiments with concurrently and sequentially presented tasks and show that it
outperforms other multi-task learning approaches in terms of generalization
performance and convergence speed, particularly in the continual learning
setting.

    

### [[2107.04551] White-Box Cartoonization Using An Extended GAN Framework](http://arxiv.org/abs/2107.04551)


  In the present study, we propose to implement a new framework for estimating
generative models via an adversarial process to extend an existing GAN
framework and develop a white-box controllable image cartoonization, which can
generate high-quality cartooned images/videos from real-world photos and
videos. The learning purposes of our system are based on three distinct
representations: surface representation, structure representation, and texture
representation. The surface representation refers to the smooth surface of the
images. The structure representation relates to the sparse colour blocks and
compresses generic content. The texture representation shows the texture,
curves, and features in cartoon images. Generative Adversarial Network (GAN)
framework decomposes the images into different representations and learns from
them to generate cartoon images. This decomposition makes the framework more
controllable and flexible which allows users to make changes based on the
required output. This approach overcomes any previous system in terms of
maintaining clarity, colours, textures, shapes of images yet showing the
characteristics of cartoon images.

    

### [[2107.04556] Deep Learning for Reduced Order Modelling and Efficient Temporal Evolution of Fluid Simulations](http://arxiv.org/abs/2107.04556)


  Reduced Order Modelling (ROM) has been widely used to create lower order,
computationally inexpensive representations of higher-order dynamical systems.
Using these representations, ROMs can efficiently model flow fields while using
significantly lesser parameters. Conventional ROMs accomplish this by linearly
projecting higher-order manifolds to lower-dimensional space using
dimensionality reduction techniques such as Proper Orthogonal Decomposition
(POD). In this work, we develop a novel deep learning framework DL-ROM (Deep
Learning - Reduced Order Modelling) to create a neural network capable of
non-linear projections to reduced order states. We then use the learned reduced
state to efficiently predict future time steps of the simulation using 3D
Autoencoder and 3D U-Net based architectures. Our model DL-ROM is able to
create highly accurate reconstructions from the learned ROM and is thus able to
efficiently predict future time steps by temporally traversing in the learned
reduced state. All of this is achieved without ground truth supervision or
needing to iteratively solve the expensive Navier-Stokes(NS) equations thereby
resulting in massive computational savings. To test the effectiveness and
performance of our approach, we evaluate our implementation on five different
Computational Fluid Dynamics (CFD) datasets using reconstruction performance
and computational runtime metrics. DL-ROM can reduce the computational runtimes
of iterative solvers by nearly two orders of magnitude while maintaining an
acceptable error threshold.

    

### [[2107.04562] The Bayesian Learning Rule](http://arxiv.org/abs/2107.04562)


  We show that many machine-learning algorithms are specific instances of a
single algorithm called the Bayesian learning rule. The rule, derived from
Bayesian principles, yields a wide-range of algorithms from fields such as
optimization, deep learning, and graphical models. This includes classical
algorithms such as ridge regression, Newton's method, and Kalman filter, as
well as modern deep-learning algorithms such as stochastic-gradient descent,
RMSprop, and Dropout. The key idea in deriving such algorithms is to
approximate the posterior using candidate distributions estimated by using
natural gradients. Different candidate distributions result in different
algorithms and further approximations to natural gradients give rise to
variants of those algorithms. Our work not only unifies, generalizes, and
improves existing algorithms, but also helps us design new ones.

    

### [[2107.04565] Universal Multilayer Network Exploration by Random Walk with Restart](http://arxiv.org/abs/2107.04565)


  The amount and variety of data is increasing drastically for several years.
These data are often represented as networks, which are then explored with
approaches arising from network theory. Recent years have witnessed the
extension of network exploration methods to leverage more complex and richer
network frameworks. Random walks, for instance, have been extended to explore
multilayer networks. However, current random walk approaches are limited in the
combination and heterogeneity of network layers they can handle. New analytical
and numerical random walk methods are needed to cope with the increasing
diversity and complexity of multilayer networks. We propose here MultiXrank, a
Python package that enables Random Walk with Restart (RWR) on any kind of
multilayer network with an optimized implementation. This package is supported
by a universal mathematical formulation of the RWR. We evaluated MultiXrank
with leave-one-out cross-validation and link prediction, and introduced
protocols to measure the impact of the addition or removal of multilayer
network data on prediction performances. We further measured the sensitivity of
MultiXrank to input parameters by in-depth exploration of the parameter space.
Finally, we illustrate the versatility of MultiXrank with different use-cases
of unsupervised node prioritization and supervised classification in the
context of human genetic diseases.

    

### [[2107.04566] Multi-level Stress Assessment from ECG in a Virtual Reality Environment using Multimodal Fusion](http://arxiv.org/abs/2107.04566)


  ECG is an attractive option to assess stress in serious Virtual Reality (VR)
applications due to its non-invasive nature. However, the existing Machine
Learning (ML) models perform poorly. Moreover, existing studies only perform a
binary stress assessment, while to develop a more engaging biofeedback-based
application, multi-level assessment is necessary. Existing studies annotate and
classify a single experience (e.g. watching a VR video) to a single stress
level, which again prevents design of dynamic experiences where real-time
in-game stress assessment can be utilized. In this paper, we report our
findings on a new study on VR stress assessment, where three stress levels are
assessed. ECG data was collected from 9 users experiencing a VR roller coaster.
The VR experience was then manually labeled in 10-seconds segments to three
stress levels by three raters. We then propose a novel multimodal deep fusion
model utilizing spectrogram and 1D ECG that can provide a stress prediction
from just a 1-second window. Experimental results demonstrate that the proposed
model outperforms the classical HRV-based ML models (9% increase in accuracy)
and baseline deep learning models (2.5% increase in accuracy). We also report
results on the benchmark WESAD dataset to show the supremacy of the model.

    

### [[2107.04568] Deep Learning for Mean Field Games and Mean Field Control with Applications to Finance](http://arxiv.org/abs/2107.04568)


  Financial markets and more generally macro-economic models involve a large
number of individuals interacting through variables such as prices resulting
from the aggregate behavior of all the agents. Mean field games have been
introduced to study Nash equilibria for such problems in the limit when the
number of players is infinite. The theory has been extensively developed in the
past decade, using both analytical and probabilistic tools, and a wide range of
applications have been discovered, from economics to crowd motion. More
recently the interaction with machine learning has attracted a growing
interest. This aspect is particularly relevant to solve very large games with
complex structures, in high dimension or with common sources of randomness. In
this chapter, we review the literature on the interplay between mean field
games and deep learning, with a focus on three families of methods. A special
emphasis is given to financial applications.

    

### [[2107.04570] ANCER: Anisotropic Certification via Sample-wise Volume Maximization](http://arxiv.org/abs/2107.04570)


  Randomized smoothing has recently emerged as an effective tool that enables
certification of deep neural network classifiers at scale. All prior art on
randomized smoothing has focused on isotropic $\ell_p$ certification, which has
the advantage of yielding certificates that can be easily compared among
isotropic methods via $\ell_p$-norm radius. However, isotropic certification
limits the region that can be certified around an input to worst-case
adversaries, \ie it cannot reason about other "close", potentially large,
constant prediction safe regions. To alleviate this issue, (i) we theoretically
extend the isotropic randomized smoothing $\ell_1$ and $\ell_2$ certificates to
their generalized anisotropic counterparts following a simplified analysis.
Moreover, (ii) we propose evaluation metrics allowing for the comparison of
general certificates - a certificate is superior to another if it certifies a
superset region - with the quantification of each certificate through the
volume of the certified region. We introduce ANCER, a practical framework for
obtaining anisotropic certificates for a given test set sample via volume
maximization. Our empirical results demonstrate that ANCER achieves
state-of-the-art $\ell_1$ and $\ell_2$ certified accuracy on both CIFAR-10 and
ImageNet at multiple radii, while certifying substantially larger regions in
terms of volume, thus highlighting the benefits of moving away from isotropic
analysis. Code used in our experiments is available in
this https URL.

    

### [[2107.04575] Scopeformer: n-CNN-ViT Hybrid Model for Intracranial Hemorrhage Classification](http://arxiv.org/abs/2107.04575)


  We propose a feature generator backbone composed of an ensemble of
convolutional neuralnetworks (CNNs) to improve the recently emerging Vision
Transformer (ViT) models. We tackled the RSNA intracranial hemorrhage
classification problem, i.e., identifying various hemorrhage types from
computed tomography (CT) slices. We show that by gradually stacking several
feature maps extracted using multiple Xception CNNs, we can develop a
feature-rich input for the ViT model. Our approach allowed the ViT model to pay
attention to relevant features at multiple levels. Moreover, pretraining the n
CNNs using various paradigms leads to a diverse feature set and further
improves the performance of the proposed n-CNN-ViT. We achieved a test accuracy
of 98.04% with a weighted logarithmic loss value of 0.0708. The proposed
architecture is modular and scalable in both the number of CNNs used for
feature extraction and the size of the ViT.

    

### [[2107.04589] ViTGAN: Training GANs with Vision Transformers](http://arxiv.org/abs/2107.04589)


  Recently, Vision Transformers (ViTs) have shown competitive performance on
image recognition while requiring less vision-specific inductive biases. In
this paper, we investigate if such observation can be extended to image
generation. To this end, we integrate the ViT architecture into generative
adversarial networks (GANs). We observe that existing regularization methods
for GANs interact poorly with self-attention, causing serious instability
during training. To resolve this issue, we introduce novel regularization
techniques for training GANs with ViTs. Empirically, our approach, named
ViTGAN, achieves comparable performance to state-of-the-art CNN-based StyleGAN2
on CIFAR-10, CelebA, and LSUN bedroom datasets.

    

### [[1905.11425] Finite-Sample Analysis of Nonlinear Stochastic Approximation with Applications in Reinforcement Learning](http://arxiv.org/abs/1905.11425)


  Motivated by applications in reinforcement learning (RL), we study a
nonlinear stochastic approximation (SA) algorithm under Markovian noise, and
establish its finite-sample convergence bounds under various stepsizes.
Specifically, we show that when using constant stepsize (i.e.,
$\epsilon_k\equiv \epsilon$), the algorithm achieves exponential fast
convergence with asymptotic accuracy $\mathcal{O}(\epsilon\log(1/\epsilon))$.
When using diminishing stepsizes with appropriate decay rate, the algorithm
converges with rate $\mathcal{O}(\log(k)/k)$. Our proof is based on the
Lyapunov drift arguments, and to handle the Markovian noise, we exploit the
fast mixing of the underlying Markov chain. To demonstrate the generality of
our theoretical results on Markovian SA, we use it to derive the finite-sample
bounds of the popular $Q$-learning with linear function approximation
algorithm, under a condition on the behavior policy. Importantly, we do not
need to make the unrealistic assumption that the samples are i.i.d., and do not
require an additional projection step in the algorithm to maintain the
boundedness of the iterates. Numerical simulations corroborate our theoretical
findings.

    

### [[1906.10109] CMRNet: Camera to LiDAR-Map Registration](http://arxiv.org/abs/1906.10109)


  In this paper we present CMRNet, a realtime approach based on a Convolutional
Neural Network to localize an RGB image of a scene in a map built from LiDAR
data. Our network is not trained in the working area, i.e. CMRNet does not
learn the map. Instead it learns to match an image to the map. We validate our
approach on the KITTI dataset, processing each frame independently without any
tracking procedure. CMRNet achieves 0.27m and 1.07deg median localization
accuracy on the sequence 00 of the odometry dataset, starting from a rough pose
estimate displaced up to 3.5m and 17deg. To the best of our knowledge this is
the first CNN-based approach that learns to match images from a monocular
camera to a given, preexisting 3D LiDAR-map.

    

### [[1911.09925] Gemmini: Enabling Systematic Deep-Learning Architecture Evaluation via Full-Stack Integration](http://arxiv.org/abs/1911.09925)


  DNN accelerators are often developed and evaluated in isolation without
considering the cross-stack, system-level effects in real-world environments.
This makes it difficult to appreciate the impact of System-on-Chip (SoC)
resource contention, OS overheads, and programming-stack inefficiencies on
overall performance/energy-efficiency. To address this challenge, we present
Gemmini, an open-source*, full-stack DNN accelerator generator. Gemmini
generates a wide design-space of efficient ASIC accelerators from a flexible
architectural template, together with flexible programming stacks and full SoCs
with shared resources that capture system-level effects. Gemmini-generated
accelerators have also been fabricated, delivering up to three
orders-of-magnitude speedups over high-performance CPUs on various DNN
benchmarks.
* this https URL


### [[2001.08826] An $O(s^r)$-Resolution ODE Framework for Understanding Discrete-Time Algorithms and Applications to the Linear Convergence of Minimax Problems](http://arxiv.org/abs/2001.08826)


  There has been a long history of using ordinary differential equations (ODEs)
to understand the dynamics of discrete-time algorithms (DTAs). Surprisingly,
there are still two fundamental and unanswered questions: (i) it is unclear how
to obtain a \emph{suitable} ODE from a given DTA, and (ii) it is unclear the
connection between the convergence of a DTA and its corresponding ODEs. In this
paper, we propose a new machinery -- an $O(s^r)$-resolution ODE framework --
for analyzing the behavior of a generic DTA, which (partially) answers the
above two questions. The framework contains three steps: 1. To obtain a
suitable ODE from a given DTA, we define a hierarchy of $O(s^r)$-resolution
ODEs of a DTA parameterized by the degree $r$, where $s$ is the step-size of
the DTA. We present a principal approach to construct the unique
$O(s^r)$-resolution ODEs from a DTA; 2. To analyze the resulting ODE, we
propose the $O(s^r)$-linear-convergence condition of a DTA with respect to an
energy function, under which the $O(s^r)$-resolution ODE converges linearly to
an optimal solution; 3. To bridge the convergence properties of a DTA and its
corresponding ODEs, we define the properness of an energy function and show
that the linear convergence of the $O(s^r)$-resolution ODE with respect to a
proper energy function can automatically guarantee the linear convergence of
the DTA. To better illustrate this machinery, we utilize it to study three
classic algorithms -- gradient descent ascent (GDA), proximal point method
(PPM) and extra-gradient method (EGM) -- for solving the unconstrained minimax
problem $\min_{x\in\RR^n} \max_{y\in \RR^m} L(x,y)$.

    

### [[2002.02881] Low Rank Saddle Free Newton: Scalable Stochastic Nonconvex Optimization](http://arxiv.org/abs/2002.02881)


  Newton methods have fallen out of favor for modern optimization problems
(e.g. deep learning) because of concerns about per-iteration computational
complexity. In this setting highly subsampled first order methods are
preferred. In this work we motivate the extension of Newton methods to the
highly stochastic regime, and argue for the use of the scalable low rank saddle
free Newton (LRSFN) method. In this setting, iterative updates are dominated by
stochastic noise, and stability of the method is key. In stability analysis, we
demonstrate that stochastic errors for Newton methods can be greatly amplified
by ill-conditioned matrix operators. The LRSFN algorithm mitigates this issue
by the use of Levenberg-Marquardt damping, but generally second order methods
with stochastic Hessian and gradient information may need to take small steps,
unlike in deterministic problems. Numerical results show that even under
restrictive step-length conditions, LRSFN can outperform popular first order
methods on nontrivial deep learning tasks in terms of generalizability for
equivalent computational work.

    

### [[2004.13747] Quantum-inspired Machine Learning on high-energy physics data](http://arxiv.org/abs/2004.13747)


  Tensor Networks, a numerical tool originally designed for simulating quantum
many-body systems, have recently been applied to solve Machine Learning
problems. Exploiting a tree tensor network, we apply a quantum-inspired machine
learning technique to a very important and challenging big data problem in high
energy physics: the analysis and classification of data produced by the Large
Hadron Collider at CERN. In particular, we present how to effectively classify
so-called b-jets, jets originating from b-quarks from proton-proton collisions
in the LHCb experiment, and how to interpret the classification results. We
exploit the Tensor Network approach to select important features and adapt the
network geometry based on information acquired in the learning process.
Finally, we show how to adapt the tree tensor network to achieve optimal
precision or fast response in time without the need of repeating the learning
process. These results pave the way to the implementation of high-frequency
real-time applications, a key ingredient needed among others for current and
future LHCb event classification able to trigger events at the tens of MHz
scale.

    

### [[2006.02745] Asymptotic Optimality of Conditioned Stochastic Gradient Descent](http://arxiv.org/abs/2006.02745)


  In this paper, we investigate a general class of stochastic gradient descent
(SGD) algorithms, called conditioned SGD, based on a preconditioning of the
gradient direction. Under some mild assumptions, namely the $L$-smoothness of
the non-convex objective function and some weak growth condition on the noise,
we establish the almost sure convergence and the asymptotic normality for a
broad class of conditioning matrices. In particular, when the conditioning
matrix is an estimate of the inverse Hessian at the optimal point, the
algorithm is proved to be asymptotically optimal. The benefits of this approach
are validated on simulated and real datasets.

    

### [[2006.05975] When is Particle Filtering Efficient for Planning in Partially Observed Linear Dynamical Systems?](http://arxiv.org/abs/2006.05975)


  Particle filtering is a popular method for inferring latent states in
stochastic dynamical systems, whose theoretical properties have been well
studied in machine learning and statistics communities. In many control
problems, e.g., partially observed linear dynamical systems (POLDS), oftentimes
the inferred latent state is further used for planning at each step. This paper
initiates a rigorous study on the efficiency of particle filtering for
sequential planning, and gives the first particle complexity bounds. Though
errors in past actions may affect the future, we are able to bound the number
of particles needed so that the long-run reward of the policy based on particle
filtering is close to that based on exact inference. In particular, we show
that, in stable systems, polynomially many particles suffice. Key in our proof
is a coupling of the ideal sequence based on the exact planning and the
sequence generated by approximate planning based on particle filtering. We
believe this technique can be useful in other sequential decision-making
problems.

    

### [[2006.11385] Quantile-Quantile Embedding for Distribution Transformation and Manifold Embedding with Ability to Choose the Embedding Distribution](http://arxiv.org/abs/2006.11385)


  We propose a new embedding method, named Quantile-Quantile Embedding (QQE),
for distribution transformation and manifold embedding with the ability to
choose the embedding distribution. QQE, which uses the concept of
quantile-quantile plot from visual statistical tests, can transform the
distribution of data to any theoretical desired distribution or empirical
reference sample. Moreover, QQE gives the user a choice of embedding
distribution in embedding the manifold of data into the low dimensional
embedding space. It can also be used for modifying the embedding distribution
of other dimensionality reduction methods, such as PCA, t-SNE, and deep metric
learning, for better representation or visualization of data. We propose QQE in
both unsupervised and supervised forms. QQE can also transform a distribution
to either an exact reference distribution or its shape. We show that QQE allows
for better discrimination of classes in some cases. Our experiments on
different synthetic and image datasets show the effectiveness of the proposed
embedding method.

    

### [[2006.14512] Uncovering the Connections Between Adversarial Transferability and Knowledge Transferability](http://arxiv.org/abs/2006.14512)


  Knowledge transferability, or transfer learning, has been widely adopted to
allow a pre-trained model in the source domain to be effectively adapted to
downstream tasks in the target domain. It is thus important to explore and
understand the factors affecting knowledge transferability. In this paper, as
the first work, we analyze and demonstrate the connections between knowledge
transferability and another important phenomenon--adversarial transferability,
\emph{i.e.}, adversarial examples generated against one model can be
transferred to attack other models. Our theoretical studies show that
adversarial transferability indicates knowledge transferability and vice versa.
Moreover, based on the theoretical insights, we propose two practical
adversarial transferability metrics to characterize this process, serving as
bidirectional indicators between adversarial and knowledge transferability. We
conduct extensive experiments for different scenarios on diverse datasets,
showing a positive correlation between adversarial transferability and
knowledge transferability. Our findings will shed light on future research
about effective knowledge transfer learning and adversarial transferability
analyses.

    

### [[2007.09327] Towards Quantum-Secure Authentication and Key Agreement via Abstract Multi-Agent Interaction](http://arxiv.org/abs/2007.09327)


  Current methods for authentication and key agreement based on public-key
cryptography are vulnerable to quantum computing. We propose a novel approach
based on artificial intelligence research in which communicating parties are
viewed as autonomous agents which interact repeatedly using their private
decision models. Authentication and key agreement are decided based on the
agents' observed behaviors during the interaction. The security of this
approach rests upon the difficulty of modeling the decisions of interacting
agents from limited observations, a problem which we conjecture is also hard
for quantum computing. We release PyAMI, a prototype authentication and key
agreement system based on the proposed method. We empirically validate our
method for authenticating legitimate users while detecting different types of
adversarial attacks. Finally, we show how reinforcement learning techniques can
be used to train server models which effectively probe a client's decisions to
achieve more sample-efficient authentication.

    

### [[2008.11825] SHAP values for Explaining CNN-based Text Classification Models](http://arxiv.org/abs/2008.11825)


  Deep neural networks are increasingly used in natural language processing
(NLP) models. However, the need to interpret and explain the results from
complex algorithms are limiting their widespread adoption in regulated
industries such as banking. There has been recent work on interpretability of
machine learning algorithms with structured data. But there are only limited
techniques for NLP applications where the problem is more challenging due to
the size of the vocabulary, high-dimensional nature, and the need to consider
textual coherence and language structure. This paper develops a methodology to
compute SHAP values for local explainability of CNN-based text classification
models. The approach is also extended to compute global scores to assess the
importance of features. The results are illustrated on sentiment analysis of
Amazon Electronic Review data.

    

### [[2009.00909] A Survey on Negative Transfer](http://arxiv.org/abs/2009.00909)


  Transfer learning (TL) tries to utilize data or knowledge from one or more
source domains to facilitate the learning in a target domain. It is
particularly useful when the target domain has few or no labeled data, due to
annotation expense, privacy concerns, etc. Unfortunately, the effectiveness of
TL is not always guaranteed. Negative transfer (NT), i.e., the source domain
data/knowledge cause reduced learning performance in the target domain, has
been a long-standing and challenging problem in TL. Various approaches to
handle NT have been proposed in the literature. However, this filed lacks a
systematic survey on the formalization of NT, their factors and the algorithms
that handle NT. This paper proposes to fill this gap. First, the definition of
negative transfer is considered and a taxonomy of the factors are discussed.
Then, near fifty representative approaches for handling NT are categorized and
reviewed, from four perspectives: secure transfer, domain similarity
estimation, distant transfer and negative transfer mitigation. NT in related
fields, e.g., multi-task learning, lifelong learning, and adversarial attacks
are also discussed.

    

### [[2010.04905] Accelerating Finite-temperature Kohn-Sham Density Functional Theory with Deep Neural Networks](http://arxiv.org/abs/2010.04905)


  We present a numerical modeling workflow based on machine learning (ML) which
reproduces the the total energies produced by Kohn-Sham density functional
theory (DFT) at finite electronic temperature to within chemical accuracy at
negligible computational cost. Based on deep neural networks, our workflow
yields the local density of states (LDOS) for a given atomic configuration.
From the LDOS, spatially-resolved, energy-resolved, and integrated quantities
can be calculated, including the DFT total free energy, which serves as the
Born-Oppenheimer potential energy surface for the atoms. We demonstrate the
efficacy of this approach for both solid and liquid metals and compare results
between independent and unified machine-learning models for solid and liquid
aluminum. Our machine-learning density functional theory framework opens up the
path towards multiscale materials modeling for matter under ambient and extreme
conditions at a computational scale and cost that is unattainable with current
algorithms.

    

### [[2010.05313] Controlling Graph Dynamics with Reinforcement Learning and Graph Neural Networks](http://arxiv.org/abs/2010.05313)


  We consider the problem of controlling a partially-observed dynamic process
on a graph by a limited number of interventions. This problem naturally arises
in contexts such as scheduling virus tests to curb an epidemic; targeted
marketing in order to promote a product; and manually inspecting posts to
detect fake news spreading on social networks.
We formulate this setup as a sequential decision problem over a temporal
graph process. In face of an exponential state space, combinatorial action
space and partial observability, we design a novel tractable scheme to control
dynamical processes on temporal graphs. We successfully apply our approach to
two popular problems that fall into our framework: prioritizing which nodes
should be tested in order to curb the spread of an epidemic, and influence
maximization on a graph.

    

### [[2011.10124] The Best of Many Worlds: Dual Mirror Descent for Online Allocation Problems](http://arxiv.org/abs/2011.10124)


  Online allocation problems with resource constraints are central problems in
revenue management and online advertising. In these problems, requests arrive
sequentially during a finite horizon and, for each request, a decision maker
needs to choose an action that consumes a certain amount of resources and
generates reward. The objective is to maximize cumulative rewards subject to a
constraint on the total consumption of resources. In this paper, we consider a
data-driven setting in which the reward and resource consumption of each
request are generated using an input model that is unknown to the decision
maker.
We design a general class of algorithms that attain good performance in
various inputs models without knowing which type of input they are facing. In
particular, our algorithms are asymptotically optimal under stochastic i.i.d.
input model as well as various non-stationary stochastic input models, and they
attain an asymptotically optimal fixed competitive ratio when the input is
adversarial. Our algorithms operate in the Lagrangian dual space: they maintain
a dual multiplier for each resource that is updated using online mirror
descent. By choosing the reference function accordingly, we recover dual
sub-gradient descent and dual exponential weights algorithm. The resulting
algorithms are simple, fast, and have minimal requirements on the reward
functions, consumption functions and the action space, in contrast to existing
methods for online allocation problems. We discuss applications to network
revenue management, online bidding in repeated auctions with budget
constraints, online proportional matching with high entropy, and personalized
assortment optimization with limited inventories.

    

### [[2012.12325] Drug-Target Interaction Prediction via an Ensemble of Weighted Nearest Neighbors with Interaction Recovery](http://arxiv.org/abs/2012.12325)


  Predicting drug-target interactions (DTI) via reliable computational methods
is an effective and efficient way to mitigate the enormous costs and time of
the drug discovery process. Structure-based drug similarities and
sequence-based target protein similarities are the commonly used information
for DTI prediction. Among numerous computational methods, neighborhood-based
chemogenomic approaches that leverage drug and target similarities to perform
predictions directly are simple but promising ones. However, existing
similarity-based methods need to be re-trained to predict interactions for any
new drugs or targets and cannot directly perform predictions for both new
drugs, new targets, and new drug-target pairs. Furthermore, a large amount of
missing (undetected) interactions in current DTI datasets hinders most DTI
prediction methods. To address these issues, we propose a new method denoted as
Weighted k-Nearest Neighbor with Interaction Recovery (WkNNIR). Not only can
WkNNIR estimate interactions of any new drugs and/or new targets without any
need of re-training, but it can also recover missing interactions (false
negatives). In addition, WkNNIR exploits local imbalance to promote the
influence of more reliable similarities on the interaction recovery and
prediction processes. We also propose a series of ensemble methods that employ
diverse sampling strategies and could be coupled with WkNNIR as well as any
other DTI prediction method to improve performance. Experimental results over
five benchmark datasets demonstrate the effectiveness of our approaches in
predicting drug-target interactions. Lastly, we confirm the practical
prediction ability of proposed methods to discover reliable interactions that
were not reported in the original benchmark datasets.

    

### [[2102.02049] On Query-efficient Planning in MDPs under Linear Realizability of the Optimal State-value Function](http://arxiv.org/abs/2102.02049)


  We consider local planning in fixed-horizon MDPs with a generative model
under the assumption that the optimal value function lies close to the span of
a feature map. The generative model provides a local access to the MDP: The
planner can ask for random transitions from previously returned states and
arbitrary actions, and features are only accessible for states that are
encountered in this process. As opposed to previous work (e.g. Lattimore et al.
(2020)) where linear realizability of all policies was assumed, we consider the
significantly relaxed assumption of a single linearly realizable
(deterministic) policy. A recent lower bound by Weisz et al. (2020) established
that the related problem when the action-value function of the optimal policy
is linearly realizable requires an exponential number of queries, either in $H$
(the horizon of the MDP) or $d$ (the dimension of the feature mapping). Their
construction crucially relies on having an exponentially large action set. In
contrast, in this work, we establish that poly$(H,d)$ planning is possible with
state value function realizability whenever the action set has a constant size.
In particular, we present the TensorPlan algorithm which uses
poly$((dH/\delta)^A)$ simulator queries to find a $\delta$-optimal policy
relative to any deterministic policy for which the value function is linearly
realizable with some bounded parameter. This is the first algorithm to give a
polynomial query complexity guarantee using only linear-realizability of a
single competing value function. Whether the computation cost is similarly
bounded remains an open question. We extend the upper bound to the
near-realizable case and to the infinite-horizon discounted setup. We also
present a lower bound in the infinite-horizon episodic setting: Planners that
achieve constant suboptimality need exponentially many queries, either in $d$
or the number of actions.

    

### [[2102.02810] Controlling Hallucinations at Word Level in Data-to-Text Generation](http://arxiv.org/abs/2102.02810)


  Data-to-Text Generation (DTG) is a subfield of Natural Language Generation
aiming at transcribing structured data in natural language descriptions. The
field has been recently boosted by the use of neural-based generators which
exhibit on one side great syntactic skills without the need of hand-crafted
pipelines; on the other side, the quality of the generated text reflects the
quality of the training data, which in realistic settings only offer
imperfectly aligned structure-text pairs. Consequently, state-of-art neural
models include misleading statements - usually called hallucinations - in their
outputs. The control of this phenomenon is today a major challenge for DTG, and
is the problem addressed in the paper.
Previous work deal with this issue at the instance level: using an alignment
score for each table-reference pair. In contrast, we propose a finer-grained
approach, arguing that hallucinations should rather be treated at the word
level. Specifically, we propose a Multi-Branch Decoder which is able to
leverage word-level labels to learn the relevant parts of each training
instance. These labels are obtained following a simple and efficient scoring
procedure based on co-occurrence analysis and dependency parsing. Extensive
evaluations, via automated metrics and human judgment on the standard WikiBio
benchmark, show the accuracy of our alignment labels and the effectiveness of
the proposed Multi-Branch Decoder. Our model is able to reduce and control
hallucinations, while keeping fluency and coherence in generated texts. Further
experiments on a degraded version of ToTTo show that our model could be
successfully used on very noisy settings.

    

### [[2102.03957] Extracting the Auditory Attention in a Dual-Speaker Scenario from EEG using a Joint CNN-LSTM Model](http://arxiv.org/abs/2102.03957)


  Human brain performs remarkably well in segregating a particular speaker from
interfering ones in a multi-speaker scenario. It has been recently shown that
we can quantitatively evaluate the segregation capability by modelling the
relationship between the speech signals present in an auditory scene and the
cortical signals of the listener measured using electroencephalography (EEG).
This has opened up avenues to integrate neuro-feedback into hearing aids
whereby the device can infer user's attention and enhance the attended speaker.
Commonly used algorithms to infer the auditory attention are based on linear
systems theory where the speech cues such as envelopes are mapped on to the EEG
signals. Here, we present a joint convolutional neural network (CNN) - long
short-term memory (LSTM) model to infer the auditory attention. Our joint
CNN-LSTM model takes the EEG signals and the spectrogram of the multiple
speakers as inputs and classifies the attention to one of the speakers. We
evaluated the reliability of our neural network using three different datasets
comprising of 61 subjects where, each subject undertook a dual-speaker
experiment. The three datasets analysed corresponded to speech stimuli
presented in three different languages namely German, Danish and Dutch. Using
the proposed joint CNN-LSTM model, we obtained a median decoding accuracy of
77.2% at a trial duration of three seconds. Furthermore, we evaluated the
amount of sparsity that our model can tolerate by means of magnitude pruning
and found that the model can tolerate up to 50% sparsity without substantial
loss of decoding accuracy.

    

### [[2102.07143] Manifold Density Estimation via Generalized Dequantization](http://arxiv.org/abs/2102.07143)


  Density estimation is an important technique for characterizing distributions
given observations. Much existing research on density estimation has focused on
cases wherein the data lies in a Euclidean space. However, some kinds of data
are not well-modeled by supposing that their underlying geometry is Euclidean.
Instead, it can be useful to model such data as lying on a {\it manifold} with
some known structure. For instance, some kinds of data may be known to lie on
the surface of a sphere. We study the problem of estimating densities on
manifolds. We propose a method, inspired by the literature on "dequantization,"
which we interpret through the lens of a coordinate transformation of an
ambient Euclidean space and a smooth manifold of interest. Using methods from
normalizing flows, we apply this method to the dequantization of smooth
manifold structures in order to model densities on the sphere, tori, and the
orthogonal group.

    

### [[2102.07501] Annealed Flow Transport Monte Carlo](http://arxiv.org/abs/2102.07501)


  Annealed Importance Sampling (AIS) and its Sequential Monte Carlo (SMC)
extensions are state-of-the-art methods for estimating normalizing constants of
probability distributions. We propose here a novel Monte Carlo algorithm,
Annealed Flow Transport (AFT), that builds upon AIS and SMC and combines them
with normalizing flows (NFs) for improved performance. This method transports a
set of particles using not only importance sampling (IS), Markov chain Monte
Carlo (MCMC) and resampling steps - as in SMC, but also relies on NFs which are
learned sequentially to push particles towards the successive annealed targets.
We provide limit theorems for the resulting Monte Carlo estimates of the
normalizing constant and expectations with respect to the target distribution.
Additionally, we show that a continuous-time scaling limit of the population
version of AFT is given by a Feynman--Kac measure which simplifies to the law
of a controlled diffusion for expressive NFs. We demonstrate experimentally the
benefits and limitations of our methodology on a variety of applications.

    

### [[2102.08540] Intuitively Assessing ML Model Reliability through Example-Based Explanations and Editing Model Inputs](http://arxiv.org/abs/2102.08540)


  Interpretability methods aim to help users build trust in and understand the
capabilities of machine learning models. However, existing approaches often
rely on abstract, complex visualizations that poorly map to the task at hand or
require non-trivial ML expertise to interpret. Here, we present two visual
analytics modules that facilitate an intuitive assessment of model reliability.
To help users better characterize and reason about a model's uncertainty, we
visualize raw and aggregate information about a given input's nearest
neighbors. Using an interactive editor, users can manipulate this input in
semantically-meaningful ways, determine the effect on the output, and compare
against their prior expectations. We evaluate our interface using an
electrocardiogram beat classification case study. Compared to a baseline
feature importance interface, we find that 14 physicians are better able to
align the model's uncertainty with domain-relevant factors and build intuition
about its capabilities and limitations.

    

### [[2103.03541] Multilingual Byte2Speech Models for Scalable Low-resource Speech Synthesis](http://arxiv.org/abs/2103.03541)


  To scale neural speech synthesis to various real-world languages, we present
a multilingual end-to-end framework that maps byte inputs to spectrograms, thus
allowing arbitrary input scripts. Besides strong results on 40+ languages, the
framework demonstrates capabilities to adapt to new languages under extreme
low-resource and even few-shot scenarios of merely 40s transcribed recording,
without the need of per-language resources like lexicon, extra corpus,
auxiliary models, or linguistic expertise, thus ensuring scalability. While it
retains satisfactory intelligibility and naturalness matching rich-resource
models. Exhaustive comparative and ablation studies are performed to reveal the
potential of the framework for low-resource languages. Furthermore, we propose
a novel method to extract language-specific sub-networks in a multilingual
model for a better understanding of its mechanism.

    

### [[2103.03635] Autocalibration and Tweedie-dominance for Insurance Pricing with Machine Learning](http://arxiv.org/abs/2103.03635)


  Boosting techniques and neural networks are particularly effective machine
learning methods for insurance pricing. Often in practice, there are
nevertheless endless debates about the choice of the right loss function to be
used to train the machine learning model, as well as about the appropriate
metric to assess the performances of competing models. Also, the sum of fitted
values can depart from the observed totals to a large extent and this often
confuses actuarial analysts. The lack of balance inherent to training models by
minimizing deviance outside the familiar GLM with canonical link setting has
been empirically documented in Wüthrich (2019, 2020) who attributes it to the
early stopping rule in gradient descent methods for model fitting. The present
paper aims to further study this phenomenon when learning proceeds by
minimizing Tweedie deviance. It is shown that minimizing deviance involves a
trade-off between the integral of weighted differences of lower partial moments
and the bias measured on a specific scale. Autocalibration is then proposed as
a remedy. This new method to correct for bias adds an extra local GLM step to
the analysis. Theoretically, it is shown that it implements the autocalibration
concept in pure premium calculation and ensures that balance also holds on a
local scale, not only at portfolio level as with existing bias-correction
techniques. The convex order appears to be the natural tool to compare
competing models, putting a new light on the diagnostic graphs and associated
metrics proposed by Denuit et al. (2019).

    

### [[2103.03664] ASC-Net : Adversarial-based Selective Network for Unsupervised Anomaly Segmentation](http://arxiv.org/abs/2103.03664)


  We introduce a neural network framework, utilizing adversarial learning to
partition an image into two cuts, with one cut falling into a reference
distribution provided by the user. This concept tackles the task of
unsupervised anomaly segmentation, which has attracted increasing attention in
recent years due to their broad applications in tasks with unlabelled data.
This Adversarial-based Selective Cutting network (ASC-Net) bridges the two
domains of cluster-based deep learning methods and adversarial-based
anomaly/novelty detection algorithms. We evaluate this unsupervised learning
model on BraTS brain tumor segmentation, LiTS liver lesion segmentation, and
MS-SEG2015 segmentation tasks. Compared to existing methods like the AnoGAN
family, our model demonstrates tremendous performance gains in unsupervised
anomaly segmentation tasks. Although there is still room to further improve
performance compared to supervised learning algorithms, the promising
experimental results shed light on building an unsupervised learning algorithm
using user-defined knowledge.

    

### [[2103.08494] BrainNetGAN: Data augmentation of brain connectivity using generative adversarial network for dementia classification](http://arxiv.org/abs/2103.08494)


  Alzheimer's disease (AD) is the most common age-related dementia. It remains
a challenge to identify the individuals at risk of dementia for precise
management. Brain MRI offers a noninvasive biomarker to detect brain aging.
Previous evidence shows that the brain structural change detected by diffusion
MRI is associated with dementia. Mounting studies has conceptualised the brain
as a complex network, which has shown the utility of this approach in
characterising various neurological and psychiatric disorders. Therefore, the
structural connectivity shows promise in dementia classification. The proposed
BrainNetGAN is a generative adversarial network variant to augment the brain
structural connectivity matrices for binary dementia classification tasks.
Structural connectivity matrices between separated brain regions are
constructed using tractography on diffusion MRI data. The BrainNetGAN model is
trained to generate fake brain connectivity matrices, which are expected to
reflect latent distribution of the real brain network data. Finally, a
convolutional neural network classifier is proposed for binary dementia
classification. Numerical results show that the binary classification
performance in the testing set was improved using the BrainNetGAN augmented
dataset. The proposed methodology allows quick synthesis of an arbitrary number
of augmented connectivity matrices and can be easily transferred to similar
classification tasks.

    

### [[2103.15138] Graph Convolutional Networks for Model-Based Learning in Nonlinear Inverse Problems](http://arxiv.org/abs/2103.15138)


  The majority of model-based learned image reconstruction methods in medical
imaging have been limited to uniform domains, such as pixelated images. If the
underlying model is solved on nonuniform meshes, arising from a finite element
method typical for nonlinear inverse problems, interpolation and embeddings are
needed. To overcome this, we present a flexible framework to extend model-based
learning directly to nonuniform meshes, by interpreting the mesh as a graph and
formulating our network architectures using graph convolutional neural
networks. This gives rise to the proposed iterative Graph Convolutional
Newton-type Method (GCNM), which includes the forward model in the solution of
the inverse problem, while all updates are directly computed by the network on
the problem specific mesh. We present results for Electrical Impedance
Tomography, a severely ill-posed nonlinear inverse problem that is frequently
solved via optimization-based methods, where the forward problem is solved by
finite element methods. Results for absolute EIT imaging are compared to
standard iterative methods as well as a graph residual network. We show that
the GCNM has strong generalizability to different domain shapes and meshes, out
of distribution data as well as experimental data, from purely simulated
training data and without transfer training.

    

### [[2104.04731] Joint Program and Layout Transformations to enable DNN Operators on Specialized Hardware based on Constraint Programming](http://arxiv.org/abs/2104.04731)


  The success of Deep Artificial Neural Networks (DNNs) in many domains created
a rich body of research concerned with hardwareaccelerators for
compute-intensive DNN operators. However, implementing such operators
efficiently with complex hardwareintrinsics such as matrix multiply is a task
not yet automated gracefully. Solving this task often requires joint program
and data layouttransformations. First solutions to this problem have been
proposed, such as TVM, UNIT or ISAMIR, which work on a loop-levelrepresentation
of operators and specify data layout and possible program transformations
before the embedding into the operator isperformed. This top-down approach
creates a tension between exploration range and search space complexity,
especially when alsoexploring data layout transformations such as im2col,
channel packing or this http URL this work, we propose a new approach to this
problem. We created a bottom-up method that allows the joint transformation
ofboth compuation and data layout based on the found embedding. By formulating
the embedding as a constraint satisfaction problemover the scalar dataflow,
every possible embedding solution is contained in the search space. Adding
additional constraints andoptmization targets to the solver generates the
subset of preferable this http URL evaluation using the VTA hardware accelerator
with the Baidu DeepBench inference benchmark shows that our approach
canautomatically generate code competitive to reference implementations.
Further, we show that dynamically determining the data layoutbased on intrinsic
and workload is beneficial for hardware utilization and performance. In cases
where the reference implementationhas low hardware utilization due to its fixed
deployment strategy, we achieve a geomean speedup of up to x2.813, while
individualoperators can improve as much as x170.

    

### [[2104.05600] PAC Bayesian Performance Guarantees for Deep (Stochastic) Networks in Medical Imaging](http://arxiv.org/abs/2104.05600)


  Application of deep neural networks to medical imaging tasks has in some
sense become commonplace. Still, a "thorn in the side" of the deep learning
movement is the argument that deep networks are prone to overfitting and are
thus unable to generalize well when datasets are small (as is common in medical
imaging tasks). One way to bolster confidence is to provide mathematical
guarantees, or bounds, on network performance after training which explicitly
quantify the possibility of overfitting. In this work, we explore recent
advances using the PAC-Bayesian framework to provide bounds on generalization
error for large (stochastic) networks. While previous efforts focus on
classification in larger natural image datasets (e.g., MNIST and CIFAR-10), we
apply these techniques to both classification and segmentation in a smaller
medical imagining dataset: the ISIC 2018 challenge set. We observe the
resultant bounds are competitive compared to a simpler baseline, while also
being more explainable and alleviating the need for holdout sets.

    

### [[2104.09872] Robust Sensor Fusion Algorithms Against Voice Command Attacks in Autonomous Vehicles](http://arxiv.org/abs/2104.09872)


  With recent advances in autonomous driving, Voice Control Systems have become
increasingly adopted as human-vehicle interaction methods. This technology
enables drivers to use voice commands to control the vehicle and will be soon
available in Advanced Driver Assistance Systems (ADAS). Prior work has shown
that Siri, Alexa and Cortana, are highly vulnerable to inaudible command
attacks. This could be extended to ADAS in real-world applications and such
inaudible command threat is difficult to detect due to microphone
nonlinearities. In this paper, we aim to develop a more practical solution by
using camera views to defend against inaudible command attacks where ADAS are
capable of detecting their environment via multi-sensors. To this end, we
propose a novel multimodal deep learning classification system to defend
against inaudible command attacks. Our experimental results confirm the
feasibility of the proposed defense methods and the best classification
accuracy reaches 89.2%. Code is available at
this https URL.

    

### [[2104.14297] End-to-End Speech Recognition from Federated Acoustic Models](http://arxiv.org/abs/2104.14297)


  Training Automatic Speech Recognition (ASR) models under federated learning
(FL) settings has attracted a lot of attention recently. However, the FL
scenarios often presented in the literature are artificial and fail to capture
the complexity of real FL systems. In this paper, we construct a challenging
and realistic ASR federated experimental setup consisting of clients with
heterogeneous data distributions using the French and Italian sets of the
CommonVoice dataset, a large heterogeneous dataset containing thousands of
different speakers, acoustic environments and noises. We present the first
empirical study on attention-based sequence-to-sequence End-to-End (E2E) ASR
model with three aggregation weighting strategies -- standard FedAvg,
loss-based aggregation and a novel word error rate (WER)-based aggregation,
compared in two realistic FL scenarios: cross-silo with 10 clients and
cross-device with 2K and 4K clients. Our analysis on E2E ASR from heterogeneous
and realistic federated acoustic models provides the foundations for future
research and development of realistic FL-based ASR applications.

    

### [[2105.12195] Bias in Machine Learning Software: Why? How? What to do?](http://arxiv.org/abs/2105.12195)


  Increasingly, software is making autonomous decisions in case of criminal
sentencing, approving credit cards, hiring employees, and so on. Some of these
decisions show bias and adversely affect certain social groups (e.g. those
defined by sex, race, age, marital status). Many prior works on bias mitigation
take the following form: change the data or learners in multiple ways, then see
if any of that improves fairness. Perhaps a better approach is to postulate
root causes of bias and then applying some resolution strategy. This paper
postulates that the root causes of bias are the prior decisions that affect-
(a) what data was selected and (b) the labels assigned to those examples. Our
Fair-SMOTE algorithm removes biased labels; and rebalances internal
distributions such that based on sensitive attribute, examples are equal in
both positive and negative classes. On testing, it was seen that this method
was just as effective at reducing bias as prior approaches. Further, models
generated via Fair-SMOTE achieve higher performance (measured in terms of
recall and F1) than other state-of-the-art fairness improvement algorithms. To
the best of our knowledge, measured in terms of number of analyzed learners and
datasets, this study is one of the largest studies on bias mitigation yet
presented in the literature.

    

### [[2105.12722] Sli2Vol: Annotate a 3D Volume from a Single Slice with Self-Supervised Learning](http://arxiv.org/abs/2105.12722)


  The objective of this work is to segment any arbitrary structures of interest
(SOI) in 3D volumes by only annotating a single slice, (i.e. semi-automatic 3D
segmentation). We show that high accuracy can be achieved by simply propagating
the 2D slice segmentation with an affinity matrix between consecutive slices,
which can be learnt in a self-supervised manner, namely slice reconstruction.
Specifically, we compare the proposed framework, termed as Sli2Vol, with
supervised approaches and two other unsupervised/ self-supervised slice
registration approaches, on 8 public datasets (both CT and MRI scans), spanning
9 different SOIs. Without any parameter-tuning, the same model achieves
superior performance with Dice scores (0-100 scale) of over 80 for most of the
benchmarks, including the ones that are unseen during training. Our results
show generalizability of the proposed approach across data from different
machines and with different SOIs: a major use case of semi-automatic
segmentation methods where fully supervised approaches would normally struggle.
The source code will be made publicly available at
this https URL.

    

### [[2106.00203] Hybrid Generative Models for Two-Dimensional Datasets](http://arxiv.org/abs/2106.00203)


  Two-dimensional array-based datasets are pervasive in a variety of domains.
Current approaches for generative modeling have typically been limited to
conventional image datasets and performed in the pixel domain which do not
explicitly capture the correlation between pixels. Additionally, these
approaches do not extend to scientific and other applications where each
element value is continuous and is not limited to a fixed range. In this paper,
we propose a novel approach for generating two-dimensional datasets by moving
the computations to the space of representation bases and show its usefulness
for two different datasets, one from imaging and another from scientific
computing. The proposed approach is general and can be applied to any dataset,
representation basis, or generative model. We provide a comprehensive
performance comparison of various combinations of generative models and
representation basis spaces. We also propose a new evaluation metric which
captures the deficiency of generating images in pixel space.

    

### [[2106.02087] Unsupervised Learning of General-Purpose Embeddings for Code Changes](http://arxiv.org/abs/2106.02087)


  Applying machine learning to tasks that operate with code changes requires
their numerical representation. In this work, we propose an approach for
obtaining such representations during pre-training and evaluate them on two
different downstream tasks - applying changes to code and commit message
generation. During pre-training, the model learns to apply the given code
change in a correct way. This task requires only code changes themselves, which
makes it unsupervised. In the task of applying code changes, our model
outperforms baseline models by 5.9 percentage points in accuracy. As for the
commit message generation, our model demonstrated the same results as
supervised models trained for this specific task, which indicates that it can
encode code changes well and can be improved in the future by pre-training on a
larger dataset of easily gathered code changes.

    

### [[2106.04763] Fixed-Budget Best-Arm Identification in Contextual Bandits: A Static-Adaptive Algorithm](http://arxiv.org/abs/2106.04763)


  We study the problem of best-arm identification (BAI) in contextual bandits
in the fixed-budget setting. We propose a general successive elimination
algorithm that proceeds in stages and eliminates a fixed fraction of suboptimal
arms in each stage. This design takes advantage of the strengths of static and
adaptive allocations. We analyze the algorithm in linear models and obtain a
better error bound than prior work. We also apply it to generalized linear
models (GLMs) and bound its error. This is the first BAI algorithm for GLMs in
the fixed-budget setting. Our extensive numerical experiments show that our
algorithm outperforms the state of art.

    

### [[2106.06171] Inter-domain Multi-relational Link Prediction](http://arxiv.org/abs/2106.06171)


  Multi-relational graph is a ubiquitous and important data structure, allowing
flexible representation of multiple types of interactions and relations between
entities. Similar to other graph-structured data, link prediction is one of the
most important tasks on multi-relational graphs and is often used for knowledge
completion. When related graphs coexist, it is of great benefit to build a
larger graph via integrating the smaller ones. The integration requires
predicting hidden relational connections between entities belonged to different
graphs (inter-domain link prediction). However, this poses a real challenge to
existing methods that are exclusively designed for link prediction between
entities of the same graph only (intra-domain link prediction). In this study,
we propose a new approach to tackle the inter-domain link prediction problem by
softly aligning the entity distributions between different domains with optimal
transport and maximum mean discrepancy regularizers. Experiments on real-world
datasets show that optimal transport regularizer is beneficial and considerably
improves the performance of baseline methods.

    

### [[2106.06988] NDPNet: A novel non-linear data projection network for few-shot fine-grained image classification](http://arxiv.org/abs/2106.06988)


  Metric-based few-shot fine-grained image classification (FSFGIC) aims to
learn a transferable feature embedding network by estimating the similarities
between query images and support classes from very few examples. In this work,
we propose, for the first time, to introduce the non-linear data projection
concept into the design of FSFGIC architecture in order to address the limited
sample problem in few-shot learning and at the same time to increase the
discriminability of the model for fine-grained image classification.
Specifically, we first design a feature re-abstraction embedding network that
has the ability to not only obtain the required semantic features for effective
metric learning but also re-enhance such features with finer details from input
images. Then the descriptors of the query images and the support classes are
projected into different non-linear spaces in our proposed similarity metric
learning network to learn discriminative projection factors. This design can
effectively operate in the challenging and restricted condition of a FSFGIC
task for making the distance between the samples within the same class smaller
and the distance between samples from different classes larger and for reducing
the coupling relationship between samples from different categories.
Furthermore, a novel similarity measure based on the proposed non-linear data
project is presented for evaluating the relationships of feature information
between a query image and a support set. It is worth to note that our proposed
architecture can be easily embedded into any episodic training mechanisms for
end-to-end training from scratch. Extensive experiments on FSFGIC tasks
demonstrate the superiority of the proposed methods over the state-of-the-art
benchmarks.

    

### [[2106.10507] GLIB: Towards Automated Test Oracle for Graphically-Rich Applications](http://arxiv.org/abs/2106.10507)


  Graphically-rich applications such as games are ubiquitous with attractive
visual effects of Graphical User Interface (GUI) that offers a bridge between
software applications and end-users. However, various types of graphical
glitches may arise from such GUI complexity and have become one of the main
component of software compatibility issues. Our study on bug reports from game
development teams in NetEase Inc. indicates that graphical glitches frequently
occur during the GUI rendering and severely degrade the quality of
graphically-rich applications such as video games. Existing automated testing
techniques for such applications focus mainly on generating various GUI test
sequences and check whether the test sequences can cause crashes. These
techniques require constant human attention to captures non-crashing bugs such
as bugs causing graphical glitches. In this paper, we present the first step in
automating the test oracle for detecting non-crashing bugs in graphically-rich
applications. Specifically, we propose \texttt{GLIB} based on a code-based data
augmentation technique to detect game GUI glitches. We perform an evaluation of
\texttt{GLIB} on 20 real-world game apps (with bug reports available) and the
result shows that \texttt{GLIB} can achieve 100\% precision and 99.5\% recall
in detecting non-crashing bugs such as game GUI glitches. Practical application
of \texttt{GLIB} on another 14 real-world games (without bug reports) further
demonstrates that \texttt{GLIB} can effectively uncover GUI glitches, with 48
of 53 bugs reported by \texttt{GLIB} having been confirmed and fixed so far.

    

### [[2106.12985] Stock Market Analysis with Text Data: A Review](http://arxiv.org/abs/2106.12985)


  Stock market movements are influenced by public and private information
shared through news articles, company reports, and social media discussions.
Analyzing these vast sources of data can give market participants an edge to
make profit. However, the majority of the studies in the literature are based
on traditional approaches that come short in analyzing unstructured, vast
textual data. In this study, we provide a review on the immense amount of
existing literature of text-based stock market analysis. We present input data
types and cover main textual data sources and variations. Feature
representation techniques are then presented. Then, we cover the analysis
techniques and create a taxonomy of the main stock market forecast models.
Importantly, we discuss representative work in each category of the taxonomy,
analyzing their respective contributions. Finally, this paper shows the
findings on unaddressed open problems and gives suggestions for future work.
The aim of this study is to survey the main stock market analysis models, text
representation techniques for financial market prediction, shortcomings of
existing techniques, and propose promising directions for future research.

    

### [[2107.04140] First-Generation Inference Accelerator Deployment at Facebook](http://arxiv.org/abs/2107.04140)


  In this paper, we provide a deep dive into the deployment of inference
accelerators at Facebook. Many of our ML workloads have unique characteristics,
such as sparse memory accesses, large model sizes, as well as high compute,
memory and network bandwidth requirements. We co-designed a high-performance,
energy-efficient inference accelerator platform based on these requirements. We
describe the inference accelerator platform ecosystem we developed and deployed
at Facebook: both hardware, through Open Compute Platform (OCP), and software
framework and tooling, through Pytorch/Caffe2/Glow. A characteristic of this
ecosystem from the start is its openness to enable a variety of AI accelerators
from different vendors. This platform, with six low-power accelerator cards
alongside a single-socket host CPU, allows us to serve models of high
complexity that cannot be easily or efficiently run on CPUs. We describe
various performance optimizations, at both platform and accelerator level,
which enables this platform to serve production traffic at Facebook. We also
share deployment challenges, lessons learned during performance optimization,
as well as provide guidance for future inference hardware co-design.

    

### [[2107.04175] A Survey on RISC-V Security: Hardware and Architecture](http://arxiv.org/abs/2107.04175)


  The Internet of Things (IoT) is an ongoing technological revolution. Embedded
processors are the processing engines of smart IoT devices. For decades, these
processors were mainly based on the Arm instruction set architecture (ISA). In
recent years, the free and open RISC-V ISA standard has attracted the attention
of industry and academia and is becoming the mainstream. Data security and user
privacy protection are common challenges faced by all IoT devices. In order to
deal with foreseeable security threats, the RISC-V community is studying
security solutions aimed at achieving a root of trust (RoT) and ensuring that
sensitive information on RISC-V devices is not tampered with or leaked. Many
RISC-V security research projects are underway, but the academic community has
not yet conducted a comprehensive survey of RISC-V security solutions. In order
to fill this research gap, this paper presents an in-depth survey on RISC-V
security technologies. This paper summarizes the representative security
mechanisms of RISC-V hardware and architecture. Based on our survey, we predict
the future research and development directions of RISC-V security. We hope that
our research can inspire RISC-V researchers and developers.

    

### [[2107.04244] WinoCNN: Kernel Sharing Winograd Systolic Array for Efficient Convolutional Neural Network Acceleration on FPGAs](http://arxiv.org/abs/2107.04244)


  The combination of Winograd's algorithm and systolic array architecture has
demonstrated the capability of improving DSP efficiency in accelerating
convolutional neural networks (CNNs) on FPGA platforms. However, handling
arbitrary convolution kernel sizes in FPGA-based Winograd processing elements
and supporting efficient data access remain underexplored. In this work, we are
the first to propose an optimized Winograd processing element (WinoPE), which
can naturally support multiple convolution kernel sizes with the same amount of
computing resources and maintains high runtime DSP efficiency. Using the
proposed WinoPE, we construct a highly efficient systolic array accelerator,
termed WinoCNN. We also propose a dedicated memory subsystem to optimize the
data access. Based on the accelerator architecture, we build accurate resource
and performance modeling to explore optimal accelerator configurations under
different resource constraints. We implement our proposed accelerator on
multiple FPGAs, which outperforms the state-of-the-art designs in terms of both
throughput and DSP efficiency. Our implementation achieves DSP efficiency up to
1.33 GOPS/DSP and throughput up to 3.1 TOPS with the Xilinx ZCU102 FPGA. These
are 29.1\% and 20.0\% better than the best solutions reported previously,
respectively.

    

### [[2107.04117] Crowd Sensing and Living Lab Outdoor Experimentation Made Easy](http://arxiv.org/abs/2107.04117)


  Outdoor `living lab' experimentation using pervasive computing provides new
opportunities: higher realism, external validity and large-scale
socio-spatio-temporal observations. However, experimentation `in the wild' is
highly complex and costly. Noise, biases, privacy concerns to comply with
standards of ethical review boards, remote moderation, control of experimental
conditions and equipment perplex the collection of high-quality data for causal
inference. This article introduces Smart Agora, a novel open-source software
platform for rigorous systematic outdoor experimentation. Without writing a
single line of code, highly complex experimental scenarios are visually
designed and automatically deployed to smart phones. Novel geolocated survey
and sensor data are collected subject of participants verifying desired
experimental conditions, for instance. their presence at certain urban spots.
This new approach drastically improves the quality and purposefulness of crowd
sensing, tailored to conditions that confirm/reject hypotheses. The features
that support this innovative functionality and the broad spectrum of its
applicability are demonstrated.

    

### [[2107.04172] Experiences with Integrating Custos SecurityServices](http://arxiv.org/abs/2107.04172)


  Science gateways are user-facing cyberinfrastruc-ture that provide
researchers and educators with Web-basedaccess to scientific software,
computing, and data resources.Managing user identities, accounts, and
permissions are essentialtasks for science gateways, and gateways likewise must
man-age secure connections between their middleware and remoteresources. The
Custos project is an effort to build open sourcesoftware that can be operated
as a multi-tenanted service thatprovides reliable implementations of common
science gatewaycybersecurity needs, including federated authentication,
iden-tity management, group and authorization management, andresource
credential management. Custos aims further to provideintegrated solutions
through these capabilities, delivering end-to-end support for several science
gateway usage scenarios. Thispaper examines four deployment scenarios using
Custos andassociated extensions beyond previously described work. Thefirst
capability illustrated by these scenarios is the need forCustos to provide
hierarchical tenant management that allowsmultiple gateway deployments to be
federated together andalso to support consolidated, hosted science gateway
platformservices. The second capability illustrated by these scenarios is
theneed to support service accounts that can support non-browserapplications
and agent applications that can act on behalf ofusers on edge resources. We
illustrate how the latter can be builtusing Web security standards combined
with Custos permissionmanagement mechanisms.

    

### [[2107.04409] An Orchestration Platform that Puts Radiologists in the Driver's Seat of AI Innovation: A Methodological Approach](http://arxiv.org/abs/2107.04409)


  Current AI-driven research in radiology requires resources and expertise that
are often inaccessible to small and resource-limited labs. The clinicians who
are able to participate in AI research are frequently well-funded,
well-staffed, and either have significant experience with AI and computing, or
have access to colleagues or facilities that do. Current imaging data is
clinician-oriented and is not easily amenable to machine learning initiatives,
resulting in inefficient, time consuming, and costly efforts that rely upon a
crew of data engineers and machine learning scientists, and all too often
preclude radiologists from driving AI research and innovation. We present the
system and methodology we have developed to address infrastructure and platform
needs, while reducing the staffing and resource barriers to entry. We emphasize
a data-first and modular approach that streamlines the AI development and
deployment process while providing efficient and familiar interfaces for
radiologists, such that they can be the drivers of new AI innovations.

    

### [[1904.03271] Optimal Communication Rates and Combinatorial Properties for Common Randomness Generation](http://arxiv.org/abs/1904.03271)


  We study common randomness generation problems where $n$ players aim to
generate same sequences of random coin flips where some subsets of the players
share an independent common coin which can be tossed multiple times, and there
is a publicly seen blackboard through which the players communicate with each
other. We provide a tight representation of the optimal communication rates via
linear programming, and more importantly, propose explicit algorithms for the
optimal distributed simulation for a wide class of hypergraphs. In particular,
the optimal communication rate in complete hypergraphs is still achievable in
sparser hypergraphs containing a path-connected cycle-free cluster of
topologically connected components. Some key steps in analyzing the upper
bounds rely on two different definitions of connectivity in hypergraphs, which
may be of independent interest.

    

### [[1912.12559] On Batch-Processing Based Coded Computing for Heterogeneous Distributed Computing Systems](http://arxiv.org/abs/1912.12559)


  In recent years, coded distributed computing (CDC) has attracted significant
attention, because it can efficiently facilitate many delay-sensitive
computation tasks against unexpected latencies in distributed computing
systems. Despite such a salient feature, many design challenges and
opportunities remain. In this paper, we focus on practical computing systems
with heterogeneous computing resources, and design a novel CDC approach, called
batch-processing based coded computing (BPCC), which exploits the fact that
every computing node can obtain some coded results before it completes the
whole task. To this end, we first describe the main idea of the BPCC framework,
and then formulate an optimization problem for BPCC to minimize the task
completion time by configuring the computation load. Through formal theoretical
analyses, extensive simulation studies, and comprehensive real experiments on
the Amazon EC2 computing clusters, we demonstrate promising performance of the
proposed BPCC scheme, in terms of high computational efficiency and robustness
to uncertain disturbances.

    

### [[2009.07785] Accelerating Domain Propagation: an Efficient GPU-Parallel Algorithm over Sparse Matrices](http://arxiv.org/abs/2009.07785)


  Fast domain propagation of linear constraints has become a crucial component
of today's best algorithms and solvers for mixed integer programming and
pseudo-boolean optimization to achieve peak solving performance. Irregularities
in the form of dynamic algorithmic behaviour, dependency structures, and
sparsity patterns in the input data make efficient implementations of domain
propagation on GPUs and, more generally, on parallel architectures challenging.
This is one of the main reasons why domain propagation in state-of-the-art
solvers is single thread only. In this paper, we present a new algorithm for
domain propagation which (a) avoids these problems and allows for an efficient
implementation on GPUs, and is (b) capable of running propagation rounds
entirely on the GPU, without any need for synchronization or communication with
the CPU. We present extensive computational results which demonstrate the
effectiveness of our approach and show that ample speedups are possible on
practically relevant problems: on state-of-the-art GPUs, our geometric mean
speed-up for reasonably-large instances is around 10x to 20x and can be as high
as 180x on favorably-large instances.

    

### [[2104.14392] COSCO: Container Orchestration using Co-Simulation and Gradient Based Optimization for Fog Computing Environments](http://arxiv.org/abs/2104.14392)


  Intelligent task placement and management of tasks in large-scale fog
platforms is challenging due to the highly volatile nature of modern workload
applications and sensitive user requirements of low energy consumption and
response time. Container orchestration platforms have emerged to alleviate this
problem with prior art either using heuristics to quickly reach scheduling
decisions or AI driven methods like reinforcement learning and evolutionary
approaches to adapt to dynamic scenarios. The former often fail to quickly
adapt in highly dynamic environments, whereas the latter have run-times that
are slow enough to negatively impact response time. Therefore, there is a need
for scheduling policies that are both reactive to work efficiently in volatile
environments and have low scheduling overheads. To achieve this, we propose a
Gradient Based Optimization Strategy using Back-propagation of gradients with
respect to Input (GOBI). Further, we leverage the accuracy of predictive
digital-twin models and simulation capabilities by developing a Coupled
Simulation and Container Orchestration Framework (COSCO). Using this, we create
a hybrid simulation driven decision approach, GOBI*, to optimize Quality of
Service (QoS) parameters. Co-simulation and the back-propagation approaches
allow these methods to adapt quickly in volatile environments. Experiments
conducted using real-world data on fog applications using the GOBI and GOBI*
methods, show a significant improvement in terms of energy consumption,
response time, Service Level Objective and scheduling time by up to 15, 40, 4,
and 82 percent respectively when compared to the state-of-the-art algorithms.

    

### [[2107.04125] The Multi-phase spatial meta-heuristic algorithm for public health emergency transportation](http://arxiv.org/abs/2107.04125)


  The delivery of Medical Countermeasures(MCMs) for mass prophylaxis in the
case of a bio-terrorist attack is an active research topic that has interested
the research community over the past decades. The objective of this study is to
design an efficient algorithm for the Receive Reload and Store Problem(RSS) in
which we aim to find feasible routes to deliver MCMs to a target population
considering time, physical, and human resources, and capacity limitations. For
doing this, we adapt the p-median problem to the POD-based emergency response
planning procedures and propose an efficient algorithm solution to perform the
p-median in reasonable computational time. We present RE-PLAN, the Response
PLan Analyzer system that contains some RSS solutions developed at The Center
for Computational Epidemiology and Response Analysis (CeCERA) at the University
of North Texas. Finally, we analyze a study case where we show how the
computational performance of the algorithm can impact the process of decision
making and emergency planning in the short and long terms.

    

### [[2107.04132] A Systematic Survey of Text Worlds as Embodied Natural Language Environments](http://arxiv.org/abs/2107.04132)


  Text Worlds are virtual environments for embodied agents that, unlike 2D or
3D environments, are rendered exclusively using textual descriptions. These
environments offer an alternative to higher-fidelity 3D environments due to
their low barrier to entry, providing the ability to study semantics,
compositional inference, and other high-level tasks with rich high-level action
spaces while controlling for perceptual input. This systematic survey outlines
recent developments in tooling, environments, and agent modeling for Text
Worlds, while examining recent trends in knowledge graphs, common sense
reasoning, transfer learning of Text World performance to higher-fidelity
environments, as well as near-term development targets that, once achieved,
make Text Worlds an attractive general research paradigm for natural language
processing.

    

### [[2107.04152] Levi Graph AMR Parser using Heterogeneous Attention](http://arxiv.org/abs/2107.04152)


  Coupled with biaffine decoders, transformers have been effectively adapted to
text-to-graph transduction and achieved state-of-the-art performance on AMR
parsing. Many prior works, however, rely on the biaffine decoder for either or
both arc and label predictions although most features used by the decoder may
be learned by the transformer already. This paper presents a novel approach to
AMR parsing by combining heterogeneous data (tokens, concepts, labels) as one
input to a transformer to learn attention, and use only attention matrices from
the transformer to predict all elements in AMR graphs (concepts, arcs, labels).
Although our models use significantly fewer parameters than the previous
state-of-the-art graph parser, they show similar or better accuracy on AMR 2.0
and 3.0.

    

### [[2107.04164] Parallel and Multi-Objective Falsification with Scenic and VerifAI](http://arxiv.org/abs/2107.04164)


  Falsification has emerged as an important tool for simulation-based
verification of autonomous systems. In this paper, we present extensions to the
Scenic scenario specification language and VerifAI toolkit that improve the
scalability of sampling-based falsification methods by using parallelism and
extend falsification to multi-objective specifications. We first present a
parallelized framework that is interfaced with both the simulation and sampling
capabilities of Scenic and the falsification capabilities of VerifAI, reducing
the execution time bottleneck inherently present in simulation-based testing.
We then present an extension of VerifAI's falsification algorithms to support
multi-objective optimization during sampling, using the concept of rulebooks to
specify a preference ordering over multiple metrics that can be used to guide
the counterexample search process. Lastly, we evaluate the benefits of these
extensions with a comprehensive set of benchmarks written in the Scenic
language.

    

### [[2107.04169] Safe Learning of Lifted Action Models](http://arxiv.org/abs/2107.04169)


  Creating a domain model, even for classical, domain-independent planning, is
a notoriously hard knowledge-engineering task. A natural approach to solve this
problem is to learn a domain model from observations. However, model learning
approaches frequently do not provide safety guarantees: the learned model may
assume actions are applicable when they are not, and may incorrectly capture
actions' effects. This may result in generating plans that will fail when
executed. In some domains such failures are not acceptable, due to the cost of
failure or inability to replan online after failure. In such settings, all
learning must be done offline, based on some observations collected, e.g., by
some other agents or a human. Through this learning, the task is to generate a
plan that is guaranteed to be successful. This is called the model-free
planning problem. Prior work proposed an algorithm for solving the model-free
planning problem in classical planning. However, they were limited to learning
grounded domains, and thus they could not scale. We generalize this prior work
and propose the first safe model-free planning algorithm for lifted domains. We
prove the correctness of our approach, and provide a statistical analysis
showing that the number of trajectories needed to solve future problems with
high probability is linear in the potential size of the domain model. We also
present experiments on twelve IPC domains showing that our approach is able to
learn the real action model in all cases with at most two trajectories.

    

### [[2107.04228] Activated Gradients for Deep Neural Networks](http://arxiv.org/abs/2107.04228)


  Deep neural networks often suffer from poor performance or even training
failure due to the ill-conditioned problem, the vanishing/exploding gradient
problem, and the saddle point problem. In this paper, a novel method by acting
the gradient activation function (GAF) on the gradient is proposed to handle
these challenges. Intuitively, the GAF enlarges the tiny gradients and
restricts the large gradient. Theoretically, this paper gives conditions that
the GAF needs to meet, and on this basis, proves that the GAF alleviates the
problems mentioned above. In addition, this paper proves that the convergence
rate of SGD with the GAF is faster than that without the GAF under some
assumptions. Furthermore, experiments on CIFAR, ImageNet, and PASCAL visual
object classes confirm the GAF's effectiveness. The experimental results also
demonstrate that the proposed method is able to be adopted in various deep
neural networks to improve their performance. The source code is publicly
available at
this https URL.

    

### [[2107.04303] Integrating Planning, Execution and Monitoring in the presence of Open World Novelties: Case Study of an Open World Monopoly Solver](http://arxiv.org/abs/2107.04303)


  The game of monopoly is an adversarial multi-agent domain where there is no
fixed goal other than to be the last player solvent, There are useful subgoals
like monopolizing sets of properties, and developing them. There is also a lot
of randomness from dice rolls, card-draws, and adversaries' strategies. This
unpredictability is made worse when unknown novelties are added during
gameplay. Given these challenges, Monopoly was one of the test beds chosen for
the DARPA-SAILON program which aims to create agents that can detect and
accommodate novelties. To handle the game complexities, we developed an agent
that eschews complete plans, and adapts it's policy online as the game evolves.
In the most recent independent evaluation in the SAILON program, our agent was
the best performing agent on most measures. We herein present our approach and
results.

    

### [[2107.04326] Semantic Segmentation on Multiple Visual Domains](http://arxiv.org/abs/2107.04326)


  Semantic segmentation models only perform well on the domain they are trained
on and datasets for training are scarce and often have a small label-spaces,
because the pixel level annotations required are expensive to make. Thus
training models on multiple existing domains is desired to increase the output
label-space. Current research shows that there is potential to improve accuracy
across datasets by using multi-domain training, but this has not yet been
successfully extended to datasets of three different non-overlapping domains
without manual labelling. In this paper a method for this is proposed for the
datasets Cityscapes, SUIM and SUN RGB-D, by creating a label-space that spans
all classes of the datasets. Duplicate classes are merged and discrepant
granularity is solved by keeping classes separate. Results show that accuracy
of the multi-domain model has higher accuracy than all baseline models
together, if hardware performance is equalized, as resources are not limitless,
showing that models benefit from additional data even from domains that have
nothing in common.

    

### [[2107.04347] An ontology for the formalization and visualization of scientific knowledge](http://arxiv.org/abs/2107.04347)


  The construction of an ontology of scientific knowledge objects, presented
here, is part of the development of an approach oriented towards the
visualization of scientific knowledge. It is motivated by the fact that the
concepts of organization of scientific knowledge (theorem, law, experience,
proof, etc.) appear in existing ontologies but that none of them is centered on
this topic and presents a simple and easily usable organization. We present the
first version built from ontological sources (ontologies of knowledge objects
of certain fields, lexical and higher level ones), specialized knowledge bases
and interviews with scientists. We have aligned this ontology with some of the
sources used, which has allowed us to verify its consistency with respect to
them. The validation of the ontology consists in using it to formalize
knowledge from various sources, which we have begun to do in the field of
physics.

    

### [[2107.04362] RGB Stream Is Enough for Temporal Action Detection](http://arxiv.org/abs/2107.04362)


  State-of-the-art temporal action detectors to date are based on two-stream
input including RGB frames and optical flow. Although combining RGB frames and
optical flow boosts performance significantly, optical flow is a hand-designed
representation which not only requires heavy computation, but also makes it
methodologically unsatisfactory that two-stream methods are often not learned
end-to-end jointly with the flow. In this paper, we argue that optical flow is
dispensable in high-accuracy temporal action detection and image level data
augmentation (ILDA) is the key solution to avoid performance degradation when
optical flow is removed. To evaluate the effectiveness of ILDA, we design a
simple yet efficient one-stage temporal action detector based on single RGB
stream named DaoTAD. Our results show that when trained with ILDA, DaoTAD has
comparable accuracy with all existing state-of-the-art two-stream detectors
while surpassing the inference speed of previous methods by a large margin and
the inference speed is astounding 6668 fps on GeForce GTX 1080 Ti. Code is
available at \url{this https URL}.

    

### [[2107.04378] Rail Topology Ontology: A Rail Infrastructure Base Ontology](http://arxiv.org/abs/2107.04378)


  Engineering projects for railway infrastructure typically involve many
subsystems which need consistent views of the planned and built infrastructure
and its underlying topology. Consistency is typically ensured by exchanging and
verifying data between tools using XML-based data formats and UML-based
object-oriented models. A tighter alignment of these data representations via a
common topology model could decrease the development effort of railway
infrastructure engineering tools. A common semantic model is also a
prerequisite for the successful adoption of railway knowledge graphs. Based on
the RailTopoModel standard, we developed the Rail Topology Ontology as a model
to represent core features of railway infrastructures in a standard-compliant
manner. This paper describes the ontology and its development method, and
discusses its suitability for integrating data of railway engineering systems
and other sources in a knowledge graph.
With the Rail Topology Ontology, software engineers and knowledge scientists
have a standard-based ontology for representing railway topologies to integrate
disconnected data sources. We use the Rail Topology Ontology for our rail
knowledge graph and plan to extend it by rail infrastructure ontologies derived
from existing data exchange standards, since many such standards use the same
base model as the presented ontology, viz., RailTopoModel.

    

### [[2107.04386] Joint Matrix Decomposition for Deep Convolutional Neural Networks Compression](http://arxiv.org/abs/2107.04386)


  Deep convolutional neural networks (CNNs) with a large number of parameters
requires huge computational resources, which has limited the application of
CNNs on resources constrained appliances. Decomposition-based methods,
therefore, have been utilized to compress CNNs in recent years. However, since
the compression factor and performance are negatively correlated, the
state-of-the-art works either suffer from severe performance degradation or
have limited low compression factors. To overcome these problems, unlike
previous works compressing layers separately, we propose to compress CNNs and
alleviate performance degradation via joint matrix decomposition. The idea is
inspired by the fact that there are lots of repeated modules in CNNs, and by
projecting weights with the same structures into the same subspace, networks
can be further compressed and even accelerated. In particular, three joint
matrix decomposition schemes are developed, and the corresponding optimization
approaches based on Singular Values Decomposition are proposed. Extensive
experiments are conducted across three challenging compact CNNs and 3 benchmark
data sets to demonstrate the superior performance of our proposed algorithms.
As a result, our methods can compress the size of ResNet-34 by 22x with
slighter accuracy degradation compared with several state-of-the-art methods.

    

### [[2107.04452] Multimodal Icon Annotation For Mobile Applications](http://arxiv.org/abs/2107.04452)


  Annotating user interfaces (UIs) that involves localization and
classification of meaningful UI elements on a screen is a critical step for
many mobile applications such as screen readers and voice control of devices.
Annotating object icons, such as menu, search, and arrow backward, is
especially challenging due to the lack of explicit labels on screens, their
similarity to pictures, and their diverse shapes. Existing studies either use
view hierarchy or pixel based methods to tackle the task. Pixel based
approaches are more popular as view hierarchy features on mobile platforms are
often incomplete or inaccurate, however it leaves out instructional information
in the view hierarchy such as resource-ids or content descriptions. We propose
a novel deep learning based multi-modal approach that combines the benefits of
both pixel and view hierarchy features as well as leverages the
state-of-the-art object detection techniques. In order to demonstrate the
utility provided, we create a high quality UI dataset by manually annotating
the most commonly used 29 icons in Rico, a large scale mobile design dataset
consisting of 72k UI screenshots. The experimental results indicate the
effectiveness of our multi-modal approach. Our model not only outperforms a
widely used object classification baseline but also pixel based object
detection models. Our study sheds light on how to combine view hierarchy with
pixel features for annotating UI elements.

    

### [[2107.04529] Entropy, Information, and the Updating of Probabilities](http://arxiv.org/abs/2107.04529)


  This paper is a review of a particular approach to the method of maximum
entropy as a general framework for inference. The discussion emphasizes the
pragmatic elements in the derivation. An epistemic notion of information is
defined in terms of its relation to the Bayesian beliefs of ideally rational
agents. The method of updating from a prior to a posterior probability
distribution is designed through an eliminative induction process. The
logarithmic relative entropy is singled out as the unique tool for updating
that (a) is of universal applicability; (b) that recognizes the value of prior
information; and (c) that recognizes the privileged role played by the notion
of independence in science. The resulting framework -- the ME method -- can
handle arbitrary priors and arbitrary constraints. It includes MaxEnt and
Bayes' rule as special cases and, therefore, it unifies entropic and Bayesian
methods into a single general inference scheme. The ME method goes beyond the
mere selection of a single posterior, but also addresses the question of how
much less probable other distributions might be, which provides a direct bridge
to the theories of fluctuations and large deviations.

    

### [[2107.04538] Learning Interaction-aware Guidance Policies for Motion Planning in Dense Traffic Scenarios](http://arxiv.org/abs/2107.04538)


  Autonomous navigation in dense traffic scenarios remains challenging for
autonomous vehicles (AVs) because the intentions of other drivers are not
directly observable and AVs have to deal with a wide range of driving
behaviors. To maneuver through dense traffic, AVs must be able to reason how
their actions affect others (interaction model) and exploit this reasoning to
navigate through dense traffic safely. This paper presents a novel framework
for interaction-aware motion planning in dense traffic scenarios. We explore
the connection between human driving behavior and their velocity changes when
interacting. Hence, we propose to learn, via deep Reinforcement Learning (RL),
an interaction-aware policy providing global guidance about the cooperativeness
of other vehicles to an optimization-based planner ensuring safety and
kinematic feasibility through constraint satisfaction. The learned policy can
reason and guide the local optimization-based planner with interactive behavior
to pro-actively merge in dense traffic while remaining safe in case the other
vehicles do not yield. We present qualitative and quantitative results in
highly interactive simulation environments (highway merging and unprotected
left turns) against two baseline approaches, a learning-based and an
optimization-based method. The presented results demonstrate that our method
significantly reduces the number of collisions and increases the success rate
with respect to both learning-based and optimization-based baselines.

    

### [[2002.05461] Coherent and Archimedean choice in general Banach spaces](http://arxiv.org/abs/2002.05461)


  I introduce and study a new notion of Archimedeanity for binary and
non-binary choice between options that live in an abstract Banach space,
through a very general class of choice models, called sets of desirable option
sets. In order to be able to bring an important diversity of contexts into the
fold, amongst which choice between horse lottery options, I pay special
attention to the case where these linear spaces don't include all `constant'
options.I consider the frameworks of conservative inference associated with
Archimedean (and coherent) choice models, and also pay quite a lot of attention
to representation of general (non-binary) choice models in terms of the
simpler, binary ones.The representation theorems proved here provide an
axiomatic characterisation for, amongst many other choice methods, Levi's
E-admissibility and Walley-Sen maximality.

    

### [[2012.02924] iGibson, a Simulation Environment for Interactive Tasks in Large Realistic Scenes](http://arxiv.org/abs/2012.02924)


  We present iGibson, a novel simulation environment to develop robotic
solutions for interactive tasks in large-scale realistic scenes. Our
environment contains 15 fully interactive home-sized scenes with 108 rooms
populated with rigid and articulated objects. The scenes are replicas of
real-world homes, with distribution and the layout of objects aligned to those
of the real world. iGibson integrates several key features to facilitate the
study of interactive tasks: i) generation of high-quality virtual sensor
signals (RGB, depth, segmentation, LiDAR, flow and so on), ii) domain
randomization to change the materials of the objects (both visual and physical)
and/or their shapes, iii) integrated sampling-based motion planners to generate
collision-free trajectories for robot bases and arms, and iv) intuitive
human-iGibson interface that enables efficient collection of human
demonstrations. Through experiments, we show that the full interactivity of the
scenes enables agents to learn useful visual representations that accelerate
the training of downstream manipulation tasks. We also show that iGibson
features enable the generalization of navigation agents, and that the
human-iGibson interface and integrated motion planners facilitate efficient
imitation learning of human demonstrated (mobile) manipulation behaviors.
iGibson is open-source, equipped with comprehensive examples and documentation.
For more information, visit our project website:
this http URL


### [[2104.01778] AST: Audio Spectrogram Transformer](http://arxiv.org/abs/2104.01778)


  In the past decade, convolutional neural networks (CNNs) have been widely
adopted as the main building block for end-to-end audio classification models,
which aim to learn a direct mapping from audio spectrograms to corresponding
labels. To better capture long-range global context, a recent trend is to add a
self-attention mechanism on top of the CNN, forming a CNN-attention hybrid
model. However, it is unclear whether the reliance on a CNN is necessary, and
if neural networks purely based on attention are sufficient to obtain good
performance in audio classification. In this paper, we answer the question by
introducing the Audio Spectrogram Transformer (AST), the first
convolution-free, purely attention-based model for audio classification. We
evaluate AST on various audio classification benchmarks, where it achieves new
state-of-the-art results of 0.485 mAP on AudioSet, 95.6% accuracy on ESC-50,
and 98.1% accuracy on Speech Commands V2.

    

### [[2105.01195] Quality Assurance Challenges for Machine Learning Software Applications During Software Development Life Cycle Phases](http://arxiv.org/abs/2105.01195)


  In the past decades, the revolutionary advances of Machine Learning (ML) have
shown a rapid adoption of ML models into software systems of diverse types.
Such Machine Learning Software Applications (MLSAs) are gaining importance in
our daily lives. As such, the Quality Assurance (QA) of MLSAs is of paramount
importance. Several research efforts are dedicated to determining the specific
challenges we can face while adopting ML models into software systems. However,
we are aware of no research that offered a holistic view of the distribution of
those ML quality assurance challenges across the various phases of software
development life cycles (SDLC). This paper conducts an in-depth literature
review of a large volume of research papers that focused on the quality
assurance of ML models. We developed a taxonomy of MLSA quality assurance
issues by mapping the various ML adoption challenges across different phases of
SDLC. We provide recommendations and research opportunities to improve SDLC
practices based on the taxonomy. This mapping can help prioritize quality
assurance efforts of MLSAs where the adoption of ML models can be considered
crucial.

    

### [[2107.04521] How to Identify Class Comment Types? A Multi-language Approach for Class Comments Classification](http://arxiv.org/abs/2107.04521)


  Most software maintenance and evolution tasks require developers to
understand the source code of their software systems. Software developers
usually inspect class comments to gain knowledge about program behavior,
regardless of the programming language they are using. Unfortunately, (i)
different programming languages present language-specific code commenting
notations/guidelines; and (ii) the source code of software projects often lacks
comments that adequately describe the class behavior, which complicates program
comprehension and evolution activities.
To handle these challenges, this paper investigates the different
language-specific class commenting practices of three programming languages:
Python, Java, and Smalltalk. In particular, we systematically analyze the
similarities and differences of the information types found in class comments
of projects developed in these languages.
We propose an approach that leverages two techniques, namely Natural Language
Processing and Text Analysis, to automatically identify various types of
information from class comments i.e., the specific types of semantic
information found in class comments. To the best of our knowledge, no previous
work has provided a comprehensive taxonomy of class comment types for these
three programming languages with the help of a common automated approach. Our
results confirm that our approach can classify frequent class comment
information types with high accuracy for Python, Java, and Smalltalk
programming languages. We believe this work can help to monitor and assess the
quality and evolution of code comments in different program languages, and thus
support maintenance and evolution tasks.

    

### [[2105.00564] The Power of Tightness for Call-By-Push-Value](http://arxiv.org/abs/2105.00564)


  We propose tight type systems for Call-by-Name (CBN) and Call-by-Value (CBV)
that can be both encoded in a tight type system for Call-by-Push-Value (CBPV).
All such systems are quantitative, in the sense that they provide exact
information about the length of normalization sequences to normal form
(discriminated between multiplicative and exponential steps) as well as the
size of these normal forms.

    