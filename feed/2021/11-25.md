
## 2021-11-25

### [[2111.12209] Sistema de sensoriamento sem fio aplicavel a deteccao de incendios florestais](http://arxiv.org/abs/2111.12209)


  In this research work, a hardware and software system is developed that uses
wireless sensors to monitor environmental variables such as temperature, gas
concentration and luminosity, in order to detect the existence of forest fires.
Lora technology was used for wireless sensor networks with communication range
that can reach on average up to 5km in urban areas and 10km in rural areas. The
developed system also has an integrated web application (dashboard) and that in
real time, collects data from wireless sensors, which together form the sensor
module, also called device. Then, this data is presented on a map associ- ated
with the positioning of each sensor module. The developed system was tested
using practical experiments that used flames, gases and lighting, simulating
the occurrence of fires. With the tests performed, it was observed the
feasibility of the system, hardware/software developed, in detecting the fires
in the simulated scenarios. Therefore, it was found that the research is
promising, and may advance in the future for the detection of real fires.

    

### [[2111.12253] Third-party Service Dependencies and Centralization Around the World](http://arxiv.org/abs/2111.12253)


  There is a growing concern about consolidation trends in Internet services,
with, for instance, a large fraction of popular websites depending on a handful
of third-party service providers. In this paper, we report on a large-scale
study of third-party dependencies around the world, using vantage points from
50 countries, from all inhabited continents, and regional top-500 popular
websites.This broad perspective shows that dependencies vary widely around the
world. We find that between 15% and as much as 80% of websites, across all
countries, depend on a DNS, CDN or CA third-party provider.Sites critical
dependencies, while lower, are equally spread ranging from 9% and 61% (CDN and
DNS in China, respectively).Despite this high variability, our results suggest
a highly concentrated market of third-party providers: three third-party
providers across all countries serve an average of 91.2% and Google, by itself,
serves an average of 72% of the surveyed websites. We explore various factors
that may help explain the differences and similarities in degrees of
third-party dependency across countries, including economic conditions,
Internet development, language, and economic trading partners.

    

### [[2111.12444] Edge Artificial Intelligence for 6G: Vision, Enabling Technologies, and Applications](http://arxiv.org/abs/2111.12444)


  The thriving of artificial intelligence (AI) applications is driving the
further evolution of wireless networks. It has been envisioned that 6G will be
transformative and will revolutionize the evolution of wireless from "connected
things" to "connected intelligence". However, state-of-the-art deep learning
and big data analytics based AI systems require tremendous computation and
communication resources, causing significant latency, energy consumption,
network congestion, and privacy leakage in both of the training and inference
processes. By embedding model training and inference capabilities into the
network edge, edge AI stands out as a disruptive technology for 6G to
seamlessly integrate sensing, communication, computation, and intelligence,
thereby improving the efficiency, effectiveness, privacy, and security of 6G
networks. In this paper, we shall provide our vision for scalable and
trustworthy edge AI systems with integrated design of wireless communication
strategies and decentralized machine learning models. New design principles of
wireless networks, service-driven resource allocation optimization methods, as
well as a holistic end-to-end system architecture to support edge AI will be
described. Standardization, software and hardware platforms, and application
scenarios are also discussed to facilitate the industrialization and
commercialization of edge AI systems.

    

### [[2111.12581] Medium Access Control protocol for Collaborative Spectrum Learning in Wireless Networks](http://arxiv.org/abs/2111.12581)


  In recent years there is a growing effort to provide learning algorithms for
spectrum collaboration. In this paper we present a medium access control
protocol which allows spectrum collaboration with minimal regret and high
spectral efficiency in highly loaded networks. We present a fully-distributed
algorithm for spectrum collaboration in congested ad-hoc networks. The
algorithm jointly solves both the channel allocation and access scheduling
problems. We prove that the algorithm has an optimal logarithmic regret. Based
on the algorithm we provide a medium access control protocol which allows
distributed implementation of the algorithm in ad-hoc networks. The protocol
utilizes single-channel opportunistic carrier sensing to carry out a
low-complexity distributed auction in time and frequency. We also discuss
practical implementation issues such as bounded frame size and speed of
convergence. Computer simulations comparing the algorithm to state-of-the-art
distributed medium access control protocols show the significant advantage of
the proposed scheme.

    

### [[2103.02434] 5G New Radio for Public Safety Mission Critical Communications](http://arxiv.org/abs/2103.02434)


  Driven by increasing demands on connectivity to improve safety, situational
awareness and operational effectiveness for first responders, more and more
public safety agencies are realizing the need of modernization of their
existing non-3GPP networks. 3GPP based cellular networks offer the unique
opportunity of providing fast, reliable, and prioritized communications for
first responders in a shared network. In this article, we give an overview of
service requirements of public safety mission critical communications. We
identify key technical challenges and explain how 5G NR features are being
evolved to meet the emerging safety critical requirements, including enabling
connectivity everywhere, supporting efficient group communications,
prioritizing mission critical traffic, and providing accurate positioning for
first responders.

    

### [[2111.12123] MICS : Multi-steps, Inverse Consistency and Symmetric deep learning registration network](http://arxiv.org/abs/2111.12123)


  Deformable registration consists of finding the best dense correspondence
between two different images. Many algorithms have been published, but the
clinical application was made difficult by the high calculation time needed to
solve the optimisation problem. Deep learning overtook this limitation by
taking advantage of GPU calculation and the learning process. However, many
deep learning methods do not take into account desirable properties respected
by classical algorithms.
In this paper, we present MICS, a novel deep learning algorithm for medical
imaging registration. As registration is an ill-posed problem, we focused our
algorithm on the respect of different properties: inverse consistency, symmetry
and orientation conservation. We also combined our algorithm with a multi-step
strategy to refine and improve the deformation grid. While many approaches
applied registration to brain MRI, we explored a more challenging body
localisation: abdominal CT. Finally, we evaluated our method on a dataset used
during the Learn2Reg challenge, allowing a fair comparison with published
methods.

    

### [[2111.12128] On the Unreasonable Effectiveness of Feature propagation in Learning on Graphs with Missing Node Features](http://arxiv.org/abs/2111.12128)


  While Graph Neural Networks (GNNs) have recently become the de facto standard
for modeling relational data, they impose a strong assumption on the
availability of the node or edge features of the graph. In many real-world
applications, however, features are only partially available; for example, in
social networks, age and gender are available only for a small subset of users.
We present a general approach for handling missing features in graph machine
learning applications that is based on minimization of the Dirichlet energy and
leads to a diffusion-type differential equation on the graph. The
discretization of this equation produces a simple, fast and scalable algorithm
which we call Feature Propagation. We experimentally show that the proposed
approach outperforms previous methods on seven common node-classification
benchmarks and can withstand surprisingly high rates of missing features: on
average we observe only around 4% relative accuracy drop when 99% of the
features are missing. Moreover, it takes only 10 seconds to run on a graph with
$\sim$2.5M nodes and $\sim$123M edges on a single GPU.

    

### [[2111.12132] Robust Principal Component Analysis: A Construction Error Minimization Perspective](http://arxiv.org/abs/2111.12132)


  In this paper we propose a novel optimization framework to systematically
solve robust PCA problem with rigorous theoretical guarantee, based on which we
investigate very computationally economic updating algorithms.

    

### [[2111.12137] Learning Interactive Driving Policies via Data-driven Simulation](http://arxiv.org/abs/2111.12137)


  Data-driven simulators promise high data-efficiency for driving policy
learning. When used for modelling interactions, this data-efficiency becomes a
bottleneck: Small underlying datasets often lack interesting and challenging
edge cases for learning interactive driving. We address this challenge by
proposing a simulation method that uses in-painted ado vehicles for learning
robust driving policies. Thus, our approach can be used to learn policies that
involve multi-agent interactions and allows for training via state-of-the-art
policy learning methods. We evaluate the approach for learning standard
interaction scenarios in driving. In extensive experiments, our work
demonstrates that the resulting policies can be directly transferred to a
full-scale autonomous vehicle without making use of any traditional sim-to-real
transfer techniques such as domain randomization.

    

### [[2111.12139] ChebLieNet: Invariant Spectral Graph NNs Turned Equivariant by Riemannian Geometry on Lie Groups](http://arxiv.org/abs/2111.12139)


  We introduce ChebLieNet, a group-equivariant method on (anisotropic)
manifolds. Surfing on the success of graph- and group-based neural networks, we
take advantage of the recent developments in the geometric deep learning field
to derive a new approach to exploit any anisotropies in data. Via discrete
approximations of Lie groups, we develop a graph neural network made of
anisotropic convolutional layers (Chebyshev convolutions), spatial pooling and
unpooling layers, and global pooling layers. Group equivariance is achieved via
equivariant and invariant operators on graphs with anisotropic left-invariant
Riemannian distance-based affinities encoded on the edges. Thanks to its simple
form, the Riemannian metric can model any anisotropies, both in the spatial and
orientation domains. This control on anisotropies of the Riemannian metrics
allows to balance equivariance (anisotropic metric) against invariance
(isotropic metric) of the graph convolution layers. Hence we open the doors to
a better understanding of anisotropic properties. Furthermore, we empirically
prove the existence of (data-dependent) sweet spots for anisotropic parameters
on CIFAR10. This crucial result is evidence of the benefice we could get by
exploiting anisotropic properties in data. We also evaluate the scalability of
this approach on STL10 (image data) and ClimateNet (spherical data), showing
its remarkable adaptability to diverse tasks.

    

### [[2111.12140] Filter Methods for Feature Selection in Supervised Machine Learning Applications -- Review and Benchmark](http://arxiv.org/abs/2111.12140)


  The amount of data for machine learning (ML) applications is constantly
growing. Not only the number of observations, especially the number of measured
variables (features) increases with ongoing digitization. Selecting the most
appropriate features for predictive modeling is an important lever for the
success of ML applications in business and research. Feature selection methods
(FSM) that are independent of a certain ML algorithm - so-called filter methods
- have been numerously suggested, but little guidance for researchers and
quantitative modelers exists to choose appropriate approaches for typical ML
problems. This review synthesizes the substantial literature on feature
selection benchmarking and evaluates the performance of 58 methods in the
widely used R environment. For concrete guidance, we consider four typical
dataset scenarios that are challenging for ML models (noisy, redundant,
imbalanced data and cases with more features than observations). Drawing on the
experience of earlier benchmarks, which have considered much fewer FSMs, we
compare the performance of the methods according to four criteria (predictive
performance, number of relevant features selected, stability of the feature
sets and runtime). We found methods relying on the random forest approach, the
double input symmetrical relevance filter (DISR) and the joint impurity filter
(JIM) were well-performing candidate methods for the given dataset scenarios.

    

### [[2111.12143] Critical initialization of wide and deep neural networks through partial Jacobians: general theory and applications to LayerNorm](http://arxiv.org/abs/2111.12143)


  Deep neural networks are notorious for defying theoretical treatment.
However, when the number of parameters in each layer tends to infinity the
network function is a Gaussian process (GP) and quantitatively predictive
description is possible. Gaussian approximation allows to formulate criteria
for selecting hyperparameters, such as variances of weights and biases, as well
as the learning rate. These criteria rely on the notion of criticality defined
for deep neural networks. In this work we describe a new way to diagnose (both
theoretically and empirically) this criticality. To that end, we introduce
partial Jacobians of a network, defined as derivatives of preactivations in
layer $l$ with respect to preactivations in layer $l_0<l$. These quantities are
particularly useful when the network architecture involves many different
layers. We discuss various properties of the partial Jacobians such as their
scaling with depth and relation to the neural tangent kernel (NTK). We derive
the recurrence relations for the partial Jacobians and utilize them to analyze
criticality of deep MLP networks with (and without) LayerNorm. We find that the
normalization layer changes the optimal values of hyperparameters and critical
exponents. We argue that LayerNorm is more stable when applied to
preactivations, rather than activations due to larger correlation depth.

    

### [[2111.12146] Sharing to learn and learning to share - Fitting together Meta-Learning, Multi-Task Learning, and Transfer Learning : A meta review](http://arxiv.org/abs/2111.12146)


  Integrating knowledge across different domains is an essential feature of
human learning. Learning paradigms like transfer learning, meta learning, and
multi-task learning reflect the human learning process by exploiting the prior
knowledge for new tasks, encouraging faster learning and good generalization
for new tasks. This article gives a detailed view of these learning paradigms
along with a comparative analysis. The weakness of a learning algorithm turns
out to be the strength of another, and thereby merging them is a prevalent
trait in the literature. This work delivers a literature review of the
articles, which fuses two algorithms to accomplish multiple tasks. A global
generic learning network, an ensemble of meta learning, transfer learning, and
multi-task learning, is also introduced here, along with some open research
questions and directions for future research.

    

### [[2111.12150] Jointly Learning from Decentralized (Federated) and Centralized Data to Mitigate Distribution Shift](http://arxiv.org/abs/2111.12150)


  With privacy as a motivation, Federated Learning (FL) is an increasingly used
paradigm where learning takes place collectively on edge devices, each with a
cache of user-generated training examples that remain resident on the local
device. These on-device training examples are gathered in situ during the
course of users' interactions with their devices, and thus are highly
reflective of at least part of the inference data distribution. Yet a
distribution shift may still exist; the on-device training examples may lack
for some data inputs expected to be encountered at inference time. This paper
proposes a way to mitigate this shift: selective usage of datacenter data,
mixed in with FL. By mixing decentralized (federated) and centralized
(datacenter) data, we can form an effective training data distribution that
better matches the inference data distribution, resulting in more useful models
while still meeting the private training data access constraints imposed by FL.

    

### [[2111.12151] Best Arm Identification with Safety Constraints](http://arxiv.org/abs/2111.12151)


  The best arm identification problem in the multi-armed bandit setting is an
excellent model of many real-world decision-making problems, yet it fails to
capture the fact that in the real-world, safety constraints often must be met
while learning. In this work we study the question of best-arm identification
in safety-critical settings, where the goal of the agent is to find the best
safe option out of many, while exploring in a way that guarantees certain,
initially unknown safety constraints are met. We first analyze this problem in
the setting where the reward and safety constraint takes a linear structure,
and show nearly matching upper and lower bounds. We then analyze a much more
general version of the problem where we only assume the reward and safety
constraint can be modeled by monotonic functions, and propose an algorithm in
this setting which is guaranteed to learn safely. We conclude with experimental
results demonstrating the effectiveness of our approaches in scenarios such as
safely identifying the best drug out of many in order to treat an illness.

    

### [[2111.12157] Bayesian Sample Size Prediction for Online Activity](http://arxiv.org/abs/2111.12157)


  In many contexts it is useful to predict the number of individuals in some
population who will initiate a particular activity during a given period. For
example, the number of users who will install a software update, the number of
customers who will use a new feature on a website or who will participate in an
A/B test. In practical settings, there is heterogeneity amongst individuals
with regard to the distribution of time until they will initiate. For these
reasons it is inappropriate to assume that the number of new individuals
observed on successive days will be identically distributed. Given observations
on the number of unique users participating in an initial period, we present a
simple but novel Bayesian method for predicting the number of additional
individuals who will subsequently participate during a subsequent period. We
illustrate the performance of the method in predicting sample size in online
experimentation.

    

### [[2111.12158] Using Language Model to Bootstrap Human Activity Recognition Ambient Sensors Based in Smart Homes](http://arxiv.org/abs/2111.12158)


  Long Short Term Memory LSTM-based structures have demonstrated their
efficiency for daily living recognition activities in smart homes by capturing
the order of sensor activations and their temporal dependencies. Nevertheless,
they still fail in dealing with the semantics and the context of the sensors.
More than isolated id and their ordered activation values, sensors also carry
meaning. Indeed, their nature and type of activation can translate various
activities. Their logs are correlated with each other, creating a global
context. We propose to use and compare two Natural Language Processing
embedding methods to enhance LSTM-based structures in activity-sequences
classification tasks: Word2Vec, a static semantic embedding, and ELMo, a
contextualized embedding. Results, on real smart homes datasets, indicate that
this approach provides useful information, such as a sensor organization map,
and makes less confusion between daily activity classes. It helps to better
perform on datasets with competing activities of other residents or pets. Our
tests show also that the embeddings can be pretrained on different datasets
than the target one, enabling transfer learning. We thus demonstrate that
taking into account the context of the sensors and their semantics increases
the classification performances and enables transfer learning.

    

### [[2111.12159] Rhythm is a Dancer: Music-Driven Motion Synthesis with Global Structure](http://arxiv.org/abs/2111.12159)


  Synthesizing human motion with a global structure, such as a choreography, is
a challenging task. Existing methods tend to concentrate on local smooth pose
transitions and neglect the global context or the theme of the motion. In this
work, we present a music-driven motion synthesis framework that generates
long-term sequences of human motions which are synchronized with the input
beats, and jointly form a global structure that respects a specific dance
genre. In addition, our framework enables generation of diverse motions that
are controlled by the content of the music, and not only by the beat. Our
music-driven dance synthesis framework is a hierarchical system that consists
of three levels: pose, motif, and choreography. The pose level consists of an
LSTM component that generates temporally coherent sequences of poses. The motif
level guides sets of consecutive poses to form a movement that belongs to a
specific distribution using a novel motion perceptual-loss. And the
choreography level selects the order of the performed movements and drives the
system to follow the global structure of a dance genre. Our results demonstrate
the effectiveness of our music-driven framework to generate natural and
consistent movements on various dance types, having control over the content of
the synthesized motions, and respecting the overall structure of the dance.

    

### [[2111.12166] Towards Empirical Sandwich Bounds on the Rate-Distortion Function](http://arxiv.org/abs/2111.12166)


  Rate-distortion (R-D) function, a key quantity in information theory,
characterizes the fundamental limit of how much a data source can be compressed
subject to a fidelity criterion, by any compression algorithm. As researchers
push for ever-improving compression performance, establishing the R-D function
of a given data source is not only of scientific interest, but also sheds light
on the possible room for improving compression algorithms. Previous work on
this problem relied on distributional assumptions on the data source (Gibson,
2017) or only applied to discrete data. By contrast, this paper makes the first
attempt at an algorithm for sandwiching the R-D function of a general (not
necessarily discrete) source requiring only i.i.d. data samples. We estimate
R-D sandwich bounds on Gaussian and high-dimension banana-shaped sources, as
well as GAN-generated images. Our R-D upper bound on natural images indicates
room for improving the performance of state-of-the-art image compression
methods by 1 dB in PSNR at various bitrates.

    

### [[2111.12170] Domain-Agnostic Clustering with Self-Distillation](http://arxiv.org/abs/2111.12170)


  Recent advancements in self-supervised learning have reduced the gap between
supervised and unsupervised representation learning. However, most
self-supervised and deep clustering techniques rely heavily on data
augmentation, rendering them ineffective for many learning tasks where
insufficient domain knowledge exists for performing augmentation. We propose a
new self-distillation based algorithm for domain-agnostic clustering. Our
method builds upon the existing deep clustering frameworks and requires no
separate student model. The proposed method outperforms existing domain
agnostic (augmentation-free) algorithms on CIFAR-10. We empirically demonstrate
that knowledge distillation can improve unsupervised representation learning by
extracting richer `dark knowledge' from the model than using predicted labels
alone. Preliminary experiments also suggest that self-distillation improves the
convergence of DeepCluster-v2.

    

### [[2111.12172] Multi-label Iterated Learning for Image Classification with Label Ambiguity](http://arxiv.org/abs/2111.12172)


  Transfer learning from large-scale pre-trained models has become essential
for many computer vision tasks. Recent studies have shown that datasets like
ImageNet are weakly labeled since images with multiple object classes present
are assigned a single label. This ambiguity biases models towards a single
prediction, which could result in the suppression of classes that tend to
co-occur in the data. Inspired by language emergence literature, we propose
multi-label iterated learning (MILe) to incorporate the inductive biases of
multi-label learning from single labels using the framework of iterated
learning. MILe is a simple yet effective procedure that builds a multi-label
description of the image by propagating binary predictions through successive
generations of teacher and student networks with a learning bottleneck.
Experiments show that our approach exhibits systematic benefits on ImageNet
accuracy as well as ReaL F1 score, which indicates that MILe deals better with
label ambiguity than the standard training procedure, even when fine-tuning
from self-supervised weights. We also show that MILe is effective reducing
label noise, achieving state-of-the-art performance on real-world large-scale
noisy data such as WebVision. Furthermore, MILe improves performance in class
incremental settings such as IIRC and it is robust to distribution shifts.
Code: this https URL


### [[2111.12175] Three-Way Deep Neural Network for Radio Frequency Map Generation and Source Localization](http://arxiv.org/abs/2111.12175)


  In this paper, we present a Generative Adversarial Network (GAN) machine
learning model to interpolate irregularly distributed measurements across the
spatial domain to construct a smooth radio frequency map (RFMap) and then
perform localization using a deep neural network. Monitoring wireless spectrum
over spatial, temporal, and frequency domains will become a critical feature in
facilitating dynamic spectrum access (DSA) in beyond-5G and 6G communication
technologies. Localization, wireless signal detection, and spectrum
policy-making are several of the applications where distributed spectrum
sensing will play a significant role. Detection and positioning of wireless
emitters is a very challenging task in a large spectral and spatial area. In
order to construct a smooth RFMap database, a large number of measurements are
required which can be very expensive and time consuming. One approach to help
realize these systems is to collect finite localized measurements across a
given area and then interpolate the measurement values to construct the
database. Current methods in the literature employ channel modeling to
construct the radio frequency map, which lacks the granularity for accurate
localization whereas our proposed approach reconstructs a new generalized
RFMap. Localization results are presented and compared with conventional
channel models.

    

### [[2111.12187] Input Convex Gradient Networks](http://arxiv.org/abs/2111.12187)


  The gradients of convex functions are expressive models of non-trivial vector
fields. For example, Brenier's theorem yields that the optimal transport map
between any two measures on Euclidean space under the squared distance is
realized as a convex gradient, which is a key insight used in recent generative
flow models. In this paper, we study how to model convex gradients by
integrating a Jacobian-vector product parameterized by a neural network, which
we call the Input Convex Gradient Network (ICGN). We theoretically study ICGNs
and compare them to taking the gradient of an Input-Convex Neural Network
(ICNN), empirically demonstrating that a single layer ICGN can fit a toy
example better than a single layer ICNN. Lastly, we explore extensions to
deeper networks and connections to constructions from Riemannian geometry.

    

### [[2111.12193] Multiset-Equivariant Set Prediction with Approximate Implicit Differentiation](http://arxiv.org/abs/2111.12193)


  Most set prediction models in deep learning use set-equivariant operations,
but they actually operate on multisets. We show that set-equivariant functions
cannot represent certain functions on multisets, so we introduce the more
appropriate notion of multiset-equivariance. We identify that the existing Deep
Set Prediction Network (DSPN) can be multiset-equivariant without being
hindered by set-equivariance and improve it with approximate implicit
differentiation, allowing for better optimization while being faster and saving
memory. In a range of toy experiments, we show that the perspective of
multiset-equivariance is beneficial and that our changes to DSPN achieve better
results in most cases. On CLEVR object property prediction, we substantially
improve over the state-of-the-art Slot Attention from 8% to 77% in one of the
strictest evaluation metrics because of the benefits made possible by implicit
differentiation.

    

### [[2111.12210] From Kepler to Newton: the Role of Explainable AI in Science Discovery](http://arxiv.org/abs/2111.12210)


  The research paradigm of the
Observation--Hypothesis--Prediction--Experimentation loop has been practiced by
researchers for years towards scientific discovery. However, with the data
explosion in both mega-scale and milli-scale scientific research, it has been
sometimes very difficult to manually analyze the data and propose new
hypothesis to drive the cycle for scientific discovery.
In this paper, we introduce an Explainable AI-assisted paradigm for science
discovery. The key is to use Explainable AI (XAI) to help derive data or model
interpretations and science discoveries. We show how computational and
data-intensive methodology -- together with experimental and theoretical
methodology -- can be seamlessly integrated for scientific research. To
demonstrate the AI-assisted science discovery process, and to pay our respect
to some of the greatest minds in human history, we show how Kepler's laws of
planetary motion and Newton's law of universal gravitation can be rediscovered
by (explainable) AI based on Tycho Brahe's astronomical observation data, whose
works were leading the scientific revolution in the 16-17th century. This work
also highlights the importance of Explainable AI (as compared to black-box AI)
in science discovery to help humans prevent or better prepare for the possible
technological singularity which may happen in the future.

    

### [[2111.12215] Explainable multiple abnormality classification of chest CT volumes with AxialNet and HiResCAM](http://arxiv.org/abs/2111.12215)


  Understanding model predictions is critical in healthcare, to facilitate
rapid verification of model correctness and to guard against use of models that
exploit confounding variables. We introduce the challenging new task of
explainable multiple abnormality classification in volumetric medical images,
in which a model must indicate the regions used to predict each abnormality. To
solve this task, we propose a multiple instance learning convolutional neural
network, AxialNet, that allows identification of top slices for each
abnormality. Next we incorporate HiResCAM, an attention mechanism, to identify
sub-slice regions. We prove that for AxialNet, HiResCAM explanations are
guaranteed to reflect the locations the model used, unlike Grad-CAM which
sometimes highlights irrelevant locations. Armed with a model that produces
faithful explanations, we then aim to improve the model's learning through a
novel mask loss that leverages HiResCAM and 3D allowed regions to encourage the
model to predict abnormalities based only on the organs in which those
abnormalities appear. The 3D allowed regions are obtained automatically through
a new approach, PARTITION, that combines location information extracted from
radiology reports with organ segmentation maps obtained through morphological
image processing. Overall, we propose the first model for explainable
multi-abnormality prediction in volumetric medical images, and then use the
mask loss to achieve a 33% improvement in organ localization of multiple
abnormalities in the RAD-ChestCT data set of 36,316 scans, representing the
state of the art. This work advances the clinical applicability of multiple
abnormality modeling in chest CT volumes.

    

### [[2111.12229] Subspace Adversarial Training](http://arxiv.org/abs/2111.12229)


  Single-step adversarial training (AT) has received wide attention as it
proved to be both efficient and robust. However, a serious problem of
catastrophic overfitting exists, i.e., the robust accuracy against projected
gradient descent (PGD) attack suddenly drops to $0\%$ during the training. In
this paper, we understand this problem from a novel perspective of optimization
and firstly reveal the close link between the fast-growing gradient of each
sample and overfitting, which can also be applied to understand the robust
overfitting phenomenon in multi-step AT. To control the growth of the gradient
during the training, we propose a new AT method, subspace adversarial training
(Sub-AT), which constrains the AT in a carefully extracted subspace. It
successfully resolves both two kinds of overfitting and hence significantly
boosts the robustness. In subspace, we also allow single-step AT with larger
steps and larger radius, which further improves the robustness performance. As
a result, we achieve the state-of-the-art single-step AT performance: our pure
single-step AT can reach over $\mathbf{51}\%$ robust accuracy against strong
PGD-50 attack with radius $8/255$ on CIFAR-10, even surpassing the standard
multi-step PGD-10 AT with huge computational advantages. The code is
released$\footnote{\url{this https URL}}$.

    

### [[2111.12272] Causal Analysis and Prediction of Human Mobility in the U.S. during the COVID-19 Pandemic](http://arxiv.org/abs/2111.12272)


  Since the increasing outspread of COVID-19 in the U.S., with the highest
number of confirmed cases and deaths in the world as of September 2020, most
states in the country have enforced travel restrictions resulting in sharp
reductions in mobility. However, the overall impact and long-term implications
of this crisis to travel and mobility remain uncertain. To this end, this study
develops an analytical framework that determines and analyzes the most dominant
factors impacting human mobility and travel in the U.S. during this pandemic.
In particular, the study uses Granger causality to determine the important
predictors influencing daily vehicle miles traveled and utilize linear
regularization algorithms, including Ridge and LASSO techniques, to model and
predict mobility. State-level time-series data were obtained from various
open-access sources for the period starting from March 1, 2020 through June 13,
2020 and the entire data set was divided into two parts for training and
testing purposes. The variables selected by Granger causality were used to
train the three different reduced order models by ordinary least square
regression, Ridge regression, and LASSO regression algorithms. Finally, the
prediction accuracy of the developed models was examined on the test data. The
results indicate that the factors including the number of new COVID cases,
social distancing index, population staying at home, percent of out of county
trips, trips to different destinations, socioeconomic status, percent of people
working from home, and statewide closure, among others, were the most important
factors influencing daily VMT. Also, among all the modeling techniques, Ridge
regression provides the most superior performance with the least error, while
LASSO regression also performed better than the ordinary least square model.

    

### [[2111.12273] Sharpness-aware Quantization for Deep Neural Networks](http://arxiv.org/abs/2111.12273)


  Network quantization is an effective compression method to reduce the model
size and computational cost. Despite the high compression ratio, training a
low-precision model is difficult due to the discrete and non-differentiable
nature of quantization, resulting in considerable performance degradation.
Recently, Sharpness-Aware Minimization (SAM) is proposed to improve the
generalization performance of the models by simultaneously minimizing the loss
value and the loss curvature. In this paper, we devise a Sharpness-Aware
Quantization (SAQ) method to train quantized models, leading to better
generalization performance. Moreover, since each layer contributes differently
to the loss value and the loss sharpness of a network, we further devise an
effective method that learns a configuration generator to automatically
determine the bitwidth configurations of each layer, encouraging lower bits for
flat regions and vice versa for sharp landscapes, while simultaneously
promoting the flatness of minima to enable more aggressive quantization.
Extensive experiments on CIFAR-100 and ImageNet show the superior performance
of the proposed methods. For example, our quantized ResNet-18 with 55.1x
Bit-Operation (BOP) reduction even outperforms the full-precision one by 0.7%
in terms of the Top-1 accuracy. Code is available at
this https URL.

    

### [[2111.12276] Utilizing Resource-Rich Language Datasets for End-to-End Scene Text Recognition in Resource-Poor Languages](http://arxiv.org/abs/2111.12276)


  This paper presents a novel training method for end-to-end scene text
recognition. End-to-end scene text recognition offers high recognition
accuracy, especially when using the encoder-decoder model based on Transformer.
To train a highly accurate end-to-end model, we need to prepare a large
image-to-text paired dataset for the target language. However, it is difficult
to collect this data, especially for resource-poor languages. To overcome this
difficulty, our proposed method utilizes well-prepared large datasets in
resource-rich languages such as English, to train the resource-poor
encoder-decoder model. Our key idea is to build a model in which the encoder
reflects knowledge of multiple languages while the decoder specializes in
knowledge of just the resource-poor language. To this end, the proposed method
pre-trains the encoder by using a multilingual dataset that combines the
resource-poor language's dataset and the resource-rich language's dataset to
learn language-invariant knowledge for scene text recognition. The proposed
method also pre-trains the decoder by using the resource-poor language's
dataset to make the decoder better suited to the resource-poor language.
Experiments on Japanese scene text recognition using a small, publicly
available dataset demonstrate the effectiveness of the proposed method.

    

### [[2111.12292] Improved Fine-tuning by Leveraging Pre-training Data: Theory and Practice](http://arxiv.org/abs/2111.12292)


  As a dominant paradigm, fine-tuning a pre-trained model on the target data is
widely used in many deep learning applications, especially for small data sets.
However, recent studies have empirically shown that training from scratch has
the final performance that is no worse than this pre-training strategy once the
number of training iterations is increased in some vision tasks. In this work,
we revisit this phenomenon from the perspective of generalization analysis
which is popular in learning theory. Our result reveals that the final
prediction precision may have a weak dependency on the pre-trained model
especially in the case of large training iterations. The observation inspires
us to leverage pre-training data for fine-tuning, since this data is also
available for fine-tuning. The generalization result of using pre-training data
shows that the final performance on a target task can be improved when the
appropriate pre-training data is included in fine-tuning. With the insight of
the theoretical finding, we propose a novel selection strategy to select a
subset from pre-training data to help improve the generalization on the target
task. Extensive experimental results for image classification tasks on 8
benchmark data sets verify the effectiveness of the proposed data selection
based fine-tuning pipeline.

    

### [[2111.12295] Animal Behavior Classification via Deep Learning on Embedded Systems](http://arxiv.org/abs/2111.12295)


  We develop an end-to-end deep-neural-network-based algorithm for classifying
animal behavior using accelerometry data on the embedded system of an
artificial intelligence of things (AIoT) device installed in a wearable collar
tag. The proposed algorithm jointly performs feature extraction and
classification utilizing a set of infinite-impulse-response (IIR) and
finite-impulse-response (FIR) filters together with a multilayer perceptron.
The utilized IIR and FIR filters can be viewed as specific types of recurrent
and convolutional neural network layers, respectively. We evaluate the
performance of the proposed algorithm via two real-world datasets collected
from grazing cattle. The results show that the proposed algorithm offers good
intra- and inter-dataset classification accuracy and outperforms its closest
contenders including two state-of-the-art convolutional-neural-network-based
time-series classification algorithms, which are significantly more complex. We
implement the proposed algorithm on the embedded system of the collar tag's
AIoT device to perform in-situ classification of animal behavior. We achieve
real-time in-situ behavior inference from accelerometry data without imposing
any strain on the available computational, memory, or energy resources of the
embedded system.

    

### [[2111.12299] EH-DNAS: End-to-End Hardware-aware Differentiable Neural Architecture Search](http://arxiv.org/abs/2111.12299)


  In hardware-aware Differentiable Neural Architecture Search (DNAS), it is
challenging to compute gradients of hardware metrics to perform architecture
search. Existing works rely on linear approximations with limited support to
customized hardware accelerators. In this work, we propose End-to-end
Hardware-aware DNAS (EH-DNAS), a seamless integration of end-to-end hardware
benchmarking, and fully automated DNAS to deliver hardware-efficient deep
neural networks on various platforms, including Edge GPUs, Edge TPUs, Mobile
CPUs, and customized accelerators. Given a desired hardware platform, we
propose to learn a differentiable model predicting the end-to-end hardware
performance of neural network architectures for DNAS. We also introduce
E2E-Perf, an end-to-end hardware benchmarking tool for customized accelerators.
Experiments on CIFAR10 and ImageNet show that EH-DNAS improves the hardware
performance by an average of $1.4\times$ on customized accelerators and
$1.6\times$ on existing hardware processors while maintaining the
classification accuracy.

    

### [[2111.12305] Thundernna: a white box adversarial attack](http://arxiv.org/abs/2111.12305)


  The existing work shows that the neural network trained by naive
gradient-based optimization method is prone to adversarial attacks, adds small
malicious on the ordinary input is enough to make the neural network wrong. At
the same time, the attack against a neural network is the key to improving its
robustness. The training against adversarial examples can make neural networks
resist some kinds of adversarial attacks. At the same time, the adversarial
attack against a neural network can also reveal some characteristics of the
neural network, a complex high-dimensional non-linear function, as discussed in
previous work.
In This project, we develop a first-order method to attack the neural
network. Compare with other first-order attacks, our method has a much higher
success rate. Furthermore, it is much faster than second-order attacks and
multi-steps first-order attacks.

    

### [[2111.12306] Efficient and Optimal Algorithms for Contextual Dueling Bandits under Realizability](http://arxiv.org/abs/2111.12306)


  We study the $K$-armed contextual dueling bandit problem, a sequential
decision making setting in which the learner uses contextual information to
make two decisions, but only observes \emph{preference-based feedback}
suggesting that one decision was better than the other. We focus on the regret
minimization problem under realizability, where the feedback is generated by a
pairwise preference matrix that is well-specified by a given function class
$\mathcal F$. We provide a new algorithm that achieves the optimal regret rate
for a new notion of best response regret, which is a strictly stronger
performance measure than those considered in prior works. The algorithm is also
computationally efficient, running in polynomial time assuming access to an
online oracle for square loss regression over $\mathcal F$. This resolves an
open problem of DudÃ­k et al. [2015] on oracle efficient, regret-optimal
algorithms for contextual dueling bandits.

    

### [[2111.12316] A comment on stabilizing reinforcement learning](http://arxiv.org/abs/2111.12316)


  This is a short comment on the paper "Asymptotically Stable Adaptive-Optimal
Control Algorithm With Saturating Actuators and Relaxed Persistence of
Excitation" by Vamvoudakis et al. The question of stability of reinforcement
learning (RL) agents remains hard and the said work suggested an on-policy
approach with a suitable stability property using a technique from adaptive
control - a robustifying term to be added to the action. However, there is an
issue with this approach to stabilizing RL, which we will explain in this note.
Furthermore, Vamvoudakis et al. seems to have made a fallacious assumption on
the Hamiltonian under a generic policy. To provide a positive result, we will
not only indicate this mistake, but show critic neural network weight
convergence under a stochastic, continuous-time environment, provided certain
conditions on the behavior policy hold.

    

### [[2111.12350] Supervised Neural Discrete Universal Denoiser for Adaptive Denoising](http://arxiv.org/abs/2111.12350)


  We improve the recently developed Neural DUDE, a neural network-based
adaptive discrete denoiser, by combining it with the supervised learning
framework. Namely, we make the supervised pre-training of Neural DUDE
compatible with the adaptive fine-tuning of the parameters based on the given
noisy data subject to denoising. As a result, we achieve a significant
denoising performance boost compared to the vanilla Neural DUDE, which only
carries out the adaptive fine-tuning step with randomly initialized parameters.
Moreover, we show the adaptive fine-tuning makes the algorithm robust such that
a noise-mismatched or blindly trained supervised model can still achieve the
performance of that of the matched model. Furthermore, we make a few
algorithmic advancements to make Neural DUDE more scalable and deal with
multi-dimensional data or data with larger alphabet size. We systematically
show our improvements on two very diverse datasets, binary images and DNA
sequences.

    

### [[2111.12370] Uniform Convergence Rates for Lipschitz Learning on Graphs](http://arxiv.org/abs/2111.12370)


  Lipschitz learning is a graph-based semi-supervised learning method where one
extends labels from a labeled to an unlabeled data set by solving the infinity
Laplace equation on a weighted graph. In this work we prove uniform convergence
rates for solutions of the graph infinity Laplace equation as the number of
vertices grows to infinity. Their continuum limits are absolutely minimizing
Lipschitz extensions with respect to the geodesic metric of the domain where
the graph vertices are sampled from. We work under very general assumptions on
the graph weights, the set of labeled vertices, and the continuum domain. Our
main contribution is that we obtain quantitative convergence rates even for
very sparsely connected graphs, as they typically appear in applications like
semi-supervised learning. In particular, our framework allows for graph
bandwidths down to the connectivity radius. For proving this we first show a
quantitative convergence statement for graph distance functions to geodesic
distance functions in the continuum. Using the "comparison with distance
functions" principle, we can pass these convergence statements to infinity
harmonic functions and absolutely minimizing Lipschitz extensions.

    

### [[2111.12389] Track Boosting and Synthetic Data Aided Drone Detection](http://arxiv.org/abs/2111.12389)


  As the usage of drones increases with lowered costs and improved drone
technology, drone detection emerges as a vital object detection task. However,
detecting distant drones under unfavorable conditions, namely weak contrast,
long-range, low visibility, requires effective algorithms. Our method
approaches the drone detection problem by fine-tuning a YOLOv5 model with real
and synthetically generated data using a Kalman-based object tracker to boost
detection confidence. Our results indicate that augmenting the real data with
an optimal subset of synthetic data can increase the performance. Moreover,
temporal information gathered by object tracking methods can increase
performance further.

    

### [[2111.12399] Dictionary-based Low-Rank Approximations and the Mixed Sparse Coding problem](http://arxiv.org/abs/2111.12399)


  Constrained tensor and matrix factorization models allow to extract
interpretable patterns from multiway data. Therefore identifiability properties
and efficient algorithms for constrained low-rank approximations are nowadays
important research topics. This work deals with columns of factor matrices of a
low-rank approximation being sparse in a known and possibly overcomplete basis,
a model coined as Dictionary-based Low-Rank Approximation (DLRA). While earlier
contributions focused on finding factor columns inside a dictionary of
candidate columns, i.e. one-sparse approximations, this work is the first to
tackle DLRA with sparsity larger than one. I propose to focus on the
sparse-coding subproblem coined Mixed Sparse-Coding (MSC) that emerges when
solving DLRA with an alternating optimization strategy. Several algorithms
based on sparse-coding heuristics (greedy methods, convex relaxations) are
provided to solve MSC. The performance of these heuristics is evaluated on
simulated data. Then, I show how to adapt an efficient MSC solver based on the
LASSO to compute Dictionary-based Matrix Factorization and Canonical Polyadic
Decomposition in the context of hyperspectral image processing and
chemometrics. These experiments suggest that DLRA extends the modeling
capabilities of low-rank approximations, helps reducing estimation variance and
enhances the identifiability and interpretability of estimated factors.

    

### [[2111.12406] Auto robust relative radiometric normalization via latent change noise modelling](http://arxiv.org/abs/2111.12406)


  Relative radiometric normalization(RRN) of different satellite images of the
same terrain is necessary for change detection, object
classification/segmentation, and map-making tasks. However, traditional RRN
models are not robust, disturbing by object change, and RRN models precisely
considering object change can not robustly obtain the no-change set. This paper
proposes auto robust relative radiometric normalization methods via latent
change noise modeling. They utilize the prior knowledge that no change points
possess small-scale noise under relative radiometric normalization and that
change points possess large-scale radiometric noise after radiometric
normalization, combining the stochastic expectation maximization method to
quickly and robustly extract the no-change set to learn the relative
radiometric normalization mapping functions. This makes our model theoretically
grounded regarding the probabilistic theory and mathematics deduction.
Specifically, when we select histogram matching as the relative radiometric
normalization learning scheme integrating with the mixture of Gaussian
noise(HM-RRN-MoG), the HM-RRN-MoG model achieves the best performance. Our
model possesses the ability to robustly against clouds/fogs/changes. Our method
naturally generates a robust evaluation indicator for RRN that is the no-change
set root mean square error. We apply the HM-RRN-MoG model to the latter
vegetation/water change detection task, which reduces the radiometric contrast
and NDVI/NDWI differences on the no-change set, generates consistent and
comparable results. We utilize the no-change set into the building change
detection task, efficiently reducing the pseudo-change and boosting the
precision.

    

### [[2111.12427] Challenges of Adversarial Image Augmentations](http://arxiv.org/abs/2111.12427)


  Image augmentations applied during training are crucial for the
generalization performance of image classifiers. Therefore, a large body of
research has focused on finding the optimal augmentation policy for a given
task. Yet, RandAugment [2], a simple random augmentation policy, has recently
been shown to outperform existing sophisticated policies. Only Adversarial
AutoAugment (AdvAA) [11], an approach based on the idea of adversarial
training, has shown to be better than RandAugment. In this paper, we show that
random augmentations are still competitive compared to an optimal adversarial
approach, as well as to simple curricula, and conjecture that the success of
AdvAA is due to the stochasticity of the policy controller network, which
introduces a mild form of curriculum.

    

### [[2111.12429] tsflex: flexible time series processing & feature extraction](http://arxiv.org/abs/2111.12429)


  Time series processing and feature extraction are crucial and time-intensive
steps in conventional machine learning pipelines. Existing packages are limited
in their real-world applicability, as they cannot cope with irregularly-sampled
and asynchronous data. We therefore present $\texttt{tsflex}$, a
domain-independent, flexible, and sequence first Python toolkit for processing
& feature extraction, that is capable of handling irregularly-sampled sequences
with unaligned measurements. This toolkit is sequence first as (1) sequence
based arguments are leveraged for strided-window feature extraction, and (2)
the sequence-index is maintained through all supported operations.
$\texttt{tsflex}$ is flexible as it natively supports (1) multivariate time
series, (2) multiple window-stride configurations, and (3) integrates with
processing and feature functions from other packages, while (4) making no
assumptions about the data sampling rate regularity and synchronization. Other
functionalities from this package are multiprocessing, in-depth execution time
logging, support for categorical & time based data, chunking sequences, and
embedded serialization. $\texttt{tsflex}$ is developed to enable fast and
memory-efficient time series processing & feature extraction. Results indicate
that $\texttt{tsflex}$ is more flexible than similar packages while
outperforming these toolkits in both runtime and memory usage.

    

### [[2111.12448] 3D Shape Variational Autoencoder Latent Disentanglement via Mini-Batch Feature Swapping for Bodies and Faces](http://arxiv.org/abs/2111.12448)


  Learning a disentangled, interpretable, and structured latent representation
in 3D generative models of faces and bodies is still an open problem. The
problem is particularly acute when control over identity features is required.
In this paper, we propose an intuitive yet effective self-supervised approach
to train a 3D shape variational autoencoder (VAE) which encourages a
disentangled latent representation of identity features. Curating the
mini-batch generation by swapping arbitrary features across different shapes
allows to define a loss function leveraging known differences and similarities
in the latent representations. Experimental results conducted on 3D meshes show
that state-of-the-art methods for latent disentanglement are not able to
disentangle identity features of faces and bodies. Our proposed method properly
decouples the generation of such features while maintaining good representation
and reconstruction capabilities.

    

### [[2111.12460] ViCE: Self-Supervised Visual Concept Embeddings as Contextual and Pixel Appearance Invariant Semantic Representations](http://arxiv.org/abs/2111.12460)


  This work presents a self-supervised method to learn dense semantically rich
visual concept embeddings for images inspired by methods for learning word
embeddings in NLP. Our method improves on prior work by generating more
expressive embeddings and by being applicable for high-resolution images.
Viewing the generation of natural images as a stochastic process where a set of
latent visual concepts give rise to observable pixel appearances, our method is
formulated to learn the inverse mapping from pixels to concepts. Our method
greatly improves the effectiveness of self-supervised learning for dense
embedding maps by introducing superpixelization as a natural hierarchical step
up from pixels to a small set of visually coherent regions. Additional
contributions are regional contextual masking with nonuniform shapes matching
visually coherent patches and complexity-based view sampling inspired by masked
language models. The enhanced expressiveness of our dense embeddings is
demonstrated by significantly improving the state-of-the-art representation
quality benchmarks on COCO (+12.94 mIoU, +87.6\%) and Cityscapes (+16.52 mIoU,
+134.2\%). Results show favorable scaling and domain generalization properties
not demonstrated by prior work.

    

### [[2111.12477] Selection of pseudo-annotated data for adverse drug reaction classification across drug groups](http://arxiv.org/abs/2111.12477)


  Automatic monitoring of adverse drug events (ADEs) or reactions (ADRs) is
currently receiving significant attention from the biomedical community. In
recent years, user-generated data on social media has become a valuable
resource for this task. Neural models have achieved impressive performance on
automatic text classification for ADR detection. Yet, training and evaluation
of these methods are carried out on user-generated texts about a targeted drug.
In this paper, we assess the robustness of state-of-the-art neural
architectures across different drug groups. We investigate several strategies
to use pseudo-labeled data in addition to a manually annotated train set.
Out-of-dataset experiments diagnose the bottleneck of supervised models in
terms of breakdown performance, while additional pseudo-labeled data improves
overall results regardless of the text selection strategy.

    

### [[2111.12480] Octree Transformer: Autoregressive 3D Shape Generation on Hierarchically Structured Sequences](http://arxiv.org/abs/2111.12480)


  Autoregressive models have proven to be very powerful in NLP text generation
tasks and lately have gained popularity for image generation as well. However,
they have seen limited use for the synthesis of 3D shapes so far. This is
mainly due to the lack of a straightforward way to linearize 3D data as well as
to scaling problems with the length of the resulting sequences when describing
complex shapes. In this work we address both of these problems. We use octrees
as a compact hierarchical shape representation that can be sequentialized by
traversal ordering. Moreover, we introduce an adaptive compression scheme, that
significantly reduces sequence lengths and thus enables their effective
generation with a transformer, while still allowing fully autoregressive
sampling and parallel training. We demonstrate the performance of our model by
comparing against the state-of-the-art in shape generation.

    

### [[2111.12482] One More Step Towards Reality: Cooperative Bandits with Imperfect Communication](http://arxiv.org/abs/2111.12482)


  The cooperative bandit problem is increasingly becoming relevant due to its
applications in large-scale decision-making. However, most research for this
problem focuses exclusively on the setting with perfect communication, whereas
in most real-world distributed settings, communication is often over stochastic
networks, with arbitrary corruptions and delays. In this paper, we study
cooperative bandit learning under three typical real-world communication
scenarios, namely, (a) message-passing over stochastic time-varying networks,
(b) instantaneous reward-sharing over a network with random delays, and (c)
message-passing with adversarially corrupted rewards, including byzantine
communication. For each of these environments, we propose decentralized
algorithms that achieve competitive performance, along with near-optimal
guarantees on the incurred group regret as well. Furthermore, in the setting
with perfect communication, we present an improved delayed-update algorithm
that outperforms the existing state-of-the-art on various network topologies.
Finally, we present tight network-dependent minimax lower bounds on the group
regret. Our proposed algorithms are straightforward to implement and obtain
competitive empirical performance.

    

### [[2111.12485] Graph Modularity: Towards Understanding the Cross-Layer Transition of Feature Representations in Deep Neural Networks](http://arxiv.org/abs/2111.12485)


  There are good arguments to support the claim that feature representations
eventually transition from general to specific in deep neural networks (DNNs),
but this transition remains relatively underexplored. In this work, we move a
tiny step towards understanding the transition of feature representations. We
first characterize this transition by analyzing the class separation in
intermediate layers, and next model the process of class separation as
community evolution in dynamic graphs. Then, we introduce modularity, a common
metric in graph theory, to quantify the evolution of communities. We find that
modularity tends to rise as the layer goes deeper, but descends or reaches a
plateau at particular layers. Through an asymptotic analysis, we show that
modularity can provide quantitative analysis of the transition of the feature
representations. With the insight on feature representations, we demonstrate
that modularity can also be used to identify and locate redundant layers in
DNNs, which provides theoretical guidance for layer pruning. Based on this
inspiring finding, we propose a layer-wise pruning method based on modularity.
Further experiments show that our method can prune redundant layers with
minimal impact on performance. The codes are available at
this https URL.

    

### [[2111.12488] Intuitive Shape Editing in Latent Space](http://arxiv.org/abs/2111.12488)


  The use of autoencoders for shape generation and editing suffers from
manipulations in latent space that may lead to unpredictable changes in the
output shape. We present an autoencoder-based method that enables intuitive
shape editing in latent space by disentangling latent sub-spaces to obtain
control points on the surface and style variables that can be manipulated
independently. The key idea is adding a Lipschitz-type constraint to the loss
function, i.e. bounding the change of the output shape proportionally to the
change in latent space, leading to interpretable latent space representations.
The control points on the surface can then be freely moved around, allowing for
intuitive shape editing directly in latent space. We evaluate our method by
comparing it to state-of-the-art data-driven shape editing methods. Besides
shape manipulation, we demonstrate the expressiveness of our control points by
leveraging them for unsupervised part segmentation.

    

### [[2111.12490] Causal Regularization Using Domain Priors](http://arxiv.org/abs/2111.12490)


  Neural networks leverage both causal and correlation-based relationships in
data to learn models that optimize a given performance criterion, such as
classification accuracy. This results in learned models that may not
necessarily reflect the true causal relationships between input and output.
When domain priors of causal relationships are available at the time of
training, it is essential that a neural network model maintains these
relationships as causal, even as it learns to optimize the performance
criterion. We propose a causal regularization method that can incorporate such
causal domain priors into the network and which supports both direct and total
causal effects. We show that this approach can generalize to various kinds of
specifications of causal priors, including monotonicity of causal effect of a
given input feature or removing a certain influence for purposes of fairness.
Our experiments on eleven benchmark datasets show the usefulness of this
approach in regularizing a learned neural network model to maintain desired
causal effects. On most datasets, domain-prior consistent models can be
obtained without compromising on accuracy.

    

### [[2111.12495] Softmax Gradient Tampering: Decoupling the Backward Pass for Improved Fitting](http://arxiv.org/abs/2111.12495)


  We introduce Softmax Gradient Tampering, a technique for modifying the
gradients in the backward pass of neural networks in order to enhance their
accuracy. Our approach transforms the predicted probability values using a
power-based probability transformation and then recomputes the gradients in the
backward pass. This modification results in a smoother gradient profile, which
we demonstrate empirically and theoretically. We do a grid search for the
transform parameters on residual networks. We demonstrate that modifying the
softmax gradients in ConvNets may result in increased training accuracy, thus
increasing the fit across the training data and maximally utilizing the
learning capacity of neural networks. We get better test metrics and lower
generalization gaps when combined with regularization techniques such as label
smoothing. Softmax gradient tampering improves ResNet-50's test accuracy by
$0.52\%$ over the baseline on the ImageNet dataset. Our approach is very
generic and may be used across a wide range of different network architectures
and datasets.

    

### [[2111.12506] A Unified Approach to Variational Autoencoders and Stochastic Normalizing Flows via Markov Chains](http://arxiv.org/abs/2111.12506)


  Normalizing flows, diffusion normalizing flows and variational autoencoders
are powerful generative models. In this paper, we provide a unified framework
to handle these approaches via Markov chains. Indeed, we consider stochastic
normalizing flows as pair of Markov chains fulfilling some properties and show
that many state-of-the-art models for data generation fit into this framework.
The Markov chains point of view enables us to couple both deterministic layers
as invertible neural networks and stochastic layers as Metropolis-Hasting
layers, Langevin layers and variational autoencoders in a mathematically sound
way. Besides layers with densities as Langevin layers, diffusion layers or
variational autoencoders, also layers having no densities as deterministic
layers or Metropolis-Hasting layers can be handled. Hence our framework
establishes a useful mathematical tool to combine the various approaches.

    

### [[2111.12516] LightSAFT: Lightweight Latent Source Aware Frequency Transform for Source Separation](http://arxiv.org/abs/2111.12516)


  Conditioned source separations have attracted significant attention because
of their flexibility, applicability and extensionality. Their performance was
usually inferior to the existing approaches, such as the single source
separation model. However, a recently proposed method called LaSAFT-Net has
shown that conditioned models can show comparable performance against existing
single-source separation models. This paper presents LightSAFT-Net, a
lightweight version of LaSAFT-Net. As a baseline, it provided a sufficient SDR
performance for comparison during the Music Demixing Challenge at ISMIR 2021.
This paper also enhances the existing LightSAFT-Net by replacing the LightSAFT
blocks in the encoder with TFC-TDF blocks. Our enhanced LightSAFT-Net
outperforms the previous one with fewer parameters.

    

### [[2111.12526] Mining Meta-indicators of University Ranking: A Machine Learning Approach Based on SHAP](http://arxiv.org/abs/2111.12526)


  University evaluation and ranking is an extremely complex activity. Major
universities are struggling because of increasingly complex indicator systems
of world university rankings. So can we find the meta-indicators of the index
system by simplifying the complexity? This research discovered three
meta-indicators based on interpretable machine learning. The first one is time,
to be friends with time, and believe in the power of time, and accumulate
historical deposits; the second one is space, to be friends with city, and grow
together by co-develop; the third one is relationships, to be friends with
alumni, and strive for more alumni donations without ceiling.

    

### [[2111.12531] Non-Intrusive Binaural Speech Intelligibility Prediction from Discrete Latent Representations](http://arxiv.org/abs/2111.12531)


  Non-intrusive speech intelligibility (SI) prediction from binaural signals is
useful in many applications. However, most existing signal-based measures are
designed to be applied to single-channel signals. Measures specifically
designed to take into account the binaural properties of the signal are often
intrusive - characterised by requiring access to a clean speech signal - and
typically rely on combining both channels into a single-channel signal before
making predictions. This paper proposes a non-intrusive SI measure that
computes features from a binaural input signal using a combination of vector
quantization (VQ) and contrastive predictive coding (CPC) methods. VQ-CPC
feature extraction does not rely on any model of the auditory system and is
instead trained to maximise the mutual information between the input signal and
output features. The computed VQ-CPC features are input to a predicting
function parameterized by a neural network. Two predicting functions are
considered in this paper. Both feature extractor and predicting functions are
trained on simulated binaural signals with isotropic noise. They are tested on
simulated signals with isotropic and real noise. For all signals, the ground
truth scores are the (intrusive) deterministic binaural STOI. Results are
presented in terms of correlations and MSE and demonstrate that VQ-CPC features
are able to capture information relevant to modelling SI and outperform all the
considered benchmarks - even when evaluating on data comprising of different
noise field types.

    

### [[2111.12545] Learning to Refit for Convex Learning Problems](http://arxiv.org/abs/2111.12545)


  Machine learning (ML) models need to be frequently retrained on changing
datasets in a wide variety of application scenarios, including data valuation
and uncertainty quantification. To efficiently retrain the model, linear
approximation methods such as influence function have been proposed to estimate
the impact of data changes on model parameters. However, these methods become
inaccurate for large dataset changes. In this work, we focus on convex learning
problems and propose a general framework to learn to estimate optimized model
parameters for different training sets using neural networks. We propose to
enforce the predicted model parameters to obey optimality conditions and
maintain utility through regularization techniques, which significantly improve
generalization. Moreover, we rigorously characterize the expressive power of
neural networks to approximate the optimizer of convex problems. Empirical
results demonstrate the advantage of the proposed method in accurate and
efficient model parameter estimation compared to the state-of-the-art.

    

### [[2111.12548] AutoDC: Automated data-centric processing](http://arxiv.org/abs/2111.12548)


  AutoML (automated machine learning) has been extensively developed in the
past few years for the model-centric approach. As for the data-centric
approach, the processes to improve the dataset, such as fixing incorrect
labels, adding examples that represent edge cases, and applying data
augmentation, are still very artisanal and expensive. Here we develop an
automated data-centric tool (AutoDC), similar to the purpose of AutoML, aims to
speed up the dataset improvement processes. In our preliminary tests on 3 open
source image classification datasets, AutoDC is estimated to reduce roughly 80%
of the manual time for data improvement tasks, at the same time, improve the
model accuracy by 10-15% with the fixed ML code.

    

### [[2111.12550] A Worker-Task Specialization Model for Crowdsourcing: Efficient Inference and Fundamental Limits](http://arxiv.org/abs/2111.12550)


  Crowdsourcing system has emerged as an effective platform to label data with
relatively low cost by using non-expert workers. However, inferring correct
labels from multiple noisy answers on data has been a challenging problem,
since the quality of answers varies widely across tasks and workers. Many
previous works have assumed a simple model where the order of workers in terms
of their reliabilities is fixed across tasks, and focused on estimating the
worker reliabilities to aggregate answers with different weights. We propose a
highly general $d$-type worker-task specialization model in which the
reliability of each worker can change depending on the type of a given task,
where the number $d$ of types can scale in the number of tasks. In this model,
we characterize the optimal sample complexity to correctly infer labels with
any given recovery accuracy, and propose an inference algorithm achieving the
order-wise optimal bound. We conduct experiments both on synthetic and
real-world datasets, and show that our algorithm outperforms the existing
algorithms developed based on strict model assumptions.

    

### [[2111.12577] A Method for Evaluating the Capacity of Generative Adversarial Networks to Reproduce High-order Spatial Context](http://arxiv.org/abs/2111.12577)


  Generative adversarial networks are a kind of deep generative model with the
potential to revolutionize biomedical imaging. This is because GANs have a
learned capacity to draw whole-image variates from a lower-dimensional
representation of an unknown, high-dimensional distribution that fully
describes the input training images. The overarching problem with GANs in
clinical applications is that there is not adequate or automatic means of
assessing the diagnostic quality of images generated by GANs. In this work, we
demonstrate several tests of the statistical accuracy of images output by two
popular GAN architectures. We designed several stochastic object models (SOMs)
of distinct features that can be recovered after generation by a trained GAN.
Several of these features are high-order, algorithmic pixel-arrangement rules
which are not readily expressed in covariance matrices. We designed and
validated statistical classifiers to detect the known arrangement rules. We
then tested the rates at which the different GANs correctly reproduced the
rules under a variety of training scenarios and degrees of feature-class
similarity. We found that ensembles of generated images can appear accurate
visually, and correspond to low Frechet Inception Distance scores (FID), while
not exhibiting the known spatial arrangements. Furthermore, GANs trained on a
spectrum of distinct spatial orders did not respect the given prevalence of
those orders in the training data. The main conclusion is that while low-order
ensemble statistics are largely correct, there are numerous quantifiable errors
per image that plausibly can affect subsequent use of the GAN-generated images.

    

### [[2111.12583] Optimizing Latent Space Directions For GAN-based Local Image Editing](http://arxiv.org/abs/2111.12583)


  Generative Adversarial Network (GAN) based localized image editing can suffer
ambiguity between semantic attributes. We thus present a novel objective
function to evaluate the locality of an image edit. By introducing the
supervision from a pre-trained segmentation network and optimizing the
objective function, our framework, called Locally Effective Latent Space
Direction (LELSD), is applicable to any dataset and GAN architecture. Our
method is also computationally fast and exhibits a high extent of
disentanglement, which allows users to interactively perform a sequence of
edits on an image. Our experiments on both GAN-generated and real images
qualitatively demonstrate the high quality and advantages of our method.

    

### [[2111.12588] Towards Cross-Cultural Analysis using Music Information Dynamics](http://arxiv.org/abs/2111.12588)


  A music piece is both comprehended hierarchically, from sonic events to
melodies, and sequentially, in the form of repetition and variation. Music from
different cultures establish different aesthetics by having different style
conventions on these two aspects. We propose a framework that could be used to
quantitatively compare music from different cultures by looking at these two
aspects.
The framework is based on an Music Information Dynamics model, a Variable
Markov Oracle (VMO), and is extended with a variational representation learning
of audio. A variational autoencoder (VAE) is trained to map audio fragments
into a latent representation. The latent representation is fed into a VMO. The
VMO then learns a clustering of the latent representation via a threshold that
maximizes the information rate of the quantized latent representation sequence.
This threshold effectively controls the sensibility of the predictive step to
acoustic changes, which determines the framework's ability to track repetitions
on longer time scales. This approach allows characterization of the overall
information contents of a musical signal at each level of acoustic sensibility.
Our findings under this framework show that sensibility to subtle acoustic
changes is higher for East-Asian musical traditions, while the Western works
exhibit longer motivic structures at higher thresholds of differences in the
latent space. This suggests that a profile of information contents, analyzed as
a function of the level of acoustic detail can serve as a possible cultural
characteristic.

    

### [[2111.12594] Conditional Object-Centric Learning from Video](http://arxiv.org/abs/2111.12594)


  Object-centric representations are a promising path toward more systematic
generalization by providing flexible abstractions upon which compositional
world models can be built. Recent work on simple 2D and 3D datasets has shown
that models with object-centric inductive biases can learn to segment and
represent meaningful objects from the statistical structure of the data alone
without the need for any supervision. However, such fully-unsupervised methods
still fail to scale to diverse realistic data, despite the use of increasingly
complex inductive biases such as priors for the size of objects or the 3D
geometry of the scene. In this paper, we instead take a weakly-supervised
approach and focus on how 1) using the temporal dynamics of video data in the
form of optical flow and 2) conditioning the model on simple object location
cues can be used to enable segmenting and tracking objects in significantly
more realistic synthetic data. We introduce a sequential extension to Slot
Attention which we train to predict optical flow for realistic looking
synthetic scenes and show that conditioning the initial state of this model on
a small set of hints, such as center of mass of objects in the first frame, is
sufficient to significantly improve instance segmentation. These benefits
generalize beyond the training distribution to novel objects, novel
backgrounds, and to longer video sequences. We also find that such
initial-state-conditioning can be used during inference as a flexible interface
to query the model for specific objects or parts of objects, which could pave
the way for a range of weakly-supervised approaches and allow more effective
interaction with trained models.

    

### [[2111.12600] Learning State Representations via Retracing in Reinforcement Learning](http://arxiv.org/abs/2111.12600)


  We propose learning via retracing, a novel self-supervised approach for
learning the state representation (and the associated dynamics model) for
reinforcement learning tasks. In addition to the predictive (reconstruction)
supervision in the forward direction, we propose to include `"retraced"
transitions for representation/model learning, by enforcing the
cycle-consistency constraint between the original and retraced states, hence
improve upon the sample efficiency of learning. Moreover, learning via
retracing explicitly propagates information about future transitions backward
for inferring previous states, thus facilitates stronger representation
learning. We introduce Cycle-Consistency World Model (CCWM), a concrete
instantiation of learning via retracing implemented under existing model-based
reinforcement learning framework. Additionally we propose a novel adaptive
"truncation" mechanism for counteracting the negative impacts brought by the
"irreversible" transitions such that learning via retracing can be maximally
effective. Through extensive empirical studies on continuous control
benchmarks, we demonstrates that CCWM achieves state-of-the-art performance in
terms of sample efficiency and asymptotic performance.

    

### [[2111.12602] Hierarchical Graph-Convolutional Variational AutoEncoding for Generative Modelling of Human Motion](http://arxiv.org/abs/2111.12602)


  Models of human motion commonly focus either on trajectory prediction or
action classification but rarely both. The marked heterogeneity and intricate
compositionality of human motion render each task vulnerable to the data
degradation and distributional shift common to real-world scenarios. A
sufficiently expressive generative model of action could in theory enable data
conditioning and distributional resilience within a unified framework
applicable to both tasks. Here we propose a novel architecture based on
hierarchical variational autoencoders and deep graph convolutional neural
networks for generating a holistic model of action over multiple time-scales.
We show this Hierarchical Graph-convolutional Variational Autoencoder (HG-VAE)
to be capable of generating coherent actions, detecting out-of-distribution
data, and imputing missing data by gradient ascent on the model's posterior.
Trained and evaluated on H3.6M and the largest collection of open source human
motion data, AMASS, we show HG-VAE can facilitate downstream discriminative
learning better than baseline models.

    

### [[2111.12606] Deep metric learning improves lab of origin prediction of genetically engineered plasmids](http://arxiv.org/abs/2111.12606)


  Genome engineering is undergoing unprecedented development and is now
becoming widely available. To ensure responsible biotechnology innovation and
to reduce misuse of engineered DNA sequences, it is vital to develop tools to
identify the lab-of-origin of engineered plasmids. Genetic engineering
attribution (GEA), the ability to make sequence-lab associations, would support
forensic experts in this process. Here, we propose a method, based on metric
learning, that ranks the most likely labs-of-origin whilst simultaneously
generating embeddings for plasmid sequences and labs. These embeddings can be
used to perform various downstream tasks, such as clustering DNA sequences and
labs, as well as using them as features in machine learning models. Our
approach employs a circular shift augmentation approach and is able to
correctly rank the lab-of-origin $90\%$ of the time within its top 10
predictions - outperforming all current state-of-the-art approaches. We also
demonstrate that we can perform few-shot-learning and obtain $76\%$ top-10
accuracy using only $10\%$ of the sequences. This means, we outperform the
previous CNN approach using only one-tenth of the data. We also demonstrate
that we are able to extract key signatures in plasmid sequences for particular
labs, allowing for an interpretable examination of the model's outputs.

    

### [[2111.12621] Accelerating Deep Learning with Dynamic Data Pruning](http://arxiv.org/abs/2111.12621)


  Deep learning's success has been attributed to the training of large,
overparameterized models on massive amounts of data. As this trend continues,
model training has become prohibitively costly, requiring access to powerful
computing systems to train state-of-the-art networks. A large body of research
has been devoted to addressing the cost per iteration of training through
various model compression techniques like pruning and quantization. Less effort
has been spent targeting the number of iterations. Previous work, such as
forget scores and GraNd/EL2N scores, address this problem by identifying
important samples within a full dataset and pruning the remaining samples,
thereby reducing the iterations per epoch. Though these methods decrease the
training time, they use expensive static scoring algorithms prior to training.
When accounting for the scoring mechanism, the total run time is often
increased. In this work, we address this shortcoming with dynamic data pruning
algorithms. Surprisingly, we find that uniform random dynamic pruning can
outperform the prior work at aggressive pruning rates. We attribute this to the
existence of "sometimes" samples -- points that are important to the learned
decision boundary only some of the training time. To better exploit the
subtlety of sometimes samples, we propose two algorithms, based on
reinforcement learning techniques, to dynamically prune samples and achieve
even higher accuracy than the random dynamic method. We test all our methods
against a full-dataset baseline and the prior work on CIFAR-10 and CIFAR-100,
and we can reduce the training time by up to 2x without significant performance
loss. Our results suggest that data pruning should be understood as a dynamic
process that is closely tied to a model's training trajectory, instead of a
static step based solely on the dataset alone.

    

### [[2111.12628] Efficient Decompositional Rule Extraction for Deep Neural Networks](http://arxiv.org/abs/2111.12628)


  In recent years, there has been significant work on increasing both
interpretability and debuggability of a Deep Neural Network (DNN) by extracting
a rule-based model that approximates its decision boundary. Nevertheless,
current DNN rule extraction methods that consider a DNN's latent space when
extracting rules, known as decompositional algorithms, are either restricted to
single-layer DNNs or intractable as the size of the DNN or data grows. In this
paper, we address these limitations by introducing ECLAIRE, a novel
polynomial-time rule extraction algorithm capable of scaling to both large DNN
architectures and large training datasets. We evaluate ECLAIRE on a wide
variety of tasks, ranging from breast cancer prognosis to particle detection,
and show that it consistently extracts more accurate and comprehensible rule
sets than the current state-of-the-art methods while using orders of magnitude
less computational resources. We make all of our methods available, including a
rule set visualisation interface, through the open-source REMIX library
(this https URL).

    

### [[2111.12665] Finite-Time Error Bounds for Distributed Linear Stochastic Approximation](http://arxiv.org/abs/2111.12665)


  This paper considers a novel multi-agent linear stochastic approximation
algorithm driven by Markovian noise and general consensus-type interaction, in
which each agent evolves according to its local stochastic approximation
process which depends on the information from its neighbors. The
interconnection structure among the agents is described by a time-varying
directed graph. While the convergence of consensus-based stochastic
approximation algorithms when the interconnection among the agents is described
by doubly stochastic matrices (at least in expectation) has been studied, less
is known about the case when the interconnection matrix is simply stochastic.
For any uniformly strongly connected graph sequences whose associated
interaction matrices are stochastic, the paper derives finite-time bounds on
the mean-square error, defined as the deviation of the output of the algorithm
from the unique equilibrium point of the associated ordinary differential
equation. For the case of interconnection matrices being stochastic, the
equilibrium point can be any unspecified convex combination of the local
equilibria of all the agents in the absence of communication. Both the cases
with constant and time-varying step-sizes are considered. In the case when the
convex combination is required to be a straight average and interaction between
any pair of neighboring agents may be uni-directional, so that doubly
stochastic matrices cannot be implemented in a distributed manner, the paper
proposes a push-sum-type distributed stochastic approximation algorithm and
provides its finite-time bound for the time-varying step-size case by
leveraging the analysis for the consensus-type algorithm with stochastic
matrices and developing novel properties of the push-sum algorithm.

    

### [[2111.12673] Adaptively Calibrated Critic Estimates for Deep Reinforcement Learning](http://arxiv.org/abs/2111.12673)


  Accurate value estimates are important for off-policy reinforcement learning.
Algorithms based on temporal difference learning typically are prone to an
over- or underestimation bias building up over time. In this paper, we propose
a general method called Adaptively Calibrated Critics (ACC) that uses the most
recent high variance but unbiased on-policy rollouts to alleviate the bias of
the low variance temporal difference targets. We apply ACC to Truncated
Quantile Critics, which is an algorithm for continuous control that allows
regulation of the bias with a hyperparameter tuned per environment. The
resulting algorithm adaptively adjusts the parameter during training rendering
hyperparameter search unnecessary and sets a new state of the art on the OpenAI
gym continuous control benchmark among all algorithms that do not tune
hyperparameters for each environment. Additionally, we demonstrate that ACC is
quite general by further applying it to TD3 and showing an improved performance
also in this setting.

    

### [[2111.12679] Reinforcement Learning for General LTL Objectives Is Intractable](http://arxiv.org/abs/2111.12679)


  In recent years, researchers have made significant progress in devising
reinforcement-learning algorithms for optimizing linear temporal logic (LTL)
objectives and LTL-like objectives. Despite these advancements, there are
fundamental limitations to how well this problem can be solved that previous
studies have alluded to but, to our knowledge, have not examined in depth. In
this paper, we address theoretically the hardness of learning with general LTL
objectives. We formalize the problem under the probably approximately correct
learning in Markov decision processes (PAC-MDP) framework, a standard framework
for measuring sample complexity in reinforcement learning. In this
formalization, we prove that the optimal policy for any LTL formula is
PAC-MDP-learnable only if the formula is in the most limited class in the LTL
hierarchy, consisting of only finite-horizon-decidable properties. Practically,
our result implies that it is impossible for a reinforcement-learning algorithm
to obtain a PAC-MDP guarantee on the performance of its learned policy after
finitely many interactions with an unconstrained environment for
non-finite-horizon-decidable LTL objectives.

    

### [[2111.12680] An XGBoost-Based Forecasting Framework for Product Cannibalization](http://arxiv.org/abs/2111.12680)


  Two major challenges in demand forecasting are product cannibalization and
long term forecasting. Product cannibalization is a phenomenon in which high
demand of some products leads to reduction in sales of other products. Long
term forecasting involves forecasting the sales over longer time frame that is
critical for strategic business purposes. Also, conventional methods, for
instance, recurrent neural networks may be ineffective where train data size is
small as in the case in this study. This work presents XGBoost-based
three-stage framework that addresses product cannibalization and associated
long term error propagation problems. The performance of the proposed
three-stage XGBoost-based framework is compared to and is found superior than
that of regular XGBoost algorithm.

    

### [[2111.12683] Data-Based Models for Hurricane Evolution Prediction: A Deep Learning Approach](http://arxiv.org/abs/2111.12683)


  Fast and accurate prediction of hurricane evolution from genesis onwards is
needed to reduce loss of life and enhance community resilience. In this work, a
novel model development methodology for predicting storm trajectory is proposed
based on two classes of Recurrent Neural Networks (RNNs). The RNN models are
trained on input features available in or derived from the HURDAT2 North
Atlantic hurricane database maintained by the National Hurricane Center (NHC).
The models use probabilities of storms passing through any location, computed
from historical data. A detailed analysis of model forecasting error shows that
Many-To-One prediction models are less accurate than Many-To-Many models owing
to compounded error accumulation, with the exception of $6-hr$ predictions, for
which the two types of model perform comparably. Application to 75 or more test
storms in the North Atlantic basin showed that, for short-term forecasting up
to 12 hours, the Many-to-Many RNN storm trajectory prediction models presented
herein are significantly faster than ensemble models used by the NHC, while
leading to errors of comparable magnitude.

    

### [[2111.12689] A stacked deep convolutional neural network to predict the remaining useful life of a turbofan engine](http://arxiv.org/abs/2111.12689)


  This paper presents the data-driven techniques and methodologies used to
predict the remaining useful life (RUL) of a fleet of aircraft engines that can
suffer failures of diverse nature. The solution presented is based on two Deep
Convolutional Neural Networks (DCNN) stacked in two levels. The first DCNN is
used to extract a low-dimensional feature vector using the normalized raw data
as input. The second DCNN ingests a list of vectors taken from the former DCNN
and estimates the RUL. Model selection was carried out by means of Bayesian
optimization using a repeated random subsampling validation approach. The
proposed methodology was ranked in the third place of the 2021 PHM Conference
Data Challenge.

    

### [[2111.12701] Unleashing Transformers: Parallel Token Prediction with Discrete Absorbing Diffusion for Fast High-Resolution Image Generation from Vector-Quantized Codes](http://arxiv.org/abs/2111.12701)


  Whilst diffusion probabilistic models can generate high quality image
content, key limitations remain in terms of both generating high-resolution
imagery and their associated high computational requirements. Recent
Vector-Quantized image models have overcome this limitation of image resolution
but are prohibitively slow and unidirectional as they generate tokens via
element-wise autoregressive sampling from the prior. By contrast, in this paper
we propose a novel discrete diffusion probabilistic model prior which enables
parallel prediction of Vector-Quantized tokens by using an unconstrained
Transformer architecture as the backbone. During training, tokens are randomly
masked in an order-agnostic manner and the Transformer learns to predict the
original tokens. This parallelism of Vector-Quantized token prediction in turn
facilitates unconditional generation of globally consistent high-resolution and
diverse imagery at a fraction of the computational expense. In this manner, we
can generate image resolutions exceeding that of the original training set
samples whilst additionally provisioning per-image likelihood estimates (in a
departure from generative adversarial approaches). Our approach achieves
state-of-the-art results in terms of Density (LSUN Bedroom: 1.51; LSUN
Churches: 1.12; FFHQ: 1.20) and Coverage (LSUN Bedroom: 0.83; LSUN Churches:
0.73; FFHQ: 0.80), and performs competitively on FID (LSUN Bedroom: 3.64; LSUN
Churches: 4.07; FFHQ: 6.11) whilst offering advantages in terms of both
computation and reduced training set requirements.

    

### [[2111.12707] MHFormer: Multi-Hypothesis Transformer for 3D Human Pose Estimation](http://arxiv.org/abs/2111.12707)


  Estimating 3D human poses from monocular videos is a challenging task due to
depth ambiguity and self-occlusion. Most existing works attempt to solve both
issues by exploiting spatial and temporal relationships. However, those works
ignore the fact that it is an inverse problem where multiple feasible solutions
(i.e., hypotheses) exist. To relieve this limitation, we propose a
Multi-Hypothesis Transformer (MHFormer) that learns spatio-temporal
representations of multiple plausible pose hypotheses. In order to effectively
model multi-hypothesis dependencies and build strong relationships across
hypothesis features, the task is decomposed into three stages: (i) Generate
multiple initial hypothesis representations; (ii) Model self-hypothesis
communication, merge multiple hypotheses into a single converged representation
and then partition it into several diverged hypotheses; (iii) Learn
cross-hypothesis communication and aggregate the multi-hypothesis features to
synthesize the final 3D pose. Through the above processes, the final
representation is enhanced and the synthesized pose is much more accurate.
Extensive experiments show that MHFormer achieves state-of-the-art results on
two challenging datasets: Human3.6M and MPI-INF-3DHP. Without bells and
whistles, its performance surpasses the previous best result by a large margin
of 3% on Human3.6M. Code and models are available at
this https URL.

    

### [[2111.12710] PeCo: Perceptual Codebook for BERT Pre-training of Vision Transformers](http://arxiv.org/abs/2111.12710)


  This paper explores a better codebook for BERT pre-training of vision
transformers. The recent work BEiT successfully transfers BERT pre-training
from NLP to the vision field. It directly adopts one simple discrete VAE as the
visual tokenizer, but has not considered the semantic level of the resulting
visual tokens. By contrast, the discrete tokens in NLP field are naturally
highly semantic. This difference motivates us to learn a perceptual codebook.
And we surprisingly find one simple yet effective idea: enforcing perceptual
similarity during the dVAE training. We demonstrate that the visual tokens
generated by the proposed perceptual codebook do exhibit better semantic
meanings, and subsequently help pre-training achieve superior transfer
performance in various downstream tasks. For example, we achieve 84.5 Top-1
accuracy on ImageNet-1K with ViT-B backbone, outperforming the competitive
method BEiT by +1.3 with the same pre-training epochs. It can also improve the
performance of object detection and segmentation tasks on COCO val by +1.3 box
AP and +1.0 mask AP, semantic segmentation on ADE20k by +1.0 mIoU, The code and
models will be available at \url{this https URL}.

    

### [[1904.12218] Graph Kernels: A Survey](http://arxiv.org/abs/1904.12218)


  Graph kernels have attracted a lot of attention during the last decade, and
have evolved into a rapidly developing branch of learning on structured data.
During the past 20 years, the considerable research activity that occurred in
the field resulted in the development of dozens of graph kernels, each focusing
on specific structural properties of graphs. Graph kernels have proven
successful in a wide range of domains, ranging from social networks to
bioinformatics. The goal of this survey is to provide a unifying view of the
literature on graph kernels. In particular, we present a comprehensive overview
of a wide range of graph kernels. Furthermore, we perform an experimental
evaluation of several of those kernels on publicly available datasets, and
provide a comparative study. Finally, we discuss key applications of graph
kernels, and outline some challenges that remain to be addressed.

    

### [[1909.00426] Global Entity Disambiguation with Pretrained Contextualized Embeddings of Words and Entities](http://arxiv.org/abs/1909.00426)


  We propose a new global entity disambiguation (ED) model based on
contextualized embeddings of words and entities. Our model is based on BERT and
trained with our new training task, which enables the model to capture both the
word-based local and entity-based global contextual information. The model
solves ED as a sequence decision task and effectively uses both types of
contextual information. We achieve new state-of-the-art results on five
standard ED datasets: AIDA-CoNLL, MSNBC, AQUAINT, ACE2004, and WNED-WIKI. Our
source code and trained model checkpoint are available at
this https URL.

    

### [[2004.09963] Structural clustering of volatility regimes for dynamic trading strategies](http://arxiv.org/abs/2004.09963)


  We develop a new method to find the number of volatility regimes in a
nonstationary financial time series by applying unsupervised learning to its
volatility structure. We use change point detection to partition a time series
into locally stationary segments and then compute a distance matrix between
segment distributions. The segments are clustered into a learned number of
discrete volatility regimes via an optimization routine. Using this framework,
we determine a volatility clustering structure for financial indices, large-cap
equities, exchange-traded funds and currency pairs. Our method overcomes the
rigid assumptions necessary to implement many parametric regime-switching
models, while effectively distilling a time series into several characteristic
behaviours. Our results provide significant simplification of these time series
and a strong descriptive analysis of prior behaviours of volatility. Finally,
we create and validate a dynamic trading strategy that learns the optimal match
between the current distribution of a time series and its past regimes, thereby
making online risk-avoidance decisions in the present.

    

### [[2007.04171] Domain Adaptation with Auxiliary Target Domain-Oriented Classifier](http://arxiv.org/abs/2007.04171)


  Domain adaptation (DA) aims to transfer knowledge from a label-rich but
heterogeneous domain to a label-scare domain, which alleviates the labeling
efforts and attracts considerable attention. Different from previous methods
focusing on learning domain-invariant feature representations, some recent
methods present generic semi-supervised learning (SSL) techniques and directly
apply them to DA tasks, even achieving competitive performance. One of the most
popular SSL techniques is pseudo-labeling that assigns pseudo labels for each
unlabeled data via the classifier trained by labeled data. However, it ignores
the distribution shift in DA problems and is inevitably biased to source data.
To address this issue, we propose a new pseudo-labeling framework called
Auxiliary Target Domain-Oriented Classifier (ATDOC). ATDOC alleviates the
classifier bias by introducing an auxiliary classifier for target data only, to
improve the quality of pseudo labels. Specifically, we employ the memory
mechanism and develop two types of non-parametric classifiers, i.e. the nearest
centroid classifier and neighborhood aggregation, without introducing any
additional network parameters. Despite its simplicity in a pseudo
classification objective, ATDOC with neighborhood aggregation significantly
outperforms domain alignment techniques and prior SSL techniques on a large
variety of DA benchmarks and even scare-labeled SSL tasks.

    

### [[2009.09379] Exploring the Generalizability of Spatio-Temporal Crowd Flow Prediction: Meta-Modeling and an Analytic Framework](http://arxiv.org/abs/2009.09379)


  The Spatio-Temporal Crowd Flow Prediction (STCFP) problem is a classical
problem with plenty of prior research efforts that benefit from traditional
statistical learning and recent deep learning approaches. While STCFP can refer
to many real-world problems, most existing studies focus on quite specific
applications, such as the prediction of taxi demand, ridesharing order, and so
on. This hinders the STCFP research as the approaches designed for different
applications are hardly comparable, and thus how an applicationdriven approach
can be generalized to other scenarios is unclear. To fill in this gap, this
paper makes two efforts: (i) we propose an analytic framework, called
STAnalytic, to qualitatively investigate STCFP approaches regarding their
design considerations on various spatial and temporal factors, aiming to make
different application-driven approaches comparable; (ii) we construct an
extensively large-scale STCFP benchmark datasets with four different scenarios
(including ridesharing, bikesharing, metro, and electrical vehicle charging)
with up to hundreds of millions of flow records, to quantitatively measure the
generalizability of STCFP approaches. Furthermore, to elaborate the
effectiveness of STAnalytic in helping design generalizable STCFP approaches,
we propose a spatio-temporal meta-model, called STMeta, by integrating
generalizable temporal and spatial knowledge identified by STAnalytic. We
implement three variants of STMeta with different deep learning techniques.
With the datasets, we demonstrate that STMeta variants can outperform
state-of-the-art STCFP approaches by 5%.

    

### [[2009.09525] Deep Autoencoders: From Understanding to Generalization Guarantees](http://arxiv.org/abs/2009.09525)


  A big mystery in deep learning continues to be the ability of methods to
generalize when the number of model parameters is larger than the number of
training examples. In this work, we take a step towards a better understanding
of the underlying phenomena of Deep Autoencoders (AEs), a mainstream deep
learning solution for learning compressed, interpretable, and structured data
representations. In particular, we interpret how AEs approximate the data
manifold by exploiting their continuous piecewise affine structure. Our
reformulation of AEs provides new insights into their mapping, reconstruction
guarantees, as well as an interpretation of commonly used regularization
techniques. We leverage these findings to derive two new regularizations that
enable AEs to capture the inherent symmetry in the data. Our regularizations
leverage recent advances in the group of transformation learning to enable AEs
to better approximate the data manifold without explicitly defining the group
underlying the manifold. Under the assumption that the symmetry of the data can
be explained by a Lie group, we prove that the regularizations ensure the
generalization of the corresponding AEs. A range of experimental evaluations
demonstrate that our methods outperform other state-of-the-art regularization
techniques.

    

### [[2010.11625] One-shot Distributed Algorithm for Generalized Eigenvalue Problem](http://arxiv.org/abs/2010.11625)


  Nowadays, more and more datasets are stored in a distributed way for the sake
of memory storage or data privacy. The generalized eigenvalue problem (GEP)
plays a vital role in a large family of high-dimensional statistical models.
However, the existing distributed method for eigenvalue decomposition cannot be
applied in GEP for the divergence of the empirical covariance matrix. Here we
propose a general distributed GEP framework with one-shot communication for
GEP. If the symmetric data covariance has repeated eigenvalues, e.g., in
canonical component analysis, we further modify the method for better
convergence. The theoretical analysis on approximation error is conducted and
the relation to the divergence of the data covariance, the eigenvalues of the
empirical data covariance, and the number of local servers is analyzed.
Numerical experiments also show the effectiveness of the proposed algorithms.

    

### [[2010.15764] Domain adaptation under structural causal models](http://arxiv.org/abs/2010.15764)


  Domain adaptation (DA) arises as an important problem in statistical machine
learning when the source data used to train a model is different from the
target data used to test the model. Recent advances in DA have mainly been
application-driven and have largely relied on the idea of a common subspace for
source and target data. To understand the empirical successes and failures of
DA methods, we propose a theoretical framework via structural causal models
that enables analysis and comparison of the prediction performance of DA
methods. This framework also allows us to itemize the assumptions needed for
the DA methods to have a low target error. Additionally, with insights from our
theory, we propose a new DA method called CIRM that outperforms existing DA
methods when both the covariates and label distributions are perturbed in the
target data. We complement the theoretical analysis with extensive simulations
to show the necessity of the devised assumptions. Reproducible synthetic and
real data experiments are also provided to illustrate the strengths and
weaknesses of DA methods when parts of the assumptions in our theory are
violated.

    

### [[2011.14814] Cost Function Unrolling in Unsupervised Optical Flow](http://arxiv.org/abs/2011.14814)


  Steepest descent algorithms, which are commonly used in deep learning, use
the gradient as the descent direction, either as-is or after a direction shift
using preconditioning. In many scenarios calculating the gradient is
numerically hard due to complex or non-differentiable cost functions,
specifically next to singular points. In this work we focus on the derivation
of the Total Variation semi-norm commonly used in unsupervised cost functions.
Specifically, we derive a differentiable proxy to the hard L1 smoothness
constraint in a novel iterative scheme which we refer to as Cost Unrolling.
Producing more accurate gradients during training, our method enables finer
predictions of a given DNN model through improved convergence, without
modifying its architecture or increasing computational complexity. We
demonstrate our method in the unsupervised optical flow task. Replacing the L1
smoothness constraint with our unrolled cost during the training of a well
known baseline, we report improved results on both MPI Sintel and KITTI 2015
unsupervised optical flow benchmarks. Particularly, we report EPE reduced by up
to 15.82% on occluded pixels, where the smoothness constraint is dominant,
enabling the detection of much sharper motion edges.

    

### [[2012.00968] Reconfigurable Intelligent Surfaces in Action for Non-Terrestrial Networks](http://arxiv.org/abs/2012.00968)


  Next-generation communication technology will be fueled on the cooperation of
terrestrial networks with nonterrestrial networks (NTNs) that contain
mega-constellations of high-altitude platform stations and low-Earth orbit
satellites. On the other hand, humanity has embarked on a long road to
establish new habitats on other planets. This deems the cooperation of NTNs
with deep space networks (DSNs) necessary. In this regard, we propose the use
of reconfigurable intelligent surfaces (RISs) to improve and escalate this
collaboration owing to the fact that they perfectly match with the size,
weight, and power restrictions of the operational environment of space. A
comprehensive framework of RIS-assisted non-terrestrial and interplanetary
communications is presented by pinpointing challenges, use cases, and open
issues. Furthermore, the performance of RIS-assisted NTNs under environmental
effects such as solar scintillation and satellite drag is discussed through
simulation results.

    

### [[2101.00304] Interval Type-2 Enhanced Possibilistic Fuzzy C-Means Clustering for Gene Expression Data Analysis](http://arxiv.org/abs/2101.00304)


  Both FCM and PCM clustering methods have been widely applied to pattern
recognition and data clustering. Nevertheless, FCM is sensitive to noise and
PCM occasionally generates coincident clusters. PFCM is an extension of the PCM
model by combining FCM and PCM, but this method still suffers from the
weaknesses of PCM and FCM. In the current paper, the weaknesses of the PFCM
algorithm are corrected and the enhanced possibilistic fuzzy c-means (EPFCM)
clustering algorithm is presented. EPFCM can still be sensitive to noise.
Therefore, we propose an interval type-2 enhanced possibilistic fuzzy c-means
(IT2EPFCM) clustering method by utilizing two fuzzifiers $(m_1, m_2)$ for fuzzy
memberships and two fuzzifiers $({\theta}_1, {\theta}_2)$ for possibilistic
typicalities. Our computational results show the superiority of the proposed
approaches compared with several state-of-the-art techniques in the literature.
Finally, the proposed methods are implemented for analyzing microarray gene
expression data.

    

### [[2101.11948] Choice modelling in the age of machine learning - discussion paper](http://arxiv.org/abs/2101.11948)


  Since its inception, the choice modelling field has been dominated by
theory-driven modelling approaches. Machine learning offers an alternative
data-driven approach for modelling choice behaviour and is increasingly drawing
interest in our field. Cross-pollination of machine learning models, techniques
and practices could help overcome problems and limitations encountered in the
current theory-driven modelling paradigm, such as subjective labour-intensive
search processes for model selection, and the inability to work with text and
image data. However, despite the potential benefits of using the advances of
machine learning to improve choice modelling practices, the choice modelling
field has been hesitant to embrace machine learning. This discussion paper aims
to consolidate knowledge on the use of machine learning models, techniques and
practices for choice modelling, and discuss their potential. Thereby, we hope
not only to make the case that further integration of machine learning in
choice modelling is beneficial, but also to further facilitate it. To this end,
we clarify the similarities and differences between the two modelling
paradigms; we review the use of machine learning for choice modelling; and we
explore areas of opportunities for embracing machine learning models and
techniques to improve our practices. To conclude this discussion paper, we put
forward a set of research questions which must be addressed to better
understand if and how machine learning can benefit choice modelling.

    

### [[2102.03906] Causal versions of Maximum Entropy and Principle of Insufficient Reason](http://arxiv.org/abs/2102.03906)


  The Principle of Insufficient Reason (PIR) assigns equal probabilities to
each alternative of a random experiment whenever there is no reason to prefer
one over the other. The Maximum Entropy Principle (MaxEnt) generalizes PIR to
the case where statistical information like expectations are given. It is known
that both principles result in paradoxical probability updates for joint
distributions of cause and effect. This is because constraints on the
conditional P(effect|cause) result in changes of P(cause) that assign higher
probability to those values of the cause that offer more options for the
effect, suggesting "intentional behaviour". Earlier work therefore suggested
sequentially maximizing (conditional) entropy according to the causal order,
but without further justification apart from plausibility on toy examples. We
justify causal modifications of PIR and MaxEnt by separating constraints into
restrictions for the cause and restrictions for the mechanism that generates
the effect from the cause. We further sketch why Causal PIR also entails
"Information Geometric Causal Inference". We briefly discuss problems of
generalizing the causal version of MaxEnt to arbitrary causal DAGs.

    

### [[2102.04525] Unified Focal loss: Generalising Dice and cross entropy-based losses to handle class imbalanced medical image segmentation](http://arxiv.org/abs/2102.04525)


  Automatic segmentation methods are an important advancement in medical image
analysis. Machine learning techniques, and deep neural networks in particular,
are the state-of-the-art for most medical image segmentation tasks. Issues with
class imbalance pose a significant challenge in medical datasets, with lesions
often occupying a considerably smaller volume relative to the background. Loss
functions used in the training of deep learning algorithms differ in their
robustness to class imbalance, with direct consequences for model convergence.
The most commonly used loss functions for segmentation are based on either the
cross entropy loss, Dice loss or a combination of the two. We propose the
Unified Focal loss, a new hierarchical framework that generalises Dice and
cross entropy-based losses for handling class imbalance. We evaluate our
proposed loss function on five publicly available, class imbalanced medical
imaging datasets: CVC-ClinicDB, Digital Retinal Images for Vessel Extraction
(DRIVE), Breast Ultrasound 2017 (BUS2017), Brain Tumour Segmentation 2020
(BraTS20) and Kidney Tumour Segmentation 2019 (KiTS19). We compare our loss
function performance against six Dice or cross entropy-based loss functions,
across 2D binary, 3D binary and 3D multiclass segmentation tasks, demonstrating
that our proposed loss function is robust to class imbalance and consistently
outperforms the other loss functions. Source code is available at:
this https URL


### [[2102.09159] Robust and Differentially Private Mean Estimation](http://arxiv.org/abs/2102.09159)


  In statistical learning and analysis from shared data, which is increasingly
widely adopted in platforms such as federated learning and meta-learning, there
are two major concerns: privacy and robustness. Each participating individual
should be able to contribute without the fear of leaking one's sensitive
information. At the same time, the system should be robust in the presence of
malicious participants inserting corrupted data. Recent algorithmic advances in
learning from shared data focus on either one of these threats, leaving the
system vulnerable to the other. We bridge this gap for the canonical problem of
estimating the mean from i.i.d. samples. We introduce PRIME, which is the first
efficient algorithm that achieves both privacy and robustness for a wide range
of distributions. We further complement this result with a novel exponential
time algorithm that improves the sample complexity of PRIME, achieving a
near-optimal guarantee and matching a known lower bound for (non-robust)
private mean estimation. This proves that there is no extra statistical cost to
simultaneously guaranteeing privacy and robustness.

    

### [[2102.09788] Sequential- and Parallel- Constrained Max-value Entropy Search via Information Lower Bound](http://arxiv.org/abs/2102.09788)


  Max-value entropy search (MES) is one of the state-of-the-art approaches in
Bayesian optimization (BO). In this paper, we propose a novel variant of MES
for constrained problems, called Constrained MES via Information lower BOund
(CMES-IBO), that is based on a Monte Carlo (MC) estimator of a lower bound of a
mutual information (MI). We first define the MI in which the max-value is
defined so that it can incorporate uncertainty with respect to feasibility.
Then, we derive a lower bound of the MI that guarantees non-negativity, while a
constrained counterpart of conventional MES can be negative. We further provide
theoretical analysis that assures the low-variability of our estimator which
has never been investigated for any existing information-theoretic BO.
Moreover, using the conditional MI, we extend CMES-IBO to the parallel setting
while maintaining the desirable properties. We demonstrate the effectiveness of
CMES-IBO by several benchmark functions and a real-world problem.

    

### [[2103.06342] Continual Semantic Segmentation via Repulsion-Attraction of Sparse and Disentangled Latent Representations](http://arxiv.org/abs/2103.06342)


  Deep neural networks suffer from the major limitation of catastrophic
forgetting old tasks when learning new ones. In this paper we focus on class
incremental continual learning in semantic segmentation, where new categories
are made available over time while previous training data is not retained. The
proposed continual learning scheme shapes the latent space to reduce forgetting
whilst improving the recognition of novel classes. Our framework is driven by
three novel components which we also combine on top of existing techniques
effortlessly. First, prototypes matching enforces latent space consistency on
old classes, constraining the encoder to produce similar latent representation
for previously seen classes in the subsequent steps. Second, features
sparsification allows to make room in the latent space to accommodate novel
classes. Finally, contrastive learning is employed to cluster features
according to their semantics while tearing apart those of different classes.
Extensive evaluation on the Pascal VOC2012 and ADE20K datasets demonstrates the
effectiveness of our approach, significantly outperforming state-of-the-art
methods.

    

### [[2104.06219] UAV-ReID: A Benchmark on Unmanned Aerial Vehicle Re-identification](http://arxiv.org/abs/2104.06219)


  As unmanned aerial vehicles (UAVs) become more accessible with a growing
range of applications, the potential risk of UAV disruption increases. Recent
development in deep learning allows vision-based counter-UAV systems to detect
and track UAVs with a single camera. However, the coverage of a single camera
is limited, necessitating the need for multicamera configurations to match UAVs
across cameras - a problem known as re-identification (reID). While there has
been extensive research on person and vehicle reID to match objects across time
and viewpoints, to the best of our knowledge, there has been no research in UAV
reID. UAVs are challenging to re-identify: they are much smaller than
pedestrians and vehicles and they are often detected in the air so appear at a
greater range of angles. Because no UAV data sets currently use multiple
cameras, we propose the first new UAV re-identification data set, UAV-reID,
that facilitates the development of machine learning solutions in this emerging
area. UAV-reID has two settings: Temporally-Near to evaluate performance across
views to assist tracking frameworks, and Big-to-Small to evaluate reID
performance across scale and to allow early reID when UAVs are detected from a
long distance. We conduct a benchmark study by extensively evaluating different
reID backbones and loss functions. We demonstrate that with the right setup,
deep networks are powerful enough to learn good representations for UAVs,
achieving 81.9% mAP on the Temporally-Near setting and 46.5% on the challenging
Big-to-Small setting. Furthermore, we find that vision transformers are the
most robust to extreme variance of scale.

    

### [[2105.05458] Distributionally Robust Graph Learning from Smooth Signals under Moment Uncertainty](http://arxiv.org/abs/2105.05458)


  We consider the problem of learning a graph from a finite set of noisy graph
signal observations, the goal of which is to find a smooth representation of
the graph signal. Such a problem is motivated by the desire to infer relational
structure in large datasets and has been extensively studied in recent years.
Most existing approaches focus on learning a graph on which the observed
signals are smooth. However, the learned graph is prone to overfitting, as it
does not take the unobserved signals into account. To address this issue, we
propose a novel graph learning model based on the distributionally robust
optimization methodology, which aims to identify a graph that not only provides
a smooth representation of but is also robust against uncertainties in the
observed signals. On the statistics side, we establish out-of-sample
performance guarantees for our proposed model. On the optimization side, we
show that under a mild assumption on the graph signal distribution, our
proposed model admits a smooth non-convex optimization formulation. We then
develop a projected gradient method to tackle this formulation and establish
its convergence guarantees. Our formulation provides a new perspective on
regularization in the graph learning setting. Moreover, extensive numerical
experiments on both synthetic and real-world data show that our model has
comparable yet more robust performance across different populations of observed
signals than existing non-robust models according to various metrics.

    

### [[2105.08291] Independent Asymmetric Embedding for Cascade Prediction on Social Networks](http://arxiv.org/abs/2105.08291)


  The prediction for information diffusion on social networks has great
practical significance in marketing and public opinion control. It aims to
predict the individuals who will potentially repost the message on the social
network. One type of method is based on demographics, complex networks and
other prior knowledge to establish an interpretable model to simulate and
predict the propagation process, while the other type of method is completely
data-driven and maps the nodes to a latent space for propagation prediction.
Existing latent space design and embedding methods lack consideration for the
intervene among users. In this paper, we propose an independent asymmetric
embedding method to embed each individual into one latent influence space and
multiple latent susceptibility spaces. Based on the similarity between
information diffusion and heat diffusion phenomenon, the heat diffusion kernel
is exploited in our model and establishes the embedding rules. Furthermore, our
method captures the co-occurrence regulation of user combinations in cascades
to improve the calculating effectiveness. The results of extensive experiments
conducted on real-world datasets verify both the predictive accuracy and
cost-effectiveness of our approach.

    

### [[2105.10598] Embracing New Techniques in Deep Learning for Estimating Image Memorability](http://arxiv.org/abs/2105.10598)


  Various work has suggested that the memorability of an image is consistent
across people, and thus can be treated as an intrinsic property of an image.
Using computer vision models, we can make specific predictions about what
people will remember or forget. While older work has used now-outdated deep
learning architectures to predict image memorability, innovations in the field
have given us new techniques to apply to this problem. Here, we propose and
evaluate five alternative deep learning models which exploit developments in
the field from the last five years, largely the introduction of residual neural
networks, which are intended to allow the model to use semantic information in
the memorability estimation process. These new models were tested against the
prior state of the art with a combined dataset built to optimize both
within-category and across-category predictions. Our findings suggest that the
key prior memorability network had overstated its generalizability and was
overfit on its training set. Our new models outperform this prior model,
leading us to conclude that Residual Networks outperform simpler convolutional
neural networks in memorability regression. We make our new state-of-the-art
model readily available to the research community, allowing memory researchers
to make predictions about memorability on a wider range of images.

    

### [[2105.14024] Near-Optimal Multi-Perturbation Experimental Design for Causal Structure Learning](http://arxiv.org/abs/2105.14024)


  Causal structure learning is a key problem in many domains. Causal structures
can be learnt by performing experiments on the system of interest. We address
the largely unexplored problem of designing a batch of experiments that each
simultaneously intervene on multiple variables. While potentially more
informative than the commonly considered single-variable interventions,
selecting such interventions is algorithmically much more challenging, due to
the doubly-exponential combinatorial search space over sets of composite
interventions. In this paper, we develop efficient algorithms for optimizing
different objective functions quantifying the informativeness of a
budget-constrained batch of experiments. By establishing novel submodularity
properties of these objectives, we provide approximation guarantees for our
algorithms. Our algorithms empirically perform superior to both random
interventions and algorithms that only select single-variable interventions.

    

### [[2106.00058] PUDLE: Implicit Acceleration of Dictionary Learning by Backpropagation](http://arxiv.org/abs/2106.00058)


  The dictionary learning problem, representing data as a combination of few
atoms, has long stood as a popular method for learning representations in
statistics and signal processing. The most popular dictionary learning
algorithm alternates between sparse coding and dictionary update steps, and a
rich literature has studied its theoretical convergence. The growing popularity
of neurally plausible unfolded sparse coding networks has led to the empirical
finding that backpropagation through such networks performs dictionary
learning. This paper offers the first theoretical proof for these empirical
results through PUDLE, a Provable Unfolded Dictionary LEarning method. We
highlight the impact of loss, unfolding, and backpropagation on convergence. We
discover an implicit acceleration: as a function of unfolding, the
backpropagated gradient converges faster and is more accurate than the gradient
from alternating minimization. We complement our findings through synthetic and
image denoising experiments. The findings support the use of accelerated deep
learning optimizers and unfolded networks for dictionary learning.

    

### [[2106.03969] Chow-Liu++: Optimal Prediction-Centric Learning of Tree Ising Models](http://arxiv.org/abs/2106.03969)


  We consider the problem of learning a tree-structured Ising model from data,
such that subsequent predictions computed using the model are accurate.
Concretely, we aim to learn a model such that posteriors $P(X_i|X_S)$ for small
sets of variables $S$ are accurate. Since its introduction more than 50 years
ago, the Chow-Liu algorithm, which efficiently computes the maximum likelihood
tree, has been the benchmark algorithm for learning tree-structured graphical
models. A bound on the sample complexity of the Chow-Liu algorithm with respect
to the prediction-centric local total variation loss was shown in [BK19]. While
those results demonstrated that it is possible to learn a useful model even
when recovering the true underlying graph is impossible, their bound depends on
the maximum strength of interactions and thus does not achieve the
information-theoretic optimum. In this paper, we introduce a new algorithm that
carefully combines elements of the Chow-Liu algorithm with tree metric
reconstruction methods to efficiently and optimally learn tree Ising models
under a prediction-centric loss. Our algorithm is robust to model
misspecification and adversarial corruptions. In contrast, we show that the
celebrated Chow-Liu algorithm can be arbitrarily suboptimal.

    

### [[2106.06935] Neural Bellman-Ford Networks: A General Graph Neural Network Framework for Link Prediction](http://arxiv.org/abs/2106.06935)


  Link prediction is a very fundamental task on graphs. Inspired by traditional
path-based methods, in this paper we propose a general and flexible
representation learning framework based on paths for link prediction.
Specifically, we define the representation of a pair of nodes as the
generalized sum of all path representations, with each path representation as
the generalized product of the edge representations in the path. Motivated by
the Bellman-Ford algorithm for solving the shortest path problem, we show that
the proposed path formulation can be efficiently solved by the generalized
Bellman-Ford algorithm. To further improve the capacity of the path
formulation, we propose the Neural Bellman-Ford Network (NBFNet), a general
graph neural network framework that solves the path formulation with learned
operators in the generalized Bellman-Ford algorithm. The NBFNet parameterizes
the generalized Bellman-Ford algorithm with 3 neural components, namely
INDICATOR, MESSAGE and AGGREGATE functions, which corresponds to the boundary
condition, multiplication operator, and summation operator respectively. The
NBFNet is very general, covers many traditional path-based methods, and can be
applied to both homogeneous graphs and multi-relational graphs (e.g., knowledge
graphs) in both transductive and inductive settings. Experiments on both
homogeneous graphs and knowledge graphs show that the proposed NBFNet
outperforms existing methods by a large margin in both transductive and
inductive settings, achieving new state-of-the-art results.

    

### [[2106.14472] Hyperbolic Busemann Learning with Ideal Prototypes](http://arxiv.org/abs/2106.14472)


  Hyperbolic space has become a popular choice of manifold for representation
learning of various datatypes from tree-like structures and text to graphs.
Building on the success of deep learning with prototypes in Euclidean and
hyperspherical spaces, a few recent works have proposed hyperbolic prototypes
for classification. Such approaches enable effective learning in
low-dimensional output spaces and can exploit hierarchical relations amongst
classes, but require privileged information about class labels to position the
hyperbolic prototypes. In this work, we propose Hyperbolic Busemann Learning.
The main idea behind our approach is to position prototypes on the ideal
boundary of the PoincarÃ© ball, which does not require prior label knowledge.
To be able to compute proximities to ideal prototypes, we introduce the
penalised Busemann loss. We provide theory supporting the use of ideal
prototypes and the proposed loss by proving its equivalence to logistic
regression in the one-dimensional case. Empirically, we show that our approach
provides a natural interpretation of classification confidence, while
outperforming recent hyperspherical and hyperbolic prototype approaches.

    

### [[2110.11024] Watermarking Graph Neural Networks based on Backdoor Attacks](http://arxiv.org/abs/2110.11024)


  Graph Neural Networks (GNNs) have achieved promising performance in various
real-world applications. Building a powerful GNN model is not a trivial task,
as it requires a large amount of training data, powerful computing resources,
and human expertise on fine-tuning the model. What is more, with the
development of adversarial attacks, e.g., model stealing attacks, GNNs raise
challenges to model authentication. To avoid copyright infringement on GNNs, it
is necessary to verify the ownership of the GNN models.
In this paper, we present a watermarking framework for GNNs for both graph
and node classification tasks. We 1) design two strategies to generate
watermarked data for the graph classification and one for the node
classification task, 2) embed the watermark into the host model through
training to obtain the watermarked GNN model, and 3) verify the ownership of
the suspicious model in a black-box setting. The experiments show that our
framework can verify the ownership of GNN models with a very high probability
(around $100\%$) for both tasks. In addition, we experimentally show that our
watermarking approach is still effective even when considering suspicious
models obtained from different architectures than the owner's.

    

### [[2111.11426] Neural Fields in Visual Computing and Beyond](http://arxiv.org/abs/2111.11426)


  Recent advances in machine learning have created increasing interest in
solving visual computing problems using a class of coordinate-based neural
networks that parametrize physical properties of scenes or objects across space
and time. These methods, which we call neural fields, have seen successful
application in the synthesis of 3D shapes and image, animation of human bodies,
3D reconstruction, and pose estimation. However, due to rapid progress in a
short time, many papers exist but a comprehensive review and formulation of the
problem has not yet emerged. In this report, we address this limitation by
providing context, mathematical grounding, and an extensive review of
literature on neural fields. This report covers research along two dimensions.
In Part I, we focus on techniques in neural fields by identifying common
components of neural field methods, including different representations,
architectures, forward mapping, and generalization methods. In Part II, we
focus on applications of neural fields to different problems in visual
computing, and beyond (e.g., robotics, audio). Our review shows the breadth of
topics already covered in visual computing, both historically and in current
incarnations, demonstrating the improved quality, flexibility, and capability
brought by neural fields methods. Finally, we present a companion website that
contributes a living version of this review that can be continually updated by
the community.

    

### [[2111.12281] Locality-based Graph Reordering for Processing Speed-Ups and Impact of Diameter](http://arxiv.org/abs/2111.12281)


  Graph analysis involves a high number of random memory access patterns.
Earlier research has shownthat the cache miss latency is responsible for more
than half of the graph processing time, with the CPU execution having the
smaller share. There has been significant study on decreasing the CPU computing
time for example, by employing better cache prefetching and replacement
policies. In thispaper, we study the various methods that do so by attempting
to decrease the CPU cache miss ratio.Graph Reordering attempts to exploit the
power-law distribution of graphs- few sparsely-populated vertices in the graph
have high number of connections- to keep the frequently accessed vertices
together locally and hence decrease the cache misses. However, reordering the
graph by keeping the hot vertices together may affect the spatial locality of
the graph, and thus add to the total CPU compute time.Also, we also need to
have a control over the total reordering time and its inverse relation with
thefinal CPU execution timeIn order to exploit this trade-off between
reordering as per vertex hotness and spatial locality, we introduce the
light-weight Community-based Reordering. We attempt to maintain the
community-structureof the graph by storing the hot-members in the community
locally together. The implementation also takes into consideration the impact
of graph diameter on the execution time. We compare our implementation with
other reordering implementations and find a significantly better result on five
graph processing algorithms- BFS, CC, CCSV, PR and BC. Lorder achieved speed-up
of upto 7x and an average speed-up of 1.2x as compared to other reordering
algorithms

    

### [[2111.12555] Serpens: A High Bandwidth Memory Based Accelerator for General-Purpose Sparse Matrix-Vector Multiplication](http://arxiv.org/abs/2111.12555)


  Sparse matrix-vector multiplication (SpMV) multiplies a sparse matrix with a
dense vector. SpMV plays a crucial role in many applications, from graph
analytics to deep learning. The random memory accesses of the sparse matrix
make accelerator design challenging. However, high bandwidth memory (HBM) based
FPGAs are a good fit for designing accelerators for SpMV. In this paper, we
present Serpens, an HBM based accelerator for general-purpose SpMV.Serpens
features (1) a general-purpose design, (2) memory-centric processing engines,
and (3) index coalescing to support the efficient processing of arbitrary
SpMVs. From the evaluation of twelve large-size matrices, Serpens is 1.91x and
1.76x better in terms of geomean throughput than the latest accelerators
GraphLiLy and Sextans, respectively. We also evaluate 2,519 SuiteSparse
matrices, and Serpens achieves 2.10x higher throughput than a K80 GPU. For the
energy efficiency, Serpens is 1.71x, 1.90x, and 42.7x better compared with
GraphLily, Sextans, and K80, respectively. After scaling up to 24 HBM channels,
Serpens achieves up to 30,204MTEPS and up to 3.79x over GraphLily.

    

### [[2111.12321] Efficient Secure Aggregation Based on SHPRG For Federated Learning](http://arxiv.org/abs/2111.12321)


  We propose a novel secure aggregation scheme based on seed-homomorphic
pseudo-random generator (SHPRG) to prevent private training data leakage from
model-related information in Federated Learning systems. Our constructions
leverage the homomorphic property of SHPRG to simplify the masking and
demasking scheme, which entails a linear overhead while revealing nothing
beyond the aggregation result against colluding entities. Additionally, our
scheme is resilient to dropouts without extra overhead. We experimentally
demonstrate our scheme significantly improves the efficiency to 20 times over
baseline, especially in the more realistic case in which the number of clients
and model size become large and a certain percentage of clients drop out from
the system.

    

### [[2111.12332] Securing Proof-of-Stake Nakamoto Consensus Under Bandwidth Constraint](http://arxiv.org/abs/2111.12332)


  Satoshi Nakamoto's Proof-of-Work (PoW) longest chain (LC) protocol was a
breakthrough for Internet-scale open-participation consensus. Many
Proof-of-Stake (PoS) variants of Nakamoto's protocol such as Ouroboros or Snow
White aim to preserve the advantages of LC by mimicking PoW LC closely, while
mitigating downsides of PoW by using PoS for Sybil resistance. Previous works
have proven these PoS LC protocols secure assuming all network messages are
delivered within a bounded delay. However, this assumption is not compatible
with PoS when considering bandwidth constraints in the underlying communication
network. This is because PoS enables the adversary to reuse block production
opportunities and spam the network with equivocating blocks, which is
impossible in PoW. The bandwidth constraint necessitates that nodes choose
carefully which blocks to spend their limited download budget on. We show that
'download along the longest header chain', a natural download rule for PoW LC,
emulated by PoS variants, is insecure for PoS LC. Instead, we propose 'download
towards the freshest block' and prove that PoS LC with this download rule is
secure in bandwidth constrained networks. Our result can be viewed as a first
step towards the co-design of consensus and network layer protocols.

    

### [[2111.12364] Crawling the MobileCoin Quorum System](http://arxiv.org/abs/2111.12364)


  We continuously crawl the young MobileCoin network, uncovering the quorum
configurations of core nodes and the quorum system resulting from these
configurations. This report discusses our crawl methodology, encountered
challenges, and our current empirical results. We find that the MobileCoin
quorum system currently comprises of 7 organisations controlling a total of 10
validator nodes. Current quorum set configurations prioritise safety over
liveness. At the time of writing, one of the involved organisations is
technically able to block the approval of new blocks, as is the case for one of
the (two) ISPs employed by crawled nodes.

    

### [[1907.02064] Accelerator-level Parallelism](http://arxiv.org/abs/1907.02064)


  Future applications demand more performance, but technology advances have
been faltering. A promising approach to further improve computer system
performance under energy constraints is to employ hardware accelerators.
Already today, mobile systems concurrently employ multiple accelerators in what
we call accelerator-level parallelism (ALP). To spread the benefits of ALP more
broadly, we charge computer scientists to develop the science needed to best
achieve the performance and cost goals of ALP hardware and software.

    

### [[2111.04398] Sub-realtime simulation of a neuronal network of natural density](http://arxiv.org/abs/2111.04398)


  Full scale simulations of neuronal network models of the brain are
challenging due to the high density of connections between neurons. This
contribution reports run times shorter than the simulated span of biological
time for a full scale model of the local cortical microcircuit with explicit
representation of synapses on a recent conventional compute node. Realtime
performance is relevant for robotics and closed-loop applications while
sub-realtime is desirable for the study of learning and development in the
brain, processes extending over hours and days of biological time.

    

### [[2111.12122] Bounding Box-Free Instance Segmentation Using Semi-Supervised Learning for Generating a City-Scale Vehicle Dataset](http://arxiv.org/abs/2111.12122)


  Vehicle classification is a hot computer vision topic, with studies ranging
from ground-view up to top-view imagery. In remote sensing, the usage of
top-view images allows for understanding city patterns, vehicle concentration,
traffic management, and others. However, there are some difficulties when
aiming for pixel-wise classification: (a) most vehicle classification studies
use object detection methods, and most publicly available datasets are designed
for this task, (b) creating instance segmentation datasets is laborious, and
(c) traditional instance segmentation methods underperform on this task since
the objects are small. Thus, the present research objectives are: (1) propose a
novel semi-supervised iterative learning approach using GIS software, (2)
propose a box-free instance segmentation approach, and (3) provide a city-scale
vehicle dataset. The iterative learning procedure considered: (1) label a small
number of vehicles, (2) train on those samples, (3) use the model to classify
the entire image, (4) convert the image prediction into a polygon shapefile,
(5) correct some areas with errors and include them in the training data, and
(6) repeat until results are satisfactory. To separate instances, we considered
vehicle interior and vehicle borders, and the DL model was the U-net with the
Efficient-net-B7 backbone. When removing the borders, the vehicle interior
becomes isolated, allowing for unique object identification. To recover the
deleted 1-pixel borders, we proposed a simple method to expand each prediction.
The results show better pixel-wise metrics when compared to the Mask-RCNN (82%
against 67% in IoU). On per-object analysis, the overall accuracy, precision,
and recall were greater than 90%. This pipeline applies to any remote sensing
target, being very efficient for segmentation and generating datasets.

    

### [[2111.12126] Panoptic Segmentation Meets Remote Sensing](http://arxiv.org/abs/2111.12126)


  Panoptic segmentation combines instance and semantic predictions, allowing
the detection of "things" and "stuff" simultaneously. Effectively approaching
panoptic segmentation in remotely sensed data can be auspicious in many
challenging problems since it allows continuous mapping and specific target
counting. Several difficulties have prevented the growth of this task in remote
sensing: (a) most algorithms are designed for traditional images, (b) image
labelling must encompass "things" and "stuff" classes, and (c) the annotation
format is complex. Thus, aiming to solve and increase the operability of
panoptic segmentation in remote sensing, this study has five objectives: (1)
create a novel data preparation pipeline for panoptic segmentation, (2) propose
an annotation conversion software to generate panoptic annotations; (3) propose
a novel dataset on urban areas, (4) modify the Detectron2 for the task, and (5)
evaluate difficulties of this task in the urban setting. We used an aerial
image with a 0,24-meter spatial resolution considering 14 classes. Our pipeline
considers three image inputs, and the proposed software uses point shapefiles
for creating samples in the COCO format. Our study generated 3,400 samples with
512x512 pixel dimensions. We used the Panoptic-FPN with two backbones
(ResNet-50 and ResNet-101), and the model evaluation considered semantic
instance and panoptic metrics. We obtained 93.9, 47.7, and 64.9 for the mean
IoU, box AP, and PQ. Our study presents the first effective pipeline for
panoptic segmentation and an extensive database for other researchers to use
and deal with other data or related problems requiring a thorough scene
understanding.

    

### [[2111.12144] Mimicking Playstyle by Adapting Parameterized Behavior Trees in RTS Games](http://arxiv.org/abs/2111.12144)


  The discovery of Behavior Trees (BTs) impacted the field of Artificial
Intelligence (AI) in games, by providing flexible and natural representation of
non-player characters (NPCs) logic, manageable by game-designers. Nevertheless,
increased pressure on ever better NPCs AI-agents forced complexity of
handcrafted BTs to became barely-tractable and error-prone. On the other hand,
while many just-launched on-line games suffer from player-shortage, the
existence of AI with a broad-range of capabilities could increase players
retention. Therefore, to handle above challenges, recent trends in the field
focused on automatic creation of AI-agents: from deep- and
reinforcementlearning techniques to combinatorial (constrained) optimization
and evolution of BTs. In this paper, we present a novel approach to
semi-automatic construction of AI-agents, that mimic and generalize given human
gameplays by adapting and tuning of expert-created BT under a developed
similarity metric between source and BT gameplays. To this end, we formulated
mixed discrete-continuous optimization problem, in which topological and
functional changes of the BT are reflected in numerical variables, and
constructed a dedicated hybrid-metaheuristic. The performance of presented
approach was verified experimentally in a prototype real-time strategy game.
Carried out experiments confirmed efficiency and perspectives of presented
approach, which is going to be applied in a commercial game.

    

### [[2111.12197] Fixed Points in Cyber Space: Rethinking Optimal Evasion Attacks in the Age of AI-NIDS](http://arxiv.org/abs/2111.12197)


  Cyber attacks are increasing in volume, frequency, and complexity. In
response, the security community is looking toward fully automating cyber
defense systems using machine learning. However, so far the resultant effects
on the coevolutionary dynamics of attackers and defenders have not been
examined. In this whitepaper, we hypothesise that increased automation on both
sides will accelerate the coevolutionary cycle, thus begging the question of
whether there are any resultant fixed points, and how they are characterised.
Working within the threat model of Locked Shields, Europe's largest
cyberdefense exercise, we study blackbox adversarial attacks on network
classifiers. Given already existing attack capabilities, we question the
utility of optimal evasion attack frameworks based on minimal evasion
distances. Instead, we suggest a novel reinforcement learning setting that can
be used to efficiently generate arbitrary adversarial perturbations. We then
argue that attacker-defender fixed points are themselves general-sum games with
complex phase transitions, and introduce a temporally extended multi-agent
reinforcement learning framework in which the resultant dynamics can be
studied. We hypothesise that one plausible fixed point of AI-NIDS may be a
scenario where the defense strategy relies heavily on whitelisted feature flow
subspaces. Finally, we demonstrate that a continual learning approach is
required to study attacker-defender dynamics in temporally extended general-sum
games.

    

### [[2111.12202] Combinations of Jaccard with Numerical Measures for Collaborative Filtering Enhancement: Current Work and Future Proposal](http://arxiv.org/abs/2111.12202)


  Collaborative filtering (CF) is an important approach for recommendation
system which is widely used in a great number of aspects of our life, heavily
in the online-based commercial systems. One popular algorithms in CF is the
K-nearest neighbors (KNN) algorithm, in which the similarity measures are used
to determine nearest neighbors of a user, and thus to quantify the dependency
degree between the relative user/item pair. Consequently, CF approach is not
just sensitive to the similarity measure, yet it is completely contingent on
selection of that measure. While Jaccard - as one of those commonly used
similarity measures for CF tasks - concerns the existence of ratings, other
numerical measures such as cosine and Pearson concern the magnitude of ratings.
Particularly speaking, Jaccard is not a dominant measure, but it is long proven
to be an important factor to improve any measure. Therefore, in our continuous
efforts to find the most effective similarity measures for CF, this research
focuses on proposing new similarity measure via combining Jaccard with several
numerical measures. The combined measures would take the advantages of both
existence and magnitude. Experimental results on, Movie-lens dataset, showed
that the combined measures are preeminent outperforming all single measures
over the considered evaluation metrics.

    

### [[2111.12218] Flexible Pattern Discovery and Analysis](http://arxiv.org/abs/2111.12218)


  Based on the analysis of the proportion of utility in the supporting
transactions used in the field of data mining, high utility-occupancy pattern
mining (HUOPM) has recently attracted widespread attention. Unlike high-utility
pattern mining (HUPM), which involves the enumeration of high-utility (e.g.,
profitable) patterns, HUOPM aims to find patterns representing a collection of
existing transactions. In practical applications, however, not all patterns are
used or valuable. For example, a pattern might contain too many items, that is,
the pattern might be too specific and therefore lack value for users in real
life. To achieve qualified patterns with a flexible length, we constrain the
minimum and maximum lengths during the mining process and introduce a novel
algorithm for the mining of flexible high utility-occupancy patterns. Our
algorithm is referred to as HUOPM+. To ensure the flexibility of the patterns
and tighten the upper bound of the utility-occupancy, a strategy called the
length upper-bound (LUB) is presented to prune the search space. In addition, a
utility-occupancy nested list (UO-nlist) and a frequency-utility-occupancy
table (FUO-table) are employed to avoid multiple scans of the database.
Evaluation results of the subsequent experiments confirm that the proposed
algorithm can effectively control the length of the derived patterns, for both
real-world and synthetic datasets. Moreover, it can decrease the execution time
and memory consumption.

    

### [[2111.12262] Reinforcement Learning based Path Exploration for Sequential Explainable Recommendation](http://arxiv.org/abs/2111.12262)


  Recent advances in path-based explainable recommendation systems have
attracted increasing attention thanks to the rich information provided by
knowledge graphs. Most existing explainable recommendations only utilize static
knowledge graphs and ignore the dynamic user-item evolutions, leading to less
convincing and inaccurate explanations. Although there are some works that
realize that modelling user's temporal sequential behaviour could boost the
performance and explainability of the recommender systems, most of them either
only focus on modelling user's sequential interactions within a path or
independently and separately of the recommendation mechanism. In this paper, we
propose a novel Temporal Meta-path Guided Explainable Recommendation leveraging
Reinforcement Learning (TMER-RL), which utilizes reinforcement item-item path
modelling between consecutive items with attention mechanisms to sequentially
model dynamic user-item evolutions on dynamic knowledge graph for explainable
recommendation. Compared with existing works that use heavy recurrent neural
networks to model temporal information, we propose simple but effective neural
networks to capture users' historical item features and path-based context to
characterize the next purchased item. Extensive evaluations of TMER on two
real-world datasets show state-of-the-art performance compared against recent
strong baselines.

    

### [[2111.12340] How does AI play football? An analysis of RL and real-world football strategies](http://arxiv.org/abs/2111.12340)


  Recent advances in reinforcement learning (RL) have made it possible to
develop sophisticated agents that excel in a wide range of applications.
Simulations using such agents can provide valuable information in scenarios
that are difficult to scientifically experiment in the real world. In this
paper, we examine the play-style characteristics of football RL agents and
uncover how strategies may develop during training. The learnt strategies are
then compared with those of real football players. We explore what can be
learnt from the use of simulated environments by using aggregated statistics
and social network analysis (SNA). As a result, we found that (1) there are
strong correlations between the competitiveness of an agent and various SNA
metrics and (2) aspects of the RL agents play style become similar to real
world footballers as the agent becomes more competitive. We discuss further
advances that may be necessary to improve our understanding necessary to fully
utilise RL for the analysis of football.

    

### [[2111.12417] NÃWA: Visual Synthesis Pre-training for Neural visUal World creAtion](http://arxiv.org/abs/2111.12417)


  This paper presents a unified multimodal pre-trained model called NÃWA that
can generate new or manipulate existing visual data (i.e., images and videos)
for various visual synthesis tasks. To cover language, image, and video at the
same time for different scenarios, a 3D transformer encoder-decoder framework
is designed, which can not only deal with videos as 3D data but also adapt to
texts and images as 1D and 2D data, respectively. A 3D Nearby Attention (3DNA)
mechanism is also proposed to consider the nature of the visual data and reduce
the computational complexity. We evaluate NÃWA on 8 downstream tasks.
Compared to several strong baselines, NÃWA achieves state-of-the-art results
on text-to-image generation, text-to-video generation, video prediction, etc.
Furthermore, it also shows surprisingly good zero-shot capabilities on
text-guided image and video manipulation tasks. Project repo is
this https URL.

    

### [[2111.12421] Few-shot Named Entity Recognition with Cloze Questions](http://arxiv.org/abs/2111.12421)


  Despite the huge and continuous advances in computational linguistics, the
lack of annotated data for Named Entity Recognition (NER) is still a
challenging issue, especially in low-resource languages and when domain
knowledge is required for high-quality annotations. Recent findings in NLP show
the effectiveness of cloze-style questions in enabling language models to
leverage the knowledge they acquired during the pre-training phase. In our
work, we propose a simple and intuitive adaptation of Pattern-Exploiting
Training (PET), a recent approach which combines the cloze-questions mechanism
and fine-tuning for few-shot learning: the key idea is to rephrase the NER task
with patterns. Our approach achieves considerably better performance than
standard fine-tuning and comparable or improved results with respect to other
few-shot baselines without relying on manually annotated data or distant
supervision on three benchmark datasets: NCBI-disease, BC2GM and a private
Italian biomedical corpus.

    

### [[2111.12454] Exploring Business Process Deviance with Sequential and Declarative Patterns](http://arxiv.org/abs/2111.12454)


  Business process deviance refers to the phenomenon whereby a subset of the
executions of a business process deviate, in a negative or positive way, with
respect to {their} expected or desirable outcomes. Deviant executions of a
business process include those that violate compliance rules, or executions
that undershoot or exceed performance targets. Deviance mining is concerned
with uncovering the reasons for deviant executions by analyzing event logs
stored by the systems supporting the execution of a business process. In this
paper, the problem of explaining deviations in business processes is first
investigated by using features based on sequential and declarative patterns,
and a combination of them. Then, the explanations are further improved by
leveraging the data attributes of events and traces in event logs through
features based on pure data attribute values and data-aware declarative rules.
The explanations characterizing the deviances are then extracted by direct and
indirect methods for rule induction. Using real-life logs from multiple
domains, a range of feature types and different forms of decision rules are
evaluated in terms of their ability to accurately discriminate between
non-deviant and deviant executions of a process as well as in terms of
understandability of the final outcome returned to the users.

    

### [[2111.12491] Efficient semidefinite bounds for multi-label discrete graphical models](http://arxiv.org/abs/2111.12491)


  By concisely representing a joint function of many variables as the
combination of small functions, discrete graphical models (GMs) provide a
powerful framework to analyze stochastic and deterministic systems of
interacting variables. One of the main queries on such models is to identify
the extremum of this joint function. This is known as the Weighted Constraint
Satisfaction Problem (WCSP) on deterministic Cost Function Networks and as
Maximum a Posteriori (MAP) inference on stochastic Markov Random Fields.
Algorithms for approximate WCSP inference typically rely on local consistency
algorithms or belief propagation. These methods are intimately related to
linear programming (LP) relaxations and often coupled with reparametrizations
defined by the dual solution of the associated LP. Since the seminal work of
Goemans and Williamson, it is well understood that convex SDP relaxations can
provide superior guarantees to LP. But the inherent computational cost of
interior point methods has limited their application. The situation has
improved with the introduction of non-convex Burer-Monteiro style methods which
are well suited to handle the SDP relaxation of combinatorial problems with
binary variables (such as MAXCUT, MaxSAT or MAP/Ising). We compute low rank SDP
upper and lower bounds for discrete pairwise graphical models with arbitrary
number of values and arbitrary binary cost functions by extending a
Burer-Monteiro style method based on row-by-row updates. We consider a
traditional dualized constraint approach and a dedicated Block Coordinate
Descent approach which avoids introducing large penalty coefficients to the
formulation. On increasingly hard and dense WCSP/CFN instances, we observe that
the BCD approach can outperform the dualized approach and provide tighter
bounds than local consistencies/convergent message passing approaches.

    

### [[2111.12498] Meta Mask Correction for Nuclei Segmentation in Histopathological Image](http://arxiv.org/abs/2111.12498)


  Nuclei segmentation is a fundamental task in digital pathology analysis and
can be automated by deep learning-based methods. However, the development of
such an automated method requires a large amount of data with precisely
annotated masks which is hard to obtain. Training with weakly labeled data is a
popular solution for reducing the workload of annotation. In this paper, we
propose a novel meta-learning-based nuclei segmentation method which follows
the label correction paradigm to leverage data with noisy masks. Specifically,
we design a fully conventional meta-model that can correct noisy masks using a
small amount of clean meta-data. Then the corrected masks can be used to
supervise the training of the segmentation model. Meanwhile, a bi-level
optimization method is adopted to alternately update the parameters of the main
segmentation model and the meta-model in an end-to-end way. Extensive
experimental results on two nuclear segmentation datasets show that our method
achieves the state-of-the-art result. It even achieves comparable performance
with the model training on supervised data in some noisy settings.

    

### [[2111.12535] Knowledge Enhanced Sports Game Summarization](http://arxiv.org/abs/2111.12535)


  Sports game summarization aims at generating sports news from live
commentaries. However, existing datasets are all constructed through automated
collection and cleaning processes, resulting in a lot of noise. Besides,
current works neglect the knowledge gap between live commentaries and sports
news, which limits the performance of sports game summarization. In this paper,
we introduce K-SportsSum, a new dataset with two characteristics: (1)
K-SportsSum collects a large amount of data from massive games. It has 7,854
commentary-news pairs. To improve the quality, K-SportsSum employs a manual
cleaning process; (2) Different from existing datasets, to narrow the knowledge
gap, K-SportsSum further provides a large-scale knowledge corpus that contains
the information of 523 sports teams and 14,724 sports players. Additionally, we
also introduce a knowledge-enhanced summarizer that utilizes both live
commentaries and the knowledge to generate sports news. Extensive experiments
on K-SportsSum and SportsSum datasets show that our model achieves new
state-of-the-art performances. Qualitative analysis and human study further
verify that our model generates more informative sports news.

    

### [[2111.12542] Autonomous bot with ML-based reactive navigation for indoor environment](http://arxiv.org/abs/2111.12542)


  Local or reactive navigation is essential for autonomous mobile robots which
operate in an indoor environment. Techniques such as SLAM, computer vision
require significant computational power which increases cost. Similarly, using
rudimentary methods makes the robot susceptible to inconsistent behavior. This
paper aims to develop a robot that balances cost and accuracy by using machine
learning to predict the best obstacle avoidance move based on distance inputs
from four ultrasonic sensors that are strategically mounted on the front,
front-left, front-right, and back of the robot. The underlying hardware
consists of an Arduino Uno and a Raspberry Pi 3B. The machine learning model is
first trained on the data collected by the robot. Then the Arduino continuously
polls the sensors and calculates the distance values, and in case of critical
need for avoidance, a suitable maneuver is made by the Arduino. In other
scenarios, sensor data is sent to the Raspberry Pi using a USB connection and
the machine learning model generates the best move for navigation, which is
sent to the Arduino for driving motors accordingly. The system is mounted on a
2-WD robot chassis and tested in a cluttered indoor setting with most
impressive results.

    

### [[2111.12560] Building Object-based Causal Programs for Human-like Generalization](http://arxiv.org/abs/2111.12560)


  We present a novel task that measures how people generalize objects' causal
powers based on observing a single (Experiment 1) or a few (Experiment 2)
causal interactions between object pairs. We propose a computational modeling
framework that can synthesize human-like generalization patterns in our task
setting, and sheds light on how people may navigate the compositional space of
possible causal functions and categories efficiently. Our modeling framework
combines a causal function generator that makes use of agent and recipient
objects' features and relations, and a Bayesian non-parametric inference
process to govern the degree of similarity-based generalization. Our model has
a natural "resource-rational" variant that outperforms a naive Bayesian account
in describing participants, in particular reproducing a generalization-order
effect and causal asymmetry observed in our behavioral experiments. We argue
that this modeling framework provides a computationally plausible mechanism for
real world causal generalization.

    

### [[2111.12677] Topological and Algebraic Structures of the Space of Atanassov's Intuitionistic Fuzzy Values](http://arxiv.org/abs/2111.12677)


  We demonstrate that the space of intuitionistic fuzzy values (IFVs) with the
linear order based on a score function and an accuracy function has the same
algebraic structure as the one induced by the linear order based on a
similarity function and an accuracy function. By introducing a new operator for
IFVs via the linear order based on a score function and an accuracy function,
we present that such an operator is a strong negation on IFVs. Moreover, we
propose that the space of IFVs is a complete lattice and a Kleene algebra with
the new operator. We also observe that the topological space of IFVs with the
order topology induced by the above two linear orders is not separable and
metrizable but compact and connected. From exactly new perspectives, our
results partially answer three open problems posed by Atanassov [Intuitionistic
Fuzzy Sets: Theory and Applications, Springer, 1999] and [On Intuitionistic
Fuzzy Sets Theory, Springer, 2012]. Furthermore, we construct an isomorphism
between the spaces of IFVs and q-rung orthopedic fuzzy values (q-ROFVs) under
the corresponding linear orders. Meanwhile, we introduce the concept of the
admissible similarity measures with particular orders for IFSs, extending the
previous definition of the similarity measure for IFSs, and construct an
admissible similarity measure with the linear order based on a score function
and an accuracy function, which is effectively applied to a pattern recognition
problem about the classification of building materials.

    

### [[2111.12696] A Lightweight Graph Transformer Network for Human Mesh Reconstruction from 2D Human Pose](http://arxiv.org/abs/2111.12696)


  Existing deep learning-based human mesh reconstruction approaches have a
tendency to build larger networks in order to achieve higher accuracy.
Computational complexity and model size are often neglected, despite being key
characteristics for practical use of human mesh reconstruction models (e.g.
virtual try-on systems). In this paper, we present GTRS, a lightweight
pose-based method that can reconstruct human mesh from 2D human pose. We
propose a pose analysis module that uses graph transformers to exploit
structured and implicit joint correlations, and a mesh regression module that
combines the extracted pose feature with the mesh template to reconstruct the
final human mesh. We demonstrate the efficiency and generalization of GTRS by
extensive evaluations on the Human3.6M and 3DPW datasets. In particular, GTRS
achieves better accuracy than the SOTA pose-based method Pose2Mesh while only
using 10.2% of the parameters (Params) and 2.5% of the FLOPs on the challenging
in-the-wild 3DPW dataset. Code will be publicly available.

    

### [[2111.12705] MixSyn: Learning Composition and Style for Multi-Source Image Synthesis](http://arxiv.org/abs/2111.12705)


  Synthetic images created by generative models increase in quality and
expressiveness as newer models utilize larger datasets and novel architectures.
Although this photorealism is a positive side-effect from a creative
standpoint, it becomes problematic when such generative models are used for
impersonation without consent. Most of these approaches are built on the
partial transfer between source and target pairs, or they generate completely
new samples based on an ideal distribution, still resembling the closest real
sample in the dataset. We propose MixSyn (read as " mixin' ") for learning
novel fuzzy compositions from multiple sources and creating novel images as a
mix of image regions corresponding to the compositions. MixSyn not only
combines uncorrelated regions from multiple source masks into a coherent
semantic composition, but also generates mask-aware high quality
reconstructions of non-existing images. We compare MixSyn to state-of-the-art
single-source sequential generation and collage generation approaches in terms
of quality, diversity, realism, and expressive power; while also showcasing
interactive synthesis, mix & match, and edit propagation tasks, with no mask
dependency.

    

### [[2002.09827] A Formal Treatment of Contract Signature](http://arxiv.org/abs/2002.09827)


  The paper develops a logical understanding of processes for signature of
legal contracts, motivated by applications to legal recognition of smart
contracts on blockchain platforms. A number of axioms and rules of inference
are developed that can be used to justify a ``meeting of the minds''
precondition for contract formation from the fact that certain content has been
signed. In addition to an ``offer and acceptance'' process, the paper considers
``signature in counterparts'', a legal process that permits a contract between
two or more parties to be brought into force by having the parties
independently (possibly, remotely) sign different copies of the contract,
rather than placing their signatures on a common copy at a physical meeting. It
is argued that a satisfactory account of signature in counterparts benefits
from a logic with syntactic self-reference. The axioms used are supported by a
formal semantics, and a number of further properties of the logic are
investigated. In particular, it is shown that the logic implies that when a
contract has been signed, the parties do not just agree, but are in mutual
agreement (a common-knowledge-like notion) about the terms of the contract.

    

### [[2012.15197] SemGloVe: Semantic Co-occurrences for GloVe from BERT](http://arxiv.org/abs/2012.15197)


  GloVe learns word embeddings by leveraging statistical information from word
co-occurrence matrices. However, word pairs in the matrices are extracted from
a predefined local context window, which might lead to limited word pairs and
potentially semantic irrelevant word pairs. In this paper, we propose SemGloVe,
which distills semantic co-occurrences from BERT into static GloVe word
embeddings. Particularly, we propose two models to extract co-occurrence
statistics based on either the masked language model or the multi-head
attention weights of BERT. Our methods can extract word pairs without limiting
by the local window assumption and can define the co-occurrence weights by
directly considering the semantic distance between word pairs. Experiments on
several word similarity datasets and four external tasks show that SemGloVe can
outperform GloVe.

    

### [[2103.13581] EfficientTDNN: Efficient Architecture Search for Speaker Recognition](http://arxiv.org/abs/2103.13581)


  Convolutional neural networks (CNNs), such as the time-delay neural network
(TDNN), have shown their remarkable capability in learning speaker embedding.
However, they meanwhile bring a huge computational cost in storage size,
processing, and memory. Discovering the specialized CNN that meets a specific
constraint requires a substantial effort of human experts. Compared with
hand-designed approaches, neural architecture search (NAS) appears as a
practical technique in automating the manual architecture design process and
has attracted increasing interest in spoken language processing tasks such as
speaker recognition. In this paper, we propose EfficientTDNN, an efficient
architecture search framework consisting of a TDNN-based supernet and a
TDNN-NAS algorithm. The proposed supernet introduces temporal convolution of
different ranges of the receptive field and feature aggregation of various
resolutions from different layers to TDNN. On top of it, the TDNN-NAS algorithm
quickly searches for the desired TDNN architecture via weight-sharing subnets,
which surprisingly reduces computation while handling the vast number of
devices with various resources requirements. Experimental results on the
VoxCeleb dataset show the proposed EfficientTDNN enables approximate $10^{13}$
architectures concerning depth, kernel, and width. Considering different
computation constraints, it achieves a 2.20% equal error rate (EER) with 204M
multiply-accumulate operations (MACs), 1.41% EER with 571M MACs as well as
0.94% EER with 1.45G MACs. Comprehensive investigations suggest that the
trained supernet generalizes subnets not sampled during training and obtains a
favorable trade-off between accuracy and efficiency.

    

### [[2106.04284] LLAMA: The Low-Level Abstraction For Memory Access](http://arxiv.org/abs/2106.04284)


  The performance gap between CPU and memory widens continuously. Choosing the
best memory layout for each hardware architecture is increasingly important as
more and more programs become memory bound. For portable codes that run across
heterogeneous hardware architectures, the choice of the memory layout for data
structures is ideally decoupled from the rest of a program. This can be
accomplished via a zero-runtime-overhead abstraction layer, underneath which
memory layouts can be freely exchanged.
We present the Low-Level Abstraction of Memory Access (LLAMA), a C++ library
that provides such a data structure abstraction layer with example
implementations for multidimensional arrays of nested, structured data. LLAMA
provides fully C++ compliant methods for defining and switching custom memory
layouts for user-defined data types. The library is extensible with third-party
allocators.
Providing two close-to-life examples, we show that the LLAMA-generated AoS
(Array of Structs) and SoA (Struct of Arrays) layouts produce identical code
with the same performance characteristics as manually written data structures.
Integrations into the SPEC CPU\textsuperscript{\textregistered} lbm benchmark
and the particle-in-cell simulation PIConGPU demonstrate LLAMA's abilities in
real-world applications. LLAMA's layout-aware copy routines can significantly
speed up transfer and reshuffling of data between layouts compared with naive
element-wise copying.
LLAMA provides a novel tool for the development of high-performance C++
applications in a heterogeneous environment.

    

### [[2111.12116] Caviar: An E-graph Based TRS for Automatic Code Optimization](http://arxiv.org/abs/2111.12116)


  Term Rewriting Systems (TRS) are used in compilers to simplify and prove
expressions. State-of-the-art TRSs in compilers use a greedy algorithm that
applies a set of rewriting rules in a predefined order (where some of the rules
are not axiomatic). This leads to a loss in the ability to simplify certain
expressions. E-graphs and equality saturation sidestep this issue by
representing the different equivalent expressions in a compact manner from
which the optimal expression can be extracted. While an e-graph-based TRS can
be more powerful than a TRS that uses a greedy algorithm, it is slower because
expressions may have a large or sometimes infinite number of equivalent
expressions. Accelerating e-graph construction is crucial for making the use of
e-graphs practical in compilers. In this paper, we present Caviar, an
e-graph-based TRS for proving expressions within compilers. Caviar is a fast
(20x faster than base e-graph TRS) and flexible (completely parameterized) TRS
that that relies on three novel techniques: 1) a technique that stops e-graphs
from growing when the goal is reached, called Iteration Level Check; 2) a
mechanism that balances exploration and exploitation in the equality saturation
algorithm, called Pulsing Caviar; 3) a technique to stop e-graph construction
before reaching saturation when a non-provable pattern is detected, called
Non-Provable Patterns Detection (NPPD). We evaluate caviar on Halide, an
optimizing compiler that relies on a greedy-algorithm-based TRS to simplify and
prove its expressions. The proposed techniques allow Caviar to accelerate
e-graph expansion by 20x for the task of proving expressions. They also allow
Caviar to prove 51% of the expressions that Halide's TRS cannot prove while
being only 0.68x slower.

    

### [[2111.12147] kmclib: Automated Inference and Verification of Session Types}](http://arxiv.org/abs/2111.12147)


  Theories and tools based on multiparty session types offer correctness
guarantees for concurrent programs that communicate using message-passing.
These guarantees usually come at the cost of an intrinsically top-down
approach, which requires the communication behaviour of the entire program to
be specified as a global type. This paper introduces kmclib: an OCaml library
that supports the development of correct message-passing programs without
having to write any types. The library utilises the meta-programming facilities
of OCaml to automatically infer the session types of concurrent programs and
verify their compatibility (k-MC). Well-typed programs, written with kmclib, do
not lead to communication errors and cannot get stuck.

    

### [[2111.12238] Composing Loop-carried Dependence with Other Loops](http://arxiv.org/abs/2111.12238)


  Sparse fusion is a compile-time loop transformation and runtime scheduling
implemented as a domain-specific code generator. Sparse fusion generates
efficient parallel code for the combination of two sparse matrix kernels where
at least one of the kernels has loop-carried dependencies. Available
implementations optimize individual sparse kernels. When optimized separately,
the irregular dependence patterns of sparse kernels create synchronization
overheads and load imbalance, and their irregular memory access patterns result
in inefficient cache usage, which reduces parallel efficiency. Sparse fusion
uses a novel inspection strategy with code transformations to generate parallel
fused code for sparse kernel combinations that is optimized for data locality
and load balance. Code generated by Sparse fusion outperforms the existing
implementations ParSy and MKL on average 1.6X and 5.1X respectively and
outperforms the LBC and DAGP coarsening strategies applied to a fused data
dependence graph on average 5.1X and 7.2X respectively for various kernel
combinations.

    

### [[2111.12243] Differentiating-based Vectorization for Sparse Kernels](http://arxiv.org/abs/2111.12243)


  Sparse computations frequently appear in scientific simulations and the
performance of these simulations rely heavily on the optimization of the sparse
codes. The compact data structures and irregular computation patterns in sparse
matrix computations introduce challenges to vectorizing these codes. Available
approaches primarily vectorize regular regions of computations in the sparse
code. They also reorganize data and computations, at a cost, to increase the
number of regular regions. In this work, we propose a novel polyhedral model,
called the partially strided codelets (PSC), that enables the vectorization of
computation regions with irregular data access patterns. PSCs also improve data
locality in sparse computation. Our DDF inspector-executor framework
efficiently mines the memory accesses in the sparse computation, using an
access function differentiation approach, to find PSC codelets. It generates
vectorized code for the sparse matrix multiplication kernel (SpMV), a kernel
with parallel outer loops, and for kernels with carried dependence,
specifically the sparse triangular solver (SpTRSV). We demonstrate the
performance of the DDF-generated code on a set of 60 large and small matrices
(0.05-130M nonzeros). DDF outperforms the highly specialized library MKL with
an average speedup of 1.93 and 4.5X for SpMV and SpTRSV, respectively. For the
same matrices, DDF outperforms the state-of-the-art inspector-executor
framework Sympiler [1] for the SpTRSV kernel by up to 11X and the work by
Augustine et. al [2] for the SpMV kernel by up to 12X.

    

### [[2111.12420] CircuitFlow: A Domain Specific Language for Dataflow Programming (with appendices)](http://arxiv.org/abs/2111.12420)


  Dataflow applications, such as machine learning algorithms, can run for days,
making it desirable to have assurances that they will work correctly. Current
tools are not good enough: too often the interactions between tasks are not
type-safe, leading to undesirable run-time errors. This paper presents a new
declarative Haskell Embedded DSL (eDSL) for dataflow programming: CircuitFlow.
Defined as a Symmetric Monoidal Preorder (SMP) on data that models dependencies
in the workflow, it has a strong mathematical basis, refocusing on how data
flows through an application, resulting in a more expressive solution that not
only catches errors statically, but also achieves competitive run-time
performance. In our preliminary evaluation, CircuitFlow outperforms the
industry-leading Luigi library of Spotify by scaling better with the number of
inputs. The innovative creation of CircuitFlow is also of note, exemplifying
how to create a modular eDSL whose semantics necessitates effects, and where
storing complex type information for program correctness is paramount.

    

### [[2111.12478] Predictive Data Race Detection for GPUs](http://arxiv.org/abs/2111.12478)


  The high degree of parallelism and relatively complicated synchronization
mechanisms in GPUs make writing correct kernels difficult. Data races pose one
such concurrency correctness challenge, and therefore, effective methods of
detecting as many data races as possible are required.
Predictive partial order relations for CPU programs aim to expose data races
that can be hidden during a dynamic execution. Existing predictive partial
orders cannot be naÃ¯vely applied to analyze GPU kernels because of the
differences in programming models. This work proposes GWCP, a predictive
partial order for data race detection of GPU kernels. GWCP extends a sound and
precise relation called weak-causally-precedes (WCP) proposed in the context of
multithreaded shared memory CPU programs to GPU kernels. GWCP takes into
account the GPU thread hierarchy and different synchronization semantics such
as barrier synchronization and scoped atomics and locks.
We implement a tool called PreDataR that tracks the GWCP relation using
binary instrumentation. PreDataR includes three optimizations and a novel
vector clock compression scheme that are readily applicable to other partial
order based analyses. Our evaluation with several microbenchmarks and
benchmarks shows that PreDataR has better data race coverage compared to prior
techniques at practical run-time overheads.

    

### [[2111.12553] CycleQ: An Efficient Basis for Cyclic Equational Reasoning](http://arxiv.org/abs/2111.12553)


  We propose a new cyclic proof system for automated, equational reasoning
about the behaviour of pure functional programs. The key to the system is the
way in which cyclic proof and equational reasoning are mediated by the use of
contextual substitution as a cut rule. We show that our system, although
simple, already subsumes several of the approaches to implicit induction
variously known as "inductionless induction", "rewriting induction", and "proof
by consistency". By restricting the form of the traces, we show that global
correctness in our system can be verified incrementally, taking advantage of
the well-known size-change principle, which leads to an efficient
implementation of proof search. Our CycleQ tool, accessible as a GHC plugin,
shows promising results on a number of standard benchmarks.

    

### [[2111.12682] A Formally-Verified Framework for Fair Synchronization in Kotlin Coroutines](http://arxiv.org/abs/2111.12682)


  Writing concurrent code that is both correct and efficient is notoriously
difficult: thus, programmers often prefer to use synchronization abstractions,
which render code simpler and easier to reason about. Despite a wealth of work
on this topic, there is still a gap between the rich semantics provided by
synchronization abstractions in modern programming languages--specifically,
fair FIFO ordering of synchronization requests and support for abortable
operations--and frameworks for implementing such semantics correctly and
efficiently. Supporting such semantics is critical given the rising popularity
of constructs for asynchronous programming, such as coroutines, which abort
frequently, and should be cheaper to suspend and resume compared to native
threads.
We introduce a new framework called the CancellableQueueSynchronizer (CQS),
which enables efficient fair and abortable implementations of fundamental
synchronization primitives such as mutexes, semaphores, barriers,
count-down-latches, and blocking pools. Our first contribution is algorithmic,
as implementing both fairness and abortability efficiently at this level of
generality is non-trivial. Importantly, all our algorithms come with formal
proofs in the Iris framework for Coq. These proofs are modular, so it is easy
to prove correctness for new primitives implemented on top of CQS. To validate
practical impact, we integrated CQS into the Kotlin Coroutines library.
Compared against Java's AbstractQueuedSynchronizer, the only practical
abstraction to provide similar semantics, CQS shows significant improvements
across all benchmarks, of up to two orders of magnitude. In sum, CQS is the
first framework to combine expressiveness with formal guarantees and strong
practical performance, and should be extensible to other languages and other
families of synchronization primitives.

    

### [[2105.05801] SoK: Practical Foundations for Software Spectre Defenses](http://arxiv.org/abs/2105.05801)


  Spectre vulnerabilities violate our fundamental assumptions about
architectural abstractions, allowing attackers to steal sensitive data despite
previously state-of-the-art countermeasures. To defend against Spectre,
developers of verification tools and compiler-based mitigations are forced to
reason about microarchitectural details such as speculative execution. In order
to aid developers with these attacks in a principled way, the research
community has sought formal foundations for speculative execution upon which to
rebuild provable security guarantees.
This paper systematizes the community's current knowledge about software
verification and mitigation for Spectre. We study state-of-the-art software
defenses, both with and without associated formal models, and use a cohesive
framework to compare the security properties each defense provides. We explore
a wide variety of tradeoffs in the expressiveness of formal frameworks, the
complexity of defense tools, and the resulting security guarantees. As a result
of our analysis, we suggest practical choices for developers of analysis and
mitigation tools, and we identify several open problems in this area to guide
future work on grounded software defenses.

    