
## 2021-11-15

### [[2111.06595] FaaS Execution Models for Edge Applications](http://arxiv.org/abs/2111.06595)


  In this paper, we address the problem of supporting stateful workflows
following a Function-as-a-Service (FaaS) model in edge networks. In particular
we focus on the problem of data transfer, which can be a performance bottleneck
due to the limited speed of communication links in some edge scenarios and we
propose three different schemes: a pure FaaS implementation, StateProp, i.e.,
propagation of the application state throughout the entire chain of functions,
and StateLocal, i.e., a solution where the state is kept local to the workers
that run functions and retrieved only as needed. We then extend the proposed
schemes to the more general case of applications modeled as Directed Acyclic
Graphs (DAGs), which cover a broad range of practical applications, e.g., in
the Internet of Things (IoT) area. Our contribution is validated via a
prototype implementation. Experiments in emulated conditions show that applying
the data locality principle reduces significantly the volume of network traffic
required and improves the end-to-end delay performance, especially with local
caching on edge nodes and low link speeds.

    

### [[2111.06596] Towards 6G Internet of Things: Recent Advances, Use Cases, and Open Challenges](http://arxiv.org/abs/2111.06596)


  Smart services based on the Internet of Everything (IoE) are gaining
considerable popularity due to the ever-increasing demands of wireless
networks. This demands the appraisal of the wireless networks with enhanced
properties as next-generation communication systems. Although 5G networks show
great potential to support numerous IoE based services, it is not adequate to
meet the complete requirements of the new smart applications. Therefore, there
is an increased demand for envisioning the 6G wireless communication systems to
overcome the major limitations in the existing 5G networks. Moreover,
incorporating artificial intelligence in 6G will provide solutions for very
complex problems relevant to network optimization. Furthermore, to add further
value to the future 6G networks, researchers are investigating new
technologies, such as THz and quantum communications. The requirements of
future 6G wireless communications demand to support massive data-driven
applications and the increasing number of users. This paper presents recent
advances in the 6G wireless networks, including the evolution from 1G to 5G
communications, the research trends for 6G, enabling technologies, and
state-of-the-art 6G projects.

    

### [[2111.06680] Deep Reinforcement Model Selection for Communications Resource Allocation in On-Site Medical Care](http://arxiv.org/abs/2111.06680)


  Greater capabilities of mobile communications technology enable
interconnection of on-site medical care at a scale previously unavailable.
However, embedding such critical, demanding tasks into the already complex
infrastructure of mobile communications proves challenging. This paper explores
a resource allocation scenario where a scheduler must balance mixed performance
metrics among connected users. To fulfill this resource allocation task, we
present a scheduler that adaptively switches between different model-based
scheduling algorithms. We make use of a deep Q-Network to learn the benefit of
selecting a scheduling paradigm for a given situation, combining advantages
from model-driven and data-driven approaches. The resulting ensemble scheduler
is able to combine its constituent algorithms to maximize a sum-utility cost
function while ensuring performance on designated high-priority users.

    

### [[2111.06714] A Review on Communication Protocols for Autonomous Unmanned Aerial Vehicles for Inspection Application](http://arxiv.org/abs/2111.06714)


  The communication system is a critical part of the system design for the
autonomous UAV. It has to address different considerations, including
efficiency, reliability and mobility of the UAV. In addition, a multi-UAV
system requires a communication system to assist information sharing, task
allocation and collaboration in a team of UAVs. In this paper, we review
communication solutions for supporting a team of UAVs while considering an
application in the power line inspection industry. We provide a review of
candidate wireless communication technologies {for supporting communication in
UAV applications. Performance measurements and UAV-related channel modeling of
those candidate technologies are reviewed. A discussion of current technologies
for building UAV mesh networks is presented. We then analyze the structure,
interface and performance of robotic communication middleware, ROS and ROS2.
Based on our review, the features and dependencies of candidate solutions in
each layer of the communication system are presented.

    

### [[2111.06723] Mobility prediction Based on Machine Learning Algorithms](http://arxiv.org/abs/2111.06723)


  Nowadays mobile communication is growing fast in the 5G communication
industry. With the increasing capacity requirements and requirements for
quality of experience, mobility prediction has been widely applied to mobile
communication and has becoming one of the key enablers that utilizes historical
traffic information to predict future locations of traffic users, Since
accurate mobility prediction can help enable efficient radio resource
management, assist route planning, guide vehicle dispatching, or mitigate
traffic congestion. However, mobility prediction is a challenging problem due
to the complicated traffic network. In the past few years, plenty of researches
have been done in this area, including Non-Machine-Learning (Non-ML)- based and
Machine-Learning (ML)-based mobility prediction. In this paper, firstly we
introduce the state of the art technologies for mobility prediction. Then, we
selected Support Vector Machine (SVM) algorithm, the ML algorithm for practical
traffic date training. Lastly, we analyse the simulation results for mobility
prediction and introduce a future work plan where mobility prediction will be
applied for improving mobile communication.

    

### [[2111.06743] Self-energy recycling for low-power reliable networks: Half-duplex or Full-duplex?](http://arxiv.org/abs/2111.06743)


  Self-energy recycling (sER), which allows transmit energy re-utilization, has
emerged as a viable option for improving the energy efficiency (EE) in
low-power Internet of Things networks. In this work, we investigate its
benefits also in terms of reliability improvements and compare the performance
of full-duplex (FD) and half-duplex (HD) schemes when using multi-antenna
techniques in a communication system. We analyze the trade-offs when
considering not only the energy spent on transmission but also the circuitry
power consumption, thus making the analysis of much more practical interest. In
addition to the well known spectral efficiency improvements, results show that
FD also outperforms HD in terms of reliability. We show that sER introduces not
only benefits in EE matters but also some modifications on how to achieve
maximum reliability fairness between uplink and downlink transmissions, which
is the main goal in this work. In order to achieve this objective, we propose
the use of a dynamic FD scheme where the small base station (SBS) determines
the optimal allocation of antennas for transmission and reception. We show the
significant improvement gains of this strategy for the system outage
probability when compared to the simple HD and FD schemes.

    

### [[2111.06417] Online-compatible Unsupervised Non-resonant Anomaly Detection](http://arxiv.org/abs/2111.06417)


  There is a growing need for anomaly detection methods that can broaden the
search for new particles in a model-agnostic manner. Most proposals for new
methods focus exclusively on signal sensitivity. However, it is not enough to
select anomalous events - there must also be a strategy to provide context to
the selected events. We propose the first complete strategy for unsupervised
detection of non-resonant anomalies that includes both signal sensitivity and a
data-driven method for background estimation. Our technique is built out of two
simultaneously-trained autoencoders that are forced to be decorrelated from
each other. This method can be deployed offline for non-resonant anomaly
detection and is also the first complete online-compatible anomaly detection
strategy. We show that our method achieves excellent performance on a variety
of signals prepared for the ADC2021 data challenge.

    

### [[2111.06420] Explainable AI (XAI): A Systematic Meta-Survey of Current Challenges and Future Opportunities](http://arxiv.org/abs/2111.06420)


  The past decade has seen significant progress in artificial intelligence
(AI), which has resulted in algorithms being adopted for resolving a variety of
problems. However, this success has been met by increasing model complexity and
employing black-box AI models that lack transparency. In response to this need,
Explainable AI (XAI) has been proposed to make AI more transparent and thus
advance the adoption of AI in critical domains. Although there are several
reviews of XAI topics in the literature that identified challenges and
potential research directions in XAI, these challenges and research directions
are scattered. This study, hence, presents a systematic meta-survey for
challenges and future research directions in XAI organized in two themes: (1)
general challenges and research directions in XAI and (2) challenges and
research directions in XAI based on machine learning life cycle's phases:
design, development, and deployment. We believe that our meta-survey
contributes to XAI literature by providing a guide for future exploration in
the XAI area.

    

### [[2111.06425] Multiple Hypothesis Hypergraph Tracking for Posture Identification in Embryonic Caenorhabditis elegans](http://arxiv.org/abs/2111.06425)


  Current methods in multiple object tracking (MOT) rely on independent object
trajectories undergoing predictable motion to effectively track large numbers
of objects. Adversarial conditions such as volatile object motion and imperfect
detections create a challenging tracking landscape in which established methods
may yield inadequate results. Multiple hypothesis hypergraph tracking (MHHT) is
developed to perform MOT among interdependent objects amid noisy detections.
The method extends traditional multiple hypothesis tracking (MHT) via
hypergraphs to model correlated object motion, allowing for robust tracking in
challenging scenarios. MHHT is applied to perform seam cell tracking during
late-stage embryogenesis in embryonic C. elegans.

    

### [[2111.06447] Observation Error Covariance Specification in Dynamical Systems for Data assimilation using Recurrent Neural Networks](http://arxiv.org/abs/2111.06447)


  Data assimilation techniques are widely used to predict complex dynamical
systems with uncertainties, based on time-series observation data. Error
covariance matrices modelling is an important element in data assimilation
algorithms which can considerably impact the forecasting accuracy. The
estimation of these covariances, which usually relies on empirical assumptions
and physical constraints, is often imprecise and computationally expensive
especially for systems of large dimension. In this work, we propose a
data-driven approach based on long short term memory (LSTM) recurrent neural
networks (RNN) to improve both the accuracy and the efficiency of observation
covariance specification in data assimilation for dynamical systems. Learning
the covariance matrix from observed/simulated time-series data, the proposed
approach does not require any knowledge or assumption about prior error
distribution, unlike classical posterior tuning methods. We have compared the
novel approach with two state-of-the-art covariance tuning algorithms, namely
DI01 and D05, first in a Lorenz dynamical system and then in a 2D shallow water
twin experiments framework with different covariance parameterization using
ensemble assimilation. This novel method shows significant advantages in
observation covariance specification, assimilation accuracy and computational
efficiency.

    

### [[2111.06457] Variability-Aware Training and Self-Tuning of Highly Quantized DNNs for Analog PIM](http://arxiv.org/abs/2111.06457)


  DNNs deployed on analog processing in memory (PIM) architectures are subject
to fabrication-time variability. We developed a new joint variability- and
quantization-aware DNN training algorithm for highly quantized analog PIM-based
models that is significantly more effective than prior work. It outperforms
variability-oblivious and post-training quantized models on multiple computer
vision datasets/models. For low-bitwidth models and high variation, the gain in
accuracy is up to 35.7% for ResNet-18 over the best alternative.
We demonstrate that, under a realistic pattern of within- and between-chip
components of variability, training alone is unable to prevent large DNN
accuracy loss (of up to 54% on CIFAR-100/ResNet-18). We introduce a self-tuning
DNN architecture that dynamically adjusts layer-wise activations during
inference and is effective in reducing accuracy loss to below 10%.

    

### [[2111.06458] MultiSV: Dataset for Far-Field Multi-Channel Speaker Verification](http://arxiv.org/abs/2111.06458)


  Motivated by unconsolidated data situation and the lack of a standard
benchmark in the field, we complement our previous efforts and present a
comprehensive corpus designed for training and evaluating text-independent
multi-channel speaker verification systems. It can be readily used also for
experiments with dereverberation, denoising, and speech enhancement. We tackled
the ever-present problem of the lack of multi-channel training data by
utilizing data simulation on top of clean parts of the Voxceleb dataset. The
development and evaluation trials are based on a retransmitted Voices Obscured
in Complex Environmental Settings (VOiCES) corpus, which we modified to provide
multi-channel trials. We publish full recipes that create the dataset from
public sources as the MultiSV corpus, and we provide results with two of our
multi-channel speaker verification systems with neural network-based
beamforming based either on predicting ideal binary masks or the more recent
Conv-TasNet.

    

### [[2111.06464] Catalytic Role Of Noise And Necessity Of Inductive Biases In The Emergence Of Compositional Communication](http://arxiv.org/abs/2111.06464)


  Communication is compositional if complex signals can be represented as a
combination of simpler subparts. In this paper, we theoretically show that
inductive biases on both the training framework and the data are needed to
develop a compositional communication. Moreover, we prove that compositionality
spontaneously arises in the signaling games, where agents communicate over a
noisy channel. We experimentally confirm that a range of noise levels, which
depends on the model and the data, indeed promotes compositionality. Finally,
we provide a comprehensive study of this dependence and report results in terms
of recently studied compositionality metrics: topographical similarity,
conflict count, and context independence.

    

### [[2111.06466] Molecular Dynamics Simulations on Cloud Computing and Machine Learning Platforms](http://arxiv.org/abs/2111.06466)


  Scientific computing applications have benefited greatly from high
performance computing infrastructure such as supercomputers. However, we are
seeing a paradigm shift in the computational structure, design, and
requirements of these applications. Increasingly, data-driven and machine
learning approaches are being used to support, speed-up, and enhance scientific
computing applications, especially molecular dynamics simulations.
Concurrently, cloud computing platforms are increasingly appealing for
scientific computing, providing "infinite" computing powers, easier programming
and deployment models, and access to computing accelerators such as TPUs
(Tensor Processing Units). This confluence of machine learning (ML) and cloud
computing represents exciting opportunities for cloud and systems researchers.
ML-assisted molecular dynamics simulations are a new class of workload, and
exhibit unique computational patterns. These simulations present new challenges
for low-cost and high-performance execution. We argue that transient cloud
resources, such as low-cost preemptible cloud VMs, can be a viable platform for
this new workload. Finally, we present some low-hanging fruits and long-term
challenges in cloud resource management, and the integration of molecular
dynamics simulations into ML platforms (such as TensorFlow).

    

### [[2111.06467] SynthBio: A Case Study in Human-AI Collaborative Curation of Text Datasets](http://arxiv.org/abs/2111.06467)


  NLP researchers need more, higher-quality text datasets. Human-labeled
datasets are expensive to collect, while datasets collected via automatic
retrieval from the web such as WikiBio are noisy and can include undesired
biases. Moreover, data sourced from the web is often included in datasets used
to pretrain models, leading to inadvertent cross-contamination of training and
test sets. In this work we introduce a novel method for efficient dataset
curation: we use a large language model to provide seed generations to human
raters, thereby changing dataset authoring from a writing task to an editing
task. We use our method to curate SynthBio - a new evaluation set for WikiBio -
composed of structured attribute lists describing fictional individuals, mapped
to natural language biographies. We show that our dataset of fictional
biographies is less noisy than WikiBio, and also more balanced with respect to
gender and nationality.

    

### [[2111.06476] Automated question generation and question answering from Turkish texts using text-to-text transformers](http://arxiv.org/abs/2111.06476)


  While exam-style questions are a fundamental educational tool serving a
variety of purposes, manual construction of questions is a complex process that
requires training, experience and resources. To reduce the expenses associated
with the manual construction of questions and to satisfy the need for a
continuous supply of new questions, automatic question generation (QG)
techniques can be utilized. However, compared to automatic question answering
(QA), QG is a more challenging task. In this work, we fine-tune a multilingual
T5 (mT5) transformer in a multi-task setting for QA, QG and answer extraction
tasks using a Turkish QA dataset. To the best of our knowledge, this is the
first academic work that attempts to perform automated text-to-text question
generation from Turkish texts. Evaluation results show that the proposed
multi-task setting achieves state-of-the-art Turkish question answering and
question generation performance over TQuADv1, TQuADv2 datasets and XQuAD
Turkish split. The source code and pre-trained models are available at
this https URL.

    

### [[2111.06483] Sequential Aggregation and Rematerialization: Distributed Full-batch Training of Graph Neural Networks on Large Graphs](http://arxiv.org/abs/2111.06483)


  We present the Sequential Aggregation and Rematerialization (SAR) scheme for
distributed full-batch training of Graph Neural Networks (GNNs) on large
graphs. Large-scale training of GNNs has recently been dominated by
sampling-based methods and methods based on non-learnable message passing. SAR
on the other hand is a distributed technique that can train any GNN type
directly on an entire large graph. The key innovation in SAR is the distributed
sequential rematerialization scheme which sequentially re-constructs then frees
pieces of the prohibitively large GNN computational graph during the backward
pass. This results in excellent memory scaling behavior where the memory
consumption per worker goes down linearly with the number of workers, even for
densely connected graphs. Using SAR, we report the largest applications of
full-batch GNN training to-date, and demonstrate large memory savings as the
number of workers increases. We also present a general technique based on
kernel fusion and attention-matrix rematerialization to optimize both the
runtime and memory efficiency of attention-based models. We show that, coupled
with SAR, our optimized attention kernels lead to significant speedups and
memory savings in attention-based GNNs.

    

### [[2111.06486] Variational Auto-Encoder Architectures that Excel at Causal Inference](http://arxiv.org/abs/2111.06486)


  Estimating causal effects from observational data (at either an individual --
or a population -- level) is critical for making many types of decisions. One
approach to address this task is to learn decomposed representations of the
underlying factors of data; this becomes significantly more challenging when
there are confounding factors (which influence both the cause and the effect).
In this paper, we take a generative approach that builds on the recent advances
in Variational Auto-Encoders to simultaneously learn those underlying factors
as well as the causal effects. We propose a progressive sequence of models,
where each improves over the previous one, culminating in the Hybrid model. Our
empirical results demonstrate that the performance of all three proposed models
are superior to both state-of-the-art discriminative as well as other
generative approaches in the literature.

    

### [[2111.06495] Fair AutoML](http://arxiv.org/abs/2111.06495)


  We present an end-to-end automated machine learning system to find machine
learning models not only with good prediction accuracy but also fair. The
system is desirable for the following reasons. (1) Comparing to traditional
AutoML systems, this system incorporates fairness assessment and unfairness
mitigation organically, which makes it possible to quantify fairness of the
machine learning models tried and mitigate their unfairness when necessary. (2)
The system is designed to have a good anytime `fair' performance, such as
accuracy of a model satisfying necessary fairness constraints. To achieve it,
the system includes a strategy to dynamically decide when and on which models
to conduct unfairness mitigation according to the prediction accuracy, fairness
and the resource consumption on the fly. (3) The system is flexible to use. It
can be used together with most of the existing fairness metrics and unfairness
mitigation methods.

    

### [[2111.06503] AnalogNets: ML-HW Co-Design of Noise-robust TinyML Models and Always-On Analog Compute-in-Memory Accelerator](http://arxiv.org/abs/2111.06503)


  Always-on TinyML perception tasks in IoT applications require very high
energy efficiency. Analog compute-in-memory (CiM) using non-volatile memory
(NVM) promises high efficiency and also provides self-contained on-chip model
storage. However, analog CiM introduces new practical considerations, including
conductance drift, read/write noise, fixed analog-to-digital (ADC) converter
gain, etc. These additional constraints must be addressed to achieve models
that can be deployed on analog CiM with acceptable accuracy loss. This work
describes $\textit{AnalogNets}$: TinyML models for the popular always-on
applications of keyword spotting (KWS) and visual wake words (VWW). The model
architectures are specifically designed for analog CiM, and we detail a
comprehensive training methodology, to retain accuracy in the face of analog
non-idealities, and low-precision data converters at inference time. We also
describe AON-CiM, a programmable, minimal-area phase-change memory (PCM) analog
CiM accelerator, with a novel layer-serial approach to remove the cost of
complex interconnects associated with a fully-pipelined design. We evaluate the
AnalogNets on a calibrated simulator, as well as real hardware, and find that
accuracy degradation is limited to 0.8$\%$/1.2$\%$ after 24 hours of PCM drift
(8-bit) for KWS/VWW. AnalogNets running on the 14nm AON-CiM accelerator
demonstrate 8.58/4.37 TOPS/W for KWS/VWW workloads using 8-bit activations,
respectively, and increasing to 57.39/25.69 TOPS/W with $4$-bit activations.

    

### [[2111.06524] An Enhanced Adaptive Bi-clustering Algorithm through Building a Shielding Complex Sub-Matrix](http://arxiv.org/abs/2111.06524)


  Bi-clustering refers to the task of finding sub-matrices (indexed by a group
of columns and a group of rows) within a matrix of data such that the elements
of each sub-matrix (data and features) are related in a particular way, for
instance, that they are similar with respect to some metric. In this paper,
after analyzing the well-known Cheng and Church (CC) bi-clustering algorithm
which has been proved to be an effective tool for mining co-expressed genes.
However, Cheng and Church bi-clustering algorithm and summarizing its
limitations (such as interference of random numbers in the greedy strategy;
ignoring overlapping bi-clusters), we propose a novel enhancement of the
adaptive bi-clustering algorithm, where a shielding complex sub-matrix is
constructed to shield the bi-clusters that have been obtained and to discover
the overlapping bi-clusters. In the shielding complex sub-matrix, the imaginary
and the real parts are used to shield and extend the new bi-clusters,
respectively, and to form a series of optimal bi-clusters. To assure that the
obtained bi-clusters have no effect on the bi-clusters already produced, a unit
impulse signal is introduced to adaptively detect and shield the constructed
bi-clusters. Meanwhile, to effectively shield the null data (zero-size data),
another unit impulse signal is set for adaptive detecting and shielding. In
addition, we add a shielding factor to adjust the mean squared residue score of
the rows (or columns), which contains the shielded data of the sub-matrix, to
decide whether to retain them or not. We offer a thorough analysis of the
developed scheme. The experimental results are in agreement with the
theoretical analysis. The results obtained on a publicly available real
microarray dataset show the enhancement of the bi-clusters performance thanks
to the proposed method.

    

### [[2111.06526] A Time-Series Scale Mixture Model of EEG with a Hidden Markov Structure for Epileptic Seizure Detection](http://arxiv.org/abs/2111.06526)


  In this paper, we propose a time-series stochastic model based on a scale
mixture distribution with Markov transitions to detect epileptic seizures in
electroencephalography (EEG). In the proposed model, an EEG signal at each time
point is assumed to be a random variable following a Gaussian distribution. The
covariance matrix of the Gaussian distribution is weighted with a latent scale
parameter, which is also a random variable, resulting in the stochastic
fluctuations of covariances. By introducing a latent state variable with a
Markov chain in the background of this stochastic relationship, time-series
changes in the distribution of latent scale parameters can be represented
according to the state of epileptic seizures. In an experiment, we evaluated
the performance of the proposed model for seizure detection using EEGs with
multiple frequency bands decomposed from a clinical dataset. The results
demonstrated that the proposed model can detect seizures with high sensitivity
and outperformed several baselines.

    

### [[2111.06530] Distributed Sparse Regression via Penalization](http://arxiv.org/abs/2111.06530)


  We study sparse linear regression over a network of agents, modeled as an
undirected graph (with no centralized node). The estimation problem is
formulated as the minimization of the sum of the local LASSO loss functions
plus a quadratic penalty of the consensus constraint -- the latter being
instrumental to obtain distributed solution methods. While penalty-based
consensus methods have been extensively studied in the optimization literature,
their statistical and computational guarantees in the high dimensional setting
remain unclear. This work provides an answer to this open problem. Our
contribution is two-fold. First, we establish statistical consistency of the
estimator: under a suitable choice of the penalty parameter, the optimal
solution of the penalized problem achieves near optimal minimax rate
$\mathcal{O}(s \log d/N)$ in $\ell_2$-loss, where $s$ is the sparsity value,
$d$ is the ambient dimension, and $N$ is the total sample size in the network
-- this matches centralized sample rates. Second, we show that the
proximal-gradient algorithm applied to the penalized problem, which naturally
leads to distributed implementations, converges linearly up to a tolerance of
the order of the centralized statistical error -- the rate scales as
$\mathcal{O}(d)$, revealing an unavoidable speed-accuracy dilemma.Numerical
results demonstrate the tightness of the derived sample rate and convergence
rate scalings.

    

### [[2111.06531] Domain Generalization on Efficient Acoustic Scene Classification using Residual Normalization](http://arxiv.org/abs/2111.06531)


  It is a practical research topic how to deal with multi-device audio inputs
by a single acoustic scene classification system with efficient design. In this
work, we propose Residual Normalization, a novel feature normalization method
that uses frequency-wise normalization % instance normalization with a shortcut
path to discard unnecessary device-specific information without losing useful
information for classification. Moreover, we introduce an efficient
architecture, BC-ResNet-ASC, a modified version of the baseline architecture
with a limited receptive field. BC-ResNet-ASC outperforms the baseline
architecture even though it contains the small number of parameters. Through
three model compression schemes: pruning, quantization, and knowledge
distillation, we can reduce model complexity further while mitigating the
performance degradation. The proposed system achieves an average test accuracy
of 76.3% in TAU Urban Acoustic Scenes 2020 Mobile, development dataset with
315k parameters, and average test accuracy of 75.3% after compression to 61.0KB
of non-zero parameters. The proposed method won the 1st place in DCASE 2021
challenge, TASK1A.

    

### [[2111.06532] Nonlinear Tensor Ring Network](http://arxiv.org/abs/2111.06532)


  The state-of-the-art deep neural networks (DNNs) have been widely applied for
various real-world applications, and achieved significant performance for
cognitive problems. However, the increment of DNNs' width and depth in
architecture results in a huge amount of parameters to challenge the storage
and memory cost, limiting to the usage of DNNs on resource-constrained
platforms, such as portable devices. By converting redundant models into
compact ones, compression technique appears to be a practical solution to
reducing the storage and memory consumption. In this paper, we develop a
nonlinear tensor ring network (NTRN) in which both fullyconnected and
convolutional layers are compressed via tensor ring decomposition. Furthermore,
to mitigate the accuracy loss caused by compression, a nonlinear activation
function is embedded into the tensor contraction and convolution operations
inside the compressed layer. Experimental results demonstrate the effectiveness
and superiority of the proposed NTRN for image classification using two basic
neural networks, LeNet-5 and VGG-11 on three datasets, viz. MNIST, Fashion
MNIST and Cifar-10.

    

### [[2111.06537] Multi-Step Budgeted Bayesian Optimization with Unknown Evaluation Costs](http://arxiv.org/abs/2111.06537)


  Bayesian optimization (BO) is a sample-efficient approach to optimizing
costly-to-evaluate black-box functions. Most BO methods ignore how evaluation
costs may vary over the optimization domain. However, these costs can be highly
heterogeneous and are often unknown in advance. This occurs in many practical
settings, such as hyperparameter tuning of machine learning algorithms or
physics-based simulation optimization. Moreover, those few existing methods
that acknowledge cost heterogeneity do not naturally accommodate a budget
constraint on the total evaluation cost. This combination of unknown costs and
a budget constraint introduces a new dimension to the exploration-exploitation
trade-off, where learning about the cost incurs the cost itself. Existing
methods do not reason about the various trade-offs of this problem in a
principled way, leading often to poor performance. We formalize this claim by
proving that the expected improvement and the expected improvement per unit of
cost, arguably the two most widely used acquisition functions in practice, can
be arbitrarily inferior with respect to the optimal non-myopic policy. To
overcome the shortcomings of existing approaches, we propose the budgeted
multi-step expected improvement, a non-myopic acquisition function that
generalizes classical expected improvement to the setting of heterogeneous and
unknown evaluation costs. Finally, we show that our acquisition function
outperforms existing methods in a variety of synthetic and real problems.

    

### [[2111.06546] Approximating Optimal Transport via Low-rank and Sparse Factorization](http://arxiv.org/abs/2111.06546)


  Optimal transport (OT) naturally arises in a wide range of machine learning
applications but may often become the computational bottleneck. Recently, one
line of works propose to solve OT approximately by searching the
\emph{transport plan} in a low-rank subspace. However, the optimal transport
plan is often not low-rank, which tends to yield large approximation errors.
For example, when Monge's \emph{transport map} exists, the transport plan is
full rank. This paper concerns the computation of the OT distance with adequate
accuracy and efficiency. A novel approximation for OT is proposed, in which the
transport plan can be decomposed into the sum of a low-rank matrix and a sparse
one. We theoretically analyze the approximation error. An augmented Lagrangian
method is then designed to efficiently calculate the transport plan.

    

### [[2111.06549] Bi-Discriminator Class-Conditional Tabular GAN](http://arxiv.org/abs/2111.06549)


  This paper introduces a bi-discriminator GAN for synthesizing tabular
datasets containing continuous, binary, and discrete columns. Our proposed
approach employs an adapted preprocessing scheme and a novel conditional term
for the generator network to more effectively capture the input sample
distributions. Additionally, we implement straightforward yet effective
architectures for discriminator networks aiming at providing more
discriminative gradient information to the generator. Our experimental results
on four benchmarking public datasets corroborates the superior performance of
our GAN both in terms of likelihood fitness metric and machine learning
efficacy.

    

### [[2111.06555] A Robust Deep Learning-Based Beamforming Design for RIS-assisted Multiuser MISO Communications with Practical Constraints](http://arxiv.org/abs/2111.06555)


  Reconfigurable intelligent surface (RIS) has become a promising technology to
improve wireless communication in recent years. It steers the incident signals
to create a favorable propagation environment by controlling the reconfigurable
passive elements with less hardware cost and lower power consumption. In this
paper, we consider a RIS-aided multiuser multiple-input single-output downlink
communication system. We aim to maximize the weighted sum-rate of all users by
joint optimizing the active beamforming at the access point and the passive
beamforming vector of the RIS elements. Unlike most existing works, we consider
the more practical situation with the discrete phase shifts and imperfect
channel state information (CSI). Specifically, for the situation that the
discrete phase shifts and perfect CSI are considered, we first develop a deep
quantization neural network (DQNN) to simultaneously design the active and
passive beamforming while most reported works design them alternatively. Then,
we propose an improved structure (I-DQNN) based on DQNN to simplify the
parameters decision process when the control bits of each RIS element are
greater than 1 bit. Finally, we extend the two proposed DQNN-based algorithms
to the case that the discrete phase shifts and imperfect CSI are considered
simultaneously. Our simulation results show that the two DQNN-based algorithms
have better performance than traditional algorithms in the perfect CSI case,
and are also more robust in the imperfect CSI case.

    

### [[2111.06578] Differential privacy and robust statistics in high dimensions](http://arxiv.org/abs/2111.06578)


  We introduce a universal framework for characterizing the statistical
efficiency of a statistical estimation problem with differential privacy
guarantees. Our framework, which we call High-dimensional Propose-Test-Release
(HPTR), builds upon three crucial components: the exponential mechanism, robust
statistics, and the Propose-Test-Release mechanism. Gluing all these together
is the concept of resilience, which is central to robust statistical
estimation. Resilience guides the design of the algorithm, the sensitivity
analysis, and the success probability analysis of the test step in
Propose-Test-Release. The key insight is that if we design an exponential
mechanism that accesses the data only via one-dimensional robust statistics,
then the resulting local sensitivity can be dramatically reduced. Using
resilience, we can provide tight local sensitivity bounds. These tight bounds
readily translate into near-optimal utility guarantees in several cases. We
give a general recipe for applying HPTR to a given instance of a statistical
estimation problem and demonstrate it on canonical problems of mean estimation,
linear regression, covariance estimation, and principal component analysis. We
introduce a general utility analysis technique that proves that HPTR nearly
achieves the optimal sample complexity under several scenarios studied in the
literature.

    

### [[2111.06580] On-the-Fly Rectification for Robust Large-Vocabulary Topic Inference](http://arxiv.org/abs/2111.06580)


  Across many data domains, co-occurrence statistics about the joint appearance
of objects are powerfully informative. By transforming unsupervised learning
problems into decompositions of co-occurrence statistics, spectral algorithms
provide transparent and efficient algorithms for posterior inference such as
latent topic analysis and community detection. As object vocabularies grow,
however, it becomes rapidly more expensive to store and run inference
algorithms on co-occurrence statistics. Rectifying co-occurrence, the key
process to uphold model assumptions, becomes increasingly more vital in the
presence of rare terms, but current techniques cannot scale to large
vocabularies. We propose novel methods that simultaneously compress and rectify
co-occurrence statistics, scaling gracefully with the size of vocabulary and
the dimension of latent space. We also present new algorithms learning latent
variables from the compressed statistics, and verify that our methods perform
comparably to previous approaches on both textual and non-textual data.

    

### [[2111.06581] Learning Quantile Functions without Quantile Crossing for Distribution-free Time Series Forecasting](http://arxiv.org/abs/2111.06581)


  Quantile regression is an effective technique to quantify uncertainty, fit
challenging underlying distributions, and often provide full probabilistic
predictions through joint learnings over multiple quantile levels. A common
drawback of these joint quantile regressions, however, is \textit{quantile
crossing}, which violates the desirable monotone property of the conditional
quantile function. In this work, we propose the Incremental (Spline) Quantile
Functions I(S)QF, a flexible and efficient distribution-free quantile
estimation framework that resolves quantile crossing with a simple neural
network layer. Moreover, I(S)QF inter/extrapolate to predict arbitrary quantile
levels that differ from the underlying training ones. Equipped with the
analytical evaluation of the continuous ranked probability score of I(S)QF
representations, we apply our methods to NN-based times series forecasting
cases, where the savings of the expensive re-training costs for non-trained
quantile levels is particularly significant. We also provide a generalization
error analysis of our proposed approaches under the sequence-to-sequence
setting. Lastly, extensive experiments demonstrate the improvement of
consistency and accuracy errors over other baselines.

    

### [[2111.06586] AnchorGAE: General Data Clustering via $O(n)$ Bipartite Graph Convolution](http://arxiv.org/abs/2111.06586)


  Graph-based clustering plays an important role in clustering tasks. As graph
convolution network (GCN), a variant of neural networks on graph-type data, has
achieved impressive performance, it is attractive to find whether GCNs can be
used to augment the graph-based clustering methods on non-graph data, i.e.,
general data. However, given $n$ samples, the graph-based clustering methods
usually need at least $O(n^2)$ time to build graphs and the graph convolution
requires nearly $O(n^2)$ for a dense graph and $O(|\mathcal{E}|)$ for a sparse
one with $|\mathcal{E}|$ edges. In other words, both graph-based clustering and
GCNs suffer from severe inefficiency problems. To tackle this problem and
further employ GCN to promote the capacity of graph-based clustering, we
propose a novel clustering method, AnchorGAE. As the graph structure is not
provided in general clustering scenarios, we first show how to convert a
non-graph dataset into a graph by introducing the generative graph model, which
is used to build GCNs. Anchors are generated from the original data to
construct a bipartite graph such that the computational complexity of graph
convolution is reduced from $O(n^2)$ and $O(|\mathcal{E}|)$ to $O(n)$. The
succeeding steps for clustering can be easily designed as $O(n)$ operations.
Interestingly, the anchors naturally lead to a siamese GCN architecture. The
bipartite graph constructed by anchors is updated dynamically to exploit the
high-level information behind data. Eventually, we theoretically prove that the
simple update will lead to degeneration and a specific strategy is accordingly
designed.

    

### [[2111.06592] Implicit vs Unfolded Graph Neural Networks](http://arxiv.org/abs/2111.06592)


  It has been observed that graph neural networks (GNN) sometimes struggle to
maintain a healthy balance between modeling long-range dependencies across
nodes while avoiding unintended consequences such as oversmoothed node
representations. To address this issue (among other things), two separate
strategies have recently been proposed, namely implicit and unfolded GNNs. The
former treats node representations as the fixed points of a deep equilibrium
model that can efficiently facilitate arbitrary implicit propagation across the
graph with a fixed memory footprint. In contrast, the latter involves treating
graph propagation as the unfolded descent iterations as applied to some
graph-regularized energy function. While motivated differently, in this paper
we carefully elucidate the similarity and differences of these methods,
quantifying explicit situations where the solutions they produced may actually
be equivalent and others where behavior diverges. This includes the analysis of
convergence, representational capacity, and interpretability. We also provide
empirical head-to-head comparisons across a variety of synthetic and public
real-world benchmarks.

    

### [[2111.06593] Using Deep Learning Sequence Models to Identify SARS-CoV-2 Divergence](http://arxiv.org/abs/2111.06593)


  SARS-CoV-2 is an upper respiratory system RNA virus that has caused over 3
million deaths and infecting over 150 million worldwide as of May 2021. With
thousands of strains sequenced to date, SARS-CoV-2 mutations pose significant
challenges to scientists on keeping pace with vaccine development and public
health measures. Therefore, an efficient method of identifying the divergence
of lab samples from patients would greatly aid the documentation of SARS-CoV-2
genomics. In this study, we propose a neural network model that leverages
recurrent and convolutional units to directly take in amino acid sequences of
spike proteins and classify corresponding clades. We also compared our model's
performance with Bidirectional Encoder Representations from Transformers (BERT)
pre-trained on protein database. Our approach has the potential of providing a
more computationally efficient alternative to current homology based
intra-species differentiation.

    

### [[2111.06599] PESTO: Switching Point based Dynamic and Relative Positional Encoding for Code-Mixed Languages](http://arxiv.org/abs/2111.06599)


  NLP applications for code-mixed (CM) or mix-lingual text have gained a
significant momentum recently, the main reason being the prevalence of language
mixing in social media communications in multi-lingual societies like India,
Mexico, Europe, parts of USA etc. Word embeddings are basic build-ing blocks of
any NLP system today, yet, word embedding for CM languages is an unexplored
territory. The major bottleneck for CM word embeddings is switching points,
where the language switches. These locations lack in contextually and
statistical systems fail to model this phenomena due to high variance in the
seen examples. In this paper we present our initial observations on applying
switching point based positional encoding techniques for CM language,
specifically Hinglish (Hindi - English). Results are only marginally better
than SOTA, but it is evident that positional encoding could bean effective way
to train position sensitive language models for CM text.

    

### [[2111.06614] Promoting Resilience in Multi-Agent Reinforcement Learning via Confusion-Based Communication](http://arxiv.org/abs/2111.06614)


  Recent advances in multi-agent reinforcement learning (MARL) provide a
variety of tools that support the ability of agents to adapt to unexpected
changes in their environment, and to operate successfully given their
environment's dynamic nature (which may be intensified by the presence of other
agents). In this work, we highlight the relationship between a group's ability
to collaborate effectively and the group's resilience, which we measure as the
group's ability to adapt to perturbations in the environment. To promote
resilience, we suggest facilitating collaboration via a novel confusion-based
communication protocol according to which agents broadcast observations that
are misaligned with their previous experiences. We allow decisions regarding
the width and frequency of messages to be learned autonomously by agents, which
are incentivized to reduce confusion. We present empirical evaluation of our
approach in a variety of MARL settings.

    

### [[2111.06625] A Convolutional Neural Network Based Approach to Recognize Bangla Spoken Digits from Speech Signal](http://arxiv.org/abs/2111.06625)


  Speech recognition is a technique that converts human speech signals into
text or words or in any form that can be easily understood by computers or
other machines. There have been a few studies on Bangla digit recognition
systems, the majority of which used small datasets with few variations in
genders, ages, dialects, and other variables. Audio recordings of Bangladeshi
people of various genders, ages, and dialects were used to create a large
speech dataset of spoken '0-9' Bangla digits in this study. Here, 400 noisy and
noise-free samples per digit have been recorded for creating the dataset. Mel
Frequency Cepstrum Coefficients (MFCCs) have been utilized for extracting
meaningful features from the raw speech data. Then, to detect Bangla numeral
digits, Convolutional Neural Networks (CNNs) were utilized. The suggested
technique recognizes '0-9' Bangla spoken digits with 97.1% accuracy throughout
the whole dataset. The efficiency of the model was also assessed using 10-fold
crossvalidation, which yielded a 96.7% accuracy.

    

### [[2111.06628] Learning to Break Deep Perceptual Hashing: The Use Case NeuralHash](http://arxiv.org/abs/2111.06628)


  Apple recently revealed its deep perceptual hashing system NeuralHash to
detect child sexual abuse material (CSAM) on user devices before files are
uploaded to its iCloud service. Public criticism quickly arose regarding the
protection of user privacy and the system's reliability. In this paper, we
present the first comprehensive empirical analysis of deep perceptual hashing
based on NeuralHash. Specifically, we show that current deep perceptual hashing
may not be robust. An adversary can manipulate the hash values by applying
slight changes in images, either induced by gradient-based approaches or simply
by performing standard image transformations, forcing or preventing hash
collisions. Such attacks permit malicious actors easily to exploit the
detection system: from hiding abusive material to framing innocent users,
everything is possible. Moreover, using the hash values, inferences can still
be made about the data stored on user devices. In our view, based on our
results, deep perceptual hashing in its current form is generally not ready for
robust client-side scanning and should not be used from a privacy perspective.

    

### [[2111.06643] Fully Automatic Page Turning on Real Scores](http://arxiv.org/abs/2111.06643)


  We present a prototype of an automatic page turning system that works
directly on real scores, i.e., sheet images, without any symbolic
representation. Our system is based on a multi-modal neural network
architecture that observes a complete sheet image page as input, listens to an
incoming musical performance, and predicts the corresponding position in the
image. Using the position estimation of our system, we use a simple heuristic
to trigger a page turning event once a certain location within the sheet image
is reached. As a proof of concept we further combine our system with an actual
machine that will physically turn the page on command.

    

### [[2111.06661] Detecting Quality Problems in Data Models by Clustering Heterogeneous Data Values](http://arxiv.org/abs/2111.06661)


  Data is of high quality if it is fit for its intended use. The quality of
data is influenced by the underlying data model and its quality. One major
quality problem is the heterogeneity of data as quality aspects such as
understandability and interoperability are impaired. This heterogeneity may be
caused by quality problems in the data model. Data heterogeneity can occur in
particular when the information given is not structured enough and just
captured in data values, often due to missing or non-suitable structure in the
underlying data model. We propose a bottom-up approach to detecting quality
problems in data models that manifest in heterogeneous data values. It supports
an explorative analysis of the existing data and can be configured by domain
experts according to their domain knowledge. All values of a selected data
field are clustered by syntactic similarity. Thereby an overview of the data
values' diversity in syntax is provided. It shall help domain experts to
understand how the data model is used in practice and to derive potential
quality problems of the data model. We outline a proof-of-concept
implementation and evaluate our approach using cultural heritage data.

    

### [[2111.06664] Extraction of Medication Names from Twitter Using Augmentation and an Ensemble of Language Models](http://arxiv.org/abs/2111.06664)


  The BioCreative VII Track 3 challenge focused on the identification of
medication names in Twitter user timelines. For our submission to this
challenge, we expanded the available training data by using several data
augmentation techniques. The augmented data was then used to fine-tune an
ensemble of language models that had been pre-trained on general-domain Twitter
content. The proposed approach outperformed the prior state-of-the-art
algorithm Kusuri and ranked high in the competition for our selected objective
function, overlapping F1 score.

    

### [[2111.06667] Understanding the Information Needs and Practices of Human Supporters of an Online Mental Health Intervention to Inform Machine Learning Applications](http://arxiv.org/abs/2111.06667)


  In the context of digital therapy interventions, such as internet-delivered
Cognitive Behavioral Therapy (iCBT) for the treatment of depression and
anxiety, extensive research has shown how the involvement of a human supporter
or coach, who assists the person undergoing treatment, improves user engagement
in therapy and leads to more effective health outcomes than unsupported
interventions. Seeking to maximize the effects and outcomes of this human
support, the research investigates how new opportunities provided through
recent advances in the field of AI and machine learning (ML) can contribute
useful data insights to effectively support the work practices of iCBT
supporters. This paper reports detailed findings of an interview study with 15
iCBT supporters that deepens understanding of their existing work practices and
information needs with the aim to meaningfully inform the development of
useful, implementable ML applications particularly in the context of iCBT
treatment for depression and anxiety. The analysis contributes (1) a set of six
themes that summarize the strategies and challenges that iCBT supporters
encounter in providing effective, personalized feedback to their mental health
clients; and in response to these learnings, (2) presents for each theme
concrete opportunities for how methods of ML could help support and address
identified challenges and information needs. It closes with reflections on
potential social, emotional and pragmatic implications of introducing new
machine-generated data insights within supporter-led client review practices.

    

### [[2111.06676] A Reverse Jensen Inequality Result with Application to Mutual Information Estimation](http://arxiv.org/abs/2111.06676)


  The Jensen inequality is a widely used tool in a multitude of fields, such as
for example information theory and machine learning. It can be also used to
derive other standard inequalities such as the inequality of arithmetic and
geometric means or the Hölder inequality. In a probabilistic setting, the
Jensen inequality describes the relationship between a convex function and the
expected value. In this work, we want to look at the probabilistic setting from
the reverse direction of the inequality. We show that under minimal constraints
and with a proper scaling, the Jensen inequality can be reversed. We believe
that the resulting tool can be helpful for many applications and provide a
variational estimation of mutual information, where the reverse inequality
leads to a new estimator with superior training behavior compared to current
estimators.

    

### [[2111.06679] deepstruct -- linking deep learning and graph theory](http://arxiv.org/abs/2111.06679)


  deepstruct connects deep learning models and graph theory such that different
graph structures can be imposed on neural networks or graph structures can be
extracted from trained neural network models. For this, deepstruct provides
deep neural network models with different restrictions which can be created
based on an initial graph. Further, tools to extract graph structures from
trained models are available. This step of extracting graphs can be
computationally expensive even for models of just a few dozen thousand
parameters and poses a challenging problem.
deepstruct supports research in pruning, neural architecture search,
automated network design and structure analysis of neural networks.

    

### [[2111.06685] DeepXML: A Deep Extreme Multi-Label Learning Framework Applied to Short Text Documents](http://arxiv.org/abs/2111.06685)


  Scalability and accuracy are well recognized challenges in deep extreme
multi-label learning where the objective is to train architectures for
automatically annotating a data point with the most relevant subset of labels
from an extremely large label set. This paper develops the DeepXML framework
that addresses these challenges by decomposing the deep extreme multi-label
task into four simpler sub-tasks each of which can be trained accurately and
efficiently. Choosing different components for the four sub-tasks allows
DeepXML to generate a family of algorithms with varying trade-offs between
accuracy and scalability. In particular, DeepXML yields the Astec algorithm
that could be 2-12% more accurate and 5-30x faster to train than leading deep
extreme classifiers on publically available short text datasets. Astec could
also efficiently train on Bing short text datasets containing up to 62 million
labels while making predictions for billions of users and data points per day
on commodity hardware. This allowed Astec to be deployed on the Bing search
engine for a number of short text applications ranging from matching user
queries to advertiser bid phrases to showing personalized ads where it yielded
significant gains in click-through-rates, coverage, revenue and other online
metrics over state-of-the-art techniques currently in production. DeepXML's
code is available at this https URL


### [[2111.06686] BSC: Block-based Stochastic Computing to Enable Accurate and Efficient TinyML](http://arxiv.org/abs/2111.06686)


  Along with the progress of AI democratization, machine learning (ML) has been
successfully applied to edge applications, such as smart phones and automated
driving. Nowadays, more applications require ML on tiny devices with extremely
limited resources, like implantable cardioverter defibrillator (ICD), which is
known as TinyML. Unlike ML on the edge, TinyML with a limited energy supply has
higher demands on low-power execution. Stochastic computing (SC) using
bitstreams for data representation is promising for TinyML since it can perform
the fundamental ML operations using simple logical gates, instead of the
complicated binary adder and multiplier. However, SC commonly suffers from low
accuracy for ML tasks due to low data precision and inaccuracy of arithmetic
units. Increasing the length of the bitstream in the existing works can
mitigate the precision issue but incur higher latency. In this work, we propose
a novel SC architecture, namely Block-based Stochastic Computing (BSC). BSC
divides inputs into blocks, such that the latency can be reduced by exploiting
high data parallelism. Moreover, optimized arithmetic units and output revision
(OUR) scheme are proposed to improve accuracy. On top of it, a global
optimization approach is devised to determine the number of blocks, which can
make a better latency-power trade-off. Experimental results show that BSC can
outperform the existing designs in achieving over 10% higher accuracy on ML
tasks and over 6 times power reduction.

    

### [[2111.06705] Silicon photonic subspace neural chip for hardware-efficient deep learning](http://arxiv.org/abs/2111.06705)


  As deep learning has shown revolutionary performance in many artificial
intelligence applications, its escalating computation demand requires hardware
accelerators for massive parallelism and improved throughput. The optical
neural network (ONN) is a promising candidate for next-generation
neurocomputing due to its high parallelism, low latency, and low energy
consumption. Here, we devise a hardware-efficient photonic subspace neural
network (PSNN) architecture, which targets lower optical component usage, area
cost, and energy consumption than previous ONN architectures with comparable
task performance. Additionally, a hardware-aware training framework is provided
to minimize the required device programming precision, lessen the chip area,
and boost the noise robustness. We experimentally demonstrate our PSNN on a
butterfly-style programmable silicon photonic integrated circuit and show its
utility in practical image recognition tasks.

    

### [[2111.06721] Causal Multi-Agent Reinforcement Learning: Review and Open Problems](http://arxiv.org/abs/2111.06721)


  This paper serves to introduce the reader to the field of multi-agent
reinforcement learning (MARL) and its intersection with methods from the study
of causality. We highlight key challenges in MARL and discuss these in the
context of how causal methods may assist in tackling them. We promote moving
toward a 'causality first' perspective on MARL. Specifically, we argue that
causality can offer improved safety, interpretability, and robustness, while
also providing strong theoretical guarantees for emergent behaviour. We discuss
potential solutions for common challenges, and use this context to motivate
future research directions.

    

### [[2111.06726] One model Packs Thousands of Items with Recurrent Conditional Query Learning](http://arxiv.org/abs/2111.06726)


  Recent studies have revealed that neural combinatorial optimization (NCO) has
advantages over conventional algorithms in many combinatorial optimization
problems such as routing, but it is less efficient for more complicated
optimization tasks such as packing which involves mutually conditioned action
spaces. In this paper, we propose a Recurrent Conditional Query Learning (RCQL)
method to solve both 2D and 3D packing problems. We first embed states by a
recurrent encoder, and then adopt attention with conditional queries from
previous actions. The conditional query mechanism fills the information gap
between learning steps, which shapes the problem as a Markov decision process.
Benefiting from the recurrence, a single RCQL model is capable of handling
different sizes of packing problems. Experiment results show that RCQL can
effectively learn strong heuristics for offline and online strip packing
problems (SPPs), outperforming a wide range of baselines in space utilization
ratio. RCQL reduces the average bin gap ratio by 1.83% in offline 2D 40-box
cases and 7.84% in 3D cases compared with state-of-the-art methods. Meanwhile,
our method also achieves 5.64% higher space utilization ratio for SPPs with
1000 items than the state of the art.

    

### [[2111.06736] The Science of Rejection: A Research Area for Human Computation](http://arxiv.org/abs/2111.06736)


  We motivate why the science of learning to reject model predictions is
central to ML, and why human computation has a lead role in this effort.

    

### [[2111.06739] Neural Motion Planning for Autonomous Parking](http://arxiv.org/abs/2111.06739)


  This paper presents a hybrid motion planning strategy that combines a deep
generative network with a conventional motion planning method. Existing
planning methods such as A* and Hybrid A* are widely used in path planning
tasks because of their ability to determine feasible paths even in complex
environments; however, they have limitations in terms of efficiency. To
overcome these limitations, a path planning algorithm based on a neural
network, namely the neural Hybrid A*, is introduced. This paper proposes using
a conditional variational autoencoder (CVAE) to guide the search algorithm by
exploiting the ability of CVAE to learn information about the planning space
given the information of the parking environment. A non-uniform expansion
strategy is utilized based on a distribution of feasible trajectories learned
in the demonstrations. The proposed method effectively learns the
representations of a given state, and shows improvement in terms of algorithm
performance.

    

### [[2111.06740] Review of Pedestrian Trajectory Prediction Methods: Comparing Deep Learning and Knowledge-based Approaches](http://arxiv.org/abs/2111.06740)


  In crowd scenarios, predicting trajectories of pedestrians is a complex and
challenging task depending on many external factors. The topology of the scene
and the interactions between the pedestrians are just some of them. Due to
advancements in data-science and data collection technologies deep learning
methods have recently become a research hotspot in numerous domains. Therefore,
it is not surprising that more and more researchers apply these methods to
predict trajectories of pedestrians. This paper compares these relatively new
deep learning algorithms with classical knowledge-based models that are widely
used to simulate pedestrian dynamics. It provides a comprehensive literature
review of both approaches, explores technical and application oriented
differences, and addresses open questions as well as future development
directions. Our investigations point out that the pertinence of knowledge-based
models to predict local trajectories is nowadays questionable because of the
high accuracy of the deep learning algorithms. Nevertheless, the ability of
deep-learning algorithms for large-scale simulation and the description of
collective dynamics remains to be demonstrated. Furthermore, the comparison
shows that the combination of both approaches (the hybrid approach) seems to be
promising to overcome disadvantages like the missing explainability of the deep
learning approach.

    

### [[2111.06742] Self-Reflective Terrain-Aware Robot Adaptation for Consistent Off-Road Ground Navigation](http://arxiv.org/abs/2111.06742)


  Ground robots require the crucial capability of traversing unstructured and
unprepared terrains and avoiding obstacles to complete tasks in real-world
robotics applications such as disaster response. When a robot operates in
off-road field environments such as forests, the robot's actual behaviors often
do not match its expected or planned behaviors, due to changes in the
characteristics of terrains and the robot itself. Therefore, the capability of
robot adaptation for consistent behavior generation is essential for
maneuverability on unstructured off-road terrains. In order to address the
challenge, we propose a novel method of self-reflective terrain-aware
adaptation for ground robots to generate consistent controls to navigate over
unstructured off-road terrains, which enables robots to more accurately execute
the expected behaviors through robot self-reflection while adapting to varying
unstructured terrains. To evaluate our method's performance, we conduct
extensive experiments using real ground robots with various functionality
changes over diverse unstructured off-road terrains. The comprehensive
experimental results have shown that our self-reflective terrain-aware
adaptation method enables ground robots to generate consistent navigational
behaviors and outperforms the compared previous and baseline techniques.

    

### [[2111.06748] Simplifying approach to Node Classification in Graph Neural Networks](http://arxiv.org/abs/2111.06748)


  Graph Neural Networks have become one of the indispensable tools to learn
from graph-structured data, and their usefulness has been shown in wide variety
of tasks. In recent years, there have been tremendous improvements in
architecture design, resulting in better performance on various prediction
tasks. In general, these neural architectures combine node feature aggregation
and feature transformation using learnable weight matrix in the same layer.
This makes it challenging to analyze the importance of node features aggregated
from various hops and the expressiveness of the neural network layers. As
different graph datasets show varying levels of homophily and heterophily in
features and class label distribution, it becomes essential to understand which
features are important for the prediction tasks without any prior information.
In this work, we decouple the node feature aggregation step and depth of graph
neural network, and empirically analyze how different aggregated features play
a role in prediction performance. We show that not all features generated via
aggregation steps are useful, and often using these less informative features
can be detrimental to the performance of the GNN model. Through our
experiments, we show that learning certain subsets of these features can lead
to better performance on wide variety of datasets. We propose to use softmax as
a regularizer and "soft-selector" of features aggregated from neighbors at
different hop distances; and L2-Normalization over GNN layers. Combining these
techniques, we present a simple and shallow model, Feature Selection Graph
Neural Network (FSGNN), and show empirically that the proposed model achieves
comparable or even higher accuracy than state-of-the-art GNN models in nine
benchmark datasets for the node classification task, with remarkable
improvements up to 51.1%.

    

### [[2111.06750] STFL: A Temporal-Spatial Federated Learning Framework for Graph Neural Networks](http://arxiv.org/abs/2111.06750)


  We present a spatial-temporal federated learning framework for graph neural
networks, namely STFL. The framework explores the underlying correlation of the
input spatial-temporal data and transform it to both node features and
adjacency matrix. The federated learning setting in the framework ensures data
privacy while achieving a good model generalization. Experiments results on the
sleep stage dataset, ISRUC_S3, illustrate the effectiveness of STFL on graph
prediction tasks.

    

### [[2111.06754] Monte Carlo dropout increases model repeatability](http://arxiv.org/abs/2111.06754)


  The integration of artificial intelligence into clinical workflows requires
reliable and robust models. Among the main features of robustness is
repeatability. Much attention is given to classification performance without
assessing the model repeatability, leading to the development of models that
turn out to be unusable in practice. In this work, we evaluate the
repeatability of four model types on images from the same patient that were
acquired during the same visit. We study the performance of binary,
multi-class, ordinal, and regression models on three medical image analysis
tasks: cervical cancer screening, breast density estimation, and retinopathy of
prematurity classification. Moreover, we assess the impact of sampling Monte
Carlo dropout predictions at test time on classification performance and
repeatability. Leveraging Monte Carlo predictions significantly increased
repeatability for all tasks on the binary, multi-class, and ordinal models
leading to an average reduction of the 95% limits of agreement by 17% points.

    

### [[2111.06773] Explainability and the Fourth AI Revolution](http://arxiv.org/abs/2111.06773)


  This chapter discusses AI from the prism of an automated process for the
organization of data, and exemplifies the role that explainability has to play
in moving from the current generation of AI systems to the next one, where the
role of humans is lifted from that of data annotators working for the AI
systems to that of collaborators working with the AI systems.

    

### [[2111.06774] Identifying On-road Scenarios Predictive of ADHD usingDriving Simulator Time Series Data](http://arxiv.org/abs/2111.06774)


  In this paper we introduce a novel algorithm called Iterative Section
Reduction (ISR) to automatically identify sub-intervals of spatiotemporal time
series that are predictive of a target classification task. Specifically, using
data collected from a driving simulator study, we identify which spatial
regions (dubbed "sections") along the simulated routes tend to manifest driving
behaviors that are predictive of the presence of Attention Deficit
Hyperactivity Disorder (ADHD). Identifying these sections is important for two
main reasons: (1) to improve predictive accuracy of the trained models by
filtering out non-predictive time series sub-intervals, and (2) to gain
insights into which on-road scenarios (dubbed events) elicit distinctly
different driving behaviors from patients undergoing treatment for ADHD versus
those that are not. Our experimental results show both improved performance
over prior efforts (+10% accuracy) and good alignment between the predictive
sections identified and scripted on-road events in the simulator (negotiating
turns and curves).

    

### [[2111.06776] Resilient Consensus-based Multi-agent Reinforcement Learning](http://arxiv.org/abs/2111.06776)


  Adversarial attacks during training can strongly influence the performance of
multi-agent reinforcement learning algorithms. It is, thus, highly desirable to
augment existing algorithms such that the impact of adversarial attacks on
cooperative networks is eliminated, or at least bounded. In this work, we
consider a fully decentralized network, where each agent receives a local
reward and observes the global state and action. We propose a resilient
consensus-based actor-critic algorithm, whereby each agent estimates the
team-average reward and value function, and communicates the associated
parameter vectors to its immediate neighbors. We show that in the presence of
Byzantine agents, whose estimation and communication strategies are completely
arbitrary, the estimates of the cooperative agents converge to a bounded
consensus value with probability one, provided that there are at most $H$
Byzantine agents in the neighborhood of each cooperative agent and the network
is $(2H+1)$-robust. Furthermore, we prove that the policy of the cooperative
agents converges with probability one to a bounded neighborhood around a local
maximizer of their team-average objective function under the assumption that
the policies of the adversarial agents asymptotically become stationary.

    

### [[2111.06780] AWD3: Dynamic Reduction of the Estimation Bias](http://arxiv.org/abs/2111.06780)


  Value-based deep Reinforcement Learning (RL) algorithms suffer from the
estimation bias primarily caused by function approximation and temporal
difference (TD) learning. This problem induces faulty state-action value
estimates and therefore harms the performance and robustness of the learning
algorithms. Although several techniques were proposed to tackle, learning
algorithms still suffer from this bias. Here, we introduce a technique that
eliminates the estimation bias in off-policy continuous control algorithms
using the experience replay mechanism. We adaptively learn the weighting
hyper-parameter beta in the Weighted Twin Delayed Deep Deterministic Policy
Gradient algorithm. Our method is named Adaptive-WD3 (AWD3). We show through
continuous control environments of OpenAI gym that our algorithm matches or
outperforms the state-of-the-art off-policy policy gradient learning
algorithms.

    

### [[2111.06781] Q-Learning for MDPs with General Spaces: Convergence and Near Optimality via Quantization under Weak Continuity](http://arxiv.org/abs/2111.06781)


  Reinforcement learning algorithms often require finiteness of state and
action spaces in Markov decision processes (MDPs) and various efforts have been
made in the literature towards the applicability of such algorithms for
continuous state and action spaces. In this paper, we show that under very mild
regularity conditions (in particular, involving only weak continuity of the
transition kernel of an MDP), Q-learning for standard Borel MDPs via
quantization of states and actions converge to a limit, and furthermore this
limit satisfies an optimality equation which leads to near optimality with
either explicit performance bounds or which are guaranteed to be asymptotically
optimal. Our approach builds on (i) viewing quantization as a measurement
kernel and thus a quantized MDP as a POMDP, (ii) utilizing near optimality and
convergence results of Q-learning for POMDPs, and (iii) finally,
near-optimality of finite state model approximations for MDPs with weakly
continuous kernels which we show to correspond to the fixed point of the
constructed POMDP. Thus, our paper presents a very general convergence and
approximation result for the applicability of Q-learning for continuous MDPs.

    

### [[2111.06783] Can neural networks predict dynamics they have never seen?](http://arxiv.org/abs/2111.06783)


  Neural networks have proven to be remarkably successful for a wide range of
complicated tasks, from image recognition and object detection to speech
recognition and machine translation. One of their successes is the skill in
prediction of future dynamics given a suitable training set of data. Previous
studies have shown how Echo State Networks (ESNs), a subset of Recurrent Neural
Networks, can successfully predict even chaotic systems for times longer than
the Lyapunov time. This study shows that, remarkably, ESNs can successfully
predict dynamical behavior that is qualitatively different from any behavior
contained in the training set. Evidence is provided for a fluid dynamics
problem where the flow can transition between laminar (ordered) and turbulent
(disordered) regimes. Despite being trained on the turbulent regime only, ESNs
are found to predict laminar behavior. Moreover, the statistics of
turbulent-to-laminar and laminar-to-turbulent transitions are also predicted
successfully, and the utility of ESNs in acting as an early-warning system for
transition is discussed. These results are expected to be widely applicable to
data-driven modelling of temporal behaviour in a range of physical, climate,
biological, ecological and finance models characterized by the presence of
tipping points and sudden transitions between several competing states.

    

### [[2111.06784] A Minimax Learning Approach to Off-Policy Evaluation in Partially Observable Markov Decision Processes](http://arxiv.org/abs/2111.06784)


  We consider off-policy evaluation (OPE) in Partially Observable Markov
Decision Processes (POMDPs), where the evaluation policy depends only on
observable variables and the behavior policy depends on unobservable latent
variables. Existing works either assume no unmeasured confounders, or focus on
settings where both the observation and the state spaces are tabular. As such,
these methods suffer from either a large bias in the presence of unmeasured
confounders, or a large variance in settings with continuous or large
observation/state spaces. In this work, we first propose novel identification
methods for OPE in POMDPs with latent confounders, by introducing bridge
functions that link the target policy's value and the observed data
distribution. In fully-observable MDPs, these bridge functions reduce to the
familiar value functions and marginal density ratios between the evaluation and
the behavior policies. We next propose minimax estimation methods for learning
these bridge functions. Our proposal permits general function approximation and
is thus applicable to settings with continuous or large observation/state
spaces. Finally, we construct three estimators based on these estimated bridge
functions, corresponding to a value function-based estimator, a marginalized
importance sampling estimator, and a doubly-robust estimator. Their
nonasymptotic and asymptotic properties are investigated in detail.

    

### [[2111.06811] ADCB: An Alzheimer's disease benchmark for evaluating observational estimators of causal effects](http://arxiv.org/abs/2111.06811)


  Simulators make unique benchmarks for causal effect estimation since they do
not rely on unverifiable assumptions or the ability to intervene on real-world
systems, but are often too simple to capture important aspects of real
applications. We propose a simulator of Alzheimer's disease aimed at modeling
intricacies of healthcare data while enabling benchmarking of causal effect and
policy estimators. We fit the system to the Alzheimer's Disease Neuroimaging
Initiative (ADNI) dataset and ground hand-crafted components in results from
comparative treatment trials and observational treatment patterns. The
simulator includes parameters which alter the nature and difficulty of the
causal inference tasks, such as latent variables, effect heterogeneity, length
of observed history, behavior policy and sample size. We use the simulator to
compare estimators of average and conditional treatment effects.

    

### [[2111.06825] Alleviating the transit timing variation bias in transit surveys. I. RIVERS: Method and detection of a pair of resonant super-Earths around Kepler-1705](http://arxiv.org/abs/2111.06825)


  Transit timing variations (TTVs) can provide useful information for systems
observed by transit, as they allow us to put constraints on the masses and
eccentricities of the observed planets, or even to constrain the existence of
non-transiting companions. However, TTVs can also act as a detection bias that
can prevent the detection of small planets in transit surveys that would
otherwise be detected by standard algorithms such as the Boxed Least Square
algorithm (BLS) if their orbit was not perturbed. This bias is especially
present for surveys with a long baseline, such as Kepler, some of the TESS
sectors, and the upcoming PLATO mission. Here we introduce a detection method
that is robust to large TTVs, and illustrate its use by recovering and
confirming a pair of resonant super-Earths with ten-hour TTVs around
Kepler-1705. The method is based on a neural network trained to recover the
tracks of low-signal-to-noise-ratio(S/N) perturbed planets in river diagrams.
We recover the transit parameters of these candidates by fitting the light
curve. The individual transit S/N of Kepler-1705b and c are about three times
lower than all the previously known planets with TTVs of 3 hours or more,
pushing the boundaries in the recovery of these small, dynamically active
planets. Recovering this type of object is essential for obtaining a complete
picture of the observed planetary systems, and solving for a bias not often
taken into account in statistical studies of exoplanet populations. In
addition, TTVs are a means of obtaining mass estimates which can be essential
for studying the internal structure of planets discovered by transit surveys.
Finally, we show that due to the strong orbital perturbations, it is possible
that the spin of the outer resonant planet of Kepler-1705 is trapped in a sub-
or super-synchronous spin-orbit resonance.

    

### [[2111.06826] Convergence Rates for the MAP of an Exponential Family and Stochastic Mirror Descent -- an Open Problem](http://arxiv.org/abs/2111.06826)


  We consider the problem of upper bounding the expected log-likelihood
sub-optimality of the maximum likelihood estimate (MLE), or a conjugate maximum
a posteriori (MAP) for an exponential family, in a non-asymptotic way.
Surprisingly, we found no general solution to this problem in the literature.
In particular, current theories do not hold for a Gaussian or in the
interesting few samples regime. After exhibiting various facets of the problem,
we show we can interpret the MAP as running stochastic mirror descent (SMD) on
the log-likelihood. However, modern convergence results do not apply for
standard examples of the exponential family, highlighting holes in the
convergence literature. We believe solving this very fundamental problem may
bring progress to both the statistics and optimization communities.

    

### [[2111.06827] NRC-GAMMA: Introducing a Novel Large Gas Meter Image Dataset](http://arxiv.org/abs/2111.06827)


  Automatic meter reading technology is not yet widespread. Gas, electricity,
or water accumulation meters reading is mostly done manually on-site either by
an operator or by the homeowner. In some countries, the operator takes a
picture as reading proof to confirm the reading by checking offline with
another operator and/or using it as evidence in case of conflicts or
complaints. The whole process is time-consuming, expensive, and prone to
errors. Automation can optimize and facilitate such labor-intensive and human
error-prone processes. With the recent advances in the fields of artificial
intelligence and computer vision, automatic meter reading systems are becoming
more viable than ever. Motivated by the recent advances in the field of
artificial intelligence and inspired by open-source open-access initiatives in
the research community, we introduce a novel large benchmark dataset of
real-life gas meter images, named the NRC-GAMMA dataset. The data were
collected from an Itron 400A diaphragm gas meter on January 20, 2020, between
00:05 am and 11:59 pm. We employed a systematic approach to label the images,
validate the labellings, and assure the quality of the annotations. The dataset
contains 28,883 images of the entire gas meter along with 57,766 cropped images
of the left and the right dial displays. We hope the NRC-GAMMA dataset helps
the research community to design and implement accurate, innovative,
intelligent, and reproducible automatic gas meter reading solutions.

    

### [[2111.06832] Speeding Up Entmax](http://arxiv.org/abs/2111.06832)


  Softmax is the de facto standard in modern neural networks for language
processing when it comes to normalizing logits. However, by producing a dense
probability distribution each token in the vocabulary has a nonzero chance of
being selected at each generation step, leading to a variety of reported
problems in text generation. $\alpha$-entmax of arXiv:1905.05702 solves this
problem, but is considerably slower than softmax.
In this paper, we propose an alternative to $\alpha$-entmax, which keeps its
virtuous characteristics, but is as fast as optimized softmax and achieves on
par or better performance in machine translation task.

    

### [[2111.06841] A posteriori learning of quasi-geostrophic turbulence parametrization: an experiment on integration steps](http://arxiv.org/abs/2111.06841)


  Modeling the subgrid-scale dynamics of reduced models is a long standing open
problem that finds application in ocean, atmosphere and climate predictions
where direct numerical simulation (DNS) is impossible. While neural networks
(NNs) have already been applied to a range of three-dimensional problems with
success, the backward energy transfer of two-dimensional flows still remains a
stability issue for trained models. We show that learning a model jointly with
the dynamical solver and a meaningful $\textit{a posteriori}$-based loss
function lead to stable and realistic simulations when applied to
quasi-geostrophic turbulence.

    

### [[2111.06849] Deceive D: Adaptive Pseudo Augmentation for GAN Training with Limited Data](http://arxiv.org/abs/2111.06849)


  Generative adversarial networks (GANs) typically require ample data for
training in order to synthesize high-fidelity images. Recent studies have shown
that training GANs with limited data remains formidable due to discriminator
overfitting, the underlying cause that impedes the generator's convergence.
This paper introduces a novel strategy called Adaptive Pseudo Augmentation
(APA) to encourage healthy competition between the generator and the
discriminator. As an alternative method to existing approaches that rely on
standard data augmentations or model regularization, APA alleviates overfitting
by employing the generator itself to augment the real data distribution with
generated images, which deceives the discriminator adaptively. Extensive
experiments demonstrate the effectiveness of APA in improving synthesis quality
in the low-data regime. We provide a theoretical analysis to examine the
convergence and rationality of our new training strategy. APA is simple and
effective. It can be added seamlessly to powerful contemporary GANs, such as
StyleGAN2, with negligible computational cost.

    

### [[2111.06862] Monolithic Silicon Photonic Architecture for Training Deep Neural Networks with Direct Feedback Alignment](http://arxiv.org/abs/2111.06862)


  The field of artificial intelligence (AI) has witnessed tremendous growth in
recent years, however some of the most pressing challenges for the continued
development of AI systems are the fundamental bandwidth, energy efficiency, and
speed limitations faced by electronic computer architectures. There has been
growing interest in using photonic processors for performing neural network
inference operations, however these networks are currently trained using
standard digital electronics. Here, we propose on-chip training of neural
networks enabled by a CMOS-compatible silicon photonic architecture to harness
the potential for massively parallel, efficient, and fast data operations. Our
scheme employs the direct feedback alignment training algorithm, which trains
neural networks using error feedback rather than error backpropagation, and can
operate at speeds of trillions of multiply-accumulate (MAC) operations per
second while consuming less than one picojoule per MAC operation. The photonic
architecture exploits parallelized matrix-vector multiplications using arrays
of microring resonators for processing multi-channel analog signals along
single waveguide buses to calculate the gradient vector of each neural network
layer in situ, which is the most computationally expensive operation performed
during the backward pass. We also experimentally demonstrate training a deep
neural network with the MNIST dataset using on-chip MAC operation results. Our
novel approach for efficient, ultra-fast neural network training showcases
photonics as a promising platform for executing AI applications.

    

### [[2111.06863] Hierarchical Clustering: New Bounds and Objective](http://arxiv.org/abs/2111.06863)


  Hierarchical Clustering has been studied and used extensively as a method for
analysis of data. More recently, Dasgupta [2016] defined a precise objective
function. Given a set of $n$ data points with a weight function $w_{i,j}$ for
each two items $i$ and $j$ denoting their similarity/dis-similarity, the goal
is to build a recursive (tree like) partitioning of the data points (items)
into successively smaller clusters. He defined a cost function for a tree $T$
to be $Cost(T) = \sum_{i,j \in [n]} \big(w_{i,j} \times |T_{i,j}| \big)$ where
$T_{i,j}$ is the subtree rooted at the least common ancestor of $i$ and $j$ and
presented the first approximation algorithm for such clustering. Then Moseley
and Wang [2017] considered the dual of Dasgupta's objective function for
similarity-based weights and showed that both random partitioning and average
linkage have approximation ratio $1/3$ which has been improved in a series of
works to $0.585$ [Alon et al. 2020]. Later Cohen-Addad et al. [2019] considered
the same objective function as Dasgupta's but for dissimilarity-based metrics,
called $Rev(T)$. It is shown that both random partitioning and average linkage
have ratio $2/3$ which has been only slightly improved to $0.667078$ [Charikar
et al. SODA2020]. Our first main result is to consider $Rev(T)$ and present a
more delicate algorithm and careful analysis that achieves approximation
$0.71604$. We also introduce a new objective function for dissimilarity-based
clustering. For any tree $T$, let $H_{i,j}$ be the number of $i$ and $j$'s
common ancestors. Intuitively, items that are similar are expected to remain
within the same cluster as deep as possible. So, for dissimilarity-based
metrics, we suggest the cost of each tree $T$, which we want to minimize, to be
$Cost_H(T) = \sum_{i,j \in [n]} \big(w_{i,j} \times H_{i,j} \big)$. We present
a $1.3977$-approximation for this objective.

    

### [[2111.06881] Multimodal Virtual Point 3D Detection](http://arxiv.org/abs/2111.06881)


  Lidar-based sensing drives current autonomous vehicles. Despite rapid
progress, current Lidar sensors still lag two decades behind traditional color
cameras in terms of resolution and cost. For autonomous driving, this means
that large objects close to the sensors are easily visible, but far-away or
small objects comprise only one measurement or two. This is an issue,
especially when these objects turn out to be driving hazards. On the other
hand, these same objects are clearly visible in onboard RGB sensors. In this
work, we present an approach to seamlessly fuse RGB sensors into Lidar-based 3D
recognition. Our approach takes a set of 2D detections to generate dense 3D
virtual points to augment an otherwise sparse 3D point cloud. These virtual
points naturally integrate into any standard Lidar-based 3D detectors along
with regular Lidar measurements. The resulting multi-modal detector is simple
and effective. Experimental results on the large-scale nuScenes dataset show
that our framework improves a strong CenterPoint baseline by a significant 6.6
mAP, and outperforms competing fusion approaches. Code and more visualizations
are available at this https URL


### [[1811.09003] On a Sparse Shortcut Topology of Artificial Neural Networks](http://arxiv.org/abs/1811.09003)


  In established network architectures, shortcut connections are often used to
take the outputs of earlier layers as additional inputs to later layers.
Despite the extraordinary effectiveness of shortcuts, there remain open
questions on the mechanism and characteristics. For example, why are shortcuts
powerful? Why do shortcuts generalize well? In this paper, we investigate the
expressivity and generalizability of a novel sparse shortcut topology. First,
we demonstrate that this topology can empower a one-neuron-wide deep network to
approximate any univariate continuous function. Then, we present a novel
width-bounded universal approximator in contrast to depth-bounded universal
approximators and extend the approximation result to a family of equally
competent networks. Furthermore, with generalization bound theory, we show that
the proposed shortcut topology enjoys excellent generalizability. Finally, we
corroborate our theoretical analyses by comparing the proposed topology with
popular architectures, including ResNet and DenseNet, on well-known benchmarks
and perform a saliency map analysis to interpret the proposed topology. Our
work helps enhance the understanding of the role of shortcuts and suggests
further opportunities to innovate neural architectures.

    

### [[1908.05783] Tackling Algorithmic Bias in Neural-Network Classifiers using Wasserstein-2 Regularization](http://arxiv.org/abs/1908.05783)


  The increasingly common use of neural network classifiers in industrial and
social applications of image analysis has allowed impressive progress these
last years. Such methods are however sensitive to algorithmic bias, i.e. to an
under- or an over-representation of positive predictions or to higher
prediction errors in specific subgroups of images. We then introduce in this
paper a new method to temper the algorithmic bias in Neural-Network based
classifiers. Our method is Neural-Network architecture agnostic and scales well
to massive training sets of images. It indeed only overloads the loss function
with a Wasserstein-2 based regularization term for which we back-propagate the
impact of specific output predictions using a new model, based on the Gateaux
derivatives of the predictions distribution. This model is algorithmically
reasonable and makes it possible to use our regularized loss with standard
stochastic gradient-descent strategies. Its good behavior is assessed on the
reference Adult census, MNIST, CelebA datasets.

    

### [[1912.00827] A Random Matrix Perspective on Mixtures of Nonlinearities for Deep Learning](http://arxiv.org/abs/1912.00827)


  One of the distinguishing characteristics of modern deep learning systems is
that they typically employ neural network architectures that utilize enormous
numbers of parameters, often in the millions and sometimes even in the
billions. While this paradigm has inspired significant research on the
properties of large networks, relatively little work has been devoted to the
fact that these networks are often used to model large complex datasets, which
may themselves contain millions or even billions of constraints. In this work,
we focus on this high-dimensional regime in which both the dataset size and the
number of features tend to infinity. We analyze the performance of random
feature regression with features $F=f(WX+B)$ for a random weight matrix $W$ and
random bias vector $B$, obtaining exact formulae for the asymptotic training
and test errors for data generated by a linear teacher model. The role of the
bias can be understood as parameterizing a distribution over activation
functions, and our analysis directly generalizes to such distributions, even
those not expressible with a traditional additive bias. Intriguingly, we find
that a mixture of nonlinearities can improve both the training and test errors
over the best single nonlinearity, suggesting that mixtures of nonlinearities
might be useful for approximate kernel methods or neural network architecture
design.

    

### [[2003.12260] A light neural network for modulation detection under impairments](http://arxiv.org/abs/2003.12260)


  We present a neural network architecture able to efficiently detect
modulation scheme in a portion of I/Q signals. This network is lighter by up to
two orders of magnitude than other state-of-the-art architectures working on
the same or similar tasks. Moreover, the number of parameters does not depend
on the signal duration, which allows processing stream of data, and results in
a signal-length invariant network. In addition, we have generated a dataset
based on the simulation of impairments that the propagation channel and the
demodulator can bring to recorded I/Q signals: random phase shifts, delays,
roll-off, sampling rates, and frequency offsets. We benefit from this dataset
to train our neural network to be invariant to impairments and quantify its
accuracy at disentangling between modulations under realistic real-life
conditions. Data and code to reproduce the results are made publicly available.

    

### [[2006.10138] An Online Method for A Class of Distributionally Robust Optimization with Non-Convex Objectives](http://arxiv.org/abs/2006.10138)


  In this paper, we propose a practical online method for solving a class of
distributionally robust optimization (DRO) with non-convex objectives, which
has important applications in machine learning for improving the robustness of
neural networks. In the literature, most methods for solving DRO are based on
stochastic primal-dual methods. However, primal-dual methods for DRO suffer
from several drawbacks: (1) manipulating a high-dimensional dual variable
corresponding to the size of data is time expensive; (2) they are not friendly
to online learning where data is coming sequentially. To address these issues,
we consider a class of DRO with an KL divergence regularization on the dual
variables, transform the min-max problem into a compositional minimization
problem, and propose practical duality-free online stochastic methods without
requiring a large mini-batch size. We establish the state-of-the-art
complexities of the proposed methods with and without a Polyak-Łojasiewicz
(PL) condition of the objective. Empirical studies on large-scale deep learning
tasks (i) demonstrate that our method can speed up the training by more than 2
times than baseline methods and save days of training time on a large-scale
dataset with $\sim$ 265K images, and (ii) verify the supreme performance of DRO
over Empirical Risk Minimization (ERM) on imbalanced datasets. Of independent
interest, the proposed method can be also used for solving a family of
stochastic compositional problems with state-of-the-art complexities.

    

### [[2007.04800] A Bandit Model for Human-Machine Decision Making with Private Information and Opacity](http://arxiv.org/abs/2007.04800)


  Applications of machine learning inform human decision makers in a broad
range of tasks. The resulting problem is usually formulated in terms of a
single decision maker. We argue that it should rather be described as a
two-player learning problem where one player is the machine and the other the
human. While both players try to optimize the final decision, the setup is
often characterized by (1) the presence of private information and (2) opacity,
i.e imperfect understanding between the decision makers. In the paper we prove
that both properties can complicate decision making considerably. A lower bound
quantifies the worst-case hardness of optimally advising a decision maker who
is opaque or has access to private information. An upper bound shows that a
simple coordination strategy is nearly minimax optimal. More efficient learning
is possible under certain assumptions on the problem, for example that both
players learn to take actions independently. Such assumptions are implicit in
existing literature, for example in medical applications of machine learning,
but have not been described or justified theoretically.

    

### [[2010.14784] A Chinese Text Classification Method With Low Hardware Requirement Based on Improved Model Concatenation](http://arxiv.org/abs/2010.14784)


  In order to improve the accuracy performance of Chinese text classification
models with low hardware requirements, an improved concatenation-based model is
designed in this paper, which is a concatenation of 5 different sub-models,
including TextCNN, LSTM, and Bi-LSTM. Compared with the existing ensemble
learning method, for a text classification mission, this model's accuracy is 2%
higher. Meanwhile, the hardware requirements of this model are much lower than
the BERT-based model.

    

### [[2012.12250] Iteratively Reweighted Least Squares for Basis Pursuit with Global Linear Convergence Rate](http://arxiv.org/abs/2012.12250)


  The recovery of sparse data is at the core of many applications in machine
learning and signal processing. While such problems can be tackled using
$\ell_1$-regularization as in the LASSO estimator and in the Basis Pursuit
approach, specialized algorithms are typically required to solve the
corresponding high-dimensional non-smooth optimization for large instances.
Iteratively Reweighted Least Squares (IRLS) is a widely used algorithm for this
purpose due its excellent numerical performance. However, while existing theory
is able to guarantee convergence of this algorithm to the minimizer, it does
not provide a global convergence rate. In this paper, we prove that a variant
of IRLS converges with a global linear rate to a sparse solution, i.e., with a
linear error decrease occurring immediately from any initialization, if the
measurements fulfill the usual null space property assumption. We support our
theory by numerical experiments showing that our linear rate captures the
correct dimension dependence. We anticipate that our theoretical findings will
lead to new insights for many other use cases of the IRLS algorithm, such as in
low-rank matrix recovery.

    

### [[2104.01328] Uncertainty for Identifying Open-Set Errors in Visual Object Detection](http://arxiv.org/abs/2104.01328)


  Deployed into an open world, object detectors are prone to open-set errors,
false positive detections of object classes not present in the training
dataset. We propose GMM-Det, a real-time method for extracting epistemic
uncertainty from object detectors to identify and reject open-set errors.
GMM-Det trains the detector to produce a structured logit space that is
modelled with class-specific Gaussian Mixture Models. At test time, open-set
errors are identified by their low log-probability under all Gaussian Mixture
Models. We test two common detector architectures, Faster R-CNN and RetinaNet,
across three varied datasets spanning robotics and computer vision. Our results
show that GMM-Det consistently outperforms existing uncertainty techniques for
identifying and rejecting open-set detections, especially at the low-error-rate
operating point required for safety-critical applications. GMM-Det maintains
object detection performance, and introduces only minimal computational
overhead. We also introduce a methodology for converting existing object
detection datasets into specific open-set datasets to evaluate open-set
performance in object detection.

    

### [[2106.05275] Tractable Density Estimation on Learned Manifolds with Conformal Embedding Flows](http://arxiv.org/abs/2106.05275)


  Normalizing flows are generative models that provide tractable density
estimation via an invertible transformation from a simple base distribution to
a complex target distribution. However, this technique cannot directly model
data supported on an unknown low-dimensional manifold, a common occurrence in
real-world domains such as image data. Recent attempts to remedy this
limitation have introduced geometric complications that defeat a central
benefit of normalizing flows: exact density estimation. We recover this benefit
with Conformal Embedding Flows, a framework for designing flows that learn
manifolds with tractable densities. We argue that composing a standard flow
with a trainable conformal embedding is the most natural way to model
manifold-supported data. To this end, we present a series of conformal building
blocks and apply them in experiments with synthetic and real-world data to
demonstrate that flows can model manifold-supported distributions without
sacrificing tractable likelihoods.

    

### [[2106.08537] Clustering Mixture Models in Almost-Linear Time via List-Decodable Mean Estimation](http://arxiv.org/abs/2106.08537)


  We study the problem of list-decodable mean estimation, where an adversary
can corrupt a majority of the dataset. Specifically, we are given a set $T$ of
$n$ points in $\mathbb{R}^d$ and a parameter $0< \alpha <\frac 1 2$ such that
an $\alpha$-fraction of the points in $T$ are i.i.d. samples from a
well-behaved distribution $\mathcal{D}$ and the remaining $(1-\alpha)$-fraction
are arbitrary. The goal is to output a small list of vectors, at least one of
which is close to the mean of $\mathcal{D}$. We develop new algorithms for
list-decodable mean estimation, achieving nearly-optimal statistical
guarantees, with running time $O(n^{1 + \epsilon_0} d)$, for any fixed
$\epsilon_0 > 0$. All prior algorithms for this problem had additional
polynomial factors in $\frac 1 \alpha$. We leverage this result, together with
additional techniques, to obtain the first almost-linear time algorithms for
clustering mixtures of $k$ separated well-behaved distributions,
nearly-matching the statistical guarantees of spectral methods. Prior
clustering algorithms inherently relied on an application of $k$-PCA, thereby
incurring runtimes of $\Omega(n d k)$. This marks the first runtime improvement
for this basic statistical problem in nearly two decades.
The starting point of our approach is a novel and simpler near-linear time
robust mean estimation algorithm in the $\alpha \to 1$ regime, based on a
one-shot matrix multiplicative weights-inspired potential decrease. We
crucially leverage this new algorithmic framework in the context of the
iterative multi-filtering technique of Diakonikolas et al. '18, '20, providing
a method to simultaneously cluster and downsample points using one-dimensional
projections -- thus, bypassing the $k$-PCA subroutines required by prior
algorithms.

    

### [[2106.13914] Low-Precision Training in Logarithmic Number System using Multiplicative Weight Update](http://arxiv.org/abs/2106.13914)


  Representing deep neural networks (DNNs) in low-precision is a promising
approach to enable efficient acceleration and memory reduction. Previous
methods that train DNNs in low-precision typically keep a copy of weights in
high-precision during the weight updates. Directly training with low-precision
weights leads to accuracy degradation due to complex interactions between the
low-precision number systems and the learning algorithms. To address this
issue, we develop a co-designed low-precision training framework, termed
LNS-Madam, in which we jointly design a logarithmic number system (LNS) and a
multiplicative weight update algorithm (Madam). We prove that LNS-Madam results
in low quantization error during weight updates, leading to a stable
convergence even if the precision is limited. We further propose a hardware
design of LNS-Madam that resolves practical challenges in implementing an
efficient datapath for LNS computations. Our implementation effectively reduces
energy overhead incurred by LNS-to-integer conversion and partial sum
accumulation. Experimental results show that LNS-Madam achieves comparable
accuracy to full-precision counterparts with only 8 bits on popular computer
vision and natural language tasks. Compared to a full-precision floating-point
implementation, LNS-Madam reduces the energy consumption by over 90.

    

### [[2111.06469] Exploiting Long-Distance Interactions and Tolerating Atom Loss in Neutral Atom Quantum Architectures](http://arxiv.org/abs/2111.06469)


  Quantum technologies currently struggle to scale beyond moderate scale
prototypes and are unable to execute even reasonably sized programs due to
prohibitive gate error rates or coherence times. Many software approaches rely
on heavy compiler optimization to squeeze extra value from noisy machines but
are fundamentally limited by hardware. Alone, these software approaches help to
maximize the use of available hardware but cannot overcome the inherent
limitations posed by the underlying technology. An alternative approach is to
explore the use of new, though potentially less developed, technology as a path
towards scalability. In this work we evaluate the advantages and disadvantages
of a Neutral Atom (NA) architecture. NA systems offer several promising
advantages such as long range interactions and native multiqubit gates which
reduce communication overhead, overall gate count, and depth for compiled
programs. Long range interactions, however, impede parallelism with restriction
zones surrounding interacting qubit pairs. We extend current compiler methods
to maximize the benefit of these advantages and minimize the cost. Furthermore,
atoms in an NA device have the possibility to randomly be lost over the course
of program execution which is extremely detrimental to total program execution
time as atom arrays are slow to load. When the compiled program is no longer
compatible with the underlying topology, we need a fast and efficient coping
mechanism. We propose hardware and compiler methods to increase system
resilience to atom loss dramatically reducing total computation time by
circumventing complete reloads or full recompilation every cycle.

    

### [[2111.06584] Elastic Silicon Interconnects: Abstracting Communication in Accelerator Design](http://arxiv.org/abs/2111.06584)


  Communication is an important part of accelerator design, though it is under
researched and under developed. Today, designers often face relatively
low-level communication tools requiring them to design straightforward but
error-prone plumbing. In this paper, we argue that raising the level of
abstraction could yield correctness, productivity, and performance benefits not
only for RTL-level designers but also for high level language developers.

    

### [[2111.06563] Serverless Platforms on the Edge: A Performance Analysis](http://arxiv.org/abs/2111.06563)


  The exponential growth of Internet of Things (IoT) has given rise to a new
wave of edge computing due to the need to process data on the edge, closer to
where it is being produced and attempting to move away from a cloud-centric
architecture. This provides its own opportunity to decrease latency and address
data privacy concerns along with the ability to reduce public cloud costs. The
serverless computing model provides a potential solution with its event-driven
architecture to reduce the need for ever-running servers and convert the
backend services to an as-used model. This model is an attractive prospect in
edge computing environments with varying workloads and limited resources.
Furthermore, its setup on the edge of the network promises reduced latency to
the edge devices communicating with it and eliminates the need to manage the
underlying infrastructure. In this book chapter, first, we introduce the novel
concept of serverless edge computing, then, we analyze the performance of
multiple serverless platforms, namely, OpenFaaS, AWS Greengrass, Apache
OpenWhisk, when set up on the single-board computers (SBCs) on the edge and
compare it with public cloud serverless offerings, namely, AWS Lambda and Azure
Functions, to deduce the suitability of serverless architectures on the network
edge. These serverless platforms are set up on a cluster of Raspberry Pis and
we evaluate their performance by simulating different types of edge workloads.
The evaluation results show that OpenFaaS achieves the lowest response time on
the SBC edge computing infrastructure while serverless cloud offerings are the
most reliable with the highest success rate.

    

### [[2111.06650] Robust and Optimal Contention Resolution without Collision Detection](http://arxiv.org/abs/2111.06650)


  We consider the classical contention resolution problem where nodes arrive
over time, each with a message to send. In each synchronous slot, each node can
send or remain idle. If in a slot one node sends alone, it succeeds; otherwise,
if multiple nodes send simultaneously, messages collide and none succeeds.
Nodes can differentiate collision and silence only if collision detection is
available. Ideally, a contention resolution algorithm should satisfy three
criteria: low time complexity (or high throughput); low energy complexity,
meaning each node does not make too many broadcast attempts; strong robustness,
meaning the algorithm can maintain good performance even if slots can be
jammed. Previous work has shown, with collision detection, there are "perfect"
contention resolution algorithms satisfying all three criteria. On the other
hand, without collision detection, it was not until 2020 that an algorithm was
discovered which can achieve optimal time complexity and low energy cost,
assuming there is no jamming. More recently, the trade-off between throughput
and robustness was studied. However, an intriguing and important question
remains unknown: without collision detection, are there robust algorithms
achieving both low total time complexity and low per-node energy cost? In this
paper, we answer the above question affirmatively. Specifically, we develop a
new randomized algorithm for robust contention resolution without collision
detection. Lower bounds show that it has both optimal time and energy
complexity. If all nodes start execution simultaneously, we design another
algorithm that is even faster, with similar energy complexity as the first
algorithm. The separation on time complexity suggests for robust contention
resolution without collision detection, ``batch'' instances (nodes start
simultaneously) are inherently easier than ``scattered'' ones (nodes arrive
over time).

    

### [[2111.06440] Personalized multi-faceted trust modeling to determine trust links in social media and its potential for misinformation management](http://arxiv.org/abs/2111.06440)


  In this paper, we present an approach for predicting trust links between
peers in social media, one that is grounded in the artificial intelligence area
of multiagent trust modeling. In particular, we propose a data-driven
multi-faceted trust modeling which incorporates many distinct features for a
comprehensive analysis. We focus on demonstrating how clustering of similar
users enables a critical new functionality: supporting more personalized, and
thus more accurate predictions for users. Illustrated in a trust-aware item
recommendation task, we evaluate the proposed framework in the context of a
large Yelp dataset. We then discuss how improving the detection of trusted
relationships in social media can assist in supporting online users in their
battle against the spread of misinformation and rumours, within a social
networking environment which has recently exploded in popularity. We conclude
with a reflection on a particularly vulnerable user base, older adults, in
order to illustrate the value of reasoning about groups of users, looking to
some future directions for integrating known preferences with insights gained
through data analysis.

    

### [[2111.06449] Expert Human-Level Driving in Gran Turismo Sport Using Deep Reinforcement Learning with Image-based Representation](http://arxiv.org/abs/2111.06449)


  When humans play virtual racing games, they use visual environmental
information on the game screen to understand the rules within the environments.
In contrast, a state-of-the-art realistic racing game AI agent that outperforms
human players does not use image-based environmental information but the
compact and precise measurements provided by the environment. In this paper, a
vision-based control algorithm is proposed and compared with human player
performances under the same conditions in realistic racing scenarios using Gran
Turismo Sport (GTS), which is known as a high-fidelity realistic racing
simulator. In the proposed method, the environmental information that
constitutes part of the observations in conventional state-of-the-art methods
is replaced with feature representations extracted from game screen images. We
demonstrate that the proposed method performs expert human-level vehicle
control under high-speed driving scenarios even with game screen images as
high-dimensional inputs. Additionally, it outperforms the built-in AI in GTS in
a time trial task, and its score places it among the top 10% approximately
28,000 human players.

    

### [[2111.06494] DPLL(MAPF): an Integration of Multi-Agent Path Finding and SAT Solving Technologies](http://arxiv.org/abs/2111.06494)


  In multi-agent path finding (MAPF), the task is to find non-conflicting paths
for multiple agents from their initial positions to given individual goal
positions. MAPF represents a classical artificial intelligence problem often
addressed by heuristic-search. An important alternative to search-based
techniques is compilation of MAPF to a different formalism such as Boolean
satisfiability (SAT). Contemporary SAT-based approaches to MAPF regard the SAT
solver as an external tool whose task is to return an assignment of all
decision variables of a Boolean model of input MAPF. We present in this short
paper a novel compilation scheme called DPLL(MAPF) in which the consistency
checking of partial assignments of decision variables with respect to the MAPF
rules is integrated directly into the SAT solver. This scheme allows for far
more automated compilation where the SAT solver and the consistency checking
procedure work together simultaneously to create the Boolean model and to
search for its satisfying assignment.

    

### [[2111.06575] Self-supervised GAN Detector](http://arxiv.org/abs/2111.06575)


  Although the recent advancement in generative models brings diverse
advantages to society, it can also be abused with malicious purposes, such as
fraud, defamation, and fake news. To prevent such cases, vigorous research is
conducted to distinguish the generated images from the real images, but
challenges still remain to distinguish the unseen generated images outside of
the training settings. Such limitations occur due to data dependency arising
from the model's overfitting issue to the training data generated by specific
GANs. To overcome this issue, we adopt a self-supervised scheme to propose a
novel framework. Our proposed method is composed of the artificial fingerprint
generator reconstructing the high-quality artificial fingerprints of GAN images
for detailed analysis, and the GAN detector distinguishing GAN images by
learning the reconstructed artificial fingerprints. To improve the
generalization of the artificial fingerprint generator, we build multiple
autoencoders with different numbers of upconvolution layers. With numerous
ablation studies, the robust generalization of our method is validated by
outperforming the generalization of the previous state-of-the-art algorithms,
even without utilizing the GAN images of the training dataset.

    

### [[2111.06638] Meta-Teacher For Face Anti-Spoofing](http://arxiv.org/abs/2111.06638)


  Face anti-spoofing (FAS) secures face recognition from presentation attacks
(PAs). Existing FAS methods usually supervise PA detectors with handcrafted
binary or pixel-wise labels. However, handcrafted labels may are not the most
adequate way to supervise PA detectors learning sufficient and intrinsic
spoofing cues. Instead of using the handcrafted labels, we propose a novel
Meta-Teacher FAS (MT-FAS) method to train a meta-teacher for supervising PA
detectors more effectively. The meta-teacher is trained in a bi-level
optimization manner to learn the ability to supervise the PA detectors learning
rich spoofing cues. The bi-level optimization contains two key components: 1) a
lower-level training in which the meta-teacher supervises the detector's
learning process on the training set; and 2) a higher-level training in which
the meta-teacher's teaching performance is optimized by minimizing the
detector's validation loss. Our meta-teacher differs significantly from
existing teacher-student models because the meta-teacher is explicitly trained
for better teaching the detector (student), whereas existing teachers are
trained for outstanding accuracy neglecting teaching ability. Extensive
experiments on five FAS benchmarks show that with the proposed MT-FAS, the
trained meta-teacher 1) provides better-suited supervision than both
handcrafted labels and existing teacher-student models; and 2) significantly
improves the performances of PA detectors.

    

### [[2111.06639] Attention Guided Cosine Margin For Overcoming Class-Imbalance in Few-Shot Road Object Detection](http://arxiv.org/abs/2111.06639)


  Few-shot object detection (FSOD) localizes and classifies objects in an image
given only a few data samples. Recent trends in FSOD research show the adoption
of metric and meta-learning techniques, which are prone to catastrophic
forgetting and class confusion. To overcome these pitfalls in metric learning
based FSOD techniques, we introduce Attention Guided Cosine Margin (AGCM) that
facilitates the creation of tighter and well separated class-specific feature
clusters in the classification head of the object detector. Our novel Attentive
Proposal Fusion (APF) module minimizes catastrophic forgetting by reducing the
intra-class variance among co-occurring classes. At the same time, the proposed
Cosine Margin Cross-Entropy loss increases the angular margin between confusing
classes to overcome the challenge of class confusion between already learned
(base) and newly added (novel) classes. We conduct our experiments on the
challenging India Driving Dataset (IDD), which presents a real-world
class-imbalanced setting alongside popular FSOD benchmark PASCAL-VOC. Our
method outperforms State-of-the-Art (SoTA) approaches by up to 6.4 mAP points
on the IDD-OS and up to 2.0 mAP points on the IDD-10 splits for the 10-shot
setting. On the PASCAL-VOC dataset, we outperform existing SoTA approaches by
up to 4.9 mAP points.

    

### [[2111.06741] A Quantum Natural Language Processing Approach to Musical Intelligence](http://arxiv.org/abs/2111.06741)


  There has been tremendous progress in Artificial Intelligence (AI) for music,
in particular for musical composition and access to large databases for
commercialisation through the Internet. We are interested in further advancing
this field, focusing on composition. In contrast to current black-box AI
methods, we are championing an interpretable compositional outlook on
generative music systems. In particular, we are importing methods from the
Distributional Compositional Categorical (DisCoCat) modelling framework for
Natural Language Processing (NLP), motivated by musical grammars. Quantum
computing is a nascent technology, which is very likely to impact the music
industry in time to come. Thus, we are pioneering a Quantum Natural Language
Processing (QNLP) approach to develop a new generation of intelligent musical
systems. This work follows from previous experimental implementations of
DisCoCat linguistic models on quantum hardware. In this chapter, we present
Quanthoven, the first proof-of-concept ever built, which (a) demonstrates that
it is possible to program a quantum computer to learn to classify music that
conveys different meanings and (b) illustrates how such a capability might be
leveraged to develop a system to compose meaningful pieces of music. After a
discussion about our current understanding of music as a communication medium
and its relationship to natural language, the chapter focuses on the techniques
developed to (a) encode musical compositions as quantum circuits, and (b)
design a quantum classifier. The chapter ends with demonstrations of
compositions created with the system.

    

### [[2111.06757] Multiway Storage Modification Machines](http://arxiv.org/abs/2111.06757)


  We present a parallel version of Schönhage's Storage Modification Machine,
the Multiway Storage Modification Machine (MWSMM). Like the alternative
Association Storage Modification Machine of Tromp and van Emde Boas, MWSMMs
recognize in polynomial time what Turing Machines recognize in polynomial
space. Falling thus into the Second Machine Class, the MWSMM is a parallel
machine model conforming to the Parallel Computation Thesis. We illustrate
MWSMMs by a simple implementation of Wolfram's String Substitution System.

    

### [[2111.06803] Two steps to risk sensitivity](http://arxiv.org/abs/2111.06803)


  Distributional reinforcement learning (RL) -- in which agents learn about all
the possible long-term consequences of their actions, and not just the expected
value -- is of great recent interest. One of the most important affordances of
a distributional view is facilitating a modern, measured, approach to risk when
outcomes are not completely certain. By contrast, psychological and
neuroscientific investigations into decision making under risk have utilized a
variety of more venerable theoretical models such as prospect theory that lack
axiomatically desirable properties such as coherence. Here, we consider a
particularly relevant risk measure for modeling human and animal planning,
called conditional value-at-risk (CVaR), which quantifies worst-case outcomes
(e.g., vehicle accidents or predation). We first adopt a conventional
distributional approach to CVaR in a sequential setting and reanalyze the
choices of human decision-makers in the well-known two-step task, revealing
substantial risk aversion that had been lurking under stickiness and
perseveration. We then consider a further critical property of risk
sensitivity, namely time consistency, showing alternatives to this form of CVaR
that enjoy this desirable characteristic. We use simulations to examine
settings in which the various forms differ in ways that have implications for
human and animal planning and behavior.

    

### [[2111.06804] Catastrophe, Compounding & Consistency in Choice](http://arxiv.org/abs/2111.06804)


  Conditional value-at-risk (CVaR) precisely characterizes the influence that
rare, catastrophic events can exert over decisions. Such characterizations are
important for both normal decision-making and for psychiatric conditions such
as anxiety disorders -- especially for sequences of decisions that might
ultimately lead to disaster. CVaR, like other well-founded risk measures,
compounds in complex ways over such sequences -- and we recently formalized
three structurally different forms in which risk either averages out or
multiplies. Unfortunately, existing cognitive tasks fail to discriminate these
approaches well; here, we provide examples that highlight their unique
characteristics, and make formal links to temporal discounting for the two of
the approaches that are time consistent. These examples can ground future
experiments with the broader aim of characterizing risk attitudes, especially
for longer horizon problems and in psychopathological populations.

    

### [[2111.06852] Influential Papers in Artificial Intelligence and Paediatrics: Assessing RPYS by Experts Review](http://arxiv.org/abs/2111.06852)


  The use of artificial intelligence in paediatrics has vastly increased in the
last few years. Interestingly, no historical bibliometric study analysing the
knowledge development in this specific paediatric field has been performed yet,
thus our study aimed to close this gap. References Publication Years
Spectrography (RPYS), more precisely CitedReferenceExplorer (CRE) software tool
was employed to achieve this aim. We identified 28 influential papers and
domain experts validation showed that both, the RPYS method and CRE tool
performed adequately in the identification process.

    

### [[2111.06854] Time in a Box: Advancing Knowledge Graph Completion with Temporal Scopes](http://arxiv.org/abs/2111.06854)


  Almost all statements in knowledge bases have a temporal scope during which
they are valid. Hence, knowledge base completion (KBC) on temporal knowledge
bases (TKB), where each statement \textit{may} be associated with a temporal
scope, has attracted growing attention. Prior works assume that each statement
in a TKB \textit{must} be associated with a temporal scope. This ignores the
fact that the scoping information is commonly missing in a KB. Thus prior work
is typically incapable of handling generic use cases where a TKB is composed of
temporal statements with/without a known temporal scope. In order to address
this issue, we establish a new knowledge base embedding framework, called
TIME2BOX, that can deal with atemporal and temporal statements of different
types simultaneously. Our main insight is that answers to a temporal query
always belong to a subset of answers to a time-agnostic counterpart. Put
differently, time is a filter that helps pick out answers to be correct during
certain periods. We introduce boxes to represent a set of answer entities to a
time-agnostic query. The filtering functionality of time is modeled by
intersections over these boxes. In addition, we generalize current evaluation
protocols on time interval prediction. We describe experiments on two datasets
and show that the proposed method outperforms state-of-the-art (SOTA) methods
on both link prediction and time prediction.

    

### [[2011.08999] PassGoodPool: Joint Passengers and Goods Fleet Management with Reinforcement Learning aided Pricing, Matching, and Route Planning](http://arxiv.org/abs/2011.08999)


  The ubiquitous growth of mobility-on-demand services for passenger and goods
delivery has brought various challenges and opportunities within the realm of
transportation systems. As a result, intelligent transportation systems are
being developed to maximize operational profitability, user convenience, and
environmental sustainability. The growth of last mile deliveries alongside
ridesharing calls for an efficient and cohesive system that transports both
passengers and goods. Existing methods address this using static routing
methods considering neither the demands of requests nor the transfer of goods
between vehicles during route planning. In this paper, we present a dynamic and
demand aware fleet management framework for combined goods and passenger
transportation that is capable of (1) Involving both passengers and drivers in
the decision-making process by allowing drivers to negotiate to a mutually
suitable price, and passengers to accept/reject, (2) Matching of goods to
vehicles, and the multi-hop transfer of goods, (3) Dynamically generating
optimal routes for each vehicle considering demand along their paths, based on
the insertion cost which then determines the matching, (4) Dispatching idle
vehicles to areas of anticipated high passenger and goods demand using Deep
Reinforcement Learning (RL), (5) Allowing for distributed inference at each
vehicle while collectively optimizing fleet objectives. Our proposed model is
deployable independently within each vehicle as this minimizes computational
costs associated with the growth of distributed systems and democratizes
decision-making to each individual. Simulations on a variety of vehicle types,
goods, and passenger utility functions show the effectiveness of our approach
as compared to other methods that do not consider combined load transportation
or dynamic multi-hop route planning.

    

### [[2103.08137] Cloth Manipulation Planning on Basis of Mesh Representations with Incomplete Domain Knowledge and Voxel-to-Mesh Estimation](http://arxiv.org/abs/2103.08137)


  We consider the problem of open-goal planning for robotic cloth manipulation.
Core of our system is a neural network trained as a forward model of cloth
behaviour under manipulation, with planning performed through backpropagation.
We introduce a neural network-based routine for estimating mesh representations
from voxel input, and perform planning in mesh format internally. We address
the problem of planning with incomplete domain knowledge by means of an
explicit epistemic uncertainty signal. This signal is calculated from
prediction divergence between two instances of the forward model network and
used to avoid epistemic uncertainty during planning. Finally, we introduce
logic for handling restriction of grasp points to a discrete set of candidates,
in order to accommodate graspability constraints imposed by robotic hardware.
We evaluate the system's mesh estimation, prediction, and planning ability on
simulated cloth for sequences of one to three manipulations. Comparative
experiments confirm that planning on basis of estimated meshes improves
accuracy compared to voxel-based planning, and that epistemic uncertainty
avoidance improves performance under conditions of incomplete domain knowledge.
Planning time cost is a few seconds. We additionally present qualitative
results on robot hardware.

    

### [[2103.12719] Characterizing and Improving the Robustness of Self-Supervised Learning through Background Augmentations](http://arxiv.org/abs/2103.12719)


  Recent progress in self-supervised learning has demonstrated promising
results in multiple visual tasks. An important ingredient in high-performing
self-supervised methods is the use of data augmentation by training models to
place different augmented views of the same image nearby in embedding space.
However, commonly used augmentation pipelines treat images holistically,
ignoring the semantic relevance of parts of an image-e.g. a subject vs. a
background-which can lead to the learning of spurious correlations. Our work
addresses this problem by investigating a class of simple, yet highly effective
"background augmentations", which encourage models to focus on
semantically-relevant content by discouraging them from focusing on image
backgrounds. Through a systematic investigation, we show that background
augmentations lead to substantial improvements in performance across a spectrum
of state-of-the-art self-supervised methods (MoCo-v2, BYOL, SwAV) on a variety
of tasks, e.g. $\sim$+1-2% gains on ImageNet, enabling performance on par with
the supervised baseline. Further, we find the improvement in limited-labels
settings is even larger (up to 4.2%). Background augmentations also improve
robustness to a number of distribution shifts, including natural adversarial
examples, ImageNet-9, adversarial attacks, ImageNet-Renditions. We also make
progress in completely unsupervised saliency detection, in the process of
generating saliency masks used for background augmentations.

    

### [[2104.08368] Motion Prediction Performance Analysis for Autonomous Driving Systems and the Effects of Tracking Noise](http://arxiv.org/abs/2104.08368)


  Autonomous driving consists of a multitude of interacting modules, where each
module must contend with errors from the others. Typically, the motion
prediction module depends upon a robust tracking system to capture each agent's
past movement. In this work, we systematically explore the importance of the
tracking module for the motion prediction task and ultimately conclude that the
overall motion prediction performance is highly sensitive to the tracking
module's imperfections. We explicitly compare models that use tracking
information to models that do not across multiple scenarios and conditions. We
find that the tracking information plays an essential role and improves motion
prediction performance in noise-free conditions. However, in the presence of
tracking noise, it can potentially affect the overall performance if not
studied thoroughly. We thus argue practitioners should be mindful of noise when
developing and testing motion/tracking modules, or that they should consider
tracking free alternatives.

    

### [[2105.12960] Hybrid Encoding For Generating Large Scale Game Level Patterns With Local Variations](http://arxiv.org/abs/2105.12960)


  Generative Adversarial Networks (GANs) are a powerful indirect
genotype-to-phenotype mapping for evolutionary search. Much previous work
applying GANs to level generation focuses on fixed-size segments combined into
a whole level, but individual segments may not fit together cohesively. In
contrast, segments in human designed levels are often repeated, directly or
with variation, and organized into patterns (the symmetric eagle in Level 1 of
The Legend of Zelda, or repeated pipe motifs in Super Mario Bros). Such
patterns can be produced with Compositional Pattern Producing Networks (CPPNs).
CPPNs define latent vector GAN inputs as a function of geometry, organizing
segments output by a GAN into complete levels. However, collections of latent
vectors can also be evolved directly, producing more chaotic levels. We propose
a hybrid approach that evolves CPPNs first, but allows latent vectors to evolve
later, combining the benefits of both approaches. These approaches are
evaluated in Super Mario Bros. and The Legend of Zelda. We previously
demonstrated via divergent search (MAP-Elites) that CPPNs better cover the
space of possible levels than directly evolved levels. Here, we show that the
hybrid approach (1) covers areas that neither of the other methods can, and (2)
achieves comparable or superior QD scores.

    