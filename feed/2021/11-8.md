
## 2021-11-8

### [[2111.03147] Multi-Connectivity in Mobile Networks: Challenges and Benefits](http://arxiv.org/abs/2111.03147)


  Satisfying the stringent 5G Quality of Service (QoS) requirements
necessitates efficient resource utilization by the mobile networks.
Consequently, we argue that Multi-Connectivity (MC) is an effective solution to
leverage the limited radio resources from multiple base stations (BSs) in order
to enhance the user throughput, provide seamless connectivity, or increase the
data reliability. For this, we study different MC architectures, where distinct
network entities and protocol layers are used to split or aggregate the user
traffic. The benefits and challenges of MC are analyzed as well as the open
issues that network/device vendors and mobile network operators (MNOs) have to
address for its use. Finally, through experimental evaluations, we illustrate
the importance of MC design decisions for the overall network performance.

    

### [[2111.03246] Long-distance Deterministic Transmission among TSN Networks: Converging CQF and DIP](http://arxiv.org/abs/2111.03246)


  With the development of 5G, innovative applications requiring bounded
transmission delays and zero packet loss emerge, e.g., AR, industrial
automation, and smart grid. In this circumstance, time-sensitive networking
(TSN) is proposed, which addresses the deterministic transmission in the local
area networks. Nevertheless, TSN is essentially a Layer 2 technique, which
cannot provide deterministic transmission on a large geographic area. To solve
this problem, this paper proposes a hierarchical network for the end-to-end
deterministic transmission. In the proposed network, we leverage CQF (i.e., one
of the most efficient TSN mechanisms) in the access networks which aggregates
the traffic from end-devices. Meanwhile, in the core network, we exploit the
DIP (i.e., a well-known deterministic networking mechanism for backbone
networks) for long-distance deterministic transmission. We design the cycle
alignment mechanism to enable seamless and deterministic transmission among
hierarchical networks. A joint schedule is also formulated, which introduces
the traffic shaping at the network edge to maximize the network throughput.
Experimental simulations show that the proposed network can achieve end-to-end
deterministic transmission, even in the highly-load scenarios.

    

### [[2111.03255] Transient Performance Modelling of 5G Slicing with Mixed Numerologies for Smart Grid Traffic](http://arxiv.org/abs/2111.03255)


  Network slicing enabled by fifth generation (5G) systems has the potential to
satisfy diversified service requirements from different vertical industries. As
a typical vertical industry, smart distribution grid poses new challenges to
communication networks. This paper investigates the behavior of network slicing
for smart grid applications in 5G radio access networks with heterogeneous
traffic. To facilitate network slicing in such a network, we employ different
5G radio access numerologies for two traffic classes which have distinct radio
resource and quality of service requirements. Three multi-dimensional Markov
models are developed to assess the transient performance of network slicing for
resource allocation with and without traffic priority. Through analysis and
simulations, we investigate the effects of smart grid protection and control
traffic on other types of parallel traffic sessions as well as on radio
resource utilization.

    

### [[2111.03310] Adaptive Warden Strategy for Countering Network Covert Storage Channels](http://arxiv.org/abs/2111.03310)


  The detection and elimination of covert channels are performed by a network
node, known as a warden. Especially if faced with adaptive covert communication
parties, a regular warden equipped with a static set of normalization rules is
ineffective compared to a dynamic warden. However, dynamic wardens rely on
periodically changing rule sets and have their own limitations, since they do
not consider traffic specifics. We propose a novel adaptive warden strategy,
capable of selecting active normalization rules by taking into account the
characteristics of the observed network traffic. Our goal is to disturb the
covert channel and provoke the covert peers to expose themselves more by
increasing the number of packets required to perform a successful covert data
transfer. Our evaluation revealed that the adaptive warden has better
efficiency and effectiveness when compared to the dynamic warden because of its
adaptive selection of normalization rules.

    

### [[2111.03438] IPAL: Breaking up Silos of Protocol-dependent and Domain-specific Industrial Intrusion Detection Systems](http://arxiv.org/abs/2111.03438)


  The increasing interconnection of industrial networks with the Internet
exposes them to an ever-growing risk of cyberattacks. A well-proven mechanism
to detect such attacks is industrial intrusion detection, which searches for
anomalies in otherwise predictable communication or process behavior. However,
efforts to improve these detection methods mostly focus on specific domains and
communication protocols, leading to a research landscape that is broken up into
isolated silos. Thus, existing approaches cannot be applied to other industrial
scenarios that would equally benefit from powerful detection approaches. To
better understand this issue, we survey 53 detection systems and conclude that
there is no fundamental reason for their narrow focus. Although they are often
coupled to specific industrial protocols in practice, many approaches could
generalize to new industrial scenario in theory. To unlock this potential for
intrusion detection across industrial domains and protocols, we propose IPAL,
our industrial protocol abstraction layer, to decouple intrusion detection from
domain-specific industrial communication protocols. We show the practical
applicability and correctness of IPAL through a reproducibility study in which
we re-implement eight detection approaches from related work on top of IPAL.
Finally, we showcase the unique benefits of IPAL for industrial intrusion
detection research by studying the generalizability of existing approaches to
new datasets and conclude that they are indeed not restricted to specific
domains or protocols.

    

### [[2111.03451] Small UAVs-supported Autonomous Generation of Fine-grained 3D Indoor Radio Environmental Maps](http://arxiv.org/abs/2111.03451)


  Radio Environmental Maps (REMs) are a powerful tool for enhancing the
performance of various communication and networked agents. However, generating
REMs is a laborious undertaking, especially in complex 3-Dimensional (3D)
environments, such as indoors. To address this issue, we propose a system for
autonomous generation of fine-grained REMs of indoor 3D spaces. In the system,
multiple small indoor Unmanned Aerial Vehicles (UAVs) are sequentially used for
3D sampling of signal quality indicators. The collected readings are
streamlined to a Machine Learning (ML) system for its training and, once
trained, the system is able to predict the signal quality at unknown 3D
locations. The system enables automated and autonomous REM generation, and can
be straightforwardly deployed in new environments. In addition, the system
supports REM sampling without self-interference and is technology-agnostic, as
long as the REM-sampling receivers features suitable sizes and weights to be
carried by the UAVs. In the demonstration, we instantiate the system design
using two UAVs and show its capability of visiting 72 waypoints and gathering
thousands of Wi-Fi data samples. Our results also include an instantiation of
the ML system for predicting the Received Signal Strength (RSS) of known Wi-Fi
Access Points (APs) at locations not visited by the UAVs.

    

### [[2111.03461] Misbehavior Detection Using Collective Perception under Privacy Considerations](http://arxiv.org/abs/2111.03461)


  In cooperative ITS, security and privacy protection are essential.
Cooperative Awareness Message (CAM) is a basic V2V message standard, and
misbehavior detection is critical for protection against attacking CAMs from
the inside system, in addition to node authentication by Public Key
Infrastructure (PKI). On the contrary, pseudonym IDs, which have been
introduced to protect privacy from tracking, make it challenging to perform
misbehavior detection. In this study, we improve the performance of misbehavior
detection using observation data of other vehicles. This is referred to as
collective perception message (CPM), which is becoming the new standard in
European countries. We have experimented using realistic traffic scenarios and
succeeded in reducing the rate of rejecting valid CAMs (false positive) by
approximately 15 percentage points while maintaining the rate of correctly
detecting attacks (true positive).

    

### [[2111.03488] SLA-Driven Load Scheduling in Multi-Tier Cloud Computing: Financial Impact Considerations](http://arxiv.org/abs/2111.03488)


  A cloud service provider strives to provide a high Quality of Service (QoS)
to client jobs. Such jobs vary in computational and Service-Level-Agreement
(SLA) obligations, as well as differ with respect to tolerating delays and SLA
violations. The job scheduling plays a critical role in servicing cloud demands
by allocating appropriate resources to execute client jobs. The response to
such jobs is optimized by the cloud provider on a multi-tier cloud computing
environment. Typically, the complex and dynamic nature of multi-tier
environments incurs difficulties in meeting such demands, because tiers are
dependent on each other which in turn makes bottlenecks of a tier shift to
escalate in subsequent tiers. However, the optimization process of existing
approaches produces single-tier-driven schedules that do not employ the
differential impact of SLA violations in executing client jobs. Furthermore,
the impact of schedules optimized at the tier level on the performance of
schedules formulated in subsequent tiers tends to be ignored, resulting in a
less than optimal performance when measured at the multi-tier level. Thus,
failing in committing job obligations incurs SLA penalties that often take the
form of either financial compensations, or losing future interests and
motivations of unsatisfied clients in the service provided. In this paper, a
scheduling and allocation approach is proposed to formulate schedules that
account for differential impacts of SLA violation penalties and, thus, produce
schedules that are optimal in financial performance. A queue virtualization
scheme is designed to facilitate the formulation of optimal schedules at the
tier and multi-tier levels of the cloud environment. Because the scheduling
problem is NP-hard, a biologically inspired approach is proposed to mitigate
the complexity of finding optimal schedules.

    

### [[2111.03550] On Slice Isolation Options in the Transport Network and Associated Feasibility Indicators](http://arxiv.org/abs/2111.03550)


  Isolation is one of the more relevant attributes associated to the idea of
network slicing, introduced by 5G services. Through isolation it is expected
that slices from different customers could gracefully coexist without
interfering each other, in the sense that whatever misbehavior or unforeseen
demand from one slice customer could not affect the communication service
received by any other slice customer supported atop the same physical transport
infrastructure. This paper surveys and compare different technical approaches
that can be taken for providing distinct isolation levels in the transport
network, as a major component of end-to-end network slices. Furthermore, a
number of isolation feasibility indicators are defined and proposed. These
indicators are based on the approaches referred before, as a mean of guiding
orchestration decisions at the time of provisioning or reconfiguring the
transport slices in the network.

    

### [[2006.01371] Energy-Efficient Cyclical Trajectory Design for UAV-Aided Maritime Data Collection in Wind](http://arxiv.org/abs/2006.01371)


  Unmanned aerial vehicles (UAVs), especially fixed-wing ones that withstand
strong winds, have great potential for oceanic exploration and research. This
paper studies a UAV-aided maritime data collection system with a fixed-wing UAV
dispatched to collect data from marine buoys. We aim to minimize the UAV's
energy consumption in completing the task by jointly optimizing the
communication time scheduling among the buoys and the UAV's flight trajectory
subject to wind effect, which is a non-convex problem and difficult to solve
optimally. Existing techniques such as the successive convex approximation
(SCA) method provide efficient sub-optimal solutions for collecting
small/moderate data volume, whereas the solution heavily relies on the
trajectory initialization and has not explicitly considered the wind effect,
while the computational complexity and resulted trajectory complexity both
become prohibitive for the task with large data volume. To this end, we propose
a new cyclical trajectory design framework that can handle arbitrary data
volume efficiently subject to wind effect. Specifically, the proposed UAV
trajectory comprises multiple cyclical laps, each responsible for collecting
only a subset of data and thereby significantly reducing the
computational/trajectory complexity, which allows searching for better
trajectory initialization that fits the buoys' topology and the wind. Numerical
results show that the proposed cyclical scheme outperforms the benchmark
one-flight-only scheme in general. Moreover, the optimized cyclical 8-shape
trajectory can proactively exploit the wind and achieve lower energy
consumption compared with the case without wind.

    

### [[2008.07438] Analysis and Optimization for Large-Scale LoRa Networks: Throughput Fairness and Scalability](http://arxiv.org/abs/2008.07438)


  LoRa networks are pivotally enabling Long Range connectivity to low-cost and
power-constrained user equipments (UEs) in a wide area, whereas a critical
issue is to effectively allocate wireless resources to support potentially
massive UEs while resolving the prominent near-far fairness issue, which is
challenging due to the lack of tractable analytical model and the practical
requirement for low-complexity and low-overhead design. Leveraging on
stochastic geometry, especially the Poisson rain model, we derive (semi-)
closed-form formulas for the aggregate interference distribution, packet
success probability and hence system throughput in both single-cell and
multi-cell setups with frequency reuse, by accounting for channel fading,
random UE distribution, partial packet overlapping, and/or multi-gateway packet
reception. The analytical formulas require only average channel statistics and
spatial UE distribution, which enable tractable network performance evaluation
and incubate our proposed Iterative Balancing (IB) method that quickly yields
high-level policies of joint spreading factor (SF) allocation, power control,
and duty cycle adjustment for gauging the average max-min UE throughput or
supported UE density with rate requirements. Numerical results validate the
analytical formulas and the effectiveness of our proposed optimization scheme,
which greatly alleviates the near-far fairness issue and reduces the spatial
power consumption, while significantly improving the cell-edge throughput as
well as the spatial (sum) throughput for the majority of UEs, by adapting to
the UE/gateway densities.

    

### [[2105.08576] AI-Native Network Slicing for 6G Networks](http://arxiv.org/abs/2105.08576)


  With the global roll-out of the fifth generation (5G) networks, it is
necessary to look beyond 5G and envision the 6G networks. The 6G networks are
expected to have space-air-ground integrated networks, advanced network
virtualization, and ubiquitous intelligence. This article presents an
artificial intelligence (AI)-native network slicing architecture for 6G
networks to enable the synergy of AI and network slicing, thereby facilitating
intelligent network management and supporting emerging AI services. AI-based
solutions are first discussed across network slicing lifecycle to intelligently
manage network slices, i.e., AI for slicing. Then, network slicing solutions
are studied to support emerging AI services by constructing AI instances and
performing efficient resource management, i.e., slicing for AI. Finally, a case
study is presented, followed by a discussion of open research issues that are
essential for AI-native network slicing in 6G networks.

    

### [[2111.03064] Physics-Guided Generative Adversarial Networks for Sea Subsurface Temperature Prediction](http://arxiv.org/abs/2111.03064)


  Sea subsurface temperature, an essential component of aquatic wildlife,
underwater dynamics and heat transfer with the sea surface, is affected by
global warming in climate change. Existing research is commonly based on either
physics-based numerical models or data based models. Physical modeling and
machine learning are traditionally considered as two unrelated fields for the
sea subsurface temperature prediction task, with very different scientific
paradigms (physics-driven and data-driven). However, we believe both methods
are complementary to each other. Physical modeling methods can offer the
potential for extrapolation beyond observational conditions, while data-driven
methods are flexible in adapting to data and are capable of detecting
unexpected patterns. The combination of both approaches is very attractive and
offers potential performance improvement. In this paper, we propose a novel
framework based on generative adversarial network (GAN) combined with numerical
model to predict sea subsurface temperature. First, a GAN-based model is used
to learn the simplified physics between the surface temperature and the target
subsurface temperature in numerical model. Then, observation data are used to
calibrate the GAN-based model parameters to obtain better prediction. We
evaluate the proposed framework by predicting daily sea subsurface temperature
in the South China sea. Extensive experiments demonstrate the effectiveness of
the proposed framework compared to existing state-of-the-art methods.

    

### [[2111.03085] Application of Machine Learning to Sleep Stage Classification](http://arxiv.org/abs/2111.03085)


  Sleep studies are imperative to recapitulate phenotypes associated with sleep
loss and uncover mechanisms contributing to psychopathology. Most often,
investigators manually classify the polysomnography into vigilance states,
which is time-consuming, requires extensive training, and is prone to
inter-scorer variability. While many works have successfully developed
automated vigilance state classifiers based on multiple EEG channels, we aim to
produce an automated and open-access classifier that can reliably predict
vigilance state based on a single cortical electroencephalogram (EEG) from
rodents to minimize the disadvantages that accompany tethering small animals
via wires to computer programs. Approximately 427 hours of continuously
monitored EEG, electromyogram (EMG), and activity were labeled by a domain
expert out of 571 hours of total data. Here we evaluate the performance of
various machine learning techniques on classifying 10-second epochs into one of
three discrete classes: paradoxical, slow-wave, or wake. Our investigations
include Decision Trees, Random Forests, Naive Bayes Classifiers, Logistic
Regression Classifiers, and Artificial Neural Networks. These methodologies
have achieved accuracies ranging from approximately 74% to approximately 96%.
Most notably, the Random Forest and the ANN achieved remarkable accuracies of
95.78% and 93.31%, respectively. Here we have shown the potential of various
machine learning classifiers to automatically, accurately, and reliably
classify vigilance states based on a single EEG reading and a single EMG
reading.

    

### [[2111.03110] Successor Feature Neural Episodic Control](http://arxiv.org/abs/2111.03110)


  A longstanding goal in reinforcement learning is to build intelligent agents
that show fast learning and a flexible transfer of skills akin to humans and
animals. This paper investigates the integration of two frameworks for tackling
those goals: episodic control and successor features. Episodic control is a
cognitively inspired approach relying on episodic memory, an instance-based
memory model of an agent's experiences. Meanwhile, successor features and
generalized policy improvement (SF&GPI) is a meta and transfer learning
framework allowing to learn policies for tasks that can be efficiently reused
for later tasks which have a different reward function. Individually, these two
techniques have shown impressive results in vastly improving sample efficiency
and the elegant reuse of previously learned policies. Thus, we outline a
combination of both approaches in a single reinforcement learning framework and
empirically illustrate its benefits.

    

### [[2111.03112] My House, My Rules: Learning Tidying Preferences with Graph Neural Networks](http://arxiv.org/abs/2111.03112)


  Robots that arrange household objects should do so according to the user's
preferences, which are inherently subjective and difficult to model. We present
NeatNet: a novel Variational Autoencoder architecture using Graph Neural
Network layers, which can extract a low-dimensional latent preference vector
from a user by observing how they arrange scenes. Given any set of objects,
this vector can then be used to generate an arrangement which is tailored to
that user's spatial preferences, with word embeddings used for generalisation
to new objects. We develop a tidying simulator to gather rearrangement examples
from 75 users, and demonstrate empirically that our method consistently
produces neat and personalised arrangements across a variety of rearrangement
scenarios.

    

### [[2111.03120] Adversarial Attacks on Knowledge Graph Embeddings via Instance Attribution Methods](http://arxiv.org/abs/2111.03120)


  Despite the widespread use of Knowledge Graph Embeddings (KGE), little is
known about the security vulnerabilities that might disrupt their intended
behaviour. We study data poisoning attacks against KGE models for link
prediction. These attacks craft adversarial additions or deletions at training
time to cause model failure at test time. To select adversarial deletions, we
propose to use the model-agnostic instance attribution methods from
Interpretable Machine Learning, which identify the training instances that are
most influential to a neural model's predictions on test instances. We use
these influential triples as adversarial deletions. We further propose a
heuristic method to replace one of the two entities in each influential triple
to generate adversarial additions. Our experiments show that the proposed
strategies outperform the state-of-art data poisoning attacks on KGE models and
improve the MRR degradation due to the attacks by up to 62% over the baselines.

    

### [[2111.03122] Functional connectivity ensemble method to enhance BCI performance (FUCONE)](http://arxiv.org/abs/2111.03122)


  Functional connectivity is a key approach to investigate oscillatory
activities of the brain that provides important insights on the underlying
dynamic of neuronal interactions and that is mostly applied for brain activity
analysis. Building on the advances in information geometry for brain-computer
interface, we propose a novel framework that combines functional connectivity
estimators and covariance-based pipelines to classify mental states, such as
motor imagery. A Riemannian classifier is trained for each estimator and an
ensemble classifier combines the decisions in each feature space. A thorough
assessment of the functional connectivity estimators is provided and the best
performing pipeline, called FUCONE, is evaluated on different conditions and
datasets. Using a meta-analysis to aggregate results across datasets, FUCONE
performed significantly better than all state-of-the-art methods. The
performance gain is mostly imputable to the improved diversity of the feature
spaces, increasing the robustness of the ensemble classifier with respect to
the inter- and intra-subject variability.

    

### [[2111.03125] Secure Machine Learning in the Cloud Using One Way Scrambling by Deconvolution](http://arxiv.org/abs/2111.03125)


  Cloud-based machine learning services (CMLS) enable organizations to take
advantage of advanced models that are pre-trained on large quantities of data.
The main shortcoming of using these services, however, is the difficulty of
keeping the transmitted data private and secure. Asymmetric encryption requires
the data to be decrypted in the cloud, while Homomorphic encryption is often
too slow and difficult to implement. We propose One Way Scrambling by
Deconvolution (OWSD), a deconvolution-based scrambling framework that offers
the advantages of Homomorphic encryption at a fraction of the computational
overhead. Extensive evaluation on multiple image datasets demonstrates OWSD's
ability to achieve near-perfect classification performance when the output
vector of the CMLS is sufficiently large. Additionally, we provide empirical
analysis of the robustness of our approach.

    

### [[2111.03126] Generative Adversarial Network for Probabilistic Forecast of Random Dynamical System](http://arxiv.org/abs/2111.03126)


  We present a deep learning model for data-driven simulations of random
dynamical systems without a distributional assumption. The deep learning model
consists of a recurrent neural network, which aims to learn the time marching
structure, and a generative adversarial network to learn and sample from the
probability distribution of the random dynamical system. Although generative
adversarial networks provide a powerful tool to model a complex probability
distribution, the training often fails without a proper regularization. Here,
we propose a regularization strategy for a generative adversarial network based
on consistency conditions for the sequential inference problems. First, the
maximum mean discrepancy (MMD) is used to enforce the consistency between
conditional and marginal distributions of a stochastic process. Then, the
marginal distributions of the multiple-step predictions are regularized by
using MMD or from multiple discriminators. The behavior of the proposed model
is studied by using three stochastic processes with complex noise structures.

    

### [[2111.03135] Scaffolding Sets](http://arxiv.org/abs/2111.03135)


  Predictors map individual instances in a population to the interval $[0,1]$.
For a collection $\mathcal C$ of subsets of a population, a predictor is
multi-calibrated with respect to $\mathcal C$ if it is simultaneously
calibrated on each set in $\mathcal C$. We initiate the study of the
construction of scaffolding sets, a small collection $\mathcal S$ of sets with
the property that multi-calibration with respect to $\mathcal S$ ensures
correctness, and not just calibration, of the predictor. Our approach is
inspired by the folk wisdom that the intermediate layers of a neural net learn
a highly structured and useful data representation.

    

### [[2111.03137] Big-Step-Little-Step: Efficient Gradient Methods for Objectives with Multiple Scales](http://arxiv.org/abs/2111.03137)


  We provide new gradient-based methods for efficiently solving a broad class
of ill-conditioned optimization problems. We consider the problem of minimizing
a function $f : \mathbb{R}^d \rightarrow \mathbb{R}$ which is implicitly
decomposable as the sum of $m$ unknown non-interacting smooth, strongly convex
functions and provide a method which solves this problem with a number of
gradient evaluations that scales (up to logarithmic factors) as the product of
the square-root of the condition numbers of the components. This complexity
bound (which we prove is nearly optimal) can improve almost exponentially on
that of accelerated gradient methods, which grow as the square root of the
condition number of $f$. Additionally, we provide efficient methods for solving
stochastic, quadratic variants of this multiscale optimization problem. Rather
than learn the decomposition of $f$ (which would be prohibitively expensive),
our methods apply a clean recursive "Big-Step-Little-Step" interleaving of
standard methods. The resulting algorithms use $\tilde{\mathcal{O}}(d m)$
space, are numerically stable, and open the door to a more fine-grained
understanding of the complexity of convex optimization beyond condition number.

    

### [[2111.03140] Multi-Objective Constrained Optimization for Energy Applications via Tree Ensembles](http://arxiv.org/abs/2111.03140)


  Energy systems optimization problems are complex due to strongly non-linear
system behavior and multiple competing objectives, e.g. economic gain vs.
environmental impact. Moreover, a large number of input variables and different
variable types, e.g. continuous and categorical, are challenges commonly
present in real-world applications. In some cases, proposed optimal solutions
need to obey explicit input constraints related to physical properties or
safety-critical operating conditions. This paper proposes a novel data-driven
strategy using tree ensembles for constrained multi-objective optimization of
black-box problems with heterogeneous variable spaces for which underlying
system dynamics are either too complex to model or unknown. In an extensive
case study comprised of synthetic benchmarks and relevant energy applications
we demonstrate the competitive performance and sampling efficiency of the
proposed algorithm compared to other state-of-the-art tools, making it a useful
all-in-one solution for real-world applications with limited evaluation
budgets.

    

### [[2111.03144] Amortized Variational Inference for Simple Hierarchical Models](http://arxiv.org/abs/2111.03144)


  It is difficult to use subsampling with variational inference in hierarchical
models since the number of local latent variables scales with the dataset.
Thus, inference in hierarchical models remains a challenge at large scale. It
is helpful to use a variational family with structure matching the posterior,
but optimization is still slow due to the huge number of local distributions.
Instead, this paper suggests an amortized approach where shared parameters
simultaneously represent all local distributions. This approach is similarly
accurate as using a given joint distribution (e.g., a full-rank Gaussian) but
is feasible on datasets that are several orders of magnitude larger. It is also
dramatically faster than using a structured variational distribution.

    

### [[2111.03146] Generating Diverse Realistic Laughter for Interactive Art](http://arxiv.org/abs/2111.03146)


  We propose an interactive art project to make those rendered invisible by the
COVID-19 crisis and its concomitant solitude reappear through the welcome
melody of laughter, and connections created and explored through advanced
laughter synthesis approaches. However, the unconditional generation of the
diversity of human emotional responses in high-quality auditory synthesis
remains an open problem, with important implications for the application of
these approaches in artistic settings. We developed LaughGANter, an approach to
reproduce the diversity of human laughter using generative adversarial networks
(GANs). When trained on a dataset of diverse laughter samples, LaughGANter
generates diverse, high quality laughter samples, and learns a latent space
suitable for emotional analysis and novel artistic applications such as latent
mixing/interpolation and emotional transfer.

    

### [[2111.03153] Are You Smarter Than a Random Expert? The Robust Aggregation of Substitutable Signals](http://arxiv.org/abs/2111.03153)


  The problem of aggregating expert forecasts is ubiquitous in fields as
wide-ranging as machine learning, economics, climate science, and national
security. Despite this, our theoretical understanding of this question is
fairly shallow. This paper initiates the study of forecast aggregation in a
context where experts' knowledge is chosen adversarially from a broad class of
information structures. While in full generality it is impossible to achieve a
nontrivial performance guarantee, we show that doing so is possible under a
condition on the experts' information structure that we call \emph{projective
substitutes}. The projective substitutes condition is a notion of informational
substitutes: that there are diminishing marginal returns to learning the
experts' signals. We show that under the projective substitutes condition,
taking the average of the experts' forecasts improves substantially upon the
strategy of trusting a random expert. We then consider a more permissive
setting, in which the aggregator has access to the prior. We show that by
averaging the experts' forecasts and then \emph{extremizing} the average by
moving it away from the prior by a constant factor, the aggregator's
performance guarantee is substantially better than is possible without
knowledge of the prior. Our results give a theoretical grounding to past
empirical research on extremization and help give guidance on the appropriate
amount to extremize.

    

### [[2111.03160] Predictive Machine Learning of Objective Boundaries for Solving COPs](http://arxiv.org/abs/2111.03160)


  Solving Constraint Optimization Problems (COPs) can be dramatically
simplified by boundary estimation, that is, providing tight boundaries of cost
functions. By feeding a supervised Machine Learning (ML) model with data
composed of known boundaries and extracted features of COPs, it is possible to
train the model to estimate boundaries of a new COP instance. In this paper, we
first give an overview of the existing body of knowledge on ML for Constraint
Programming (CP) which learns from problem instances. Second, we introduce a
boundary estimation framework that is applied as a tool to support a CP solver.
Within this framework, different ML models are discussed and evaluated
regarding their suitability for boundary estimation, and countermeasures to
avoid unfeasible estimations that avoid the solver to find an optimal solution
are shown. Third, we present an experimental study with distinct CP solvers on
seven COPs. Our results show that near-optimal boundaries can be learned for
these COPs with only little overhead. These estimated boundaries reduce the
objective domain size by 60-88% and can help the solver to find near-optimal
solutions early during search.

    

### [[2111.03162] GraN-GAN: Piecewise Gradient Normalization for Generative Adversarial Networks](http://arxiv.org/abs/2111.03162)


  Modern generative adversarial networks (GANs) predominantly use piecewise
linear activation functions in discriminators (or critics), including ReLU and
LeakyReLU. Such models learn piecewise linear mappings, where each piece
handles a subset of the input space, and the gradients per subset are piecewise
constant. Under such a class of discriminator (or critic) functions, we present
Gradient Normalization (GraN), a novel input-dependent normalization method,
which guarantees a piecewise K-Lipschitz constraint in the input space. In
contrast to spectral normalization, GraN does not constrain processing at the
individual network layers, and, unlike gradient penalties, strictly enforces a
piecewise Lipschitz constraint almost everywhere. Empirically, we demonstrate
improved image generation performance across multiple datasets (incl.
CIFAR-10/100, STL-10, LSUN bedrooms, and CelebA), GAN loss functions, and
metrics. Further, we analyze altering the often untuned Lipschitz constant K in
several standard GANs, not only attaining significant performance gains, but
also finding connections between K and training dynamics, particularly in
low-gradient loss plateaus, with the common Adam optimizer.

    

### [[2111.03165] Infinite Time Horizon Safety of Bayesian Neural Networks](http://arxiv.org/abs/2111.03165)


  Bayesian neural networks (BNNs) place distributions over the weights of a
neural network to model uncertainty in the data and the network's prediction.
We consider the problem of verifying safety when running a Bayesian neural
network policy in a feedback loop with infinite time horizon systems. Compared
to the existing sampling-based approaches, which are inapplicable to the
infinite time horizon setting, we train a separate deterministic neural network
that serves as an infinite time horizon safety certificate. In particular, we
show that the certificate network guarantees the safety of the system over a
subset of the BNN weight posterior's support. Our method first computes a safe
weight set and then alters the BNN's weight posterior to reject samples outside
this set. Moreover, we show how to extend our approach to a safe-exploration
reinforcement learning setting, in order to avoid unsafe trajectories during
the training of the policy. We evaluate our approach on a series of
reinforcement learning benchmarks, including non-Lyapunovian safety
specifications.

    

### [[2111.03168] ExClus: Explainable Clustering on Low-dimensional Data Representations](http://arxiv.org/abs/2111.03168)


  Dimensionality reduction and clustering techniques are frequently used to
analyze complex data sets, but their results are often not easy to interpret.
We consider how to support users in interpreting apparent cluster structure on
scatter plots where the axes are not directly interpretable, such as when the
data is projected onto a two-dimensional space using a dimensionality-reduction
method. Specifically, we propose a new method to compute an interpretable
clustering automatically, where the explanation is in the original
high-dimensional space and the clustering is coherent in the low-dimensional
projection. It provides a tunable balance between the complexity and the amount
of information provided, through the use of information theory. We study the
computational complexity of this problem and introduce restrictions on the
search space of solutions to arrive at an efficient, tunable, greedy
optimization algorithm. This algorithm is furthermore implemented in an
interactive tool called ExClus. Experiments on several data sets highlight that
ExClus can provide informative and easy-to-understand patterns, and they expose
where the algorithm is efficient and where there is room for improvement
considering tunability and scalability.

    

### [[2111.03169] Hard Negative Sampling via Regularized Optimal Transport for Contrastive Representation Learning](http://arxiv.org/abs/2111.03169)


  We study the problem of designing hard negative sampling distributions for
unsupervised contrastive representation learning. We analyze a novel min-max
framework that seeks a representation which minimizes the maximum (worst-case)
generalized contrastive learning loss over all couplings (joint distributions
between positive and negative samples subject to marginal constraints) and
prove that the resulting min-max optimum representation will be degenerate.
This provides the first theoretical justification for incorporating additional
regularization constraints on the couplings. We re-interpret the min-max
problem through the lens of Optimal Transport theory and utilize regularized
transport couplings to control the degree of hardness of negative examples. We
demonstrate that the state-of-the-art hard negative sampling distributions that
were recently proposed are a special case corresponding to entropic
regularization of the coupling.

    

### [[2111.03175] Rate of Convergence of Polynomial Networks to Gaussian Processes](http://arxiv.org/abs/2111.03175)


  We examine one-hidden-layer neural networks with random weights. It is
well-known that in the limit of infinitely many neurons they simplify to
Gaussian processes. For networks with a polynomial activation, we demonstrate
that the rate of this convergence in 2-Wasserstein metric is
$O(n^{-\frac{1}{2}})$, where $n$ is the number of hidden neurons. We suspect
this rate is asymptotically sharp. We improve the known convergence rate for
other activations, to power-law in $n$ for ReLU and inverse-square-root up to
logarithmic factors for erf. We explore the interplay between spherical
harmonics, Stein kernels and optimal transport in the non-isotropic setting.

    

### [[2111.03179] Community detection in censored hypergraph](http://arxiv.org/abs/2111.03179)


  Community detection refers to the problem of clustering the nodes of a
network (either graph or hypergrah) into groups. Various algorithms are
available for community detection and all these methods apply to uncensored
networks. In practice, a network may has censored (or missing) values and it is
shown that censored values have non-negligible effect on the structural
properties of a network. In this paper, we study community detection in
censored $m$-uniform hypergraph from information-theoretic point of view. We
derive the information-theoretic threshold for exact recovery of the community
structure. Besides, we propose a polynomial-time algorithm to exactly recover
the community structure up to the threshold. The proposed algorithm consists of
a spectral algorithm plus a refinement step. It is also interesting to study
whether a single spectral algorithm without refinement achieves the threshold.
To this end, we also explore the semi-definite relaxation algorithm and analyze
its performance.

    

### [[2111.03184] LW-GCN: A Lightweight FPGA-based Graph Convolutional Network Accelerator](http://arxiv.org/abs/2111.03184)


  Graph convolutional networks (GCNs) have been introduced to effectively
process non-euclidean graph data. However, GCNs incur large amounts of
irregularity in computation and memory access, which prevents efficient use of
traditional neural network accelerators. Moreover, existing dedicated GCN
accelerators demand high memory volumes and are difficult to implement onto
resource limited edge devices. In this work, we propose LW-GCN, a lightweight
FPGA-based accelerator with a software-hardware co-designed process to tackle
irregularity in computation and memory access in GCN inference. LW-GCN
decomposes the main GCN operations into sparse-dense matrix multiplication
(SDMM) and dense matrix multiplication (DMM). We propose a novel compression
format to balance workload across PEs and prevent data hazards. Moreover, we
apply data quantization and workload tiling, and map both SDMM and DMM of GCN
inference onto a uniform architecture on resource limited hardware. Evaluation
on GCN and GraphSAGE are performed on Xilinx Kintex-7 FPGA with three popular
datasets. Compared to existing CPU, GPU, and state-of-the-art FPGA-based
accelerator, LW-GCN reduces latency by up to 60x, 12x and 1.7x and increases
power efficiency by up to 912x., 511x and 3.87x, respectively. Furthermore,
compared with NVIDIA's latest edge GPU Jetson Xavier NX, LW-GCN achieves
speedup and energy savings of 32x and 84x, respectively.

    

### [[2111.03187] MIRACLE: Causally-Aware Imputation via Learning Missing Data Mechanisms](http://arxiv.org/abs/2111.03187)


  Missing data is an important problem in machine learning practice. Starting
from the premise that imputation methods should preserve the causal structure
of the data, we develop a regularization scheme that encourages any baseline
imputation method to be causally consistent with the underlying data generating
mechanism. Our proposal is a causally-aware imputation algorithm (MIRACLE).
MIRACLE iteratively refines the imputation of a baseline by simultaneously
modeling the missingness generating mechanism, encouraging imputation to be
consistent with the causal structure of the data. We conduct extensive
experiments on synthetic and a variety of publicly available datasets to show
that MIRACLE is able to consistently improve imputation over a variety of
benchmark methods across all three missingness scenarios: at random, completely
at random, and not at random.

    

### [[2111.03189] Value Function Spaces: Skill-Centric State Abstractions for Long-Horizon Reasoning](http://arxiv.org/abs/2111.03189)


  Reinforcement learning can train policies that effectively perform complex
tasks. However for long-horizon tasks, the performance of these methods
degrades with horizon, often necessitating reasoning over and composing
lower-level skills. Hierarchical reinforcement learning aims to enable this by
providing a bank of low-level skills as action abstractions. Hierarchies can
further improve on this by abstracting the space states as well. We posit that
a suitable state abstraction should depend on the capabilities of the available
lower-level policies. We propose Value Function Spaces: a simple approach that
produces such a representation by using the value functions corresponding to
each lower-level skill. These value functions capture the affordances of the
scene, thus forming a representation that compactly abstracts task relevant
information and robustly ignores distractors. Empirical evaluations for
maze-solving and robotic manipulation tasks demonstrate that our approach
improves long-horizon performance and enables better zero-shot generalization
than alternative model-free and model-based methods.

    

### [[2111.03193] Explainable k-means. Don't be greedy, plant bigger trees!](http://arxiv.org/abs/2111.03193)


  We provide a new bi-criteria $\tilde{O}(\log^2 k)$ competitive algorithm for
explainable $k$-means clustering. Explainable $k$-means was recently introduced
by Dasgupta, Frost, Moshkovitz, and Rashtchian (ICML 2020). It is described by
an easy to interpret and understand (threshold) decision tree or diagram. The
cost of the explainable $k$-means clustering equals to the sum of costs of its
clusters; and the cost of each cluster equals the sum of squared distances from
the points in the cluster to the center of that cluster. Our randomized
bi-criteria algorithm constructs a threshold decision tree that partitions the
data set into $(1+\delta)k$ clusters (where $\delta\in (0,1)$ is a parameter of
the algorithm). The cost of this clustering is at most $\tilde{O}(1/\delta
\cdot \log^2 k)$ times the cost of the optimal unconstrained $k$-means
clustering. We show that this bound is almost optimal.

    

### [[2111.03196] An Empirical Study of the Effectiveness of an Ensemble of Stand-alone Sentiment Detection Tools for Software Engineering Datasets](http://arxiv.org/abs/2111.03196)


  Sentiment analysis in software engineering (SE) has shown promise to analyze
and support diverse development activities. We report the results of an
empirical study that we conducted to determine the feasibility of developing an
ensemble engine by combining the polarity labels of stand-alone SE-specific
sentiment detectors. Our study has two phases. In the first phase, we pick five
SE-specific sentiment detection tools from two recently published papers by Lin
et al. [31, 32], who first reported negative results with standalone sentiment
detectors and then proposed an improved SE-specific sentiment detector, POME
[31]. We report the study results on 17,581 units (sentences/documents) coming
from six currently available sentiment benchmarks for SE. We find that the
existing tools can be complementary to each other in 85-95% of the cases, i.e.,
one is wrong, but another is right. However, a majority voting-based ensemble
of those tools fails to improve the accuracy of sentiment detection. We develop
Sentisead, a supervised tool by combining the polarity labels and bag of words
as features. Sentisead improves the performance (F1-score) of the individual
tools by 4% (over Senti4SD [5]) - 100% (over POME [31]). In a second phase, we
compare and improve Sentisead infrastructure using Pre-trained Transformer
Models (PTMs). We find that a Sentisead infrastructure with RoBERTa as the
ensemble of the five stand-alone rule-based and shallow learning SE-specific
tools from Lin et al. [31, 32] offers the best F1-score of 0.805 across the six
datasets, while a stand-alone RoBERTa shows an F1-score of 0.801.

    

### [[2111.03198] On the Complexity of Dynamic Submodular Maximization](http://arxiv.org/abs/2111.03198)


  We study dynamic algorithms for the problem of maximizing a monotone
submodular function over a stream of $n$ insertions and deletions. We show that
any algorithm that maintains a $(0.5+\epsilon)$-approximate solution under a
cardinality constraint, for any constant $\epsilon>0$, must have an amortized
query complexity that is $\mathit{polynomial}$ in $n$. Moreover, a linear
amortized query complexity is needed in order to maintain a $0.584$-approximate
solution. This is in sharp contrast with recent dynamic algorithms of [LMNF+20,
Mon20] that achieve $(0.5-\epsilon)$-approximation with a
$\mathsf{poly}\log(n)$ amortized query complexity.
On the positive side, when the stream is insertion-only, we present efficient
algorithms for the problem under a cardinality constraint and under a matroid
constraint with approximation guarantee $1-1/e-\epsilon$ and amortized query
complexities $\smash{O(\log (k/\epsilon)/\epsilon^2)}$ and
$\smash{k^{\tilde{O}(1/\epsilon^2)}\log n}$, respectively, where $k$ denotes
the cardinality parameter or the rank of the matroid.

    

### [[2111.03201] Compressing Sensor Data for Remote Assistance of Autonomous Vehicles using Deep Generative Models](http://arxiv.org/abs/2111.03201)


  In the foreseeable future, autonomous vehicles will require human assistance
in situations they can not resolve on their own. In such scenarios, remote
assistance from a human can provide the required input for the vehicle to
continue its operation. Typical sensors used in autonomous vehicles include
camera and lidar sensors. Due to the massive volume of sensor data that must be
sent in real-time, highly efficient data compression is elementary to prevent
an overload of network infrastructure. Sensor data compression using deep
generative neural networks has been shown to outperform traditional compression
approaches for both image and lidar data, regarding compression rate as well as
reconstruction quality. However, there is a lack of research about the
performance of generative-neural-network-based compression algorithms for
remote assistance. In order to gain insights into the feasibility of deep
generative models for usage in remote assistance, we evaluate state-of-the-art
algorithms regarding their applicability and identify potential weaknesses.
Further, we implement an online pipeline for processing sensor data and
demonstrate its performance for remote assistance using the CARLA simulator.

    

### [[2111.03205] LILA: Language-Informed Latent Actions](http://arxiv.org/abs/2111.03205)


  We introduce Language-Informed Latent Actions (LILA), a framework for
learning natural language interfaces in the context of human-robot
collaboration. LILA falls under the shared autonomy paradigm: in addition to
providing discrete language inputs, humans are given a low-dimensional
controller $-$ e.g., a 2 degree-of-freedom (DoF) joystick that can move
left/right and up/down $-$ for operating the robot. LILA learns to use language
to modulate this controller, providing users with a language-informed control
space: given an instruction like "place the cereal bowl on the tray," LILA may
learn a 2-DoF space where one dimension controls the distance from the robot's
end-effector to the bowl, and the other dimension controls the robot's
end-effector pose relative to the grasp point on the bowl. We evaluate LILA
with real-world user studies, where users can provide a language instruction
while operating a 7-DoF Franka Emika Panda Arm to complete a series of complex
manipulation tasks. We show that LILA models are not only more sample efficient
and performant than imitation learning and end-effector control baselines, but
that they are also qualitatively preferred by users.

    

### [[2111.03207] Artificial Neural Network-Based Voltage Control of DC/DC Converter for DC Microgrid Applications](http://arxiv.org/abs/2111.03207)


  The rapid growth of renewable energy technology enables the concept of
microgrid (MG) to be widely accepted in the power systems. Due to the
advantages of the DC distribution system such as easy integration of energy
storage and less system loss, DC MG attracts significant attention nowadays.
The linear controller such as PI or PID is matured and extensively used by the
power electronics industry, but their performance is not optimal as system
parameters are changed. In this study, an artificial neural network (ANN) based
voltage control strategy is proposed for the DC-DC boost converter. In this
paper, the model predictive control (MPC) is used as an expert, which provides
the data to train the proposed ANN. As ANN is tuned finely, then it is utilized
directly to control the step-up DC converter. The main advantage of the ANN is
that the neural network system identification decreases the inaccuracy of the
system model even with inaccurate parameters and has less computational burden
compared to MPC due to its parallel structure. To validate the performance of
the proposed ANN, extensive MATLAB/Simulink simulations are carried out. The
simulation results show that the ANN-based control strategy has better
performance under different loading conditions comparison to the PI controller.
The accuracy of the trained ANN model is about 97%, which makes it suitable to
be used for DC microgrid applications.

    

### [[2111.03212] An overview of event extraction and its applications](http://arxiv.org/abs/2111.03212)


  With the rapid development of information technology, online platforms have
produced enormous text resources. As a particular form of Information
Extraction (IE), Event Extraction (EE) has gained increasing popularity due to
its ability to automatically extract events from human language. However, there
are limited literature surveys on event extraction. Existing review works
either spend much effort describing the details of various approaches or focus
on a particular field. This study provides a comprehensive overview of the
state-of-the-art event extraction methods and their applications from text,
including closed-domain and open-domain event extraction. A trait of this
survey is that it provides an overview in moderate complexity, avoiding
involving too many details of particular approaches. This study focuses on
discussing the common characters, application fields, advantages, and
disadvantages of representative works, ignoring the specificities of individual
approaches. Finally, we summarize the common issues, current solutions, and
future research directions. We hope this work could help researchers and
practitioners obtain a quick overview of recent event extraction.

    

### [[2111.03220] Augmentations in Graph Contrastive Learning: Current Methodological Flaws & Towards Better Practices](http://arxiv.org/abs/2111.03220)


  Graph classification has applications in bioinformatics, social sciences,
automated fake news detection, web document classification, and more. In many
practical scenarios, including web-scale applications, where labels are scarce
or hard to obtain, unsupervised learning is a natural paradigm but it trades
off performance. Recently, contrastive learning (CL) has enabled unsupervised
computer vision models to compete well against supervised ones. Theoretical and
empirical works analyzing visual CL frameworks find that leveraging large
datasets and domain aware augmentations is essential for framework success.
Interestingly, graph CL frameworks often report high performance while using
orders of magnitude smaller data, and employing domain-agnostic augmentations
(e.g., node or edge dropping, feature perturbations) that can corrupt the
graphs' underlying properties.
Motivated by these discrepancies, we seek to determine: (i) why existing
graph CL frameworks perform well despite weak augmentations and limited data;
and (ii) whether adhering to visual CL principles can improve performance on
graph classification tasks. Through extensive analysis, we identify flawed
practices in graph data augmentation and evaluation protocols that are commonly
used in the graph CL literature, and propose improved practices and sanity
checks for future research and applications. We show that on small benchmark
datasets, the inductive bias of graph neural networks can significantly
compensate for the limitations of existing frameworks. In case studies with
relatively larger graph classification tasks, we find that commonly used
domain-agnostic augmentations perform poorly, while adhering to principles in
visual CL can significantly improve performance. For example, in graph-based
document classification, which can be used for better web search, we show
task-relevant augmentations improve accuracy by 20%.

    

### [[2111.03237] Analysis of Sensing Spectral for Signal Recovery Under a Generalized Linear Model](http://arxiv.org/abs/2111.03237)


  We consider a nonlinear inverse problem $\mathbf{y}= f(\mathbf{Ax})$, where
observations $\mathbf{y} \in \mathbb{R}^m$ are the componentwise nonlinear
transformation of $\mathbf{Ax} \in \mathbb{R}^m$, $\mathbf{x} \in \mathbb{R}^n$
is the signal of interest and $\mathbf{A}$ is a known linear mapping. By
properly specifying the nonlinear processing function, this model can be
particularized to many signal processing problems, including compressed sensing
and phase retrieval.
Our main goal in this paper is to understand the impact of sensing matrices,
or more specifically the spectrum of sensing matrices, on the difficulty of
recovering $\mathbf{x}$ from $\mathbf{y}$. Towards this goal, we study the
performance of one of the most successful recovery methods, i.e. the
expectation propagation algorithm (EP). We define a notion for the spikiness of
the spectrum of $\mathbf{A}$ and show the importance of this measure in the
performance of the EP. Whether the spikiness of the spectrum can hurt or help
the recovery performance of EP depends on $f$. We define certain quantities
based on the function $f$ that enables us to describe the impact of the
spikiness of the spectrum on EP recovery. Based on our framework, we are able
to show that for instance, in phase-retrieval problems, matrices with spikier
spectrums are better for EP, while in 1-bit compressed sensing problems, less
spiky (flatter) spectrums offer better recoveries. Our results unify and
substantially generalize the existing results that compare sub-Gaussian and
orthogonal matrices, and provide a platform toward designing optimal sensing
systems.

    

### [[2111.03250] Context-Aware Transformer Transducer for Speech Recognition](http://arxiv.org/abs/2111.03250)


  End-to-end (E2E) automatic speech recognition (ASR) systems often have
difficulty recognizing uncommon words, that appear infrequently in the training
data. One promising method, to improve the recognition accuracy on such rare
words, is to latch onto personalized/contextual information at inference. In
this work, we present a novel context-aware transformer transducer (CATT)
network that improves the state-of-the-art transformer-based ASR system by
taking advantage of such contextual signals. Specifically, we propose a
multi-head attention-based context-biasing network, which is jointly trained
with the rest of the ASR sub-networks. We explore different techniques to
encode contextual data and to create the final attention context vectors. We
also leverage both BLSTM and pretrained BERT based models to encode contextual
data and guide the network training. Using an in-house far-field dataset, we
show that CATT, using a BERT based context encoder, improves the word error
rate of the baseline transformer transducer and outperforms an existing deep
contextual model by 24.2% and 19.4% respectively.

    

### [[2111.03253] Dynamic Data Augmentation with Gating Networks](http://arxiv.org/abs/2111.03253)


  Data augmentation is a technique to improve the generalization ability of
machine learning methods by increasing the size of the dataset. However, since
every augmentation method is not equally effective for every dataset, you need
to carefully select the best method. We propose a neural network that
dynamically selects the best combination using a mutually beneficial gating
network and a feature consistency loss. The gating network is able to control
how much of each data augmentation is used for the representation within the
network. The feature consistency loss, on the other hand, gives a constraint
that augmented features from the same input should be in similar. In
experiments, we demonstrate the effectiveness of the proposed method on the 12
largest time-series datasets from 2018 UCR Time Series Archive and reveal the
relationships between the data augmentation methods through analysis of the
proposed method.

    

### [[2111.03260] Remote Sensing Image Super-resolution and Object Detection: Benchmark and State of the Art](http://arxiv.org/abs/2111.03260)


  For the past two decades, there have been significant efforts to develop
methods for object detection in Remote Sensing (RS) images. In most cases, the
datasets for small object detection in remote sensing images are inadequate.
Many researchers used scene classification datasets for object detection, which
has its limitations; for example, the large-sized objects outnumber the small
objects in object categories. Thus, they lack diversity; this further affects
the detection performance of small object detectors in RS images. This paper
reviews current datasets and object detection methods (deep learning-based) for
remote sensing images. We also propose a large-scale, publicly available
benchmark Remote Sensing Super-resolution Object Detection (RSSOD) dataset. The
RSSOD dataset consists of 1,759 hand-annotated images with 22,091 instances of
very high resolution (VHR) images with a spatial resolution of ~0.05 m. There
are five classes with varying frequencies of labels per class. The image
patches are extracted from satellite images, including real image distortions
such as tangential scale distortion and skew distortion. We also propose a
novel Multi-class Cyclic super-resolution Generative adversarial network with
Residual feature aggregation (MCGR) and auxiliary YOLOv5 detector to benchmark
image super-resolution-based object detection and compare with the existing
state-of-the-art methods based on image super-resolution (SR). The proposed
MCGR achieved state-of-the-art performance for image SR with an improvement of
1.2dB PSNR compared to the current state-of-the-art NLSN method. MCGR achieved
best object detection mAPs of 0.758, 0.881, 0.841, and 0.983, respectively, for
five-class, four-class, two-class, and single classes, respectively surpassing
the performance of the state-of-the-art object detectors YOLOv5, EfficientDet,
Faster RCNN, SSD, and RetinaNet.

    

### [[2111.03262] Collaborative Graph Contrastive Learning: Data Augmentation Composition May Not be Necessary for Graph Representation Learning](http://arxiv.org/abs/2111.03262)


  Unsupervised graph representation learning is a non-trivial topic for graph
data. The success of contrastive learning and self-supervised learning in the
unsupervised representation learning of structured data inspires similar
attempts on the graph. The current unsupervised graph representation learning
and pre-training using the contrastive loss are mainly based on the contrast
between handcrafted augmented graph data. However, the graph data augmentation
is still not well-explored due to the unpredictable invariance. In this paper,
we propose a novel collaborative graph neural networks contrastive learning
framework (CGCL), which uses multiple graph encoders to observe the graph.
Features observed from different views act as the graph augmentation for
contrastive learning between graph encoders, avoiding any perturbation to
guarantee the invariance. CGCL is capable of handling both graph-level and
node-level representation learning. Extensive experiments demonstrate the
advantages of CGCL in unsupervised graph representation learning and the
non-necessity of handcrafted data augmentation composition for graph
representation learning.

    

### [[2111.03264] Graph Denoising with Framelet Regularizer](http://arxiv.org/abs/2111.03264)


  As graph data collected from the real world is merely noise-free, a practical
representation of graphs should be robust to noise. Existing research usually
focuses on feature smoothing but leaves the geometric structure untouched.
Furthermore, most work takes L2-norm that pursues a global smoothness, which
limits the expressivity of graph neural networks. This paper tailors
regularizers for graph data in terms of both feature and structure noises,
where the objective function is efficiently solved with the alternating
direction method of multipliers (ADMM). The proposed scheme allows to take
multiple layers without the concern of over-smoothing, and it guarantees
convergence to the optimal solutions. Empirical study proves that our model
achieves significantly better performance compared with popular graph
convolutions even when the graph is heavily contaminated.

    

### [[2111.03265] EpilNet: A Novel Approach to IoT based Epileptic Seizure Prediction and Diagnosis System using Artificial Intelligence](http://arxiv.org/abs/2111.03265)


  Epilepsy is one of the most occurring neurological diseases. The main
characteristic of this disease is a frequent seizure, which is an electrical
imbalance in the brain. It is generally accompanied by shaking of body parts
and even leads (fainting). In the past few years, many treatments have come up.
These mainly involve the use of anti-seizure drugs for controlling seizures.
But in 70% of cases, these drugs are not effective, and surgery is the only
solution when the condition worsens. So patients need to take care of
themselves while having a seizure and be safe. Wearable electroencephalogram
(EEG) devices have come up with the development in medical science and
technology. These devices help in the analysis of brain electrical activities.
EEG helps in locating the affected cortical region. The most important is that
it can predict any seizure in advance on-site. This has resulted in a sudden
increase in demand for effective and efficient seizure prediction and diagnosis
systems. A novel approach to epileptic seizure prediction and diagnosis system
EpilNet is proposed in the present paper. It is a one-dimensional (1D)
convolution neural network. EpilNet gives the testing accuracy of 79.13% for
five classes, leading to a significant increase of about 6-7% compared to
related works. The developed Web API helps in bringing EpilNet into practical
use. Thus, it is an integrated system for both patients and doctors. The system
will help patients prevent injury or accidents and increase the efficiency of
the treatment process by doctors in the hospitals.

    

### [[2111.03267] Distilling Heterogeneity: From Explanations of Heterogeneous Treatment Effect Models to Interpretable Policies](http://arxiv.org/abs/2111.03267)


  Internet companies are increasingly using machine learning models to create
personalized policies which assign, for each individual, the best predicted
treatment for that individual. They are frequently derived from black-box
heterogeneous treatment effect (HTE) models that predict individual-level
treatment effects. In this paper, we focus on (1) learning explanations for HTE
models; (2) learning interpretable policies that prescribe treatment
assignments. We also propose guidance trees, an approach to ensemble multiple
interpretable policies without the loss of interpretability. These rule-based
interpretable policies are easy to deploy and avoid the need to maintain a HTE
model in a production environment.

    

### [[2111.03268] Neural Network Based Epileptic EEG Detection and Classification](http://arxiv.org/abs/2111.03268)


  Timely diagnosis is important for saving the life of epileptic patients. In
past few years, a lot of treatments are available for epilepsy. These
treatments require use of anti-seizure drugs but are not effective in
controlling frequency of seizure. There is need of removal of an affected
region using surgery. Electroencephalogram (EEG) is a widely used technique for
monitoring the brain activity and widely popular for seizure region detection.
It is used before surgery for locating affected region. This manual process,
using EEG graphs, is time consuming and requires deep expertise. In the present
paper, a model has been proposed that preserves the true nature of an EEG
signal in form of textual one-dimensional vector. The proposed model achieves a
state of art performance for Bonn University dataset giving an average
sensitivity, specificity of 81% and 81.4% respectively for classification of
EEG data among all five classes. Also for binary classification achieving
99.9%, 99.5% score value for specificity and sensitivity instead of 2D models
used by other researchers. Thus, developed system will significantly help
neurosurgeons in the increase of their performance.

    

### [[2111.03270] Automated Human Mind Reading Using EEG Signals for Seizure Detection](http://arxiv.org/abs/2111.03270)


  Epilepsy is one of the most occurring neurological disease globally emerged
back in 4000 BC. It is affecting around 50 million people of all ages these
days. The trait of this disease is recurrent seizures. In the past few decades,
the treatments available for seizure control have improved a lot with the
advancements in the field of medical science and technology.
Electroencephalogram (EEG) is a widely used technique for monitoring the brain
activity and widely popular for seizure region detection. It is performed
before surgery and also to predict seizure at the time operation which is
useful in neuro stimulation device. But in most of cases visual examination is
done by neurologist in order to detect and classify patterns of the disease but
this requires a lot of pre-domain knowledge and experience. This all in turns
put a pressure on neurosurgeons and leads to time wastage and also reduce their
accuracy and efficiency. There is a need of some automated systems in arena of
information technology like use of neural networks in deep learning which can
assist neurologists. In the present paper, a model is proposed to give an
accuracy of 98.33% which can be used for development of automated systems. The
developed system will significantly help neurologists in their performance.

    

### [[2111.03274] Pathological Analysis of Blood Cells Using Deep Learning Techniques](http://arxiv.org/abs/2111.03274)


  Pathology deals with the practice of discovering the reasons for disease by
analyzing the body samples. The most used way in this field, is to use
histology which is basically studying and viewing microscopic structures of
cell and tissues. The slide viewing method is widely being used and converted
into digital form to produce high resolution images. This enabled the area of
deep learning and machine learning to deep dive into this field of medical
sciences. In the present study, a neural based network has been proposed for
classification of blood cells images into various categories. When input image
is passed through the proposed architecture and all the hyper parameters and
dropout ratio values are used in accordance with proposed algorithm, then model
classifies the blood images with an accuracy of 95.24%. The performance of
proposed model is better than existing standard architectures and work done by
various researchers. Thus model will enable development of pathological system
which will reduce human errors and daily load on laboratory men. This will in
turn help pathologists in carrying out their work more efficiently and
effectively.

    

### [[2111.03282] Recurrent Neural Networks for Learning Long-term Temporal Dependencies with Reanalysis of Time Scale Representation](http://arxiv.org/abs/2111.03282)


  Recurrent neural networks with a gating mechanism such as an LSTM or GRU are
powerful tools to model sequential data. In the mechanism, a forget gate, which
was introduced to control information flow in a hidden state in the RNN, has
recently been re-interpreted as a representative of the time scale of the
state, i.e., a measure how long the RNN retains information on inputs. On the
basis of this interpretation, several parameter initialization methods to
exploit prior knowledge on temporal dependencies in data have been proposed to
improve learnability. However, the interpretation relies on various unrealistic
assumptions, such as that there are no inputs after a certain time point. In
this work, we reconsider this interpretation of the forget gate in a more
realistic setting. We first generalize the existing theory on gated RNNs so
that we can consider the case where inputs are successively given. We then
argue that the interpretation of a forget gate as a temporal representation is
valid when the gradient of loss with respect to the state decreases
exponentially as time goes back. We empirically demonstrate that existing RNNs
satisfy this gradient condition at the initial training phase on several tasks,
which is in good agreement with previous initialization methods. On the basis
of this finding, we propose an approach to construct new RNNs that can
represent a longer time scale than conventional models, which will improve the
learnability for long-term sequential data. We verify the effectiveness of our
method by experiments with real-world datasets.

    

### [[2111.03289] Improved Regret Analysis for Variance-Adaptive Linear Bandits and Horizon-Free Linear Mixture MDPs](http://arxiv.org/abs/2111.03289)


  In online learning problems, exploiting low variance plays an important role
in obtaining tight performance guarantees yet is challenging because variances
are often not known a priori. Recently, a considerable progress has been made
by Zhang et al. (2021) where they obtain a variance-adaptive regret bound for
linear bandits without knowledge of the variances and a horizon-free regret
bound for linear mixture Markov decision processes (MDPs). In this paper, we
present novel analyses that improve their regret bounds significantly. For
linear bandits, we achieve $\tilde O(d^{1.5}\sqrt{\sum_{k}^K \sigma_k^2} +
d^2)$ where $d$ is the dimension of the features, $K$ is the time horizon, and
$\sigma_k^2$ is the noise variance at time step $k$, and $\tilde O$ ignores
polylogarithmic dependence, which is a factor of $d^3$ improvement. For linear
mixture MDPs, we achieve a horizon-free regret bound of $\tilde
O(d^{1.5}\sqrt{K} + d^3)$ where $d$ is the number of base models and $K$ is the
number of episodes. This is a factor of $d^3$ improvement in the leading term
and $d^6$ in the lower order term. Our analysis critically relies on a novel
elliptical potential `count' lemma. This lemma allows a peeling-based regret
analysis, which can be of independent interest.

    

### [[2111.03290] Maillard Sampling: Boltzmann Exploration Done Optimally](http://arxiv.org/abs/2111.03290)


  The PhD thesis of Maillard (2013) presents a randomized algorithm for the
$K$-armed bandit problem. This less-known algorithm, which we call Maillard
sampling (MS), computes the probability of choosing each arm in a closed form,
which is useful for counterfactual evaluation from bandit-logged data but was
lacking from Thompson sampling, a widely-adopted bandit algorithm in the
industry. Motivated by such merit, we revisit MS and perform an improved
analysis to show that it achieves both the asymptotical optimality and
$\sqrt{KT\log{T}}$ minimax regret bound where $T$ is the time horizon, which
matches the standard asymptotically optimal UCB's performance. We then propose
a variant of MS called MS$^+$ that improves its minimax bound to
$\sqrt{KT\log{K}}$ without losing the asymptotic optimality. MS$^+$ can also be
tuned to be aggressive (i.e., less exploration) without losing theoretical
guarantees, a unique feature unavailable from existing bandit algorithms. Our
numerical evaluation shows the effectiveness of MS$^+$.

    

### [[2111.03299] Dataset of Fake News Detection and Fact Verification: A Survey](http://arxiv.org/abs/2111.03299)


  The rapid increase in fake news, which causes significant damage to society,
triggers many fake news related studies, including the development of fake news
detection and fact verification techniques. The resources for these studies are
mainly available as public datasets taken from Web data. We surveyed 118
datasets related to fake news research on a large scale from three
perspectives: (1) fake news detection, (2) fact verification, and (3) other
tasks; for example, the analysis of fake news and satire detection. We also
describe in detail their utilization tasks and their characteristics. Finally,
we highlight the challenges in the fake news dataset construction and some
research opportunities that address these challenges. Our survey facilitates
fake news research by helping researchers find suitable datasets without
reinventing the wheel, and thereby, improves fake news studies in depth.

    

### [[2111.03308] Confidential Machine Learning Computation in Untrusted Environments: A Systems Security Perspective](http://arxiv.org/abs/2111.03308)


  As machine learning (ML) technologies and applications are rapidly changing
many domains of computing, security issues associated with ML are also
emerging. In the domain of systems security, many endeavors have been made to
ensure ML model and data confidentiality. ML computations are often inevitably
performed in untrusted environments and entail complex multi-party security
requirements. Hence, researchers have leveraged the Trusted Execution
Environments (TEEs) to build confidential ML computation systems. This paper
conducts a systematic and comprehensive survey by classifying attack vectors
and mitigation in TEE-protected confidential ML computation in the untrusted
environment, analyzes the multi-party ML security requirements, and discusses
related engineering challenges.

    

### [[2111.03317] Learning on Random Balls is Sufficient for Estimating (Some) Graph Parameters](http://arxiv.org/abs/2111.03317)


  Theoretical analyses for graph learning methods often assume a complete
observation of the input graph. Such an assumption might not be useful for
handling any-size graphs due to the scalability issues in practice. In this
work, we develop a theoretical framework for graph classification problems in
the partial observation setting (i.e., subgraph samplings). Equipped with
insights from graph limit theory, we propose a new graph classification model
that works on a randomly sampled subgraph and a novel topology to characterize
the representability of the model. Our theoretical framework contributes a
theoretical validation of mini-batch learning on graphs and leads to new
learning-theoretic results on generalization bounds as well as
size-generalizability without assumptions on the input.

    

### [[2111.03340] FINN.no Slates Dataset: A new Sequential Dataset Logging Interactions, allViewed Items and Click Responses/No-Click for Recommender Systems Research](http://arxiv.org/abs/2111.03340)


  We present a novel recommender systems dataset that records the sequential
interactions between users and an online marketplace. The users are
sequentially presented with both recommendations and search results in the form
of ranked lists of items, called slates, from the marketplace. The dataset
includes the presented slates at each round, whether the user clicked on any of
these items and which item the user clicked on. Although the usage of exposure
data in recommender systems is growing, to our knowledge there is no open
large-scale recommender systems dataset that includes the slates of items
presented to the users at each interaction. As a result, most articles on
recommender systems do not utilize this exposure information. Instead, the
proposed models only depend on the user's click responses, and assume that the
user is exposed to all the items in the item universe at each step, often
called uniform candidate sampling. This is an incomplete assumption, as it
takes into account items the user might not have been exposed to. This way
items might be incorrectly considered as not of interest to the user. Taking
into account the actually shown slates allows the models to use a more natural
likelihood, based on the click probability given the exposure set of items, as
is prevalent in the bandit and reinforcement learning literature.
\cite{Eide2021DynamicSampling} shows that likelihoods based on uniform
candidate sampling (and similar assumptions) are implicitly assuming that the
platform only shows the most relevant items to the user. This causes the
recommender system to implicitly reinforce feedback loops and to be biased
towards previously exposed items to the user.

    

### [[2111.03341] DVFL: A Vertical Federated Learning Method for Dynamic Data](http://arxiv.org/abs/2111.03341)


  Federated learning, which solves the problem of data island by connecting
multiple computational devices into a decentralized system, has become a
promising paradigm for privacy-preserving machine learning. This paper studies
vertical federated learning (VFL), which tackles the scenarios where
collaborating organizations share the same set of users but disjoint features.
Contemporary VFL methods are mainly used in static scenarios where the active
party and the passive party have all the data from the beginning and will not
change. However, the data in real life often changes dynamically. To alleviate
this problem, we propose a new vertical federation learning method, DVFL, which
adapts to dynamic data distribution changes through knowledge distillation. In
DVFL, most of the computations are held locally to improve data security and
model efficiency. Our extensive experimental results show that DVFL can not
only obtain results close to existing VFL methods in static scenes, but also
adapt to changes in data distribution in dynamic scenarios.

    

### [[2111.03362] Fighting COVID-19 in the Dark: Methodology for Improved Inference Using Homomorphically Encrypted DNN](http://arxiv.org/abs/2111.03362)


  Privacy-preserving deep neural network (DNN) inference is a necessity in
different regulated industries such as healthcare, finance, and retail.
Recently, homomorphic encryption (HE) has been used as a method to enable
analytics while addressing privacy concerns. HE enables secure predictions over
encrypted data. However, there are several challenges related to the use of HE,
including DNN size limitations and the lack of support for some operation
types. Most notably, the commonly used ReLU activation is not supported under
some HE schemes. We propose a structured methodology to replace ReLU with a
quadratic polynomial activation. To address the accuracy degradation issue, we
use a pre-trained model that trains another HE-friendly model, using techniques
such as "trainable activation" functions and knowledge distillation. We
demonstrate our methodology on the AlexNet architecture, using the chest X-Ray
and CT datasets for COVID-19 detection. Our experiments show that by using our
approach, the gap between the F1 score and accuracy of the models trained with
ReLU and the HE-friendly model is narrowed down to within a mere 1.1 - 5.3
percent degradation.

    

### [[2111.03370] Segmentation of 2D Brain MR Images](http://arxiv.org/abs/2111.03370)


  Brain tumour segmentation is an essential task in medical image processing.
Early diagnosis of brain tumours plays a crucial role in improving treatment
possibilities and increases the survival rate of the patients. Manual
segmentation of the brain tumours for cancer diagnosis, from large number of
MRI images, is both a difficult and time-consuming task. There is a need for
automatic brain tumour image segmentation. The purpose of this project is to
provide an automatic brain tumour segmentation method of MRI images to help
locate the tumour accurately and quickly.

    

### [[2111.03377] Online Learning in Periodic Zero-Sum Games](http://arxiv.org/abs/2111.03377)


  A seminal result in game theory is von Neumann's minmax theorem, which states
that zero-sum games admit an essentially unique equilibrium solution. Classical
learning results build on this theorem to show that online no-regret dynamics
converge to an equilibrium in a time-average sense in zero-sum games. In the
past several years, a key research direction has focused on characterizing the
day-to-day behavior of such dynamics. General results in this direction show
that broad classes of online learning dynamics are cyclic, and formally
Poincaré recurrent, in zero-sum games. We analyze the robustness of these
online learning behaviors in the case of periodic zero-sum games with a
time-invariant equilibrium. This model generalizes the usual repeated game
formulation while also being a realistic and natural model of a repeated
competition between players that depends on exogenous environmental variations
such as time-of-day effects, week-to-week trends, and seasonality.
Interestingly, time-average convergence may fail even in the simplest such
settings, in spite of the equilibrium being fixed. In contrast, using novel
analysis methods, we show that Poincaré recurrence provably generalizes
despite the complex, non-autonomous nature of these dynamical systems.

    

### [[2111.03383] Epidemic inference through generative neural networks](http://arxiv.org/abs/2111.03383)


  Reconstructing missing information in epidemic spreading on contact networks
can be essential in prevention and containment strategies. For instance,
identifying and warning infective but asymptomatic individuals (e.g., manual
contact tracing) helped contain outbreaks in the COVID-19 pandemic. The number
of possible epidemic cascades typically grows exponentially with the number of
individuals involved. The challenge posed by inference problems in the
epidemics processes originates from the difficulty of identifying the almost
negligible subset of those compatible with the evidence (for instance, medical
tests). Here we present a new generative neural networks framework that can
sample the most probable infection cascades compatible with observations.
Moreover, the framework can infer the parameters governing the spreading of
infections. The proposed method obtains better or comparable results with
existing methods on the patient zero problem, risk assessment, and inference of
infectious parameters in synthetic and real case scenarios like spreading
infections in workplaces and hospitals.

    

### [[2111.03388] A Deep Learning Generative Model Approach for Image Synthesis of Plant Leaves](http://arxiv.org/abs/2111.03388)


  Objectives. We generate via advanced Deep Learning (DL) techniques artificial
leaf images in an automatized way. We aim to dispose of a source of training
samples for AI applications for modern crop management. Such applications
require large amounts of data and, while leaf images are not truly scarce,
image collection and annotation remains a very time--consuming process. Data
scarcity can be addressed by augmentation techniques consisting in simple
transformations of samples belonging to a small dataset, but the richness of
the augmented data is limited: this motivates the search for alternative
approaches. Methods. Pursuing an approach based on DL generative models, we
propose a Leaf-to-Leaf Translation (L2L) procedure structured in two steps:
first, a residual variational autoencoder architecture generates synthetic leaf
skeletons (leaf profile and veins) starting from companions binarized skeletons
of real images. In a second step, we perform translation via a Pix2pix
framework, which uses conditional generator adversarial networks to reproduce
the colorization of leaf blades, preserving the shape and the venation pattern.
Results. The L2L procedure generates synthetic images of leaves with a
realistic appearance. We address the performance measurement both in a
qualitative and a quantitative way; for this latter evaluation, we employ a DL
anomaly detection strategy which quantifies the degree of anomaly of synthetic
leaves with respect to real samples. Conclusions. Generative DL approaches have
the potential to be a new paradigm to provide low-cost meaningful synthetic
samples for computer-aided applications. The present L2L approach represents a
step towards this goal, being able to generate synthetic samples with a
relevant qualitative and quantitative resemblance to real leaves.

    

### [[2111.03394] Long Range Probabilistic Forecasting in Time-Series using High Order Statistics](http://arxiv.org/abs/2111.03394)


  Long range forecasts are the starting point of many decision support systems
that need to draw inference from high-level aggregate patterns on forecasted
values. State of the art time-series forecasting methods are either subject to
concept drift on long-horizon forecasts, or fail to accurately predict coherent
and accurate high-level aggregates.
In this work, we present a novel probabilistic forecasting method that
produces forecasts that are coherent in terms of base level and predicted
aggregate statistics. We achieve the coherency between predicted base-level and
aggregate statistics using a novel inference method. Our inference method is
based on KL-divergence and can be solved efficiently in closed form. We show
that our method improves forecast performance across both base level and unseen
aggregates post inference on real datasets ranging three diverse domains.

    

### [[2111.03396] FedLess: Secure and Scalable Federated Learning Using Serverless Computing](http://arxiv.org/abs/2111.03396)


  The traditional cloud-centric approach for Deep Learning (DL) requires
training data to be collected and processed at a central server which is often
challenging in privacy-sensitive domains like healthcare. Towards this, a new
learning paradigm called Federated Learning (FL) has been proposed that brings
the potential of DL to these domains while addressing privacy and data
ownership issues. FL enables remote clients to learn a shared ML model while
keeping the data local. However, conventional FL systems face several
challenges such as scalability, complex infrastructure management, and wasted
compute and incurred costs due to idle clients. These challenges of FL systems
closely align with the core problems that serverless computing and
Function-as-a-Service (FaaS) platforms aim to solve. These include rapid
scalability, no infrastructure management, automatic scaling to zero for idle
clients, and a pay-per-use billing model. To this end, we present a novel
system and framework for serverless FL, called FedLess. Our system supports
multiple commercial and self-hosted FaaS providers and can be deployed in the
cloud, on-premise in institutional data centers, and on edge devices. To the
best of our knowledge, we are the first to enable FL across a large fabric of
heterogeneous FaaS providers while providing important features like security
and Differential Privacy. We demonstrate with comprehensive experiments that
the successful training of DNNs for different tasks across up to 200 client
functions and more is easily possible using our system. Furthermore, we
demonstrate the practical viability of our methodology by comparing it against
a traditional FL system and show that it can be cheaper and more
resource-efficient.

    

### [[2111.03412] Dual Parameterization of Sparse Variational Gaussian Processes](http://arxiv.org/abs/2111.03412)


  Sparse variational Gaussian process (SVGP) methods are a common choice for
non-conjugate Gaussian process inference because of their computational
benefits. In this paper, we improve their computational efficiency by using a
dual parameterization where each data example is assigned dual parameters,
similarly to site parameters used in expectation propagation. Our dual
parameterization speeds-up inference using natural gradient descent, and
provides a tighter evidence lower bound for hyperparameter learning. The
approach has the same memory cost as the current SVGP methods, but it is faster
and more accurate.

    

### [[2111.03418] Meta-Forecasting by combining Global DeepRepresentations with Local Adaptation](http://arxiv.org/abs/2111.03418)


  While classical time series forecasting considers individual time series in
isolation, recent advances based on deep learning showed that jointly learning
from a large pool of related time series can boost the forecasting accuracy.
However, the accuracy of these methods suffers greatly when modeling
out-of-sample time series, significantly limiting their applicability compared
to classical forecasting methods. To bridge this gap, we adopt a meta-learning
view of the time series forecasting problem. We introduce a novel forecasting
method, called Meta Global-Local Auto-Regression (Meta-GLAR), that adapts to
each time series by learning in closed-form the mapping from the
representations produced by a recurrent neural network (RNN) to one-step-ahead
forecasts. Crucially, the parameters ofthe RNN are learned across multiple time
series by backpropagating through the closed-form adaptation mechanism. In our
extensive empirical evaluation we show that our method is competitive with the
state-of-the-art in out-of-sample forecasting accuracy reported in earlier
work.

    

### [[2111.03421] Solving Traffic4Cast Competition with U-Net and Temporal Domain Adaptation](http://arxiv.org/abs/2111.03421)


  In this technical report, we present our solution to the Traffic4Cast 2021
Core Challenge, in which participants were asked to develop algorithms for
predicting a traffic state 60 minutes ahead, based on the information from the
previous hour, in 4 different cities. In contrast to the previously held
competitions, this year's challenge focuses on the temporal domain shift in
traffic due to the COVID-19 pandemic. Following the past success of U-Net, we
utilize it for predicting future traffic maps. Additionally, we explore the
usage of pre-trained encoders such as DenseNet and EfficientNet and employ
multiple domain adaptation techniques to fight the domain shift. Our solution
has ranked third in the final competition. The code is available at
this https URL.

    

### [[2111.03422] Transferable Time-Series Forecasting under Causal Conditional Shift](http://arxiv.org/abs/2111.03422)


  This paper focuses on the problem of \textcolor{black}{semi-supervised}
domain adaptation for time-series forecasting, which is an easily neglected but
challenging problem due to the changeable and complex conditional dependencies.
In fact, these domain-specific conditional dependencies are mainly led by the
data offset, the time lags, and the variant data distribution. In order to cope
with this problem, we analyze the variational conditional dependencies in
time-series data and consider that the causal structures are stable among
different domains, and further raise the causal conditional shift assumption.
Enlightened by this assumption, we consider the causal generation process for
time-series data and devise an end-to-end model for transferable time-series
forecasting. The proposed method can not only discover the cross-domain
\textit{Granger Causality} but also address the cross-domain time-series
forecasting problem. It can even provide the interpretability of the predicted
results to some extent. We further theoretically analyze the superiority of the
proposed methods, where the generalization error on the target domain is not
only bounded by the empirical risks on the source and target domains but also
by the similarity between the causal structures from different domains.
Experimental results on both synthetic and real data demonstrate the
effectiveness of the proposed method for transferable time-series forecasting.

    

### [[2111.03431] Learning to Cooperate with Unseen Agent via Meta-Reinforcement Learning](http://arxiv.org/abs/2111.03431)


  Ad hoc teamwork problem describes situations where an agent has to cooperate
with previously unseen agents to achieve a common goal. For an agent to be
successful in these scenarios, it has to have a suitable cooperative skill. One
could implement cooperative skills into an agent by using domain knowledge to
design the agent's behavior. However, in complex domains, domain knowledge
might not be available. Therefore, it is worthwhile to explore how to directly
learn cooperative skills from data. In this work, we apply meta-reinforcement
learning (meta-RL) formulation in the context of the ad hoc teamwork problem.
Our empirical results show that such a method could produce robust cooperative
agents in two cooperative environments with different cooperative
circumstances: social compliance and language interpretation. (This is a full
paper of the extended abstract version.)

    

### [[2111.03447] Contextual Bayesian optimization with binary outputs](http://arxiv.org/abs/2111.03447)


  Bayesian optimization (BO) is an efficient method to optimize expensive
black-box functions. It has been generalized to scenarios where objective
function evaluations return stochastic binary feedback, such as success/failure
in a given test, or preference between different parameter settings. In many
real-world situations, the objective function can be evaluated in controlled
'contexts' or 'environments' that directly influence the observations. For
example, one could directly alter the 'difficulty' of the test that is used to
evaluate a system's performance. With binary feedback, the context determines
the information obtained from each observation. For example, if the test is too
easy/hard, the system will always succeed/fail, yielding uninformative binary
outputs. Here we combine ideas from Bayesian active learning and optimization
to efficiently choose the best context and optimization parameter on each
iteration. We demonstrate the performance of our algorithm and illustrate how
it can be used to tackle a concrete application in visual psychophysics:
efficiently improving patients' vision via corrective lenses, using
psychophysics measurements.

    

### [[2111.03452] Generalized Radiograph Representation Learning via Cross-supervision between Images and Free-text Radiology Reports](http://arxiv.org/abs/2111.03452)


  Pre-training lays the foundation for recent successes in radiograph analysis
supported by deep learning. It learns transferable image representations by
conducting large-scale fully-supervised or self-supervised learning on a source
domain. However, supervised pre-training requires a complex and labor intensive
two-stage human-assisted annotation process while self-supervised learning
cannot compete with the supervised paradigm. To tackle these issues, we propose
a cross-supervised methodology named REviewing FreE-text Reports for
Supervision (REFERS), which acquires free supervision signals from original
radiology reports accompanying the radiographs. The proposed approach employs a
vision transformer and is designed to learn joint representations from multiple
views within every patient study. REFERS outperforms its transfer learning and
self-supervised learning counterparts on 4 well-known X-ray datasets under
extremely limited supervision. Moreover, REFERS even surpasses methods based on
a source domain of radiographs with human-assisted structured labels. Thus
REFERS has the potential to replace canonical pre-training methodologies.

    

### [[2111.03454] Control of a fly-mimicking flyer in complex flow using deep reinforcement learning](http://arxiv.org/abs/2111.03454)


  An integrated framework of computational fluid-structural dynamics (CFD-CSD)
and deep reinforcement learning (deep-RL) is developed for control of a
fly-scale flexible-winged flyer in complex flow. Dynamics of the flyer in
complex flow is highly unsteady and nonlinear, which makes modeling the
dynamics challenging. Thus, conventional control methodologies, where the
dynamics is modeled, are insufficient for regulating such complicated dynamics.
Therefore, in the present study, the integrated framework, in which the whole
governing equations for fluid and structure are solved, is proposed to generate
a control policy for the flyer. For the deep-RL to successfully learn the
control policy, accurate and ample data of the dynamics are required. However,
satisfying both the quality and quantity of the data on the intricate dynamics
is extremely difficult since, in general, more accurate data are more costly.
In the present study, two strategies are proposed to deal with the dilemma. To
obtain accurate data, the CFD-CSD is adopted for precisely predicting the
dynamics. To gain ample data, a novel data reproduction method is devised,
where the obtained data are replicated for various situations while conserving
the dynamics. With those data, the framework learns the control policy in
various flow conditions and the learned policy is shown to have remarkable
performance in controlling the flyer in complex flow fields.

    

### [[2111.03463] RADAMS: Resilient and Adaptive Alert and Attention Management Strategy against Informational Denial-of-Service (IDoS) Attacks](http://arxiv.org/abs/2111.03463)


  Attacks exploiting human attentional vulnerability have posed severe threats
to cybersecurity. In this work, we identify and formally define a new type of
proactive attentional attacks called Informational Denial-of-Service (IDoS)
attacks that generate a large volume of feint attacks to overload human
operators and hide real attacks among feints. We incorporate human factors
(e.g., levels of expertise, stress, and efficiency) and empirical results
(e.g., the Yerkes-Dodson law and the sunk cost fallacy) to model the operators'
attention dynamics and their decision-making processes along with the real-time
alert monitoring and inspection.
To assist human operators in timely and accurately dismissing the feints and
escalating the real attacks, we develop a Resilient and Adaptive Data-driven
alert and Attention Management Strategy (RADAMS) that de-emphasizes alerts
selectively based on the alerts' observable features. RADAMS uses reinforcement
learning to achieve a customized and transferable design for various human
operators and evolving IDoS attacks.
The integrated modeling and theoretical analysis lead to the Product
Principle of Attention (PPoA), fundamental limits, and the tradeoff among
crucial human and economic factors. Experimental results corroborate that the
proposed strategy outperforms the default strategy and can reduce the IDoS risk
by as much as 20%. Besides, the strategy is resilient to large variations of
costs, attack frequencies, and human attention capacities. We have recognized
interesting phenomena such as attentional risk equivalency, attacker's dilemma,
and the half-truth optimal attack strategy.

    

### [[2111.03466] Learning Large Neighborhood Search Policy for Integer Programming](http://arxiv.org/abs/2111.03466)


  We propose a deep reinforcement learning (RL) method to learn large
neighborhood search (LNS) policy for integer programming (IP). The RL policy is
trained as the destroy operator to select a subset of variables at each step,
which is reoptimized by an IP solver as the repair operator. However, the
combinatorial number of variable subsets prevents direct application of typical
RL algorithms. To tackle this challenge, we represent all subsets by
factorizing them into binary decisions on each variable. We then design a
neural network to learn policies for each variable in parallel, trained by a
customized actor-critic algorithm. We evaluate the proposed method on four
representative IP problems. Results show that it can find better solutions than
SCIP in much less time, and significantly outperform other LNS baselines with
the same runtime. Moreover, these advantages notably persist when the policies
generalize to larger problems. Further experiments with Gurobi also reveal that
our method can outperform this state-of-the-art commercial solver within the
same time limit.

    

### [[2111.03469] Perturbational Complexity by Distribution Mismatch: A Systematic Analysis of Reinforcement Learning in Reproducing Kernel Hilbert Space](http://arxiv.org/abs/2111.03469)


  Most existing theoretical analysis of reinforcement learning (RL) is limited
to the tabular setting or linear models due to the difficulty in dealing with
function approximation in high dimensional space with an uncertain environment.
This work offers a fresh perspective into this challenge by analyzing RL in a
general reproducing kernel Hilbert space (RKHS). We consider a family of Markov
decision processes $\mathcal{M}$ of which the reward functions lie in the unit
ball of an RKHS and transition probabilities lie in a given arbitrary set. We
define a quantity called perturbational complexity by distribution mismatch
$\Delta_{\mathcal{M}}(\epsilon)$ to characterize the complexity of the
admissible state-action distribution space in response to a perturbation in the
RKHS with scale $\epsilon$. We show that $\Delta_{\mathcal{M}}(\epsilon)$ gives
both the lower bound of the error of all possible algorithms and the upper
bound of two specific algorithms (fitted reward and fitted Q-iteration) for the
RL problem. Hence, the decay of $\Delta_\mathcal{M}(\epsilon)$ with respect to
$\epsilon$ measures the difficulty of the RL problem on $\mathcal{M}$. We
further provide some concrete examples and discuss whether
$\Delta_{\mathcal{M}}(\epsilon)$ decays fast or not in these examples. As a
byproduct, we show that when the reward functions lie in a high dimensional
RKHS, even if the transition probability is known and the action space is
finite, it is still possible for RL problems to suffer from the curse of
dimensionality.

    

### [[2111.03470] PerSpeechNorm: A Persian Toolkit for Speech Processing Normalization](http://arxiv.org/abs/2111.03470)


  In general, speech processing models consist of a language model along with
an acoustic model. Regardless of the language model's complexity and variants,
three critical pre-processing steps are needed in language models: cleaning,
normalization, and tokenization. Among mentioned steps, the normalization step
is so essential to format unification in pure textual applications. However,
for embedded language models in speech processing modules, normalization is not
limited to format unification. Moreover, it has to convert each readable
symbol, number, etc., to how they are pronounced. To the best of our knowledge,
there is no Persian normalization toolkits for embedded language models in
speech processing modules, So in this paper, we propose an open-source
normalization toolkit for text processing in speech applications. Briefly, we
consider different readable Persian text like symbols (common currencies, #, @,
URL, etc.), numbers (date, time, phone number, national code, etc.), and so on.
Comparison with other available Persian textual normalization tools indicates
the superiority of the proposed method in speech processing. Also, comparing
the model's performance for one of the proposed functions (sentence separation)
with other common natural language libraries such as HAZM and Parsivar
indicates the proper performance of the proposed method. Besides, its
evaluation of some Persian Wikipedia data confirms the proper performance of
the proposed method.

    

### [[2111.03474] Supervised Advantage Actor-Critic for Recommender Systems](http://arxiv.org/abs/2111.03474)


  Casting session-based or sequential recommendation as reinforcement learning
(RL) through reward signals is a promising research direction towards
recommender systems (RS) that maximize cumulative profits. However, the direct
use of RL algorithms in the RS setting is impractical due to challenges like
off-policy training, huge action spaces and lack of sufficient reward signals.
Recent RL approaches for RS attempt to tackle these challenges by combining RL
and (self-)supervised sequential learning, but still suffer from certain
limitations. For example, the estimation of Q-values tends to be biased toward
positive values due to the lack of negative reward signals. Moreover, the
Q-values also depend heavily on the specific timestamp of a sequence.
To address the above problems, we propose negative sampling strategy for
training the RL component and combine it with supervised sequential learning.
We call this method Supervised Negative Q-learning (SNQN). Based on sampled
(negative) actions (items), we can calculate the "advantage" of a positive
action over the average case, which can be further utilized as a normalized
weight for learning the supervised sequential part. This leads to another
learning framework: Supervised Advantage Actor-Critic (SA2C). We instantiate
SNQN and SA2C with four state-of-the-art sequential recommendation models and
conduct experiments on two real-world datasets. Experimental results show that
the proposed approaches achieve significantly better performance than
state-of-the-art supervised methods and existing self-supervised RL methods .
Code will be open-sourced.

    

### [[2111.03476] A Variational U-Net for Weather Forecasting](http://arxiv.org/abs/2111.03476)


  Not only can discovering patterns and insights from atmospheric data enable
more accurate weather predictions, but it may also provide valuable information
to help tackle climate change. Weather4cast is an open competition that aims to
evaluate machine learning algorithms' capability to predict future atmospheric
states. Here, we describe our third-place solution to Weather4cast. We present
a novel Variational U-Net that combines a Variational Autoencoder's ability to
consider the probabilistic nature of data with a U-Net's ability to recover
fine-grained details. This solution is an evolution from our fourth-place
solution to Traffic4cast 2020 with many commonalities, suggesting its
applicability to vastly different domains, such as weather and traffic.

    

### [[2111.03495] Automated Supervised Feature Selection for Differentiated Patterns of Care](http://arxiv.org/abs/2111.03495)


  An automated feature selection pipeline was developed using several
state-of-the-art feature selection techniques to select optimal features for
Differentiating Patterns of Care (DPOC). The pipeline included three types of
feature selection techniques; Filters, Wrappers and Embedded methods to select
the top K features. Five different datasets with binary dependent variables
were used and their different top K optimal features selected. The selected
features were tested in the existing multi-dimensional subset scanning (MDSS)
where the most anomalous subpopulations, most anomalous subsets, propensity
scores, and effect of measures were recorded to test their performance. This
performance was compared with four similar metrics gained after using all
covariates in the dataset in the MDSS pipeline. We found out that despite the
different feature selection techniques used, the data distribution is key to
note when determining the technique to use.

    

### [[2111.03496] Monitoring geometrical properties of word embeddings for detecting the emergence of new topics](http://arxiv.org/abs/2111.03496)


  Slow emerging topic detection is a task between event detection, where we
aggregate behaviors of different words on short period of time, and language
evolution, where we monitor their long term evolution. In this work, we tackle
the problem of early detection of slowly emerging new topics. To this end, we
gather evidence of weak signals at the word level. We propose to monitor the
behavior of words representation in an embedding space and use one of its
geometrical properties to characterize the emergence of topics. As evaluation
is typically hard for this kind of task, we present a framework for
quantitative evaluation. We show positive results that outperform
state-of-the-art methods on two public datasets of press and scientific
articles.

    

### [[2111.03504] Deep-Learning Based Linear Precoding for MIMO Channels with Finite-Alphabet Signaling](http://arxiv.org/abs/2111.03504)


  This paper studies the problem of linear precoding for multiple-input
multiple-output (MIMO) communication channels employing finite-alphabet
signaling. Existing solutions typically suffer from high computational
complexity due to costly computations of the constellation-constrained mutual
information. In contrast to existing works, this paper takes a different path
of tackling the MIMO precoding problem. Namely, a data-driven approach, based
on deep learning, is proposed. In the offline training phase, a deep neural
network learns the optimal solution on a set of MIMO channel matrices. This
allows the reduction of the computational complexity of the precoder
optimization in the online inference phase. Numerical results demonstrate the
efficiency of the proposed solution vis-à-vis existing precoding algorithms
in terms of significantly reduced complexity and close-to-optimal performance.

    

### [[2111.03505] Visualizing the Emergence of Intermediate Visual Patterns in DNNs](http://arxiv.org/abs/2111.03505)


  This paper proposes a method to visualize the discrimination power of
intermediate-layer visual patterns encoded by a DNN. Specifically, we visualize
(1) how the DNN gradually learns regional visual patterns in each intermediate
layer during the training process, and (2) the effects of the DNN using
non-discriminative patterns in low layers to construct disciminative patterns
in middle/high layers through the forward propagation. Based on our
visualization method, we can quantify knowledge points (i.e., the number of
discriminative visual patterns) learned by the DNN to evaluate the
representation capacity of the DNN. Furthermore, this method also provides new
insights into signal-processing behaviors of existing deep-learning techniques,
such as adversarial attacks and knowledge distillation.

    

### [[2111.03512] Data Selection for Efficient Model Update in Federated Learning](http://arxiv.org/abs/2111.03512)


  The Federated Learning workflow of training a centralized model with
distributed data is growing in popularity. However, until recently, this was
the realm of contributing clients with similar computing capabilities. The fast
expanding IoT space and data being generated and processed at the edge are
encouraging more effort into expanding federated learning to include
heterogeneous systems. Previous approaches distribute smaller models to clients
for distilling the characteristic of local data. But the problem of training
with vast amounts of local data on the client side still remains. We propose to
reduce the amount of local data that is needed to train a global model. We do
this by splitting the model into a lower part for generic feature extraction
and an upper part that is more sensitive to the characteristics of the local
data. We reduce the amount of data needed to train the upper part by clustering
the local data and selecting only the most representative samples to use for
training. Our experiments show that less than 1% of the local data can transfer
the characteristics of the client data to the global model with our slit
network approach. These preliminary results are encouraging continuing towards
federated learning with reduced amount of data on devices with limited
computing resources, but which hold critical information to contribute to the
global model.

    

### [[2111.03514] SocialVec: Social Entity Embeddings](http://arxiv.org/abs/2111.03514)


  This paper introduces SocialVec, a general framework for eliciting social
world knowledge from social networks, and applies this framework to Twitter.
SocialVec learns low-dimensional embeddings of popular accounts, which
represent entities of general interest, based on their co-occurrences patterns
within the accounts followed by individual users, thus modeling entity
similarity in socio-demographic terms. Similar to word embeddings, which
facilitate tasks that involve text processing, we expect social entity
embeddings to benefit tasks of social flavor. We have learned social embeddings
for roughly 200,000 popular accounts from a sample of the Twitter network that
includes more than 1.3 million users and the accounts that they follow, and
evaluate the resulting embeddings on two different tasks. The first task
involves the automatic inference of personal traits of users from their social
media profiles. In another study, we exploit SocialVec embeddings for gauging
the political bias of news sources in Twitter. In both cases, we prove
SocialVec embeddings to be advantageous compared with existing entity embedding
schemes. We will make the SocialVec entity embeddings publicly available to
support further exploration of social world knowledge as reflected in Twitter.

    

### [[2111.03516] Solving the Class Imbalance Problem Using a Counterfactual Method for Data Augmentation](http://arxiv.org/abs/2111.03516)


  Learning from class imbalanced datasets poses challenges for many machine
learning algorithms. Many real-world domains are, by definition, class
imbalanced by virtue of having a majority class that naturally has many more
instances than its minority class (e.g. genuine bank transactions occur much
more often than fraudulent ones). Many methods have been proposed to solve the
class imbalance problem, among the most popular being oversampling techniques
(such as SMOTE). These methods generate synthetic instances in the minority
class, to balance the dataset, performing data augmentations that improve the
performance of predictive machine learning (ML) models. In this paper we
advance a novel data augmentation method (adapted from eXplainable AI), that
generates synthetic, counterfactual instances in the minority class. Unlike
other oversampling techniques, this method adaptively combines exist-ing
instances from the dataset, using actual feature-values rather than
interpolating values between instances. Several experiments using four
different classifiers and 25 datasets are reported, which show that this
Counterfactual Augmentation method (CFA) generates useful synthetic data points
in the minority class. The experiments also show that CFA is competitive with
many other oversampling methods many of which are variants of SMOTE. The basis
for CFAs performance is discussed, along with the conditions under which it is
likely to perform better or worse in future tests.

    

### [[2111.03519] S-multi-SNE: Semi-Supervised Classification and Visualisation of Multi-View Data](http://arxiv.org/abs/2111.03519)


  An increasing number of multi-view data are being published by studies in
several fields. This type of data corresponds to multiple data-views, each
representing a different aspect of the same set of samples. We have recently
proposed multi-SNE, an extension of t-SNE, that produces a single visualisation
of multi-view data. The multi-SNE approach provides low-dimensional embeddings
of the samples, produced by being updated iteratively through the different
data-views. Here, we further extend multi-SNE to a semi-supervised approach,
that classifies unlabelled samples by regarding the labelling information as an
extra data-view. We look deeper into the performance, limitations and strengths
of multi-SNE and its extension, S-multi-SNE, by applying the two methods on
various multi-view datasets with different challenges. We show that by
including the labelling information, the projection of the samples improves
drastically and it is accompanied by a strong classification performance.

    

### [[2111.03524] A Data-driven Approach to Neural Architecture Search Initialization](http://arxiv.org/abs/2111.03524)


  Algorithmic design in neural architecture search (NAS) has received a lot of
attention, aiming to improve performance and reduce computational cost. Despite
the great advances made, few authors have proposed to tailor initialization
techniques for NAS. However, literature shows that a good initial set of
solutions facilitate finding the optima. Therefore, in this study, we propose a
data-driven technique to initialize a population-based NAS algorithm.
Particularly, we proposed a two-step methodology. First, we perform a
calibrated clustering analysis of the search space, and second, we extract the
centroids and use them to initialize a NAS algorithm. We benchmark our proposed
approach against random and Latin hypercube sampling initialization using three
population-based algorithms, namely a genetic algorithm, evolutionary
algorithm, and aging evolution, on CIFAR-10. More specifically, we use
NAS-Bench-101 to leverage the availability of NAS benchmarks. The results show
that compared to random and Latin hypercube sampling, the proposed
initialization technique enables achieving significant long-term improvements
for two of the search baselines, and sometimes in various search scenarios
(various training budgets). Moreover, we analyze the distributions of solutions
obtained and find that that the population provided by the data-driven
initialization technique enables retrieving local optima (maxima) of high
fitness and similar configurations.

    

### [[2111.03532] A Retrospective Analysis using Deep-Learning Models for Prediction of Survival Outcome and Benefit of Adjuvant Chemotherapy in Stage II/III Colorectal Cancer](http://arxiv.org/abs/2111.03532)


  Most early-stage colorectal cancer (CRC) patients can be cured by surgery
alone, and only certain high-risk early-stage CRC patients benefit from
adjuvant chemotherapies. However, very few validated biomarkers are available
to accurately predict survival benefit from postoperative chemotherapy. We
developed a novel deep-learning algorithm (CRCNet) using whole-slide images
from Molecular and Cellular Oncology (MCO) to predict survival benefit of
adjuvant chemotherapy in stage II/III CRC. We validated CRCNet both internally
through cross-validation and externally using an independent cohort from The
Cancer Genome Atlas (TCGA). We showed that CRCNet can accurately predict not
only survival prognosis but also the treatment effect of adjuvant chemotherapy.
The CRCNet identified high-risk subgroup benefits from adjuvant chemotherapy
most and significant longer survival is observed among chemo-treated patients.
Conversely, minimal chemotherapy benefit is observed in the CRCNet low- and
medium-risk subgroups. Therefore, CRCNet can potentially be of great use in
guiding treatments for Stage II/III CRC.

    

### [[2111.03533] An Analysis of Elephants' Movement Data in Sub-Saharan Africa Using Clustering](http://arxiv.org/abs/2111.03533)


  Understanding the movement of animals is crucial to conservation efforts.
Past research often focuses on factors affecting movement, rather than
locations of interest that animals return to or habitat. We explore the use of
clustering to identify locations of interest to African Elephants in regions of
Sub-Saharan Africa. Our analysis was performed using publicly available
datasets for tracking African elephants at Kruger National Park (KNP), South
Africa; Etosha National Park, Namibia; as well as areas in Burkina Faso and the
Congo. Using the DBSCAN and KMeans clustering algorithms, we calculate clusters
and centroids to simplify elephant movement data and highlight important
locations of interest. Through a comparison of feature spaces with and without
temperature, we show that temperature is an important feature to explain
movement clustering. Recognizing the importance of temperature, we develop a
technique to add external temperature data from an API to other geospatial
datasets that would otherwise not have temperature data. After addressing the
hurdles of using external data with marginally different timestamps, we
consider the quality of this data, and the quality of the centroids of the
clusters calculated based on this external temperature data. Finally, we
overlay these centroids onto satellite imagery and locations of human
settlements to validate the real-life applications of the calculated centroids
to identify locations of interest for elephants. As expected, we confirmed that
elephants tend to cluster their movement around sources of water as well as
some human settlements, especially those with water holes. Identifying key
locations of interest for elephants is beneficial in predicting the movement of
elephants and preventing poaching. These methods may in the future be applied
to other animals beyond elephants to identify locations of interests for them.

    

### [[2111.03536] A Unified Game-Theoretic Interpretation of Adversarial Robustness](http://arxiv.org/abs/2111.03536)


  This paper provides a unified view to explain different adversarial attacks
and defense methods, \emph{i.e.} the view of multi-order interactions between
input variables of DNNs. Based on the multi-order interaction, we discover that
adversarial attacks mainly affect high-order interactions to fool the DNN.
Furthermore, we find that the robustness of adversarially trained DNNs comes
from category-specific low-order interactions. Our findings provide a potential
method to unify adversarial perturbations and robustness, which can explain the
existing defense methods in a principle way. Besides, our findings also make a
revision of previous inaccurate understanding of the shape bias of
adversarially learned features.

    

### [[2111.03543] An Empirical Study of Neural Kernel Bandits](http://arxiv.org/abs/2111.03543)


  Neural bandits have enabled practitioners to operate efficiently on problems
with non-linear reward functions. While in general contextual bandits commonly
utilize Gaussian process (GP) predictive distributions for decision making, the
most successful neural variants use only the last layer parameters in the
derivation. Research on neural kernels (NK) has recently established a
correspondence between deep networks and GPs that take into account all the
parameters of a NN and can be trained more efficiently than most Bayesian NNs.
We propose to directly apply NK-induced distributions to guide an upper
confidence bound or Thompson sampling-based policy. We show that NK bandits
achieve state-of-the-art performance on highly non-linear structured data.
Furthermore, we analyze practical considerations such as training frequency and
model partitioning. We believe our work will help better understand the impact
of utilizing NKs in applied settings.

    

### [[2111.03549] Interpreting Representation Quality of DNNs for 3D Point Cloud Processing](http://arxiv.org/abs/2111.03549)


  In this paper, we evaluate the quality of knowledge representations encoded
in deep neural networks (DNNs) for 3D point cloud processing. We propose a
method to disentangle the overall model vulnerability into the sensitivity to
the rotation, the translation, the scale, and local 3D structures. Besides, we
also propose metrics to evaluate the spatial smoothness of encoding 3D
structures, and the representation complexity of the DNN. Based on such
analysis, experiments expose representation problems with classic DNNs, and
explain the utility of the adversarial training.

    

### [[2111.03555] AUTOKD: Automatic Knowledge Distillation Into A Student Architecture Family](http://arxiv.org/abs/2111.03555)


  State-of-the-art results in deep learning have been improving steadily, in
good part due to the use of larger models. However, widespread use is
constrained by device hardware limitations, resulting in a substantial
performance gap between state-of-the-art models and those that can be
effectively deployed on small devices. While Knowledge Distillation (KD)
theoretically enables small student models to emulate larger teacher models, in
practice selecting a good student architecture requires considerable human
expertise. Neural Architecture Search (NAS) appears as a natural solution to
this problem but most approaches can be inefficient, as most of the computation
is spent comparing architectures sampled from the same distribution, with
negligible differences in performance. In this paper, we propose to instead
search for a family of student architectures sharing the property of being good
at learning from a given teacher. Our approach AutoKD, powered by Bayesian
Optimization, explores a flexible graph-based search space, enabling us to
automatically learn the optimal student architecture distribution and KD
parameters, while being 20x more sample efficient compared to existing
state-of-the-art. We evaluate our method on 3 datasets; on large images
specifically, we reach the teacher performance while using 3x less memory and
10x less parameters. Finally, while AutoKD uses the traditional KD loss, it
outperforms more advanced KD variants using hand-designed students.

    

### [[2111.03563] Machine Learning Product State Distributions from Initial Reactant States for a Reactive Atom-Diatom Collision System](http://arxiv.org/abs/2111.03563)


  A machine learned (ML) model for predicting product state distributions from
specific initial states (state-to-distribution or STD) for reactive atom-diatom
collisions is presented and quantitatively tested for the N($^4$S)+O$_{2}$(X$^3
\Sigma_{\rm g}^{-}$) $\rightarrow$ NO(X$^2\Pi$) +O($^3$P) reaction. The
reference data set for training the neural network (NN) consists of final state
distributions determined from explicit quasi-classical trajectory (QCT)
simulations for $\sim 2000$ initial conditions. Overall, the prediction
accuracy as quantified by the root-mean-squared difference $(\sim 0.003)$ and
the $R^2$ $(\sim 0.99)$ between the reference QCT and predictions of the STD
model is high for the test set and off-grid state specific initial conditions
and for initial conditions drawn from reactant state distributions
characterized by translational, rotational and vibrational temperatures.
Compared with a more coarse grained distribution-to-distribution (DTD) model
evaluated on the same initial state distributions, the STD model shows
comparable performance with the additional benefit of the state resolution in
the reactant preparation. Starting from specific initial states also leads to a
more diverse range of final state distributions which requires a more
expressive neural network to be used compared with DTD. Direct comparison
between explicit QCT simulations, the STD model, and the widely used
Larsen-Borgnakke (LB) model shows that the STD model is quantitative whereas
the LB model is qualitative at best for rotational distributions $P(j')$ and
fails for vibrational distributions $P(v')$. As such the STD model can be
well-suited for simulating nonequilibrium high-speed flows, e.g., using the
direct simulation Monte Carlo method.

    

### [[2111.03576] Investigation of Topic Modelling Methods for Understanding the Reports of the Mining Projects in Queensland](http://arxiv.org/abs/2111.03576)


  In the mining industry, many reports are generated in the project management
process. These past documents are a great resource of knowledge for future
success. However, it would be a tedious and challenging task to retrieve the
necessary information if the documents are unorganized and unstructured.
Document clustering is a powerful approach to cope with the problem, and many
methods have been introduced in past studies. Nonetheless, there is no silver
bullet that can perform the best for any types of documents. Thus, exploratory
studies are required to apply the clustering methods for new datasets. In this
study, we will investigate multiple topic modelling (TM) methods. The
objectives are finding the appropriate approach for the mining project reports
using the dataset of the Geological Survey of Queensland, Department of
Resources, Queensland Government, and understanding the contents to get the
idea of how to organise them. Three TM methods, Latent Dirichlet Allocation
(LDA), Nonnegative Matrix Factorization (NMF), and Nonnegative Tensor
Factorization (NTF) are compared statistically and qualitatively. After the
evaluation, we conclude that the LDA performs the best for the dataset;
however, the possibility remains that the other methods could be adopted with
some improvements.

    

### [[2111.03577] Mixtures of Laplace Approximations for Improved Post-Hoc Uncertainty in Deep Learning](http://arxiv.org/abs/2111.03577)


  Deep neural networks are prone to overconfident predictions on outliers.
Bayesian neural networks and deep ensembles have both been shown to mitigate
this problem to some extent. In this work, we aim to combine the benefits of
the two approaches by proposing to predict with a Gaussian mixture model
posterior that consists of a weighted sum of Laplace approximations of
independently trained deep neural networks. The method can be used post hoc
with any set of pre-trained networks and only requires a small computational
and memory overhead compared to regular ensembles. We theoretically validate
that our approach mitigates overconfidence "far away" from the training data
and empirically compare against state-of-the-art baselines on standard
uncertainty quantification benchmarks.

    

### [[2111.03592] Nonnegative Matrix Factorization to understand Spatio-Temporal Traffic Pattern Variations during COVID-19: A Case Study](http://arxiv.org/abs/2111.03592)


  Due to the rapid developments in Intelligent Transportation System (ITS) and
increasing trend in the number of vehicles on road, abundant of road traffic
data is generated and available. Understanding spatio-temporal traffic patterns
from this data is crucial and has been effectively helping in traffic
plannings, road constructions, etc. However, understanding traffic patterns
during COVID-19 pandemic is quite challenging and important as there is a huge
difference in-terms of people's and vehicle's travel behavioural patterns. In
this paper, a case study is conducted to understand the variations in
spatio-temporal traffic patterns during COVID-19. We apply nonnegative matrix
factorization (NMF) to elicit patterns. The NMF model outputs are analysed
based on the spatio-temporal pattern behaviours observed during the year 2019
and 2020, which is before pandemic and during pandemic situations respectively,
in Great Britain. The outputs of the analysed spatio-temporal traffic pattern
variation behaviours will be useful in the fields of traffic management in
Intelligent Transportation System and management in various stages of pandemic
or unavoidable scenarios in-relation to road traffic.

    

### [[2111.03602] NAS-Bench-x11 and the Power of Learning Curves](http://arxiv.org/abs/2111.03602)


  While early research in neural architecture search (NAS) required extreme
computational resources, the recent releases of tabular and surrogate
benchmarks have greatly increased the speed and reproducibility of NAS
research. However, two of the most popular benchmarks do not provide the full
training information for each architecture. As a result, on these benchmarks it
is not possible to run many types of multi-fidelity techniques, such as
learning curve extrapolation, that require evaluating architectures at
arbitrary epochs. In this work, we present a method using singular value
decomposition and noise modeling to create surrogate benchmarks, NAS-Bench-111,
NAS-Bench-311, and NAS-Bench-NLP11, that output the full training information
for each architecture, rather than just the final validation accuracy. We
demonstrate the power of using the full training information by introducing a
learning curve extrapolation framework to modify single-fidelity algorithms,
showing that it leads to improvements over popular single-fidelity algorithms
which claimed to be state-of-the-art upon release. Our code and pretrained
models are available at this https URL.

    

### [[2111.03612] Sexism Identification in Tweets and Gabs using Deep Neural Networks](http://arxiv.org/abs/2111.03612)


  Through anonymisation and accessibility, social media platforms have
facilitated the proliferation of hate speech, prompting increased research in
developing automatic methods to identify these texts. This paper explores the
classification of sexism in text using a variety of deep neural network model
architectures such as Long-Short-Term Memory (LSTMs) and Convolutional Neural
Networks (CNNs). These networks are used in conjunction with transfer learning
in the form of Bidirectional Encoder Representations from Transformers (BERT)
and DistilBERT models, along with data augmentation, to perform binary and
multiclass sexism classification on the dataset of tweets and gabs from the
sEXism Identification in Social neTworks (EXIST) task in IberLEF 2021. The
models are seen to perform comparatively to those from the competition, with
the best performances seen using BERT and a multi-filter CNN model. Data
augmentation further improves these results for the multi-class classification
task. This paper also explores the errors made by the models and discusses the
difficulty in automatically classifying sexism due to the subjectivity of the
labels and the complexity of natural language used in social media.

    

### [[2111.03617] Adaptive Low-Pass Filtering using Sliding Window Gaussian Processes](http://arxiv.org/abs/2111.03617)


  When signals are measured through physical sensors, they are perturbed by
noise. To reduce noise, low-pass filters are commonly employed in order to
attenuate high frequency components in the incoming signal, regardless if they
come from noise or the actual signal. Therefore, low-pass filters must be
carefully tuned in order to avoid significant deterioration of the signal. This
tuning requires prior knowledge about the signal, which is often not available
in applications such as reinforcement learning or learning-based control. In
order to overcome this limitation, we propose an adaptive low-pass filter based
on Gaussian process regression. By considering a constant window of previous
observations, updates and predictions fast enough for real-world filtering
applications can be realized. Moreover, the online optimization of
hyperparameters leads to an adaptation of the low-pass behavior, such that no
prior tuning is necessary. We show that the estimation error of the proposed
method is uniformly bounded, and demonstrate the flexibility and efficiency of
the approach in several simulations.

    

### [[2111.03637] Risk-averse Heteroscedastic Bayesian Optimization](http://arxiv.org/abs/2111.03637)


  Many black-box optimization tasks arising in high-stakes applications require
risk-averse decisions. The standard Bayesian optimization (BO) paradigm,
however, optimizes the expected value only. We generalize BO to trade mean and
input-dependent variance of the objective, both of which we assume to be
unknown a priori. In particular, we propose a novel risk-averse heteroscedastic
Bayesian optimization algorithm (RAHBO) that aims to identify a solution with
high return and low noise variance, while learning the noise distribution on
the fly. To this end, we model both expectation and variance as (unknown) RKHS
functions, and propose a novel risk-aware acquisition function. We bound the
regret for our approach and provide a robust rule to report the final decision
point for applications where only a single solution must be identified. We
demonstrate the effectiveness of RAHBO on synthetic benchmark functions and
hyperparameter tuning tasks.

    

### [[2111.03638] Increasing Fairness in Predictions Using Bias Parity Score Based Loss Function Regularization](http://arxiv.org/abs/2111.03638)


  Increasing utilization of machine learning based decision support systems
emphasizes the need for resulting predictions to be both accurate and fair to
all stakeholders. In this work we present a novel approach to increase a Neural
Network model's fairness during training. We introduce a family of fairness
enhancing regularization components that we use in conjunction with the
traditional binary-cross-entropy based accuracy loss. These loss functions are
based on Bias Parity Score (BPS), a score that helps quantify bias in the
models with a single number. In the current work we investigate the behavior
and effect of these regularization components on bias. We deploy them in the
context of a recidivism prediction task as well as on a census-based adult
income dataset. The results demonstrate that with a good choice of fairness
loss function we can reduce the trained model's bias without deteriorating
accuracy even in unbalanced dataset.

    

### [[2111.03642] Grounded Graph Decoding Improves Compositional Generalization in Question Answering](http://arxiv.org/abs/2111.03642)


  Question answering models struggle to generalize to novel compositions of
training patterns, such to longer sequences or more complex test structures.
Current end-to-end models learn a flat input embedding which can lose input
syntax context. Prior approaches improve generalization by learning permutation
invariant models, but these methods do not scale to more complex train-test
splits. We propose Grounded Graph Decoding, a method to improve compositional
generalization of language representations by grounding structured predictions
with an attention mechanism. Grounding enables the model to retain syntax
information from the input in thereby significantly improving generalization
over complex inputs. By predicting a structured graph containing conjunctions
of query clauses, we learn a group invariant representation without making
assumptions on the target domain. Our model significantly outperforms
state-of-the-art baselines on the Compositional Freebase Questions (CFQ)
dataset, a challenging benchmark for compositional generalization in question
answering. Moreover, we effectively solve the MCD1 split with 98% accuracy.

    

### [[1905.03871] Differentially Private Learning with Adaptive Clipping](http://arxiv.org/abs/1905.03871)


  Existing approaches for training neural networks with user-level differential
privacy (e.g., DP Federated Averaging) in federated learning (FL) settings
involve bounding the contribution of each user's model update by *clipping* it
to some constant value. However there is no good *a priori* setting of the
clipping norm across tasks and learning settings: the update norm distribution
depends on the model architecture and loss, the amount of data on each device,
the client learning rate, and possibly various other parameters. We propose a
method wherein instead of a fixed clipping norm, one clips to a value at a
specified quantile of the update norm distribution, where the value at the
quantile is itself estimated online, with differential privacy. The method
tracks the quantile closely, uses a negligible amount of privacy budget, is
compatible with other federated learning technologies such as compression and
secure aggregation, and has a straightforward joint DP analysis with DP-FedAvg.
Experiments demonstrate that adaptive clipping to the median update norm works
well across a range of realistic federated learning tasks, sometimes
outperforming even the best fixed clip chosen in hindsight, and without the
need to tune any clipping hyperparameter.

    

### [[1908.02805] Fast Multi-Agent Temporal-Difference Learning via Homotopy Stochastic Primal-Dual Optimization](http://arxiv.org/abs/1908.02805)


  We study the policy evaluation problem in multi-agent reinforcement learning
where a group of agents, with jointly observed states and private local actions
and rewards, collaborate to learn the value function of a given policy via
local computation and communication over a connected undirected network. This
problem arises in various large-scale multi-agent systems, including power
grids, intelligent transportation systems, wireless sensor networks, and
multi-agent robotics. When the dimension of state-action space is large, the
temporal-difference learning with linear function approximation is widely used.
In this paper, we develop a new distributed temporal-difference learning
algorithm and quantify its finite-time performance. Our algorithm combines a
distributed stochastic primal-dual method with a homotopy-based approach to
adaptively adjust the learning rate in order to minimize the mean-square
projected Bellman error by taking fresh online samples from a causal on-policy
trajectory. We explicitly take into account the Markovian nature of sampling
and improve the best-known finite-time error bound from $O(1/\sqrt{T})$
to~$O(1/T)$, where $T$ is the total number of iterations.

    

### [[2006.02615] Double Generative Adversarial Networks for Conditional Independence Testing](http://arxiv.org/abs/2006.02615)


  In this article, we study the problem of high-dimensional conditional
independence testing, a key building block in statistics and machine learning.
We propose an inferential procedure based on double generative adversarial
networks (GANs). Specifically, we first introduce a double GANs framework to
learn two generators of the conditional distributions. We then integrate the
two generators to construct a test statistic, which takes the form of the
maximum of generalized covariance measures of multiple transformation
functions. We also employ data-splitting and cross-fitting to minimize the
conditions on the generators to achieve the desired asymptotic properties, and
employ multiplier bootstrap to obtain the corresponding $p$-value. We show that
the constructed test statistic is doubly robust, and the resulting test both
controls type-I error and has the power approaching one asymptotically. Also
notably, we establish those theoretical guarantees under much weaker and
practically more feasible conditions compared to the existing tests, and our
proposal gives a concrete example of how to utilize some state-of-the-art deep
learning tools, such as GANs, to help address a classical but challenging
statistical problem. We demonstrate the efficacy of our test through both
simulations and an application to an anti-cancer drug dataset. A Python
implementation of the proposed procedure is available at
this https URL.

    

### [[2006.05356] Scalable Thompson Sampling using Sparse Gaussian Process Models](http://arxiv.org/abs/2006.05356)


  Thompson Sampling (TS) from Gaussian Process (GP) models is a powerful tool
for the optimization of black-box functions. Although TS enjoys strong
theoretical guarantees and convincing empirical performance, it incurs a large
computational overhead that scales polynomially with the optimization budget.
Recently, scalable TS methods based on sparse GP models have been proposed to
increase the scope of TS, enabling its application to problems that are
sufficiently multi-modal, noisy or combinatorial to require more than a few
hundred evaluations to be solved. However, the approximation error introduced
by sparse GPs invalidates all existing regret bounds. In this work, we perform
a theoretical and empirical analysis of scalable TS. We provide theoretical
guarantees and show that the drastic reduction in computational complexity of
scalable TS can be enjoyed without loss in the regret performance over the
standard TS. These conceptual claims are validated for practical
implementations of scalable TS on synthetic benchmarks and as part of a
real-world high-throughput molecular design task.

    

### [[2009.08142] Online Algorithms for Estimating Change Rates of Web Pages](http://arxiv.org/abs/2009.08142)


  A search engine maintains local copies of different web pages to provide
quick search results. This local cache is kept up-to-date by a web crawler that
frequently visits these different pages to track changes in them. Ideally, the
local copy should be updated as soon as a page changes on the web. However,
finite bandwidth availability and server restrictions limit how frequently
different pages can be crawled. This brings forth the following optimization
problem: maximize the freshness of the local cache subject to the crawling
frequencies being within prescribed bounds. While tractable algorithms do exist
to solve this problem, these either assume the knowledge of exact page change
rates or use inefficient methods such as MLE for estimating the same. We
address this issue here.
We provide three novel schemes for online estimation of page change rates,
all of which have extremely low running times per iteration. The first is based
on the law of large numbers and the second on stochastic approximation. The
third is an extension of the second and includes a heavy-ball momentum term.
All these schemes only need partial information about the page change process,
i.e., they only need to know if the page has changed or not since the last
crawled instance. Our main theoretical results concern asymptotic convergence
and convergence rates of these three schemes. In fact, our work is the first to
show convergence of the original stochastic heavy-ball method when neither the
gradient nor the noise variance is uniformly bounded. We also provide some
numerical experiments (based on real and synthetic data) to demonstrate the
superiority of our proposed estimators over existing ones such as MLE. We
emphasize that our algorithms are also readily applicable to the
synchronization of databases and network inventory management.

    

### [[2010.00654] VAEBM: A Symbiosis between Variational Autoencoders and Energy-based Models](http://arxiv.org/abs/2010.00654)


  Energy-based models (EBMs) have recently been successful in representing
complex distributions of small images. However, sampling from them requires
expensive Markov chain Monte Carlo (MCMC) iterations that mix slowly in high
dimensional pixel space. Unlike EBMs, variational autoencoders (VAEs) generate
samples quickly and are equipped with a latent space that enables fast
traversal of the data manifold. However, VAEs tend to assign high probability
density to regions in data space outside the actual data distribution and often
fail at generating sharp images. In this paper, we propose VAEBM, a symbiotic
composition of a VAE and an EBM that offers the best of both worlds. VAEBM
captures the overall mode structure of the data distribution using a
state-of-the-art VAE and it relies on its EBM component to explicitly exclude
non-data-like regions from the model and refine the image samples. Moreover,
the VAE component in VAEBM allows us to speed up MCMC updates by
reparameterizing them in the VAE's latent space. Our experimental results show
that VAEBM outperforms state-of-the-art VAEs and EBMs in generative quality on
several benchmark image datasets by a large margin. It can generate
high-quality images as large as 256$\times$256 pixels with short MCMC chains.
We also demonstrate that VAEBM provides complete mode coverage and performs
well in out-of-distribution detection. The source code is available at
this https URL


### [[2010.09891] FLAG: Adversarial Data Augmentation for Graph Neural Networks](http://arxiv.org/abs/2010.09891)


  Data augmentation helps neural networks generalize better by enlarging the
training set, but it remains an open question how to effectively augment graph
data to enhance the performance of GNNs (Graph Neural Networks). While most
existing graph regularizers focus on manipulating graph topological structures
by adding/removing edges, we offer a method to augment node features for better
performance. We propose FLAG (Free Large-scale Adversarial Augmentation on
Graphs), which iteratively augments node features with gradient-based
adversarial perturbations during training. By making the model invariant to
small fluctuations in input data, our method helps models generalize to
out-of-distribution samples and boosts model performance at test time. FLAG is
a general-purpose approach for graph data, which universally works in node
classification, link prediction, and graph classification tasks. FLAG is also
highly flexible and scalable, and is deployable with arbitrary GNN backbones
and large-scale datasets. We demonstrate the efficacy and stability of our
method through extensive experiments and ablation studies. We also provide
intuitive observations for a deeper understanding of our method.

    

### [[2011.04476] Deep Learning for Flight Demand Forecasting](http://arxiv.org/abs/2011.04476)


  Inspired by the success of deep learning (DL) in natural language processing
(NLP), we applied cutting-edge DL techniques to predict flight departure demand
in a strategic time horizon (4 hours or longer). This work was conducted in
support of a MITRE-developed mobile application, Pacer, which displays
predicted departure demand to general aviation (GA) flight operators so they
can have better situation awareness of the potential for departure delays
during busy periods. Field demonstrations involving Pacer's previously designed
rule-based prediction method showed that the prediction accuracy of departure
demand still has room for improvement. This research strives to improve
prediction accuracy from two key aspects: better data sources and robust
forecasting algorithms. We leveraged two data sources, Aviation System
Performance Metrics (ASPM) and System Wide Information Management (SWIM), as
our input. We then trained forecasting models with DL techniques of sequence to
sequence (seq2seq) and seq2seq with attention. The case study has shown that
our seq2seq with attention performs best among four forecasting algorithms
tested. In addition, with better data sources, seq2seq with attention can
reduce mean squared error (mse) over 60%, compared to the classical
autoregressive (AR) forecasting method.

    

### [[2011.06507] Reinforcement Learning with Videos: Combining Offline Observations with Interaction](http://arxiv.org/abs/2011.06507)


  Reinforcement learning is a powerful framework for robots to acquire skills
from experience, but often requires a substantial amount of online data
collection. As a result, it is difficult to collect sufficiently diverse
experiences that are needed for robots to generalize broadly. Videos of humans,
on the other hand, are a readily available source of broad and interesting
experiences. In this paper, we consider the question: can we perform
reinforcement learning directly on experience collected by humans? This problem
is particularly difficult, as such videos are not annotated with actions and
exhibit substantial visual domain shift relative to the robot's embodiment. To
address these challenges, we propose a framework for reinforcement learning
with videos (RLV). RLV learns a policy and value function using experience
collected by humans in combination with data collected by robots. In our
experiments, we find that RLV is able to leverage such videos to learn
challenging vision-based skills with less than half as many samples as RL
methods that learn from scratch.

    

### [[2012.04576] Convergence Rates for Multi-classs Logistic Regression Near Minimum](http://arxiv.org/abs/2012.04576)


  In the current paper we provide constructive estimation of the convergence
rate for training a known class of neural networks: the multi-class logistic
regression. Despite several decades of successful use, our rigorous results
appear new, reflective of the gap between practice and theory of machine
learning. Training a neural network is typically done via variations of the
gradient descent method. If a minimum of the loss function exists and gradient
descent is used as the training method, we provide an expression that relates
learning rate to the rate of convergence to the minimum. The method involves an
estimate of the condition number of the Hessian of the loss function. We also
discuss the existence of a minimum, as it is not automatic that a minimum
exists. One method of ensuring convergence is by assigning positive probabiity
to every class in the training dataset.

    

### [[2102.06740] Appearance of Random Matrix Theory in Deep Learning](http://arxiv.org/abs/2102.06740)


  We investigate the local spectral statistics of the loss surface Hessians of
artificial neural networks, where we discover excellent agreement with Gaussian
Orthogonal Ensemble statistics across several network architectures and
datasets. These results shed new light on the applicability of Random Matrix
Theory to modelling neural networks and suggest a previously unrecognised role
for it in the study of loss surfaces in deep learning. Inspired by these
observations, we propose a novel model for the true loss surfaces of neural
networks, consistent with our observations, which allows for Hessian spectral
densities with rank degeneracy and outliers, extensively observed in practice,
and predicts a growing independence of loss gradients as a function of distance
in weight-space. We further investigate the importance of the true loss surface
in neural networks and find, in contrast to previous work, that the exponential
hardness of locating the global minimum has practical consequences for
achieving state of the art performance.

    

### [[2103.12452] Bandits with many optimal arms](http://arxiv.org/abs/2103.12452)


  We consider a stochastic bandit problem with a possibly infinite number of
arms. We write $p^*$ for the proportion of optimal arms and $\Delta$ for the
minimal mean-gap between optimal and sub-optimal arms. We characterize the
optimal learning rates both in the cumulative regret setting, and in the
best-arm identification setting in terms of the problem parameters $T$ (the
budget), $p^*$ and $\Delta$. For the objective of minimizing the cumulative
regret, we provide a lower bound of order $\Omega(\log(T)/(p^*\Delta))$ and a
UCB-style algorithm with matching upper bound up to a factor of
$\log(1/\Delta)$. Our algorithm needs $p^*$ to calibrate its parameters, and we
prove that this knowledge is necessary, since adapting to $p^*$ in this setting
is impossible. For best-arm identification we also provide a lower bound of
order $\Omega(\exp(-cT\Delta^2 p^*))$ on the probability of outputting a
sub-optimal arm where $c>0$ is an absolute constant. We also provide an
elimination algorithm with an upper bound matching the lower bound up to a
factor of order $\log(T)$ in the exponential, and that does not need $p^*$ or
$\Delta$ as parameter. Our results apply directly to the three related problems
of competing against the $j$-th best arm, identifying an $\epsilon$ good arm,
and finding an arm with mean larger than a quantile of a known order.

    

### [[2103.13443] Blind Speech Separation and Dereverberation using Neural Beamforming](http://arxiv.org/abs/2103.13443)


  In this paper, we present the Blind Speech Separation and Dereverberation
(BSSD) network, which performs simultaneous speaker separation, dereverberation
and speaker identification in a single neural network. Speaker separation is
guided by a set of predefined spatial cues. Dereverberation is performed by
using neural beamforming, and speaker identification is aided by embedding
vectors and triplet mining. We introduce a frequency-domain model which uses
complex-valued neural networks, and a time-domain variant which performs
beamforming in latent space. Further, we propose a block-online mode to process
longer audio recordings, as they occur in meeting scenarios. We evaluate our
system in terms of Scale Independent Signal to Distortion Ratio (SI-SDR), Word
Error Rate (WER) and Equal Error Rate (EER).

    

### [[2104.06176] COVID-19 detection using chest X-rays: is lung segmentation important for generalization?](http://arxiv.org/abs/2104.06176)


  We evaluated the generalization capability of deep neural networks (DNNs),
trained to classify chest X-rays as COVID-19, normal or pneumonia, using a
relatively small and mixed dataset. We proposed a DNN to perform lung
segmentation and classification, stacking a segmentation module (U-Net), an
original intermediate module and a classification module (DenseNet201). To
evaluate generalization, we tested the DNN with an external dataset (from
distinct localities) and used Bayesian inference to estimate probability
distributions of performance metrics. Our DNN achieved 0.917 AUC on the
external test dataset, and a DenseNet without segmentation, 0.906. Bayesian
inference indicated mean accuracy of 76.1% and [0.695, 0.826] 95% HDI (high
density interval, which concentrates 95% of the metric's probability mass) with
segmentation and, without segmentation, 71.7% and [0.646, 0.786]. We proposed a
novel DNN evaluation technique, using Layer-wise Relevance Propagation (LRP)
and Brixia scores. LRP heatmaps indicated that areas where radiologists found
strong COVID-19 symptoms and attributed high Brixia scores are the most
important for the stacked DNN classification. External validation showed
smaller accuracies than internal, indicating difficulty in generalization,
which segmentation improves. Performance in the external dataset and LRP
analysis suggest that DNNs can be trained in small and mixed datasets and
detect COVID-19.

    

### [[2105.01303] Personalized Algorithm Generation: A Case Study in Meta-Learning ODE Integrators](http://arxiv.org/abs/2105.01303)


  We study the meta-learning of numerical algorithms for scientific computing,
which combines the mathematically driven, handcrafted design of general
algorithm structure with a data-driven adaptation to specific classes of tasks.
This represents a departure from the classical approaches in numerical
analysis, which typically do not feature such learning-based adaptations. As a
case study, we develop a machine learning approach that automatically learns
effective solvers for initial value problems in the form of ordinary
differential equations (ODEs), based on the Runge-Kutta (RK) integrator
architecture. By combining neural network approximations and meta-learning, we
show that we can obtain high-order integrators for targeted families of
differential equations without the need for computing integrator coefficients
by hand. Moreover, we demonstrate that in certain cases we can obtain superior
performance to classical RK methods. This can be attributed to certain
properties of the ODE families being identified and exploited by the approach.
Overall, this work demonstrates an effective, learning-based approach to the
design of algorithms for the numerical solution of differential equations, an
approach that can be readily extended to other numerical tasks.

    

### [[2105.13290] CogView: Mastering Text-to-Image Generation via Transformers](http://arxiv.org/abs/2105.13290)


  Text-to-Image generation in the general domain has long been an open problem,
which requires both a powerful generative model and cross-modal understanding.
We propose CogView, a 4-billion-parameter Transformer with VQ-VAE tokenizer to
advance this problem. We also demonstrate the finetuning strategies for various
downstream tasks, e.g. style learning, super-resolution, text-image ranking and
fashion design, and methods to stabilize pretraining, e.g. eliminating NaN
losses. CogView achieves the state-of-the-art FID on the blurred MS COCO
dataset, outperforming previous GAN-based models and a recent similar work
DALL-E.

    

### [[2105.13889] Equilibrium and non-Equilibrium regimes in the learning of Restricted Boltzmann Machines](http://arxiv.org/abs/2105.13889)


  Training Restricted Boltzmann Machines (RBMs) has been challenging for a long
time due to the difficulty of computing precisely the log-likelihood gradient.
Over the past decades, many works have proposed more or less successful
training recipes but without studying the crucial quantity of the problem: the
mixing time, i.e. the number of Monte Carlo iterations needed to sample new
configurations from a model. In this work, we show that this mixing time plays
a crucial role in the dynamics and stability of the trained model, and that
RBMs operate in two well-defined regimes, namely equilibrium and
out-of-equilibrium, depending on the interplay between this mixing time of the
model and the number of steps, $k$, used to approximate the gradient. We
further show empirically that this mixing time increases with the learning,
which often implies a transition from one regime to another as soon as $k$
becomes smaller than this time. In particular, we show that using the popular
$k$ (persistent) contrastive divergence approaches, with $k$ small, the
dynamics of the learned model are extremely slow and often dominated by strong
out-of-equilibrium effects. On the contrary, RBMs trained in equilibrium
display faster dynamics, and a smooth convergence to dataset-like
configurations during the sampling. Finally we discuss how to exploit in
practice both regimes depending on the task one aims to fulfill: (i) short $k$
can be used to generate convincing samples in short learning times, (ii) large
$k$ (or increasingly large) is needed to learn the correct equilibrium
distribution of the RBM. Finally, the existence of these two operational
regimes seems to be a general property of energy based models trained via
likelihood maximization.

    

### [[2106.05397] From inexact optimization to learning via gradient concentration](http://arxiv.org/abs/2106.05397)


  Optimization in machine learning typically deals with the minimization of
empirical objectives defined by training data. However, the ultimate goal of
learning is to minimize the error on future data (test error), for which the
training data provides only partial information. In this view, the optimization
problems that are practically feasible are based on inexact quantities that are
stochastic in nature. In this paper, we show how probabilistic results,
specifically gradient concentration, can be combined with results from inexact
optimization to derive sharp test error guarantees. By considering
unconstrained objectives we highlight the implicit regularization properties of
optimization for learning.

    

### [[2106.06926] Bellman-consistent Pessimism for Offline Reinforcement Learning](http://arxiv.org/abs/2106.06926)


  The use of pessimism, when reasoning about datasets lacking exhaustive
exploration has recently gained prominence in offline reinforcement learning.
Despite the robustness it adds to the algorithm, overly pessimistic reasoning
can be equally damaging in precluding the discovery of good policies, which is
an issue for the popular bonus-based pessimism. In this paper, we introduce the
notion of Bellman-consistent pessimism for general function approximation:
instead of calculating a point-wise lower bound for the value function, we
implement pessimism at the initial state over the set of functions consistent
with the Bellman equations. Our theoretical guarantees only require Bellman
closedness as standard in the exploratory setting, in which case bonus-based
pessimism fails to provide guarantees. Even in the special case of linear
function approximation where stronger expressivity assumptions hold, our result
improves upon a recent bonus-based approach by $\mathcal{O}(d)$ in its sample
complexity when the action space is finite. Remarkably, our algorithms
automatically adapt to the best bias-variance tradeoff in the hindsight,
whereas most prior approaches require tuning extra hyperparameters a priori.

    

### [[2106.07148] On the Sample Complexity of Learning under Invariance and Geometric Stability](http://arxiv.org/abs/2106.07148)


  Many supervised learning problems involve high-dimensional data such as
images, text, or graphs. In order to make efficient use of data, it is often
useful to leverage certain geometric priors in the problem at hand, such as
invariance to translations, permutation subgroups, or stability to small
deformations. We study the sample complexity of learning problems where the
target function presents such invariance and stability properties, by
considering spherical harmonic decompositions of such functions on the sphere.
We provide non-parametric rates of convergence for kernel methods, and show
improvements in sample complexity by a factor equal to the size of the group
when using an invariant kernel over the group, compared to the corresponding
non-invariant kernel. These improvements are valid when the sample size is
large enough, with an asymptotic behavior that depends on spectral properties
of the group. Finally, these gains are extended beyond invariance groups to
also cover geometric stability to small deformations, modeled here as subsets
(not necessarily subgroups) of permutations.

    

### [[2106.08881] Nonparametric Empirical Bayes Estimation and Testing for Sparse and Heteroscedastic Signals](http://arxiv.org/abs/2106.08881)


  Large-scale modern data often involves estimation and testing for
high-dimensional unknown parameters. It is desirable to identify the sparse
signals, ``the needles in the haystack'', with accuracy and false discovery
control. However, the unprecedented complexity and heterogeneity in modern data
structure require new machine learning tools to effectively exploit
commonalities and to robustly adjust for both sparsity and heterogeneity. In
addition, estimates for high-dimensional parameters often lack uncertainty
quantification. In this paper, we propose a novel Spike-and-Nonparametric
mixture prior (SNP) -- a spike to promote the sparsity and a nonparametric
structure to capture signals. In contrast to the state-of-the-art methods, the
proposed methods solve the estimation and testing problem at once with several
merits: 1) an accurate sparsity estimation; 2) point estimates with
shrinkage/soft-thresholding property; 3) credible intervals for uncertainty
quantification; 4) an optimal multiple testing procedure that controls false
discovery rate. Our method exhibits promising empirical performance on both
simulated data and a gene expression case study.

    

### [[2106.09019] Amortized Synthesis of Constrained Configurations Using a Differentiable Surrogate](http://arxiv.org/abs/2106.09019)


  In design, fabrication, and control problems, we are often faced with the
task of synthesis, in which we must generate an object or configuration that
satisfies a set of constraints while maximizing one or more objective
functions. The synthesis problem is typically characterized by a physical
process in which many different realizations may achieve the goal. This
many-to-one map presents challenges to the supervised learning of feed-forward
synthesis, as the set of viable designs may have a complex structure. In
addition, the non-differentiable nature of many physical simulations prevents
efficient direct optimization. We address both of these problems with a
two-stage neural network architecture that we may consider to be an
autoencoder. We first learn the decoder: a differentiable surrogate that
approximates the many-to-one physical realization process. We then learn the
encoder, which maps from goal to design, while using the fixed decoder to
evaluate the quality of the realization. We evaluate the approach on two case
studies: extruder path planning in additive manufacturing and constrained soft
robot inverse kinematics. We compare our approach to direct optimization of the
design using the learned surrogate, and to supervised learning of the synthesis
problem. We find that our approach produces higher quality solutions than
supervised learning, while being competitive in quality with direct
optimization, at a greatly reduced computational cost.

    

### [[2106.11189] Well-tuned Simple Nets Excel on Tabular Datasets](http://arxiv.org/abs/2106.11189)


  Tabular datasets are the last "unconquered castle" for deep learning, with
traditional ML methods like Gradient-Boosted Decision Trees still performing
strongly even against recent specialized neural architectures. In this paper,
we hypothesize that the key to boosting the performance of neural networks lies
in rethinking the joint and simultaneous application of a large set of modern
regularization techniques. As a result, we propose regularizing plain
Multilayer Perceptron (MLP) networks by searching for the optimal
combination/cocktail of 13 regularization techniques for each dataset using a
joint optimization over the decision on which regularizers to apply and their
subsidiary hyperparameters. We empirically assess the impact of these
regularization cocktails for MLPs in a large-scale empirical study comprising
40 tabular datasets and demonstrate that (i) well-regularized plain MLPs
significantly outperform recent state-of-the-art specialized neural network
architectures, and (ii) they even outperform strong traditional ML methods,
such as XGBoost.

    

### [[2106.13280] Hierarchically Integrated Models: Learning to Navigate from Heterogeneous Robots](http://arxiv.org/abs/2106.13280)


  Deep reinforcement learning algorithms require large and diverse datasets in
order to learn successful policies for perception-based mobile navigation.
However, gathering such datasets with a single robot can be prohibitively
expensive. Collecting data with multiple different robotic platforms with
possibly different dynamics is a more scalable approach to large-scale data
collection. But how can deep reinforcement learning algorithms leverage such
heterogeneous datasets? In this work, we propose a deep reinforcement learning
algorithm with hierarchically integrated models (HInt). At training time, HInt
learns separate perception and dynamics models, and at test time, HInt
integrates the two models in a hierarchical manner and plans actions with the
integrated model. This method of planning with hierarchically integrated models
allows the algorithm to train on datasets gathered by a variety of different
platforms, while respecting the physical capabilities of the deployment robot
at test time. Our mobile navigation experiments show that HInt outperforms
conventional hierarchical policies and single-source approaches.

    

### [[2106.13358] Scalable Perception-Action-Communication Loops with Convolutional and Graph Neural Networks](http://arxiv.org/abs/2106.13358)


  In this paper, we present a perception-action-communication loop design using
Vision-based Graph Aggregation and Inference (VGAI). This multi-agent
decentralized learning-to-control framework maps raw visual observations to
agent actions, aided by local communication among neighboring agents. Our
framework is implemented by a cascade of a convolutional and a graph neural
network (CNN / GNN), addressing agent-level visual perception and feature
learning, as well as swarm-level communication, local information aggregation
and agent action inference, respectively. By jointly training the CNN and GNN,
image features and communication messages are learned in conjunction to better
address the specific task. We use imitation learning to train the VGAI
controller in an offline phase, relying on a centralized expert controller.
This results in a learned VGAI controller that can be deployed in a distributed
manner for online execution. Additionally, the controller exhibits good scaling
properties, with training in smaller teams and application in larger teams.
Through a multi-agent flocking application, we demonstrate that VGAI yields
performance comparable to or better than other decentralized controllers, using
only the visual input modality and without accessing precise location or motion
state information.

    

### [[2106.15013] Small random initialization is akin to spectral learning: Optimization and generalization guarantees for overparameterized low-rank matrix reconstruction](http://arxiv.org/abs/2106.15013)


  Recently there has been significant theoretical progress on understanding the
convergence and generalization of gradient-based methods on nonconvex losses
with overparameterized models. Nevertheless, many aspects of optimization and
generalization and in particular the critical role of small random
initialization are not fully understood. In this paper, we take a step towards
demystifying this role by proving that small random initialization followed by
a few iterations of gradient descent behaves akin to popular spectral methods.
We also show that this implicit spectral bias from small random initialization,
which is provably more prominent for overparameterized models, also puts the
gradient descent iterations on a particular trajectory towards solutions that
are not only globally optimal but also generalize well. Concretely, we focus on
the problem of reconstructing a low-rank matrix from a few measurements via a
natural nonconvex formulation. In this setting, we show that the trajectory of
the gradient descent iterations from small random initialization can be
approximately decomposed into three phases: (I) a spectral or alignment phase
where we show that that the iterates have an implicit spectral bias akin to
spectral initialization allowing us to show that at the end of this phase the
column space of the iterates and the underlying low-rank matrix are
sufficiently aligned, (II) a saddle avoidance/refinement phase where we show
that the trajectory of the gradient iterates moves away from certain degenerate
saddle points, and (III) a local refinement phase where we show that after
avoiding the saddles the iterates converge quickly to the underlying low-rank
matrix. Underlying our analysis are insights for the analysis of
overparameterized nonconvex optimization schemes that may have implications for
computational problems beyond low-rank reconstruction.

    

### [[2106.16200] Revisiting the Effects of Stochasticity for Hamiltonian Samplers](http://arxiv.org/abs/2106.16200)


  We revisit the theoretical properties of Hamiltonian stochastic differential
equations (SDES) for Bayesian posterior sampling, and we study the two types of
errors that arise from numerical SDE simulation: the discretization error and
the error due to noisy gradient estimates in the context of data subsampling.
Our main result is a novel analysis for the effect of mini-batches through the
lens of differential operator splitting, revising previous literature results.
The stochastic component of a Hamiltonian SDE is decoupled from the gradient
noise, for which we make no normality assumptions. This leads to the
identification of a convergence bottleneck: when considering mini-batches, the
best achievable error rate is $\mathcal{O}(\eta^2)$, with $\eta$ being the
integrator step size. Our theoretical results are supported by an empirical
study on a variety of regression and classification tasks for Bayesian neural
networks.

    

### [[2108.10105] Deep learning for surrogate modelling of 2D mantle convection](http://arxiv.org/abs/2108.10105)


  Traditionally, 1D models based on scaling laws have been used to
parameterized convective heat transfer rocks in the interior of terrestrial
planets like Earth, Mars, Mercury and Venus to tackle the computational
bottleneck of high-fidelity forward runs in 2D or 3D. However, these are
limited in the amount of physics they can model (e.g. depth dependent material
properties) and predict only mean quantities such as the mean mantle
temperature. We recently showed that feedforward neural networks (FNN) trained
using a large number of 2D simulations can overcome this limitation and
reliably predict the evolution of entire 1D laterally-averaged temperature
profile in time for complex models. We now extend that approach to predict the
full 2D temperature field, which contains more information in the form of
convection structures such as hot plumes and cold downwellings. Using a dataset
of 10,525 two-dimensional simulations of the thermal evolution of the mantle of
a Mars-like planet, we show that deep learning techniques can produce reliable
parameterized surrogates (i.e. surrogates that predict state variables such as
temperature based only on parameters) of the underlying partial differential
equations. We first use convolutional autoencoders to compress the temperature
fields by a factor of 142 and then use FNN and long-short term memory networks
(LSTM) to predict the compressed fields. On average, the FNN predictions are
99.30% and the LSTM predictions are 99.22% accurate with respect to unseen
simulations. Proper orthogonal decomposition (POD) of the LSTM and FNN
predictions shows that despite a lower mean absolute relative accuracy, LSTMs
capture the flow dynamics better than FNNs. When summed, the POD coefficients
from FNN predictions and from LSTM predictions amount to 96.51% and 97.66%
relative to the coefficients of the original simulations, respectively.

    

### [[2110.12884] DECAF: Generating Fair Synthetic Data Using Causally-Aware Generative Networks](http://arxiv.org/abs/2110.12884)


  Machine learning models have been criticized for reflecting unfair biases in
the training data. Instead of solving for this by introducing fair learning
algorithms directly, we focus on generating fair synthetic data, such that any
downstream learner is fair. Generating fair synthetic data from unfair data -
while remaining truthful to the underlying data-generating process (DGP) - is
non-trivial. In this paper, we introduce DECAF: a GAN-based fair synthetic data
generator for tabular data. With DECAF we embed the DGP explicitly as a
structural causal model in the input layers of the generator, allowing each
variable to be reconstructed conditioned on its causal parents. This procedure
enables inference time debiasing, where biased edges can be strategically
removed for satisfying user-defined fairness requirements. The DECAF framework
is versatile and compatible with several popular definitions of fairness. In
our experiments, we show that DECAF successfully removes undesired bias and -
in contrast to existing methods - is capable of generating high-quality
synthetic data. Furthermore, we provide theoretical guarantees on the
generator's convergence and the fairness of downstream models.

    

### [[2110.12658] Operator Augmentation for Model-based Policy Evaluation](http://arxiv.org/abs/2110.12658)


  In model-based reinforcement learning, the transition matrix and reward
vector are often estimated from random samples subject to noise. Even if the
estimated model is an unbiased estimate of the true underlying model, the value
function computed from the estimated model is biased. We introduce an operator
augmentation method for reducing the error introduced by the estimated model.
When the error is in the residual norm, we prove that the augmentation factor
is always positive and upper bounded by $1 + O (1/n)$, where n is the number of
samples used in learning each row of the transition matrix. We also propose a
practical numerical algorithm for implementing the operator augmentation.

    

### [[2111.03297] RC-RNN: Reconfigurable Cache Architecture for Storage Systems Using Recurrent Neural Networks](http://arxiv.org/abs/2111.03297)


  Solid-State Drives (SSDs) have significant performance advantages over
traditional Hard Disk Drives (HDDs) such as lower latency and higher
throughput. Significantly higher price per capacity and limited lifetime,
however, prevents designers to completely substitute HDDs by SSDs in enterprise
storage systems. SSD-based caching has recently been suggested for storage
systems to benefit from higher performance of SSDs while minimizing the overall
cost. While conventional caching algorithms such as Least Recently Used (LRU)
provide high hit ratio in processors, due to the highly random behavior of
Input/Output (I/O) workloads, they hardly provide the required performance
level for storage systems. In addition to poor performance, inefficient
algorithms also shorten SSD lifetime with unnecessary cache replacements. Such
shortcomings motivate us to benefit from more complex non-linear algorithms to
achieve higher cache performance and extend SSD lifetime. In this paper, we
propose RC-RNN, the first reconfigurable SSD-based cache architecture for
storage systems that utilizes machine learning to identify performance-critical
data pages for I/O caching. The proposed architecture uses Recurrent Neural
Networks (RNN) to characterize ongoing workloads and optimize itself towards
higher cache performance while improving SSD lifetime. RC-RNN attempts to learn
characteristics of the running workload to predict its behavior and then uses
the collected information to identify performance-critical data pages to fetch
into the cache. Experimental results show that RC-RNN characterizes workloads
with an accuracy up to 94.6% for SNIA I/O workloads. RC-RNN can perform
similarly to the optimal cache algorithm by an accuracy of 95% on average, and
outperforms previous SSD caching architectures by providing up to 7x higher hit
ratio and decreasing cache replacements by up to 2x.

    

### [[2111.03307] PIM-Enclave: Bringing Confidential Computation Inside Memory](http://arxiv.org/abs/2111.03307)


  Demand for data-intensive workloads and confidential computing are the
prominent research directions shaping the future of cloud computing. Computer
architectures are evolving to accommodate the computing of large data better.
Protecting the computation of sensitive data is also an imperative yet
challenging objective; processor-supported secure enclaves serve as the key
element in confidential computing in the cloud. However, side-channel attacks
are threatening their security boundaries. The current processor architectures
consume a considerable portion of its cycles in moving data. Near data
computation is a promising approach that minimizes redundant data movement by
placing computation inside storage. In this paper, we present a novel design
for Processing-In-Memory (PIM) as a data-intensive workload accelerator for
confidential computing. Based on our observation that moving computation closer
to memory can achieve efficiency of computation and confidentiality of the
processed information simultaneously, we study the advantages of confidential
computing \emph{inside} memory. We then explain our security model and
programming model developed for PIM-based computation offloading. We construct
our findings into a software-hardware co-design, which we call PIM-Enclave. Our
design illustrates the advantages of PIM-based confidential computing
acceleration. Our evaluation shows PIM-Enclave can provide a side-channel
resistant secure computation offloading and run data-intensive applications
with negligible performance overhead compared to baseline PIM model.

    

### [[2111.03065] Safe and Practical GPU Acceleration in TrustZone](http://arxiv.org/abs/2111.03065)


  We present a holistic design for GPU-accelerated computation in TrustZone
TEE. Without pulling the complex GPU software stack into the TEE, we follow a
simple approach: record the CPU/GPU interactions ahead of time, and replay the
interactions in the TEE at run time. This paper addresses the approach's key
missing piece -- the recording environment, which needs both strong security
and access to diverse mobile GPUs. To this end, we present a novel architecture
called CODY, in which a mobile device (which possesses the GPU hardware) and a
trustworthy cloud service (which runs the GPU software) exercise the GPU
hardware/software in a collaborative, distributed fashion. To overcome numerous
network round trips and long delays, CODY contributes optimizations specific to
mobile GPUs: register access deferral, speculation, and metastate-only
synchronization. With these optimizations, recording a compute workload takes
only tens of seconds, which is up to 95% less than a naive approach; replay
incurs 25% lower delays compared to insecure, native execution.

    

### [[2111.03395] Predictive Replica Placement for Mobile Users in Distributed Fog Data Stores with Client-Side Markov Models](http://arxiv.org/abs/2111.03395)


  Mobile clients that consume and produce data are abundant in fog environments
and low latency access to this data can only be achieved by storing it in their
close physical proximity. To adapt data replication in fog data stores in an
efficient manner and make client data available at the fog node that is closest
to the client, the systems need to predict both client movement and pauses in
data consumption.
In this paper, we present variations of Markov model algorithms that can run
on clients to increase the data availability while minimizing excess data. In a
simulation, we find the availability of data at the closest node can be
improved by 35% without incurring the storage and communication overheads of
global replication.

    

### [[2010.15718] Minimal Model Structure Analysis for Input Reconstruction in Federated Learning](http://arxiv.org/abs/2010.15718)


  \ac{fl} proposed a distributed \ac{ml} framework where every distributed
worker owns a complete copy of global model and their own data. The training is
occurred locally, which assures no direct transmission of training data.
However, the recent work \citep{zhu2019deep} demonstrated that input data from
a neural network may be reconstructed only using knowledge of gradients of that
network, which completely breached the promise of \ac{fl} and sabotaged the
user privacy.
In this work, we aim to further explore the theoretical limits of
reconstruction, speedup and stabilize the reconstruction procedure. We show
that a single input may be reconstructed with the analytical form, regardless
of network depth using a fully-connected neural network with one hidden node.
Then we generalize this result to a gradient averaged over batches of size $B$.
In this case, the full batch can be reconstructed if the number of hidden units
exceeds $B$. For a \ac{cnn}, the number of required kernels in convolutional
layers is decided by multiple factors, e.g., padding, kernel and stride size,
etc. We require the number of kernels $h\geq (\frac{d}{d^{\prime}})^2C$, where
we define $d$ as input width, $d^{\prime}$ as output width after convolutional
layer, and $C$ as channel number of input. We validate our observation and
demonstrate the improvements using bio-medical (fMRI, \ac{wbc}) and benchmark
data (MNIST, Kuzushiji-MNIST, CIFAR100, ImageNet and face images).

    

### [[2111.03106] Skeleton-Split Framework using Spatial Temporal Graph Convolutional Networks for Action Recogntion](http://arxiv.org/abs/2111.03106)


  There has been a dramatic increase in the volume of videos and their related
content uploaded to the internet. Accordingly, the need for efficient
algorithms to analyse this vast amount of data has attracted significant
research interest. An action recognition system based upon human body motions
has been proven to interpret videos contents accurately. This work aims to
recognize activities of daily living using the ST-GCN model, providing a
comparison between four different partitioning strategies: spatial
configuration partitioning, full distance split, connection split, and index
split. To achieve this aim, we present the first implementation of the ST-GCN
framework upon the HMDB-51 dataset. We have achieved 48.88 % top-1 accuracy by
using the connection split partitioning approach. Through experimental
simulation, we show that our proposals have achieved the highest accuracy
performance on the UCF-101 dataset using the ST-GCN framework than the
state-of-the-art approach. Finally, accuracy of 73.25 % top-1 is achieved by
using the index split partitioning strategy.

    

### [[2111.03186] EditGAN: High-Precision Semantic Image Editing](http://arxiv.org/abs/2111.03186)


  Generative adversarial networks (GANs) have recently found applications in
image editing. However, most GAN based image editing methods often require
large scale datasets with semantic segmentation annotations for training, only
provide high level control, or merely interpolate between different images.
Here, we propose EditGAN, a novel method for high quality, high precision
semantic image editing, allowing users to edit images by modifying their highly
detailed part segmentation masks, e.g., drawing a new mask for the headlight of
a car. EditGAN builds on a GAN framework that jointly models images and their
semantic segmentations, requiring only a handful of labeled examples, making it
a scalable tool for editing. Specifically, we embed an image into the GAN
latent space and perform conditional latent code optimization according to the
segmentation edit, which effectively also modifies the image. To amortize
optimization, we find editing vectors in latent space that realize the edits.
The framework allows us to learn an arbitrary number of editing vectors, which
can then be directly applied on other images at interactive rates. We
experimentally show that EditGAN can manipulate images with an unprecedented
level of detail and freedom, while preserving full image quality.We can also
easily combine multiple edits and perform plausible edits beyond EditGAN
training data. We demonstrate EditGAN on a wide variety of image types and
quantitatively outperform several previous editing methods on standard editing
benchmark tasks.

    

### [[2111.03204] Learning Model Predictive Controllers for Real-Time Ride-Hailing Vehicle Relocation and Pricing Decisions](http://arxiv.org/abs/2111.03204)


  Large-scale ride-hailing systems often combine real-time routing at the
individual request level with a macroscopic Model Predictive Control (MPC)
optimization for dynamic pricing and vehicle relocation. The MPC relies on a
demand forecast and optimizes over a longer time horizon to compensate for the
myopic nature of the routing optimization. However, the longer horizon
increases computational complexity and forces the MPC to operate at coarser
spatial-temporal granularity, degrading the quality of its decisions. This
paper addresses these computational challenges by learning the MPC
optimization. The resulting machine-learning model then serves as the
optimization proxy and predicts its optimal solutions. This makes it possible
to use the MPC at higher spatial-temporal fidelity, since the optimizations can
be solved and learned offline. Experimental results show that the proposed
approach improves quality of service on challenging instances from the New York
City dataset.

    

### [[2111.03284] Dialogue Inspectional Summarization with Factual Inconsistency Awareness](http://arxiv.org/abs/2111.03284)


  Dialogue summarization has been extensively studied and applied, where the
prior works mainly focused on exploring superior model structures to align the
input dialogue and the output summary. However, for professional dialogues
(e.g., legal debate and medical diagnosis), semantic/statistical alignment can
hardly fill the logical/factual gap between input dialogue discourse and
summary output with external knowledge. In this paper, we mainly investigate
the factual inconsistency problem for Dialogue Inspectional Summarization (DIS)
under non-pretraining and pretraining settings. An innovative end-to-end
dialogue summary generation framework is proposed with two auxiliary tasks:
Expectant Factual Aspect Regularization (EFAR) and Missing Factual Entity
Discrimination (MFED). Comprehensive experiments demonstrate that the proposed
model can generate a more readable summary with accurate coverage of factual
aspects as well as informing the user with potential missing facts detected
from the input dialogue for further human intervention.

    

### [[2111.03320] On the Impact of Temporal Representations on Metaphor Detection](http://arxiv.org/abs/2111.03320)


  State-of-the-art approaches for metaphor detection compare their literal - or
core - meaning and their contextual meaning using sequential metaphor
classifiers based on neural networks. The signal that represents the literal
meaning is often represented by (non-contextual) word embeddings. However,
metaphorical expressions evolve over time due to various reasons, such as
cultural and societal impact. Metaphorical expressions are known to co-evolve
with language and literal word meanings, and even drive, to some extent, this
evolution. This rises the question whether different, possibly time-specific,
representations of literal meanings may impact on the metaphor detection task.
To the best of our knowledge, this is the first study which examines the
metaphor detection task with a detailed exploratory analysis where different
temporal and static word embeddings are used to account for different
representations of literal meanings. Our experimental analysis is based on
three popular benchmarks used for metaphor detection and word embeddings
extracted from different corpora and temporally aligned to different
state-of-the-art approaches. The results suggest that different word embeddings
do impact on the metaphor detection task and some temporal word embeddings
slightly outperform static methods on some performance measures. However,
results also suggest that temporal word embeddings may provide representations
of words' core meaning even too close to their metaphorical meaning, thus
confusing the classifier. Overall, the interaction between temporal language
evolution and metaphor detection appears tiny in the benchmark datasets used in
our experiments. This suggests that future work for the computational analysis
of this important linguistic phenomenon should first start by creating a new
dataset where this interaction is better represented.

    

### [[2111.03414] Structure-aware Image Inpainting with Two Parallel Streams](http://arxiv.org/abs/2111.03414)


  Recent works in image inpainting have shown that structural information plays
an important role in recovering visually pleasing results. In this paper, we
propose an end-to-end architecture composed of two parallel UNet-based streams:
a main stream (MS) and a structure stream (SS). With the assistance of SS, MS
can produce plausible results with reasonable structures and realistic details.
Specifically, MS reconstructs detailed images by inferring missing structures
and textures simultaneously, and SS restores only missing structures by
processing the hierarchical information from the encoder of MS. By interacting
with SS in the training process, MS can be implicitly encouraged to exploit
structural cues. In order to help SS focus on structures and prevent textures
in MS from being affected, a gated unit is proposed to depress
structure-irrelevant activations in the information flow between MS and SS.
Furthermore, the multi-scale structure feature maps in SS are utilized to
explicitly guide the structure-reasonable image reconstruction in the decoder
of MS through the fusion block. Extensive experiments on CelebA, Paris
StreetView and Places2 datasets demonstrate that our proposed method
outperforms state-of-the-art methods.

    

### [[2111.03433] Numerisation D'un Siecle de Paysage Ferroviaire Français : recul du rail, conséquences territoriales et coût environnemental](http://arxiv.org/abs/2111.03433)


  The reconstruction of geographical data over a century, allows to figuring
out the evolution of the French railway landscape, and how it has been impacted
by major events (eg.: WWII), or longer time span processes : industry
outsourcing, metropolization, public transport policies or absence of them.
This work is resulting from the fusion of several public geographical data
(SNCF, IGN), enriched with the computer-assisted addition of multiple data
gathered on the Internet (Wikipedia, volunteer geographic information). The
dataset compounds almost every rail stations (even simple stops) and railway
branch nodes, whose link to their respective rail lines allows to build the
underlying consistent graph of the network. Every rail line has a "valid to"
date (or approx) so that time evolution can be displayed. The present progress
of that reconstruction sums up to roughly 90% of what is expected (exact total
unknown). This allows to consider temporal demographic analysis (how many
cities and towns served by the railway since 1925 up on today), and
environmental simulations as well (CO2 cost by given destination ).

    

### [[2111.03465] Spatio-Temporal Urban Knowledge Graph Enabled Mobility Prediction](http://arxiv.org/abs/2111.03465)


  With the rapid development of the mobile communication technology, mobile
trajectories of humans are massively collected by Internet service providers
(ISPs) and application service providers (ASPs). On the other hand, the rising
paradigm of knowledge graph (KG) provides us a promising solution to extract
structured "knowledge" from massive trajectory data. In this paper, we focus on
modeling users' spatio-temporal mobility patterns based on knowledge graph
techniques, and predicting users' future movement based on the ``knowledge''
extracted from multiple sources in a cohesive manner. Specifically, we propose
a new type of knowledge graph, i.e., spatio-temporal urban knowledge graph
(STKG), where mobility trajectories, category information of venues, and
temporal information are jointly modeled by the facts with different relation
types in STKG. The mobility prediction problem is converted to the knowledge
graph completion problem in STKG. Further, a complex embedding model with
elaborately designed scoring functions is proposed to measure the plausibility
of facts in STKG to solve the knowledge graph completion problem, which
considers temporal dynamics of the mobility patterns and utilizes PoI
categories as the auxiliary information and background knowledge. Extensive
evaluations confirm the high accuracy of our model in predicting users'
mobility, i.e., improving the accuracy by 5.04% compared with the
state-of-the-art algorithms. In addition, PoI categories as the background
knowledge and auxiliary information are confirmed to be helpful by improving
the performance by 3.85% in terms of accuracy. Additionally, experiments show
that our proposed method is time-efficient by reducing the computational time
by over 43.12% compared with existing methods.

    

### [[2111.03480] DriveGuard: Robustification of Automated Driving Systems with Deep Spatio-Temporal Convolutional Autoencoder](http://arxiv.org/abs/2111.03480)


  Autonomous vehicles increasingly rely on cameras to provide the input for
perception and scene understanding and the ability of these models to classify
their environment and objects, under adverse conditions and image noise is
crucial. When the input is, either unintentionally or through targeted attacks,
deteriorated, the reliability of autonomous vehicle is compromised. In order to
mitigate such phenomena, we propose DriveGuard, a lightweight spatio-temporal
autoencoder, as a solution to robustify the image segmentation process for
autonomous vehicles. By first processing camera images with DriveGuard, we
offer a more universal solution than having to re-train each perception model
with noisy input. We explore the space of different autoencoder architectures
and evaluate them on a diverse dataset created with real and synthetic images
demonstrating that by exploiting spatio-temporal information combined with
multi-component loss we significantly increase robustness against adverse image
effects reaching within 5-6% of that of the original model on clean images.

    

### [[2111.03547] POSHAN: Cardinal POS Pattern Guided Attention for News Headline Incongruence](http://arxiv.org/abs/2111.03547)


  Automatic detection of click-bait and incongruent news headlines is crucial
to maintaining the reliability of the Web and has raised much research
attention. However, most existing methods perform poorly when news headlines
contain contextually important cardinal values, such as a quantity or an
amount. In this work, we focus on this particular case and propose a neural
attention based solution, which uses a novel cardinal Part of Speech (POS) tag
pattern based hierarchical attention network, namely POSHAN, to learn effective
representations of sentences in a news article. In addition, we investigate a
novel cardinal phrase guided attention, which uses word embeddings of the
contextually-important cardinal value and neighbouring words. In the
experiments conducted on two publicly available datasets, we observe that the
proposed methodgives appropriate significance to cardinal values and
outperforms all the baselines. An ablation study of POSHAN shows that the
cardinal POS-tag pattern-based hierarchical attention is very effective for the
cases in which headlines contain cardinal values.

    

### [[2111.03628] Exploiting a Zoo of Checkpoints for Unseen Tasks](http://arxiv.org/abs/2111.03628)


  There are so many models in the literature that it is difficult for
practitioners to decide which combinations are likely to be effective for a new
task. This paper attempts to address this question by capturing relationships
among checkpoints published on the web. We model the space of tasks as a
Gaussian process. The covariance can be estimated from checkpoints and
unlabeled probing data. With the Gaussian process, we can identify
representative checkpoints by a maximum mutual information criterion. This
objective is submodular. A greedy method identifies representatives that are
likely to "cover" the task space. These representatives generalize to new tasks
with superior performance. Empirical evidence is provided for applications from
both computational linguistics as well as computer vision.

    

### [[2111.03630] Dynamic Human-Robot Role Allocation based on Human Ergonomics Risk Prediction and Robot Actions Adaptation](http://arxiv.org/abs/2111.03630)


  Despite cobots have high potential in bringing several benefits in the
manufacturing and logistic processes, but their rapid (re-)deployment in
changing environments is still limited. To enable fast adaptation to new
product demands and to boost the fitness of the human workers to the allocated
tasks, we propose a novel method that optimizes assembly strategies and
distributes the effort among the workers in human-robot cooperative tasks. The
cooperation model exploits AND/OR Graphs that we adapted to solve also the role
allocation problem. The allocation algorithm considers quantitative
measurements that are computed online to describe human operator's ergonomic
status and task properties. We conducted preliminary experiments to demonstrate
that the proposed approach succeeds in controlling the task allocation process
to ensure safe and ergonomic conditions for the human worker.

    

### [[2111.03647] Regular Decision Processes for Grid Worlds](http://arxiv.org/abs/2111.03647)


  Markov decision processes are typically used for sequential decision making
under uncertainty. For many aspects however, ranging from constrained or safe
specifications to various kinds of temporal (non-Markovian) dependencies in
task and reward structures, extensions are needed. To that end, in recent years
interest has grown into combinations of reinforcement learning and temporal
logic, that is, combinations of flexible behavior learning methods with robust
verification and guarantees. In this paper we describe an experimental
investigation of the recently introduced regular decision processes that
support both non-Markovian reward functions as well as transition functions. In
particular, we provide a tool chain for regular decision processes, algorithmic
extensions relating to online, incremental learning, an empirical evaluation of
model-free and model-based solution algorithms, and applications in regular,
but non-Markovian, grid worlds.

    

### [[2008.06727] A Review on Drivers Red Light Running Behaviour Predictions and Technology Based Countermeasures](http://arxiv.org/abs/2008.06727)


  Red light running at signalised intersections is a growing road safety issue
worldwide, leading to the rapid development of advanced intelligent
transportation technologies and countermeasures. However, existing studies have
yet to summarise and present the effect of these technology-based innovations
in improving safety. This paper represents a comprehensive review of red-light
running behaviour prediction methodologies and technology-based
countermeasures. Specifically, the major focus of this study is to provide a
comprehensive review on two streams of literature targeting red-light running
and stop-and-go behaviour at signalised intersection (1) studies focusing on
modelling and predicting the red-light running and stop-and-go related driver
behaviour and (2) studies focusing on the effectiveness of different
technology-based countermeasures which combat such unsafe behaviour. The study
provides a systematic guide to assist researchers and stakeholders in
understanding how to best identify red-light running and stop-and-go associated
driving behaviour and subsequently implement countermeasures to combat such
risky behaviour and improve the associated safety.

    

### [[2104.08620] Decrypting Cryptic Crosswords: Semantically Complex Wordplay Puzzles as a Target for NLP](http://arxiv.org/abs/2104.08620)


  Cryptic crosswords, the dominant crossword variety in the UK, are a promising
target for advancing NLP systems that seek to process semantically complex,
highly compositional language. Cryptic clues read like fluent natural language
but are adversarially composed of two parts: a definition and a wordplay cipher
requiring character-level manipulations. Expert humans use creative
intelligence to solve cryptics, flexibly combining linguistic, world, and
domain knowledge. In this paper, we make two main contributions. First, we
present a dataset of cryptic clues as a challenging new benchmark for NLP
systems that seek to process compositional language in more creative,
human-like ways. After showing that three non-neural approaches and T5, a
state-of-the-art neural language model, do not achieve good performance, we
make our second main contribution: a novel curriculum approach, in which the
model is first fine-tuned on related tasks such as unscrambling words.We also
introduce a challenging data split, examine the meta-linguistic capabilities of
subword-tokenized models, and investigate model systematicity by perturbing the
wordplay part of clues, showing that T5 exhibits behavior partially consistent
with human solving strategies. Although our curricular approach considerably
improves on the T5 baseline, our best-performing model still fails to
generalize to the extent that humans can. Thus, cryptic crosswords remain an
unsolved challenge for NLP systems and a potential source of future innovation.

    

### [[2109.12912] A User-Centred Framework for Explainable Artificial Intelligence in Human-Robot Interaction](http://arxiv.org/abs/2109.12912)


  State of the art Artificial Intelligence (AI) techniques have reached an
impressive complexity. Consequently, researchers are discovering more and more
methods to use them in real-world applications. However, the complexity of such
systems requires the introduction of methods that make those transparent to the
human user. The AI community is trying to overcome the problem by introducing
the Explainable AI (XAI) field, which is tentative to make AI algorithms less
opaque. However, in recent years, it became clearer that XAI is much more than
a computer science problem: since it is about communication, XAI is also a
Human-Agent Interaction problem. Moreover, AI came out of the laboratories to
be used in real life. This implies the need for XAI solutions tailored to
non-expert users. Hence, we propose a user-centred framework for XAI that
focuses on its social-interactive aspect taking inspiration from cognitive and
social sciences' theories and findings. The framework aims to provide a
structure for interactive XAI solutions thought for non-expert users.

    

### [[2105.02814] End-to-end deep meta modelling to calibrate and optimize energy consumption and comfort](http://arxiv.org/abs/2105.02814)


  In this paper, we propose a new end-to-end methodology to optimize the energy
performance as well as comfort and air quality in large buildings without any
renovation work. We introduce a metamodel based on recurrent neural networks
and trained to predict the behavior of a general class of buildings using a
database sampled from a simulation program. This metamodel is then deployed in
different frameworks and its parameters are calibrated using the specific data
of two real buildings. Parameters are estimated by comparing the predictions of
the metamodel with real data obtained from sensors using the CMA-ES algorithm,
a derivative free optimization procedure. Then, energy consumptions are
optimized while maintaining a target thermal comfort and air quality, using the
NSGA-II multi-objective optimization procedure. The numerical experiments
illustrate how this metamodel ensures a significant gain in energy efficiency,
up to almost 10%, while being computationally much more appealing than
numerical models and flexible enough to be adapted to several types of
buildings.

    

### [[2110.10572] Estimation & Recognition under Perspective of Random-Fuzzy Dual Interpretation of Unknown Quantity: with Demonstration of IMM Filter](http://arxiv.org/abs/2110.10572)


  This paper is to consider the problems of estimation and recognition from the
perspective of sigma-max inference (probability-possibility inference), with a
focus on discovering whether some of the unknown quantities involved could be
more faithfully modeled as fuzzy uncertainty. Two related key issues are
addressed: 1) the random-fuzzy dual interpretation of unknown quantity being
estimated; 2) the principle of selecting sigma-max operator for practical
problems, such as estimation and recognition. Our perspective, conceived from
definitions of randomness and fuzziness, is that continuous unknown quantity
involved in estimation with inaccurate prior should be more appropriately
modeled as randomness and handled by sigma inference; whereas discrete unknown
quantity involved in recognition with insufficient (and inaccurate) prior could
be better modeled as fuzziness and handled by max inference. The philosophy was
demonstrated by an updated version of the well-known interacting multiple model
(IMM) filter, for which the jump Markovian System is reformulated as a hybrid
uncertainty system, with continuous state evolution modeled as usual as
model-conditioned stochastic system and discrete mode transitions modeled as
fuzzy system by a possibility (instead of probability) transition matrix, and
hypotheses mixing is conducted by using the operation of "max" instead of
"sigma". For our example of maneuvering target tracking using simulated data
from both a short-range fire control radar and a long-range surveillance radar,
the updated IMM filter shows significant improvement over the classic IMM
filter, due to its peculiarity of hard decision of system model and a faster
response to the transition of discrete mode.

    

### [[1806.05444] Scalable load balancing in networked systems: A survey of recent advances](http://arxiv.org/abs/1806.05444)


  The basic load balancing scenario involves a single dispatcher where tasks
arrive that must immediately be forwarded to one of $N$ single-server queues.
We discuss recent advances on scalable load balancing schemes which provide
favorable delay performance when $N$ grows large, and yet only require minimal
implementation overhead. Join-the-Shortest-Queue (JSQ) yields vanishing delays
as $N$ grows large, as in a centralized queueing arrangement, but involves a
prohibitive communication burden. In contrast, power-of-$d$ or JSQ($d$) schemes
that assign an incoming task to a server with the shortest queue among $d$
servers selected uniformly at random require little communication, but lead to
constant delays. In order to examine this fundamental trade-off between delay
performance and implementation overhead, we consider JSQ($d(N)$) schemes where
the diversity parameter $d(N)$ depends on $N$ and investigate what growth rate
of $d(N)$ is required to asymptotically match the optimal JSQ performance on
fluid and diffusion scale.
Stochastic coupling techniques and stochastic-process limits play an
instrumental role in establishing the asymptotic optimality. We demonstrate how
this methodology carries over to infinite-server settings, finite buffers,
multiple dispatchers, servers arranged on graph topologies, and token-based
load balancing including the popular Join-the-Idle-Queue (JIQ) scheme. In this
way we provide a broad overview of the many recent advances in the field. This
survey extends the short review presented at ICM 2018 (arXiv:1712.08555).

    

### [[2111.03354] Programming with union, intersection, and negation types](http://arxiv.org/abs/2111.03354)


  In this essay, I present the advantages and, I dare say, the beauty of
programming in a language with set-theoretic types, that is, types that include
union, intersection, and negation type connectives. I show by several examples
how set-theoretic types are necessary to type some common programming patterns,
but also how they play a key role in typing several language constructs-from
branching and pattern matching to function overloading and type-cases-very
precisely. I start by presenting the theory of types known as semantic
subtyping and extend it to include polymorphic types. Next, I discuss the
design of languages that use these types. I start by defining a theoretical
framework that covers all the examples given in the first part of the
presentation. Since the system of the framework cannot be effectively
implemented, I then describe three effective restrictions of this system: (i) a
polymorphic language with explicitly-typed functions, (ii) an implicitly-typed
polymorphic language{à} la Hindley-Milner, and (iii) a monomorphic language
that, by implementing classic union-elimination, precisely reconstructs
intersection types for functions and implements a very general form of
occurrence typing. I conclude the presentation with a short overview of other
aspects of these languages, such as pattern matching, gradual typing, and
denotational semantics.

    

### [[2111.03484] Pirouette: Higher-Order Typed Functional Choreographies](http://arxiv.org/abs/2111.03484)


  We present Pirouette, a language for typed higher-order functional
choreographic programming. Pirouette offers programmers the ability to write a
centralized functional program and compile it via endpoint projection into
programs for each node in a distributed system. Moreover, Pirouette is defined
generically over a (local) language of messages, and lifts guarantees about the
message type system to its own. Message type soundness also guarantees deadlock
freedom. All of our results are verified in Coq.

    

### [[2111.03534] Learning Formulas in Finite Variable Logics](http://arxiv.org/abs/2111.03534)


  We investigate exact learning of formulas in finite-variable logics over
positively- and negatively-labeled finite structures. We propose a general
automata-theoretic solution, establish decidability, and give algorithms for
synthesis. We also study variants of the learning problem for learning queries
and terms, and we provide algorithms for realizability and synthesis along with
upper and lower bounds. We study the problem also along the dimension of
logics, establishing positive results for first-order logic with least fixed
points and several other logics.

    