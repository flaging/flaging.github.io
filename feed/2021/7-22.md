
## 2021-7-22

### [<title>学校原版|卡比兰诺大学Capilano毕业证/成绩单offer-p - DockOne.io</title>](http://dockone.io/question/775435)

### [<title>关于）安阳电商营业执照怎么办理流程-爱上本地宝 - DockOne.io</title>](http://dockone.io/question/775434)

### [<title>关于）新乡电商营业执照怎么办理流程-爱上本地宝 - DockOne.io</title>](http://dockone.io/question/775433)

### [<title>学校原版|皇家山大学Mount Royal毕业证/成绩单offer-t - DockOne.io</title>](http://dockone.io/question/775432)

### [<title>学校原版|麦科文大学Grant MacEwan毕业证/成绩单offer-t - DockOne.io</title>](http://dockone.io/question/775431)

### [<title>关于）漯河电商营业执照怎么办理流程-爱上本地宝 - DockOne.io</title>](http://dockone.io/question/775430)

### [<title>关于）开封电商营业执照怎么办理流程-爱上本地宝 - DockOne.io</title>](http://dockone.io/question/775429)

### [<title>学校原版|卡尔加里大学UCalgary毕业证/成绩单offer-y - DockOne.io</title>](http://dockone.io/question/775428)

### [<title>学校原版|莱斯布里奇大学U of L毕业证/成绩单offer-y - DockOne.io</title>](http://dockone.io/question/775427)

### [<title>关于）洛阳电商营业执照怎么办理流程-爱上本地宝 - DockOne.io</title>](http://dockone.io/question/775426)

### [<title>关于）河南电商营业执照怎么办理流程-爱上本地宝 - DockOne.io</title>](http://dockone.io/question/775425)

### [<title>学校原版|阿尔伯塔大学UA毕业证/成绩单offer-a - DockOne.io</title>](http://dockone.io/question/775424)

### [<title>学校原版|东北伊利诺伊大学NEIU毕业证/成绩单offer-p - DockOne.io</title>](http://dockone.io/question/775423)

### [<title>关于）黄石电商营业执照怎么办理流程-爱上本地宝 - DockOne.io</title>](http://dockone.io/question/775422)

### [<title>学校原版|北园大学North Park毕业证/成绩单offer-y - DockOne.io</title>](http://dockone.io/question/775421)

### [<title>关于）湖北电商营业执照怎么办理流程-爱上本地宝 - DockOne.io</title>](http://dockone.io/question/775420)

### [<title>学校原版|中北大学NCC毕业证/成绩单offer-n - DockOne.io</title>](http://dockone.io/question/775419)

### [<title>学校原版|路易斯安那州立大学LSU毕业证/成绩单offer-l - DockOne.io</title>](http://dockone.io/question/775418)

### [<title>关于）郴州电商营业执照怎么办理流程-爱上本地宝 - DockOne.io</title>](http://dockone.io/question/775417)

### [<title>学校原版|莫顿学院Morton毕业证/成绩单offer-o - DockOne.io</title>](http://dockone.io/question/775416)

### [[2107.09851] Fundamental requirements for the design of ultra-reliable low-latency mobile networks](http://arxiv.org/abs/2107.09851)


  The support for ultra-reliable communication is a key distinction between
today's and tomorrow's mobile networks, enabling emerging
critical-communication services such as factory automation, remote-controlled
vessels, mobile cloud computing, and yet-to-come applications. In this paper,
we study the fundamental requirements to design mobile networks capable of
ultra-reliable communication. We consider two network design assets, bandwidth
and network density, and network models by the 3GPP. Our findings indicate that
required assets can be beyond what is typically found in today's networks. We
study network sharing as an alternative approach to facilitate the provision of
resources to meet ultra-reliability goals.

    

### [[2107.09896] THz Transmission meets Untrusted UAV-Relaying; Trajectory and Communication Co-design for Secrecy Energy Efficiency Maximization](http://arxiv.org/abs/2107.09896)


  Unmanned aerial vehicles (UAVs) and Terahertz (THz) technology are envisioned
to play paramount roles in next-generation wireless communications. Hence, this
paper presents a novel secure UAV-assisted mobile relaying system operating at
THz bands for data acquisition from multiple ground user equipments towards a
destination. We assume that the UAV-mounted relay may act, besides providing
relaying services, as a potential adversary called the untrusted UAV relay. To
safeguard end-to-end communications, we present a secure two-phase transmission
strategy with cooperative jamming. Then, we formulate an optimization problem
in terms of a new measure $-$ secrecy energy efficiency (SEE), defined as the
ratio of achievable average secrecy rate to average system power consumption,
which enables us to obtain the best possible security level while taking UAV's
inherent flight power limitation into account. This optimization problem leads
to a joint design of key system parameters, including UAV's trajectory and
velocity, communication scheduling, and power allocations. Since the formulated
problem is a mixed-integer nonconvex optimization and computationally
intractable, we propose alternative algorithms to solve it efficiently via
greedy/sequential block coordinated descent, successive convex approximation,
and non-linear fractional programming techniques. Numerical results demonstrate
significant SEE performance improvement of our designs when compared to other
known benchmarks.

    

### [[2107.10065] Pushing the Limits: Resilience Testing for Mission-Critical Machine-Type Communication](http://arxiv.org/abs/2107.10065)


  Interdisciplinary application fields, such as automotive, industrial
applications or field robotics show an increasing need for reliable and
resilient wireless communication even under high load conditions. These
mission-critical applications require dependable service quality
characteristics in terms of latency and especially stability. Current
deployments often use either wired links that lack the flexibility to
accommodate them, or wireless technologies that are susceptible to
interference. Depending on the application and the surrounding environments,
different technologies can meet the associated requirements and have to be
tested deliberately to prevent unexpected system failure. To stress test these
infrastructures in a reproducible and application-aware manner, we propose
STING, a spatially distributed traffic and interference generation framework.
STING is evaluated in a remote control test case of an Unmanned Ground Vehicle
that serves as a scout in Search and Rescue missions. A significant impact of
interference on the remote control quality of experience is shown in tests with
different operators, which result in an 80% increase in completion time in our
test scenario with high interference on the radio channel. With this case
study, we have proven STING to be a reliable and reproducible way to asses
resilience against interference of wireless machine-type communication use
cases. Our concept can find use for any type of wireless technology, in
unlicensed (e.g. Wi-Fi) as well as licensed bands (e.g. 5G).

    

### [[2107.10135] Global Outliers Detection in Wireless Sensor Networks: A Novel Approach Integrating Time-Series Analysis, Entropy, and Random Forest-based Classification](http://arxiv.org/abs/2107.10135)


  Wireless Sensor Networks (WSNs) have recently attracted greater attention
worldwide due to their practicality in monitoring, communicating, and reporting
specific physical phenomena. The data collected by WSNs is often inaccurate as
a result of unavoidable environmental factors, which may include noise, signal
weakness, or intrusion attacks depending on the specific situation. Sending
high-noise data has negative effects not just on data accuracy and network
reliability, but also regarding the decision-making processes in the base
station. Anomaly detection, or outlier detection, is the process of detecting
noisy data amidst the contexts thus described. The literature contains
relatively few noise detection techniques in the context of WSNs, particularly
for outlier-detection algorithms applying time series analysis, which considers
the effective neighbors to ensure a global-collaborative detection. Hence, the
research presented in this paper is intended to design and implement a global
outlier-detection approach, which allows us to find and select appropriate
neighbors to ensure an adaptive collaborative detection based on time-series
analysis and entropy techniques. The proposed approach applies a random forest
algorithm for identifying the best results. To measure the effectiveness and
efficiency of the proposed approach, a comprehensive and real scenario provided
by the Intel Berkeley Research lab has been simulated. Noisy data have been
injected into the collected data randomly. The results obtained from the
experiment then conducted experimentation demonstrate that our approach can
detect anomalies with up to 99% accuracy.

    

### [[2005.06523] UAVs as Mobile Base Stations](http://arxiv.org/abs/2005.06523)


  The research presented here has been conducted as part of professor Fabrizion
Granelli's course "Advanced Network Modeling and Design" at UniTn and regards
the use of drones as mobile base stations. With the advent of fifth generation
(5G) RANs, networks will have to handle an increasing amount of diverse
devices. This will lead to a greater demand on current telecom companies and
infrastructures. Solutions to meet these current new demands might not suffice
in guaranteeing the required service for the increasing demand. In emergency
situations in particular, using terrestrial infrastructures is impossible for
various reasons. All these factors suggest exploiting unmanned aerial vehicles
as mobile base stations, overcoming all these adversities. The current state of
the art is evaluated, in order to pinpoint the best approach which fulfills all
requirements; in doing so, the business impact is also taken into account. This
proposal is a guideline for further research and the eventual creation of a new
startup. The outline of the research proposal is as follows: 1) This section is
a brief overview of the current state of the art, examining what is readily
available and what needs to be further developed. 2) This section covers the
research proposal, an appropriate solution is suggested, overcoming the
shortcomings of the current state of the art. 3) This section covers the
possible business impacts and outcomes that this research could have if further
developed and implemented.

    

### [[2009.13640] TEL: Low-Latency Failover Traffic Engineering in Data Plane](http://arxiv.org/abs/2009.13640)


  Modern network applications demand low-latency traffic engineering in the
presence of network failure while preserving the quality of service constraints
like delay and capacity. Fast Re-Route (FRR) mechanisms are widely used for
traffic re-routing purposes in failure scenarios. Control plane FRR typically
computes the backup forwarding rules to detour the traffic in the data plane
when the failure occurs. This mechanism could be computed in the data plane
with the emergence of programmable data planes. In this paper, we propose a
system (called TEL) that contains two FRR mechanisms, namely, TEL-C and TEL-D.
The first one computes backup forwarding rules in the control plane, satisfying
max-min fair allocation. The second mechanism provides FRR in the data plane.
Both algorithms require minimal memory on programmable data planes and are
well-suited with modern line rate match-action forwarding architectures (e.g.,
PISA). We implement both mechanisms on P4 programmable software switches (e.g.,
BMv2 and Tofino) and measure their performance on various topologies. The
obtained results from a datacenter topology show that our FRR mechanism can
improve the flow completion time up to 4.6x$-$7.3x (i.e., small flows) and
3.1x$-$12x (i.e., large flows) compared to recirculation-based mechanisms, such
as F10, respectively.

    

### [[2105.02867] Age of Gossip in Networks with Community Structure](http://arxiv.org/abs/2105.02867)


  We consider a network consisting of a single source and $n$ receiver nodes
that are grouped into $m$ equal size communities, i.e., clusters, where each
cluster includes $k$ nodes and is served by a dedicated cluster head. The
source node keeps versions of an observed process and updates each cluster
through the associated cluster head. Nodes within each cluster are connected to
each other according to a given network topology. Based on this topology, each
node relays its current update to its neighboring nodes by $local$ $gossiping$.
We use the $version$ $age$ metric to quantify information timeliness at the
receiver nodes. We consider disconnected, ring, and fully connected network
topologies for each cluster. For each of these network topologies, we
characterize the average version age at each node and find the version age
scaling as a function of the network size $n$. Our results indicate that per
node version age scalings of $O(\sqrt{n})$, $O(n^{\frac{1}{3}})$, and $O(\log
n)$ are achievable in disconnected, ring, and fully connected cluster models,
respectively. Finally, through numerical evaluations, we determine the version
age-optimum $(m,k)$ pairs as a function of the source, cluster head, and node
update rates.

    

### [[2107.09700] 3D-StyleGAN: A Style-Based Generative Adversarial Network for Generative Modeling of Three-Dimensional Medical Images](http://arxiv.org/abs/2107.09700)


  Image synthesis via Generative Adversarial Networks (GANs) of
three-dimensional (3D) medical images has great potential that can be extended
to many medical applications, such as, image enhancement and disease
progression modeling. However, current GAN technologies for 3D medical image
synthesis need to be significantly improved to be readily adapted to real-world
medical problems. In this paper, we extend the state-of-the-art StyleGAN2
model, which natively works with two-dimensional images, to enable 3D image
synthesis. In addition to the image synthesis, we investigate the
controllability and interpretability of the 3D-StyleGAN via style vectors
inherited form the original StyleGAN2 that are highly suitable for medical
applications: (i) the latent space projection and reconstruction of unseen real
images, and (ii) style mixing. We demonstrate the 3D-StyleGAN's performance and
feasibility with ~12,000 three-dimensional full brain MR T1 images, although it
can be applied to any 3D volumetric images. Furthermore, we explore different
configurations of hyperparameters to investigate potential improvement of the
image synthesis with larger networks. The codes and pre-trained networks are
available online: this https URL.

    

### [[2107.09716] Regularized Classification-Aware Quantization](http://arxiv.org/abs/2107.09716)


  Traditionally, quantization is designed to minimize the reconstruction error
of a data source. When considering downstream classification tasks, other
measures of distortion can be of interest; such as the 0-1 classification loss.
Furthermore, it is desirable that the performance of these quantizers not
deteriorate once they are deployed into production, as relearning the scheme
online is not always possible. In this work, we present a class of algorithms
that learn distributed quantization schemes for binary classification tasks.
Our method performs well on unseen data, and is faster than previous methods
proportional to a quadratic term of the dataset size. It works by regularizing
the 0-1 loss with the reconstruction error. We present experiments on synthetic
mixture and bivariate Gaussian data and compare training, testing, and
generalization errors with a family of benchmark quantization schemes from the
literature. Our method is called Regularized Classification-Aware Quantization.

    

### [[2107.09728] Machine Learning Approaches to Automated Flow Cytometry Diagnosis of Chronic Lymphocytic Leukemia](http://arxiv.org/abs/2107.09728)


  Flow cytometry is a technique that measures multiple fluorescence and light
scatter-associated parameters from individual cells as they flow a single file
through an excitation light source. These cells are labeled with antibodies to
detect various antigens and the fluorescence signals reflect antigen
expression. Interpretation of the multiparameter flow cytometry data is
laborious, time-consuming, and expensive. It involves manual interpretation of
cell distribution and pattern recognition on two-dimensional plots by highly
trained medical technologists and pathologists. Using various machine learning
algorithms, we attempted to develop an automated analysis for clinical flow
cytometry cases that would automatically classify normal and chronic
lymphocytic leukemia cases. We achieved the best success with the Gradient
Boosting. The XGBoost classifier achieved a specificity of 1.00 and a
sensitivity of 0.67, a negative predictive value of 0.75, a positive predictive
value of 1.00, and an overall accuracy of 0.83 in prospectively classifying
cases with malignancies.

    

### [[2107.09729] What Do You Get When You Cross Beam Search with Nucleus Sampling?](http://arxiv.org/abs/2107.09729)


  We combine beam search with the probabilistic pruning technique of nucleus
sampling to create two deterministic nucleus search algorithms for natural
language generation. The first algorithm, p-exact search, locally prunes the
next-token distribution and performs an exact search over the remaining space.
The second algorithm, dynamic beam search, shrinks and expands the beam size
according to the entropy of the candidate's probability distribution. Despite
the probabilistic intuition behind nucleus search, experiments on machine
translation and summarization benchmarks show that both algorithms reach the
same performance levels as standard beam search.

    

### [[2107.09734] Uncertainty Estimation and Out-of-Distribution Detection for Counterfactual Explanations: Pitfalls and Solutions](http://arxiv.org/abs/2107.09734)


  Whilst an abundance of techniques have recently been proposed to generate
counterfactual explanations for the predictions of opaque black-box systems,
markedly less attention has been paid to exploring the uncertainty of these
generated explanations. This becomes a critical issue in high-stakes scenarios,
where uncertain and misleading explanations could have dire consequences (e.g.,
medical diagnosis and treatment planning). Moreover, it is often difficult to
determine if the generated explanations are well grounded in the training data
and sensitive to distributional shifts. This paper proposes several practical
solutions that can be leveraged to solve these problems by establishing novel
connections with other research works in explainability (e.g., trust scores)
and uncertainty estimation (e.g., Monte Carlo Dropout). Two experiments
demonstrate the utility of our proposed solutions.

    

### [[2107.09735] kNet: A Deep kNN Network To Handle Label Noise](http://arxiv.org/abs/2107.09735)


  Deep Neural Networks require large amounts of labeled data for their
training. Collecting this data at scale inevitably causes label noise.Hence,the
need to develop learning algorithms that are robust to label noise. In recent
years, k Nearest Neighbors (kNN) emerged as a viable solution to this problem.
Despite its success, kNN is not without its problems. Mainly, it requires a
huge memory footprint to store all the training samples and it needs an
advanced data structure to allow for fast retrieval of the relevant examples,
given a query sample. We propose a neural network, termed kNet, that learns to
perform kNN. Once trained, we no longer need to store the training data, and
processing a query sample is a simple matter of inference. To use kNet, we
first train a preliminary network on the data set, and then train kNet on the
penultimate layer of the preliminary network.We find that kNet gives a smooth
approximation of kNN,and cannot handle the sharp label changes between samples
that kNN can exhibit. This indicates that currently kNet is best suited to
approximate kNN with a fairly large k. Experiments on two data sets show that
this is the regime in which kNN works best,and can therefore be replaced by
this http URL practice, kNet consistently improve the results of all preliminary
networks, in all label noise regimes, by up to 3%.

    

### [[2107.09766] Enhancing Loop-Invariant Synthesis via Reinforcement Learning](http://arxiv.org/abs/2107.09766)


  Loop-invariant synthesis is the basis of every program verification
procedure. Due to its undecidability in general, a tool for invariant synthesis
necessarily uses heuristics. Despite the common belief that the design of
heuristics is vital for the effective performance of a verifier, little work
has been performed toward obtaining the optimal heuristics for each
invariant-synthesis tool. Instead, developers have hand-tuned the heuristics of
tools. This study demonstrates that we can effectively and automatically learn
a good heuristic via reinforcement learning for an invariant synthesizer PCSat.
Our experiment shows that PCSat combined with the heuristic learned by
reinforcement learning outperforms the state-of-the-art solvers for this task.
To the best of our knowledge, this is the first work that investigates learning
the heuristics of an invariant synthesis tool.

    

### [[2107.09767] Explainable AI Enabled Inspection of Business Process Prediction Models](http://arxiv.org/abs/2107.09767)


  Modern data analytics underpinned by machine learning techniques has become a
key enabler to the automation of data-led decision making. As an important
branch of state-of-the-art data analytics, business process predictions are
also faced with a challenge in regard to the lack of explanation to the
reasoning and decision by the underlying `black-box' prediction models. With
the development of interpretable machine learning techniques, explanations can
be generated for a black-box model, making it possible for (human) users to
access the reasoning behind machine learned predictions. In this paper, we aim
to present an approach that allows us to use model explanations to investigate
certain reasoning applied by machine learned predictions and detect potential
issues with the underlying methods thus enhancing trust in business process
prediction models. A novel contribution of our approach is the proposal of
model inspection that leverages both the explanations generated by
interpretable machine learning mechanisms and the contextual or domain
knowledge extracted from event logs that record historical process execution.
Findings drawn from this work are expected to serve as a key input to
developing model reliability metrics and evaluation in the context of business
process predictions.

    

### [[2107.09768] Checkovid: A COVID-19 misinformation detection system on Twitter using network and content mining perspectives](http://arxiv.org/abs/2107.09768)


  During the COVID-19 pandemic, social media platforms were ideal for
communicating due to social isolation and quarantine. Also, it was the primary
source of misinformation dissemination on a large scale, referred to as the
infodemic. Therefore, automatic debunking misinformation is a crucial problem.
To tackle this problem, we present two COVID-19 related misinformation datasets
on Twitter and propose a misinformation detection system comprising
network-based and content-based processes based on machine learning algorithms
and NLP techniques. In the network-based process, we focus on social
properties, network characteristics, and users. On the other hand, we classify
misinformation using the content of the tweets directly in the content-based
process, which contains text classification models (paragraph-level and
sentence-level) and similarity models. The evaluation results on the
network-based process show the best results for the artificial neural network
model with an F1 score of 88.68%. In the content-based process, our novel
similarity models, which obtained an F1 score of 90.26%, show an improvement in
the misinformation classification results compared to the network-based models.
In addition, in the text classification models, the best result was achieved
using the stacking ensemble-learning model by obtaining an F1 score of 95.18%.
Furthermore, we test our content-based models on the Constraint@AAAI2021
dataset, and by getting an F1 score of 94.38%, we improve the baseline results.
Finally, we develop a fact-checking website called Checkovid that uses each
process to detect misinformative and informative claims in the domain of
COVID-19 from different perspectives.

    

### [[2107.09770] Faster Matchings via Learned Duals](http://arxiv.org/abs/2107.09770)


  A recent line of research investigates how algorithms can be augmented with
machine-learned predictions to overcome worst case lower bounds. This area has
revealed interesting algorithmic insights into problems, with particular
success in the design of competitive online algorithms. However, the question
of improving algorithm running times with predictions has largely been
unexplored.
We take a first step in this direction by combining the idea of
machine-learned predictions with the idea of "warm-starting" primal-dual
algorithms. We consider one of the most important primitives in combinatorial
optimization: weighted bipartite matching and its generalization to
$b$-matching. We identify three key challenges when using learned dual
variables in a primal-dual algorithm. First, predicted duals may be infeasible,
so we give an algorithm that efficiently maps predicted infeasible duals to
nearby feasible solutions. Second, once the duals are feasible, they may not be
optimal, so we show that they can be used to quickly find an optimal solution.
Finally, such predictions are useful only if they can be learned, so we show
that the problem of learning duals for matching has low sample complexity. We
validate our theoretical findings through experiments on both real and
synthetic data. As a result we give a rigorous, practical, and empirically
effective method to compute bipartite matchings.

    

### [[2107.09773] Statistical Estimation from Dependent Data](http://arxiv.org/abs/2107.09773)


  We consider a general statistical estimation problem wherein binary labels
across different observations are not independent conditioned on their feature
vectors, but dependent, capturing settings where e.g. these observations are
collected on a spatial domain, a temporal domain, or a social network, which
induce dependencies. We model these dependencies in the language of Markov
Random Fields and, importantly, allow these dependencies to be substantial, i.e
do not assume that the Markov Random Field capturing these dependencies is in
high temperature. As our main contribution we provide algorithms and
statistically efficient estimation rates for this model, giving several
instantiations of our bounds in logistic regression, sparse logistic
regression, and neural network settings with dependent data. Our estimation
guarantees follow from novel results for estimating the parameters (i.e.
external fields and interaction strengths) of Ising models from a {\em single}
sample. {We evaluate our estimation approach on real networked data, showing
that it outperforms standard regression approaches that ignore dependencies,
across three text classification datasets: Cora, Citeseer and Pubmed.}

    

### [[2107.09781] Quantum Measurement Classification with Qudits](http://arxiv.org/abs/2107.09781)


  This paper presents a hybrid classical-quantum program for density estimation
and supervised classification. The program is implemented as a quantum circuit
in a high-dimensional quantum computer simulator. We show that the proposed
quantum protocols allow to estimate probability density functions and to make
predictions in a supervised learning manner. This model can be generalized to
find expected values of density matrices in high-dimensional quantum computers.
Experiments on various data sets are presented. Results show that the proposed
method is a viable strategy to implement supervised classification and density
estimation in a high-dimensional quantum computer.

    

### [[2107.09785] High-dimensional Multivariate Time Series Forecasting in IoT Applications using Embedding Non-stationary Fuzzy Time Series](http://arxiv.org/abs/2107.09785)


  In Internet of things (IoT), data is continuously recorded from different
data sources and devices can suffer faults in their embedded electronics, thus
leading to a high-dimensional data sets and concept drift events. Therefore,
methods that are capable of high-dimensional non-stationary time series are of
great value in IoT applications. Fuzzy Time Series (FTS) models stand out as
data-driven non-parametric models of easy implementation and high accuracy.
Unfortunately, FTS encounters difficulties when dealing with data sets of many
variables and scenarios with concept drift. We present a new approach to handle
high-dimensional non-stationary time series, by projecting the original
high-dimensional data into a low dimensional embedding space and using FTS
approach. Combining these techniques enables a better representation of the
complex content of non-stationary multivariate time series and accurate
forecasts. Our model is able to explain 98% of the variance and reach 11.52% of
RMSE, 2.68% of MAE and 2.91% of MAPE.

    

### [[2107.09786] Communication and Computation Reduction for Split Learning using Asynchronous Training](http://arxiv.org/abs/2107.09786)


  Split learning is a promising privacy-preserving distributed learning scheme
that has low computation requirement at the edge device but has the
disadvantage of high communication overhead between edge device and server. To
reduce the communication overhead, this paper proposes a loss-based
asynchronous training scheme that updates the client-side model less frequently
and only sends/receives activations/gradients in selected epochs. To further
reduce the communication overhead, the activations/gradients are quantized
using 8-bit floating point prior to transmission. An added benefit of the
proposed communication reduction method is that the computations at the client
side are reduced due to reduction in the number of client model updates.
Furthermore, the privacy of the proposed communication reduction based split
learning method is almost the same as traditional split learning. Simulation
results on VGG11, VGG13 and ResNet18 models on CIFAR-10 show that the
communication cost is reduced by 1.64x-106.7x and the computations in the
client are reduced by 2.86x-32.1x when the accuracy degradation is less than
0.5% for the single-client case. For 5 and 10-client cases, the communication
cost reduction is 11.9x and 11.3x on VGG11 for 0.5% loss in accuracy.

    

### [[2107.09787] Group Contrastive Self-Supervised Learning on Graphs](http://arxiv.org/abs/2107.09787)


  We study self-supervised learning on graphs using contrastive methods. A
general scheme of prior methods is to optimize two-view representations of
input graphs. In many studies, a single graph-level representation is computed
as one of the contrastive objectives, capturing limited characteristics of
graphs. We argue that contrasting graphs in multiple subspaces enables graph
encoders to capture more abundant characteristics. To this end, we propose a
group contrastive learning framework in this work. Our framework embeds the
given graph into multiple subspaces, of which each representation is prompted
to encode specific characteristics of graphs. To learn diverse and informative
representations, we develop principled objectives that enable us to capture the
relations among both intra-space and inter-space representations in groups.
Under the proposed framework, we further develop an attention-based representor
function to compute representations that capture different substructures of a
given graph. Built upon our framework, we extend two current methods into
GroupCL and GroupIG, equipped with the proposed objective. Comprehensive
experimental results show our framework achieves a promising boost in
performance on a variety of datasets. In addition, our qualitative results show
that features generated from our representor successfully capture various
specific characteristics of graphs.

    

### [[2107.09802] Private Alternating Least Squares: Practical Private Matrix Completion with Tighter Rates](http://arxiv.org/abs/2107.09802)


  We study the problem of differentially private (DP) matrix completion under
user-level privacy. We design a joint differentially private variant of the
popular Alternating-Least-Squares (ALS) method that achieves: i) (nearly)
optimal sample complexity for matrix completion (in terms of number of items,
users), and ii) the best known privacy/utility trade-off both theoretically, as
well as on benchmark data sets. In particular, we provide the first global
convergence analysis of ALS with noise introduced to ensure DP, and show that,
in comparison to the best known alternative (the Private Frank-Wolfe algorithm
by Jain et al. (2018)), our error bounds scale significantly better with
respect to the number of items and users, which is critical in practical
problems. Extensive validation on standard benchmarks demonstrate that the
algorithm, in combination with carefully designed sampling procedures, is
significantly more accurate than existing techniques, thus promising to be the
first practical DP embedding model.

    

### [[2107.09804] Using Undervolting as an On-Device Defense Against Adversarial Machine Learning Attacks](http://arxiv.org/abs/2107.09804)


  Deep neural network (DNN) classifiers are powerful tools that drive a broad
spectrum of important applications, from image recognition to autonomous
vehicles. Unfortunately, DNNs are known to be vulnerable to adversarial attacks
that affect virtually all state-of-the-art models. These attacks make small
imperceptible modifications to inputs that are sufficient to induce the DNNs to
produce the wrong classification.
In this paper we propose a novel, lightweight adversarial correction and/or
detection mechanism for image classifiers that relies on undervolting (running
a chip at a voltage that is slightly below its safe margin). We propose using
controlled undervolting of the chip running the inference process in order to
introduce a limited number of compute errors. We show that these errors disrupt
the adversarial input in a way that can be used either to correct the
classification or detect the input as adversarial. We evaluate the proposed
solution in an FPGA design and through software simulation. We evaluate 10
attacks on two popular DNNs and show an average detection rate of 80% to 95%.

    

### [[2107.09807] Multi-agent Reinforcement Learning Improvement in a Dynamic Environment Using Knowledge Transfer](http://arxiv.org/abs/2107.09807)


  Cooperative multi-agent systems are being widely used in different domains.
Interaction among agents would bring benefits, including reducing operating
costs, high scalability, and facilitating parallel processing. These systems
are also a good option for handling large-scale, unknown, and dynamic
environments. However, learning in these environments has become a very
important challenge in various applications. These challenges include the
effect of search space size on learning time, inefficient cooperation among
agents, and the lack of proper coordination among agents' decisions. Moreover,
reinforcement learning algorithms may suffer from long convergence time in
these problems. In this paper, a communication framework using knowledge
transfer concepts is introduced to address such challenges in the herding
problem with large state space. To handle the problems of convergence,
knowledge transfer has been utilized that can significantly increase the
efficiency of reinforcement learning algorithms. Coordination between the
agents is carried out through a head agent in each group of agents and a
coordinator agent respectively. The results demonstrate that this framework
could indeed enhance the speed of learning and reduce convergence time.

    

### [[2107.09814] Manifold learning-based polynomial chaos expansions for high-dimensional surrogate models](http://arxiv.org/abs/2107.09814)


  In this work we introduce a manifold learning-based method for uncertainty
quantification (UQ) in systems describing complex spatiotemporal processes. Our
first objective is to identify the embedding of a set of high-dimensional data
representing quantities of interest of the computational or analytical model.
For this purpose, we employ Grassmannian diffusion maps, a two-step nonlinear
dimension reduction technique which allows us to reduce the dimensionality of
the data and identify meaningful geometric descriptions in a parsimonious and
inexpensive manner. Polynomial chaos expansion is then used to construct a
mapping between the stochastic input parameters and the diffusion coordinates
of the reduced space. An adaptive clustering technique is proposed to identify
an optimal number of clusters of points in the latent space. The similarity of
points allows us to construct a number of geometric harmonic emulators which
are finally utilized as a set of inexpensive pre-trained models to perform an
inverse map of realizations of latent features to the ambient space and thus
perform accurate out-of-sample predictions. Thus, the proposed method acts as
an encoder-decoder system which is able to automatically handle very
high-dimensional data while simultaneously operating successfully in the
small-data regime. The method is demonstrated on two benchmark problems and on
a system of advection-diffusion-reaction equations which model a first-order
chemical reaction between two species. In all test cases, the proposed method
is able to achieve highly accurate approximations which ultimately lead to the
significant acceleration of UQ tasks.

    

### [[2107.09815] A Factor Graph-based approach to vehicle sideslip angle estimation](http://arxiv.org/abs/2107.09815)


  Sideslip angle is an important variable for understanding and monitoring
vehicle dynamics but it lacks an inexpensive method for direct measurement.
Therefore, it is typically estimated from inertial and other proprioceptive
sensors onboard using filtering methods from the family of the Kalman Filter.
As a novel alternative, this work proposes modelling the problem directly as a
graphical model (factor graph), which can then be optimized using a variety of
methods, such as whole dataset batch optimization for offline processing or
fixed-lag smoother for on-line operation. Experimental results on real vehicle
datasets validate the proposal with a good agreement between estimated and
actual sideslip angle, showing similar performance than the state-of-the-art
with a great potential for future extensions due to the flexible mathematical
framework.

    

### [[2107.09817] Audio Captioning Transformer](http://arxiv.org/abs/2107.09817)


  Audio captioning aims to automatically generate a natural language
description of an audio clip. Most captioning models follow an encoder-decoder
architecture, where the decoder predicts words based on the audio features
extracted by the encoder. Convolutional neural networks (CNNs) and recurrent
neural networks (RNNs) are often used as the audio encoder. However, CNNs can
be limited in modelling temporal relationships among the time frames in an
audio signal, while RNNs can be limited in modelling the long-range
dependencies among the time frames. In this paper, we propose an Audio
Captioning Transformer (ACT), which is a full Transformer network based on an
encoder-decoder architecture and is totally convolution-free. The proposed
method has a better ability to model the global information within an audio
signal as well as capture temporal relationships between audio events. We
evaluate our model on AudioCaps, which is the largest audio captioning dataset
publicly available. Our model shows competitive performance compared to other
state-of-the-art approaches.

    

### [[2107.09853] EMG Pattern Recognition via Bayesian Inference with Scale Mixture-Based Stochastic Generative Models](http://arxiv.org/abs/2107.09853)


  Electromyogram (EMG) has been utilized to interface signals for prosthetic
hands and information devices owing to its ability to reflect human motion
intentions. Although various EMG classification methods have been introduced
into EMG-based control systems, they do not fully consider the stochastic
characteristics of EMG signals. This paper proposes an EMG pattern
classification method incorporating a scale mixture-based generative model. A
scale mixture model is a stochastic EMG model in which the EMG variance is
considered as a random variable, enabling the representation of uncertainty in
the variance. This model is extended in this study and utilized for EMG pattern
classification. The proposed method is trained by variational Bayesian
learning, thereby allowing the automatic determination of the model complexity.
Furthermore, to optimize the hyperparameters of the proposed method with a
partial discriminative approach, a mutual information-based determination
method is introduced. Simulation and EMG analysis experiments demonstrated the
relationship between the hyperparameters and classification accuracy of the
proposed method as well as the validity of the proposed method. The comparison
using public EMG datasets revealed that the proposed method outperformed the
various conventional classifiers. These results indicated the validity of the
proposed method and its applicability to EMG-based control systems. In EMG
pattern recognition, a classifier based on a generative model that reflects the
stochastic characteristics of EMG signals can outperform the conventional
general-purpose classifier.

    

### [[2107.09869] ECG Heartbeat Classification Using Multimodal Fusion](http://arxiv.org/abs/2107.09869)


  Electrocardiogram (ECG) is an authoritative source to diagnose and counter
critical cardiovascular syndromes such as arrhythmia and myocardial infarction
(MI). Current machine learning techniques either depend on manually extracted
features or large and complex deep learning networks which merely utilize the
1D ECG signal directly. Since intelligent multimodal fusion can perform at the
stateof-the-art level with an efficient deep network, therefore, in this paper,
we propose two computationally efficient multimodal fusion frameworks for ECG
heart beat classification called Multimodal Image Fusion (MIF) and Multimodal
Feature Fusion (MFF). At the input of these frameworks, we convert the raw ECG
data into three different images using Gramian Angular Field (GAF), Recurrence
Plot (RP) and Markov Transition Field (MTF). In MIF, we first perform image
fusion by combining three imaging modalities to create a single image modality
which serves as input to the Convolutional Neural Network (CNN). In MFF, we
extracted features from penultimate layer of CNNs and fused them to get unique
and interdependent information necessary for better performance of classifier.
These informational features are finally used to train a Support Vector Machine
(SVM) classifier for ECG heart-beat classification. We demonstrate the
superiority of the proposed fusion models by performing experiments on
PhysioNets MIT-BIH dataset for five distinct conditions of arrhythmias which
are consistent with the AAMI EC57 protocols and on PTB diagnostics dataset for
Myocardial Infarction (MI) classification. We achieved classification accuracy
of 99.7% and 99.2% on arrhythmia and MI classification, respectively.

    

### [[2107.09883] MG-NET: Leveraging Pseudo-Imaging for Multi-Modal Metagenome Analysis](http://arxiv.org/abs/2107.09883)


  The emergence of novel pathogens and zoonotic diseases like the SARS-CoV-2
have underlined the need for developing novel diagnosis and intervention
pipelines that can learn rapidly from small amounts of labeled data. Combined
with technological advances in next-generation sequencing, metagenome-based
diagnostic tools hold much promise to revolutionize rapid point-of-care
diagnosis. However, there are significant challenges in developing such an
approach, the chief among which is to learn self-supervised representations
that can help detect novel pathogen signatures with very low amounts of labeled
data. This is particularly a difficult task given that closely related
pathogens can share more than 90% of their genome structure. In this work, we
address these challenges by proposing MG-Net, a self-supervised representation
learning framework that leverages multi-modal context using pseudo-imaging data
derived from clinical metagenome sequences. We show that the proposed framework
can learn robust representations from unlabeled data that can be used for
downstream tasks such as metagenome sequence classification with limited access
to labeled data. Extensive experiments show that the learned features
outperform current baseline metagenome representations, given only 1000 samples
per class.

    

### [[2107.09892] Towards Lower-Dose PET using Physics-Based Uncertainty-Aware Multimodal Learning with Robustness to Out-of-Distribution Data](http://arxiv.org/abs/2107.09892)


  Radiation exposure in positron emission tomography (PET) imaging limits its
usage in the studies of radiation-sensitive populations, e.g., pregnant women,
children, and adults that require longitudinal imaging. Reducing the PET
radiotracer dose or acquisition time reduces photon counts, which can
deteriorate image quality. Recent deep-neural-network (DNN) based methods for
image-to-image translation enable the mapping of low-quality PET images
(acquired using substantially reduced dose), coupled with the associated
magnetic resonance imaging (MRI) images, to high-quality PET images. However,
such DNN methods focus on applications involving test data that match the
statistical characteristics of the training data very closely and give little
attention to evaluating the performance of these DNNs on new
out-of-distribution (OOD) acquisitions. We propose a novel DNN formulation that
models the (i) underlying sinogram-based physics of the PET imaging system and
(ii) the uncertainty in the DNN output through the per-voxel heteroscedasticity
of the residuals between the predicted and the high-quality reference images.
Our sinogram-based uncertainty-aware DNN framework, namely, suDNN, estimates a
standard-dose PET image using multimodal input in the form of (i) a
low-dose/low-count PET image and (ii) the corresponding multi-contrast MRI
images, leading to improved robustness of suDNN to OOD acquisitions. Results on
in vivo simultaneous PET-MRI, and various forms of OOD data in PET-MRI, show
the benefits of suDNN over the current state of the art, quantitatively and
qualitatively.

    

### [[2107.09898] Defending against Reconstruction Attack in Vertical Federated Learning](http://arxiv.org/abs/2107.09898)


  Recently researchers have studied input leakage problems in Federated
Learning (FL) where a malicious party can reconstruct sensitive training inputs
provided by users from shared gradient. It raises concerns about FL since input
leakage contradicts the privacy-preserving intention of using FL. Despite a
relatively rich literature on attacks and defenses of input reconstruction in
Horizontal FL, input leakage and protection in vertical FL starts to draw
researcher's attention recently. In this paper, we study how to defend against
input leakage attacks in Vertical FL. We design an adversarial training-based
framework that contains three modules: adversarial reconstruction, noise
regularization, and distance correlation minimization. Those modules can not
only be employed individually but also applied together since they are
independent to each other. Through extensive experiments on a large-scale
industrial online advertising dataset, we show our framework is effective in
protecting input privacy while retaining the model utility.

    

### [[2107.09904] Integration of Autoencoder and Functional Link Artificial Neural Network for Multi-label Classification](http://arxiv.org/abs/2107.09904)


  Multi-label (ML) classification is an actively researched topic currently,
which deals with convoluted and overlapping boundaries that arise due to
several labels being active for a particular data instance. We propose a
classifier capable of extracting underlying features and introducing
non-linearity to the data to handle the complex decision boundaries. A novel
neural network model has been developed where the input features are subjected
to two transformations adapted from multi-label functional link artificial
neural network and autoencoders. First, a functional expansion of the original
features are made using basis functions. This is followed by an
autoencoder-aided transformation and reduction on the expanded features. This
network is capable of improving separability for the multi-label data owing to
the two-layer transformation while reducing the expanded feature space to a
more manageable amount. This balances the input dimension which leads to a
better classification performance even for a limited amount of data. The
proposed network has been validated on five ML datasets which shows its
superior performance in comparison with six well-established ML classifiers.
Furthermore, a single-label variation of the proposed network has also been
formulated simultaneously and tested on four relevant datasets against three
existing classifiers to establish its effectiveness.

    

### [[2107.09912] Design of Experiments for Stochastic Contextual Linear Bandits](http://arxiv.org/abs/2107.09912)


  In the stochastic linear contextual bandit setting there exist several
minimax procedures for exploration with policies that are reactive to the data
being acquired. In practice, there can be a significant engineering overhead to
deploy these algorithms, especially when the dataset is collected in a
distributed fashion or when a human in the loop is needed to implement a
different policy. Exploring with a single non-reactive policy is beneficial in
such cases. Assuming some batch contexts are available, we design a single
stochastic policy to collect a good dataset from which a near-optimal policy
can be extracted. We present a theoretical analysis as well as numerical
experiments on both synthetic and real-world datasets.

    

### [[2107.09927] GLIME: A new graphical methodology for interpretable model-agnostic explanations](http://arxiv.org/abs/2107.09927)


  Explainable artificial intelligence (XAI) is an emerging new domain in which
a set of processes and tools allow humans to better comprehend the decisions
generated by black box models. However, most of the available XAI tools are
often limited to simple explanations mainly quantifying the impact of
individual features to the models' output. Therefore, human users are not able
to understand how the features are related to each other to make predictions,
whereas the inner workings of the trained models remain hidden. This paper
contributes to the development of a novel graphical explainability tool that
not only indicates the significant features of the model but also reveals the
conditional relationships between features and the inference capturing both the
direct and indirect impact of features to the models' decision. The proposed
XAI methodology, termed as gLIME, provides graphical model-agnostic
explanations either at the global (for the entire dataset) or the local scale
(for specific data points). It relies on a combination of local interpretable
model-agnostic explanations (LIME) with graphical least absolute shrinkage and
selection operator (GLASSO) producing undirected Gaussian graphical models.
Regularization is adopted to shrink small partial correlation coefficients to
zero providing sparser and more interpretable graphical explanations. Two
well-known classification datasets (BIOPSY and OAI) were selected to confirm
the superiority of gLIME over LIME in terms of both robustness and consistency
over multiple permutations. Specifically, gLIME accomplished increased
stability over the two datasets with respect to features' importance (76%-96%
compared to 52%-77% using LIME). gLIME demonstrates a unique potential to
extend the functionality of the current state-of-the-art in XAI by providing
informative graphically given explanations that could unlock black boxes.

    

### [[2107.09931] The Effectiveness of Intermediate-Task Training for Code-Switched Natural Language Understanding](http://arxiv.org/abs/2107.09931)


  While recent benchmarks have spurred a lot of new work on improving the
generalization of pretrained multilingual language models on multilingual
tasks, techniques to improve code-switched natural language understanding tasks
have been far less explored. In this work, we propose the use of bilingual
intermediate pretraining as a reliable technique to derive large and consistent
performance gains on three different NLP tasks using code-switched text. We
achieve substantial absolute improvements of 7.87%, 20.15%, and 10.99%, on the
mean accuracies and F1 scores over previous state-of-the-art systems for
Hindi-English Natural Language Inference (NLI), Question Answering (QA) tasks,
and Spanish-English Sentiment Analysis (SA) respectively. We show consistent
performance gains on four different code-switched language-pairs
(Hindi-English, Spanish-English, Tamil-English and Malayalam-English) for SA.
We also present a code-switched masked language modelling (MLM) pretraining
technique that consistently benefits SA compared to standard MLM pretraining
using real code-switched text.

    

### [[2107.09936] Predicting Issue Types on GitHub](http://arxiv.org/abs/2107.09936)


  Software maintenance and evolution involves critical activities for the
success of software projects. To support such activities and keep code
up-to-date and error-free, software communities make use of issue trackers,
i.e., tools for signaling, handling, and addressing the issues occurring in
software systems. However, in popular projects, tens or hundreds of issue
reports are daily submitted. In this context, identifying the type of each
submitted report (e.g., bug report, feature request, etc.) would facilitate the
management and the prioritization of the issues to address. To support issue
handling activities, in this paper, we propose Ticket Tagger, a GitHub app
analyzing the issue title and description through machine learning techniques
to automatically recognize the types of reports submitted on GitHub and assign
labels to each issue accordingly. We empirically evaluated the tool's
prediction performance on about 30,000 GitHub issues. Our results show that the
Ticket Tagger can identify the correct labels to assign to GitHub issues with
reasonably high effectiveness. Considering these results and the fact that the
tool is designed to be easily integrated in the GitHub issue management
process, Ticket Tagger consists in a useful solution for developers.

    

### [[2107.09937] Fast and Scalable Adversarial Training of Kernel SVM via Doubly Stochastic Gradients](http://arxiv.org/abs/2107.09937)


  Adversarial attacks by generating examples which are almost indistinguishable
from natural examples, pose a serious threat to learning models. Defending
against adversarial attacks is a critical element for a reliable learning
system. Support vector machine (SVM) is a classical yet still important
learning algorithm even in the current deep learning era. Although a wide range
of researches have been done in recent years to improve the adversarial
robustness of learning models, but most of them are limited to deep neural
networks (DNNs) and the work for kernel SVM is still vacant. In this paper, we
aim at kernel SVM and propose adv-SVM to improve its adversarial robustness via
adversarial training, which has been demonstrated to be the most promising
defense techniques. To the best of our knowledge, this is the first work that
devotes to the fast and scalable adversarial training of kernel SVM.
Specifically, we first build connection of perturbations of samples between
original and kernel spaces, and then give a reduced and equivalent formulation
of adversarial training of kernel SVM based on the connection. Next, doubly
stochastic gradients (DSG) based on two unbiased stochastic approximations
(i.e., one is on training points and another is on random features) are applied
to update the solution of our objective function. Finally, we prove that our
algorithm optimized by DSG converges to the optimal solution at the rate of
O(1/t) under the constant and diminishing stepsizes. Comprehensive experimental
results show that our adversarial training algorithm enjoys robustness against
various attacks and meanwhile has the similar efficiency and scalability with
classical DSG algorithm.

    

### [[2107.09947] Preventing dataset shift from breaking machine-learning biomarkers](http://arxiv.org/abs/2107.09947)


  Machine learning brings the hope of finding new biomarkers extracted from
cohorts with rich biomedical measurements. A good biomarker is one that gives
reliable detection of the corresponding condition. However, biomarkers are
often extracted from a cohort that differs from the target population. Such a
mismatch, known as a dataset shift, can undermine the application of the
biomarker to new individuals. Dataset shifts are frequent in biomedical
research, e.g. because of recruitment biases. When a dataset shift occurs,
standard machine-learning techniques do not suffice to extract and validate
biomarkers. This article provides an overview of when and how dataset shifts
breaks machine-learning extracted biomarkers, as well as detection and
correction strategies.

    

### [[2107.09949] Online structural kernel selection for mobile health](http://arxiv.org/abs/2107.09949)


  Motivated by the need for efficient and personalized learning in mobile
health, we investigate the problem of online kernel selection for Gaussian
Process regression in the multi-task setting. We propose a novel generative
process on the kernel composition for this purpose. Our method demonstrates
that trajectories of kernel evolutions can be transferred between users to
improve learning and that the kernels themselves are meaningful for an mHealth
prediction goal.

    

### [[2107.09950] Boundary of Distribution Support Generator (BDSG): Sample Generation on the Boundary](http://arxiv.org/abs/2107.09950)


  Generative models, such as Generative Adversarial Networks (GANs), have been
used for unsupervised anomaly detection. While performance keeps improving,
several limitations exist particularly attributed to difficulties at capturing
multimodal supports and to the ability to approximate the underlying
distribution closer to the tails, i.e. the boundary of the distribution's
support. This paper proposes an approach that attempts to alleviate such
shortcomings. We propose an invertible-residual-network-based model, the
Boundary of Distribution Support Generator (BDSG). GANs generally do not
guarantee the existence of a probability distribution and here, we use the
recently developed Invertible Residual Network (IResNet) and Residual Flow
(ResFlow), for density estimation. These models have not yet been used for
anomaly detection. We leverage IResNet and ResFlow for Out-of-Distribution
(OoD) sample detection and for sample generation on the boundary using a
compound loss function that forces the samples to lie on the boundary. The BDSG
addresses non-convex support, disjoint components, and multimodal
distributions. Results on synthetic data and data from multimodal
distributions, such as MNIST and CIFAR-10, demonstrate competitive performance
compared to methods from the literature.

    

### [[2107.09951] Deep learning for temporal data representation in electronic health records: A systematic review of challenges and methodologies](http://arxiv.org/abs/2107.09951)


  Objective: Temporal electronic health records (EHRs) can be a wealth of
information for secondary uses, such as clinical events prediction or chronic
disease management. However, challenges exist for temporal data representation.
We therefore sought to identify these challenges and evaluate novel
methodologies for addressing them through a systematic examination of deep
learning solutions.
Methods: We searched five databases (PubMed, EMBASE, the Institute of
Electrical and Electronics Engineers [IEEE] Xplore Digital Library, the
Association for Computing Machinery [ACM] digital library, and Web of Science)
complemented with hand-searching in several prestigious computer science
conference proceedings. We sought articles that reported deep learning
methodologies on temporal data representation in structured EHR data from
January 1, 2010, to August 30, 2020. We summarized and analyzed the selected
articles from three perspectives: nature of time series, methodology, and model
implementation.
Results: We included 98 articles related to temporal data representation
using deep learning. Four major challenges were identified, including data
irregularity, data heterogeneity, data sparsity, and model opacity. We then
studied how deep learning techniques were applied to address these challenges.
Finally, we discuss some open challenges arising from deep learning.
Conclusion: Temporal EHR data present several major challenges for clinical
prediction modeling and data utilization. To some extent, current deep learning
solutions can address these challenges. Future studies can consider designing
comprehensive and integrated solutions. Moreover, researchers should
incorporate additional clinical domain knowledge into study designs and enhance
the interpretability of the model to facilitate its implementation in clinical
practice.

    

### [[2107.09957] Memorization in Deep Neural Networks: Does the Loss Function matter?](http://arxiv.org/abs/2107.09957)


  Deep Neural Networks, often owing to the overparameterization, are shown to
be capable of exactly memorizing even randomly labelled data. Empirical studies
have also shown that none of the standard regularization techniques mitigate
such overfitting. We investigate whether the choice of the loss function can
affect this memorization. We empirically show, with benchmark data sets MNIST
and CIFAR-10, that a symmetric loss function, as opposed to either
cross-entropy or squared error loss, results in significant improvement in the
ability of the network to resist such overfitting. We then provide a formal
definition for robustness to memorization and provide a theoretical explanation
as to why the symmetric losses provide this robustness. Our results clearly
bring out the role loss functions alone can play in this phenomenon of
memorization.

    

### [[2107.09989] High-Resolution Pelvic MRI Reconstruction Using a Generative Adversarial Network with Attention and Cyclic Loss](http://arxiv.org/abs/2107.09989)


  Magnetic resonance imaging (MRI) is an important medical imaging modality,
but its acquisition speed is quite slow due to the physiological limitations.
Recently, super-resolution methods have shown excellent performance in
accelerating MRI. In some circumstances, it is difficult to obtain
high-resolution images even with prolonged scan time. Therefore, we proposed a
novel super-resolution method that uses a generative adversarial network (GAN)
with cyclic loss and attention mechanism to generate high-resolution MR images
from low-resolution MR images by a factor of 2. We implemented our model on
pelvic images from healthy subjects as training and validation data, while
those data from patients were used for testing. The MR dataset was obtained
using different imaging sequences, including T2, T2W SPAIR, and mDIXON-W. Four
methods, i.e., BICUBIC, SRCNN, SRGAN, and EDSR were used for comparison.
Structural similarity, peak signal to noise ratio, root mean square error, and
variance inflation factor were used as calculation indicators to evaluate the
performances of the proposed method. Various experimental results showed that
our method can better restore the details of the high-resolution MR image as
compared to the other methods. In addition, the reconstructed high-resolution
MR image can provide better lesion textures in the tumor patients, which is
promising to be used in clinical diagnosis.

    

### [[2107.09996] MarsExplorer: Exploration of Unknown Terrains via Deep Reinforcement Learning and Procedurally Generated Environments](http://arxiv.org/abs/2107.09996)


  This paper is an initial endeavor to bridge the gap between powerful Deep
Reinforcement Learning methodologies and the problem of exploration/coverage of
unknown terrains. Within this scope, MarsExplorer, an openai-gym compatible
environment tailored to exploration/coverage of unknown areas, is presented.
MarsExplorer translates the original robotics problem into a Reinforcement
Learning setup that various off-the-shelf algorithms can tackle. Any learned
policy can be straightforwardly applied to a robotic platform without an
elaborate simulation model of the robot's dynamics to apply a different
learning/adaptation phase. One of its core features is the controllable
multi-dimensional procedural generation of terrains, which is the key for
producing policies with strong generalization capabilities. Four different
state-of-the-art RL algorithms (A3C, PPO, Rainbow, and SAC) are trained on the
MarsExplorer environment, and a proper evaluation of their results compared to
the average human-level performance is reported. In the follow-up experimental
analysis, the effect of the multi-dimensional difficulty setting on the
learning capabilities of the best-performing algorithm (PPO) is analyzed. A
milestone result is the generation of an exploration policy that follows the
Hilbert curve without providing this information to the environment or
rewarding directly or indirectly Hilbert-curve-like trajectories. The
experimental analysis is concluded by comparing PPO learned policy results with
frontier-based exploration context for extended terrain sizes. The source code
can be found at: this https URL.

    

### [[2107.10004] Deep Iterative 2D/3D Registration](http://arxiv.org/abs/2107.10004)


  Deep Learning-based 2D/3D registration methods are highly robust but often
lack the necessary registration accuracy for clinical application. A refinement
step using the classical optimization-based 2D/3D registration method applied
in combination with Deep Learning-based techniques can provide the required
accuracy. However, it also increases the runtime. In this work, we propose a
novel Deep Learning driven 2D/3D registration framework that can be used
end-to-end for iterative registration tasks without relying on any further
refinement step. We accomplish this by learning the update step of the 2D/3D
registration framework using Point-to-Plane Correspondences. The update step is
learned using iterative residual refinement-based optical flow estimation, in
combination with the Point-to-Plane correspondence solver embedded as a known
operator. Our proposed method achieves an average runtime of around 8s, a mean
re-projection distance error of 0.60 $\pm$ 0.40 mm with a success ratio of 97
percent and a capture range of 60 mm. The combination of high registration
accuracy, high robustness, and fast runtime makes our solution ideal for
clinical applications.

    

### [[2107.10006] Window Detection In Facade Imagery: A Deep Learning Approach Using Mask R-CNN](http://arxiv.org/abs/2107.10006)


  The parsing of windows in building facades is a long-desired but challenging
task in computer vision. It is crucial to urban analysis, semantic
reconstruction, lifecycle analysis, digital twins, and scene parsing amongst
other building-related tasks that require high-quality semantic data. This
article investigates the usage of the mask R-CNN framework to be used for
window detection of facade imagery input. We utilize transfer learning to train
our proposed method on COCO weights with our own collected dataset of street
view images of facades to produce instance segmentations of our new window
class. Experimental results show that our suggested approach with a relatively
small dataset trains the network only with transfer learning and augmentation
achieves results on par with prior state-of-the-art window detection
approaches, even without post-optimization techniques.

    

### [[2107.10014] Delving Into Deep Walkers: A Convergence Analysis of Random-Walk-Based Vertex Embeddings](http://arxiv.org/abs/2107.10014)


  Graph vertex embeddings based on random walks have become increasingly
influential in recent years, showing good performance in several tasks as they
efficiently transform a graph into a more computationally digestible format
while preserving relevant information. However, the theoretical properties of
such algorithms, in particular the influence of hyperparameters and of the
graph structure on their convergence behaviour, have so far not been
well-understood. In this work, we provide a theoretical analysis for
random-walks based embeddings techniques. Firstly, we prove that, under some
weak assumptions, vertex embeddings derived from random walks do indeed
converge both in the single limit of the number of random walks $N \to \infty$
and in the double limit of both $N$ and the length of each random walk
$L\to\infty$. Secondly, we derive concentration bounds quantifying the converge
rate of the corpora for the single and double limits. Thirdly, we use these
results to derive a heuristic for choosing the hyperparameters $N$ and $L$. We
validate and illustrate the practical importance of our findings with a range
of numerical and visual experiments on several graphs drawn from real-world
applications.

    

### [[2107.10015] Relational Graph Convolutional Networks: A Closer Look](http://arxiv.org/abs/2107.10015)


  In this paper, we describe a reproduction of the Relational Graph
Convolutional Network (RGCN). Using our reproduction, we explain the intuition
behind the model. Our reproduction results empirically validate the correctness
of our implementations using benchmark Knowledge Graph datasets on node
classification and link prediction tasks. Our explanation provides a friendly
understanding of the different components of the RGCN for both users and
researchers extending the RGCN approach. Furthermore, we introduce two new
configurations of the RGCN that are more parameter efficient. The code and
datasets are available at this https URL.

    

### [[2107.10030] Differentiable Feature Selection, a Reparameterization Approach](http://arxiv.org/abs/2107.10030)


  We consider the task of feature selection for reconstruction which consists
in choosing a small subset of features from which whole data instances can be
reconstructed. This is of particular importance in several contexts involving
for example costly physical measurements, sensor placement or information
compression. To break the intrinsic combinatorial nature of this problem, we
formulate the task as optimizing a binary mask distribution enabling an
accurate reconstruction. We then face two main challenges. One concerns
differentiability issues due to the binary distribution. The second one
corresponds to the elimination of redundant information by selecting variables
in a correlated fashion which requires modeling the covariance of the binary
distribution. We address both issues by introducing a relaxation of the problem
via a novel reparameterization of the logitNormal distribution. We demonstrate
that the proposed method provides an effective exploration scheme and leads to
efficient feature selection for reconstruction through evaluation on several
high dimensional image benchmarks. We show that the method leverages the
intrinsic geometry of the data, facilitating reconstruction.

    

### [[2107.10034] Learning Theorem Proving Components](http://arxiv.org/abs/2107.10034)


  Saturation-style automated theorem provers (ATPs) based on the given clause
procedure are today the strongest general reasoners for classical first-order
logic. The clause selection heuristics in such systems are, however, often
evaluating clauses in isolation, ignoring other clauses. This has changed
recently by equipping the E/ENIGMA system with a graph neural network (GNN)
that chooses the next given clause based on its evaluation in the context of
previously selected clauses. In this work, we describe several algorithms and
experiments with ENIGMA, advancing the idea of contextual evaluation based on
learning important components of the graph of clauses.

    

### [[2107.10043] KalmanNet: Neural Network Aided Kalman Filtering for Partially Known Dynamics](http://arxiv.org/abs/2107.10043)


  Real-time state estimation of dynamical systems is a fundamental task in
signal processing and control. For systems that are well-represented by a fully
known linear Gaussian state space (SS) model, the celebrated Kalman filter (KF)
is a low complexity optimal solution. However, both linearity of the underlying
SS model and accurate knowledge of it are often not encountered in practice.
Here, we present KalmanNet, a real-time state estimator that learns from data
to carry out Kalman filtering under non-linear dynamics with partial
information. By incorporating the structural SS model with a dedicated
recurrent neural network module in the flow of the KF, we retain data
efficiency and interpretability of the classic algorithm while implicitly
learning complex dynamics from data. We numerically demonstrate that KalmanNet
overcomes nonlinearities and model mismatch, outperforming classic filtering
methods operating with both mismatched and accurate domain knowledge.

    

### [[2107.10060] CGANs with Auxiliary Discriminative Classifier](http://arxiv.org/abs/2107.10060)


  Conditional generative models aim to learn the underlying joint distribution
of data and labels, and thus realize conditional generation. Among them,
auxiliary classifier generative adversarial networks (AC-GAN) have been widely
used, but suffer from the issue of low intra-class diversity on generated
samples. In this paper, we point out that the fundamental reason is that the
classifier of AC-GAN is generator-agnostic, and thus cannot provide informative
guidance to the generator to approximate the target joint distribution, leading
to a minimization of conditional entropy that decreases the intra-class
diversity. Based on this finding, we propose novel cGANs with auxiliary
discriminative classifier (ADC-GAN) to address the issue of AC-GAN.
Specifically, the auxiliary discriminative classifier becomes generator-aware
by distinguishing between the real and fake data while recognizing their
labels. We then optimize the generator based on the auxiliary classifier along
with the original discriminator to match the joint and marginal distributions
of the generated samples with those of the real samples. We provide theoretical
analysis and empirical evidence on synthetic and real-world datasets to
demonstrate the superiority of the proposed ADC-GAN compared to competitive
cGANs.

    

### [[2107.10066] Adaptive Inducing Points Selection For Gaussian Processes](http://arxiv.org/abs/2107.10066)


  Gaussian Processes (\textbf{GPs}) are flexible non-parametric models with
strong probabilistic interpretation. While being a standard choice for
performing inference on time series, GPs have few techniques to work in a
streaming setting. \cite{bui2017streaming} developed an efficient variational
approach to train online GPs by using sparsity techniques: The whole set of
observations is approximated by a smaller set of inducing points (\textbf{IPs})
and moved around with new data. Both the number and the locations of the IPs
will affect greatly the performance of the algorithm. In addition to optimizing
their locations, we propose to adaptively add new points, based on the
properties of the GP and the structure of the data.

    

### [[2107.10072] Interpreting diffusion score matching using normalizing flow](http://arxiv.org/abs/2107.10072)


  Scoring matching (SM), and its related counterpart, Stein discrepancy (SD)
have achieved great success in model training and evaluations. However, recent
research shows their limitations when dealing with certain types of
distributions. One possible fix is incorporating the original score matching
(or Stein discrepancy) with a diffusion matrix, which is called diffusion score
matching (DSM) (or diffusion Stein discrepancy (DSD)). However, the lack of
interpretation of the diffusion limits its usage within simple distributions
and manually chosen matrix. In this work, we plan to fill this gap by
interpreting the diffusion matrix using normalizing flows. Specifically, we
theoretically prove that DSM (or DSD) is equivalent to the original score
matching (or Stein discrepancy) evaluated in the transformed space defined by
the normalizing flow, where the diffusion matrix is the inverse of the flow's
Jacobian matrix. In addition, we also build its connection to Riemannian
manifolds and further extend it to continuous flows, where the change of DSM is
characterized by an ODE.

    

### [[2107.10093] Incentivizing Compliance with Algorithmic Instruments](http://arxiv.org/abs/2107.10093)


  Randomized experiments can be susceptible to selection bias due to potential
non-compliance by the participants. While much of the existing work has studied
compliance as a static behavior, we propose a game-theoretic model to study
compliance as dynamic behavior that may change over time. In rounds, a social
planner interacts with a sequence of heterogeneous agents who arrive with their
unobserved private type that determines both their prior preferences across the
actions (e.g., control and treatment) and their baseline rewards without taking
any treatment. The planner provides each agent with a randomized recommendation
that may alter their beliefs and their action selection. We develop a novel
recommendation mechanism that views the planner's recommendation as a form of
instrumental variable (IV) that only affects an agents' action selection, but
not the observed rewards. We construct such IVs by carefully mapping the
history -- the interactions between the planner and the previous agents -- to a
random recommendation. Even though the initial agents may be completely
non-compliant, our mechanism can incentivize compliance over time, thereby
enabling the estimation of the treatment effect of each treatment, and
minimizing the cumulative regret of the planner whose goal is to identify the
optimal treatment.

    

### [[2107.10098] Discovering Latent Causal Variables via Mechanism Sparsity: A New Principle for Nonlinear ICA](http://arxiv.org/abs/2107.10098)


  It can be argued that finding an interpretable low-dimensional representation
of a potentially high-dimensional phenomenon is central to the scientific
enterprise. Independent component analysis (ICA) refers to an ensemble of
methods which formalize this goal and provide estimation procedure for
practical application. This work proposes mechanism sparsity regularization as
a new principle to achieve nonlinear ICA when latent factors depend sparsely on
observed auxiliary variables and/or past latent factors. We show that the
latent variables can be recovered up to a permutation if one regularizes the
latent mechanisms to be sparse and if some graphical criterion is satisfied by
the data generating process. As a special case, our framework shows how one can
leverage unknown-target interventions on the latent factors to disentangle
them, thus drawing further connections between ICA and causality. We validate
our theoretical results with toy experiments.

    

### [[2107.10110] On the Convergence of Prior-Guided Zeroth-Order Optimization Algorithms](http://arxiv.org/abs/2107.10110)


  Zeroth-order (ZO) optimization is widely used to handle challenging tasks,
such as query-based black-box adversarial attacks and reinforcement learning.
Various attempts have been made to integrate prior information into the
gradient estimation procedure based on finite differences, with promising
empirical results. However, their convergence properties are not well
understood. This paper makes an attempt to fill this gap by analyzing the
convergence of prior-guided ZO algorithms under a greedy descent framework with
various gradient estimators. We provide a convergence guarantee for the
prior-guided random gradient-free (PRGF) algorithms. Moreover, to further
accelerate over greedy descent methods, we present a new accelerated random
search (ARS) algorithm that incorporates prior information, together with a
convergence analysis. Finally, our theoretical results are confirmed by
experiments on several numerical benchmarks as well as adversarial attacks.

    

### [[2107.10111] Training Electric Vehicle Charging Controllers with Imitation Learning](http://arxiv.org/abs/2107.10111)


  The problem of coordinating the charging of electric vehicles gains more
importance as the number of such vehicles grows. In this paper, we develop a
method for the training of controllers for the coordination of EV charging. In
contrast to most existing works on this topic, we require the controllers to
preserve the privacy of the users, therefore we do not allow any communication
from the controller to any third party.
In order to train the controllers, we use the idea of imitation learning --
we first find an optimum solution for a relaxed version of the problem using
quadratic optimization and then train the controllers to imitate this solution.
We also investigate the effects of regularization of the optimum solution on
the performance of the controllers. The method is evaluated on realistic data
and shows improved performance and training speed compared to similar
controllers trained using evolutionary algorithms.

    

### [[2107.10125] A variational approximate posterior for the deep Wishart process](http://arxiv.org/abs/2107.10125)


  Recent work introduced deep kernel processes as an entirely kernel-based
alternative to NNs (Aitchison et al. 2020). Deep kernel processes flexibly
learn good top-layer representations by alternately sampling the kernel from a
distribution over positive semi-definite matrices and performing nonlinear
transformations. A particular deep kernel process, the deep Wishart process
(DWP), is of particular interest because its prior is equivalent to deep
Gaussian process (DGP) priors. However, inference in DWPs has not yet been
possible due to the lack of sufficiently flexible distributions over positive
semi-definite matrices. Here, we give a novel approach to obtaining flexible
distributions over positive semi-definite matrices by generalising the Bartlett
decomposition of the Wishart probability density. We use this new distribution
to develop an approximate posterior for the DWP that includes dependency across
layers. We develop a doubly-stochastic inducing-point inference scheme for the
DWP and show experimentally that inference in the DWP gives improved
performance over doing inference in a DGP with the equivalent prior.

    

### [[2107.10140] S4T: Source-free domain adaptation for semantic segmentation via self-supervised selective self-training](http://arxiv.org/abs/2107.10140)


  Most modern approaches for domain adaptive semantic segmentation rely on
continued access to source data during adaptation, which may be infeasible due
to computational or privacy constraints. We focus on source-free domain
adaptation for semantic segmentation, wherein a source model must adapt itself
to a new target domain given only unlabeled target data. We propose
Self-Supervised Selective Self-Training (S4T), a source-free adaptation
algorithm that first uses the model's pixel-level predictive consistency across
diverse views of each target image along with model confidence to classify
pixel predictions as either reliable or unreliable. Next, the model is
self-trained, using predicted pseudolabels for reliable predictions and
pseudolabels inferred via a selective interpolation strategy for unreliable
ones. S4T matches or improves upon the state-of-the-art in source-free
adaptation on 3 standard benchmarks for semantic segmentation within a single
epoch of adaptation.

    

### [[2107.10143] On the Memorization Properties of Contrastive Learning](http://arxiv.org/abs/2107.10143)


  Memorization studies of deep neural networks (DNNs) help to understand what
patterns and how do DNNs learn, and motivate improvements to DNN training
approaches. In this work, we investigate the memorization properties of SimCLR,
a widely used contrastive self-supervised learning approach, and compare them
to the memorization of supervised learning and random labels training. We find
that both training objects and augmentations may have different complexity in
the sense of how SimCLR learns them. Moreover, we show that SimCLR is similar
to random labels training in terms of the distribution of training objects
complexity.

    

### [[2107.10146] A Deep Reinforcement Learning Approach for Fair Traffic Signal Control](http://arxiv.org/abs/2107.10146)


  Traffic signal control is one of the most effective methods of traffic
management in urban areas. In recent years, traffic control methods based on
deep reinforcement learning (DRL) have gained attention due to their ability to
exploit real-time traffic data, which is often poorly used by the traditional
hand-crafted methods. While most recent DRL-based methods have focused on
maximizing the throughput or minimizing the average travel time of the
vehicles, the fairness of the traffic signal controllers has often been
neglected. This is particularly important as neglecting fairness can lead to
situations where some vehicles experience extreme waiting times, or where the
throughput of a particular traffic flow is highly impacted by the fluctuations
of another conflicting flow at the intersection. In order to address these
issues, we introduce two notions of fairness: delay-based and throughput-based
fairness, which correspond to the two issues mentioned above. Furthermore, we
propose two DRL-based traffic signal control methods for implementing these
fairness notions, that can achieve a high throughput as well. We evaluate the
performance of our proposed methods using three traffic arrival distributions,
and find that our methods outperform the baselines in the tested scenarios.

    

### [[2107.10154] Predicting trajectory behaviour via machine-learned invariant manifolds](http://arxiv.org/abs/2107.10154)


  In this paper we use support vector machines (SVM) to develop a machine
learning framework to discover the phase space structure that can distinguish
between distinct reaction pathways. The machine learning model is trained using
data from trajectories of Hamilton's equations but lends itself for use in
molecular dynamics simulation. The framework is specifically designed to
require minimal a priori knowledge of the dynamics in a system. We benchmark
our approach with a model Hamiltonian for the reaction of an ion and a molecule
due to Chesnavich consisting of two parts: a rigid, symmetric top representing
the $\text{CH}_3^{+}$ ion, and a mobile $\text{H}$ atom. We begin with
trajectories and use support vector machines to determine the boundaries
between initial conditions corresponding to different classes of trajectories.
We then show that these boundaries between different classes of trajectories
approximate invariant phase space structures of the same type observed in
earlier analyses of Chesnavich's model. Our approach is designed with
extensions to higher-dimensional applications in mind. SVM is known to work
well even with small amounts of data, therefore our approach is computationally
better suited than existing methods for high-dimensional systems and systems
where integrating trajectories is expensive.

    

### [[2107.10159] Answer-Set Programs for Reasoning about Counterfactual Interventions and Responsibility Scores for Classification](http://arxiv.org/abs/2107.10159)


  We describe how answer-set programs can be used to declaratively specify
counterfactual interventions on entities under classification, and reason about
them. In particular, they can be used to define and compute responsibility
scores as attribution-based explanations for outcomes from classification
models. The approach allows for the inclusion of domain knowledge and supports
query answering. A detailed example with a naive-Bayes classifier is presented.

    

### [[2107.10171] Leave-one-out Unfairness](http://arxiv.org/abs/2107.10171)


  We introduce leave-one-out unfairness, which characterizes how likely a
model's prediction for an individual will change due to the inclusion or
removal of a single other person in the model's training data. Leave-one-out
unfairness appeals to the idea that fair decisions are not arbitrary: they
should not be based on the chance event of any one person's inclusion in the
training data. Leave-one-out unfairness is closely related to algorithmic
stability, but it focuses on the consistency of an individual point's
prediction outcome over unit changes to the training data, rather than the
error of the model in aggregate. Beyond formalizing leave-one-out unfairness,
we characterize the extent to which deep models behave leave-one-out unfairly
on real data, including in cases where the generalization error is small.
Further, we demonstrate that adversarial training and randomized smoothing
techniques have opposite effects on leave-one-out fairness, which sheds light
on the relationships between robustness, memorization, individual fairness, and
leave-one-out fairness in deep models. Finally, we discuss salient practical
applications that may be negatively affected by leave-one-out unfairness.

    

### [[2107.10174] Black-box Probe for Unsupervised Domain Adaptation without Model Transferring](http://arxiv.org/abs/2107.10174)


  In recent years, researchers have been paying increasing attention to the
threats brought by deep learning models to data security and privacy,
especially in the field of domain adaptation. Existing unsupervised domain
adaptation (UDA) methods can achieve promising performance without transferring
data from source domain to target domain. However, UDA with representation
alignment or self-supervised pseudo-labeling relies on the transferred source
models. In many data-critical scenarios, methods based on model transferring
may suffer from membership inference attacks and expose private data. In this
paper, we aim to overcome a challenging new setting where the source models are
only queryable but cannot be transferred to the target domain. We propose
Black-box Probe Domain Adaptation (BPDA), which adopts query mechanism to probe
and refine information from source model using third-party dataset. In order to
gain more informative query results, we further propose Distributionally
Adversarial Training (DAT) to align the distribution of third-party data with
that of target data. BPDA uses public third-party dataset and adversarial
examples based on DAT as the information carrier between source and target
domains, dispensing with transferring source data or model. Experimental
results on benchmarks of Digit-Five, Office-Caltech, Office-31, Office-Home,
and DomainNet demonstrate the feasibility of BPDA without model transferring.

    

### [[2107.10188] JEFL: Joint Embedding of Formal Proof Libraries](http://arxiv.org/abs/2107.10188)


  The heterogeneous nature of the logical foundations used in different
interactive proof assistant libraries has rendered discovery of similar
mathematical concepts among them difficult. In this paper, we compare a
previously proposed algorithm for matching concepts across libraries with our
unsupervised embedding approach that can help us retrieve similar concepts. Our
approach is based on the fasttext implementation of Word2Vec, on top of which a
tree traversal module is added to adapt its algorithm to the representation
format of our data export pipeline. We compare the explainability,
customizability, and online-servability of the approaches and argue that the
neural embedding approach has more potential to be integrated into an
interactive proof assistant.

    

### [[2107.10199] Distribution of Classification Margins: Are All Data Equal?](http://arxiv.org/abs/2107.10199)


  Recent theoretical results show that gradient descent on deep neural networks
under exponential loss functions locally maximizes classification margin, which
is equivalent to minimizing the norm of the weight matrices under margin
constraints. This property of the solution however does not fully characterize
the generalization performance. We motivate theoretically and show empirically
that the area under the curve of the margin distribution on the training set is
in fact a good measure of generalization. We then show that, after data
separation is achieved, it is possible to dynamically reduce the training set
by more than 99% without significant loss of performance. Interestingly, the
resulting subset of "high capacity" features is not consistent across different
training runs, which is consistent with the theoretical claim that all training
points should converge to the same asymptotic margin under SGD and in the
presence of both batch normalization and weight decay.

    

### [[2107.10201] Learning a Large Neighborhood Search Algorithm for Mixed Integer Programs](http://arxiv.org/abs/2107.10201)


  Large Neighborhood Search (LNS) is a combinatorial optimization heuristic
that starts with an assignment of values for the variables to be optimized, and
iteratively improves it by searching a large neighborhood around the current
assignment. In this paper we consider a learning-based LNS approach for mixed
integer programs (MIPs). We train a Neural Diving model to represent a
probability distribution over assignments, which, together with an existing MIP
solver, generates an initial assignment. Formulating the subsequent search
steps as a Markov Decision Process, we train a Neural Neighborhood Selection
policy to select a search neighborhood at each step, which is searched using a
MIP solver to find the next assignment. The policy network is trained using
imitation learning. We propose a target policy for imitation that, given enough
compute resources, is guaranteed to select the neighborhood containing the
optimal next assignment across all possible choices for the neighborhood of a
specified size. Our approach matches or outperforms all the baselines on five
real-world MIP datasets with large-scale instances from diverse applications,
including two production applications at Google. At large running times it
achieves $2\times$ to $37.8\times$ better average primal gap than the best
baseline on three of the datasets.

    

### [[2107.10209] Efficient Algorithms for Learning Depth-2 Neural Networks with General ReLU Activations](http://arxiv.org/abs/2107.10209)


  We present polynomial time and sample efficient algorithms for learning an
unknown depth-2 feedforward neural network with general ReLU activations, under
mild non-degeneracy assumptions. In particular, we consider learning an unknown
network of the form $f(x) = {a}^{\mathsf{T}}\sigma({W}^\mathsf{T}x+b)$, where
$x$ is drawn from the Gaussian distribution, and $\sigma(t) := \max(t,0)$ is
the ReLU activation. Prior works for learning networks with ReLU activations
assume that the bias $b$ is zero. In order to deal with the presence of the
bias terms, our proposed algorithm consists of robustly decomposing multiple
higher order tensors arising from the Hermite expansion of the function $f(x)$.
Using these ideas we also establish identifiability of the network parameters
under minimal assumptions.

    

### [[2107.10211] Differentiable Annealed Importance Sampling and the Perils of Gradient Noise](http://arxiv.org/abs/2107.10211)


  Annealed importance sampling (AIS) and related algorithms are highly
effective tools for marginal likelihood estimation, but are not fully
differentiable due to the use of Metropolis-Hastings (MH) correction steps.
Differentiability is a desirable property as it would admit the possibility of
optimizing marginal likelihood as an objective using gradient-based methods. To
this end, we propose a differentiable AIS algorithm by abandoning MH steps,
which further unlocks mini-batch computation. We provide a detailed convergence
analysis for Bayesian linear regression which goes beyond previous analyses by
explicitly accounting for non-perfect transitions. Using this analysis, we
prove that our algorithm is consistent in the full-batch setting and provide a
sublinear convergence rate. However, we show that the algorithm is inconsistent
when mini-batch gradients are used due to a fundamental incompatibility between
the goals of last-iterate convergence to the posterior and elimination of the
pathwise stochastic error. This result is in stark contrast to our experience
with stochastic optimization and stochastic gradient Langevin dynamics, where
the effects of gradient noise can be washed out by taking more steps of a
smaller size. Our negative result relies crucially on our explicit
consideration of convergence to the stationary distribution, and it helps
explain the difficulty of developing practically effective AIS-like algorithms
that exploit mini-batch gradients.

    

### [[2107.10234] Bridging the Gap between Spatial and Spectral Domains: A Theoretical Framework for Graph Neural Networks](http://arxiv.org/abs/2107.10234)


  During the past decade, deep learning's performance has been widely
recognized in a variety of machine learning tasks, ranging from image
classification, speech recognition to natural language understanding. Graph
neural networks (GNN) are a type of deep learning that is designed to handle
non-Euclidean issues using graph-structured data that are difficult to solve
with traditional deep learning techniques. The majority of GNNs were created
using a variety of processes, including random walk, PageRank, graph
convolution, and heat diffusion, making direct comparisons impossible. Previous
studies have primarily focused on classifying current models into distinct
categories, with little investigation of their internal relationships. This
research proposes a unified theoretical framework and a novel perspective that
can methodologically integrate existing GNN into our framework. We survey and
categorize existing GNN models into spatial and spectral domains, as well as
show linkages between subcategories within each domain. Further investigation
reveals a strong relationship between the spatial, spectral, and subgroups of
these domains.

    

### [[2107.10236] Using system context information to complement weakly labeled data](http://arxiv.org/abs/2107.10236)


  Real-world datasets collected with sensor networks often contain incomplete
and uncertain labels as well as artefacts arising from the system environment.
Complete and reliable labeling is often infeasible for large-scale and
long-term sensor network deployments due to the labor and time overhead,
limited availability of experts and missing ground truth. In addition, if the
machine learning method used for analysis is sensitive to certain features of a
deployment, labeling and learning needs to be repeated for every new
deployment. To address these challenges, we propose to make use of system
context information formalized in an information graph and embed it in the
learning process via contrastive learning. Based on real-world data we show
that this approach leads to an increased accuracy in case of weakly labeled
data and leads to an increased robustness and transferability of the classifier
to new sensor locations.

    

### [[2107.10239] Machine Learning for Real-World Evidence Analysis of COVID-19 Pharmacotherapy](http://arxiv.org/abs/2107.10239)


  Introduction: Real-world data generated from clinical practice can be used to
analyze the real-world evidence (RWE) of COVID-19 pharmacotherapy and validate
the results of randomized clinical trials (RCTs). Machine learning (ML) methods
are being used in RWE and are promising tools for precision-medicine. In this
study, ML methods are applied to study the efficacy of therapies on COVID-19
hospital admissions in the Valencian Region in Spain. Methods: 5244 and 1312
COVID-19 hospital admissions - dated between January 2020 and January 2021 from
10 health departments, were used respectively for training and validation of
separate treatment-effect models (TE-ML) for remdesivir, corticosteroids,
tocilizumab, lopinavir-ritonavir, azithromycin and
chloroquine/hydroxychloroquine. 2390 admissions from 2 additional health
departments were reserved as an independent test to analyze retrospectively the
survival benefits of therapies in the population selected by the TE-ML models
using cox-proportional hazard models. TE-ML models were adjusted using
treatment propensity scores to control for pre-treatment confounding variables
associated to outcome and further evaluated for futility. ML architecture was
based on boosted decision-trees. Results: In the populations identified by the
TE-ML models, only Remdesivir and Tocilizumab were significantly associated
with an increase in survival time, with hazard ratios of 0.41 (P = 0.04) and
0.21 (P = 0.001), respectively. No survival benefits from chloroquine
derivatives, lopinavir-ritonavir and azithromycin were demonstrated. Tools to
explain the predictions of TE-ML models are explored at patient-level as
potential tools for personalized decision making and precision medicine.
Conclusion: ML methods are suitable tools toward RWE analysis of COVID-19
pharmacotherapies. Results obtained reproduce published results on RWE and
validate the results from RCTs.

    

### [[2107.10243] Federated Learning using Smart Contracts on Blockchains, based on Reward Driven Approach](http://arxiv.org/abs/2107.10243)


  Over the recent years, Federated machine learning continues to gain interest
and momentum where there is a need to draw insights from data while preserving
the data provider's privacy. However, one among other existing challenges in
the adoption of federated learning has been the lack of fair, transparent and
universally agreed incentivization schemes for rewarding the federated learning
contributors. Smart contracts on a blockchain network provide transparent,
immutable and independently verifiable proofs by all participants of the
network. We leverage this open and transparent nature of smart contracts on a
blockchain to define incentivization rules for the contributors, which is based
on a novel scalar quantity - federated contribution. Such a smart contract
based reward-driven model has the potential to revolutionize the federated
learning adoption in enterprises. Our contribution is two-fold: first is to
show how smart contract based blockchain can be a very natural communication
channel for federated learning. Second, leveraging this infrastructure, we can
show how an intuitive measure of each agents' contribution can be built and
integrated with the life cycle of the training and reward process.

    

### [[2107.10253] Demonstration-Guided Reinforcement Learning with Learned Skills](http://arxiv.org/abs/2107.10253)


  Demonstration-guided reinforcement learning (RL) is a promising approach for
learning complex behaviors by leveraging both reward feedback and a set of
target task demonstrations. Prior approaches for demonstration-guided RL treat
every new task as an independent learning problem and attempt to follow the
provided demonstrations step-by-step, akin to a human trying to imitate a
completely unseen behavior by following the demonstrator's exact muscle
movements. Naturally, such learning will be slow, but often new behaviors are
not completely unseen: they share subtasks with behaviors we have previously
learned. In this work, we aim to exploit this shared subtask structure to
increase the efficiency of demonstration-guided RL. We first learn a set of
reusable skills from large offline datasets of prior experience collected
across many tasks. We then propose Skill-based Learning with Demonstrations
(SkiLD), an algorithm for demonstration-guided RL that efficiently leverages
the provided demonstrations by following the demonstrated skills instead of the
primitive actions, resulting in substantial performance improvements over prior
demonstration-guided RL approaches. We validate the effectiveness of our
approach on long-horizon maze navigation and complex robot manipulation tasks.

    

### [[2107.10254] Neural Fixed-Point Acceleration for Convex Optimization](http://arxiv.org/abs/2107.10254)


  Fixed-point iterations are at the heart of numerical computing and are often
a computational bottleneck in real-time applications, which typically instead
need a fast solution of moderate accuracy. Classical acceleration methods for
fixed-point problems focus on designing algorithms with theoretical guarantees
that apply to any fixed-point problem. We present neural fixed-point
acceleration, a framework to automatically learn to accelerate convex
fixed-point problems that are drawn from a distribution, using ideas from
meta-learning and classical acceleration algorithms. We apply our framework to
SCS, the state-of-the-art solver for convex cone programming, and design models
and loss functions to overcome the challenges of learning over unrolled
optimization and acceleration instabilities. Our work brings neural
acceleration into any optimization problem expressible with CVXPY. The source
code behind this paper is available at
this https URL


### [[1808.01345] Investigating the performance of multi-objective optimization when learning Bayesian Networks](http://arxiv.org/abs/1808.01345)


  Bayesian Networks have been widely used in the last decades in many fields,
to describe statistical dependencies among random variables. In general,
learning the structure of such models is a problem with considerable
theoretical interest that poses many challenges. On the one hand, it is a
well-known NP-complete problem, practically hardened by the huge search space
of possible solutions. On the other hand, the phenomenon of I-equivalence,
i.e., different graphical structures underpinning the same set of statistical
dependencies, may lead to multimodal fitness landscapes further hindering
maximum likelihood approaches to solve the task. In particular, we exploit the
NSGA-II multi-objective optimization procedure in order to explicitly account
for both the likelihood of a solution and the number of selected arcs, by
setting these as the two objective functions of the method. The aim of this
work is to investigate the behavior of NSGA-II and analyse the quality of its
solutions. We thus thoroughly examined the optimization results obtained on a
wide set of simulated data, by considering both the goodness of the inferred
solutions in terms of the objective functions values achieved, and by comparing
the retrieved structures with the ground truth, i.e., the networks used to
generate the target data. Our results show that NSGA-II can converge to
solutions characterized by better likelihood and less arcs than classic
approaches, although paradoxically characterized in many cases by a lower
similarity with the target network.

    

### [[1811.02319] Fast Hyperparameter Optimization of Deep Neural Networks via Ensembling Multiple Surrogates](http://arxiv.org/abs/1811.02319)


  The performance of deep neural networks crucially depends on good
hyperparameter configurations. Bayesian optimization is a powerful framework
for optimizing the hyperparameters of DNNs. These methods need sufficient
evaluation data to approximate and minimize the validation error function of
hyperparameters. However, the expensive evaluation cost of DNNs leads to very
few evaluation data within a limited time, which greatly reduces the efficiency
of Bayesian optimization. Besides, the previous researches focus on using the
complete evaluation data to conduct Bayesian optimization, and ignore the
intermediate evaluation data generated by early stopping methods. To alleviate
the insufficient evaluation data problem, we propose a fast hyperparameter
optimization method, HOIST, that utilizes both the complete and intermediate
evaluation data to accelerate the hyperparameter optimization of DNNs.
Specifically, we train multiple basic surrogates to gather information from the
mixed evaluation data, and then combine all basic surrogates using weighted
bagging to provide an accurate ensemble surrogate. Our empirical studies show
that HOIST outperforms the state-of-the-art approaches on a wide range of DNNs,
including feed forward neural networks, convolutional neural networks,
recurrent neural networks, and variational autoencoder.

    

### [[1905.08616] Unsupervised Depth Completion from Visual Inertial Odometry](http://arxiv.org/abs/1905.08616)


  We describe a method to infer dense depth from camera motion and sparse depth
as estimated using a visual-inertial odometry system. Unlike other scenarios
using point clouds from lidar or structured light sensors, we have few hundreds
to few thousand points, insufficient to inform the topology of the scene. Our
method first constructs a piecewise planar scaffolding of the scene, and then
uses it to infer dense depth using the image along with the sparse points. We
use a predictive cross-modal criterion, akin to `self-supervision,' measuring
photometric consistency across time, forward-backward pose consistency, and
geometric compatibility with the sparse point cloud. We also launch the first
visual-inertial + depth dataset, which we hope will foster additional
exploration into combining the complementary strengths of visual and inertial
sensors. To compare our method to prior work, we adopt the unsupervised KITTI
depth completion benchmark, and show state-of-the-art performance on it. Code
available at:
this https URL.

    

### [[2002.01335] Structural Inductive Biases in Emergent Communication](http://arxiv.org/abs/2002.01335)


  In order to communicate, humans flatten a complex representation of ideas and
their attributes into a single word or a sentence. We investigate the impact of
representation learning in artificial agents by developing graph referential
games. We empirically show that agents parametrized by graph neural networks
develop a more compositional language compared to bag-of-words and sequence
models, which allows them to systematically generalize to new combinations of
familiar features.

    

### [[2002.04225] Regularized Evolutionary Population-Based Training](http://arxiv.org/abs/2002.04225)


  Metalearning of deep neural network (DNN) architectures and hyperparameters
has become an increasingly important area of research. At the same time,
network regularization has been recognized as a crucial dimension to effective
training of DNNs. However, the role of metalearning in establishing effective
regularization has not yet been fully explored. There is recent evidence that
loss-function optimization could play this role, however it is computationally
impractical as an outer loop to full training. This paper presents an algorithm
called Evolutionary Population-Based Training (EPBT) that interleaves the
training of a DNN's weights with the metalearning of loss functions. They are
parameterized using multivariate Taylor expansions that EPBT can directly
optimize. Such simultaneous adaptation of weights and loss functions can be
deceptive, and therefore EPBT uses a quality-diversity heuristic called Novelty
Pulsation as well as knowledge distillation to prevent overfitting during
training. On the CIFAR-10 and SVHN image classification benchmarks, EPBT
results in faster, more accurate learning. The discovered hyperparameters adapt
to the training process and serve to regularize the learning task by
discouraging overfitting to the labels. EPBT thus demonstrates a practical
instantiation of regularization metalearning based on simultaneous training.

    

### [[2002.11867] Bridging the Gap between Spatial and Spectral Domains: A Survey on Graph Neural Networks](http://arxiv.org/abs/2002.11867)


  Deep learning's success has been widely recognized in a variety of machine
learning tasks, including image classification, audio recognition, and natural
language processing. As an extension of deep learning beyond these domains,
graph neural networks (GNNs) are designed to handle the non-Euclidean
graph-structure which is intractable to previous deep learning techniques.
Existing GNNs are presented using various techniques, making direct comparison
and cross-reference more complex. Although existing studies categorize GNNs
into spatial-based and spectral-based techniques, there hasn't been a thorough
examination of their relationship. To close this gap, this study presents a
single framework that systematically incorporates most GNNs. We organize
existing GNNs into spatial and spectral domains, as well as expose the
connections within each domain. A review of spectral graph theory and
approximation theory builds a strong relationship across the spatial and
spectral domains in further investigation.

    

### [[2003.01247] Iterative Averaging in the Quest for Best Test Error](http://arxiv.org/abs/2003.01247)


  We analyse and explain the increased generalisation performance
\latestEdits{of} Iterate Averaging using a Gaussian Process perturbation model
between the true and batch risk surface on the high dimensional quadratic. %
Based on our theoretical results We derive three phenomena \latestEdits{from
our theoretical results:} (1) The importance of combining iterate averaging
with large learning rates and regularisation for improved regularisation (2)
Justification for less frequent averaging. (3) That we expect adaptive gradient
methods to work equally well or better with iterate averaging than their non
adaptive counterparts. Inspired by these results\latestEdits{, together with}
empirical investigations of the importance of appropriate regularisation for
the solution diversity of the iterates, we propose two adaptive algorithms with
iterate averaging. \latestEdits{These} give significantly better results than
SGD, require less tuning and do not require early stopping or validation set
monitoring. We showcase the efficacy of our approach on the CIFAR-10/100,
ImageNet and Penn Treebank datasets on a variety of modern and classical
network architectures.

    

### [[2004.05867] On the Neural Tangent Kernel of Deep Networks with Orthogonal Initialization](http://arxiv.org/abs/2004.05867)


  The prevailing thinking is that orthogonal weights are crucial to enforcing
dynamical isometry and speeding up training. The increase in learning speed
that results from orthogonal initialization in linear networks has been
well-proven. However, while the same is believed to also hold for nonlinear
networks when the dynamical isometry condition is satisfied, the training
dynamics behind this contention have not been thoroughly explored. In this
work, we study the dynamics of ultra-wide networks across a range of
architectures, including Fully Connected Networks (FCNs) and Convolutional
Neural Networks (CNNs) with orthogonal initialization via neural tangent kernel
(NTK). Through a series of propositions and lemmas, we prove that two NTKs, one
corresponding to Gaussian weights and one to orthogonal weights, are equal when
the network width is infinite. Further, during training, the NTK of an
orthogonally-initialized infinite-width network should theoretically remain
constant. This suggests that the orthogonal initialization cannot speed up
training in the NTK (lazy training) regime, contrary to the prevailing
thoughts. In order to explore under what circumstances can orthogonality
accelerate training, we conduct a thorough empirical investigation outside the
NTK regime. We find that when the hyper-parameters are set to achieve a linear
regime in nonlinear activation, orthogonal initialization can improve the
learning speed with a large learning rate or large depth.

    

### [[2005.02356] Manifold Proximal Point Algorithms for Dual Principal Component Pursuit and Orthogonal Dictionary Learning](http://arxiv.org/abs/2005.02356)


  We consider the problem of maximizing the $\ell_1$ norm of a linear map over
the sphere, which arises in various machine learning applications such as
orthogonal dictionary learning (ODL) and robust subspace recovery (RSR). The
problem is numerically challenging due to its nonsmooth objective and nonconvex
constraint, and its algorithmic aspects have not been well explored. In this
paper, we show how the manifold structure of the sphere can be exploited to
design fast algorithms for tackling this problem. Specifically, our
contribution is threefold. First, we present a manifold proximal point
algorithm (ManPPA) for the problem and show that it converges at a sublinear
rate. Furthermore, we show that ManPPA can achieve a quadratic convergence rate
when applied to the ODL and RSR problems. Second, we propose a stochastic
variant of ManPPA called StManPPA, which is well suited for large-scale
computation, and establish its sublinear convergence rate. Both ManPPA and
StManPPA have provably faster convergence rates than existing subgradient-type
methods. Third, using ManPPA as a building block, we propose a new approach to
solving a matrix analog of the problem, in which the sphere is replaced by the
Stiefel manifold. The results from our extensive numerical experiments on the
ODL and RSR problems demonstrate the efficiency and efficacy of our proposed
methods.

    

### [[2006.01508] Inductive Geometric Matrix Midranges](http://arxiv.org/abs/2006.01508)


  Covariance data as represented by symmetric positive definite (SPD) matrices
are ubiquitous throughout technical study as efficient descriptors of
interdependent systems. Euclidean analysis of SPD matrices, while
computationally fast, can lead to skewed and even unphysical interpretations of
data. Riemannian methods preserve the geometric structure of SPD data at the
cost of expensive eigenvalue computations. In this paper, we propose a
geometric method for unsupervised clustering of SPD data based on the Thompson
metric. This technique relies upon a novel "inductive midrange" centroid
computation for SPD data, whose properties are examined and numerically
confirmed. We demonstrate the incorporation of the Thompson metric and
inductive midrange into X-means and K-means++ clustering algorithms.

    

### [[2006.07487] Scalable Control Variates for Monte Carlo Methods via Stochastic Optimization](http://arxiv.org/abs/2006.07487)


  Control variates are a well-established tool to reduce the variance of Monte
Carlo estimators. However, for large-scale problems including high-dimensional
and large-sample settings, their advantages can be outweighed by a substantial
computational cost. This paper considers control variates based on Stein
operators, presenting a framework that encompasses and generalizes existing
approaches that use polynomials, kernels and neural networks. A learning
strategy based on minimising a variational objective through stochastic
optimization is proposed, leading to scalable and effective control variates.
Novel theoretical results are presented to provide insight into the variance
reduction that can be achieved, and an empirical assessment, including
applications to Bayesian inference, is provided in support.

    

### [[2006.12063] Deep Residual Mixture Models](http://arxiv.org/abs/2006.12063)


  We propose Deep Residual Mixture Models (DRMMs), a novel deep generative
model architecture. Compared to other deep models, DRMMs allow more flexible
conditional sampling: The model can be trained once with all variables, and
then used for sampling with arbitrary combinations of conditioning variables,
Gaussian priors, and (in)equality constraints. This provides new opportunities
for interactive and exploratory machine learning, where one should minimize the
user waiting for retraining a model. We demonstrate DRMMs in constrained
multi-limb inverse kinematics and controllable generation of animations.

    

### [[2008.06043] Offline Meta-Reinforcement Learning with Advantage Weighting](http://arxiv.org/abs/2008.06043)


  This paper introduces the offline meta-reinforcement learning (offline
meta-RL) problem setting and proposes an algorithm that performs well in this
setting. Offline meta-RL is analogous to the widely successful supervised
learning strategy of pre-training a model on a large batch of fixed,
pre-collected data (possibly from various tasks) and fine-tuning the model to a
new task with relatively little data. That is, in offline meta-RL, we
meta-train on fixed, pre-collected data from several tasks in order to adapt to
a new task with a very small amount (less than 5 trajectories) of data from the
new task. By nature of being offline, algorithms for offline meta-RL can
utilize the largest possible pool of training data available and eliminate
potentially unsafe or costly data collection during meta-training. This setting
inherits the challenges of offline RL, but it differs significantly because
offline RL does not generally consider a) transfer to new tasks or b) limited
data from the test task, both of which we face in offline meta-RL. Targeting
the offline meta-RL setting, we propose Meta-Actor Critic with Advantage
Weighting (MACAW), an optimization-based meta-learning algorithm that uses
simple, supervised regression objectives for both the inner and outer loop of
meta-training. On offline variants of common meta-RL benchmarks, we empirically
find that this approach enables fully offline meta-reinforcement learning and
achieves notable gains over prior methods.

    

### [[2010.00130] Computing Graph Neural Networks: A Survey from Algorithms to Accelerators](http://arxiv.org/abs/2010.00130)


  Graph Neural Networks (GNNs) have exploded onto the machine learning scene in
recent years owing to their capability to model and learn from graph-structured
data. Such an ability has strong implications in a wide variety of fields whose
data is inherently relational, for which conventional neural networks do not
perform well. Indeed, as recent reviews can attest, research in the area of
GNNs has grown rapidly and has lead to the development of a variety of GNN
algorithm variants as well as to the exploration of groundbreaking applications
in chemistry, neurology, electronics, or communication networks, among others.
At the current stage of research, however, the efficient processing of GNNs is
still an open challenge for several reasons. Besides of their novelty, GNNs are
hard to compute due to their dependence on the input graph, their combination
of dense and very sparse operations, or the need to scale to huge graphs in
some applications. In this context, this paper aims to make two main
contributions. On the one hand, a review of the field of GNNs is presented from
the perspective of computing. This includes a brief tutorial on the GNN
fundamentals, an overview of the evolution of the field in the last decade, and
a summary of operations carried out in the multiple phases of different GNN
algorithm variants. On the other hand, an in-depth analysis of current software
and hardware acceleration schemes is provided, from which a hardware-software,
graph-aware, and communication-centric vision for GNN accelerators is
distilled.

    

### [[2010.14496] $γ$-Models: Generative Temporal Difference Learning for Infinite-Horizon Prediction](http://arxiv.org/abs/2010.14496)


  We introduce the $\gamma$-model, a predictive model of environment dynamics
with an infinite probabilistic horizon. Replacing standard single-step models
with $\gamma$-models leads to generalizations of the procedures central to
model-based control, including the model rollout and model-based value
estimation. The $\gamma$-model, trained with a generative reinterpretation of
temporal difference learning, is a natural continuous analogue of the successor
representation and a hybrid between model-free and model-based mechanisms. Like
a value function, it contains information about the long-term future; like a
standard predictive model, it is independent of task reward. We instantiate the
$\gamma$-model as both a generative adversarial network and normalizing flow,
discuss how its training reflects an inescapable tradeoff between training-time
and testing-time compounding errors, and empirically investigate its utility
for prediction and control.

    

### [[2011.00515] On Signal-to-Noise Ratio Issues in Variational Inference for Deep Gaussian Processes](http://arxiv.org/abs/2011.00515)


  We show that the gradient estimates used in training Deep Gaussian Processes
(DGPs) with importance-weighted variational inference are susceptible to
signal-to-noise ratio (SNR) issues. Specifically, we show both theoretically
and via an extensive empirical evaluation that the SNR of the gradient
estimates for the latent variable's variational parameters decreases as the
number of importance samples increases. As a result, these gradient estimates
degrade to pure noise if the number of importance samples is too large. To
address this pathology, we show how doubly reparameterized gradient estimators,
originally proposed for training variational autoencoders, can be adapted to
the DGP setting and that the resultant estimators completely remedy the SNR
issue, thereby providing more reliable training. Finally, we demonstrate that
our fix can lead to consistent improvements in the predictive performance of
DGP models.

    

### [[2012.12310] Mixture Model Framework for Traumatic Brain Injury Prognosis Using Heterogeneous Clinical and Outcome Data](http://arxiv.org/abs/2012.12310)


  Prognoses of Traumatic Brain Injury (TBI) outcomes are neither easily nor
accurately determined from clinical indicators. This is due in part to the
heterogeneity of damage inflicted to the brain, ultimately resulting in diverse
and complex outcomes. Using a data-driven approach on many distinct data
elements may be necessary to describe this large set of outcomes and thereby
robustly depict the nuanced differences among TBI patients' recovery. In this
work, we develop a method for modeling large heterogeneous data types relevant
to TBI. Our approach is geared toward the probabilistic representation of mixed
continuous and discrete variables with missing values. The model is trained on
a dataset encompassing a variety of data types, including demographics,
blood-based biomarkers, and imaging findings. In addition, it includes a set of
clinical outcome assessments at 3, 6, and 12 months post-injury. The model is
used to stratify patients into distinct groups in an unsupervised learning
setting. We use the model to infer outcomes using input data, and show that the
collection of input data reduces uncertainty of outcomes over a baseline
approach. In addition, we quantify the performance of a likelihood scoring
technique that can be used to self-evaluate the extrapolation risk of prognosis
on unseen patients.

    

### [[2101.05303] Understanding the Effect of Out-of-distribution Examples and Interactive Explanations on Human-AI Decision Making](http://arxiv.org/abs/2101.05303)


  Although AI holds promise for improving human decision making in societally
critical domains, it remains an open question how human-AI teams can reliably
outperform AI alone and human alone in challenging prediction tasks (also known
as complementary performance). We explore two directions to understand the gaps
in achieving complementary performance. First, we argue that the typical
experimental setup limits the potential of human-AI teams. To account for lower
AI performance out-of-distribution than in-distribution because of distribution
shift, we design experiments with different distribution types and investigate
human performance for both in-distribution and out-of-distribution examples.
Second, we develop novel interfaces to support interactive explanations so that
humans can actively engage with AI assistance. Using virtual pilot studies and
large-scale randomized experiments across three tasks, we demonstrate a clear
difference between in-distribution and out-of-distribution, and observe mixed
results for interactive explanations: while interactive explanations improve
human perception of AI assistance's usefulness, they may reinforce human biases
and lead to limited performance improvement. Overall, our work points out
critical challenges and future directions towards enhancing human performance
with AI assistance.

    

### [[2101.07948] SparseDNN: Fast Sparse Deep Learning Inference on CPUs](http://arxiv.org/abs/2101.07948)


  The last few years have seen gigantic leaps in algorithms and systems to
support efficient deep learning inference. Pruning and quantization algorithms
can now consistently compress neural networks by an order of magnitude. For a
compressed neural network, a multitude of inference frameworks have been
designed to maximize the performance of the target hardware. While we find
mature support for quantized neural networks in production frameworks such as
OpenVINO and MNN, support for pruned sparse neural networks is still lacking.
To tackle this challenge, we present SparseDNN, a sparse deep learning
inference engine targeting CPUs. We present both kernel-level optimizations
with a sparse code generator to accelerate sparse operators and novel
network-level optimizations catering to sparse networks. We show that our
sparse code generator can achieve significant speedups over state-of-the-art
sparse and dense libraries. On end-to-end benchmarks such as Huggingface
pruneBERT, SparseDNN achieves up to 5x throughput improvement over dense
inference with state-of-the-art OpenVINO. Open source library at:
this https URL.

    

### [[2101.12741] Post-OCR Paragraph Recognition by Graph Convolutional Networks](http://arxiv.org/abs/2101.12741)


  Paragraphs are an important class of document entities. We propose a new
approach for paragraph identification by spatial graph convolutional neural
networks (GCN) applied on OCR text boxes. Two steps, namely line splitting and
line clustering, are performed to extract paragraphs from the lines in OCR
results. Each step uses a beta-skeleton graph constructed from bounding boxes,
where the graph edges provide efficient support for graph convolution
operations. With only pure layout input features, the GCN model size is 3~4
orders of magnitude smaller compared to R-CNN based models, while achieving
comparable or better accuracies on PubLayNet and other datasets. Furthermore,
the GCN models show good generalization from synthetic training data to
real-world images, and good adaptivity for variable document styles.

    

### [[2102.00931] Information-Theoretic Generalization Bounds for Stochastic Gradient Descent](http://arxiv.org/abs/2102.00931)


  We study the generalization properties of the popular stochastic optimization
method known as stochastic gradient descent (SGD) for optimizing general
non-convex loss functions. Our main contribution is providing upper bounds on
the generalization error that depend on local statistics of the stochastic
gradients evaluated along the path of iterates calculated by SGD. The key
factors our bounds depend on are the variance of the gradients (with respect to
the data distribution) and the local smoothness of the objective function along
the SGD path, and the sensitivity of the loss function to perturbations to the
final output. Our key technical tool is combining the information-theoretic
generalization bounds previously used for analyzing randomized variants of SGD
with a perturbation analysis of the iterates.

    

### [[2102.03159] Active Slices for Sliced Stein Discrepancy](http://arxiv.org/abs/2102.03159)


  Sliced Stein discrepancy (SSD) and its kernelized variants have demonstrated
promising successes in goodness-of-fit tests and model learning in high
dimensions. Despite their theoretical elegance, their empirical performance
depends crucially on the search of optimal slicing directions to discriminate
between two distributions. Unfortunately, previous gradient-based optimisation
approaches for this task return sub-optimal results: they are computationally
expensive, sensitive to initialization, and they lack theoretical guarantees
for convergence. We address these issues in two steps. First, we provide
theoretical results stating that the requirement of using optimal slicing
directions in the kernelized version of SSD can be relaxed, validating the
resulting discrepancy with finite random slicing directions. Second, given that
good slicing directions are crucial for practical performance, we propose a
fast algorithm for finding such slicing directions based on ideas of active
sub-space construction and spectral decomposition. Experiments on
goodness-of-fit tests and model learning show that our approach achieves both
improved performance and faster convergence. Especially, we demonstrate a
14-80x speed-up in goodness-of-fit tests when comparing with gradient-based
alternatives.

    

### [[2102.05373] GuiltyWalker: Distance to illicit nodes in the Bitcoin network](http://arxiv.org/abs/2102.05373)


  Money laundering is a global phenomenon with wide-reaching social and
economic consequences. Cryptocurrencies are particularly susceptible due to the
lack of control by authorities and their anonymity. Thus, it is important to
develop new techniques to detect and prevent illicit cryptocurrency
transactions. In our work, we propose new features based on the structure of
the graph and past labels to boost the performance of machine learning methods
to detect money laundering. Our method, GuiltyWalker, performs random walks on
the bitcoin transaction graph and computes features based on the distance to
illicit transactions. We combine these new features with features proposed by
Weber et al. and observe an improvement of about 5pp regarding illicit
classification. Namely, we observe that our proposed features are particularly
helpful during a black market shutdown, where the algorithm by Weber et al. was
low performing.

    

### [[2102.05855] Differential Privacy Dynamics of Langevin Diffusion and Noisy Gradient Descent](http://arxiv.org/abs/2102.05855)


  What is the information leakage of an iterative learning algorithm about its
training data, when the internal state of the algorithm is \emph{not}
observable? How much is the contribution of each specific training epoch to the
final leakage? We study this problem for noisy gradient descent algorithms, and
model the \emph{dynamics} of Rényi differential privacy loss throughout the
training process. Our analysis traces a provably tight bound on the Rényi
divergence between the pair of probability distributions over parameters of
models with neighboring datasets. We prove that the privacy loss converges
exponentially fast, for smooth and strongly convex loss functions, which is a
significant improvement over composition theorems. For Lipschitz, smooth, and
strongly convex loss functions, we prove optimal utility for differential
privacy algorithms with a small gradient complexity.

    

### [[2102.12903] Self-Tuning for Data-Efficient Deep Learning](http://arxiv.org/abs/2102.12903)


  Deep learning has made revolutionary advances to diverse applications in the
presence of large-scale labeled datasets. However, it is prohibitively
time-costly and labor-expensive to collect sufficient labeled data in most
realistic scenarios. To mitigate the requirement for labeled data,
semi-supervised learning (SSL) focuses on simultaneously exploring both labeled
and unlabeled data, while transfer learning (TL) popularizes a favorable
practice of fine-tuning a pre-trained model to the target data. A dilemma is
thus encountered: Without a decent pre-trained model to provide an implicit
regularization, SSL through self-training from scratch will be easily misled by
inaccurate pseudo-labels, especially in large-sized label space; Without
exploring the intrinsic structure of unlabeled data, TL through fine-tuning
from limited labeled data is at risk of under-transfer caused by model shift.
To escape from this dilemma, we present Self-Tuning to enable data-efficient
deep learning by unifying the exploration of labeled and unlabeled data and the
transfer of a pre-trained model, as well as a Pseudo Group Contrast (PGC)
mechanism to mitigate the reliance on pseudo-labels and boost the tolerance to
false labels. Self-Tuning outperforms its SSL and TL counterparts on five tasks
by sharp margins, e.g. it doubles the accuracy of fine-tuning on Cars with 15%
labels.

    

### [[2103.01937] Neural Production Systems](http://arxiv.org/abs/2103.01937)


  Visual environments are structured, consisting of distinct objects or
entities. These entities have properties -- both visible and latent -- that
determine the manner in which they interact with one another. To partition
images into entities, deep-learning researchers have proposed structural
inductive biases such as slot-based architectures. To model interactions among
entities, equivariant graph neural nets (GNNs) are used, but these are not
particularly well suited to the task for two reasons. First, GNNs do not
predispose interactions to be sparse, as relationships among independent
entities are likely to be. Second, GNNs do not factorize knowledge about
interactions in an entity-conditional manner. As an alternative, we take
inspiration from cognitive science and resurrect a classic approach, production
systems, which consist of a set of rule templates that are applied by binding
placeholder variables in the rules to specific entities. Rules are scored on
their match to entities, and the best fitting rules are applied to update
entity properties. In a series of experiments, we demonstrate that this
architecture achieves a flexible, dynamic flow of control and serves to
factorize entity-specific and rule-based information. This disentangling of
knowledge achieves robust future-state prediction in rich visual environments,
outperforming state-of-the-art methods using GNNs, and allows for the
extrapolation from simple (few object) environments to more complex
environments.

    

### [[2103.10492] Recent Advances in Deep Learning Techniques for Face Recognition](http://arxiv.org/abs/2103.10492)


  In recent years, researchers have proposed many deep learning (DL) methods
for various tasks, and particularly face recognition (FR) made an enormous leap
using these techniques. Deep FR systems benefit from the hierarchical
architecture of the DL methods to learn discriminative face representation.
Therefore, DL techniques significantly improve state-of-the-art performance on
FR systems and encourage diverse and efficient real-world applications. In this
paper, we present a comprehensive analysis of various FR systems that leverage
the different types of DL techniques, and for the study, we summarize 168
recent contributions from this area. We discuss the papers related to different
algorithms, architectures, loss functions, activation functions, datasets,
challenges, improvement ideas, current and future trends of DL-based FR
systems. We provide a detailed discussion of various DL methods to understand
the current state-of-the-art, and then we discuss various activation and loss
functions for the methods. Additionally, we summarize different datasets used
widely for FR tasks and discuss challenges related to illumination, expression,
pose variations, and occlusion. Finally, we discuss improvement ideas, current
and future trends of FR tasks.

    

### [[2104.02373] Leverage Score Sampling for Complete Mode Coverage in Generative Adversarial Networks](http://arxiv.org/abs/2104.02373)


  Commonly, machine learning models minimize an empirical expectation. As a
result, the trained models typically perform well for the majority of the data
but the performance may deteriorate in less dense regions of the dataset. This
issue also arises in generative modeling. A generative model may overlook
underrepresented modes that are less frequent in the empirical data
distribution. This problem is known as complete mode coverage. We propose a
sampling procedure based on ridge leverage scores which significantly improves
mode coverage when compared to standard methods and can easily be combined with
any GAN. Ridge leverage scores are computed by using an explicit feature map,
associated with the next-to-last layer of a GAN discriminator or of a
pre-trained network, or by using an implicit feature map corresponding to a
Gaussian kernel. Multiple evaluations against recent approaches of complete
mode coverage show a clear improvement when using the proposed sampling
strategy.

    

### [[2104.09036] Mining Latent Structures for Multimedia Recommendation](http://arxiv.org/abs/2104.09036)


  Multimedia content is of predominance in the modern Web era. Investigating
how users interact with multimodal items is a continuing concern within the
rapid development of recommender systems. The majority of previous work focuses
on modeling user-item interactions with multimodal features included as side
information. However, this scheme is not well-designed for multimedia
recommendation. Specifically, only collaborative item-item relationships are
implicitly modeled through high-order item-user-item relations. Considering
that items are associated with rich contents in multiple modalities, we argue
that the latent semantic item-item structures underlying these multimodal
contents could be beneficial for learning better item representations and
further boosting recommendation. To this end, we propose a LATent sTructure
mining method for multImodal reCommEndation, which we term LATTICE for brevity.
To be specific, in the proposed LATTICE model, we devise a novel modality-aware
structure learning layer, which learns item-item structures for each modality
and aggregates multiple modalities to obtain latent item graphs. Based on the
learned latent graphs, we perform graph convolutions to explicitly inject
high-order item affinities into item representations. These enriched item
representations can then be plugged into existing collaborative filtering
methods to make more accurate recommendations. Extensive experiments on three
real-world datasets demonstrate the superiority of our method over
state-of-the-art multimedia recommendation methods and validate the efficacy of
mining latent item-item relationships from multimodal features.

    

### [[2104.14060] WGCN: Graph Convolutional Networks with Weighted Structural Features](http://arxiv.org/abs/2104.14060)


  Graph structural information such as topologies or connectivities provides
valuable guidance for graph convolutional networks (GCNs) to learn nodes'
representations. Existing GCN models that capture nodes' structural information
weight in- and out-neighbors equally or differentiate in- and out-neighbors
globally without considering nodes' local topologies. We observe that in- and
out-neighbors contribute differently for nodes with different local topologies.
To explore the directional structural information for different nodes, we
propose a GCN model with weighted structural features, named WGCN. WGCN first
captures nodes' structural fingerprints via a direction and degree aware Random
Walk with Restart algorithm, where the walk is guided by both edge direction
and nodes' in- and out-degrees. Then, the interactions between nodes'
structural fingerprints are used as the weighted node structural features. To
further capture nodes' high-order dependencies and graph geometry, WGCN embeds
graphs into a latent space to obtain nodes' latent neighbors and geometrical
relationships. Based on nodes' geometrical relationships in the latent space,
WGCN differentiates latent, in-, and out-neighbors with an attention-based
geometrical aggregation. Experiments on transductive node classification tasks
show that WGCN outperforms the baseline models consistently by up to 17.07% in
terms of accuracy on five benchmark datasets.

    

### [[2105.03733] Generative Actor-Critic: An Off-policy Algorithm Using the Push-forward Model](http://arxiv.org/abs/2105.03733)


  Model-free deep reinforcement learning has achieved great success in many
domains, such as video games, recommendation systems and robotic control tasks.
In continuous control tasks, widely used policies with Gaussian distributions
results in ineffective exploration of environments and limited performance of
algorithms in many cases. In this paper, we propose a density-free off-policy
algorithm, Generative Actor-Critic(GAC), using the push-forward model to
increase the expressiveness of policies, which also includes an entropy-like
technique, MMD-entropy regularizer, to balance the exploration and
exploitation. Additionnally, we devise an adaptive mechanism to automatically
scale this regularizer, which further improves the stability and robustness of
GAC. The experiment results show that push-forward policies possess desirable
features, such as multi-modality, which can improve the efficiency of
exploration and asymptotic performance of algorithms obviously.

    

### [[2105.09829] Personalized Counterfactual Fairness in Recommendation](http://arxiv.org/abs/2105.09829)


  Recommender systems are gaining increasing and critical impacts on human and
society since a growing number of users use them for information seeking and
decision making. Therefore, it is crucial to address the potential unfairness
problems in recommendations. Just like users have personalized preferences on
items, users' demands for fairness are also personalized in many scenarios.
Therefore, it is important to provide personalized fair recommendations for
users to satisfy their personalized fairness demands. Besides, previous works
on fair recommendation mainly focus on association-based fairness. However, it
is important to advance from associative fairness notions to causal fairness
notions for assessing fairness more properly in recommender systems. Based on
the above considerations, this paper focuses on achieving personalized
counterfactual fairness for users in recommender systems. To this end, we
introduce a framework for achieving counterfactually fair recommendations
through adversary learning by generating feature-independent user embeddings
for recommendation. The framework allows recommender systems to achieve
personalized fairness for users while also covering non-personalized
situations. Experiments on two real-world datasets with shallow and deep
recommendation algorithms show that our method can generate fairer
recommendations for users with a desirable recommendation performance.

    

### [[2105.13461] Learning Model-Based Vehicle-Relocation Decisions for Real-Time Ride-Sharing: Hybridizing Learning and Optimization](http://arxiv.org/abs/2105.13461)


  Large-scale ride-sharing systems combine real-time dispatching and routing
optimization over a rolling time horizon with a model predictive control (MPC)
component that relocates idle vehicles to anticipate the demand. The MPC
optimization operates over a longer time horizon to compensate for the inherent
myopic nature of the real-time dispatching. These longer time horizons are
beneficial for the quality of relocation decisions but increase computational
complexity. Consequently, the ride-sharing operators are often forced to use a
relatively short time horizon. To address this computational challenge, this
paper proposes a hybrid approach that combines machine learning and
optimization. The machine-learning component learns the optimal solution to the
MPC on the aggregated level to overcome the sparsity and high-dimensionality of
the solution. The optimization component transforms the machine-learning
prediction back to the original granularity through a tractable transportation
model. As a consequence, the original NP-hard MPC problem is reduced to a
polynomial time prediction and optimization, which allows the ride-sharing
operators to consider a longer time horizon. Experimental results show that the
hybrid approach achieves significantly better service quality than the MPC
optimization in terms of average rider waiting time, due to its ability to
model a longer horizon.

    

### [[2106.01009] FedHealth 2: Weighted Federated Transfer Learning via Batch Normalization for Personalized Healthcare](http://arxiv.org/abs/2106.01009)


  The success of machine learning applications often needs a large quantity of
data. Recently, federated learning (FL) is attracting increasing attention due
to the demand for data privacy and security, especially in the medical field.
However, the performance of existing FL approaches often deteriorates when
there exist domain shifts among clients, and few previous works focus on
personalization in healthcare. In this article, we propose FedHealth 2, an
extension of FedHealth \cite{chen2020fedhealth} to tackle domain shifts and get
personalized models for local clients. FedHealth 2 obtains the client
similarities via a pretrained model, and then it averages all weighted models
with preserving local batch normalization. Wearable activity recognition and
COVID-19 auxiliary diagnosis experiments have evaluated that FedHealth 2 can
achieve better accuracy (10%+ improvement for activity recognition) and
personalized healthcare without compromising privacy and security.

    

### [[2106.02039] Reinforcement Learning as One Big Sequence Modeling Problem](http://arxiv.org/abs/2106.02039)


  Reinforcement learning (RL) is typically concerned with estimating
single-step policies or single-step models, leveraging the Markov property to
factorize the problem in time. However, we can also view RL as a sequence
modeling problem, with the goal being to predict a sequence of actions that
leads to a sequence of high rewards. Viewed in this way, it is tempting to
consider whether powerful, high-capacity sequence prediction models that work
well in other domains, such as natural-language processing, can also provide
simple and effective solutions to the RL problem. To this end, we explore how
RL can be reframed as "one big sequence modeling" problem, using
state-of-the-art Transformer architectures to model distributions over
sequences of states, actions, and rewards. Addressing RL as a sequence modeling
problem significantly simplifies a range of design decisions: we no longer
require separate behavior policy constraints, as is common in prior work on
offline model-free RL, and we no longer require ensembles or other epistemic
uncertainty estimators, as is common in prior work on model-based RL. All of
these roles are filled by the same Transformer sequence model. In our
experiments, we demonstrate the flexibility of this approach across
long-horizon dynamics prediction, imitation learning, goal-conditioned RL, and
offline RL.

    

### [[2106.03464] Learning stable reduced-order models for hybrid twins](http://arxiv.org/abs/2106.03464)


  The concept of Hybrid Twin (HT) has recently received a growing interest
thanks to the availability of powerful machine learning techniques. This twin
concept combines physics-based models within a model-order reduction
framework-to obtain real-time feedback rates-and data science. Thus, the main
idea of the HT is to develop on-the-fly data-driven models to correct possible
deviations between measurements and physics-based model predictions. This paper
is focused on the computation of stable, fast and accurate corrections in the
Hybrid Twin framework. Furthermore, regarding the delicate and important
problem of stability, a new approach is proposed, introducing several
sub-variants and guaranteeing a low computational cost as well as the
achievement of a stable time-integration.

    

### [[2106.03699] Formalizing Distribution Inference Risks](http://arxiv.org/abs/2106.03699)


  Property inference attacks reveal statistical properties about a training set
but are difficult to distinguish from the primary purposes of statistical
machine learning, which is to produce models that capture statistical
properties about a distribution. Motivated by Yeom et al.'s membership
inference framework, we propose a formal and generic definition of property
inference attacks. The proposed notion describes attacks that can distinguish
between possible training distributions, extending beyond previous property
inference attacks that infer the ratio of a particular type of data in the
training data set. In this paper, we show how our definition captures previous
property inference attacks as well as a new attack that reveals the average
degree of nodes of a training graph and report on experiments giving insight
into the potential risks of property inference attacks.

    

### [[2106.05426] Low-Dimensional Structure in the Space of Language Representations is Reflected in Brain Responses](http://arxiv.org/abs/2106.05426)


  How related are the representations learned by neural language models,
translation models, and language tagging tasks? We answer this question by
adapting an encoder-decoder transfer learning method from computer vision to
investigate the structure among 100 different feature spaces extracted from
hidden representations of various networks trained on language tasks. This
method reveals a low-dimensional structure where language models and
translation models smoothly interpolate between word embeddings, syntactic and
semantic tasks, and future word embeddings. We call this low-dimensional
structure a language representation embedding because it encodes the
relationships between representations needed to process language for a variety
of NLP tasks. We find that this representation embedding can predict how well
each individual feature space maps to human brain responses to natural language
stimuli recorded using fMRI. Additionally, we find that the principal dimension
of this structure can be used to create a metric which highlights the brain's
natural language processing hierarchy. This suggests that the embedding
captures some part of the brain's natural language representation structure.

    

### [[2107.09833] Leaking Secrets through Modern Branch Predictor in the Speculative World](http://arxiv.org/abs/2107.09833)


  Transient execution attacks that exploit speculation have raised significant
concerns in computer systems. Typically, branch predictors are leveraged to
trigger mis-speculation in transient execution attacks. In this work, we
demonstrate a new class of speculation-based attack that targets branch
prediction unit (BPU). We find that speculative resolution of conditional
branches (i.e., in nested speculation) alter the states of pattern history
table (PHT) in modern processors, which are not restored after the
corresponding branches are later squashed. Such characteristic allows attackers
to exploit BPU as the secret transmitting medium in transient execution
attacks. To evaluate the discovered vulnerability, we build a novel attack
framework, BranchSpectre, that enables exfiltration of unintended secrets
through observing speculative PHT updates (in the form of covert and side
channels). We further investigate PHT collision mechanism in the history-based
predictor as well as the branch prediction mode transitions in Intel
processors. Built upon such knowledge, we implement an ultra high-speed covert
channel (BranchSpectre-cc) as well as two side channels (i.e., BranchSpectre-v1
and BranchSpectre-v2) that merely rely on BPU for mis-speculation trigger and
secret inference in the speculative domain. Notably, BranchSpectre side
channels can take advantage of much simpler code patterns than the ones used in
Spectre attacks. We present an extensive BranchSpectre code gadget analysis on
a set of popular real-world application code bases followed by a demonstration
of real-world side channel attack on OpenSSL. The evaluation results show
substantial wider existence and higher exploitability of BranchSpectre code
patterns in real-world software. Finally, we discuss several secure branch
prediction mechanisms that can mitigate transient execution attacks exploiting
modern branch predictors.

    

### [[2107.09707] A Cooperative Optimal Mining Model for Bitcoin](http://arxiv.org/abs/2107.09707)


  We analyze Bitcoin mining from the perspective of a game and propose an
optimal mining model that maximizes profits of pools and miners. The model is a
two-stage Stackelberg game in which each stage forms a sub-game. In stage I,
pools are the leaders who assign a computing power to be consumed by miners. In
stage II, miners decide of their power consumption and distribution. They find
themselves in a social dilemma in which they must choose between mining in
solo, therefore prioritizing their individual preferences, and participating in
a pool for the collective interest. The model relies on a pool protocol based
on a simulated game in which the miners compete for the reward won by the pool.
The solutions for the stage I sub-game and the simulated protocol game are
unique and stable Nash equilibriums while the stage II sub-game leads to a
stable cooperative equilibrium only when miners choose their strategies
according to certain criteria. We conclude that the cooperative optimal mining
model has the potential to favor Bitcoin decentralization and stability.
Mainly, the social dilemma faced by miners together with the balance of
incentives ensure a certain distribution of the network computing power between
pools and solo miners, while equilibriums in the game solutions provide
stability to the system.

    

### [[2107.09834] Communication Lower Bounds for Nested Bilinear Algorithms](http://arxiv.org/abs/2107.09834)


  We develop lower bounds on communication in the memory hierarchy or between
processors for nested bilinear algorithms, such as Strassen's algorithm for
matrix multiplication. We build on a previous framework that establishes
communication lower bounds by use of the rank expansion, or the minimum rank of
any fixed size subset of columns of a matrix, for each of the three matrices
encoding the bilinear algorithm. This framework provides lower bounds for any
way of computing a bilinear algorithm, which encompasses a larger space of
algorithms than by fixing a particular dependency graph. Nested bilinear
algorithms include fast recursive algorithms for convolution, matrix
multiplication, and contraction of tensors with symmetry. Two bilinear
algorithms can be nested by taking Kronecker products between their encoding
matrices. Our main result is a lower bound on the rank expansion of a matrix
constructed by a Kronecker product derived from lower bounds on the rank
expansion of the Kronecker product's operands. To prove this bound, we map a
subset of columns from a submatrix to a 2D grid, collapse them into a dense
grid, expand the grid, and use the size of the expanded grid to bound the
number of linearly independent columns of the submatrix. We apply the rank
expansion lower bounds to obtain novel communication lower bounds for nested
Toom-Cook convolution, Strassen's algorithm, and fast algorithms for partially
symmetric contractions.

    

### [[2107.09886] Understanding the Scalability of Hyperledger Fabric](http://arxiv.org/abs/2107.09886)


  The rapid growth of blockchain systems leads to increasing interest in
understanding and comparing blockchain performance at scale. In this paper, we
focus on analyzing the performance of Hyperledger Fabric v1.1 - one of the most
popular permissioned blockchain systems. Prior works have analyzed Hyperledger
Fabric v0.6 in depth, but newer versions of the system undergo significant
changes that warrant new analysis. Existing works on benchmarking the system
are limited in their scope: some consider only small networks, others consider
scalability of only parts of the system instead of the whole. We perform a
comprehensive performance analysis of Hyperledger Fabric v1.1 at scale. We
extend an existing benchmarking tool to conduct experiments over many servers
while scaling all important components of the system. Our results demonstrate
that Fabric v1.1's scalability bottlenecks lie in the communication overhead
between the execution and ordering phase. Furthermore, we show that scaling the
Kafka cluster that is used for the ordering phase does not affect the overall
throughput.

    

### [[2107.10008] Architecture-Specific Performance Optimization of Compute-Intensive FaaS Functions](http://arxiv.org/abs/2107.10008)


  FaaS allows an application to be decomposed into functions that are executed
on a FaaS platform. The FaaS platform is responsible for the resource
provisioning of the functions. Recently, there is a growing trend towards the
execution of compute-intensive FaaS functions that run for several seconds.
However, due to the billing policies followed by commercial FaaS offerings, the
execution of these functions can incur significantly higher costs. Moreover,
due to the abstraction of underlying processor architectures on which the
functions are executed, the performance optimization of these functions is
challenging. As a result, most FaaS functions use pre-compiled libraries
generic to x86-64 leading to performance degradation. In this paper, we examine
the underlying processor architectures for Google Cloud Functions (GCF) and
determine their prevalence across the 19 available GCF regions. We modify,
adapt, and optimize three compute-intensive FaaS workloads written in Python
using Numba, a JIT compiler based on LLVM, and present results wrt performance,
memory consumption, and costs on GCF. Results from our experiments show that
the optimization of FaaS functions can improve performance by 12.8x (geometric
mean) and save costs by 73.4% on average for the three functions. Our results
show that optimization of the FaaS functions for the specific architecture is
very important. We achieved a maximum speedup of 1.79x by tuning the function
especially for the instruction set of the underlying processor architecture.

    

### [[2107.10018] Formal method of synthesis of optimal topologies of computing systems based on projective description of graphs](http://arxiv.org/abs/2107.10018)


  A deterministic method for synthesizing the interconnect topologies optimized
for the required properties is proposed. The method is based on the original
description of graphs by projections, on establishing the bijective
correspondence of the required properties and the projection properties of the
initial graph, on postulating the corresponding restrictions of modified
projections and on iteratively applying these restrictions to them either until
the projection system is solved and the projections of the desired graph are
obtained, or until its incompatibility with the given initial conditions is
revealed.

    

### [[1910.08494] DLB: Deep Learning Based Load Balancing](http://arxiv.org/abs/1910.08494)


  In this paper, we introduce DLB, a Deep Learning based load Balancing
mechanism, to effectively address the data skew problem. The key idea of DLB is
to replace hash functions in the load balancing mechanisms with deep learning
models, which are trained to be able to map different distributions of
workloads and data to the servers in a uniformed manner. We implemented DLB and
deployed it on a practical Cloud environment using CloudSim. Experimental
results using both synthetic and real-world data sets show that compared with
traditional hash function based load balancing methods, DLB is able to achieve
more balanced mappings, especially when the workload is highly skewed.

    

### [[2107.09667] Human Perception of Audio Deepfakes](http://arxiv.org/abs/2107.09667)


  The recent emergence of deepfakes, computerized realistic multimedia fakes,
brought the detection of manipulated and generated content to the forefront.
While many machine learning models for deepfakes detection have been proposed,
the human detection capabilities have remained far less explored. This is of
special importance as human perception differs from machine perception and
deepfakes are generally designed to fool the human. So far, this issue has only
been addressed in the area of images and video.
To compare the ability of humans and machines in detecting audio deepfakes,
we conducted an online gamified experiment in which we asked users to discern
bonda-fide audio samples from spoofed audio, generated with a variety of
algorithms. 200 users competed for 8976 game rounds with an artificial
intelligence (AI) algorithm trained for audio deepfake detection. With the
collected data we found that the machine generally outperforms the humans in
detecting audio deepfakes, but that the converse holds for a certain attack
type, for which humans are still more accurate. Furthermore, we found that
younger participants are on average better at detecting audio deepfakes than
older participants, while IT-professionals hold no advantage over laymen. We
conclude that it is important to combine human and machine knowledge in order
to improve audio deepfake detection.

    

### [[2107.09668] Learning MR-Sort Models from Non-Monotone Data](http://arxiv.org/abs/2107.09668)


  The Majority Rule Sorting (MR-Sort) method assigns alternatives evaluated on
multiple criteria to one of the predefined ordered categories. The Inverse
MR-Sort problem (Inv-MR-Sort) computes MR-Sort parameters that match a dataset.
Existing learning algorithms for Inv-MR-Sort consider monotone preferences on
criteria. We extend this problem to the case where the preferences on criteria
are not necessarily monotone, but possibly single-peaked (or single-valley). We
propose a mixed-integer programming based algorithm that learns the preferences
on criteria together with the other MR-Sort parameters from the training data.
We investigate the performance of the algorithm using numerical experiments and
we illustrate its use on a real-world case study.

    

### [[2107.09718] An Efficient Multi-objective Evolutionary Approach for Solving the Operation of Multi-Reservoir System Scheduling in Hydro-Power Plants](http://arxiv.org/abs/2107.09718)


  This paper tackles the short-term hydro-power unit commitment problem in a
multi-reservoir system - a cascade-based operation scenario. For this, we
propose a new mathematical modelling in which the goal is to maximize the total
energy production of the hydro-power plant in a sub-daily operation, and,
simultaneously, to maximize the total water content (volume) of reservoirs. For
solving the problem, we discuss the Multi-objective Evolutionary Swarm
Hybridization (MESH) algorithm, a recently proposed multi-objective swarm
intelligence-based optimization method which has obtained very competitive
results when compared to existing evolutionary algorithms in specific
applications. The MESH approach has been applied to find the optimal water
discharge and the power produced at the maximum reservoir volume for all
possible combinations of turbines in a hydro-power plant. The performance of
MESH has been compared with that of well-known evolutionary approaches such as
NSGA-II, NSGA-III, SPEA2, and MOEA/D in a realistic problem considering data
from a hydro-power energy system with two cascaded hydro-power plants in
Brazil. Results indicate that MESH showed a superior performance than
alternative multi-objective approaches in terms of efficiency and accuracy,
providing a profit of \$412,500 per month in a projection analysis carried out.

    

### [[2107.09801] Two-phase Optimization of Binary Sequences with Low Peak Sidelobe Level Value](http://arxiv.org/abs/2107.09801)


  The search for binary sequences with low peak sidelobe level value represents
a formidable computational problem. To locate better sequences for this
problem, we designed a stochastic algorithm that uses two fitness functions. In
these fitness functions, the value of the autocorrelation function has a
different impact on the final fitness value. It is defined with the value of
the exponent over the autocorrelation function values. Each function is used in
the corresponding optimization phase, and the optimization process switches
between these two phases until the stopping condition is satisfied. The
proposed algorithm was implemented using the compute unified device
architecture and therefore allowed us to exploit the computational power of
graphics processing units. This algorithm was tested on sequences with lengths
$L = 2^m - 1$, for $14 \le m \le 20$. From the obtained results it is evident
that the usage of two fitness functions improved the efficiency of the
algorithm significantly, new-best known solutions were achieved, and the
achieved PSL values were significantly less than $\sqrt{L}$.

    

### [[2107.09822] Bayesian Controller Fusion: Leveraging Control Priors in Deep Reinforcement Learning for Robotics](http://arxiv.org/abs/2107.09822)


  We present Bayesian Controller Fusion (BCF): a hybrid control strategy that
combines the strengths of traditional hand-crafted controllers and model-free
deep reinforcement learning (RL). BCF thrives in the robotics domain, where
reliable but suboptimal control priors exist for many tasks, but RL from
scratch remains unsafe and data-inefficient. By fusing uncertainty-aware
distributional outputs from each system, BCF arbitrates control between them,
exploiting their respective strengths. We study BCF on two real-world robotics
tasks involving navigation in a vast and long-horizon environment, and a
complex reaching task that involves manipulability maximisation. For both these
domains, there exist simple handcrafted controllers that can solve the task at
hand in a risk-averse manner but do not necessarily exhibit the optimal
solution given limitations in analytical modelling, controller miscalibration
and task variation. As exploration is naturally guided by the prior in the
early stages of training, BCF accelerates learning, while substantially
improving beyond the performance of the control prior, as the policy gains more
experience. More importantly, given the risk-aversity of the control prior, BCF
ensures safe exploration \emph{and} deployment, where the control prior
naturally dominates the action distribution in states unknown to the policy. We
additionally show BCF's applicability to the zero-shot sim-to-real setting and
its ability to deal with out-of-distribution states in the real-world. BCF is a
promising approach for combining the complementary strengths of deep RL and
traditional robotic control, surpassing what either can achieve independently.
The code and supplementary video material are made publicly available at
\url{this https URL}.

    

### [[2107.09847] CogME: A Novel Evaluation Metric for Video Understanding Intelligence](http://arxiv.org/abs/2107.09847)


  Developing video understanding intelligence is quite challenging because it
requires holistic integration of images, scripts, and sounds based on natural
language processing, temporal dependency, and reasoning. Recently, substantial
attempts have been made on several video datasets with associated question
answering (QA) on a large scale. However, existing evaluation metrics for video
question answering (VideoQA) do not provide meaningful analysis. To make
progress, we argue that a well-made framework, established on the way humans
understand, is required to explain and evaluate the performance of
understanding in detail. Then we propose a top-down evaluation system for
VideoQA, based on the cognitive process of humans and story elements: Cognitive
Modules for Evaluation (CogME). CogME is composed of three cognitive modules:
targets, contents, and thinking. The interaction among the modules in the
understanding procedure can be expressed in one sentence as follows: "I
understand the CONTENT of the TARGET through a way of THINKING." Each module
has sub-components derived from the story elements. We can specify the required
aspects of understanding by annotating the sub-components to individual
questions. CogME thus provides a framework for an elaborated specification of
VideoQA datasets. To examine the suitability of a VideoQA dataset for
validating video understanding intelligence, we evaluated the baseline model of
the DramaQA dataset by applying CogME. The evaluation reveals that story
elements are unevenly reflected in the existing dataset, and the model based on
the dataset may cause biased predictions. Although this study has only been
able to grasp a narrow range of stories, we expect that it offers the first
step in considering the cognitive process of humans on the video understanding
intelligence of humans and AI.

    

### [[2107.09888] Strategic Mitigation of Agent Inattention in Drivers with Open-Quantum Cognition Models](http://arxiv.org/abs/2107.09888)


  State-of-the-art driver-assist systems have failed to effectively mitigate
driver inattention and had minimal impacts on the ever-growing number of road
mishaps (e.g. life loss, physical injuries due to accidents caused by various
factors that lead to driver inattention). This is because traditional
human-machine interaction settings are modeled in classical and behavioral
game-theoretic domains which are technically appropriate to characterize
strategic interaction between either two utility maximizing agents, or human
decision makers. Therefore, in an attempt to improve the persuasive
effectiveness of driver-assist systems, we develop a novel strategic and
personalized driver-assist system which adapts to the driver's mental state and
choice behavior. First, we propose a novel equilibrium notion in human-system
interaction games, where the system maximizes its expected utility and human
decisions can be characterized using any general decision model. Then we use
this novel equilibrium notion to investigate the strategic driver-vehicle
interaction game where the car presents a persuasive recommendation to steer
the driver towards safer driving decisions. We assume that the driver employs
an open-quantum system cognition model, which captures complex aspects of human
decision making such as violations to classical law of total probability and
incompatibility of certain mental representations of information. We present
closed-form expressions for players' final responses to each other's strategies
so that we can numerically compute both pure and mixed equilibria. Numerical
results are presented to illustrate both kinds of equilibria.

    

### [[2107.09990] CL4AC: A Contrastive Loss for Audio Captioning](http://arxiv.org/abs/2107.09990)


  Automated Audio captioning (AAC) is a cross-modal translation task that aims
to use natural language to describe the content of an audio clip. As shown in
the submissions received for Task 6 of the DCASE 2021 Challenges, this problem
has received increasing interest in the community. The existing AAC systems are
usually based on an encoder-decoder architecture, where the audio signal is
encoded into a latent representation, and aligned with its corresponding text
descriptions, then a decoder is used to generate the captions. However,
training of an AAC system often encounters the problem of data scarcity, which
may lead to inaccurate representation and audio-text alignment. To address this
problem, we propose a novel encoder-decoder framework called Contrastive Loss
for Audio Captioning (CL4AC). In CL4AC, the self-supervision signals derived
from the original audio-text paired data are used to exploit the
correspondences between audio and texts by contrasting samples, which can
improve the quality of latent representation and the alignment between audio
and texts, while trained with limited data. Experiments are performed on the
Clotho dataset to show the effectiveness of our proposed approach.

    

### [[2107.09998] Conditional Sound Generation Using Neural Discrete Time-Frequency Representation Learning](http://arxiv.org/abs/2107.09998)


  Deep generative models have recently achieved impressive performance in
speech synthesis and music generation. However, compared to the generation of
those domain-specific sounds, the generation of general sounds (such as car
horn, dog barking, and gun shot) has received less attention, despite their
wide potential applications. In our previous work, sounds are generated in the
time domain using SampleRNN. However, it is difficult to capture long-range
dependencies within sound recordings using this method. In this work, we
propose to generate sounds conditioned on sound classes via neural discrete
time-frequency representation learning. This offers an advantage in modelling
long-range dependencies and retaining local fine-grained structure within a
sound clip. We evaluate our proposed approach on the UrbanSound8K dataset, as
compared to a SampleRNN baseline, with the performance metrics measuring the
quality and diversity of the generated sound samples. Experimental results show
that our proposed method offers significantly better performance in diversity
and comparable performance in quality, as compared to the baseline method.

    

### [[2107.10013] Optimal Operation of Power Systems with Energy Storage under Uncertainty: A Scenario-based Method with Strategic Sampling](http://arxiv.org/abs/2107.10013)


  The multi-period dynamics of energy storage (ES), intermittent renewable
generation and uncontrollable power loads, make the optimization of power
system operation (PSO) challenging. A multi-period optimal PSO under
uncertainty is formulated using the chance-constrained optimization (CCO)
modeling paradigm, where the constraints include the nonlinear energy storage
and AC power flow models. Based on the emerging scenario optimization method
which does not rely on pre-known probability distribution functions, this paper
develops a novel solution method for this challenging CCO problem. The proposed
meth-od is computationally effective for mainly two reasons. First, the
original AC power flow constraints are approximated by a set of
learning-assisted quadratic convex inequalities based on a generalized least
absolute shrinkage and selection operator. Second, considering the physical
patterns of data and motived by learning-based sampling, the strategic sampling
method is developed to significantly reduce the required number of scenarios
through different sampling strategies. The simulation results on IEEE standard
systems indicate that 1) the proposed strategic sampling significantly improves
the computational efficiency of the scenario-based approach for solving the
chance-constrained optimal PSO problem, 2) the data-driven convex approximation
of power flow can be promising alternatives of nonlinear and nonconvex AC power
flow.

    

### [[2107.10021] An artificial intelligence natural language processing pipeline for information extraction in neuroradiology](http://arxiv.org/abs/2107.10021)


  The use of electronic health records in medical research is difficult because
of the unstructured format. Extracting information within reports and
summarising patient presentations in a way amenable to downstream analysis
would be enormously beneficial for operational and clinical research. In this
work we present a natural language processing pipeline for information
extraction of radiological reports in neurology. Our pipeline uses a hybrid
sequence of rule-based and artificial intelligence models to accurately extract
and summarise neurological reports. We train and evaluate a custom language
model on a corpus of 150000 radiological reports from National Hospital for
Neurology and Neurosurgery, London MRI imaging. We also present results for
standard NLP tasks on domain-specific neuroradiology datasets. We show our
pipeline, called `neuroNLP', can reliably extract clinically relevant
information from these reports, enabling downstream modelling of reports and
associated imaging on a heretofore unprecedented scale.

    

### [[2107.10083] SituationCO v1.2's Terms, Properties, Relationships and Axioms -- A Core Ontology for Particular and Generic Situations](http://arxiv.org/abs/2107.10083)


  The current preprint is an update to SituationCO v1.1 (Situation Core
Ontology), which represents its new version 1.2. It specifies and defines all
the terms, properties, relationships and axioms of SituationCO v1.2, being an
ontology for particular and generic Situations placed at the core level in the
context of a four-layered ontological architecture called FCD-OntoArch
(Foundational, Core, and Domain Ontological Architecture for Sciences). This is
a four-layered ontological architecture, which considers Foundational, Core,
Domain and Instance levels. In turn, the domain level is split down in two
sub-levels, namely: Top-domain and Low-domain ontological levels. So in fact,
we can consider it to be a five-tier architecture. Ontologies at the same level
can be related to each other, except for the foundational level where only
ThingFO (Thing Foundational Ontology) is found. In addition, ontologies' terms
and relationships at lower levels can be semantically enriched by ontologies'
terms and relationships from the higher levels. Note that both ThingFO and
ontologies at the core level such as SituationCO, ProcessCO, among others, are
domain independent. SituationCO's terms and relationships are specialized
primarily from ThingFO. It also completely reuses terms primarily from
ProcessCO, ProjectCO and GoalCO ontologies. Stereotypes are the used mechanism
for enriching SituationCO terms. Note that in the end of this document, we
address the SituationCO vs. ThingFO non-taxonomic relationship verification
matrix.

    

### [[2107.10121] Peer Selection with Noisy Assessments](http://arxiv.org/abs/2107.10121)


  In the peer selection problem a group of agents must select a subset of
themselves as winners for, e.g., peer-reviewed grants or prizes. Here, we take
a Condorcet view of this aggregation problem, i.e., that there is a
ground-truth ordering over the agents and we wish to select the best set of
agents, subject to the noisy assessments of the peers. Given this model, some
agents may be unreliable, while others might be self-interested, attempting to
influence the outcome in their favour. In this paper we extend PeerNomination,
the most accurate peer reviewing algorithm to date, into
WeightedPeerNomination, which is able to handle noisy and inaccurate agents. To
do this, we explicitly formulate assessors' reliability weights in a way that
does not violate strategyproofness, and use this information to reweight their
scores. We show analytically that a weighting scheme can improve the overall
accuracy of the selection significantly. Finally, we implement several
instances of reweighting methods and show empirically that our methods are
robust in the face of noisy assessments.

    

### [[2009.07982] Strategy Proof Mechanisms for Facility Location at Limited Locations](http://arxiv.org/abs/2009.07982)


  Facility location problems often permit facilities to be located at any
position. But what if this is not the case in practice? What if facilities can
only be located at particular locations like a highway exit or close to a bus
stop? We consider here the impact of such constraints on the location of
facilities on the performance of strategy proof mechanisms for locating
facilities.We study four different performance objectives: the total distance
agents must travel to their closest facility, the maximum distance any agent
must travel to their closest facility, and the utilitarian and egalitarian
welfare.We show that constraining facilities to a limited set of locations
makes all four objectives harder to approximate in general.

    

### [[2102.09754] VisuoSpatial Foresight for Physical Sequential Fabric Manipulation](http://arxiv.org/abs/2102.09754)


  Robotic fabric manipulation has applications in home robotics, textiles,
senior care and surgery. Existing fabric manipulation techniques, however, are
designed for specific tasks, making it difficult to generalize across different
but related tasks. We build upon the Visual Foresight framework to learn fabric
dynamics that can be efficiently reused to accomplish different sequential
fabric manipulation tasks with a single goal-conditioned policy. We extend our
earlier work on VisuoSpatial Foresight (VSF), which learns visual dynamics on
domain randomized RGB images and depth maps simultaneously and completely in
simulation. In this earlier work, we evaluated VSF on multi-step fabric
smoothing and folding tasks against 5 baseline methods in simulation and on the
da Vinci Research Kit (dVRK) surgical robot without any demonstrations at train
or test time. A key finding was that depth sensing significantly improves
performance: RGBD data yields an 80% improvement in fabric folding success rate
in simulation over pure RGB data. In this work, we vary 4 components of VSF,
including data generation, visual dynamics model, cost function, and
optimization procedure. Results suggest that training visual dynamics models
using longer, corner-based actions can improve the efficiency of fabric folding
by 76% and enable a physical sequential fabric folding task that VSF could not
previously perform with 90% reliability. Code, data, videos, and supplementary
material are available at this https URL.

    

### [[2104.00053] LazyDAgger: Reducing Context Switching in Interactive Imitation Learning](http://arxiv.org/abs/2104.00053)


  Corrective interventions while a robot is learning to automate a task provide
an intuitive method for a human supervisor to assist the robot and convey
information about desired behavior. However, these interventions can impose
significant burden on a human supervisor, as each intervention interrupts other
work the human is doing, incurs latency with each context switch between
supervisor and autonomous control, and requires time to perform. We present
LazyDAgger, which extends the interactive imitation learning (IL) algorithm
SafeDAgger to reduce context switches between supervisor and autonomous
control. We find that LazyDAgger improves the performance and robustness of the
learned policy during both learning and execution while limiting burden on the
supervisor. Simulation experiments suggest that LazyDAgger can reduce context
switches by an average of 60% over SafeDAgger on 3 continuous control tasks
while maintaining state-of-the-art policy performance. In physical fabric
manipulation experiments with an ABB YuMi robot, LazyDAgger reduces context
switches by 60% while achieving a 60% higher success rate than SafeDAgger at
execution time.

    

### [[2104.01542] Synergies Between Affordance and Geometry: 6-DoF Grasp Detection via Implicit Representations](http://arxiv.org/abs/2104.01542)


  Grasp detection in clutter requires the robot to reason about the 3D scene
from incomplete and noisy perception. In this work, we draw insight that 3D
reconstruction and grasp learning are two intimately connected tasks, both of
which require a fine-grained understanding of local geometry details. We thus
propose to utilize the synergies between grasp affordance and 3D reconstruction
through multi-task learning of a shared representation. Our model takes
advantage of deep implicit functions, a continuous and memory-efficient
representation, to enable differentiable training of both tasks. We train the
model on self-supervised grasp trials data in simulation. Evaluation is
conducted on a clutter removal task, where the robot clears cluttered objects
by grasping them one at a time. The experimental results in simulation and on
the real robot have demonstrated that the use of implicit neural
representations and joint learning of grasp affordance and 3D reconstruction
have led to state-of-the-art grasping results. Our method outperforms baselines
by over 10% in terms of grasp success rate. Additional results and videos can
be found at this https URL


### [[2105.04165] Inter-GPS: Interpretable Geometry Problem Solving with Formal Language and Symbolic Reasoning](http://arxiv.org/abs/2105.04165)


  Geometry problem solving has attracted much attention in the NLP community
recently. The task is challenging as it requires abstract problem understanding
and symbolic reasoning with axiomatic knowledge. However, current datasets are
either small in scale or not publicly available. Thus, we construct a new
large-scale benchmark, Geometry3K, consisting of 3,002 geometry problems with
dense annotation in formal language. We further propose a novel geometry
solving approach with formal language and symbolic reasoning, called
Interpretable Geometry Problem Solver (Inter-GPS). Inter-GPS first parses the
problem text and diagram into formal language automatically via rule-based text
parsing and neural object detecting, respectively. Unlike implicit learning in
existing methods, Inter-GPS incorporates theorem knowledge as conditional rules
and performs symbolic reasoning step by step. Also, a theorem predictor is
designed to infer the theorem application sequence fed to the symbolic solver
for the more efficient and reasonable searching path. Extensive experiments on
the Geometry3K and GEOS datasets demonstrate that Inter-GPS achieves
significant improvements over existing methods. The project with code and data
is available at this https URL.

    

### [[2105.11267] Actions You Can Handle: Dependent Types for AI Plans](http://arxiv.org/abs/2105.11267)


  Verification of AI is a challenge that has engineering, algorithmic and
programming language components. For example, AI planners are deployed to model
actions of autonomous agents. They comprise a number of searching algorithms
that, given a set of specified properties, find a sequence of actions that
satisfy these properties. Although AI planners are mature tools from the
algorithmic and engineering points of view, they have limitations as
programming languages. Decidable and efficient automated search entails
restrictions on the syntax of the language, prohibiting use of higher-order
properties or recursion. This paper proposes a methodology for embedding plans
produced by AI planners into dependently-typed language Agda, which enables
users to reason about and verify more general and abstract properties of plans,
and also provides a more holistic programming language infrastructure for
modelling plan execution.

    

### [[2105.11888] Bi-objective Search with Bi-directional A*](http://arxiv.org/abs/2105.11888)


  Bi-objective search is a well-known algorithmic problem, concerned with
finding a set of optimal solutions in a two-dimensional domain. This problem
has a wide variety of applications such as planning in transport systems or
optimal control in energy systems. Recently, bi-objective A*-based search
(BOA*) has shown state-of-the-art performance in large networks. This paper
develops a bi-directional and parallel variant of BOA*, enriched with several
speed-up heuristics. Our experimental results on 1,000 benchmark cases show
that our bi-directional A* algorithm for bi-objective search (BOBA*) can
optimally solve all of the benchmark cases within the time limit, outperforming
the state of the art BOA*, bi-objective Dijkstra and bi-directional
bi-objective Dijkstra by an average runtime improvement of a factor of five
over all of the benchmark instances.

    

### [[2106.15515] What Is Consciousness? Artificial Intelligence, Real Intelligence, Quantum Mind, And Qualia](http://arxiv.org/abs/2106.15515)


  We approach the question "What is Consciousness?" in a new way, not as
Descartes' "systematic doubt", but as how organisms find their way in their
world. Finding one's way involves finding possible uses of features of the
world that might be beneficial or avoiding those that might be harmful.
"Possible uses of X to accomplish Y" are "Affordances". The number of uses of X
is indefinite (or unknown), the different uses are unordered and are not
deducible from one another. All biological adaptations are either affordances
seized by heritable variation and selection or, far faster, by the organism
acting in its world finding uses of X to accomplish Y. Based on this, we reach
rather astonishing conclusions: (1) Artificial General Intelligence based on
Universal Turing Machines (UTMs) is not possible, since UTMs cannot "find"
novel affordances. (2) Brain-mind is not purely classical physics for no
classical physics system can be an analogue computer whose dynamical behavior
can be isomorphic to "possible uses". (3) Brain mind must be partly quantum -
supported by increasing evidence at 6.0 sigma to 7.3 Sigma. (4) Based on
Heisenberg's interpretation of the quantum state as "Potentia" converted to
"Actuals" by Measurement, a natural hypothesis is that mind actualizes
Potentia. This is supported at 5.2 Sigma. Then Mind's actualizations of
entangled brain-mind-world states are experienced as qualia and allow "seeing"
or "perceiving" of uses of X to accomplish Y. We can and do jury-rig. Computers
cannot. (5) Beyond familiar quantum computers, we discuss the potentialities of
Trans-Turing-Systems.

    

### [[2106.15979] Hypothetical Expected Utility](http://arxiv.org/abs/2106.15979)


  This paper provides a model to analyze and identify a decision maker's (DM's)
hypothetical reasoning. Using this model, I show that a DM's propensity to
engage in hypothetical thinking is captured exactly by her ability to recognize
implications (i.e., to identify that one hypothesis implies another) and that
this later relation is encoded by a DM's observable behavior. Thus, this
characterization both provides a concrete definition of (flawed) hypothetical
reasoning and, importantly, yields a methodology to identify these judgments
from standard economic data.

    

### [[2107.10047] Performance landscape of resource-constrained platforms targeting DNNs](http://arxiv.org/abs/2107.10047)


  Over the recent years, a significant number of complex, deep neural networks
have been developed for a variety of applications including speech and face
recognition, computer vision in the areas of health-care, automatic
translation, image classification, etc. Moreover, there is an increasing demand
in deploying these networks in resource-constrained edge devices. As the
computational demands of these models keep increasing, pushing to their limits
the targeted devices, the constant development of new hardware systems tailored
to those workloads has been observed. Since programmability of these diverse
and complex platforms -- compounded by the rapid development of new DNN models
-- is a major challenge, platform vendors have developed Machine Learning
tailored SDKs to maximize the platform's performance.
This work investigates the performance achieved on a number of modern
commodity embedded platforms coupled with the vendors' provided software
support when state-of-the-art DNN models from image classification, object
detection and image segmentation are targeted. The work quantifies the relative
latency gains of the particular embedded platforms and provides insights on the
relationship between the required minimum batch size for achieving maximum
throughput, concluding that modern embedded systems reach their maximum
performance even for modest batch sizes when a modern state of the art DNN
model is targeted. Overall, the presented results provide a guide for the
expected performance for a number of state-of-the-art DNNs on popular embedded
platforms across the image classification, detection and segmentation domains.

    

### [[2104.02856] Irregular-Mapped Protograph LDPC-Coded Modulation: A Bandwidth-Efficient Solution for $5$G Networks with Massive Data-Storage Requirement](http://arxiv.org/abs/2104.02856)


  The huge amount of data produced in the fifth-generation (5G) networks not
only brings new challenges to the reliability and efficiency of mobile devices
but also drives rapid development of new storage techniques. With the benefits
of fast access speed and high reliability, NAND flash memory has become a
promising storage solution for the 5G networks. In this paper, we investigate a
protograph-coded bit-interleaved coded modulation with iterative detection and
decoding (BICM-ID) utilizing irregular mapping (IM) in the multi-level-cell
(MLC) NAND flash-memory systems. First, we propose an enhanced protograph-based
extrinsic information transfer (EPEXIT) algorithm to facilitate the analysis of
protograph codes in the IM-BICM-ID systems. With the use of EPEXIT algorithm, a
simple design method is conceived for the construction of a family of high-rate
protograph codes, called irregular-mapped accumulate-repeat-accumulate (IMARA)
codes, which possess both excellent decoding thresholds and
linear-minimum-distance-growth property. Furthermore, motivated by the
voltage-region iterative gain characteristics of IM-BICM-ID systems, a novel
read-voltage optimization scheme is developed to acquire accurate read-voltage
levels, thus minimizing the decoding thresholds of protograph codes.
Theoretical analyses and error-rate simulations indicate that the proposed
IMARA-aided IM-BICM-ID scheme and the proposed read-voltage optimization scheme
remarkably improve the convergence and decoding performance of flash-memory
systems. Thus, the proposed protograph-coded IM-BICM-ID flash-memory systems
can be viewed as a reliable and efficient storage solution for the
new-generation mobile networks with massive data-storage requirement.

    

### [[2107.10160] Pre-proceedings of the 31st International Symposium on Logic-Based Program Synthesis and Transformation (LOPSTR 2021)](http://arxiv.org/abs/2107.10160)


  This volume constitutes the pre-proceedings of the 31st International
Symposium on Logic-Based Program Synthesis and Transformation (LOPSTR 2021),
held on 7-8th September 2021 as a hybrid (blended) meeting, both in-person (at
the Teachers' House in Tallinn, Estonia) and virtual, and co-located with the
23rd International Symposium on Principles and Practice of Declarative
Programming (PPDP 2021). After discussion at the symposium papers will go
through a second round of refereeing and selection for the formal proceedings.

    