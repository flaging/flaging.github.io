
## 2021-10-7

### [<title>XGBclassifier with custom objective function gives different results in different spark versions - XGBoost</title>](https://discuss.xgboost.ai/t/xgbclassifier-with-custom-objective-function-gives-different-results-in-different-spark-versions/2489/1)

### [[2110.02224] Transparent Forwarders: An Unnoticed Component of the Open DNS Infrastructure](http://arxiv.org/abs/2110.02224)


  In this short paper, we revisit the open DNS (ODNS) infrastructure and, for
the first time, systematically measure and analyze transparent forwarders, DNS
components that transparently relay between stub resolvers and recursive
resolvers. Our key findings include four takeaways. First, transparent
forwarders contribute 26% (563k) to the current ODNS infrastructure.
Unfortunately, common periodic scanning campaigns such as Shadowserver do not
capture transparent forwarders and thus underestimate the current threat
potential of the ODNS. Second, we find an increased deployment of transparent
forwarders in Asia and South America. In India alone, the ODNS consists of 80%
transparent forwarders. Third, many transparent forwarders relay to a few
selected public resolvers such as Google and Cloudflare, which confirms a
consolidation trend of DNS stakeholders. Finally, we introduce DNSRoute++, a
new traceroute approach to understand the network infrastructure connecting
transparent forwarders and resolvers.

    

### [[2110.02472] What is A Wireless UAV? A Design Blueprint for 6G Flying Wireless Nodes](http://arxiv.org/abs/2110.02472)


  Wireless Unmanned Aerial Vehicles (UAVs) were introduced in the world of 4th
generation networks (4G) as cellular users, and have attracted the interest of
the wireless community ever since. In~5G, UAVs operate also as flying Base
Stations providing service to ground users. They can also implement independent
off-the-grid UAV networks. In~6G networks, wireless UAVs will connect ground
users to in-orbit wireless infrastructure. As the design and prototyping of
wireless UAVs are on the rise, the time is ripe for introducing a more precise
definition of what is a wireless UAV. In doing so, we revise the major design
challenges in the prototyping of wireless UAVs for future 6G spectrum research.
We then introduce a new wireless UAV prototype that addresses these challenges.
The design of our wireless UAV prototype will be made public and freely
available to other researchers.

    

### [[2110.02565] A Region-based Collaborative Management Scheme for Dynamic Clustering in Green VANET](http://arxiv.org/abs/2110.02565)


  Green Vehicular Ad-hoc Network (VANET) is a newly-emerged research area which
focuses on reducing harmful impacts of vehicular communication equipments on
the natural environment. Recent studies have shown that grouping vehicles into
clusters for green communications in VANETs can significantly improve
networking efficiency and reduce infrastructure costs. As a dynamic network
system, maintaining the network connectivity and reducing the communication
overlap are two critical challenges for green VANET clustering. However, most
existing work studies connectivity and overlap separately, lacking a deep
understanding of the relationship between them. To address this issue, we
present a comprehensive analysis that jointly considers the two critical
factors in one model. Specifically, we first design a state resemblance
prediction (SRP) model based on the historical trajectory feature relevance
between vehicles; Combined with the SRP model, we propose the region-based
collaborative management scheme (RCMS) to establish the dynamic clustering;
Lastly, we take extensive experiments to verify the region-based collaborative
management scheme for dynamic clustering. The results demonstrate that the
proposed clustering algorithm can achieve high networking efficiency and better
communication stability.

    

### [[2110.02594] Empowering Citizens by a Blockchain-Based Robinson List](http://arxiv.org/abs/2110.02594)


  A Robinson list protects phone subscribers against commercial spam calls. Its
least basic functionality is to collect the denial of the subscribers to be
contacted by market operators. Nowadays, Robinson lists run as centralised
services, which implies that citizens should trust third parties for the
management of their choices. In this paper, we show a design that allows us to
realise a Robinson list as a decentralised service. Our work leverages the
experience developed by Fondazione Ugo Bordoni as the manager of the Italian
Robinson list. We present a general solution and a proof-of-concept (PoC)
adopting the Algorand technology. We evaluate the performances of our PoC in
terms of its scalability and of the latency perceived by the involved actors.
We also discuss aspects related to identity management and privacy.

    

### [[2110.02653] Proactive Scheduling and Caching for Wireless VR Viewport Streaming](http://arxiv.org/abs/2110.02653)


  Virtual Reality (VR) applications require high data rate for a high-quality
immersive experience, in addition to low latency to avoid dizziness and motion
sickness. One of the key wireless VR challenges is providing seamless
connectivity and meeting the stringent latency and bandwidth requirements. This
work proposes a proactive wireless VR system that utilizes information about
the user's future orientation for proactive scheduling and caching. This is
achieved by leveraging deep neural networks to predict users' orientation
trained on a real dataset. The 360Â° scene is then partitioned using an
overlapping viewports scheme so that only portions of the scene covered by the
users' perceptive field-of-view are streamed. Furthermore, to minimize the
backhaul latency, popular viewports are cached at the edge cloud based on
spatial popularity profiles. Through extensive simulations, we show that the
proposed system provides significant latency and throughput performance
improvement, especially in fluctuating channels and heavy load conditions. The
proactive scheduling enabled by the combination of machine learning prediction
and the proposed viewport scheme reduces the mean latency by more than 80%
while achieving successful delivery rate close to 100%.

    

### [[2110.02788] The Impact of Blocking Cars on Pathloss Within a Platoon: Measurements for 26 GHz Band](http://arxiv.org/abs/2110.02788)


  Platooning is considered to be one of the possible prospective
implementations of the autonomous driving concept, where the train-of-cars
moves together following the platoon leader's commands. However, the practical
realization of this scheme assumes the use of reliable communications between
platoon members. In this paper, the results of the measurement experiment have
been presented showing the impact of the blocking cars on the signal
attenuation. The tests have been carried out for the high-frequency band, i.e.
for 26.555 GHz. It has been observed that on one hand side, the attenuation can
reach even tens of dB for 2 or 3 blocking cars, but in some locations, the
impact of a two-ray propagation mitigates the presence of obstructing vehicles.

    

### [[2110.02938] Deployment of Polar Codes for Mission-Critical Machine-Type Communication Over Wireless Networks](http://arxiv.org/abs/2110.02938)


  Mission critical Machine-type Communication, also referred to as
Ultra-reliable Low Latency Communication is primarily characterized by
communication that provides ultra-high reliability and very low latency to
concurrently transmit short commands to a massive number of connected devices.
While the reduction in PHY layer overhead and improvement in channel coding
techniques are pivotal in reducing latency and improving reliability, the
current wireless standards dedicated to support mcMTC rely heavily on adopting
the bottom layers of general-purpose wireless standards and customizing only
the upper layers. The mcMTC has a significant technical impact on the design of
all layers of the communication protocol stack. In this paper, an innovative
bottom-up approach has been proposed for mcMTC applications through PHY layer
targeted at improving the transmission reliability by implementing
ultra-reliable channel coding scheme in the PHY layer of IEEE 802.11a bearing
in mind short packet transmission system. To achieve this aim, we analyzed and
compared the channel coding performance of convolutional codes, LDPC codes, and
polar codes in wireless network on the condition of short data packet
transmission. The Viterbi decoding algorithm, logarithmic belief propagation
algorithm, and cyclic redundancy check - successive cancellation list decoding
algorithm were adopted to CC, LDPC codes, and polar codes, respectively.
Consequently, a new PHY layer for mcMTC has been proposed. The reliability of
the proposed approach has been validated by simulation in terms of Bit error
rate vs. SNR. The simulation results demonstrate that the reliability of IEEE
802.11a standard has been significantly improved to be at PER less 10e-5 with
the implementation of polar codes. The results also show that the
general-purpose wireless networks are prominent in providing short packet mcMTC
with the modification needed.

    

### [[2110.02219] RC-Struct: A Structure-based Neural Network Approach for MIMO-OFDM Detection](http://arxiv.org/abs/2110.02219)


  In this paper, we introduce a structure-based neural network architecture,
namely RC-Struct, for MIMO-OFDM symbol detection. The RC-Struct exploits the
temporal structure of the MIMO-OFDM signals through reservoir computing (RC). A
binary classifier leverages the repetitive constellation structure in the
system to perform multi-class detection. The incorporation of RC allows the
RC-Struct to be learned in a purely online fashion with extremely limited pilot
symbols in each OFDM subframe. The binary classifier enables the efficient
utilization of the precious online training symbols and allows an easy
extension to high-order modulations without a substantial increase in
complexity. Experiments show that the introduced RC-Struct outperforms both the
conventional model-based symbol detection approaches and the state-of-the-art
learning-based strategies in terms of bit error rate (BER). The advantages of
RC-Struct over existing methods become more significant when rank and link
adaptation are adopted. The introduced RC-Struct sheds light on combining
communication domain knowledge and learning-based receive processing for 5G and
5G Beyond.

    

### [[2110.02220] Fast Contextual Adaptation with Neural Associative Memory for On-Device Personalized Speech Recognition](http://arxiv.org/abs/2110.02220)


  Fast contextual adaptation has shown to be effective in improving Automatic
Speech Recognition (ASR) of rare words and when combined with an on-device
personalized training, it can yield an even better recognition result. However,
the traditional re-scoring approaches based on an external language model is
prone to diverge during the personalized training. In this work, we introduce a
model-based end-to-end contextual adaptation approach that is decoder-agnostic
and amenable to on-device personalization. Our on-device simulation experiments
demonstrate that the proposed approach outperforms the traditional re-scoring
technique by 12% relative WER and 15.7% entity mention specific F1-score in a
continues personalization scenario.

    

### [[2110.02222] Hybrid Classical-Quantum method for Diabetic Foot Ulcer Classification](http://arxiv.org/abs/2110.02222)


  Diabetes is a raising problem that affects many people globally. Diabetic
patients are at risk of developing foot ulcer that usually leads to limb
amputation, causing significant morbidity, and psychological distress. In order
to develop a self monitoring mobile application, it is necessary to be able to
classify such ulcers into either of the following classes: Infection,
Ischaemia, None, or Both. In this work, we compare the performance of a
classical transfer-learning-based method, with the performance of a hybrid
classical-quantum Classifier on diabetic foot ulcer classification task. As
such, we merge the pre-trained Xception network with a multi-class variational
classifier. Thus, after modifying and re-training the Xception network, we
extract the output of a mid-layer and employ it as deep-features presenters of
the given images. Finally, we use those deep-features to train multi-class
variational classifier, where each classifier is implemented on an individual
variational circuit. The method is then evaluated on the blind test set
DFUC2021. The results proves that our proposed hybrid classical-quantum
Classifier leads to considerable improvement compared to solely relying on
transfer learning concept through training the modified version of Xception
network.

    

### [[2110.02226] Communication-Efficient Federated Learning with Binary Neural Networks](http://arxiv.org/abs/2110.02226)


  Federated learning (FL) is a privacy-preserving machine learning setting that
enables many devices to jointly train a shared global model without the need to
reveal their data to a central server. However, FL involves a frequent exchange
of the parameters between all the clients and the server that coordinates the
training. This introduces extensive communication overhead, which can be a
major bottleneck in FL with limited communication links. In this paper, we
consider training the binary neural networks (BNN) in the FL setting instead of
the typical real-valued neural networks to fulfill the stringent delay and
efficiency requirement in wireless edge networks. We introduce a novel FL
framework of training BNN, where the clients only upload the binary parameters
to the server. We also propose a novel parameter updating scheme based on the
Maximum Likelihood (ML) estimation that preserves the performance of the BNN
even without the availability of aggregated real-valued auxiliary parameters
that are usually needed during the training of the BNN. Moreover, for the first
time in the literature, we theoretically derive the conditions under which the
training of BNN is converging. { Numerical results show that the proposed FL
framework significantly reduces the communication cost compared to the
conventional neural networks with typical real-valued parameters, and the
performance loss incurred by the binarization can be further compensated by a
hybrid method.

    

### [[2110.02248] Contextual Combinatorial Volatile Bandits via Gaussian Processes](http://arxiv.org/abs/2110.02248)


  We consider a contextual bandit problem with a combinatorial action set and
time-varying base arm availability. At the beginning of each round, the agent
observes the set of available base arms and their contexts and then selects an
action that is a feasible subset of the set of available base arms to maximize
its cumulative reward in the long run. We assume that the mean outcomes of base
arms are samples from a Gaussian Process indexed by the context set ${\cal X}$,
and the expected reward is Lipschitz continuous in expected base arm outcomes.
For this setup, we propose an algorithm called Optimistic Combinatorial
Learning and Optimization with Kernel Upper Confidence Bounds (O'CLOK-UCB) and
prove that it incurs $\tilde{O}(K\sqrt{T\overline{\gamma}_{T}} )$ regret with
high probability, where $\overline{\gamma}_{T}$ is the maximum information gain
associated with the set of base arm contexts that appeared in the first $T$
rounds and $K$ is the maximum cardinality of any feasible action over all
rounds. To dramatically speed up the algorithm, we also propose a variant of
O'CLOK-UCB that uses sparse GPs. Finally, we experimentally show that both
algorithms exploit inter-base arm outcome correlation and vastly outperform the
previous state-of-the-art UCB-based algorithms in realistic setups.

    

### [[2110.02250] Measuring chemical likeness of stars with RSCA](http://arxiv.org/abs/2110.02250)


  Identification of chemically similar stars using elemental abundances is core
to many pursuits within Galactic archaeology. However, measuring the chemical
likeness of stars using abundances directly is limited by systematic imprints
of imperfect synthetic spectra in abundance derivation. We present a novel
data-driven model that is capable of identifying chemically similar stars from
spectra alone. We call this Relevant Scaled Component Analysis (RSCA). RSCA
finds a mapping from stellar spectra to a representation that optimizes
recovery of known open clusters. By design, RSCA amplifies factors of chemical
abundance variation and minimizes those of non-chemical parameters, such as
instrument systematics. The resultant representation of stellar spectra can
therefore be used for precise measurements of chemical similarity between
stars. We validate RSCA using 185 cluster stars in 22 open clusters in the
APOGEE survey. We quantify our performance in measuring chemical similarity
using a reference set of 151,145 field stars. We find that our representation
identifies known stellar siblings more effectively than stellar abundance
measurements. Using RSCA, 1.8% of pairs of field stars are as similar as birth
siblings, compared to 2.3% when using stellar abundance labels. We find that
almost all of the information within spectra leveraged by RSCA fits into a
two-dimensional basis, which we link to [Fe/H] and alpha-element abundances. We
conclude that chemical tagging of stars to their birth clusters remains
prohibitive. However, using the spectra has noticeable gain, and our approach
is poised to benefit from larger datasets and improved algorithm designs.

    

### [[2110.02267] Disambiguation-BERT for N-best Rescoring in Low-Resource Conversational ASR](http://arxiv.org/abs/2110.02267)


  We study the inclusion of past conversational context through BERT language
models into a CTC-based Automatic Speech Recognition (ASR) system via N-best
rescoring. We introduce a data-efficient strategy to fine-tune BERT on
transcript disambiguation without external data. Our results show word error
rate recoveries up to 37.2% with context-augmented BERT rescoring. We do this
in low-resource data domains, both in language (Norwegian), tone (spontaneous,
conversational), and topics (parliament proceedings and customer service phone
calls). We show how the nature of the data greatly affects the performance of
context-augmented N-best rescoring.

    

### [[2110.02271] Networked Time Series Prediction with Incomplete Data](http://arxiv.org/abs/2110.02271)


  A networked time series (NETS) is a family of time series on a given graph,
one for each node. It has found a wide range of applications from intelligent
transportation, environment monitoring to mobile network management. An
important task in such applications is to predict the future values of a NETS
based on its historical values and the underlying graph. Most existing methods
require complete data for training. However, in real-world scenarios, it is not
uncommon to have missing data due to sensor malfunction, incomplete sensing
coverage, etc. In this paper, we study the problem of NETS prediction with
incomplete data. We propose NETS-ImpGAN, a novel deep learning framework that
can be trained on incomplete data with missing values in both history and
future. Furthermore, we propose novel Graph Temporal Attention Networks by
incorporating the attention mechanism to capture both inter-time series
correlations and temporal correlations. We conduct extensive experiments on
three real-world datasets under different missing patterns and missing rates.
The experimental results show that NETS-ImpGAN outperforms existing methods
except when data exhibit very low variance, in which case NETS-ImpGAN still
achieves competitive performance.

    

### [[2110.02273] Bilevel Imaging Learning Problems as Mathematical Programs with Complementarity Constraints](http://arxiv.org/abs/2110.02273)


  We investigate a family of bilevel imaging learning problems where the
lower-level instance corresponds to a convex variational model involving first-
and second-order nonsmooth regularizers. By using geometric properties of the
primal-dual reformulation of the lower-level problem and introducing suitable
changes of variables, we are able to reformulate the original bilevel problems
as Mathematical Programs with Complementarity Constraints (MPCC). For the
latter, we prove tight constraint qualification conditions (MPCC-MFCQ and
partial MPCC-LICQ) and derive Mordukovich (M-) and Strong (S-) stationarity
conditions. The S-stationarity system for the MPCC turns also into
S-stationarity conditions for the original formulation. Second-order sufficient
optimality conditions are derived as well. The proposed reformulation may be
extended to problems in function spaces, leading to MPCC's with additional
constraints on the gradient of the state. Finally, we report on some numerical
results obtained by using the proposed MPCC reformulations together with
available large-scale nonlinear programming solvers.

    

### [[2110.02276] SeanNet: Semantic Understanding Network for Localization Under Object Dynamics](http://arxiv.org/abs/2110.02276)


  We aim for domestic robots to operate indoor for long-term service. Under the
object-level scene dynamics induced by human daily activities, a robot needs to
robustly localize itself in the environment subject to scene uncertainties.
Previous works have addressed visual-based localization in static environments,
yet the object-level scene dynamics challenge existing methods on long-term
deployment of the robot. This paper proposes SEmantic understANding Network
(SeanNet) that enables robots to measure the similarity between two scenes on
both visual and semantic aspects. We further develop a similarity-based
localization method based on SeanNet for monitoring the progress of visual
navigation tasks. In our experiments, we benchmarked SeanNet against baselines
methods on scene similarity measures, as well as visual navigation performance
once integrated with a visual navigator. We demonstrate that SeanNet
outperforms all baseline methods, by robustly localizing the robot under object
dynamics, thus reliably informing visual navigation about the task status.

    

### [[2110.02279] Turing approximations, toric isometric embeddings & manifold convolutions](http://arxiv.org/abs/2110.02279)


  Convolutions are fundamental elements in deep learning architectures. Here,
we present a theoretical framework for combining extrinsic and intrinsic
approaches to manifold convolution through isometric embeddings into tori. In
this way, we define a convolution operator for a manifold of arbitrary topology
and dimension. We also explain geometric and topological conditions that make
some local definitions of convolutions which rely on translating filters along
geodesic paths on a manifold, computationally intractable. A result of Alan
Turing from 1938 underscores the need for such a toric isometric embedding
approach to achieve a global definition of convolution on computable, finite
metric space approximations to a smooth manifold.

    

### [[2110.02283] Co-training an Unsupervised Constituency Parser with Weak Supervision](http://arxiv.org/abs/2110.02283)


  We introduce a method for unsupervised parsing that relies on bootstrapping
classifiers to identify if a node dominates a specific span in a sentence.
There are two types of classifiers, an inside classifier that acts on a span,
and an outside classifier that acts on everything outside of a given span.
Through self-training and co-training with the two classifiers, we show that
the interplay between them helps improve the accuracy of both, and as a result,
effectively parse. A seed bootstrapping technique prepares the data to train
these classifiers. Our analyses further validate that such an approach in
conjunction with weak supervision using prior branching knowledge of a known
language (left/right-branching) and minimal heuristics injects strong inductive
bias into the parser, achieving 63.1 F$_1$ on the English (PTB) test set. In
addition, we show the effectiveness of our architecture by evaluating on
treebanks for Chinese (CTB) and Japanese (KTB) and achieve new state-of-the-art
results.\footnote{For code or data, please contact the authors.}

    

### [[2110.02291] FedDQ: Communication-Efficient Federated Learning with Descending Quantization](http://arxiv.org/abs/2110.02291)


  Federated learning (FL) is an emerging privacy-preserving distributed
learning scheme. Due to the large model size and frequent model aggregation, FL
suffers from critical communication bottleneck. Many techniques have been
proposed to reduce the communication volume, including model compression and
quantization, where quantization with increasing number of levels has been
proposed. This paper proposes an opposite approach to do adaptive quantization.
First, we present the drawback of ascending-trend quantization based on the
characteristics of training. Second, we formulate the quantization optimization
problem and theoretical analysis shows that quantization with decreasing number
of levels is preferred. Then we propose two strategies to guide the adaptive
quantization process by using the change in training loss and the range of
model update. Experimental results on three sets of benchmarks show that
descending-trend quantization not only saves more communication bits but also
helps FL converge faster, when compares with current ascending-trend
quantization.

    

### [[2110.02296] On the Correspondence between Gaussian Processes and Geometric Harmonics](http://arxiv.org/abs/2110.02296)


  We discuss the correspondence between Gaussian process regression and
Geometric Harmonics, two similar kernel-based methods that are typically used
in different contexts. Research communities surrounding the two concepts often
pursue different goals. Results from both camps can be successfully combined,
providing alternative interpretations of uncertainty in terms of error
estimation, or leading towards accelerated Bayesian Optimization due to
dimensionality reduction.

    

### [[2110.02297] Robustness modularity in complex networks](http://arxiv.org/abs/2110.02297)


  A basic question in network community detection is how modular a given
network is. This is usually addressed by evaluating the quality of partitions
detected in the network. The Girvan-Newman (GN) modularity function is the
standard way to make this assessment, but it has a number of drawbacks. Most
importantly, it is not clearly interpretable, given that the measure can take
relatively large values on partitions of random networks without communities.
Here we propose a new measure based on the concept of robustness: modularity is
the probability to find trivial partitions when the structure of the network is
randomly perturbed. This concept can be implemented for any clustering
algorithm capable of telling when a group structure is absent. Tests on
artificial and real graphs reveal that robustness modularity can be used to
assess and compare the strength of the community structure of different
networks. We also introduce two other quality functions: modularity difference,
a suitably normalized version of the GN modularity; information modularity, a
measure of distance based on information compression. Both measures are
strongly correlated with robustness modularity, and are promising options as
well.

    

### [[2110.02304] You Only Evaluate Once: a Simple Baseline Algorithm for Offline RL](http://arxiv.org/abs/2110.02304)


  The goal of offline reinforcement learning (RL) is to find an optimal policy
given prerecorded trajectories. Many current approaches customize existing
off-policy RL algorithms, especially actor-critic algorithms in which policy
evaluation and improvement are iterated. However, the convergence of such
approaches is not guaranteed due to the use of complex non-linear function
approximation and an intertwined optimization process. By contrast, we propose
a simple baseline algorithm for offline RL that only performs the policy
evaluation step once so that the algorithm does not require complex
stabilization schemes. Since the proposed algorithm is not likely to converge
to an optimal policy, it is an appropriate baseline for actor-critic algorithms
that ought to be outperformed if there is indeed value in iterative
optimization in the offline setting. Surprisingly, we empirically find that the
proposed algorithm exhibits competitive and sometimes even state-of-the-art
performance in a subset of the D4RL offline RL benchmark. This result suggests
that future work is needed to fully exploit the potential advantages of
iterative optimization in order to justify the reduced stability of such
methods.

    

### [[2110.02307] Coarsening Optimization for Differentiable Programming](http://arxiv.org/abs/2110.02307)


  This paper presents a novel optimization for differentiable programming named
coarsening optimization. It offers a systematic way to synergize symbolic
differentiation and algorithmic differentiation (AD). Through it, the
granularity of the computations differentiated by each step in AD can become
much larger than a single operation, and hence lead to much reduced runtime
computations and data allocations in AD. To circumvent the difficulties that
control flow creates to symbolic differentiation in coarsening, this work
introduces phi-calculus, a novel method to allow symbolic reasoning and
differentiation of computations that involve branches and loops. It further
avoids "expression swell" in symbolic differentiation and balance reuse and
coarsening through the design of reuse-centric segment of interest
identification. Experiments on a collection of real-world applications show
that coarsening optimization is effective in speeding up AD, producing several
times to two orders of magnitude speedups.

    

### [[2110.02313] Phoebe: A Learning-based Checkpoint Optimizer](http://arxiv.org/abs/2110.02313)


  Easy-to-use programming interfaces paired with cloud-scale processing engines
have enabled big data system users to author arbitrarily complex analytical
jobs over massive volumes of data. However, as the complexity and scale of
analytical jobs increase, they encounter a number of unforeseen problems,
hotspots with large intermediate data on temporary storage, longer job recovery
time after failures, and worse query optimizer estimates being examples of
issues that we are facing at Microsoft.
To address these issues, we propose Phoebe, an efficient learning-based
checkpoint optimizer. Given a set of constraints and an objective function at
compile-time, Phoebe is able to determine the decomposition of job plans, and
the optimal set of checkpoints to preserve their outputs to durable global
storage. Phoebe consists of three machine learning predictors and one
optimization module. For each stage of a job, Phoebe makes accurate predictions
for: (1) the execution time, (2) the output size, and (3) the start/end time
taking into account the inter-stage dependencies. Using these predictions, we
formulate checkpoint optimization as an integer programming problem and propose
a scalable heuristic algorithm that meets the latency requirement of the
production environment.
We demonstrate the effectiveness of Phoebe in production workloads, and show
that we can free the temporary storage on hotspots by more than 70% and restart
failed jobs 68% faster on average with minimum performance impact. Phoebe also
illustrates that adding multiple sets of checkpoints is not cost-efficient,
which dramatically reduces the complexity of the optimization.

    

### [[2110.02316] Prediction of the Facial Growth Direction is Challenging](http://arxiv.org/abs/2110.02316)


  Facial dysmorphology or malocclusion is frequently associated with abnormal
growth of the face. The ability to predict facial growth (FG) direction would
allow clinicians to prepare individualized therapy to increase the chance for
successful treatment. Prediction of FG direction is a novel problem in the
machine learning (ML) domain. In this paper, we perform feature selection and
point the attribute that plays a central role in the abovementioned problem.
Then we successfully apply data augmentation (DA) methods and improve the
previously reported classification accuracy by 2.81%. Finally, we present the
results of two experienced clinicians that were asked to solve a similar task
to ours and show how tough is solving this problem for human experts.

    

### [[2110.02329] Task-aware Privacy Preservation for Multi-dimensional Data](http://arxiv.org/abs/2110.02329)


  Local differential privacy (LDP), a state-of-the-art technique for privacy
preservation, has been successfully deployed in a few real-world applications.
In the future, LDP can be adopted to anonymize richer user data attributes that
will be input to more sophisticated machine learning (ML) tasks. However,
today's LDP approaches are largely task-agnostic and often lead to sub-optimal
performance -- they will simply inject noise to all data attributes according
to a given privacy budget, regardless of what features are most relevant for an
ultimate task. In this paper, we address how to significantly improve the
ultimate task performance for multi-dimensional user data by considering a
task-aware privacy preservation problem. The key idea is to use an
encoder-decoder framework to learn (and anonymize) a task-relevant latent
representation of user data, which gives an analytical near-optimal solution
for a linear setting with mean-squared error (MSE) task loss. We also provide
an approximate solution through a learning algorithm for general nonlinear
cases. Extensive experiments demonstrate that our task-aware approach
significantly improves ultimate task accuracy compared to a standard benchmark
LDP approach while guaranteeing the same level of privacy.

    

### [[2110.02332] OTTR: Off-Road Trajectory Tracking using Reinforcement Learning](http://arxiv.org/abs/2110.02332)


  In this work, we present a novel Reinforcement Learning (RL) algorithm for
the off-road trajectory tracking problem. Off-road environments involve varying
terrain types and elevations, and it is difficult to model the interaction
dynamics of specific off-road vehicles with such a diverse and complex
environment. Standard RL policies trained on a simulator will fail to operate
in such challenging real-world settings. Instead of using a naive domain
randomization approach, we propose an innovative supervised-learning based
approach for overcoming the sim-to-real gap problem. Our approach efficiently
exploits the limited real-world data available to adapt the baseline RL policy
obtained using a simple kinematics simulator. This avoids the need for modeling
the diverse and complex interaction of the vehicle with off-road environments.
We evaluate the performance of the proposed algorithm using two different
off-road vehicles, Warthog and Moose. Compared to the standard ILQR approach,
our proposed approach achieves a 30% and 50% reduction in cross track error in
Warthog and Moose, respectively, by utilizing only 30 minutes of real-world
driving data.

    

### [[2110.02333] On the Impact of Stable Ranks in Deep Nets](http://arxiv.org/abs/2110.02333)


  A recent line of work has established intriguing connections between the
generalization/compression properties of a deep neural network (DNN) model and
the so-called layer weights' stable ranks. Intuitively, the latter are
indicators of the effective number of parameters in the net. In this work, we
address some natural questions regarding the space of DNNs conditioned on the
layers' stable rank, where we study feed-forward dynamics, initialization,
training and expressivity. To this end, we first propose a random DNN model
with a new sampling scheme based on stable rank. Then, we show how feed-forward
maps are affected by the constraint and how training evolves in the
overparametrized regime (via Neural Tangent Kernels). Our results imply that
stable ranks appear layerwise essentially as linear factors whose effect
accumulates exponentially depthwise. Moreover, we provide empirical analysis
suggesting that stable rank initialization alone can lead to convergence speed
ups.

    

### [[2110.02334] Exploring Conditional Text Generation for Aspect-Based Sentiment Analysis](http://arxiv.org/abs/2110.02334)


  Aspect-based sentiment analysis (ABSA) is an NLP task that entails processing
user-generated reviews to determine (i) the target being evaluated, (ii) the
aspect category to which it belongs, and (iii) the sentiment expressed towards
the target and aspect pair. In this article, we propose transforming ABSA into
an abstract summary-like conditional text generation task that uses targets,
aspects, and polarities to generate auxiliary statements. To demonstrate the
efficacy of our task formulation and a proposed system, we fine-tune a
pre-trained model for conditional text generation tasks to get new
state-of-the-art results on a few restaurant domains and urban neighborhoods
domain benchmark datasets.

    

### [[2110.02341] How to Query An Oracle? Efficient Strategies to Label Data](http://arxiv.org/abs/2110.02341)


  We consider the basic problem of querying an expert oracle for labeling a
dataset in machine learning. This is typically an expensive and time consuming
process and therefore, we seek ways to do so efficiently. The conventional
approach involves comparing each sample with (the representative of) each class
to find a match. In a setting with $N$ equally likely classes, this involves
$N/2$ pairwise comparisons (queries per sample) on average. We consider a
$k$-ary query scheme with $k\ge 2$ samples in a query that identifies
(dis)similar items in the set while effectively exploiting the associated
transitive relations. We present a randomized batch algorithm that operates on
a round-by-round basis to label the samples and achieves a query rate of
$O(\frac{N}{k^2})$. In addition, we present an adaptive greedy query scheme,
which achieves an average rate of $\approx 0.2N$ queries per sample with
triplet queries. For the proposed algorithms, we investigate the query rate
performance analytically and with simulations. Empirical studies suggest that
each triplet query takes an expert at most 50\% more time compared with a
pairwise query, indicating the effectiveness of the proposed $k$-ary query
schemes. We generalize the analyses to nonuniform class distributions when
possible.

    

### [[2110.02343] Quantum Semi-Supervised Learning with Quantum Supremacy](http://arxiv.org/abs/2110.02343)


  Quantum machine learning promises to efficiently solve important problems.
There are two persistent challenges in classical machine learning: the lack of
labeled data, and the limit of computational power. We propose a novel
framework that resolves both issues: quantum semi-supervised learning.
Moreover, we provide a protocol in systematically designing quantum machine
learning algorithms with quantum supremacy, which can be extended beyond
quantum semi-supervised learning. We showcase two concrete quantum
semi-supervised learning algorithms: a quantum self-training algorithm named
the propagating nearest-neighbor classifier, and the quantum semi-supervised
K-means clustering algorithm. By doing time complexity analysis, we conclude
that they indeed possess quantum supremacy.

    

### [[2110.02344] HYPER: Learned Hybrid Trajectory Prediction via Factored Inference and Adaptive Sampling](http://arxiv.org/abs/2110.02344)


  Modeling multi-modal high-level intent is important for ensuring diversity in
trajectory prediction. Existing approaches explore the discrete nature of human
intent before predicting continuous trajectories, to improve accuracy and
support explainability. However, these approaches often assume the intent to
remain fixed over the prediction horizon, which is problematic in practice,
especially over longer horizons. To overcome this limitation, we introduce
HYPER, a general and expressive hybrid prediction framework that models
evolving human intent. By modeling traffic agents as a hybrid
discrete-continuous system, our approach is capable of predicting discrete
intent changes over time. We learn the probabilistic hybrid model via a maximum
likelihood estimation problem and leverage neural proposal distributions to
sample adaptively from the exponentially growing discrete space. The overall
approach affords a better trade-off between accuracy and coverage. We train and
validate our model on the Argoverse dataset, and demonstrate its effectiveness
through comprehensive ablation studies and comparisons with state-of-the-art
models.

    

### [[2110.02364] Adversarial defenses via a mixture of generators](http://arxiv.org/abs/2110.02364)


  In spite of the enormous success of neural networks, adversarial examples
remain a relatively weakly understood feature of deep learning systems. There
is a considerable effort in both building more powerful adversarial attacks and
designing methods to counter the effects of adversarial examples. We propose a
method to transform the adversarial input data through a mixture of generators
in order to recover the correct class obfuscated by the adversarial attack. A
canonical set of images is used to generate adversarial examples through
potentially multiple attacks. Such transformed images are processed by a set of
generators, which are trained adversarially as a whole to compete in inverting
the initial transformations. To our knowledge, this is the first use of a
mixture-based adversarially trained system as a defense mechanism. We show that
it is possible to train such a system without supervision, simultaneously on
multiple adversarial attacks. Our system is able to recover class information
for previously-unseen examples with neither attack nor data labels on the MNIST
dataset. The results demonstrate that this multi-attack approach is competitive
with adversarial defenses tested in single-attack settings.

    

### [[2110.02369] EntQA: Entity Linking as Question Answering](http://arxiv.org/abs/2110.02369)


  A conventional approach to entity linking is to first find mentions in a
given document and then infer their underlying entities in the knowledge base.
A well-known limitation of this approach is that it requires finding mentions
without knowing their entities, which is unnatural and difficult. We present a
new model that does not suffer from this limitation called EntQA, which stands
for Entity linking as Question Answering. EntQA first proposes candidate
entities with a fast retrieval module, and then scrutinizes the document to
find mentions of each candidate with a powerful reader module. Our approach
combines progress in entity linking with that in open-domain question answering
and capitalizes on pretrained models for dense entity retrieval and reading
comprehension. Unlike in previous works, we do not rely on a mention-candidates
dictionary or large-scale weak supervision. EntQA achieves strong results on
the GERBIL benchmarking platform.

    

### [[2110.02381] Robust Peak Detection for Holter ECGs by Self-Organized Operational Neural Networks](http://arxiv.org/abs/2110.02381)


  Although numerous R-peak detectors have been proposed in the literature,
their robustness and performance levels may significantly deteriorate in low
quality and noisy signals acquired from mobile ECG sensors such as Holter
monitors. Recently, this issue has been addressed by deep 1D Convolutional
Neural Networks (CNNs) that have achieved state-of-the-art performance levels
in Holter monitors; however, they pose a high complexity level that requires
special parallelized hardware setup for real-time processing. On the other
hand, their performance deteriorates when a compact network configuration is
used instead. This is an expected outcome as recent studies have demonstrated
that the learning performance of CNNs is limited due to their strictly
homogenous configuration with the sole linear neuron model. This has been
addressed by Operational Neural Networks (ONNs) with their heterogenous network
configuration encapsulating neurons with various non-linear operators. In this
study, to further boost the peak detection performance along with an elegant
computational efficiency, we propose 1D Self-Organized Operational Neural
Networks (Self-ONNs) with generative neurons. The most crucial advantage of 1D
Self-ONNs over the ONNs is their self-organization capability that voids the
need to search for the best operator set per neuron since each generative
neuron has the ability to create the optimal operator during training. The
experimental results over the China Physiological Signal Challenge-2020 (CPSC)
dataset with more than one million ECG beats show that the proposed 1D
Self-ONNs can significantly surpass the state-of-the-art deep CNN with less
computational complexity. Results demonstrate that the proposed solution
achieves 99.10% F1-score, 99.79% sensitivity, and 98.42% positive predictivity
in the CPSC dataset which is the best R-peak detection performance ever
achieved.

    

### [[2110.02388] Fast and Interpretable Consensus Clustering via Minipatch Learning](http://arxiv.org/abs/2110.02388)


  Consensus clustering has been widely used in bioinformatics and other
applications to improve the accuracy, stability and reliability of clustering
results. This approach ensembles cluster co-occurrences from multiple
clustering runs on subsampled observations. For application to large-scale
bioinformatics data, such as to discover cell types from single-cell sequencing
data, for example, consensus clustering has two significant drawbacks: (i)
computational inefficiency due to repeatedly applying clustering algorithms,
and (ii) lack of interpretability into the important features for
differentiating clusters. In this paper, we address these two challenges by
developing IMPACC: Interpretable MiniPatch Adaptive Consensus Clustering. Our
approach adopts three major innovations. We ensemble cluster co-occurrences
from tiny subsets of both observations and features, termed minipatches, thus
dramatically reducing computation time. Additionally, we develop adaptive
sampling schemes for observations, which result in both improved reliability
and computational savings, as well as adaptive sampling schemes of features,
which leads to interpretable solutions by quickly learning the most relevant
features that differentiate clusters. We study our approach on synthetic data
and a variety of real large-scale bioinformatics data sets; results show that
our approach not only yields more accurate and interpretable cluster solutions,
but it also substantially improves computational efficiency compared to
standard consensus clustering approaches.

    

### [[2110.02393] Geometric Algebra Attention Networks for Small Point Clouds](http://arxiv.org/abs/2110.02393)


  Much of the success of deep learning is drawn from building architectures
that properly respect underlying symmetry and structure in the data on which
they operate - a set of considerations that have been united under the banner
of geometric deep learning. Often problems in the physical sciences deal with
relatively small sets of points in two- or three-dimensional space wherein
translation, rotation, and permutation equivariance are important or even vital
for models to be useful in practice. In this work, we present rotation- and
permutation-equivariant architectures for deep learning on these small point
clouds, composed of a set of products of terms from the geometric algebra and
reductions over those products using an attention mechanism. The geometric
algebra provides valuable mathematical structure by which to combine vector,
scalar, and other types of geometric inputs in a systematic way to account for
rotation invariance or covariance, while attention yields a powerful way to
impose permutation equivariance. We demonstrate the usefulness of these
architectures by training models to solve sample problems relevant to physics,
chemistry, and biology.

    

### [[2110.02395] Structural Causal Interpretation Theorem](http://arxiv.org/abs/2110.02395)


  Human mental processes allow for qualitative reasoning about causality in
terms of mechanistic relations of the variables of interest, which we argue are
naturally described by structural causal model (SCM). Since interpretations are
being derived from mental models, the same applies for SCM. By defining a
metric space on SCM, we provide a theoretical perspective on the comparison of
mental models and thereby conclude that interpretations can be used for guiding
a learning system towards true causality. To this effect, we present a
theoretical analysis from first principles that results in a human-readable
interpretation scheme consistent with the provided causality that we name
structural causal interpretations (SCI). Going further, we prove that any
existing neural induction method (NIM) is in fact interpretable. Our first
experiment (E1) assesses the quality of such NIM-based SCI. In (E2) we observe
evidence for our conjecture on improved sample-efficiency for SCI-based
learning. After conducting a small user study, in (E3) we observe superiority
in human-based over NIM-based SCI in support of our initial hypothesis.

    

### [[2110.02398] Quasi-Newton policy gradient algorithms](http://arxiv.org/abs/2110.02398)


  Policy gradient algorithms have been widely applied to reinforcement learning
(RL) problems in recent years. Regularization with various entropy functions is
often used to encourage exploration and improve stability. In this paper, we
propose a quasi-Newton method for the policy gradient algorithm with entropy
regularization. In the case of Shannon entropy, the resulting algorithm
reproduces the natural policy gradient (NPG) algorithm. For other entropy
functions, this method results in brand new policy gradient algorithms. We
provide a simple proof that all these algorithms enjoy the Newton-type
quadratic convergence near the optimal policy. Using synthetic and
industrial-scale examples, we demonstrate that the proposed quasi-Newton method
typically converges in single-digit iterations, often orders of magnitude
faster than other state-of-the-art algorithms.

    

### [[2110.02399] Task Affinity with Maximum Bipartite Matching in Few-Shot Learning](http://arxiv.org/abs/2110.02399)


  We propose an asymmetric affinity score for representing the complexity of
utilizing the knowledge of one task for learning another one. Our method is
based on the maximum bipartite matching algorithm and utilizes the Fisher
Information matrix. We provide theoretical analyses demonstrating that the
proposed score is mathematically well-defined, and subsequently use the
affinity score to propose a novel algorithm for the few-shot learning problem.
In particular, using this score, we find relevant training data labels to the
test data and leverage the discovered relevant data for episodically
fine-tuning a few-shot model. Results on various few-shot benchmark datasets
demonstrate the efficacy of the proposed approach by improving the
classification accuracy over the state-of-the-art methods even when using
smaller models.

    

### [[2110.02402] Language Modeling using LMUs: 10x Better Data Efficiency or Improved Scaling Compared to Transformers](http://arxiv.org/abs/2110.02402)


  Recent studies have demonstrated that the performance of transformers on the
task of language modeling obeys a power-law relationship with model size over
six orders of magnitude. While transformers exhibit impressive scaling, their
performance hinges on processing large amounts of data, and their computational
and memory requirements grow quadratically with sequence length. Motivated by
these considerations, we construct a Legendre Memory Unit based model that
introduces a general prior for sequence processing and exhibits an $O(n)$ and
$O(n \ln n)$ (or better) dependency for memory and computation respectively.
Over three orders of magnitude, we show that our new architecture attains the
same accuracy as transformers with 10x fewer tokens. We also show that for the
same amount of training our model improves the loss over transformers about as
much as transformers improve over LSTMs. Additionally, we demonstrate that
adding global self-attention complements our architecture and the augmented
model improves performance even further.

    

### [[2110.02403] Tradeoffs in Streaming Binary Classification under Limited Inspection Resources](http://arxiv.org/abs/2110.02403)


  Institutions are increasingly relying on machine learning models to identify
and alert on abnormal events, such as fraud, cyber attacks and system failures.
These alerts often need to be manually investigated by specialists. Given the
operational cost of manual inspections, the suspicious events are selected by
alerting systems with carefully designed thresholds. In this paper, we consider
an imbalanced binary classification problem, where events arrive sequentially
and only a limited number of suspicious events can be inspected. We model the
event arrivals as a non-homogeneous Poisson process, and compare various
suspicious event selection methods including those based on static and adaptive
thresholds. For each method, we analytically characterize the tradeoff between
the minority-class detection rate and the inspection capacity as a function of
the data class imbalance and the classifier confidence score densities. We
implement the selection methods on a real public fraud detection dataset and
compare the empirical results with analytical bounds. Finally, we investigate
how class imbalance and the choice of classifier impact the tradeoff.

    

### [[2110.02411] Voice Aging with Audio-Visual Style Transfer](http://arxiv.org/abs/2110.02411)


  Face aging techniques have used generative adversarial networks (GANs) and
style transfer learning to transform one's appearance to look younger/older.
Identity is maintained by conditioning these generative networks on a learned
vector representation of the source content. In this work, we apply a similar
approach to age a speaker's voice, referred to as voice aging. We first analyze
the classification of a speaker's age by training a convolutional neural
network (CNN) on the speaker's voice and face data from Common Voice and
VoxCeleb datasets. We generate aged voices from style transfer to transform an
input spectrogram to various ages and demonstrate our method on a mobile app.

    

### [[2110.02414] Imaginary Hindsight Experience Replay: Curious Model-based Learning for Sparse Reward Tasks](http://arxiv.org/abs/2110.02414)


  Model-based reinforcement learning is a promising learning strategy for
practical robotic applications due to its improved data-efficiency versus
model-free counterparts. However, current state-of-the-art model-based methods
rely on shaped reward signals, which can be difficult to design and implement.
To remedy this, we propose a simple model-based method tailored for
sparse-reward multi-goal tasks that foregoes the need for complicated reward
engineering. This approach, termed Imaginary Hindsight Experience Replay,
minimises real-world interactions by incorporating imaginary data into policy
updates. To improve exploration in the sparse-reward setting, the policy is
trained with standard Hindsight Experience Replay and endowed with
curiosity-based intrinsic rewards. Upon evaluation, this approach provides an
order of magnitude increase in data-efficiency on average versus the
state-of-the-art model-free method in the benchmark OpenAI Gym Fetch Robotics
tasks.

    

### [[2110.02417] CADA: Multi-scale Collaborative Adversarial Domain Adaptation for Unsupervised Optic Disc and Cup Segmentation](http://arxiv.org/abs/2110.02417)


  The diversity of retinal imaging devices poses a significant challenge:
domain shift, which leads to performance degradation when applying the deep
learning models trained on one domain to new testing domains. In this paper, we
propose a multi-scale input along with multiple domain adaptors applied
hierarchically in both feature and output spaces. The proposed training
strategy and novel unsupervised domain adaptation framework, called
Collaborative Adversarial Domain Adaptation (CADA), can effectively overcome
the challenge. Multi-scale inputs can reduce the information loss due to the
pooling layers used in the network for feature extraction, while our proposed
CADA is an interactive paradigm that presents an exquisite collaborative
adaptation through both adversarial learning and ensembling weights at
different network layers. In particular, to produce a better prediction for the
unlabeled target domain data, we simultaneously achieve domain invariance and
model generalizability via adversarial learning at multi-scale outputs from
different levels of network layers and maintaining an exponential moving
average (EMA) of the historical weights during training. Without annotating any
sample from the target domain, multiple adversarial losses in encoder and
decoder layers guide the extraction of domain-invariant features to confuse the
domain classifier. Meanwhile, the ensembling of weights via EMA reduces the
uncertainty of adapting multiple discriminator learning. Comprehensive
experimental results demonstrate that our CADA model incorporating multi-scale
input training can overcome performance degradation and outperform
state-of-the-art domain adaptation methods in segmenting retinal optic disc and
cup from fundus images stemming from the REFUGE, Drishti-GS, and Rim-One-r3
datasets.

    

### [[2110.02419] Feature Selection by a Mechanism Design](http://arxiv.org/abs/2110.02419)


  In constructing an econometric or statistical model, we pick relevant
features or variables from many candidates. A coalitional game is set up to
study the selection problem where the players are the candidates and the payoff
function is a performance measurement in all possible modeling scenarios. Thus,
in theory, an irrelevant feature is equivalent to a dummy player in the game,
which contributes nothing to all modeling situations. The hypothesis test of
zero mean contribution is the rule to decide a feature is irrelevant or not. In
our mechanism design, the end goal perfectly matches the expected model
performance with the expected sum of individual marginal effects. Within a
class of noninformative likelihood among all modeling opportunities, the
matching equation results in a specific valuation for each feature. After
estimating the valuation and its standard deviation, we drop any candidate
feature if its valuation is not significantly different from zero. In the
simulation studies, our new approach significantly outperforms several popular
methods used in practice, and its accuracy is robust to the choice of the
payoff function.

    

### [[2110.02421] Explaining Off-Policy Actor-Critic From A Bias-Variance Perspective](http://arxiv.org/abs/2110.02421)


  Off-policy Actor-Critic algorithms have demonstrated phenomenal experimental
performance but still require better explanations. To this end, we show its
policy evaluation error on the distribution of transitions decomposes into: a
Bellman error, a bias from policy mismatch, and a variance term from sampling.
By comparing the magnitude of bias and variance, we explain the success of the
Emphasizing Recent Experience sampling and 1/age weighted sampling. Both
sampling strategies yield smaller bias and variance and are hence preferable to
uniform sampling.

    

### [[2110.02423] Geometric Transformers for Protein Interface Contact Prediction](http://arxiv.org/abs/2110.02423)


  Computational methods for predicting the interface contacts between proteins
come highly sought after for drug discovery as they can significantly advance
the accuracy of alternative approaches, such as protein-protein docking,
protein function analysis tools, and other computational methods for protein
bioinformatics. In this work, we present the Geometric Transformer, a novel
geometry-evolving graph transformer for rotation and translation-invariant
protein interface contact prediction, packaged within DeepInteract, an
end-to-end prediction pipeline. DeepInteract predicts partner-specific protein
interface contacts (i.e., inter-protein residue-residue contacts) given the 3D
tertiary structures of two proteins as input. In rigorous benchmarks,
DeepInteract, on challenging protein complex targets from the new Enhanced
Database of Interacting Protein Structures (DIPS-Plus) and the 13th and 14th
CASP-CAPRI experiments, achieves 17% and 13% top L/5 precision (L: length of a
protein unit in a complex), respectively. In doing so, DeepInteract, with the
Geometric Transformer as its graph-based backbone, outperforms existing methods
for interface contact prediction in addition to other graph-based neural
network backbones compatible with DeepInteract, thereby validating the
effectiveness of the Geometric Transformer for learning rich
relational-geometric features for downstream tasks on 3D protein structures.

    

### [[2110.02424] Spectral Bias in Practice: The Role of Function Frequency in Generalization](http://arxiv.org/abs/2110.02424)


  Despite their ability to represent highly expressive functions, deep learning
models trained with SGD seem to find simple, constrained solutions that
generalize surprisingly well. Spectral bias - the tendency of neural networks
to prioritize learning low frequency functions - is one possible explanation
for this phenomenon, but so far spectral bias has only been observed in
theoretical models and simplified experiments. In this work, we propose
methodologies for measuring spectral bias in modern image classification
networks. We find that these networks indeed exhibit spectral bias, and that
networks that generalize well strike a balance between having enough
complexity(i.e. high frequencies) to fit the data while being simple enough to
avoid overfitting. For example, we experimentally show that larger models learn
high frequencies faster than smaller ones, but many forms of regularization,
both explicit and implicit, amplify spectral bias and delay the learning of
high frequencies. We also explore the connections between function frequency
and image frequency and find that spectral bias is sensitive to the low
frequencies prevalent in natural images. Our work enables measuring and
ultimately controlling the spectral behavior of neural networks used for image
classification, and is a step towards understanding why deep models generalize
well

    

### [[2110.02436] A Deep Learning-based Audio-in-Image Watermarking Scheme](http://arxiv.org/abs/2110.02436)


  This paper presents a deep learning-based audio-in-image watermarking scheme.
Audio-in-image watermarking is the process of covertly embedding and extracting
audio watermarks on a cover-image. Using audio watermarks can open up
possibilities for different downstream applications. For the purpose of
implementing an audio-in-image watermarking that adapts to the demands of
increasingly diverse situations, a neural network architecture is designed to
automatically learn the watermarking process in an unsupervised manner. In
addition, a similarity network is developed to recognize the audio watermarks
under distortions, therefore providing robustness to the proposed method.
Experimental results have shown high fidelity and robustness of the proposed
blind audio-in-image watermarking scheme.

    

### [[2110.02439] Replay-Guided Adversarial Environment Design](http://arxiv.org/abs/2110.02439)


  Deep reinforcement learning (RL) agents may successfully generalize to new
settings if trained on an appropriately diverse set of environment and task
configurations. Unsupervised Environment Design (UED) is a promising
self-supervised RL paradigm, wherein the free parameters of an underspecified
environment are automatically adapted during training to the agent's
capabilities, leading to the emergence of diverse training environments. Here,
we cast Prioritized Level Replay (PLR), an empirically successful but
theoretically unmotivated method that selectively samples randomly-generated
training levels, as UED. We argue that by curating completely random levels,
PLR, too, can generate novel and complex levels for effective training. This
insight reveals a natural class of UED methods we call Dual Curriculum Design
(DCD). Crucially, DCD includes both PLR and a popular UED algorithm, PAIRED, as
special cases and inherits similar theoretical guarantees. This connection
allows us to develop novel theory for PLR, providing a version with a
robustness guarantee at Nash equilibria. Furthermore, our theory suggests a
highly counterintuitive improvement to PLR: by stopping the agent from updating
its policy on uncurated levels (training on less data), we can improve the
convergence to Nash equilibria. Indeed, our experiments confirm that our new
method, PLR$^{\perp}$, obtains better results on a suite of
out-of-distribution, zero-shot transfer tasks, in addition to demonstrating
that PLR$^{\perp}$ improves the performance of PAIRED, from which it inherited
its theoretical framework.

    

### [[2110.02442] PoNet: Pooling Network for Efficient Token Mixing in Long Sequences](http://arxiv.org/abs/2110.02442)


  Transformer-based models have achieved great success in various NLP, vision,
and speech tasks. However, the core of Transformer, the self-attention
mechanism, has a quadratic time and memory complexity with respect to the
sequence length, which hinders applications of Transformer-based models to long
sequences. Many approaches have been proposed to mitigate this problem, such as
sparse attention mechanisms, low-rank matrix approximations and scalable
kernels, and token mixing alternatives to self-attention. We propose a novel
Pooling Network (PoNet) for token mixing in long sequences with linear
complexity. We design multi-granularity pooling and pooling fusion to capture
different levels of contextual information and combine their interactions with
tokens. On the Long Range Arena benchmark, PoNet significantly outperforms
Transformer and achieves competitive accuracy, while being only slightly slower
than the fastest model, FNet, across all sequence lengths measured on GPUs. We
also conduct systematic studies on the transfer learning capability of PoNet
and observe that PoNet achieves 96.0% of the accuracy of BERT on the GLUE
benchmark, outperforming FNet by 4.5% relative. Comprehensive ablation analysis
demonstrates effectiveness of the designed multi-granularity pooling and
pooling fusion for token mixing in long sequences and efficacy of the designed
pre-training tasks for PoNet to learn transferable contextualized language
representations.

    

### [[2110.02443] Pedestrian Wind Factor Estimation in Complex Urban Environments](http://arxiv.org/abs/2110.02443)


  Urban planners and policy makers face the challenge of creating livable and
enjoyable cities for larger populations in much denser urban conditions. While
the urban microclimate holds a key role in defining the quality of urban spaces
today and in the future, the integration of wind microclimate assessment in
early urban design and planning processes remains a challenge due to the
complexity and high computational expense of computational fluid dynamics (CFD)
simulations. This work develops a data-driven workflow for real-time pedestrian
wind comfort estimation in complex urban environments which may enable
designers, policy makers and city residents to make informed decisions about
mobility, health, and energy choices. We use a conditional generative
adversarial network (cGAN) architecture to reduce the computational computation
while maintaining high confidence levels and interpretability, adequate
representation of urban complexity, and suitability for pedestrian comfort
estimation. We demonstrate high quality wind field approximations while
reducing computation time from days to seconds.

    

### [[2110.02444] Influence-Balanced Loss for Imbalanced Visual Classification](http://arxiv.org/abs/2110.02444)


  In this paper, we propose a balancing training method to address problems in
imbalanced data learning. To this end, we derive a new loss used in the
balancing training phase that alleviates the influence of samples that cause an
overfitted decision boundary. The proposed loss efficiently improves the
performance of any type of imbalance learning methods. In experiments on
multiple benchmark data sets, we demonstrate the validity of our method and
reveal that the proposed loss outperforms the state-of-the-art cost-sensitive
loss methods. Furthermore, since our loss is not restricted to a specific task,
model, or training method, it can be easily used in combination with other
recent re-sampling, meta-learning, and cost-sensitive learning methods for
class-imbalance problems.

    

### [[2110.02453] Ripple Attention for Visual Perception with Sub-quadratic Complexity](http://arxiv.org/abs/2110.02453)


  Transformer architectures are now central to modeling in natural language
processing tasks. At its heart is the attention mechanism, which enables
effective modeling of long-term dependencies in a sequence. Recently,
transformers have been successfully applied in the computer vision domain,
where 2D images are first segmented into patches and then treated as 1D
sequences. Such linearization, however, impairs the notion of spatial locality
in images, which bears important visual clues. To bridge the gap, we propose
ripple attention, a sub-quadratic attention mechanism for visual perception. In
ripple attention, contributions of different tokens to a query are weighted
with respect to their relative spatial distances in the 2D space. To favor
correlations with vicinal tokens yet permit long-term dependencies, we derive
the spatial weights through a stick-breaking transformation. We further design
a dynamic programming algorithm that computes weighted contributions for all
queries in linear observed time, taking advantage of the summed-area table and
recent advances in linearized attention. Extensive experiments and analyses
demonstrate the effectiveness of ripple attention on various visual tasks.

    

### [[2110.02456] VC dimension of partially quantized neural networks in the overparametrized regime](http://arxiv.org/abs/2110.02456)


  Vapnik-Chervonenkis (VC) theory has so far been unable to explain the small
generalization error of overparametrized neural networks. Indeed, existing
applications of VC theory to large networks obtain upper bounds on VC dimension
that are proportional to the number of weights, and for a large class of
networks, these upper bound are known to be tight. In this work, we focus on a
class of partially quantized networks that we refer to as hyperplane
arrangement neural networks (HANNs). Using a sample compression analysis, we
show that HANNs can have VC dimension significantly smaller than the number of
weights, while being highly expressive. In particular, empirical risk
minimization over HANNs in the overparametrized regime achieves the minimax
rate for classification with Lipschitz posterior class probability. We further
demonstrate the expressivity of HANNs empirically. On a panel of 121 UCI
datasets, overparametrized HANNs match the performance of state-of-the-art
full-precision models.

    

### [[2110.02457] Solve Minimax Optimization by Anderson Acceleration](http://arxiv.org/abs/2110.02457)


  Many modern machine learning algorithms such as generative adversarial
networks (GANs) and adversarial training can be formulated as minimax
optimization. Gradient descent ascent (GDA) is the most commonly used algorithm
due to its simplicity. However, GDA can converge to non-optimal minimax points.
We propose a new minimax optimization framework, GDA-AM, that views the
GDAdynamics as a fixed-point iteration and solves it using Anderson Mixing to
con-verge to the local minimax. It addresses the diverging issue of
simultaneous GDAand accelerates the convergence of alternating GDA. We show
theoretically that the algorithm can achieve global convergence for bilinear
problems under mild conditions. We also empirically show that GDA-AMsolves a
variety of minimax problems and improves GAN training on several datasets

    

### [[2110.02459] Post-hoc Models for Performance Estimation of Machine Learning Inference](http://arxiv.org/abs/2110.02459)


  Estimating how well a machine learning model performs during inference is
critical in a variety of scenarios (for example, to quantify uncertainty, or to
choose from a library of available models). However, the standard accuracy
estimate of softmax confidence is not versatile and cannot reliably predict
different performance metrics (e.g., F1-score, recall) or the performance in
different application scenarios or input domains. In this work, we
systematically generalize performance estimation to a diverse set of metrics
and scenarios and discuss generalized notions of uncertainty calibration. We
propose the use of post-hoc models to accomplish this goal and investigate
design parameters, including the model type, feature engineering, and
performance metric, to achieve the best estimation quality. Emphasis is given
to object detection problems and, unlike prior work, our approach enables the
estimation of per-image metrics such as recall and F1-score. Through extensive
experiments with computer vision models and datasets in three use cases --
mobile edge offloading, model selection, and dataset shift -- we find that
proposed post-hoc models consistently outperform the standard calibrated
confidence baselines. To the best of our knowledge, this is the first work to
develop a unified framework to address different performance estimation
problems for machine learning inference.

    

### [[2110.02470] SSFL: Tackling Label Deficiency in Federated Learning via Personalized Self-Supervision](http://arxiv.org/abs/2110.02470)


  Federated Learning (FL) is transforming the ML training ecosystem from a
centralized over-the-cloud setting to distributed training over edge devices in
order to strengthen data privacy. An essential but rarely studied challenge in
FL is label deficiency at the edge. This problem is even more pronounced in FL
compared to centralized training due to the fact that FL users are often
reluctant to label their private data. Furthermore, due to the heterogeneous
nature of the data at edge devices, it is crucial to develop personalized
models. In this paper we propose self-supervised federated learning (SSFL), a
unified self-supervised and personalized federated learning framework, and a
series of algorithms under this framework which work towards addressing these
challenges. First, under the SSFL framework, we demonstrate that the standard
FedAvg algorithm is compatible with recent breakthroughs in centralized
self-supervised learning such as SimSiam networks. Moreover, to deal with data
heterogeneity at the edge devices in this framework, we have innovated a series
of algorithms that broaden existing supervised personalization algorithms into
the setting of self-supervised learning. We further propose a novel
personalized federated self-supervised learning algorithm, Per-SSFL, which
balances personalization and consensus by carefully regulating the distance
between the local and global representations of data. To provide a
comprehensive comparative analysis of all proposed algorithms, we also develop
a distributed training system and related evaluation protocol for SSFL. Our
findings show that the gap of evaluation accuracy between supervised learning
and unsupervised learning in FL is both small and reasonable. The performance
comparison indicates the representation regularization-based personalization
method is able to outperform other variants.

    

### [[2110.02473] The Power of Contrast for Feature Learning: A Theoretical Analysis](http://arxiv.org/abs/2110.02473)


  Contrastive learning has achieved state-of-the-art performance in various
self-supervised learning tasks and even outperforms its supervised counterpart.
Despite its empirical success, theoretical understanding of why contrastive
learning works is still limited. In this paper, (i) we provably show that
contrastive learning outperforms autoencoder, a classical unsupervised learning
method, for both feature recovery and downstream tasks; (ii) we also illustrate
the role of labeled data in supervised contrastive learning. This provides
theoretical support for recent findings that contrastive learning with labels
improves the performance of learned representations in the in-domain downstream
task, but it can harm the performance in transfer learning. We verify our
theory with numerical experiments.

    

### [[2110.02474] Can an AI agent hit a moving target?](http://arxiv.org/abs/2110.02474)


  As the economies we live in are evolving over time, it is imperative that
economic agents in models form expectations that can adjust to changes in the
environment. This exercise offers a plausible expectation formation model that
connects to computer science, psychology and neural science research on
learning and decision-making, and applies it to an economy with a policy regime
change. Employing the actor-critic model of reinforcement learning, the agent
born in a fresh environment learns through first interacting with the
environment. This involves taking exploratory actions and observing the
corresponding stimulus signals. This interactive experience is then used to
update its subjective belief about the world. I show, through several
simulation experiments, that the agent adjusts its subjective belief facing an
increase of inflation target. Moreover, the subjective belief evolves according
to the agent's experience in the world.

    

### [[2110.02479] Exponentially Many Local Minima in Quantum Neural Networks](http://arxiv.org/abs/2110.02479)


  Quantum Neural Networks (QNNs), or the so-called variational quantum
circuits, are important quantum applications both because of their similar
promises as classical neural networks and because of the feasibility of their
implementation on near-term intermediate-size noisy quantum machines (NISQ).
However, the training task of QNNs is challenging and much less understood. We
conduct a quantitative investigation on the landscape of loss functions of QNNs
and identify a class of simple yet extremely hard QNN instances for training.
Specifically, we show for typical under-parameterized QNNs, there exists a
dataset that induces a loss function with the number of spurious local minima
depending exponentially on the number of parameters. Moreover, we show the
optimality of our construction by providing an almost matching upper bound on
such dependence. While local minima in classical neural networks are due to
non-linear activations, in quantum neural networks local minima appear as a
result of the quantum interference phenomenon. Finally, we empirically confirm
that our constructions can indeed be hard instances in practice with typical
gradient-based optimizers, which demonstrates the practical value of our
findings.

    

### [[2110.02483] Detecting and Quantifying Malicious Activity with Simulation-based Inference](http://arxiv.org/abs/2110.02483)


  We propose the use of probabilistic programming techniques to tackle the
malicious user identification problem in a recommendation algorithm.
Probabilistic programming provides numerous advantages over other techniques,
including but not limited to providing a disentangled representation of how
malicious users acted under a structured model, as well as allowing for the
quantification of damage caused by malicious users. We show experiments in
malicious user identification using a model of regular and malicious users
interacting with a simple recommendation algorithm, and provide a novel
simulation-based measure for quantifying the effects of a user or group of
users on its dynamics.

    

### [[2110.02484] Shapley variable importance clouds for interpretable machine learning](http://arxiv.org/abs/2110.02484)


  Interpretable machine learning has been focusing on explaining final models
that optimize performance. The current state-of-the-art is the Shapley additive
explanations (SHAP) that locally explains variable impact on individual
predictions, and it is recently extended for a global assessment across the
dataset. Recently, Dong and Rudin proposed to extend the investigation to
models from the same class as the final model that are "good enough", and
identified a previous overclaim of variable importance based on a single model.
However, this method does not directly integrate with existing Shapley-based
interpretations. We close this gap by proposing a Shapley variable importance
cloud that pools information across good models to avoid biased assessments in
SHAP analyses of final models, and communicate the findings via novel
visualizations. We demonstrate the additional insights gain compared to
conventional explanations and Dong and Rudin's method using criminal justice
and electronic medical records data.

    

### [[2110.02490] The Variability of Model Specification](http://arxiv.org/abs/2110.02490)


  It's regarded as an axiom that a good model is one that compromises between
bias and variance. The bias is measured in training cost, while the variance of
a (say, regression) model is measure by the cost associated with a validation
set. If reducing bias is the goal, one will strive to fetch as complex a model
as necessary, but complexity is invariably coupled with variance: greater
complexity implies greater variance. In practice, driving training cost to near
zero does not pose a fundamental problem; in fact, a sufficiently complex
decision tree is perfectly capable of driving training cost to zero; however,
the problem is often with controlling the model's variance. We investigate
various regression model frameworks, including generalized linear models, Cox
proportional hazard models, ARMA, and illustrate how misspecifying a model
affects the variance.

    

### [[2110.02491] Data-Centric AI Requires Rethinking Data Notion](http://arxiv.org/abs/2110.02491)


  The transition towards data-centric AI requires revisiting data notions from
mathematical and implementational standpoints to obtain unified data-centric
machine learning packages. Towards this end, this work proposes unifying
principles offered by categorical and cochain notions of data, and discusses
the importance of these principles in data-centric AI transition. In the
categorical notion, data is viewed as a mathematical structure that we act upon
via morphisms to preserve this structure. As for cochain notion, data can be
viewed as a function defined in a discrete domain of interest and acted upon
via operators. While these notions are almost orthogonal, they provide a
unifying definition to view data, ultimately impacting the way machine learning
packages are developed, implemented, and utilized by practitioners.

    

### [[2110.02497] Pretraining & Reinforcement Learning: Sharpening the Axe Before Cutting the Tree](http://arxiv.org/abs/2110.02497)


  Pretraining is a common technique in deep learning for increasing performance
and reducing training time, with promising experimental results in deep
reinforcement learning (RL). However, pretraining requires a relevant dataset
for training. In this work, we evaluate the effectiveness of pretraining for RL
tasks, with and without distracting backgrounds, using both large, publicly
available datasets with minimal relevance, as well as case-by-case generated
datasets labeled via self-supervision. Results suggest filters learned during
training on less relevant datasets render pretraining ineffective, while
filters learned during training on the in-distribution datasets reliably reduce
RL training time and improve performance after 80k RL training steps. We
further investigate, given a limited number of environment steps, how to
optimally divide the available steps into pretraining and RL training to
maximize RL performance. Our code is available on GitHub

    

### [[2110.02501] Sharp Learning Bounds for Contrastive Unsupervised Representation Learning](http://arxiv.org/abs/2110.02501)


  Contrastive unsupervised representation learning (CURL) encourages data
representation to make semantically similar pairs closer than randomly drawn
negative samples, which has been successful in various domains such as vision,
language, and graphs. Although recent theoretical studies have attempted to
explain its success by upper bounds of a downstream classification loss by the
contrastive loss, they are still not sharp enough to explain an experimental
fact: larger negative samples improve the classification performance. This
study establishes a downstream classification loss bound with a tight intercept
in the negative sample size. By regarding the contrastive loss as a downstream
loss estimator, our theory not only improves the existing learning bounds
substantially but also explains why downstream classification empirically
improves with larger negative samples -- because the estimation variance of the
downstream loss decays with larger negative samples. We verify that our theory
is consistent with experiments on synthetic, vision, and language datasets.

    

### [[2110.02508] Online Hyperparameter Meta-Learning with Hypergradient Distillation](http://arxiv.org/abs/2110.02508)


  Many gradient-based meta-learning methods assume a set of parameters that do
not participate in inner-optimization, which can be considered as
hyperparameters. Although such hyperparameters can be optimized using the
existing gradient-based hyperparameter optimization (HO) methods, they suffer
from the following issues. Unrolled differentiation methods do not scale well
to high-dimensional hyperparameters or horizon length, Implicit Function
Theorem (IFT) based methods are restrictive for online optimization, and short
horizon approximations suffer from short horizon bias. In this work, we propose
a novel HO method that can overcome these limitations, by approximating the
second-order term with knowledge distillation. Specifically, we parameterize a
single Jacobian-vector product (JVP) for each HO step and minimize the distance
from the true second-order term. Our method allows online optimization and also
is scalable to the hyperparameter dimension and the horizon length. We
demonstrate the effectiveness of our method on two different meta-learning
methods and three benchmark datasets.

    

### [[2110.02510] A Topological View of Rule Learning in Knowledge Graphs](http://arxiv.org/abs/2110.02510)


  Inductive relation prediction is an important learning task for knowledge
graph completion. One can use the existence of rules, namely a sequence of
relations, to predict the relation between two entities. Previous works view
rules as paths and primarily focus on the searching of paths between entities.
The space of paths is huge, and one has to sacrifice either efficiency or
accuracy. In this paper, we consider rules in knowledge graphs as cycles and
show that the space of cycles has a unique structure based on the theory of
algebraic topology. By exploring the linear structure of the cycle space, we
can improve the searching efficiency of rules. We propose to collect cycle
bases that span the space of cycles. We build a novel GNN framework on the
collected cycles to learn the representations of cycles, and to predict the
existence/non-existence of a relation. Our method achieves state-of-the-art
performance on benchmarks.

    

### [[2110.02516] Attack as the Best Defense: Nullifying Image-to-image Translation GANs via Limit-aware Adversarial Attack](http://arxiv.org/abs/2110.02516)


  With the successful creation of high-quality image-to-image (Img2Img)
translation GANs comes the non-ethical applications of DeepFake and DeepNude.
Such misuses of img2img techniques present a challenging problem for society.
In this work, we tackle the problem by introducing the Limit-Aware Self-Guiding
Gradient Sliding Attack (LaS-GSA). LaS-GSA follows the Nullifying Attack to
cancel the img2img translation process under a black-box setting. In other
words, by processing input images with the proposed LaS-GSA before publishing,
any targeted img2img GANs can be nullified, preventing the model from
maliciously manipulating the images. To improve efficiency, we introduce the
limit-aware random gradient-free estimation and the gradient sliding mechanism
to estimate the gradient that adheres to the adversarial limit, i.e., the pixel
value limitations of the adversarial example. Theoretical justifications
validate how the above techniques prevent inefficiency caused by the
adversarial limit in both the direction and the step length. Furthermore, an
effective self-guiding prior is extracted solely from the threat model and the
target image to efficiently leverage the prior information and guide the
gradient estimation process. Extensive experiments demonstrate that LaS-GSA
requires fewer queries to nullify the image translation process with higher
success rates than 4 state-of-the-art black-box methods.

    

### [[2110.02529] On the Importance of Firth Bias Reduction in Few-Shot Classification](http://arxiv.org/abs/2110.02529)


  Learning accurate classifiers for novel categories from very few examples,
known as few-shot image classification, is a challenging task in statistical
machine learning and computer vision. The performance in few-shot
classification suffers from the bias in the estimation of classifier
parameters; however, an effective underlying bias reduction technique that
could alleviate this issue in training few-shot classifiers has been
overlooked. In this work, we demonstrate the effectiveness of Firth bias
reduction in few-shot classification. Theoretically, Firth bias reduction
removes the first order term $O(N^{-1})$ from the small-sample bias of the
Maximum Likelihood Estimator. Here we show that the general Firth bias
reduction technique simplifies to encouraging uniform class assignment
probabilities for multinomial logistic classification, and almost has the same
effect in cosine classifiers. We derive the optimization objective for Firth
penalized multinomial logistic and cosine classifiers, and empirically evaluate
that it is consistently effective across the board for few-shot image
classification, regardless of (1) the feature representations from different
backbones, (2) the number of samples per class, and (3) the number of classes.
Finally, we show the robustness of Firth bias reduction, in the case of
imbalanced data distribution. Our implementation is available at
this https URL


### [[2110.02544] Learning to Iteratively Solve Routing Problems with Dual-Aspect Collaborative Transformer](http://arxiv.org/abs/2110.02544)


  Recently, Transformer has become a prevailing deep architecture for solving
vehicle routing problems (VRPs). However, it is less effective in learning
improvement models for VRP because its positional encoding (PE) method is not
suitable in representing VRP solutions. This paper presents a novel Dual-Aspect
Collaborative Transformer (DACT) to learn embeddings for the node and
positional features separately, instead of fusing them together as done in
existing ones, so as to avoid potential noises and incompatible correlations.
Moreover, the positional features are embedded through a novel cyclic
positional encoding (CPE) method to allow Transformer to effectively capture
the circularity and symmetry of VRP solutions (i.e., cyclic sequences). We
train DACT using Proximal Policy Optimization and design a curriculum learning
strategy for better sample efficiency. We apply DACT to solve the traveling
salesman problem (TSP) and capacitated vehicle routing problem (CVRP). Results
show that our DACT outperforms existing Transformer based improvement models,
and exhibits much better generalization performance across different problem
sizes on synthetic and benchmark instances, respectively.

    

### [[2110.02550] CBP: Backpropagation with constraint on weight precision using a pseudo-Lagrange multiplier method](http://arxiv.org/abs/2110.02550)


  Backward propagation of errors (backpropagation) is a method to minimize
objective functions (e.g., loss functions) of deep neural networks by
identifying optimal sets of weights and biases. Imposing constraints on weight
precision is often required to alleviate prohibitive workloads on hardware.
Despite the remarkable success of backpropagation, the algorithm itself is not
capable of considering such constraints unless additional algorithms are
applied simultaneously. To address this issue, we propose the constrained
backpropagation (CBP) algorithm based on a pseudo-Lagrange multiplier method to
obtain the optimal set of weights that satisfy a given set of constraints. The
defining characteristic of the proposed CBP algorithm is the utilization of a
Lagrangian function (loss function plus constraint function) as its objective
function. We considered various types of constraints--binary, ternary, one-bit
shift, and two-bit shift weight constraints. As a post-training method, CBP
applied to AlexNet, ResNet-18, ResNet-50, and GoogLeNet on ImageNet, which were
pre-trained using the conventional backpropagation. For all cases, the proposed
algorithm outperforms the state-of-the-art methods on ImageNet, e.g., 66.6%,
74.4%, and 64.0% top-1 accuracy for ResNet-18, ResNet-50, and GoogLeNet with
binary weights, respectively. This highlights CBP as a learning algorithm to
address diverse constraints with the minimal performance loss by employing
appropriate constraint functions.

    

### [[2110.02554] A Regularized Wasserstein Framework for Graph Kernels](http://arxiv.org/abs/2110.02554)


  We propose a learning framework for graph kernels, which is theoretically
grounded on regularizing optimal transport. This framework provides a novel
optimal transport distance metric, namely Regularized Wasserstein (RW)
discrepancy, which can preserve both features and structure of graphs via
Wasserstein distances on features and their local variations, local barycenters
and global connectivity. Two strongly convex regularization terms are
introduced to improve the learning ability. One is to relax an optimal
alignment between graphs to be a cluster-to-cluster mapping between their
locally connected vertices, thereby preserving the local clustering structure
of graphs. The other is to take into account node degree distributions in order
to better preserve the global structure of graphs. We also design an efficient
algorithm to enable a fast approximation for solving the optimization problem.
Theoretically, our framework is robust and can guarantee the convergence and
numerical stability in optimization. We have empirically validated our method
using 12 datasets against 16 state-of-the-art baselines. The experimental
results show that our method consistently outperforms all state-of-the-art
methods on all benchmark databases for both graphs with discrete attributes and
graphs with continuous attributes.

    

### [[2110.02566] Adaptive control of a mechatronic system using constrained residual reinforcement learning](http://arxiv.org/abs/2110.02566)


  We propose a simple, practical and intuitive approach to improve the
performance of a conventional controller in uncertain environments using deep
reinforcement learning while maintaining safe operation. Our approach is
motivated by the observation that conventional controllers in industrial motion
control value robustness over adaptivity to deal with different operating
conditions and are suboptimal as a consequence. Reinforcement learning on the
other hand can optimize a control signal directly from input-output data and
thus adapt to operational conditions, but lacks safety guarantees, impeding its
use in industrial environments. To realize adaptive control using reinforcement
learning in such conditions, we follow a residual learning methodology, where a
reinforcement learning algorithm learns corrective adaptations to a base
controller's output to increase optimality. We investigate how constraining the
residual agent's actions enables to leverage the base controller's robustness
to guarantee safe operation. We detail the algorithmic design and propose to
constrain the residual actions relative to the base controller to increase the
method's robustness. Building on Lyapunov stability theory, we prove stability
for a broad class of mechatronic closed-loop systems. We validate our method
experimentally on a slider-crank setup and investigate how the constraints
affect the safety during learning and optimality after convergence.

    

### [[2110.02573] T-SNE Is Not Optimized to Reveal Clusters in Data](http://arxiv.org/abs/2110.02573)


  Cluster visualization is an essential task for nonlinear dimensionality
reduction as a data analysis tool. It is often believed that Student
t-Distributed Stochastic Neighbor Embedding (t-SNE) can show clusters for well
clusterable data, with a smaller Kullback-Leibler divergence corresponding to a
better quality. There was even theoretical proof for the guarantee of this
property. However, we point out that this is not necessarily the case -- t-SNE
may leave clustering patterns hidden despite strong signals present in the
data. Extensive empirical evidence is provided to support our claim. First,
several real-world counter-examples are presented, where t-SNE fails even if
the input neighborhoods are well clusterable. Tuning hyperparameters in t-SNE
or using better optimization algorithms does not help solve this issue because
a better t-SNE learning objective can correspond to a worse cluster embedding.
Second, we check the assumptions in the clustering guarantee of t-SNE and find
they are often violated for real-world data sets.

    

### [[2110.02578] Decoupled Adaptation for Cross-Domain Object Detection](http://arxiv.org/abs/2110.02578)


  Cross-domain object detection is more challenging than object classification
since multiple objects exist in an image and the location of each object is
unknown in the unlabeled target domain. As a result, when we adapt features of
different objects to enhance the transferability of the detector, the features
of the foreground and the background are easy to be confused, which may hurt
the discriminability of the detector. Besides, previous methods focused on
category adaptation but ignored another important part for object detection,
i.e., the adaptation on bounding box regression. To this end, we propose
D-adapt, namely Decoupled Adaptation, to decouple the adversarial adaptation
and the training of the detector. Besides, we fill the blank of regression
domain adaptation in object detection by introducing a bounding box adaptor.
Experiments show that D-adapt achieves state-of-the-art results on four
cross-domain object detection tasks and yields 17% and 21% relative improvement
on benchmark datasets Clipart1k and Comic2k in particular.

    

### [[2110.02582] FADNet++: Real-Time and Accurate Disparity Estimation with Configurable Networks](http://arxiv.org/abs/2110.02582)


  Deep neural networks (DNNs) have achieved great success in the area of
computer vision. The disparity estimation problem tends to be addressed by DNNs
which achieve much better prediction accuracy than traditional hand-crafted
feature-based methods. However, the existing DNNs hardly serve both efficient
computation and rich expression capability, which makes them difficult for
deployment in real-time and high-quality applications, especially on mobile
devices. To this end, we propose an efficient, accurate, and configurable deep
network for disparity estimation named FADNet++. Leveraging several liberal
network design and training techniques, FADNet++ can boost its accuracy with a
fast model inference speed for real-time applications. Besides, it enables
users to easily configure different sizes of models for balancing accuracy and
inference efficiency. We conduct extensive experiments to demonstrate the
effectiveness of FADNet++ on both synthetic and realistic datasets among six
GPU devices varying from server to mobile platforms. Experimental results show
that FADNet++ and its variants achieve state-of-the-art prediction accuracy,
and run at a significant order of magnitude faster speed than existing 3D
models. With the constraint of running at above 15 frames per second (FPS) on a
mobile GPU, FADNet++ achieves a new state-of-the-art result for the SceneFlow
dataset.

    

### [[2110.02583] Deep Identification of Nonlinear Systems in Koopman Form](http://arxiv.org/abs/2110.02583)


  The present paper treats the identification of nonlinear dynamical systems
using Koopman-based deep state-space encoders. Through this method, the usual
drawback of needing to choose a dictionary of lifting functions a priori is
circumvented. The encoder represents the lifting function to the space where
the dynamics are linearly propagated using the Koopman operator. An
input-affine formulation is considered for the lifted model structure and we
address both full and partial state availability. The approach is implemented
using the the deepSI toolbox in Python. To lower the computational need of the
simulation error-based training, the data is split into subsections where
multi-step prediction errors are calculated independently. This formulation
allows for efficient batch optimization of the network parameters and, at the
same time, excellent long term prediction capabilities of the obtained models.
The performance of the approach is illustrated by nonlinear benchmark examples.

    

### [[2110.02584] EdiTTS: Score-based Editing for Controllable Text-to-Speech](http://arxiv.org/abs/2110.02584)


  We present EdiTTS, an off-the-shelf speech editing methodology based on
score-based generative modeling for text-to-speech synthesis. EdiTTS allows for
targeted, granular editing of audio, both in terms of content and pitch,
without the need for any additional training, task-specific optimization, or
architectural modifications to the score-based model backbone. Specifically, we
apply coarse yet deliberate perturbations in the Gaussian prior space to induce
desired behavior from the diffusion model, while applying masks and softening
kernels to ensure that iterative edits are applied only to the target region.
Listening tests demonstrate that EdiTTS is capable of reliably generating
natural-sounding audio that satisfies user-imposed requirements.

    

### [[2110.02585] Simplicial Convolutional Neural Networks](http://arxiv.org/abs/2110.02585)


  Graphs can model networked data by representing them as nodes and their
pairwise relationships as edges. Recently, signal processing and neural
networks have been extended to process and learn from data on graphs, with
achievements in tasks like graph signal reconstruction, graph or node
classifications, and link prediction. However, these methods are only suitable
for data defined on the nodes of a graph. In this paper, we propose a
simplicial convolutional neural network (SCNN) architecture to learn from data
defined on simplices, e.g., nodes, edges, triangles, etc. We study the SCNN
permutation and orientation equivariance, complexity, and spectral analysis.
Finally, we test the SCNN performance for imputing citations on a coauthorship
complex.

    

### [[2110.02609] Deep Classifiers with Label Noise Modeling and Distance Awareness](http://arxiv.org/abs/2110.02609)


  Uncertainty estimation in deep learning has recently emerged as a crucial
area of interest to advance reliability and robustness in safety-critical
applications. While there have been many proposed methods that either focus on
distance-aware model uncertainties for out-of-distribution detection or on
input-dependent label uncertainties for in-distribution calibration, both of
these types of uncertainty are often necessary. In this work, we propose the
HetSNGP method for jointly modeling the model and data uncertainty. We show
that our proposed model affords a favorable combination between these two
complementary types of uncertainty and thus outperforms the baseline methods on
some challenging out-of-distribution datasets, including CIFAR-100C,
Imagenet-C, and Imagenet-A. Moreover, we propose HetSNGP Ensemble, an ensembled
version of our method which adds an additional type of uncertainty and also
outperforms other ensemble baselines.

    

### [[2110.02619] Focus on the Common Good: Group Distributional Robustness Follows](http://arxiv.org/abs/2110.02619)


  We consider the problem of training a classification model with group
annotated training data. Recent work has established that, if there is
distribution shift across different groups, models trained using the standard
empirical risk minimization (ERM) objective suffer from poor performance on
minority groups and that group distributionally robust optimization (Group-DRO)
objective is a better alternative. The starting point of this paper is the
observation that though Group-DRO performs better than ERM on minority groups
for some benchmark datasets, there are several other datasets where it performs
much worse than ERM. Inspired by ideas from the closely related problem of
domain generalization, this paper proposes a new and simple algorithm that
explicitly encourages learning of features that are shared across various
groups. The key insight behind our proposed algorithm is that while Group-DRO
focuses on groups with worst regularized loss, focusing instead, on groups that
enable better performance even on other groups, could lead to learning of
shared/common features, thereby enhancing minority performance beyond what is
achieved by Group-DRO. Empirically, we show that our proposed algorithm matches
or achieves better performance compared to strong contemporary baselines
including ERM and Group-DRO on standard benchmarks on both minority groups and
across all groups. Theoretically, we show that the proposed algorithm is a
descent method and finds first order stationary points of smooth nonconvex
functions.

    

### [[2110.02627] MovingFashion: a Benchmark for the Video-to-Shop Challenge](http://arxiv.org/abs/2110.02627)


  Retrieving clothes which are worn in social media videos (Instagram, TikTok)
is the latest frontier of e-fashion, referred to as "video-to-shop" in the
computer vision literature. In this paper we present MovingFashion, the first
publicly available dataset to cope with this challenge. MovingFashion is
composed of 14855 social videos, each one of them associated to e-commerce
"shop" images where the corresponding clothing items are clearly portrayed. In
addition, we present a network for retrieving the shop images in this scenario,
dubbed SEAM Match-RCNN. The model is trained by image-to-video domain
adaptation, allowing to use video sequences where only their association with a
shop image is given, eliminating the need of millions of annotated bounding
boxes. SEAM Match-RCNN builds an embedding, where an attention-based weighted
sum of few frames (10) of a social video is enough to individuate the correct
product within the first 5 retrieved items in a 14K+ shop element gallery with
an accuracy of 80%. This provides the best performance on MovingFashion,
comparing exhaustively against the related state-of-the-art approaches and
alternative baselines.

    

### [[2110.02628] Characterizing Learning Dynamics of Deep Neural Networks via Complex Networks](http://arxiv.org/abs/2110.02628)


  In this paper, we interpret Deep Neural Networks with Complex Network Theory.
Complex Network Theory (CNT) represents Deep Neural Networks (DNNs) as directed
weighted graphs to study them as dynamical systems. We efficiently adapt CNT
measures to examine the evolution of the learning process of DNNs with
different initializations and architectures: we introduce metrics for
nodes/neurons and layers, namely Nodes Strength and Layers Fluctuation. Our
framework distills trends in the learning dynamics and separates low from high
accurate networks. We characterize populations of neural networks (ensemble
analysis) and single instances (individual analysis). We tackle standard
problems of image recognition, for which we show that specific learning
dynamics are indistinguishable when analysed through the solely Link-Weights
analysis. Further, Nodes Strength and Layers Fluctuations make unprecedented
behaviours emerge: accurate networks, when compared to under-trained models,
show substantially divergent distributions with the greater extremity of
deviations. On top of this study, we provide an efficient implementation of the
CNT metrics for both Convolutional and Fully Connected Networks, to fasten the
research in this direction.

    

### [[2110.02629] Deep Reinforcement Learning for Solving the Heterogeneous Capacitated Vehicle Routing Problem](http://arxiv.org/abs/2110.02629)


  Existing deep reinforcement learning (DRL) based methods for solving the
capacitated vehicle routing problem (CVRP) intrinsically cope with homogeneous
vehicle fleet, in which the fleet is assumed as repetitions of a single
vehicle. Hence, their key to construct a solution solely lies in the selection
of the next node (customer) to visit excluding the selection of vehicle.
However, vehicles in real-world scenarios are likely to be heterogeneous with
different characteristics that affect their capacity (or travel speed),
rendering existing DRL methods less effective. In this paper, we tackle
heterogeneous CVRP (HCVRP), where vehicles are mainly characterized by
different capacities. We consider both min-max and min-sum objectives for
HCVRP, which aim to minimize the longest or total travel time of the vehicle(s)
in the fleet. To solve those problems, we propose a DRL method based on the
attention mechanism with a vehicle selection decoder accounting for the
heterogeneous fleet constraint and a node selection decoder accounting for the
route construction, which learns to construct a solution by automatically
selecting both a vehicle and a node for this vehicle at each step. Experimental
results based on randomly generated instances show that, with desirable
generalization to various problem sizes, our method outperforms the
state-of-the-art DRL method and most of the conventional heuristics, and also
delivers competitive performance against the state-of-the-art heuristic method,
i.e., SISR. Additionally, the results of extended experiments demonstrate that
our method is also able to solve CVRPLib instances with satisfactory
performance.

    

### [[2110.02631] Inference Attacks Against Graph Neural Networks](http://arxiv.org/abs/2110.02631)


  Graph is an important data representation ubiquitously existing in the real
world. However, analyzing the graph data is computationally difficult due to
its non-Euclidean nature. Graph embedding is a powerful tool to solve the graph
analytics problem by transforming the graph data into low-dimensional vectors.
These vectors could also be shared with third parties to gain additional
insights of what is behind the data. While sharing graph embedding is
intriguing, the associated privacy risks are unexplored. In this paper, we
systematically investigate the information leakage of the graph embedding by
mounting three inference attacks. First, we can successfully infer basic graph
properties, such as the number of nodes, the number of edges, and graph
density, of the target graph with up to 0.89 accuracy. Second, given a subgraph
of interest and the graph embedding, we can determine with high confidence that
whether the subgraph is contained in the target graph. For instance, we achieve
0.98 attack AUC on the DD dataset. Third, we propose a novel graph
reconstruction attack that can reconstruct a graph that has similar graph
structural statistics to the target graph. We further propose an effective
defense mechanism based on graph embedding perturbation to mitigate the
inference attacks without noticeable performance degradation for graph
classification tasks. Our code is available at
this https URL.

    

### [[2110.02634] Heterogeneous Attentions for Solving Pickup and Delivery Problem via Deep Reinforcement Learning](http://arxiv.org/abs/2110.02634)


  Recently, there is an emerging trend to apply deep reinforcement learning to
solve the vehicle routing problem (VRP), where a learnt policy governs the
selection of next node for visiting. However, existing methods could not handle
well the pairing and precedence relationships in the pickup and delivery
problem (PDP), which is a representative variant of VRP. To address this
challenging issue, we leverage a novel neural network integrated with a
heterogeneous attention mechanism to empower the policy in deep reinforcement
learning to automatically select the nodes. In particular, the heterogeneous
attention mechanism specifically prescribes attentions for each role of the
nodes while taking into account the precedence constraint, i.e., the pickup
node must precede the pairing delivery node. Further integrated with a masking
scheme, the learnt policy is expected to find higher-quality solutions for
solving PDP. Extensive experimental results show that our method outperforms
the state-of-the-art heuristic and deep learning model, respectively, and
generalizes well to different distributions and problem sizes.

    

### [[2110.02636] Learning Sparse Masks for Diffusion-based Image Inpainting](http://arxiv.org/abs/2110.02636)


  Diffusion-based inpainting is a powerful tool for the reconstruction of
images from sparse data. Its quality strongly depends on the choice of known
data. Optimising their spatial location -- the inpainting mask -- is
challenging. A commonly used tool for this task are stochastic optimisation
strategies. However, they are slow as they compute multiple inpainting results.
We provide a remedy in terms of a learned mask generation model. By emulating
the complete inpainting pipeline with two networks for mask generation and
neural surrogate inpainting, we obtain a model for highly efficient adaptive
mask generation. Experiments indicate that our model can achieve competitive
quality with an acceleration by as much as four orders of magnitude. Our
findings serve as a basis for making diffusion-based inpainting more attractive
for various applications such as image compression, where fast encoding is
highly desirable.

    

### [[2110.02639] On The Transferability of Deep-Q Networks](http://arxiv.org/abs/2110.02639)


  Transfer Learning (TL) is an efficient machine learning paradigm that allows
overcoming some of the hurdles that characterize the successful training of
deep neural networks, ranging from long training times to the needs of large
datasets. While exploiting TL is a well established and successful training
practice in Supervised Learning (SL), its applicability in Deep Reinforcement
Learning (DRL) is rarer. In this paper, we study the level of transferability
of three different variants of Deep-Q Networks on popular DRL benchmarks as
well as on a set of novel, carefully designed control tasks. Our results show
that transferring neural networks in a DRL context can be particularly
challenging and is a process which in most cases results in negative transfer.
In the attempt of understanding why Deep-Q Networks transfer so poorly, we gain
novel insights into the training dynamics that characterizes this family of
algorithms.

    

### [[2110.02642] Anomaly Transformer: Time Series Anomaly Detection with Association Discrepancy](http://arxiv.org/abs/2110.02642)


  Unsupervisedly detecting anomaly points in time series is challenging, which
requires the model to learn informative representations and derive a
distinguishable criterion. Prior methods mainly detect anomalies based on the
recurrent network representation of each time point. However, the point-wise
representation is less informative for complex temporal patterns and can be
dominated by normal patterns, making rare anomalies less distinguishable. We
find that in each time series, each time point can also be described by its
associations with all time points, presenting as a point-wise distribution that
is more expressive for temporal modeling. We further observe that due to the
rarity of anomalies, it is harder for anomalies to build strong associations
with the whole series and their associations shall mainly concentrate on the
adjacent time points. This observation implies an inherently distinguishable
criterion between normal and abnormal points, which we highlight as the
\emph{Association Discrepancy}. Technically we propose the \emph{Anomaly
Transformer} with an \emph{Anomaly-Attention} mechanism to compute the
association discrepancy. A minimax strategy is devised to amplify the
normal-abnormal distinguishability of the association discrepancy. Anomaly
Transformer achieves state-of-the-art performance on six unsupervised time
series anomaly detection benchmarks for three applications: service monitoring,
space \& earth exploration, and water treatment.

    

### [[2110.02661] PlumeCityNet: Multi-Resolution Air Quality Forecasting](http://arxiv.org/abs/2110.02661)


  This paper presents an engine able to forecast jointly the concentrations of
the main pollutants harming people's health: nitrogen dioxide (NO2), ozone (O3)
and particulate matter (PM2.5 and PM10, which are respectively the particles
whose diameters are below 2.5um and 10um respectively). The engine is fed with
air quality monitoring stations' measurements, weather forecasts, physical
models' outputs and traffic estimates to produce forecasts up to 24 hours. The
forecasts are produced with several spatial resolutions, from a few dozens of
meters to dozens of kilometers, fitting several use-cases needing air quality
data.
We introduce the Scale-Unit block, which enables to integrate seamlessly all
available inputs at a given resolution to return forecasts at the same
resolution. Then, the engine is based on a U-Net architecture built with
several of those blocks, giving it the ability to process inputs and to output
predictions at different resolutions.
We have implemented and evaluated the engine on the largest cities in Europe
and the United States, and it clearly outperforms other prediction methods. In
particular, the out-of-sample accuracy remains high, meaning that the engine
can be used in cities which are not included in the training dataset. A
valuable advantage of the engine is that it does not need much computing power:
the forecasts can be built in a few minutes on a standard CPU. Thus, they can
be updated very frequently, as soon as new air quality monitoring stations'
measurements are available (generally every hour), which is not the case of
physical models traditionally used for air quality forecasting.

    

### [[2110.02667] An Analysis of Attentive Walk-Aggregating Graph Neural Networks](http://arxiv.org/abs/2110.02667)


  Graph neural networks (GNNs) have been shown to possess strong representation
power, which can be exploited for downstream prediction tasks on
graph-structured data, such as molecules and social networks. They typically
learn representations by aggregating information from the K-hop neighborhood of
individual vertices or from the enumerated walks in the graph. Prior studies
have demonstrated the effectiveness of incorporating weighting schemes into
GNNs; however, this has been primarily limited to K-hop neighborhood GNNs so
far. In this paper, we aim to extensively analyze the effect of incorporating
weighting schemes into walk-aggregating GNNs. Towards this objective, we
propose a novel GNN model, called AWARE, that aggregates information about the
walks in the graph using attention schemes in a principled way to obtain an
end-to-end supervised learning method for graph-level prediction tasks. We
perform theoretical, empirical, and interpretability analyses of AWARE. Our
theoretical analysis provides the first provable guarantees for weighted GNNs,
demonstrating how the graph information is encoded in the representation, and
how the weighting schemes in AWARE affect the representation and learning
performance. We empirically demonstrate the superiority of AWARE over prior
baselines in the domains of molecular property prediction (61 tasks) and social
networks (4 tasks). Our interpretation study illustrates that AWARE can
successfully learn to capture the important substructures of the input graph.

    

### [[2110.02670] S-Extension Patch: A simple and efficient way to extend an object detection model](http://arxiv.org/abs/2110.02670)


  While building convolutional network-based systems, the toll it takes to
train the network is something that cannot be ignored. In cases where we need
to append additional capabilities to the existing model, the attention
immediately goes towards retraining techniques. In this paper, I show how to
leverage knowledge about the dataset to append the class faster while
maintaining the speed of inference as well as the accuracies; while reducing
the amount of time and data required. The method can extend a class in the
existing object detection model in 1/10th of the time compared to the other
existing methods. S-Extension patch not only offers faster training but also
speed and ease of adaptation, as it can be appended to any existing system,
given it fulfills the similarity threshold condition.

    

### [[2110.02672] Physics-Informed Neural Networks for AC Optimal Power Flow](http://arxiv.org/abs/2110.02672)


  This paper introduces, for the first time to our knowledge, physics-informed
neural networks to accurately estimate the AC-OPF result and delivers rigorous
guarantees about their performance. Power system operators, along with several
other actors, are increasingly using Optimal Power Flow (OPF) algorithms for a
wide number of applications, including planning and real-time operations.
However, in its original form, the AC Optimal Power Flow problem is often
challenging to solve as it is non-linear and non-convex. Besides the large
number of approximations and relaxations, recent efforts have also been
focusing on Machine Learning approaches, especially neural networks. So far,
however, these approaches have only partially considered the wide number of
physical models available during training. And, more importantly, they have
offered no guarantees about potential constraint violations of their output.
Our approach (i) introduces the AC power flow equations inside neural network
training and (ii) integrates methods that rigorously determine and reduce the
worst-case constraint violations across the entire input domain, while
maintaining the optimality of the prediction. We demonstrate how
physics-informed neural networks achieve higher accuracy and lower constraint
violations than standard neural networks, and show how we can further reduce
the worst-case violations for all neural networks.

    

### [[2110.02673] Scaling Up Machine Learning For Quantum Field Theory with Equivariant Continuous Flows](http://arxiv.org/abs/2110.02673)


  We propose a continuous normalizing flow for sampling from the
high-dimensional probability distributions of Quantum Field Theories in
Physics. In contrast to the deep architectures used so far for this task, our
proposal is based on a shallow design and incorporates the symmetries of the
problem. We test our model on the $\phi^4$ theory, showing that it
systematically outperforms a realNVP baseline in sampling efficiency, with the
difference between the two increasing for larger lattices. On the largest
lattice we consider, of size $32\times 32$, we improve a key metric, the
effective sample size, from 1% to 66% w.r.t. the realNVP baseline.

    

### [[2110.02690] Tuning Confidence Bound for Stochastic Bandits with Bandit Distance](http://arxiv.org/abs/2110.02690)


  We propose a novel modification of the standard upper confidence bound (UCB)
method for the stochastic multi-armed bandit (MAB) problem which tunes the
confidence bound of a given bandit based on its distance to others. Our UCB
distance tuning (UCB-DT) formulation enables improved performance as measured
by expected regret by preventing the MAB algorithm from focusing on non-optimal
bandits which is a well-known deficiency of standard UCB. "Distance tuning" of
the standard UCB is done using a proposed distance measure, which we call
bandit distance, that is parameterizable and which therefore can be optimized
to control the transition rate from exploration to exploitation based on
problem requirements. We empirically demonstrate increased performance of
UCB-DT versus many existing state-of-the-art methods which use the UCB
formulation for the MAB problem. Our contribution also includes the development
of a conceptual tool called the "Exploration Bargain Point" which gives
insights into the tradeoffs between exploration and exploitation. We argue that
the Exploration Bargain Point provides an intuitive perspective that is useful
for comparatively analyzing the performance of UCB-based methods.

    

### [[2110.02711] DiffusionCLIP: Text-guided Image Manipulation Using Diffusion Models](http://arxiv.org/abs/2110.02711)


  Diffusion models are recent generative models that have shown great success
in image generation with the state-of-the-art performance. However, only a few
researches have been conducted for image manipulation with diffusion models.
Here, we present a novel DiffusionCLIP which performs text-driven image
manipulation with diffusion models using Contrastive Language-Image
Pre-training (CLIP) loss. Our method has a performance comparable to that of
the modern GAN-based image processing methods for in and out-of-domain image
processing tasks, with the advantage of almost perfect inversion even without
additional encoders or optimization. Furthermore, our method can be easily used
for various novel applications, enabling image translation from an unseen
domain to another unseen domain or stroke-conditioned image generation in an
unseen domain, etc. Finally, we present a novel multiple attribute control with
DiffusionCLIPby combining multiple fine-tuned diffusion models.

    

### [[2110.02715] Variance function estimation in regression model via aggregation procedures](http://arxiv.org/abs/2110.02715)


  In the regression problem, we consider the problem of estimating the variance
function by the means of aggregation methods. We focus on two particular
aggregation setting: Model Selection aggregation (MS) and Convex aggregation
(C) where the goal is to select the best candidate and to build the best convex
combination of candidates respectively among a collection of candidates. In
both cases, the construction of the estimator relies on a two-step procedure
and requires two independent samples. The first step exploits the first sample
to build the candidate estimators for the variance function by the
residual-based method and then the second dataset is used to perform the
aggregation step. We show the consistency of the proposed method with respect
to the L 2error both for MS and C aggregations. We evaluate the performance of
these two methods in the heteroscedastic model and illustrate their interest in
the regression problem with reject option.

    

### [[2110.02716] Knothe-Rosenblatt transport for Unsupervised Domain Adaptation](http://arxiv.org/abs/2110.02716)


  Unsupervised domain adaptation (UDA) aims at exploiting related but different
data sources to tackle a common task in a target domain. UDA remains a central
yet challenging problem in machine learning. In this paper, we present an
approach tailored to moderate-dimensional tabular problems which are hugely
important in industrial applications and less well-served by the plethora of
methods designed for image and language data. Knothe-Rosenblatt Domain
Adaptation (KRDA) is based on the Knothe-Rosenblatt transport: we exploit
autoregressive density estimation algorithms to accurately model the different
sources by an autoregressive model using a mixture of Gaussians. KRDA then
takes advantage of the triangularity of the autoregressive models to build an
explicit mapping of the source samples into the target domain. We show that the
transfer map built by KRDA preserves each component quantiles of the
observations, hence aligning the representations of the different data sets in
the same target domain. Finally, we show that KRDA has state-of-the-art
performance on both synthetic and real world UDA problems.

    

### [[2110.02718] Generalizing Neural Networks by Reflecting Deviating Data in Production](http://arxiv.org/abs/2110.02718)


  Trained with a sufficiently large training and testing dataset, Deep Neural
Networks (DNNs) are expected to generalize. However, inputs may deviate from
the training dataset distribution in real deployments. This is a fundamental
issue with using a finite dataset. Even worse, real inputs may change over time
from the expected distribution. Taken together, these issues may lead deployed
DNNs to mis-predict in production.
In this work, we present a runtime approach that mitigates DNN
mis-predictions caused by the unexpected runtime inputs to the DNN. In contrast
to previous work that considers the structure and parameters of the DNN itself,
our approach treats the DNN as a blackbox and focuses on the inputs to the DNN.
Our approach has two steps. First, it recognizes and distinguishes "unseen"
semantically-preserving inputs. For this we use a distribution analyzer based
on the distance metric learned by a Siamese network. Second, our approach
transforms those unexpected inputs into inputs from the training set that are
identified as having similar semantics. We call this process input reflection
and formulate it as a search problem over the embedding space on the training
set. This embedding space is learned by a Quadruplet network as an auxiliary
model for the subject model to improve the generalization.
We implemented a tool called InputReflector based on the above two-step
approach and evaluated it with experiments on three DNN models trained on
CIFAR-10, MNIST, and FMINST image datasets. The results show that
InputReflector can effectively distinguish inputs that retain semantics of the
distribution (e.g., blurred, brightened, contrasted, and zoomed images) and
out-of-distribution inputs from normal inputs.

    

### [[2110.02719] The Information Geometry of Unsupervised Reinforcement Learning](http://arxiv.org/abs/2110.02719)


  How can a reinforcement learning (RL) agent prepare to solve downstream tasks
if those tasks are not known a priori? One approach is unsupervised skill
discovery, a class of algorithms that learn a set of policies without access to
a reward function. Such algorithms bear a close resemblance to representation
learning algorithms (e.g., contrastive learning) in supervised learning, in
that both are pretraining algorithms that maximize some approximation to a
mutual information objective. While prior work has shown that the set of skills
learned by such methods can accelerate downstream RL tasks, prior work offers
little analysis into whether these skill learning algorithms are optimal, or
even what notion of optimality would be appropriate to apply to them. In this
work, we show that unsupervised skill discovery algorithms based on mutual
information maximization do not learn skills that are optimal for every
possible reward function. However, we show that the distribution over skills
provides an optimal initialization minimizing regret against
adversarially-chosen reward functions, assuming a certain type of adaptation
procedure. Our analysis also provides a geometric perspective on these skill
learning methods.

    

### [[2110.02722] Graphon based Clustering and Testing of Networks: Algorithms and Theory](http://arxiv.org/abs/2110.02722)


  Network-valued data are encountered in a wide range of applications and pose
challenges in learning due to their complex structure and absence of vertex
correspondence. Typical examples of such problems include classification or
grouping of protein structures and social networks. Various methods, ranging
from graph kernels to graph neural networks, have been proposed that achieve
some success in graph classification problems. However, most methods have
limited theoretical justification, and their applicability beyond
classification remains unexplored. In this work, we propose methods for
clustering multiple graphs, without vertex correspondence, that are inspired by
the recent literature on estimating graphons -- symmetric functions
corresponding to infinite vertex limit of graphs. We propose a novel graph
distance based on sorting-and-smoothing graphon estimators. Using the proposed
graph distance, we present two clustering algorithms and show that they achieve
state-of-the-art results. We prove the statistical consistency of both
algorithms under Lipschitz assumptions on the graph degrees. We further study
the applicability of the proposed distance for graph two-sample testing
problems.

    

### [[2110.02724] ParaDiS: Parallelly Distributable Slimmable Neural Networks](http://arxiv.org/abs/2110.02724)


  When several limited power devices are available, one of the most efficient
ways to make profit of these resources, while reducing the processing latency
and communication load, is to run in parallel several neural sub-networks and
to fuse the result at the end of processing. However, such a combination of
sub-networks must be trained specifically for each particular configuration of
devices (characterized by number of devices and their capacities) which may
vary over different model deployments and even within the same deployment. In
this work we introduce parallelly distributable slimmable (ParaDiS) neural
networks that are splittable in parallel among various device configurations
without retraining. While inspired by slimmable networks allowing instant
adaptation to resources on just one device, ParaDiS networks consist of several
multi-device distributable configurations or switches that strongly share the
parameters between them. We evaluate ParaDiS framework on MobileNet v1 and
ResNet-50 architectures on ImageNet classification task. We show that ParaDiS
switches achieve similar or better accuracy than the individual models, i.e.,
distributed models of the same structure trained individually. Moreover, we
show that, as compared to universally slimmable networks that are not
distributable, the accuracy of distributable ParaDiS switches either does not
drop at all or drops by a maximum of 1 % only in the worst cases.

    

### [[2110.02732] On Margin Maximization in Linear and ReLU Networks](http://arxiv.org/abs/2110.02732)


  The implicit bias of neural networks has been extensively studied in recent
years. Lyu and Li [2019] showed that in homogeneous networks trained with the
exponential or the logistic loss, gradient flow converges to a KKT point of the
max margin problem in the parameter space. However, that leaves open the
question of whether this point will generally be an actual optimum of the max
margin problem. In this paper, we study this question in detail, for several
neural network architectures involving linear and ReLU activations. Perhaps
surprisingly, we show that in many cases, the KKT point is not even a local
optimum of the max margin problem. On the flip side, we identify multiple
settings where a local or global optimum can be guaranteed. Finally, we answer
a question posed in Lyu and Li [2019] by showing that for non-homogeneous
networks, the normalized margin may strictly decrease over time.

    

### [[2110.02736] A Deep Reinforcement Learning Framework for Contention-Based Spectrum Sharing](http://arxiv.org/abs/2110.02736)


  The increasing number of wireless devices operating in unlicensed spectrum
motivates the development of intelligent adaptive approaches to spectrum
access. We consider decentralized contention-based medium access for base
stations (BSs) operating on unlicensed shared spectrum, where each BS
autonomously decides whether or not to transmit on a given resource. The
contention decision attempts to maximize not its own downlink throughput, but
rather a network-wide objective. We formulate this problem as a decentralized
partially observable Markov decision process with a novel reward structure that
provides long term proportional fairness in terms of throughput. We then
introduce a two-stage Markov decision process in each time slot that uses
information from spectrum sensing and reception quality to make a medium access
decision. Finally, we incorporate these features into a distributed
reinforcement learning framework for contention-based spectrum access. Our
formulation provides decentralized inference, online adaptability and also
caters to partial observability of the environment through recurrent
Q-learning. Empirically, we find its maximization of the proportional fairness
metric to be competitive with a genie-aided adaptive energy detection
threshold, while being robust to channel fading and small contention windows.

    

### [[2110.02738] Blind Coherent Preamble Detection via Neural Networks](http://arxiv.org/abs/2110.02738)


  In wireless communications systems, the user equipment (UE) transmits a
random access preamble sequence to the base station (BS) to be detected and
synchronized. In standardized cellular communications systems Zadoff-Chu
sequences has been proposed due to their constant amplitude zero
autocorrelation (CAZAC) properties. The conventional approach is to use matched
filters to detect the sequence. Sequences arrived from different antennas and
time instances are summed up to reduce the noise variance. Since the knowledge
of the channel is unknown at this stage, a coherent combining scheme would be
very difficult to implement.
In this work, we leverage the system design knowledge and propose a neural
network (NN) sequence detector and timing advanced estimator. We do not replace
the whole process of preamble detection by a NN. Instead, we propose to use NN
only for \textit{blind} coherent combining of the signals in the detector to
compensate for the channel effect, thus maximize the signal to noise ratio. We
have further reduced the problem's complexity using Kronecker approximation
model for channel covariance matrices, thereby, reducing the size of required
NN. The analysis on timing advanced estimation and sequences detection has been
performed and compared with the matched filter baseline.

    

### [[2110.02739] A Step Towards Efficient Evaluation of Complex Perception Tasks in Simulation](http://arxiv.org/abs/2110.02739)


  There has been increasing interest in characterising the error behaviour of
systems which contain deep learning models before deploying them into any
safety-critical scenario. However, characterising such behaviour usually
requires large-scale testing of the model that can be extremely computationally
expensive for complex real-world tasks. For example, tasks involving compute
intensive object detectors as one of their components. In this work, we propose
an approach that enables efficient large-scale testing using simplified
low-fidelity simulators and without the computational cost of executing
expensive deep learning models. Our approach relies on designing an efficient
surrogate model corresponding to the compute intensive components of the task
under test. We demonstrate the efficacy of our methodology by evaluating the
performance of an autonomous driving task in the Carla simulator with reduced
computational expense by training efficient surrogate models for PIXOR and
CenterPoint LiDAR detectors, whilst demonstrating that the accuracy of the
simulation is maintained.

    

### [[2110.02740] Cluster Analysis on Jester Dataset: A Review](http://arxiv.org/abs/2110.02740)


  Unsupervised Machine Learning Paradigms are often the only methodology to
rely on, given a Pattern Recognition Task with no target label or annotations
being present. In such scenarios, data preparation is a crucial step to be
performed so that the Unsupervised Paradigms work with as much perfection as
possible. But, when there is no sufficient or missing data being present in
each and every instance of a dataset, data preparation becomes a challenge
itself. One such case-study is the Jester Dataset that has missing values which
are basically ratings given by Joke-Readers to a specified set of 100 jokes. In
order to perform a Cluster Analysis on such a dataset, the data preparation
step should involve filling the missing ratings with appropriate values
followed by cluster analysis using an Unsupervised ML Paradigm. In this study,
the most recent and probably the only work that involves Cluster Analysis on
the Jester Dataset of Jokes is reviewed and validated with corrections and
future scope.

    

### [[2110.02743] Towards efficient end-to-end speech recognition with biologically-inspired neural networks](http://arxiv.org/abs/2110.02743)


  Automatic speech recognition (ASR) is a capability which enables a program to
process human speech into a written form. Recent developments in artificial
intelligence (AI) have led to high-accuracy ASR systems based on deep neural
networks, such as the recurrent neural network transducer (RNN-T). However, the
core components and the performed operations of these approaches depart from
the powerful biological counterpart, i.e., the human brain. On the other hand,
the current developments in biologically-inspired ASR models, based on spiking
neural networks (SNNs), lag behind in terms of accuracy and focus primarily on
small scale applications. In this work, we revisit the incorporation of
biologically-plausible models into deep learning and we substantially enhance
their capabilities, by taking inspiration from the diverse neural and synaptic
dynamics found in the brain. In particular, we introduce neural connectivity
concepts emulating the axo-somatic and the axo-axonic synapses. Based on this,
we propose novel deep learning units with enriched neuro-synaptic dynamics and
integrate them into the RNN-T architecture. We demonstrate for the first time,
that a biologically realistic implementation of a large-scale ASR model can
yield competitive performance levels compared to the existing deep learning
models. Specifically, we show that such an implementation bears several
advantages, such as a reduced computational cost and a lower latency, which are
critical for speech recognition applications.

    

### [[2110.02750] Extensions of Karger's Algorithm: Why They Fail in Theory and How They Are Useful in Practice](http://arxiv.org/abs/2110.02750)


  The minimum graph cut and minimum $s$-$t$-cut problems are important
primitives in the modeling of combinatorial problems in computer science,
including in computer vision and machine learning. Some of the most efficient
algorithms for finding global minimum cuts are randomized algorithms based on
Karger's groundbreaking contraction algorithm. Here, we study whether Karger's
algorithm can be successfully generalized to other cut problems. We first prove
that a wide class of natural generalizations of Karger's algorithm cannot
efficiently solve the $s$-$t$-mincut or the normalized cut problem to
optimality. However, we then present a simple new algorithm for seeded
segmentation / graph-based semi-supervised learning that is closely based on
Karger's original algorithm, showing that for these problems, extensions of
Karger's algorithm can be useful. The new algorithm has linear asymptotic
runtime and yields a potential that can be interpreted as the posterior
probability of a sample belonging to a given seed / class. We clarify its
relation to the random walker algorithm / harmonic energy minimization in terms
of distributions over spanning forests. On classical problems from seeded image
segmentation and graph-based semi-supervised learning on image data, the method
performs at least as well as the random walker / harmonic energy minimization /
Gaussian processes.

    

### [[2110.02753] Semi-relaxed Gromov Wasserstein divergence with applications on graphs](http://arxiv.org/abs/2110.02753)


  Comparing structured objects such as graphs is a fundamental operation
involved in many learning tasks. To this end, the Gromov-Wasserstein (GW)
distance, based on Optimal Transport (OT), has proven to be successful in
handling the specific nature of the associated objects. More specifically,
through the nodes connectivity relations, GW operates on graphs, seen as
probability measures over specific spaces. At the core of OT is the idea of
conservation of mass, which imposes a coupling between all the nodes from the
two considered graphs. We argue in this paper that this property can be
detrimental for tasks such as graph dictionary or partition learning, and we
relax it by proposing a new semi-relaxed Gromov-Wasserstein divergence. Aside
from immediate computational benefits, we discuss its properties, and show that
it can lead to an efficient graph dictionary learning algorithm. We empirically
demonstrate its relevance for complex tasks on graphs such as partitioning,
clustering and completion.

    

### [[2110.02758] Mismatched No More: Joint Model-Policy Optimization for Model-Based RL](http://arxiv.org/abs/2110.02758)


  Many model-based reinforcement learning (RL) methods follow a similar
template: fit a model to previously observed data, and then use data from that
model for RL or planning. However, models that achieve better training
performance (e.g., lower MSE) are not necessarily better for control: an RL
agent may seek out the small fraction of states where an accurate model makes
mistakes, or it might act in ways that do not expose the errors of an
inaccurate model. As noted in prior work, there is an objective mismatch:
models are useful if they yield good policies, but they are trained to maximize
their accuracy, rather than the performance of the policies that result from
them. In this work, we propose a single objective for jointly training the
model and the policy, such that updates to either component increases a lower
bound on expected return. This joint optimization mends the objective mismatch
in prior work. Our objective is a global lower bound on expected return, and
this bound becomes tight under certain assumptions. The resulting algorithm
(MnM) is conceptually similar to a GAN: a classifier distinguishes between real
and fake transitions, the model is updated to produce transitions that look
realistic, and the policy is updated to avoid states where the model
predictions are unrealistic.

    

### [[2110.02768] Posture Recognition in the Critical Care Settings using Wearable Devices](http://arxiv.org/abs/2110.02768)


  Low physical activity levels in the intensive care units (ICU) patients have
been linked to adverse clinical outcomes. Therefore, there is a need for
continuous and objective measurement of physical activity in the ICU to
quantify the association between physical activity and patient outcomes. This
measurement would also help clinicians evaluate the efficacy of proposed
rehabilitation and physical therapy regimens in improving physical activity. In
this study, we examined the feasibility of posture recognition in an ICU
population using data from wearable sensors.

    

### [[2110.02771] DNN-assisted Particle-based Bayesian Joint Synchronization and Localization](http://arxiv.org/abs/2110.02771)


  In this work, we propose a Deep neural network-assisted Particle Filter-based
(DePF) approach to address the Mobile User (MU) joint synchronization and
localization (sync\&loc) problem in ultra dense networks. In particular, DePF
deploys an asymmetric time-stamp exchange mechanism between the MUs and the
Access Points (APs), which, traditionally, provides us with information about
the MUs' clock offset and skew. However, information about the distance between
an AP and an MU is also intrinsic to the propagation delay experienced by
exchanged time-stamps. In addition, to estimate the angle of arrival of the
received synchronization packet, DePF draws on the multiple signal
classification algorithm that is fed by Channel Impulse Response (CIR)
experienced by the sync packets. The CIR is also leveraged on to determine the
link condition, i.e. Line-of-Sight (LoS) or Non-LoS. Finally, to perform joint
sync\&loc, DePF capitalizes on particle Gaussian mixtures that allow for a
hybrid particle-based and parametric Bayesian Recursive Filtering (BRF) fusion
of the aforementioned pieces of information and thus jointly estimate the
position and clock parameters of the MUs. The simulation results verifies the
superiority of the proposed algorithm over the state-of-the-art schemes,
especially that of Extended Kalman filter- and linearized BRF-based joint
sync\&loc. In particular, only drawing on the synchronization time-stamp
exchange and CIRs, for 90$\%$of the cases, the absolute position and clock
offset estimation error remain below 1 meter and 2 nanoseconds, respectively.

    

### [[2110.02772] The Challenge of Appearance-Free Object Tracking with Feedforward Neural Networks](http://arxiv.org/abs/2110.02772)


  Nearly all models for object tracking with artificial neural networks depend
on appearance features extracted from a "backbone" architecture, designed for
object recognition. Indeed, significant progress on object tracking has been
spurred by introducing backbones that are better able to discriminate objects
by their appearance. However, extensive neurophysiology and psychophysics
evidence suggests that biological visual systems track objects using both
appearance and motion features. Here, we introduce $\textit{PathTracker}$, a
visual challenge inspired by cognitive psychology, which tests the ability of
observers to learn to track objects solely by their motion. We find that
standard 3D-convolutional deep network models struggle to solve this task when
clutter is introduced into the generated scenes, or when objects travel long
distances. This challenge reveals that tracing the path of object motion is a
blind spot of feedforward neural networks. We expect that strategies for
appearance-free object tracking from biological vision can inspire solutions
these failures of deep neural networks.

    

### [[2110.02775] NEWRON: A New Generalization of the Artificial Neuron to Enhance the Interpretability of Neural Networks](http://arxiv.org/abs/2110.02775)


  In this work, we formulate NEWRON: a generalization of the McCulloch-Pitts
neuron structure. This new framework aims to explore additional desirable
properties of artificial neurons. We show that some specializations of NEWRON
allow the network to be interpretable with no change in their expressiveness.
By just inspecting the models produced by our NEWRON-based networks, we can
understand the rules governing the task. Extensive experiments show that the
quality of the generated models is better than traditional interpretable models
and in line or better than standard neural networks.

    

### [[2110.02781] FTPipeHD: A Fault-Tolerant Pipeline-Parallel Distributed Training Framework for Heterogeneous Edge Devices](http://arxiv.org/abs/2110.02781)


  With the increased penetration and proliferation of Internet of Things (IoT)
devices, there is a growing trend towards distributing the power of deep
learning (DL) across edge devices rather than centralizing it in the cloud.
This development enables better privacy preservation, real-time responses, and
user-specific models. To deploy deep and complex models to edge devices with
limited resources, model partitioning of deep neural networks (DNN) model is
necessary, and has been widely studied. However, most of the existing
literature only considers distributing the inference model while still relying
centralized cloud infrastructure to generate this model through training. In
this paper, we propose FTPipeHD, a novel DNN training framework that trains DNN
models across distributed heterogeneous devices with fault tolerance mechanism.
To accelerate the training with time-varying computing power of each device, we
optimize the partition points dynamically according to real-time computing
capacities. We also propose a novel weight redistribution approach that
replicates the weights to both the neighboring nodes and the central node
periodically, which combats the failure of multiple devices during training
while incurring limited communication cost. Our numerical results demonstrate
that FTPipeHD is 6.8x faster in training than the state of the art method when
the computing capacity of the best device is 10x greater than the worst one. It
is also shown that the proposed method is able to accelerate the training even
with the existence of device failures.

    

### [[2110.02784] Cooperative Multi-Agent Actor-Critic for Privacy-Preserving Load Scheduling in a Residential Microgrid](http://arxiv.org/abs/2110.02784)


  As a scalable data-driven approach, multi-agent reinforcement learning (MARL)
has made remarkable advances in solving the cooperative residential load
scheduling problems. However, the common centralized training strategy of MARL
algorithms raises privacy risks for involved households. In this work, we
propose a privacy-preserving multi-agent actor-critic framework where the
decentralized actors are trained with distributed critics, such that both the
decentralized execution and the distributed training do not require the global
state information. The proposed framework can preserve the privacy of the
households while simultaneously learn the multi-agent credit assignment
mechanism implicitly. The simulation experiments demonstrate that the proposed
framework significantly outperforms the existing privacy-preserving
actor-critic framework, and can achieve comparable performance to the
state-of-the-art actor-critic framework without privacy constraints.

    

### [[2110.02787] Relative Entropy Gradient Sampler for Unnormalized Distributions](http://arxiv.org/abs/2110.02787)


  We propose a relative entropy gradient sampler (REGS) for sampling from
unnormalized distributions. REGS is a particle method that seeks a sequence of
simple nonlinear transforms iteratively pushing the initial samples from a
reference distribution into the samples from an unnormalized target
distribution. To determine the nonlinear transforms at each iteration, we
consider the Wasserstein gradient flow of relative entropy. This gradient flow
determines a path of probability distributions that interpolates the reference
distribution and the target distribution. It is characterized by an ODE system
with velocity fields depending on the density ratios of the density of evolving
particles and the unnormalized target density. To sample with REGS, we need to
estimate the density ratios and simulate the ODE system with particle
evolution. We propose a novel nonparametric approach to estimating the
logarithmic density ratio using neural networks. Extensive simulation studies
on challenging multimodal 1D and 2D mixture distributions and Bayesian logistic
regression on real datasets demonstrate that the REGS outperforms the
state-of-the-art sampling methods included in the comparison.

    

### [[2110.02792] From STL Rulebooks to Rewards](http://arxiv.org/abs/2110.02792)


  The automatic synthesis of neural-network controllers for autonomous agents
through reinforcement learning has to simultaneously optimize many, possibly
conflicting, objectives of various importance. This multi-objective
optimization task is reflected in the shape of the reward function, which is
most often the result of an ad-hoc and crafty-like activity.
In this paper we propose a principled approach to shaping rewards for
reinforcement learning from multiple objectives that are given as a
partially-ordered set of signal-temporal-logic (STL) rules. To this end, we
first equip STL with a novel quantitative semantics allowing to automatically
evaluate individual requirements. We then develop a method for systematically
combining evaluations of multiple requirements into a single reward that takes
into account the priorities defined by the partial order. We finally evaluate
our approach on several case studies, demonstrating its practical
applicability.

    

### [[2110.02796] An Unconstrained Layer-Peeled Perspective on Neural Collapse](http://arxiv.org/abs/2110.02796)


  Neural collapse is a highly symmetric geometric pattern of neural networks
that emerges during the terminal phase of training, with profound implications
on the generalization performance and robustness of the trained networks. To
understand how the last-layer features and classifiers exhibit this recently
discovered implicit bias, in this paper, we introduce a surrogate model called
the unconstrained layer-peeled model (ULPM). We prove that gradient flow on
this model converges to critical points of a minimum-norm separation problem
exhibiting neural collapse in its global minimizer. Moreover, we show that the
ULPM with the cross-entropy loss has a benign global landscape for its loss
function, which allows us to prove that all the critical points are strict
saddle points except the global minimizers that exhibit the neural collapse
phenomenon. Empirically, we show that our results also hold during the training
of neural networks in real-world tasks when explicit regularization or weight
decay is not used.

    

### [[2110.02797] Adversarial Robustness Comparison of Vision Transformer and MLP-Mixer to CNNs](http://arxiv.org/abs/2110.02797)


  Convolutional Neural Networks (CNNs) have become the de facto gold standard
in computer vision applications in the past years. Recently, however, new model
architectures have been proposed challenging the status quo. The Vision
Transformer (ViT) relies solely on attention modules, while the MLP-Mixer
architecture substitutes the self-attention modules with Multi-Layer
Perceptrons (MLPs). Despite their great success, CNNs have been widely known to
be vulnerable to adversarial attacks, causing serious concerns for
security-sensitive applications. Thus, it is critical for the community to know
whether the newly proposed ViT and MLP-Mixer are also vulnerable to adversarial
attacks. To this end, we empirically evaluate their adversarial robustness
under several adversarial attack setups and benchmark them against the widely
used CNNs. Overall, we find that the two architectures, especially ViT, are
more robust than their CNN models. Using a toy example, we also provide
empirical evidence that the lower adversarial robustness of CNNs can be
partially attributed to their shift-invariant property. Our frequency analysis
suggests that the most robust ViT architectures tend to rely more on
low-frequency features compared with CNNs. Additionally, we have an intriguing
finding that MLP-Mixer is extremely vulnerable to universal adversarial
perturbations.

    

### [[2110.02827] Colmena: Scalable Machine-Learning-Based Steering of Ensemble Simulations for High Performance Computing](http://arxiv.org/abs/2110.02827)


  Scientific applications that involve simulation ensembles can be accelerated
greatly by using experiment design methods to select the best simulations to
perform. Methods that use machine learning (ML) to create proxy models of
simulations show particular promise for guiding ensembles but are challenging
to deploy because of the need to coordinate dynamic mixes of simulation and
learning tasks. We present Colmena, an open-source Python framework that allows
users to steer campaigns by providing just the implementations of individual
tasks plus the logic used to choose which tasks to execute when. Colmena
handles task dispatch, results collation, ML model invocation, and ML model
(re)training, using Parsl to execute tasks on HPC systems. We describe the
design of Colmena and illustrate its capabilities by applying it to electrolyte
design, where it both scales to 65536 CPUs and accelerates the discovery rate
for high-performance molecules by a factor of 100 over unguided searches.

    

### [[2110.02839] Census-Independent Population Estimation using Representation Learning](http://arxiv.org/abs/2110.02839)


  Knowledge of population distribution is critical for building infrastructure,
distributing resources, and monitoring the progress of sustainable development
goals. Although censuses can provide this information, they are typically
conducted every ten years with some countries having forgone the process for
several decades. Population can change in the intercensal period due to rapid
migration, development, urbanisation, natural disasters, and conflicts.
Census-independent population estimation approaches using alternative data
sources, such as satellite imagery, have shown promise in providing frequent
and reliable population estimates locally. Existing approaches, however,
require significant human supervision, for example annotating buildings and
accessing various public datasets, and therefore, are not easily reproducible.
We explore recent representation learning approaches, and assess the
transferability of representations to population estimation in Mozambique.
Using representation learning reduces required human supervision, since
features are extracted automatically, making the process of population
estimation more sustainable and likely to be transferable to other regions or
countries. We compare the resulting population estimates to existing population
products from GRID3, Facebook (HRSL) and WorldPop. We observe that our approach
matches the most accurate of these maps, and is interpretable in the sense that
it recognises built-up areas to be an informative indicator of population.

    

### [[2110.02843] Improving Generalization of Deep Reinforcement Learning-based TSP Solvers](http://arxiv.org/abs/2110.02843)


  Recent work applying deep reinforcement learning (DRL) to solve traveling
salesman problems (TSP) has shown that DRL-based solvers can be fast and
competitive with TSP heuristics for small instances, but do not generalize well
to larger instances. In this work, we propose a novel approach named MAGIC that
includes a deep learning architecture and a DRL training method. Our
architecture, which integrates a multilayer perceptron, a graph neural network,
and an attention model, defines a stochastic policy that sequentially generates
a TSP solution. Our training method includes several innovations: (1) we
interleave DRL policy gradient updates with local search (using a new local
search technique), (2) we use a novel simple baseline, and (3) we apply
curriculum learning. Finally, we empirically demonstrate that MAGIC is superior
to other DRL-based methods on random TSP instances, both in terms of
performance and generalizability. Moreover, our method compares favorably
against TSP heuristics and other state-of-the-art approach in terms of
performance and computational time.

    

### [[2110.02846] Seed Classification using Synthetic Image Datasets Generated from Low-Altitude UAV Imagery](http://arxiv.org/abs/2110.02846)


  Plant breeding programs extensively monitor the evolution of seed kernels for
seed certification, wherein lies the need to appropriately label the seed
kernels by type and quality. However, the breeding environments are large where
the monitoring of seed kernels can be challenging due to the minuscule size of
seed kernels. The use of unmanned aerial vehicles aids in seed monitoring and
labeling since they can capture images at low altitudes whilst being able to
access even the remotest areas in the environment. A key bottleneck in the
labeling of seeds using UAV imagery is drone altitude i.e. the classification
accuracy decreases as the altitude increases due to lower image detail.
Convolutional neural networks are a great tool for multi-class image
classification when there is a training dataset that closely represents the
different scenarios that the network might encounter during evaluation. The
article addresses the challenge of training data creation using Domain
Randomization wherein synthetic image datasets are generated from a meager
sample of seeds captured by the bottom camera of an autonomously driven Parrot
AR Drone 2.0. Besides, the article proposes a seed classification framework as
a proof-of-concept using the convolutional neural networks of Microsoft's
ResNet-100, Oxford's VGG-16, and VGG-19. To enhance the classification accuracy
of the framework, an ensemble model is developed resulting in an overall
accuracy of 94.6%.

    

### [[2110.02858] Distribution Preserving Multiple Hypotheses Prediction for Uncertainty Modeling](http://arxiv.org/abs/2110.02858)


  Many supervised machine learning tasks, such as future state prediction in
dynamical systems, require precise modeling of a forecast's uncertainty. The
Multiple Hypotheses Prediction (MHP) approach addresses this problem by
providing several hypotheses that represent possible outcomes. Unfortunately,
with the common $l_2$ loss function, these hypotheses do not preserve the data
distribution's characteristics. We propose an alternative loss for distribution
preserving MHP and review relevant theorems supporting our claims. Furthermore,
we empirically show that our approach yields more representative hypotheses on
a synthetic and a real-world motion prediction data set. The outputs of the
proposed method can directly be used in sampling-based Monte-Carlo methods.

    

### [[2110.02861] 8-bit Optimizers via Block-wise Quantization](http://arxiv.org/abs/2110.02861)


  Stateful optimizers maintain gradient statistics over time, e.g., the
exponentially smoothed sum (SGD with momentum) or squared sum (Adam) of past
gradient values. This state can be used to accelerate optimization compared to
plain stochastic gradient descent but uses memory that might otherwise be
allocated to model parameters, thereby limiting the maximum size of models
trained in practice. In this paper, we develop the first optimizers that use
8-bit statistics while maintaining the performance levels of using 32-bit
optimizer states. To overcome the resulting computational, quantization, and
stability challenges, we develop block-wise dynamic quantization. Block-wise
quantization divides input tensors into smaller blocks that are independently
quantized. Each block is processed in parallel across cores, yielding faster
optimization and high precision quantization. To maintain stability and
performance, we combine block-wise quantization with two additional changes:
(1) dynamic quantization, a form of non-linear optimization that is precise for
both large and small magnitude values, and (2) a stable embedding layer to
reduce gradient variance that comes from the highly non-uniform distribution of
input tokens in language models. As a result, our 8-bit optimizers maintain
32-bit performance with a small fraction of the memory footprint on a range of
tasks, including 1.5B parameter language modeling, GLUE finetuning, ImageNet
classification, WMT'14 machine translation, MoCo v2 contrastive ImageNet
pretraining+finetuning, and RoBERTa pretraining, without changes to the
original optimizer hyperparameters. We open-source our 8-bit optimizers as a
drop-in replacement that only requires a two-line code change.

    

### [[2110.02863] Exploring the Common Principal Subspace of Deep Features in Neural Networks](http://arxiv.org/abs/2110.02863)


  We find that different Deep Neural Networks (DNNs) trained with the same
dataset share a common principal subspace in latent spaces, no matter in which
architectures (e.g., Convolutional Neural Networks (CNNs), Multi-Layer
Preceptors (MLPs) and Autoencoders (AEs)) the DNNs were built or even whether
labels have been used in training (e.g., supervised, unsupervised, and
self-supervised learning). Specifically, we design a new metric
$\mathcal{P}$-vector to represent the principal subspace of deep features
learned in a DNN, and propose to measure angles between the principal subspaces
using $\mathcal{P}$-vectors. Small angles (with cosine close to $1.0$) have
been found in the comparisons between any two DNNs trained with different
algorithms/architectures. Furthermore, during the training procedure from
random scratch, the angle decrease from a larger one ($70^\circ-80^\circ$
usually) to the small one, which coincides the progress of feature space
learning from scratch to convergence. Then, we carry out case studies to
measure the angle between the $\mathcal{P}$-vector and the principal subspace
of training dataset, and connect such angle with generalization performance.
Extensive experiments with practically-used Multi-Layer Perceptron (MLPs), AEs
and CNNs for classification, image reconstruction, and self-supervised learning
tasks on MNIST, CIFAR-10 and CIFAR-100 datasets have been done to support our
claims with solid evidences.
Interpretability of Deep Learning, Feature Learning, and Subspaces of Deep
Features

    

### [[2110.02865] Spike-inspired Rank Coding for Fast and Accurate Recurrent Neural Networks](http://arxiv.org/abs/2110.02865)


  Biological spiking neural networks (SNNs) can temporally encode information
in their outputs, e.g. in the rank order in which neurons fire, whereas
artificial neural networks (ANNs) conventionally do not. As a result, models of
SNNs for neuromorphic computing are regarded as potentially more rapid and
efficient than ANNs when dealing with temporal input. On the other hand, ANNs
are simpler to train, and usually achieve superior performance. Here we show
that temporal coding such as rank coding (RC) inspired by SNNs can also be
applied to conventional ANNs such as LSTMs, and leads to computational savings
and speedups. In our RC for ANNs, we apply backpropagation through time using
the standard real-valued activations, but only from a strategically early time
step of each sequential input example, decided by a threshold-crossing event.
Learning then incorporates naturally also _when_ to produce an output, without
other changes to the model or the algorithm. Both the forward and the backward
training pass can be significantly shortened by skipping the remaining input
sequence after that first event. RC-training also significantly reduces
time-to-insight during inference, with a minimal decrease in accuracy. The
desired speed-accuracy trade-off is tunable by varying the threshold or a
regularization parameter that rewards output entropy. We demonstrate these in
two toy problems of sequence classification, and in a temporally-encoded MNIST
dataset where our RC model achieves 99.19% accuracy after the first input
time-step, outperforming the state of the art in temporal coding with SNNs, as
well as in spoken-word classification of Google Speech Commands, outperforming
non-RC-trained early inference with LSTMs.

    

### [[2110.02879] Nested Policy Reinforcement Learning](http://arxiv.org/abs/2110.02879)


  Off-policy reinforcement learning (RL) has proven to be a powerful framework
for guiding agents' actions in environments with stochastic rewards and unknown
or noisy state dynamics. In many real-world settings, these agents must operate
in multiple environments, each with slightly different dynamics. For example,
we may be interested in developing policies to guide medical treatment for
patients with and without a given disease, or policies to navigate curriculum
design for students with and without a learning disability. Here, we introduce
nested policy fitted Q-iteration (NFQI), an RL framework that finds optimal
policies in environments that exhibit such a structure. Our approach develops a
nested $Q$-value function that takes advantage of the shared structure between
two groups of observations from two separate environments while allowing their
policies to be distinct from one another. We find that NFQI yields policies
that rely on relevant features and perform at least as well as a policy that
does not consider group structure. We demonstrate NFQI's performance using an
OpenAI Gym environment and a clinical decision making RL task. Our results
suggest that NFQI can develop policies that are better suited to many
real-world clinical environments.

    

### [[2110.02880] Space-Time Graph Neural Networks](http://arxiv.org/abs/2110.02880)


  We introduce space-time graph neural network (ST-GNN), a novel GNN
architecture, tailored to jointly process the underlying space-time topology of
time-varying network data. The cornerstone of our proposed architecture is the
composition of time and graph convolutional filters followed by pointwise
nonlinear activation functions. We introduce a generic definition of
convolution operators that mimic the diffusion process of signals over its
underlying support. On top of this definition, we propose space-time graph
convolutions that are built upon a composition of time and graph shift
operators. We prove that ST-GNNs with multivariate integral Lipschitz filters
are stable to small perturbations in the underlying graphs as well as small
perturbations in the time domain caused by time warping. Our analysis shows
that small variations in the network topology and time evolution of a system
does not significantly affect the performance of ST-GNNs. Numerical experiments
with decentralized control systems showcase the effectiveness and stability of
the proposed ST-GNNs.

    

### [[2110.02884] Human-in-the-Loop Refinement of Word Embeddings](http://arxiv.org/abs/2110.02884)


  Word embeddings are a fixed, distributional representation of the context of
words in a corpus learned from word co-occurrences. Despite their proven
utility in machine learning tasks, word embedding models may capture uneven
semantic and syntactic representations, and can inadvertently reflect various
kinds of bias present within corpora upon which they were trained. It has been
demonstrated that post-processing of word embeddings to apply information found
in lexical dictionaries can improve the semantic associations, thus improving
their quality. Building on this idea, we propose a system that incorporates an
adaptation of word embedding post-processing, which we call "interactive
refitting", to address some of the most daunting qualitative problems found in
word embeddings. Our approach allows a human to identify and address potential
quality issues with word embeddings interactively. This has the advantage of
negating the question of who decides what constitutes bias or what other
quality issues may affect downstream tasks. It allows each organization or
entity to address concerns they may have at a fine grained level and to do so
in an iterative and interactive fashion. It also allows for better insight into
what effect word embeddings, and refinements to word embeddings, have on
machine learning pipelines.

    

### [[2110.02885] Bayesian neural network unit priors and generalized Weibull-tail property](http://arxiv.org/abs/2110.02885)


  The connection between Bayesian neural networks and Gaussian processes gained
a lot of attention in the last few years. Hidden units are proven to follow a
Gaussian process limit when the layer width tends to infinity. Recent work has
suggested that finite Bayesian neural networks may outperform their infinite
counterparts because they adapt their internal representations flexibly. To
establish solid ground for future research on finite-width neural networks, our
goal is to study the prior induced on hidden units. Our main result is an
accurate description of hidden units tails which shows that unit priors become
heavier-tailed going deeper, thanks to the introduced notion of generalized
Weibull-tail. This finding sheds light on the behavior of hidden units of
finite Bayesian neural networks.

    

### [[2110.02891] Style Equalization: Unsupervised Learning of Controllable Generative Sequence Models](http://arxiv.org/abs/2110.02891)


  Controllable generative sequence models with the capability to extract and
replicate the style of specific examples enable many applications, including
narrating audiobooks in different voices, auto-completing and auto-correcting
written handwriting, and generating missing training samples for downstream
recognition tasks. However, typical training algorithms for these controllable
sequence generative models suffer from the training-inference mismatch, where
the same sample is used as content and style input during training but
different samples are given during inference. In this paper, we tackle the
training-inference mismatch encountered during unsupervised learning of
controllable generative sequence models. By introducing a style transformation
module that we call style equalization, we enable training using different
content and style samples and thereby mitigate the training-inference mismatch.
To demonstrate its generality, we applied style equalization to text-to-speech
and text-to-handwriting synthesis on three datasets. Our models achieve
state-of-the-art style replication with a similar mean style opinion score as
the real data. Moreover, the proposed method enables style interpolation
between sequences and generates novel styles.

    

### [[2110.02892] Probabilistic Metamodels for an Efficient Characterization of Complex Driving Scenarios](http://arxiv.org/abs/2110.02892)


  To systematically validate the safe behavior of automated vehicles (AV), the
aim of scenario-based testing is to cluster the infinite situations an AV might
encounter into a finite set of functional scenarios. Every functional scenario,
however, can still manifest itself in a vast amount of variations. Thus,
metamodels are often used to perform analyses or to select specific variations
for examination. However, despite the safety criticalness of AV testing,
metamodels are usually seen as a part of an overall approach, and their
predictions are not further examined. In this paper, we analyze the predictive
performance of Gaussian processes (GP), deep Gaussian processes, extra-trees
(ET), and Bayesian neural networks (BNN), considering four scenarios with 5 to
20 inputs. Building on this, we introduce and evaluate an iterative approach to
efficiently select test cases. Our results show that regarding predictive
performance, the appropriate selection of test cases is more important than the
choice of metamodels. While their great flexibility allows BNNs to benefit from
large amounts of data and to model even the most complex scenarios, less
flexible models like GPs can convince with higher reliability. This implies
that relevant test cases have to be explored using scalable virtual
environments and flexible models so that more realistic test environments and
more trustworthy models can be used for targeted testing and validation.

    

### [[2110.02896] Predicting the Popularity of Games on Steam](http://arxiv.org/abs/2110.02896)


  The video game industry has seen rapid growth over the last decade. Thousands
of video games are released and played by millions of people every year,
creating a large community of players. Steam is a leading gaming platform and
social networking site, which allows its users to purchase and store games. A
by-product of Steam is a large database of information about games, players,
and gaming behavior. In this paper, we take recent video games released on
Steam and aim to discover the relation between game popularity and a game's
features that can be acquired through Steam. We approach this task by
predicting the popularity of Steam games in the early stages after their
release and we use a Bayesian approach to understand the influence of a game's
price, size, supported languages, release date, and genres on its player count.
We implement several models and discover that a genre-based hierarchical
approach achieves the best performance. We further analyze the model and
interpret its coefficients, which indicate that games released at the beginning
of the month and games of certain genres correlate with game popularity.

    

### [[2110.02905] Geometric and Physical Quantities improve E(3) Equivariant Message Passing](http://arxiv.org/abs/2110.02905)


  Including covariant information, such as position, force, velocity or spin is
important in many tasks in computational physics and chemistry. We introduce
Steerable E(3) Equivariant Graph Neural Networks (SEGNNs) that generalise
equivariant graph networks, such that node and edge attributes are not
restricted to invariant scalars, but can contain covariant information, such as
vectors or tensors. This model, composed of steerable MLPs, is able to
incorporate geometric and physical information in both the message and update
functions. Through the definition of steerable node attributes, the MLPs
provide a new class of activation functions for general use with steerable
feature fields. We discuss ours and related work through the lens of
equivariant non-linear convolutions, which further allows us to pin-point the
successful components of SEGNNs: non-linear message aggregation improves upon
classic linear (steerable) point convolutions; steerable messages improve upon
recent equivariant graph networks that send invariant messages. We demonstrate
the effectiveness of our method on several tasks in computational physics and
chemistry and provide extensive ablation studies.

    

### [[2110.02910] Equivariant Subgraph Aggregation Networks](http://arxiv.org/abs/2110.02910)


  Message-passing neural networks (MPNNs) are the leading architecture for deep
learning on graph-structured data, in large part due to their simplicity and
scalability. Unfortunately, it was shown that these architectures are limited
in their expressive power. This paper proposes a novel framework called
Equivariant Subgraph Aggregation Networks (ESAN) to address this issue. Our
main observation is that while two graphs may not be distinguishable by an
MPNN, they often contain distinguishable subgraphs. Thus, we propose to
represent each graph as a set of subgraphs derived by some predefined policy,
and to process it using a suitable equivariant architecture. We develop novel
variants of the 1-dimensional Weisfeiler-Leman (1-WL) test for graph
isomorphism, and prove lower bounds on the expressiveness of ESAN in terms of
these new WL variants. We further prove that our approach increases the
expressive power of both MPNNs and more expressive architectures. Moreover, we
provide theoretical results that describe how design choices such as the
subgraph selection policy and equivariant neural architecture affect our
architecture's expressive power. To deal with the increased computational cost,
we propose a subgraph sampling scheme, which can be viewed as a stochastic
version of our framework. A comprehensive set of experiments on real and
synthetic datasets demonstrates that our framework improves the expressive
power and overall performance of popular GNN architectures.

    

### [[2110.02911] Shifting Capsule Networks from the Cloud to the Deep Edge](http://arxiv.org/abs/2110.02911)


  Capsule networks (CapsNets) are an emerging trend in image processing. In
contrast to a convolutional neural network, CapsNets are not vulnerable to
object deformation, as the relative spatial information of the objects is
preserved across the network. However, their complexity is mainly related with
the capsule structure and the dynamic routing mechanism, which makes it almost
unreasonable to deploy a CapsNet, in its original form, in a
resource-constrained device powered by a small microcontroller (MCU). In an era
where intelligence is rapidly shifting from the cloud to the edge, this high
complexity imposes serious challenges to the adoption of CapsNets at the very
edge. To tackle this issue, we present an API for the execution of quantized
CapsNets in Cortex-M and RISC-V MCUs. Our software kernels extend the Arm
CMSIS-NN and RISC-V PULP-NN, to support capsule operations with 8-bit integers
as operands. Along with it, we propose a framework to perform post training
quantization of a CapsNet. Results show a reduction in memory footprint of
almost 75%, with a maximum accuracy loss of 1%. In terms of throughput, our
software kernels for the Arm Cortex-M are, at least, 5.70x faster than a
pre-quantized CapsNet running on an NVIDIA GTX 980 Ti graphics card. For
RISC-V, the throughout gain increases to 26.28x and 56.91x for a single- and
octa-core configuration, respectively.

    

### [[2110.02912] Generative Optimization Networks for Memory Efficient Data Generation](http://arxiv.org/abs/2110.02912)


  In standard generative deep learning models, such as autoencoders or GANs,
the size of the parameter set is proportional to the complexity of the
generated data distribution. A significant challenge is to deploy
resource-hungry deep learning models in devices with limited memory to prevent
system upgrade costs. To combat this, we propose a novel framework called
generative optimization networks (GON) that is similar to GANs, but does not
use a generator, significantly reducing its memory footprint. GONs use a single
discriminator network and run optimization in the input space to generate new
data samples, achieving an effective compromise between training time and
memory consumption. GONs are most suited for data generation problems in
limited memory settings. Here we illustrate their use for the problem of
anomaly detection in memory-constrained edge devices arising from attacks or
intrusion events. Specifically, we use a GON to calculate a
reconstruction-based anomaly score for input time-series windows. Experiments
on a Raspberry-Pi testbed with two existing and a new suite of datasets show
that our framework gives up to 32% higher detection F1 scores and 58% lower
memory consumption, with only 5% higher training overheads compared to the
state-of-the-art.

    

### [[2110.02914] Foolish Crowds Support Benign Overfitting](http://arxiv.org/abs/2110.02914)


  We prove a lower bound on the excess risk of sparse interpolating procedures
for linear regression with Gaussian data in the overparameterized regime. We
work in a setting where the covariance structure has previously been shown to
be compatible with benign overfitting with fast convergence to the Bayes risk.
We apply the general bound to obtain a lower bound for basis pursuit (the
minimum $\ell_1$-norm interpolant) that implies that its excess risk can
converge at an exponentially slower rate than OLS (the minimum $\ell_2$-norm
interpolant), even when the ground truth is sparse. Our analysis exposes the
benefit of an effect analogous to the "wisdom of the crowd", except here the
harm arising from fitting the noise is ameliorated by spreading it among many
directions - the variance reduction arises from a foolish crowd.

    

### [[2110.02915] Unrolling Particles: Unsupervised Learning of Sampling Distributions](http://arxiv.org/abs/2110.02915)


  Particle filtering is used to compute good nonlinear estimates of complex
systems. It samples trajectories from a chosen distribution and computes the
estimate as a weighted average. Easy-to-sample distributions often lead to
degenerate samples where only one trajectory carries all the weight, negatively
affecting the resulting performance of the estimate. While much research has
been done on the design of appropriate sampling distributions that would lead
to controlled degeneracy, in this paper our objective is to \emph{learn}
sampling distributions. Leveraging the framework of algorithm unrolling, we
model the sampling distribution as a multivariate normal, and we use neural
networks to learn both the mean and the covariance. We carry out unsupervised
training of the model to minimize weight degeneracy, relying only on the
observed measurements of the system. We show in simulations that the resulting
particle filter yields good estimates in a wide range of scenarios.

    

### [[2110.02919] Residual Overfit Method of Exploration](http://arxiv.org/abs/2110.02919)


  Exploration is a crucial aspect of bandit and reinforcement learning
algorithms. The uncertainty quantification necessary for exploration often
comes from either closed-form expressions based on simple models or resampling
and posterior approximations that are computationally intensive. We propose
instead an approximate exploration methodology based on fitting only two point
estimates, one tuned and one overfit. The approach, which we term the residual
overfit method of exploration (ROME), drives exploration towards actions where
the overfit model exhibits the most overfitting compared to the tuned model.
The intuition is that overfitting occurs the most at actions and contexts with
insufficient data to form accurate predictions of the reward. We justify this
intuition formally from both a frequentist and a Bayesian information theoretic
perspective. The result is a method that generalizes to a wide variety of
models and avoids the computational overhead of resampling or posterior
approximations. We compare ROME against a set of established contextual bandit
methods on three datasets and find it to be one of the best performing.

    

### [[2110.02924] No-Press Diplomacy from Scratch](http://arxiv.org/abs/2110.02924)


  Prior AI successes in complex games have largely focused on settings with at
most hundreds of actions at each decision point. In contrast, Diplomacy is a
game with more than 10^20 possible actions per turn. Previous attempts to
address games with large branching factors, such as Diplomacy, StarCraft, and
Dota, used human data to bootstrap the policy or used handcrafted reward
shaping. In this paper, we describe an algorithm for action exploration and
equilibrium approximation in games with combinatorial action spaces. This
algorithm simultaneously performs value iteration while learning a policy
proposal network. A double oracle step is used to explore additional actions to
add to the policy proposals. At each state, the target state value and policy
for the model training are computed via an equilibrium search procedure. Using
this algorithm, we train an agent, DORA, completely from scratch for a popular
two-player variant of Diplomacy and show that it achieves superhuman
performance. Additionally, we extend our methods to full-scale no-press
Diplomacy and for the first time train an agent from scratch with no human
data. We present evidence that this agent plays a strategy that is incompatible
with human-data bootstrapped agents. This presents the first strong evidence of
multiple equilibria in Diplomacy and suggests that self play alone may be
insufficient for achieving superhuman performance in Diplomacy.

    

### [[2110.02926] On the Global Convergence of Gradient Descent for multi-layer ResNets in the mean-field regime](http://arxiv.org/abs/2110.02926)


  Finding the optimal configuration of parameters in ResNet is a nonconvex
minimization problem, but first-order methods nevertheless find the global
optimum in the overparameterized regime. We study this phenomenon with
mean-field analysis, by translating the training process of ResNet to a
gradient-flow partial differential equation (PDE) and examining the convergence
properties of this limiting process. The activation function is assumed to be
$2$-homogeneous or partially $1$-homogeneous; the regularized ReLU satisfies
the latter condition. We show that if the ResNet is sufficiently large, with
depth and width depending algebraically on the accuracy and confidence levels,
first-order optimization methods can find global minimizers that fit the
training data.

    

### [[2110.02927] Data Twinning](http://arxiv.org/abs/2110.02927)


  In this work, we develop a method named Twinning, for partitioning a dataset
into statistically similar twin sets. Twinning is based on SPlit, a recently
proposed model-independent method for optimally splitting a dataset into
training and testing sets. Twinning is orders of magnitude faster than the
SPlit algorithm, which makes it applicable to Big Data problems such as data
compression. Twinning can also be used for generating multiple splits of a
given dataset to aid divide-and-conquer procedures and $k$-fold cross
validation.

    

### [[2110.02932] Machine Learning Practices Outside Big Tech: How Resource Constraints Challenge Responsible Development](http://arxiv.org/abs/2110.02932)


  Practitioners from diverse occupations and backgrounds are increasingly using
machine learning (ML) methods. Nonetheless, studies on ML Practitioners
typically draw populations from Big Tech and academia, as researchers have
easier access to these communities. Through this selection bias, past research
often excludes the broader, lesser-resourced ML community -- for example,
practitioners working at startups, at non-tech companies, and in the public
sector. These practitioners share many of the same ML development difficulties
and ethical conundrums as their Big Tech counterparts; however, their
experiences are subject to additional under-studied challenges stemming from
deploying ML with limited resources, increased existential risk, and absent
access to in-house research teams. We contribute a qualitative analysis of 17
interviews with stakeholders from organizations which are less represented in
prior studies. We uncover a number of tensions which are introduced or
exacerbated by these organizations' resource constraints -- tensions between
privacy and ubiquity, resource management and performance optimization, and
access and monopolization. Increased academic focus on these practitioners can
facilitate a more holistic understanding of ML limitations, and so is useful
for prescribing a research agenda to facilitate responsible ML development for
all.

    

### [[2110.02940] Secure Byzantine-Robust Distributed Learning via Clustering](http://arxiv.org/abs/2110.02940)


  Federated learning systems that jointly preserve Byzantine robustness and
privacy have remained an open problem. Robust aggregation, the standard defense
for Byzantine attacks, generally requires server access to individual updates
or nonlinear computation -- thus is incompatible with privacy-preserving
methods such as secure aggregation via multiparty computation. To this end, we
propose SHARE (Secure Hierarchical Robust Aggregation), a distributed learning
framework designed to cryptographically preserve client update privacy and
robustness to Byzantine adversaries simultaneously. The key idea is to
incorporate secure averaging among randomly clustered clients before filtering
malicious updates through robust aggregation. Experiments show that SHARE has
similar robustness guarantees as existing techniques while enhancing privacy.

    

### [[2110.02950] Self-Supervised Knowledge Assimilation for Expert-Layman Text Style Transfer](http://arxiv.org/abs/2110.02950)


  Expert-layman text style transfer technologies have the potential to improve
communication between members of scientific communities and the general public.
High-quality information produced by experts is often filled with difficult
jargon laypeople struggle to understand. This is a particularly notable issue
in the medical domain, where layman are often confused by medical text online.
At present, two bottlenecks interfere with the goal of building high-quality
medical expert-layman style transfer systems: a dearth of pretrained
medical-domain language models spanning both expert and layman terminologies
and a lack of parallel corpora for training the transfer task itself. To
mitigate the first issue, we propose a novel language model (LM) pretraining
task, Knowledge Base Assimilation, to synthesize pretraining data from the
edges of a graph of expert- and layman-style medical terminology terms into an
LM during self-supervised learning. To mitigate the second issue, we build a
large-scale parallel corpus in the medical expert-layman domain using a
margin-based criterion. Our experiments show that transformer-based models
pretrained on knowledge base assimilation and other well-established
pretraining tasks fine-tuning on our new parallel corpus leads to considerable
improvement against expert-layman transfer benchmarks, gaining an average
relative improvement of our human evaluation, the Overall Success Rate (OSR),
by 106%.

    

### [[2110.02951] Video Autoencoder: self-supervised disentanglement of static 3D structure and motion](http://arxiv.org/abs/2110.02951)


  A video autoencoder is proposed for learning disentan- gled representations
of 3D structure and camera pose from videos in a self-supervised manner.
Relying on temporal continuity in videos, our work assumes that the 3D scene
structure in nearby video frames remains static. Given a sequence of video
frames as input, the video autoencoder extracts a disentangled representation
of the scene includ- ing: (i) a temporally-consistent deep voxel feature to
represent the 3D structure and (ii) a 3D trajectory of camera pose for each
frame. These two representations will then be re-entangled for rendering the
input video frames. This video autoencoder can be trained directly using a
pixel reconstruction loss, without any ground truth 3D or camera pose
annotations. The disentangled representation can be applied to a range of
tasks, including novel view synthesis, camera pose estimation, and video
generation by motion following. We evaluate our method on several large- scale
natural video datasets, and show generalization results on out-of-domain
images.

    

### [[1812.08434] Graph Neural Networks: A Review of Methods and Applications](http://arxiv.org/abs/1812.08434)


  Lots of learning tasks require dealing with graph data which contains rich
relation information among elements. Modeling physics systems, learning
molecular fingerprints, predicting protein interface, and classifying diseases
demand a model to learn from graph inputs. In other domains such as learning
from non-structural data like texts and images, reasoning on extracted
structures (like the dependency trees of sentences and the scene graphs of
images) is an important research topic which also needs graph reasoning models.
Graph neural networks (GNNs) are neural models that capture the dependence of
graphs via message passing between the nodes of graphs. In recent years,
variants of GNNs such as graph convolutional network (GCN), graph attention
network (GAT), graph recurrent network (GRN) have demonstrated ground-breaking
performances on many deep learning tasks. In this survey, we propose a general
design pipeline for GNN models and discuss the variants of each component,
systematically categorize the applications, and propose four open problems for
future research.

    

### [[1901.10371] On the Effect of Low-Rank Weights on Adversarial Robustness of Neural Networks](http://arxiv.org/abs/1901.10371)


  Recently, there has been an abundance of works on designing Deep Neural
Networks (DNNs) that are robust to adversarial examples. In particular, a
central question is which features of DNNs influence adversarial robustness
and, therefore, can be to used to design robust DNNs. In this work, this
problem is studied through the lens of compression which is captured by the
low-rank structure of weight matrices. It is first shown that adversarial
training tends to promote simultaneously low-rank and sparse structure in the
weight matrices of neural networks. This is measured through the notions of
effective rank and effective sparsity. In the reverse direction, when the low
rank structure is promoted by nuclear norm regularization and combined with
sparsity inducing regularizations, neural networks show significantly improved
adversarial robustness. The effect of nuclear norm regularization on
adversarial robustness is paramount when it is applied to convolutional neural
networks. Although still not competing with adversarial training, this result
contributes to understanding the key properties of robust classifiers.

    

### [[1911.03432] Penalty Method for Inversion-Free Deep Bilevel Optimization](http://arxiv.org/abs/1911.03432)


  Solving a bilevel optimization problem is at the core of several machine
learning problems such as hyperparameter tuning, data denoising, meta- and
few-shot learning, and training-data poisoning. Different from simultaneous or
multi-objective optimization, the steepest descent direction for minimizing the
upper-level cost in a bilevel problem requires the inverse of the Hessian of
the lower-level cost. In this work, we propose a novel algorithm for solving
bilevel optimization problems based on the classical penalty function approach.
Our method avoids computing the Hessian inverse and can handle constrained
bilevel problems easily. We prove the convergence of the method under mild
conditions and show that the exact hypergradient is obtained asymptotically.
Our method's simplicity and small space and time complexities enable us to
effectively solve large-scale bilevel problems involving deep neural networks.
We present results on data denoising, few-shot learning, and training-data
poisoning problems in a large-scale setting. Our results show that our approach
outperforms or is comparable to previously proposed methods based on automatic
differentiation and approximate inversion in terms of accuracy, run-time, and
convergence speed.

    

### [[1912.07773] MEDIRL: Predicting the Visual Attention of Drivers via Maximum Entropy Deep Inverse Reinforcement Learning](http://arxiv.org/abs/1912.07773)


  Inspired by human visual attention, we propose a novel inverse reinforcement
learning formulation using Maximum Entropy Deep Inverse Reinforcement Learning
(MEDIRL) for predicting the visual attention of drivers in accident-prone
situations. MEDIRL predicts fixation locations that lead to maximal rewards by
learning a task-sensitive reward function from eye fixation patterns recorded
from attentive drivers. Additionally, we introduce EyeCar, a new driver
attention dataset in accident-prone situations. We conduct comprehensive
experiments to evaluate our proposed model on three common benchmarks:
(DR(eye)VE, BDD-A, DADA-2000), and our EyeCar dataset. Results indicate that
MEDIRL outperforms existing models for predicting attention and achieves
state-of-the-art performance. We present extensive ablation studies to provide
more insights into different features of our proposed model.

    

### [[2003.06321] Micro-supervised Disturbance Learning: A Perspective of Representation Probability Distribution](http://arxiv.org/abs/2003.06321)


  The instability is shown in the existing methods of representation learning
based on Euclidean distance under a broad set of conditions. Furthermore, the
scarcity and high cost of labels prompt us to explore more expressive
representation learning methods which depends on the labels as few as possible.
To address these issues, the small-perturbation ideology is firstly introduced
on the representation learning model based on the representation probability
distribution. The positive small-perturbation information (SPI) which only
depend on two labels of each cluster is used to stimulate the representation
probability distribution and then two variant models are proposed to fine-tune
the expected representation distribution of RBM, namely, Micro-supervised
Disturbance GRBM (Micro-DGRBM) and Micro-supervised Disturbance RBM
(Micro-DRBM) models. The Kullback-Leibler (KL) divergence of SPI is minimized
in the same cluster to promote the representation probability distributions to
become more similar in Contrastive Divergence(CD) learning. In contrast, the KL
divergence of SPI is maximized in the different clusters to enforce the
representation probability distributions to become more dissimilar in CD
learning. To explore the representation learning capability under the
continuous stimulation of the SPI, we present a deep Micro-supervised
Disturbance Learning (Micro-DL) framework based on the Micro-DGRBM and
Micro-DRBM models and compare it with a similar deep structure which has not
any external stimulation. Experimental results demonstrate that the proposed
deep Micro-DL architecture shows better performance in comparison to the
baseline method, the most related shallow models and deep frameworks for
clustering.

    

### [[2003.06658] From SCAN to Real Data: Systematic Generalization via Meaningful Learning](http://arxiv.org/abs/2003.06658)


  Humans can systematically generalize to novel compositions of existing
concepts. There have been extensive conjectures into the extent to which neural
networks can do the same. Recent arguments supported by evidence on the SCAN
dataset claim that neural networks are inherently ineffective in such cognitive
capacity. In this paper, we revisit systematic generalization from the
perspective of meaningful learning, an exceptional capability of humans to
learn new concepts by connecting them with other previously known knowledge. We
propose to augment a training dataset in either an inductive or deductive
manner to build semantic links between new and old concepts. Our observations
on SCAN suggest that, following the meaningful learning principle, modern
sequence-to-sequence models, including RNNs, CNNs, and Transformers, can
successfully generalize to compositions of new concepts. We further validate
our findings on two real-world datasets on semantic parsing and consistent
compositional generalization is also observed. Moreover, our experiments
demonstrate that both prior knowledge and semantic linking play a key role to
achieve systematic generalization. Meanwhile, inductive learning generally
works better than deductive learning in our experiments. Finally, we provide an
explanation for data augmentation techniques by concluding them into either
inductive-based or deductive-based meaningful learning. We hope our findings
will encourage excavating existing neural networks' potential in systematic
generalization through more advanced learning schemes.

    

### [[2005.09874] An Incremental Clustering Method for Anomaly Detection in Flight Data](http://arxiv.org/abs/2005.09874)


  Safety is a top priority for civil aviation. New anomaly detection methods,
primarily clustering methods, have been developed to monitor pilot operations
and detect any risks from such flight data. However, all existing anomaly
detection methods are offlline learning - the models are trained once using
historical data and used for all future predictions. In practice, new flight
data are accumulated continuously and analyzed every month at airlines.
Clustering such dynamically growing data is challenging for an offlline method
because it is memory and time intensive to re-train the model every time new
data come in. If the model is not re-trained, false alarms or missed detections
may increase since the model cannot reflect changes in data patterns. To
address this problem, we propose a novel incremental anomaly detection method
based on Gaussian Mixture Model (GMM) to identify common patterns and detect
outliers in flight operations from digital flight data. It is a probabilistic
clustering model of flight operations that can incrementally update its
clusters based on new data rather than to re-cluster all data from scratch. It
trains an initial GMM model based on historical offlline data. Then, it
continuously adapts to new incoming data points via an expectation-maximization
(EM) algorithm. To track changes in flight operation patterns, only model
parameters need to be saved. The proposed method was tested on three sets of
simulation data and two sets of real-world flight data. Compared with the
traditional offline GMM method, the proposed method can generate similar
clustering results with significantly reduced processing time (57 % - 99 % time
reduction in testing sets) and memory usage (91 % - 95 % memory usage reduction
in testing sets). Preliminary results indicate that the incremental learning
scheme is effective in dealing with dynamically growing data in flight data
analytics.

    

### [[2006.05624] Adjoined Networks: A Training Paradigm with Applications to Network Compression](http://arxiv.org/abs/2006.05624)


  Compressing deep neural networks while maintaining accuracy is important when
we want to deploy large, powerful models in production and/or edge devices. One
common technique used to achieve this goal is knowledge distillation.
Typically, the output of a static pre-defined teacher (a large base network) is
used as soft labels to train and transfer information to a student (or smaller)
network. In this paper, we introduce Adjoined Networks, or AN, a learning
paradigm that trains both the original base network and the smaller compressed
network together. In our training approach, the parameters of the smaller
network are shared across both the base and the compressed networks. Using our
training paradigm, we can simultaneously compress (the student network) and
regularize (the teacher network) any architecture. In this paper, we focus on
popular CNN-based architectures used for computer vision tasks. We conduct an
extensive experimental evaluation of our training paradigm on various
large-scale datasets. Using ResNet-50 as the base network, AN achieves 71.8%
top-1 accuracy with only 1.8M parameters and 1.6 GFLOPs on the ImageNet
data-set. We further propose Differentiable Adjoined Networks (DAN), a training
paradigm that augments AN by using neural architecture search to jointly learn
both the width and the weights for each layer of the smaller network. DAN
achieves ResNet-50 level accuracy on ImageNet with $3.8\times$ fewer parameters
and $2.2\times$ fewer FLOPs.

    

### [[2008.12813] HittER: Hierarchical Transformers for Knowledge Graph Embeddings](http://arxiv.org/abs/2008.12813)


  This paper examines the challenging problem of learning representations of
entities and relations in a complex multi-relational knowledge graph. We
propose HittER, a Hierarchical Transformer model to jointly learn
Entity-relation composition and Relational contextualization based on a source
entity's neighborhood. Our proposed model consists of two different Transformer
blocks: the bottom block extracts features of each entity-relation pair in the
local neighborhood of the source entity and the top block aggregates the
relational information from outputs of the bottom block. We further design a
masked entity prediction task to balance information from the relational
context and the source entity itself. Experimental results show that HittER
achieves new state-of-the-art results on multiple link prediction datasets. We
additionally propose a simple approach to integrate HittER into BERT and
demonstrate its effectiveness on two Freebase factoid question answering
datasets.

    

### [[2009.08574] Linear Convergence of Generalized Mirror Descent with Time-Dependent Mirrors](http://arxiv.org/abs/2009.08574)


  The Polyak-Lojasiewicz (PL) inequality is a sufficient condition for
establishing linear convergence of gradient descent, even in non-convex
settings. While several recent works use a PL-based analysis to establish
linear convergence of stochastic gradient descent methods, the question remains
as to whether a similar analysis can be conducted for more general optimization
methods. In this work, we present a PL-based analysis for linear convergence of
generalized mirror descent (GMD), a generalization of mirror descent with a
possibly time-dependent mirror. GMD subsumes popular first order optimization
methods including gradient descent, mirror descent, and preconditioned gradient
descent methods such as Adagrad. Since the standard PL analysis cannot be
extended naturally from GMD to stochastic GMD, we present a Taylor-series based
analysis to establish sufficient conditions for linear convergence of
stochastic GMD. As a corollary, our result establishes sufficient conditions
and provides learning rates for linear convergence of stochastic mirror descent
and Adagrad. Lastly, for functions that are locally PL*, our analysis implies
existence of an interpolating solution and convergence of GMD to this solution.

    

### [[2010.11918] AdapterDrop: On the Efficiency of Adapters in Transformers](http://arxiv.org/abs/2010.11918)


  Massively pre-trained transformer models are computationally expensive to
fine-tune, slow for inference, and have large storage requirements. Recent
approaches tackle these shortcomings by training smaller models, dynamically
reducing the model size, and by training light-weight adapters. In this paper,
we propose AdapterDrop, removing adapters from lower transformer layers during
training and inference, which incorporates concepts from all three directions.
We show that AdapterDrop can dynamically reduce the computational overhead when
performing inference over multiple tasks simultaneously, with minimal decrease
in task performances. We further prune adapters from AdapterFusion, which
improves the inference efficiency while maintaining the task performances
entirely.

    

### [[2101.04041] Evaluating Disentanglement of Structured Latent Representations](http://arxiv.org/abs/2101.04041)


  We introduce the first metric for evaluating disentanglement at individual
hierarchy levels of a structured latent representation. Applied to
object-centric generative models, this offers a systematic, unified approach to
evaluating (i) object separation between latent slots (ii) disentanglement of
object properties inside individual slots (iii) disentanglement of intrinsic
and extrinsic object properties. We theoretically show that our framework gives
stronger guarantees of selecting a good model than previous disentanglement
metrics. Experimentally, we demonstrate that viewing object compositionality as
a disentanglement problem addresses several issues with prior visual metrics of
object separation. As a core technical component, we present the first
representation probing algorithm handling slot permutation invariance.

    

### [[2101.04348] Phase Retrieval using Expectation Consistent Signal Recovery Algorithm based on Hypernetwork](http://arxiv.org/abs/2101.04348)


  Phase retrieval (PR) is an important component in modern computational
imaging systems. Many algorithms have been developed over the past
half-century. Recent advances in deep learning have introduced new
possibilities for a robust and fast PR. An emerging technique called deep
unfolding provides a systematic connection between conventional model-based
iterative algorithms and modern data-based deep learning. Unfolded algorithms,
which are powered by data learning, have shown remarkable performance and
convergence speed improvement over original algorithms. Despite their
potential, most existing unfolded algorithms are strictly confined to a fixed
number of iterations when layer-dependent parameters are used. In this study,
we develop a novel framework for deep unfolding to overcome existing
limitations. Our development is based on an unfolded generalized expectation
consistent signal recovery (GEC-SR) algorithm, wherein damping factors are left
for data-driven learning. In particular, we introduce a hypernetwork to
generate the damping factors for GEC-SR. Instead of learning a set of optimal
damping factors directly, the hypernetwork learns how to generate the optimal
damping factors according to the clinical settings, thereby ensuring its
adaptivity to different scenarios. To enable the hypernetwork to adapt to
varying layer numbers, we use a recurrent architecture to develop a dynamic
hypernetwork that generates a damping factor that can vary online across
layers. We also exploit a self-attention mechanism to enhance the robustness of
the hypernetwork. Extensive experiments show that the proposed algorithm
outperforms existing ones in terms of convergence speed and accuracy and still
works well under very harsh settings, even under which many classical PR
algorithms are unstable.

    

### [[2101.08448] Noisy intermediate-scale quantum (NISQ) algorithms](http://arxiv.org/abs/2101.08448)


  A universal fault-tolerant quantum computer that can solve efficiently
problems such as integer factorization and unstructured database search
requires millions of qubits with low error rates and long coherence times.
While the experimental advancement towards realizing such devices will
potentially take decades of research, noisy intermediate-scale quantum (NISQ)
computers already exist. These computers are composed of hundreds of noisy
qubits, i.e. qubits that are not error-corrected, and therefore perform
imperfect operations in a limited coherence time. In the search for quantum
advantage with these devices, algorithms have been proposed for applications in
various disciplines spanning physics, machine learning, quantum chemistry and
combinatorial optimization. The goal of such algorithms is to leverage the
limited available resources to perform classically challenging tasks. In this
review, we provide a thorough summary of NISQ computational paradigms and
algorithms. We discuss the key structure of these algorithms, their
limitations, and advantages. We additionally provide a comprehensive overview
of various benchmarking and software tools useful for programming and testing
NISQ devices.

    

### [[2102.02340] MUFASA: Multimodal Fusion Architecture Search for Electronic Health Records](http://arxiv.org/abs/2102.02340)


  One important challenge of applying deep learning to electronic health
records (EHR) is the complexity of their multimodal structure. EHR usually
contains a mixture of structured (codes) and unstructured (free-text) data with
sparse and irregular longitudinal features -- all of which doctors utilize when
making decisions. In the deep learning regime, determining how different
modality representations should be fused together is a difficult problem, which
is often addressed by handcrafted modeling and intuition. In this work, we
extend state-of-the-art neural architecture search (NAS) methods and propose
MUltimodal Fusion Architecture SeArch (MUFASA) to simultaneously search across
multimodal fusion strategies and modality-specific architectures for the first
time. We demonstrate empirically that our MUFASA method outperforms established
unimodal NAS on public EHR data with comparable computation costs. In addition,
MUFASA produces architectures that outperform Transformer and Evolved
Transformer. Compared with these baselines on CCS diagnosis code prediction,
our discovered models improve top-5 recall from 0.88 to 0.91 and demonstrate
the ability to generalize to other EHR tasks. Studying our top architecture in
depth, we provide empirical evidence that MUFASA's improvements are derived
from its ability to both customize modeling for each data modality and find
effective fusion strategies.

    

### [[2102.02551] ML-Doctor: Holistic Risk Assessment of Inference Attacks Against Machine Learning Models](http://arxiv.org/abs/2102.02551)


  Inference attacks against Machine Learning (ML) models allow adversaries to
learn sensitive information about training data, model parameters, etc. While
researchers have studied, in depth, several kinds of attacks, they have done so
in isolation. As a result, we lack a comprehensive picture of the risks caused
by the attacks, e.g., the different scenarios they can be applied to, the
common factors that influence their performance, the relationship among them,
or the effectiveness of possible defenses. In this paper, we fill this gap by
presenting a first-of-its-kind holistic risk assessment of different inference
attacks against machine learning models. We concentrate on four attacks --
namely, membership inference, model inversion, attribute inference, and model
stealing -- and establish a threat model taxonomy.
Our extensive experimental evaluation, run on five model architectures and
four image datasets, shows that the complexity of the training dataset plays an
important role with respect to the attack's performance, while the
effectiveness of model stealing and membership inference attacks are negatively
correlated. We also show that defenses like DP-SGD and Knowledge Distillation
can only mitigate some of the inference attacks. Our analysis relies on a
modular re-usable software, ML-Doctor, which enables ML model owners to assess
the risks of deploying their models, and equally serves as a benchmark tool for
researchers and practitioners.

    

### [[2102.02828] Scattering Networks on the Sphere for Scalable and Rotationally Equivariant Spherical CNNs](http://arxiv.org/abs/2102.02828)


  Convolutional neural networks (CNNs) constructed natively on the sphere have
been developed recently and shown to be highly effective for the analysis of
spherical data. While an efficient framework has been formulated, spherical
CNNs are nevertheless highly computationally demanding; typically they cannot
scale beyond spherical signals of thousands of pixels. We develop scattering
networks constructed natively on the sphere that provide a powerful
representational space for spherical data. Spherical scattering networks are
computationally scalable and exhibit rotational equivariance, while their
representational space is invariant to isometries and provides efficient and
stable signal representations. By integrating scattering networks as an
additional type of layer in the generalized spherical CNN framework, we show
how they can be leveraged to scale spherical CNNs to the high-resolution data
typical of many practical applications, with spherical signals of many tens of
megapixels and beyond.

    

### [[2102.05313] Conditional Loss and Deep Euler Scheme for Time Series Generation](http://arxiv.org/abs/2102.05313)


  We introduce three new generative models for time series that are based on
Euler discretization of Stochastic Differential Equations (SDEs) and
Wasserstein metrics. Two of these methods rely on the adaptation of generative
adversarial networks (GANs) to time series. The third algorithm, called
Conditional Euler Generator (CEGEN), minimizes a dedicated distance between the
transition probability distributions over all time steps. In the context of Ito
processes, we provide theoretical guarantees that minimizing this criterion
implies accurate estimations of the drift and volatility parameters. We
demonstrate empirically that CEGEN outperforms state-of-the-art and GAN
generators on both marginal and temporal dynamics metrics. Besides, it
identifies accurate correlation structures in high dimension. When few data
points are available, we verify the effectiveness of CEGEN, when combined with
transfer learning methods on Monte Carlo simulations. Finally, we illustrate
the robustness of our method on various real-world datasets.

    

### [[2102.05912] On Transportation of Mini-batches: A Hierarchical Approach](http://arxiv.org/abs/2102.05912)


  Mini-batch optimal transport (m-OT) has been successfully used in practical
applications that involve probability measures with a very high number of
supports. The m-OT solves several smaller optimal transport problems and then
returns the average of their costs and transportation plans. Despite its
scalability advantage, the m-OT does not consider the relationship between
mini-batches which leads to undesirable estimation. Moreover, the m-OT does not
approximate a proper metric between probability measures since the identity
property is not satisfied. To address these problems, we propose a novel
mini-batching scheme for optimal transport, named Batch of Mini-batches Optimal
Transport (BoMb-OT), that finds the optimal coupling between mini-batches and
it can be seen as an approximation to a well-defined distance on the space of
probability measures. Furthermore, we show that the m-OT is a limit of the
entropic regularized version of the BoMb-OT when the regularized parameter goes
to infinity. Finally, we present the new algorithms of the BoMb-OT in various
applications, such as deep generative models and deep domain adaptation. From
extensive experiments, we observe that the BoMb-OT achieves a favorable
performance in deep learning models such as deep generative models and deep
domain adaptation. In other applications such as approximate Bayesian
computation, color transfer, and gradient flow, the BoMb-OT also yields either
a lower quantitative result or a better qualitative result than the m-OT.

    

### [[2102.06571] Bayesian Neural Network Priors Revisited](http://arxiv.org/abs/2102.06571)


  Isotropic Gaussian priors are the de facto standard for modern Bayesian
neural network inference. However, it is unclear whether these priors
accurately reflect our true beliefs about the weight distributions or give
optimal performance. To find better priors, we study summary statistics of
neural network weights in networks trained using SGD. We find that
convolutional neural network (CNN) weights display strong spatial correlations,
while fully connected networks (FCNNs) display heavy-tailed weight
distributions. Building these observations into priors leads to improved
performance on a variety of image classification datasets. Surprisingly, these
priors mitigate the cold posterior effect in FCNNs, but slightly increase the
cold posterior effect in ResNets.

    

### [[2102.07559] Certifiably Robust Variational Autoencoders](http://arxiv.org/abs/2102.07559)


  We introduce an approach for training Variational Autoencoders (VAEs) that
are certifiably robust to adversarial attack. Specifically, we first derive
actionable bounds on the minimal size of an input perturbation required to
change a VAE's reconstruction by more than an allowed amount, with these bounds
depending on certain key parameters such as the Lipschitz constants of the
encoder and decoder. We then show how these parameters can be controlled,
thereby providing a mechanism to ensure \textit{a priori} that a VAE will
attain a desired level of robustness. Moreover, we extend this to a complete
practical approach for training such VAEs to ensure our criteria are met.
Critically, our method allows one to specify a desired level of robustness
\emph{upfront} and then train a VAE that is guaranteed to achieve this
robustness. We further demonstrate that these Lipschitz--constrained VAEs are
more robust to attack than standard VAEs in practice.

    

### [[2102.12317] Learning-Augmented Sketches for Hessians](http://arxiv.org/abs/2102.12317)


  Sketching is a dimensionality reduction technique where one compresses a
matrix by linear combinations that are chosen at random. A line of work has
shown how to sketch the Hessian to speed up each iteration in a second order
method, but such sketches usually depend only on the matrix at hand, and in a
number of cases are even oblivious to the input matrix. One could instead hope
to learn a distribution on sketching matrices that is optimized for the
specific distribution of input matrices. We show how to design learned sketches
for the Hessian in the context of second order methods. We prove that a smaller
sketching dimension of the column space of a tall matrix is possible, given an
oracle that can predict the indices of the rows of large leverage score. We
design such an oracle for various datasets, and this leads to a faster
convergence of the well-studied iterative Hessian sketch procedure, which
applies to a wide range of problems in convex optimization. We show empirically
that learned sketches, compared with their "non-learned" counterparts, do
improve the approximation accuracy for important problems, including LASSO and
matrix estimation with nuclear norm constraints.

    

### [[2103.03113] Towards Deepening Graph Neural Networks: A GNTK-based Optimization Perspective](http://arxiv.org/abs/2103.03113)


  Graph convolutional networks (GCNs) and their variants have achieved great
success in dealing with graph-structured data. However, it is well known that
deep GCNs suffer from the over-smoothing problem, where node representations
tend to be indistinguishable as more layers are stacked up. The theoretical
research to date on deep GCNs has focused primarily on expressive power rather
than trainability, an optimization perspective. Compared to expressivity,
trainability attempts to address a more fundamental question: given a
sufficiently expressive space of models, can we successfully find a good
solution by gradient descent-based optimizer? This work fills this gap by
exploiting the Graph Neural Tangent Kernel (GNTK), which governs the
optimization trajectory under gradient descent for wide GCNs. We formulate the
asymptotic behaviors of GNTK in the large depth, which enables us to reveal the
dropping trainability of wide and deep GCNs at an exponential rate in the
optimization process. Additionally, we extend our theoretical framework to
analyze residual connection-resemble techniques, which are found to be only
able to mildly mitigate the exponential decay of trainability. To overcome the
exponential decay problem more fundamentally, we propose Critical DropEdge, a
connectivity-aware and graph-adaptive sampling method, inspired by our
theoretical insights on trainability. Experimental evaluation consistently
confirms using our proposed method can achieve better results compared to
relevant counterparts with both infinite-width and finite-width.

    

### [[2103.11257] Robust Models Are More Interpretable Because Attributions Look Normal](http://arxiv.org/abs/2103.11257)


  Recent work has found that adversarially-robust deep networks used for image
classification are more interpretable: their feature attributions tend to be
sharper, and are more concentrated on the objects associated with the image's
ground-truth class. We show that smooth decision boundaries play an important
role in this enhanced interpretability, as the model's input gradients around
data points will more closely align with boundaries' normal vectors when they
are smooth. Thus, because robust models have smoother boundaries, the results
of gradient-based attribution methods, like Integrated Gradients and DeepLift,
will capture more accurate information about nearby decision boundaries. This
understanding of robust interpretability leads to our second contribution:
\emph{boundary attributions}, which aggregate information about the normal
vectors of local decision boundaries to explain a classification outcome. We
show that by leveraging the key factors underpinning robust interpretability,
boundary attributions produce sharper, more concentrated visual explanations --
even on non-robust models. Any example implementation can be found at
\url{this https URL}.

    

### [[2104.00820] LatentCLR: A Contrastive Learning Approach for Unsupervised Discovery of Interpretable Directions](http://arxiv.org/abs/2104.00820)


  Recent research has shown that it is possible to find interpretable
directions in the latent spaces of pre-trained Generative Adversarial Networks
(GANs). These directions enable controllable image generation and support a
wide range of semantic editing operations, such as zoom or rotation. The
discovery of such directions is often done in a supervised or semi-supervised
manner and requires manual annotations which limits their use in practice. In
comparison, unsupervised discovery allows finding subtle directions that are
difficult to detect a priori. In this work, we propose a contrastive
learning-based approach to discover semantic directions in the latent space of
pre-trained GANs in a self-supervised manner. Our approach finds semantically
meaningful dimensions comparable with state-of-the-art methods.

    

### [[2104.04448] Relating Adversarially Robust Generalization to Flat Minima](http://arxiv.org/abs/2104.04448)


  Adversarial training (AT) has become the de-facto standard to obtain models
robust against adversarial examples. However, AT exhibits severe robust
overfitting: cross-entropy loss on adversarial examples, so-called robust loss,
decreases continuously on training examples, while eventually increasing on
test examples. In practice, this leads to poor robust generalization, i.e.,
adversarial robustness does not generalize well to new examples. In this paper,
we study the relationship between robust generalization and flatness of the
robust loss landscape in weight space, i.e., whether robust loss changes
significantly when perturbing weights. To this end, we propose average- and
worst-case metrics to measure flatness in the robust loss landscape and show a
correlation between good robust generalization and flatness. For example,
throughout training, flatness reduces significantly during overfitting such
that early stopping effectively finds flatter minima in the robust loss
landscape. Similarly, AT variants achieving higher adversarial robustness also
correspond to flatter minima. This holds for many popular choices, e.g.,
AT-AWP, TRADES, MART, AT with self-supervision or additional unlabeled
examples, as well as simple regularization techniques, e.g., AutoAugment,
weight decay or label noise. For fair comparison across these approaches, our
flatness measures are specifically designed to be scale-invariant and we
conduct extensive experiments to validate our findings.

    

### [[2104.06069] 1-bit LAMB: Communication Efficient Large-Scale Large-Batch Training with LAMB's Convergence Speed](http://arxiv.org/abs/2104.06069)


  To train large models (like BERT and GPT-3) on hundreds of GPUs,
communication has become a major bottleneck, especially on commodity systems
with limited-bandwidth TCP network. On one side large batch-size optimization
such as LAMB algorithm was proposed to reduce the frequency of communication.
On the other side, communication compression algorithms such as 1-bit Adam help
to reduce the volume of each communication. However, we find that simply using
one of the techniques is not sufficient to solve the communication challenge,
especially under low network bandwidth. Motivated by this we aim to combine the
power of large-batch optimization and communication compression, but we find
that existing compression strategies cannot be directly applied to LAMB due to
its unique adaptive layerwise learning rates. To this end, we design a new
communication-efficient algorithm, 1-bit LAMB, which introduces a novel way to
support adaptive layerwise learning rates under compression. In addition, we
introduce a new system implementation for compressed communication using the
NCCL backend of PyTorch distributed, which improves both usability and
performance. For BERT-Large pre-training task with batch sizes from 8K to 64K,
our evaluations on up to 256 GPUs demonstrate that 1-bit LAMB with NCCL-based
backend is able to achieve up to 4.6x communication volume reduction, up to
2.8x end-to-end time-wise speedup, and the same sample-wise convergence speed
(and same fine-tuning task accuracy) compared to uncompressed LAMB.

    

### [[2104.07012] Sparse Attention with Linear Units](http://arxiv.org/abs/2104.07012)


  Recently, it has been argued that encoder-decoder models can be made more
interpretable by replacing the softmax function in the attention with its
sparse variants. In this work, we introduce a novel, simple method for
achieving sparsity in attention: we replace the softmax activation with a ReLU,
and show that sparsity naturally emerges from such a formulation. Training
stability is achieved with layer normalization with either a specialized
initialization or an additional gating function. Our model, which we call
Rectified Linear Attention (ReLA), is easy to implement and more efficient than
previously proposed sparse attention mechanisms. We apply ReLA to the
Transformer and conduct experiments on five machine translation tasks. ReLA
achieves translation performance comparable to several strong baselines, with
training and decoding speed similar to that of the vanilla attention. Our
analysis shows that ReLA delivers high sparsity rate and head diversity, and
the induced cross attention achieves better accuracy with respect to
source-target word alignment than recent sparsified softmax-based models.
Intriguingly, ReLA heads also learn to attend to nothing (i.e. 'switch off')
for some queries, which is not possible with sparsified softmax alternatives.

    

### [[2104.07886] Reinforced Neighborhood Selection Guided Multi-Relational Graph Neural Networks](http://arxiv.org/abs/2104.07886)


  Graph Neural Networks (GNNs) have been widely used for the representation
learning of various structured graph data. While promising, most existing GNNs
oversimplified the complexity and diversity of the edges in the graph, and thus
inefficient to cope with ubiquitous heterogeneous graphs, which are typically
in the form of multi-relational graph representations. In this paper, we
propose RioGNN, a novel Reinforced, recursive and flexible neighborhood
selection guided multi-relational Graph Neural Network architecture, to
navigate complexity of neural network structures whilst maintaining
relation-dependent representations. We first construct a multi-relational
graph, according to the practical task, to reflect the heterogeneity of nodes,
edges, attributes and labels. To avoid the embedding over-assimilation among
different types of nodes, we employ a label-aware neural similarity measure to
ascertain the most similar neighbors based on node attributes. A reinforced
relation-aware neighbor selection mechanism is developed to choose the most
similar neighbors of a targeting node within a relation before aggregating all
neighborhood information from different relations to obtain the eventual node
embedding. Particularly, to improve the efficiency of neighbor selecting, we
propose a new recursive and scalable reinforcement learning framework with
estimable depth and width for different scales of multi-relational graphs.
RioGNN can learn more discriminative node embedding with enhanced
explainability due to the recognition of individual importance of each relation
via the filtering threshold mechanism. Comprehensive experiments on real-world
graph data and practical tasks demonstrate the advancements of effectiveness,
efficiency and the model explainability, as opposed to other comparative GNN
models.

    

### [[2104.13225] Visually grounded models of spoken language: A survey of datasets, architectures and evaluation techniques](http://arxiv.org/abs/2104.13225)


  This survey provides an overview of the evolution of visually grounded models
of spoken language over the last 20 years. Such models are inspired by the
observation that when children pick up a language, they rely on a wide range of
indirect and noisy clues, crucially including signals from the visual modality
co-occurring with spoken utterances. Several fields have made important
contributions to this approach to modeling or mimicking the process of learning
language: Machine Learning, Natural Language and Speech Processing, Computer
Vision and Cognitive Science. The current paper brings together these
contributions in order to provide a useful introduction and overview for
practitioners in all these areas. We discuss the central research questions
addressed, the timeline of developments, and the datasets which enabled much of
this work. We then summarize the main modeling architectures and offer an
exhaustive overview of the evaluation metrics and analysis techniques.

    

### [[2105.05381] Accuracy-Privacy Trade-off in Deep Ensemble: A Membership Inference Perspective](http://arxiv.org/abs/2105.05381)


  Deep ensemble learning has been shown to improve accuracy by training
multiple neural networks and fusing their outputs. Ensemble learning has also
been used to defend against membership inference attacks that undermine
privacy. In this paper, we empirically demonstrate a trade-off between these
two goals, namely accuracy and privacy (in terms of membership inference
attacks), in deep ensembles. Using a wide range of datasets and model
architectures, we show that the effectiveness of membership inference attacks
also increases when ensembling improves accuracy. To better understand this
trade-off, we study the impact of various factors such as prediction confidence
and agreement between models that constitute the ensemble. Finally, we evaluate
defenses against membership inference attacks based on regularization and
differential privacy. We show that while these defenses can mitigate the
effectiveness of the membership inference attack, they simultaneously degrade
ensemble accuracy. We illustrate similar trade-off in more advanced and
state-of-the-art ensembling techniques, such as snapshot ensembles and
diversified ensemble networks. The source code is available in supplementary
materials.

    

### [[2105.14328] Transfer Learning under High-dimensional Generalized Linear Models](http://arxiv.org/abs/2105.14328)


  In this work, we study the transfer learning problem under high-dimensional
generalized linear models (GLMs), which aim to improve the fit on target data
by borrowing information from useful source data. Given which sources to
transfer, we propose an oracle algorithm and derive its $\ell_2$-estimation
error bounds. The theoretical analysis shows that under certain conditions,
when the target and source are sufficiently close to each other, the estimation
error bound could be improved over that of the classical penalized estimator
using only target data. When we don't know which sources to transfer, an
algorithm-free transferable source detection approach is introduced to detect
informative sources. The detection consistency is proved under the
high-dimensional GLM transfer learning setting. Extensive simulations and a
real-data experiment verify the effectiveness of our algorithms.

    

### [[2105.14785] Adversarial Training with Rectified Rejection](http://arxiv.org/abs/2105.14785)


  Adversarial training (AT) is one of the most effective strategies for
promoting model robustness, whereas even the state-of-the-art adversarially
trained models struggle to exceed 65% robust test accuracy on CIFAR-10 without
additional data, which is far from practical. A natural way to improve beyond
this accuracy bottleneck is to introduce a rejection option, where confidence
is a commonly used certainty proxy. However, the vanilla confidence can
overestimate the model certainty if the input is wrongly classified. To this
end, we propose to use true confidence (T-Con) (i.e., predicted probability of
the true class) as a certainty oracle, and learn to predict T-Con by rectifying
confidence. Intriguingly, we prove that under mild conditions, a rectified
confidence (R-Con) rejector and a confidence rejector can be coupled to
distinguish any wrongly classified input from correctly classified ones. We
also quantify that training R-Con to be aligned with T-Con could be an easier
task than learning robust classifiers. In our experiments, we evaluate our
rectified rejection (RR) module on CIFAR-10, CIFAR-10-C, and CIFAR-100 under
several attacks, and demonstrate that the RR module is well compatible with
different AT frameworks on improving robustness, with little extra computation.

    

### [[2105.15013] SHAQ: Incorporating Shapley Value Theory into Multi-Agent Q-Learning](http://arxiv.org/abs/2105.15013)


  Value factorisation proves to be a useful technique in multi-agent
reinforcement learning (MARL), but the underlying mechanism is not yet fully
understood. This paper explores a theoretical framework for value factorisation
with interpretability. We generalise Shapley value in coalitional game theory
to Markov convex game (MCG) and use it as a value factorisation method for
MARL. We show that the generalised Shapley value possesses several features
such as (1) efficiency: the sum of optimal generalised Shapley values is equal
to the optimal global value, (2) fairness in factorisation of the global value,
and (3) sensitiveness to dummy agents. Moreover, we show that MCG with the
grand coalition and the generalised Shapley value is within $\epsilon$-core,
which means no agents would deviate from the grand coalition. Since MCG with
the grand coalition is equivalent to global reward game, it is the first time
that Shapley value is rigorously proved to be rationally applied as a value
factorisation method for global reward game. Moreover, extending from the
Bellman operator we propose Shapley-Q operator that is proved to converge to
the optimal generalised Shapley value. With stochastic approximation, a new
MARL algorithm called Shapley Q-learning (SHAQ) is yielded. We show the
performance of SHAQ on Predator-Prey for modelling relative overgeneralisation
and StarCraft Multi-Agent Challenge (SMAC). In experiments, we also demonstrate
the interpretability of SHAQ that is lacking in the state-of-the-art baselines.

    

### [[2106.00563] IID-GAN: an IID Sampling Perspective for Regularizing Mode Collapse](http://arxiv.org/abs/2106.00563)


  Despite its success, generative adversarial networks (GANs) still suffer from
mode collapse, namely the generator can only map latent variables to a partial
set of modes of the target distribution. In this paper, we analyze and try to
regularize this issue with an independent and identically distributed (IID)
sampling perspective and emphasize that holding the IID property for generation
for target distribution (i.e. real distribution) can naturally avoid mode
collapse. This is based on the basic IID assumption for real data in machine
learning. However, though the source samples $\{\mathbf{z}\}$ obey IID, the
generations $\{G(\mathbf{z})\}$ may not necessarily be IID from the target
distribution. Based on this observation, we propose a necessary condition of
IID generation and provide a new loss to encourage the closeness between the
inverse source of real data and the Gaussian source in the latent space to
regularize the generation to be IID from the target distribution. The logic is
that the inverse samples from target data should also be IID in the source
distribution. Experiments on both synthetic and real-world data show the
effectiveness of our model.

    

### [[2106.01216] Evidential Turing Processes](http://arxiv.org/abs/2106.01216)


  A probabilistic classifier with reliable predictive uncertainties i) fits
successfully to the target domain data, ii) provides calibrated class
probabilities in difficult regions of the target domain (e.g.\ class overlap),
and iii) accurately identifies queries coming out of the target domain and
reject them. We introduce an original combination of Evidential Deep Learning,
Neural Processes, and Neural Turing Machines capable of providing all three
essential properties mentioned above for total uncertainty quantification. We
observe our method on three image classification benchmarks to consistently
improve the in-domain uncertainty quantification, out-of-domain detection, and
robustness against input data corruption with one single model. Our unified
solution delivers an implementation-friendly and computationally efficient
recipe for safety clearance and provides intellectual economy to an
investigation of algorithmic roots of epistemic awareness in deep neural nets.

    

### [[2106.02229] RL-DARTS: Differentiable Architecture Search for Reinforcement Learning](http://arxiv.org/abs/2106.02229)


  Recently, Differentiable Architecture Search (DARTS) has become one of the
most popular Neural Architecture Search (NAS) methods successfully applied in
supervised learning (SL). However, its applications in other domains, in
particular for reinforcement learning (RL), has seldom been studied. This is
due in part to RL possessing a significantly different optimization paradigm
than SL, especially with regards to the notion of replay data, which is
continually generated via inference in RL. In this paper, we introduce
RL-DARTS, one of the first applications of end-to-end DARTS in RL to search for
convolutional cells, applied to the challenging, infinitely procedurally
generated Procgen benchmark. We demonstrate that the benefits of DARTS become
amplified when applied to RL, namely search efficiency in terms of time and
compute, as well as simplicity in integration with complex preexisting RL code
via simply replacing the image encoder with a DARTS supernet, compatible with
both off-policy and on-policy RL algorithms. At the same time however, we
provide one of the first extensive studies of DARTS outside of the standard
fixed dataset setting in SL via RL-DARTS. We show that throughout training, the
supernet gradually learns better cells, leading to alternative architectures
which can be highly competitive against manually designed policies, but also
verify previous design choices for RL policies.

    

### [[2106.02938] Energy-Based Learning for Cooperative Games, with Applications to Valuation Problems in Machine Learning](http://arxiv.org/abs/2106.02938)


  Valuation problems, such as feature interpretation, data valuation and model
valuation for ensembles, become increasingly more important in many machine
learning applications. Such problems are commonly solved by well-known
game-theoretic criteria, such as Shapley value or Banzhaf index. In this work,
we present a novel energy-based treatment for cooperative games, with a
theoretical justification by the maximum entropy framework. Surprisingly, by
conducting variational inference of the energy-based model, we recover various
game-theoretic valuation criteria through conducting one-step gradient ascent
for maximizing the mean-field ELBO objective. This observation also verifies
the rationality of existing criteria, as they are all attempting to decouple
the correlations among the players through the mean-field approach. By running
gradient ascent for multiple steps, we achieve a trajectory of the valuations,
among which we define the valuation with the best conceivable decoupling error
as the Variational Index. We experimentally demonstrate that the proposed
Variational Index enjoys intriguing properties on certain synthetic and
real-world valuation problems.

    

### [[2106.03498] Identifiability in inverse reinforcement learning](http://arxiv.org/abs/2106.03498)


  Inverse reinforcement learning attempts to reconstruct the reward function in
a Markov decision problem, using observations of agent actions. As already
observed in Russell [1998] the problem is ill-posed, and the reward function is
not identifiable, even under the presence of perfect information about optimal
behavior. We provide a resolution to this non-identifiability for problems with
entropy regularization. For a given environment, we fully characterize the
reward functions leading to a given policy and demonstrate that, given
demonstrations of actions for the same reward under two distinct discount
factors, or under sufficiently different environments, the unobserved reward
can be recovered up to a constant. We also give general necessary and
sufficient conditions for reconstruction of time-homogeneous rewards on finite
horizons, and for action-independent rewards, generalizing recent results of
Kim et al. [2021] and Fu et al. [2018].

    

### [[2106.05194] DIGRAC: Digraph Clustering Based on Flow Imbalance](http://arxiv.org/abs/2106.05194)


  Node clustering is a powerful tool in the analysis of networks. We introduce
a graph neural network framework to obtain node embeddings for directed
networks in a self-supervised manner, including a novel probabilistic imbalance
loss, which can be used for network clustering. Here, we propose directed flow
imbalance measures, which are tightly related to directionality, to reveal
clusters in the network even when there is no density difference between
clusters. In contrast to standard approaches in the literature, in this paper,
directionality is not treated as a nuisance, but rather contains the main
signal. DIGRAC optimizes directed flow imbalance for clustering without
requiring label supervision, unlike existing GNN methods, and can naturally
incorporate node features, unlike existing spectral methods. Experimental
results on synthetic data, in the form of directed stochastic block models, and
real-world data at different scales, demonstrate that our method, based on flow
imbalance, attains state-of-the-art results on directed graph clustering, for a
wide range of noise and sparsity levels and graph structures and topologies.

    

### [[2106.05424] Fair Disaster Containment via Graph-Cut Problems](http://arxiv.org/abs/2106.05424)


  Graph cut problems are fundamental in Combinatorial Optimization, and are a
central object of study in both theory and practice. Furthermore, the study of
\emph{fairness} in Algorithmic Design and Machine Learning has recently
received significant attention, with many different notions proposed and
analyzed for a variety of contexts. In this paper we initiate the study of
fairness for graph cut problems by giving the first fair definitions for them,
and subsequently we demonstrate appropriate algorithmic techniques that yield a
rigorous theoretical analysis. Specifically, we incorporate two different
notions of fairness, namely \emph{demographic} and \emph{probabilistic
individual} fairness, in a particular cut problem that models disaster
containment scenarios. Our results include a variety of approximation
algorithms with provable theoretical guarantees.

    

### [[2106.07704] Text Generation with Efficient (Soft) Q-Learning](http://arxiv.org/abs/2106.07704)


  Maximum likelihood estimation (MLE) is the predominant algorithm for training
text generation models. This paradigm relies on direct supervision examples,
which is not applicable to many emerging applications, such as generating
adversarial attacks or generating prompts to control language models.
Reinforcement learning (RL) on the other hand offers a more flexible solution
by allowing users to plug in arbitrary task metrics as reward. Yet previous RL
algorithms for text generation, such as policy gradient (on-policy RL) and
Q-learning (off-policy RL), are often notoriously inefficient or unstable to
train due to the large sequence space and the sparse reward received only at
the end of sequences. In this paper, we introduce a new RL formulation for text
generation from the soft Q-learning (SQL) perspective. It enables us to draw
from the latest RL advances, such as path consistency learning, to combine the
best of on-/off-policy updates, and learn effectively from sparse reward. We
apply the approach to a wide range of text generation tasks, including learning
from noisy/negative examples, adversarial attacks, and prompt generation.
Experiments show our approach consistently outperforms both task-specialized
algorithms and the previous RL methods.

    

### [[2106.09534] Adversarial Visual Robustness by Causal Intervention](http://arxiv.org/abs/2106.09534)


  Adversarial training is the de facto most promising defense against
adversarial examples. Yet, its passive nature inevitably prevents it from being
immune to unknown attackers. To achieve a proactive defense, we need a more
fundamental understanding of adversarial examples, beyond the popular bounded
threat model. In this paper, we provide a causal viewpoint of adversarial
vulnerability: the cause is the spurious correlation ubiquitously existing in
learning, i.e., the confounding effect, where attackers are precisely
exploiting these effects. Therefore, a fundamental solution for adversarial
robustness is by causal intervention. As these visual confounders are
imperceptible in general, we propose to use the instrumental variable that
achieves causal intervention without the need for confounder observation. We
term our robust training method as Causal intervention by instrumental Variable
(CiiV). It's a causal regularization that 1) augments the image with multiple
retinotopic centers and 2) encourages the model to learn causal features,
rather than local confounding patterns, by favoring features linearly
responding to spatial interpolations. Extensive experiments on a wide spectrum
of attackers and settings applied in CIFAR-10, CIFAR-100, and mini-ImageNet
demonstrate that CiiV is robust to adaptive attacks, including the recent
AutoAttack. Besides, as a general causal regularization, it can be easily
plugged into other methods to further boost the robustness.

    

### [[2106.12112] Bregman Gradient Policy Optimization](http://arxiv.org/abs/2106.12112)


  In this paper, we design a novel Bregman gradient policy optimization
framework for reinforcement learning based on Bregman divergences and momentum
techniques. Specifically, we propose a Bregman gradient policy optimization
(BGPO) algorithm based on the basic momentum technique and mirror descent
iteration. At the same time, we present an accelerated Bregman gradient policy
optimization (VR-BGPO) algorithm based on a momentum variance-reduced
technique. Moreover, we introduce a convergence analysis framework for our
Bregman gradient policy optimization under the nonconvex setting. Specifically,
we prove that BGPO achieves the sample complexity of $\tilde{O}(\epsilon^{-4})$
for finding $\epsilon$-stationary point only requiring one trajectory at each
iteration, and VR-BGPO reaches the best known sample complexity of
$\tilde{O}(\epsilon^{-3})$ for finding an $\epsilon$-stationary point, which
also only requires one trajectory at each iteration. In particular, by using
different Bregman divergences, our methods unify many existing policy
optimization algorithms and their new variants such as the existing
(variance-reduced) policy gradient algorithms and (variance-reduced) natural
policy gradient algorithms. Extensive experimental results on multiple
reinforcement learning tasks demonstrate the efficiency of our new algorithms.

    

### [[2106.12307] Should You Go Deeper? Optimizing Convolutional Neural Network Architectures without Training by Receptive Field Analysis](http://arxiv.org/abs/2106.12307)


  When optimizing convolutional neural networks (CNN) for a specific
image-based task, specialists commonly overshoot the number of convolutional
layers in their designs. By implication, these CNNs are unnecessarily resource
intensive to train and deploy, with diminishing beneficial effects on the
predictive performance.
The features a convolutional layer can process are strictly limited by its
receptive field. By layer-wise analyzing the size of the receptive fields, we
can reliably predict sequences of layers that will not contribute qualitatively
to the test accuracy in the given CNN architecture. Based on this analysis, we
propose design strategies based on a so-called border layer. This layer allows
to identify unproductive convolutional layers and hence to resolve these
inefficiencies, optimize the explainability and the computational performance
of CNNs. Since neither the strategies nor the analysis requires training of the
actual model, these insights allow for a very efficient design process of CNN
architectures, which might be automated in the future.

    

### [[2106.13863] Fully Steerable 3D Spherical Neurons](http://arxiv.org/abs/2106.13863)


  Emerging from low-level vision theory, steerable filters found their
counterpart in prior work on steerable convolutional neural networks
equivariant to rigid transformations. In our work, we propose a steerable
feed-forward learning-based approach that consists of spherical decision
surfaces and operates on point clouds. Focusing on 3D geometry, we derive a 3D
steerability constraint for hypersphere neurons, which are obtained by
conformal embedding of Euclidean space and have recently been revisited in the
context of learning representations of point sets. Exploiting the rotational
equivariance, we show how our model parameters are fully steerable at inference
time. We use a synthetic point set and real-world 3D skeleton data to show how
the proposed spherical filter banks enable making equivariant and, after online
optimization, invariant class predictions for known point sets in unknown
orientations.

    

### [[2107.00166] Sanity Checks for Lottery Tickets: Does Your Winning Ticket Really Win the Jackpot?](http://arxiv.org/abs/2107.00166)


  There have been long-standing controversies and inconsistencies over the
experiment setup and criteria for identifying the "winning ticket" in
literature. To reconcile such, we revisit the definition of lottery ticket
hypothesis, with comprehensive and more rigorous conditions. Under our new
definition, we show concrete evidence to clarify whether the winning ticket
exists across the major DNN architectures and/or applications. Through
extensive experiments, we perform quantitative analysis on the correlations
between winning tickets and various experimental factors, and empirically study
the patterns of our observations. We find that the key training
hyperparameters, such as learning rate and training epochs, as well as the
architecture characteristics such as capacities and residual connections, are
all highly correlated with whether and when the winning tickets can be
identified. Based on our analysis, we summarize a guideline for parameter
settings in regards of specific architecture characteristics, which we hope to
catalyze the research progress on the topic of lottery ticket hypothesis.

    

### [[2107.00948] From Personalized Medicine to Population Health: A Survey of mHealth Sensing Techniques](http://arxiv.org/abs/2107.00948)


  Mobile Sensing Apps have been widely used as a practical approach to collect
behavioral and health-related information from individuals and provide timely
intervention to promote health and well-beings, such as mental health and
chronic cares. As the objectives of mobile sensing could be either \emph{(a)
personalized medicine for individuals} or \emph{(b) public health for
populations}, in this work we review the design of these mobile sensing apps,
and propose to categorize the design of these apps/systems in two paradigms --
\emph{(i) Personal Sensing} and \emph{(ii) Crowd Sensing} paradigms. While both
sensing paradigms might incorporate with common ubiquitous sensing
technologies, such as wearable sensors, mobility monitoring, mobile data
offloading, and/or cloud-based data analytics to collect and process sensing
data from individuals, we present a novel taxonomy system with two major
components that can specify and classify apps/systems from aspects of the
life-cycle of mHealth Sensing: \emph{(1) Sensing Task Creation \&
Participation}, \emph{(2) Health Surveillance \& Data Collection}, and
\emph{(3) Data Analysis \& Knowledge Discovery}. With respect to different
goals of the two paradigms, this work systematically reviews this field, and
summarizes the design of typical apps/systems in the view of the configurations
and interactions between these two components. In addition to summarization,
the proposed taxonomy system also helps figure out the potential directions of
mobile sensing for health from both personalized medicines and population
health perspectives.

    

### [[2108.07183] Improving Self-supervised Learning with Hardness-aware Dynamic Curriculum Learning: An Application to Digital Pathology](http://arxiv.org/abs/2108.07183)


  Self-supervised learning (SSL) has recently shown tremendous potential to
learn generic visual representations useful for many image analysis tasks.
Despite their notable success, the existing SSL methods fail to generalize to
downstream tasks when the number of labeled training instances is small or if
the domain shift between the transfer domains is significant. In this paper, we
attempt to improve self-supervised pretrained representations through the lens
of curriculum learning by proposing a hardness-aware dynamic curriculum
learning (HaDCL) approach. To improve the robustness and generalizability of
SSL, we dynamically leverage progressive harder examples via easy-to-hard and
hard-to-very-hard samples during mini-batch downstream fine-tuning. We discover
that by progressive stage-wise curriculum learning, the pretrained
representations are significantly enhanced and adaptable to both in-domain and
out-of-domain distribution data.
We performed extensive validation on three histology benchmark datasets on
both patch-wise and slide-level classification problems. Our curriculum based
fine-tuning yields a significant improvement over standard fine-tuning, with a
minimum improvement in area-under-the-curve (AUC) score of 1.7% and 2.2% on
in-domain and out-of-domain distribution data, respectively. Further, we
empirically show that our approach is more generic and adaptable to any SSL
methods and does not impose any additional overhead complexity. Besides, we
also outline the role of patch-based versus slide-based curriculum learning in
histopathology to provide practical insights into the success of curriculum
based fine-tuning of SSL methods. Code is released at
this https URL


### [[2108.13264] Deep Reinforcement Learning at the Edge of the Statistical Precipice](http://arxiv.org/abs/2108.13264)


  Deep reinforcement learning (RL) algorithms are predominantly evaluated by
comparing their relative performance on a large suite of tasks. Most published
results on deep RL benchmarks compare point estimates of aggregate performance
such as mean and median scores across tasks, ignoring the statistical
uncertainty implied by the use of a finite number of training runs. Beginning
with the Arcade Learning Environment (ALE), the shift towards
computationally-demanding benchmarks has led to the practice of evaluating only
a small number of runs per task, exacerbating the statistical uncertainty in
point estimates. In this paper, we argue that reliable evaluation in the few
run deep RL regime cannot ignore the uncertainty in results without running the
risk of slowing down progress in the field. We illustrate this point using a
case study on the Atari 100k benchmark, where we find substantial discrepancies
between conclusions drawn from point estimates alone versus a more thorough
statistical analysis. With the aim of increasing the field's confidence in
reported results with a handful of runs, we advocate for reporting interval
estimates of aggregate performance and propose performance profiles to account
for the variability in results, as well as present more robust and efficient
aggregate metrics, such as interquartile mean scores, to achieve small
uncertainty in results. Using such statistical tools, we scrutinize performance
evaluations of existing algorithms on other widely used RL benchmarks including
the ALE, Procgen, and the DeepMind Control Suite, again revealing discrepancies
in prior comparisons. Our findings call for a change in how we evaluate
performance in deep RL, for which we present a more rigorous evaluation
methodology, accompanied with an open-source library rliable, to prevent
unreliable results from stagnating the field.

    

### [[2110.01458] Designing Complex Experiments by Applying Unsupervised Machine Learning](http://arxiv.org/abs/2110.01458)


  Design of experiments (DOE) is playing an essential role in learning and
improving a variety of objects and processes. The article discusses the
application of unsupervised machine learning to support the pragmatic designs
of complex experiments. Complex experiments are characterized by having a large
number of factors, mixed-level designs, and may be subject to constraints that
eliminate some unfeasible trials for various reasons. Having such attributes,
it is very challenging to design pragmatic experiments that are economically,
operationally, and timely sound. It means a significant decrease in the number
of required trials from a full factorial design, while still attempting to
achieve the defined objectives. A beta variational autoencoder (beta-VAE) has
been applied to represent trials of the initial full factorial design after
filtering out unfeasible trials on the low dimensional latent space. Regarding
visualization and interpretability, the paper is limited to 2D representations.
Beta-VAE supports (1) orthogonality of the latent space dimensions, (2)
isotropic multivariate standard normal distribution of the representation on
the latent space, (3) disentanglement of the latent space representation by
levels of factors, (4) propagation of the applied constraints of the initial
design into the latent space, and (5) generation of trials by decoding latent
space points. Having an initial design representation on the latent space with
such properties, it allows for the generation of pragmatic design of
experiments (G-DOE) by specifying the number of trials and their pattern on the
latent space, such as square or polar grids. Clustering and aggregated gradient
metrics have been shown to guide grid specification.

    

### [[2105.06872] Revizor: Testing Black-box CPUs against Speculation Contracts](http://arxiv.org/abs/2105.06872)


  Speculative vulnerabilities such as Spectre and Meltdown expose speculative
execution state that can be exploited to leak information across security
domains via side-channels. Such vulnerabilities often stay undetected for a
long time as we lack the tools for systematic testing of CPUs to find them.
In this paper, we propose an approach to automatically detect
microarchitectural information leakage in commercial black-box CPUs. We build
on speculation contracts, which we employ to specify the permitted side effects
of program execution on the CPU's microarchitectural state. We propose a
Model-based Relational Testing (MRT) technique to empirically assess the CPU
compliance with these specifications.
We implement MRT in a testing framework called Revizor, and showcase its
effectiveness on real Intel x86 CPUs. Revizor automatically detects violations
of a rich set of contracts, or indicates their absence. A highlight of our
findings is that Revizor managed to automatically surface Spectre, MDS, and
LVI, as well as several previously unknown variants.

    

### [[2110.02481] Massively Parallel Probabilistic Computing with Sparse Ising Machines](http://arxiv.org/abs/2110.02481)


  Inspired by the developments in quantum computing, building quantum-inspired
classical hardware to solve computationally hard problems has been receiving
increasing attention. By introducing systematic sparsification techniques, we
propose and demonstrate a massively parallel architecture, termed sIM or the
sparse Ising Machine. Exploiting the sparsity of the resultant problem graphs,
the sIM achieves ideal parallelism: the key figure of merit $-$ flips per
second $-$ scales linearly with the total number of probabilistic bits (p-bit)
in the system. This makes sIM up to 6 orders of magnitude faster than a CPU
implementing standard Gibbs sampling. When compared to optimized
implementations in TPUs and GPUs, the sIM delivers up to ~ 5 - 18x measured
speedup. In benchmark combinatorial optimization problems such as integer
factorization, the sIM can reliably factor semi-primes up to 32-bits, far
larger than previous attempts from D-Wave and other probabilistic solvers.
Strikingly, the sIM beats competition-winning SAT solvers (by up to ~ 4 - 700x
in runtime to reach 95% accuracy) in solving hard instances of the 3SAT
problem. A surprising observation is that even when the asynchronous sampling
is made inexact with simultaneous updates using faster clocks, sIM can find the
correct ground state with further speedup. The problem encoding and
sparsification techniques we introduce can be readily applied to other Ising
Machines (classical and quantum) and the asynchronous architecture we present
can be used for scaling the demonstrated 5,000$-$10,000 p-bits to 1,000,000 or
more through CMOS or emerging nanodevices.

    

### [[2009.07834] Immutable Log Storage as a Service on Private and Public Blockchains](http://arxiv.org/abs/2009.07834)


  Service Level Agreements (SLA) are employed to ensure the performance of
Cloud solutions. When a component fails, the importance of logs increases
significantly. All departments may turn to logs to determine the cause of the
issue and find the party at fault. The party at fault may be motivated to
tamper with the logs to hide their role. We argue that the critical nature of
Cloud logs calls for immutability and verification mechanism without the
presence of a single trusted party.
This paper proposes such a mechanism by describing a blockchain-based log
storage system, called Logchain, which can be integrated with existing private
and public blockchain solutions. Logchain uses the immutability feature of
blockchain to provide a tamper-resistance platform for log storage.
Additionally, we propose a hierarchical structure to address blockchains'
scalability issues. To validate the mechanism, we integrate Logchain into
Ethereum and IBM Blockchain. We show that the solution is scalable and perform
the analysis of the cost of ownership to help a reader select an implementation
that would address their needs.
The Logchain's scalability improvement on a blockchain is achieved without
any alteration of blockchains' fundamental architecture. As shown in this work,
it can function on private and public blockchains and, therefore, can be a
suitable alternative for organizations that need a secure, immutable log
storage platform.

    

### [[2103.09801] Real-Time Fault-Tolerance Node-to-Node Disjoint Paths Algorithm for Symmetric Networks](http://arxiv.org/abs/2103.09801)


  Disjoint paths are defined as paths between the source and destination nodes
where the intermediate nodes in any two paths are disjoint. They are helpful in
fault-tolerance routing and securing message distribution in the network.
Several research papers were proposed to solve the problem of finding disjoint
paths for variety of interconnection networks such as Hypercube, Generalized
Hypercube, Mesh, Torus, Gaussian, Eisenstein-Jacobi, and many other topologies.
In this research, we have developed a general real-time fault-tolerance
algorithm that constructs all node-to-node disjoint paths for symmetric
networks where all paths are shortest or close to shortest. In addition, we
have simulated the proposed algorithm on different networks. The solution of
unsolved problem in Cube-Connected-Cycles is given in the simulation results.

    

### [[2106.15531] The Power of Alignment-Free Histogram-based Functions: a Comprehensive Genome Scale Experimental Analysis -- Version 2](http://arxiv.org/abs/2106.15531)


  Motivation: Alignment-free (AF) distance/similarity functions are a key tool
for sequence analysis. Experimental studies on real datasets abound and, to
some extent, there are also studies regarding their control of false positive
rate (Type I error). However, assessment of their power, i.e., their ability to
identify true similarity, has been limited to some members of the D2 family by
experimental studies on short sequences, not adequate for current applications,
where sequence lengths may vary considerably. Such a State of the Art is
methodologically problematic, since information regarding a key feature such as
power is either missing or limited. Results: By concentrating on a
representative set of word-frequency based AF functions, we perform the first
coherent and uniform evaluation of the power, involving also Type I error for
completeness. Two Alternative models of important genomic features (CIS
Regulatory Modules and Horizontal Gene Transfer), a wide range of sequence
lengths from a few thousand to millions, and different values of k have been
used. As a result, we provide a characterization of those AF functions that is
novel and informative. Indeed, we identify weak and strong points of each
function considered, which may be used as a guide to choose one for analysis
tasks. Remarkably, of the fifteen functions that we have considered, only four
stand out, with small differences between small and short sequence length
scenarios. Finally, in order to encourage the use of our methodology for
validation of future AF functions, the Big Data platform supporting it is
public.

    

### [[2110.02270] Transformer Assisted Convolutional Network for Cell Instance Segmentation](http://arxiv.org/abs/2110.02270)


  Region proposal based methods like R-CNN and Faster R-CNN models have proven
to be extremely successful in object detection and segmentation tasks.
Recently, Transformers have also gained popularity in the domain of Computer
Vision, and are being utilised to improve the performance of conventional
models. In this paper, we present a relatively new transformer based approach
to enhance the performance of the conventional convolutional feature extractor
in the existing region proposal based methods. Our approach merges the
convolutional feature maps with transformer-based token embeddings by applying
a projection operation similar to self-attention in transformers. The results
of our experiments show that transformer assisted feature extractor achieves a
significant improvement in mIoU (mean Intersection over Union) scores compared
to vanilla convolutional backbone.

    

### [[2110.02325] Unifying AI Algorithms with Probabilistic Programming using Implicitly Defined Representations](http://arxiv.org/abs/2110.02325)


  We introduce Scruff, a new framework for developing AI systems using
probabilistic programming. Scruff enables a variety of representations to be
included, such as code with stochastic choices, neural networks, differential
equations, and constraint systems. These representations are defined implicitly
using a set of standardized operations that can be performed on them.
General-purpose algorithms are then implemented using these operations,
enabling generalization across different representations. Zero, one, or more
operation implementations can be provided for any given representation, giving
algorithms the flexibility to use the most appropriate available
implementations for their purposes and enabling representations to be used in
ways that suit their capabilities. In this paper, we explain the general
approach of implicitly defined representations and provide a variety of
examples of representations at varying degrees of abstraction. We also show how
a relatively small set of operations can serve to unify a variety of AI
algorithms. Finally, we discuss how algorithms can use policies to choose which
operation implementations to use during execution.

    

### [[2110.02370] Leveraging the Inductive Bias of Large Language Models for Abstract Textual Reasoning](http://arxiv.org/abs/2110.02370)


  Large natural language models (such as GPT-3 or T5) demonstrate impressive
abilities across a range of general NLP tasks. Here, we show that the knowledge
embedded in such models provides a useful inductive bias, not just on
traditional NLP tasks, but also in the nontraditional task of training a
symbolic reasoning engine. We observe that these engines learn quickly and
generalize in a natural way that reflects human intuition. For example,
training such a system to model block-stacking might naturally generalize to
stacking other types of objects because of structure in the real world that has
been partially captured by the language describing it. We study several
abstract textual reasoning tasks, such as object manipulation and navigation,
and demonstrate multiple types of generalization to novel scenarios and the
symbols that comprise them. We also demonstrate the surprising utility of
\textit{compositional learning}, where a learner dedicated to mastering a
complicated task gains an advantage by training on relevant simpler tasks
instead of jumping straight to the complicated task.

    

### [[2110.02376] Foundations of Symbolic Languages for Model Interpretability](http://arxiv.org/abs/2110.02376)


  Several queries and scores have recently been proposed to explain individual
predictions over ML models. Given the need for flexible, reliable, and
easy-to-apply interpretability methods for ML models, we foresee the need for
developing declarative languages to naturally specify different explainability
queries. We do this in a principled way by rooting such a language in a logic,
called FOIL, that allows for expressing many simple but important
explainability queries, and might serve as a core for more expressive
interpretability languages. We study the computational complexity of FOIL
queries over two classes of ML models often deemed to be easily interpretable:
decision trees and OBDDs. Since the number of possible inputs for an ML model
is exponential in its dimension, the tractability of the FOIL evaluation
problem is delicate but can be achieved by either restricting the structure of
the models or the fragment of FOIL being evaluated. We also present a prototype
implementation of FOIL wrapped in a high-level declarative language and perform
experiments showing that such a language can be used in practice.

    

### [[2110.02386] Analyzing the Effects of Reasoning Types on Cross-Lingual Transfer Performance](http://arxiv.org/abs/2110.02386)


  Multilingual language models achieve impressive zero-shot accuracies in many
languages in complex tasks such as Natural Language Inference (NLI). Examples
in NLI (and equivalent complex tasks) often pertain to various types of
sub-tasks, requiring different kinds of reasoning. Certain types of reasoning
have proven to be more difficult to learn in a monolingual context, and in the
crosslingual context, similar observations may shed light on zero-shot transfer
efficiency and few-shot sample selection. Hence, to investigate the effects of
types of reasoning on transfer performance, we propose a category-annotated
multilingual NLI dataset and discuss the challenges to scale monolingual
annotations to multiple languages. We statistically observe interesting effects
that the confluence of reasoning types and language similarities have on
transfer performance.

    

### [[2110.02432] Federated Distillation of Natural Language Understanding with Confident Sinkhorns](http://arxiv.org/abs/2110.02432)


  Enhancing the user experience is an essential task for application service
providers. For instance, two users living wide apart may have different tastes
of food. A food recommender mobile application installed on an edge device
might want to learn from user feedback (reviews) to satisfy the client's needs
pertaining to distinct domains. Retrieving user data comes at the cost of
privacy while asking for model parameters trained on a user device becomes
space inefficient at a large scale. In this work, we propose an approach to
learn a central (global) model from the federation of (local) models which are
trained on user-devices, without disclosing the local data or model parameters
to the server. We propose a federation mechanism for the problems with natural
similarity metric between the labels which commonly appear in natural language
understanding (NLU) tasks. To learn the global model, the objective is to
minimize the optimal transport cost of the global model's predictions from the
confident sum of soft-targets assigned by local models. The confidence (a model
weighting scheme) score of a model is defined as the L2 distance of a model's
prediction from its probability bias. The method improves the global model's
performance over the baseline designed on three NLU tasks with intrinsic label
space semantics, i.e., fine-grained sentiment analysis, emotion recognition in
conversation, and natural language inference. We make our codes public at
this https URL.

    

### [[2110.02450] Reward-Punishment Symmetric Universal Intelligence](http://arxiv.org/abs/2110.02450)


  Can an agent's intelligence level be negative? We extend the Legg-Hutter
agent-environment framework to include punishments and argue for an affirmative
answer to that question. We show that if the background encodings and Universal
Turing Machine (UTM) admit certain Kolmogorov complexity symmetries, then the
resulting Legg-Hutter intelligence measure is symmetric about the origin. In
particular, this implies reward-ignoring agents have Legg-Hutter intelligence 0
according to such UTMs.

    

### [[2110.02467] BadPre: Task-agnostic Backdoor Attacks to Pre-trained NLP Foundation Models](http://arxiv.org/abs/2110.02467)


  Pre-trained Natural Language Processing (NLP) models can be easily adapted to
a variety of downstream language tasks. This significantly accelerates the
development of language models. However, NLP models have been shown to be
vulnerable to backdoor attacks, where a pre-defined trigger word in the input
text causes model misprediction. Previous NLP backdoor attacks mainly focus on
some specific tasks. This makes those attacks less general and applicable to
other kinds of NLP models and tasks. In this work, we propose \Name, the first
task-agnostic backdoor attack against the pre-trained NLP models. The key
feature of our attack is that the adversary does not need prior information
about the downstream tasks when implanting the backdoor to the pre-trained
model. When this malicious model is released, any downstream models transferred
from it will also inherit the backdoor, even after the extensive transfer
learning process. We further design a simple yet effective strategy to bypass a
state-of-the-art defense. Experimental results indicate that our approach can
compromise a wide range of downstream NLP tasks in an effective and stealthy
way.

    

### [[2110.02480] Efficient Multi-agent Epistemic Planning: Teaching Planners About Nested Belief](http://arxiv.org/abs/2110.02480)


  Many AI applications involve the interaction of multiple autonomous agents,
requiring those agents to reason about their own beliefs, as well as those of
other agents. However, planning involving nested beliefs is known to be
computationally challenging. In this work, we address the task of synthesizing
plans that necessitate reasoning about the beliefs of other agents. We plan
from the perspective of a single agent with the potential for goals and actions
that involve nested beliefs, non-homogeneous agents, co-present observations,
and the ability for one agent to reason as if it were another. We formally
characterize our notion of planning with nested belief, and subsequently
demonstrate how to automatically convert such problems into problems that
appeal to classical planning technology for solving efficiently. Our approach
represents an important step towards applying the well-established field of
automated planning to the challenging task of planning involving nested beliefs
of multiple agents.

    

### [[2110.02610] Tackling the DM Challenges with cDMN: A Tight Integration of DMN and Constraint Reasoning](http://arxiv.org/abs/2110.02610)


  Knowledge-based AI typically depends on a knowledge engineer to construct a
formal model of domain knowledge -- but what if domain experts could do this
themselves? This paper describes an extension to the Decision Model and
Notation (DMN) standard, called Constraint Decision Model and Notation (cDMN).
DMN is a user-friendly, table-based notation for decision logic, which allows
domain experts to model simple decision procedures without the help of IT
staff. cDMN aims to enlarge the expressiveness of DMN in order to model more
complex domain knowledge, while retaining DMN's goal of being understandable by
domain experts. We test cDMN by solving the most complex challenges posted on
the DM Community website. We compare our own cDMN solutions to the solutions
that have been submitted to the website and find that our approach is
competitive. Moreover, cDMN is able to solve more challenges than any other
approach.

    

### [[2110.02623] Is An Image Worth Five Sentences? A New Look into Semantics for Image-Text Matching](http://arxiv.org/abs/2110.02623)


  The task of image-text matching aims to map representations from different
modalities into a common joint visual-textual embedding. However, the most
widely used datasets for this task, MSCOCO and Flickr30K, are actually image
captioning datasets that offer a very limited set of relationships between
images and sentences in their ground-truth annotations. This limited ground
truth information forces us to use evaluation metrics based on binary
relevance: given a sentence query we consider only one image as relevant.
However, many other relevant images or captions may be present in the dataset.
In this work, we propose two metrics that evaluate the degree of semantic
relevance of retrieved items, independently of their annotated binary
relevance. Additionally, we incorporate a novel strategy that uses an image
captioning metric, CIDEr, to define a Semantic Adaptive Margin (SAM) to be
optimized in a standard triplet loss. By incorporating our formulation to
existing models, a \emph{large} improvement is obtained in scenarios where
available training data is limited. We also demonstrate that the performance on
the annotated image-caption pairs is maintained while improving on other
non-annotated relevant items when employing the full training set. Code with
our metrics and adaptive margin formulation will be made public.

    

### [[2110.02624] CLIP-Forge: Towards Zero-Shot Text-to-Shape Generation](http://arxiv.org/abs/2110.02624)


  While recent progress has been made in text-to-image generation,
text-to-shape generation remains a challenging problem due to the
unavailability of paired text and shape data at a large scale. We present a
simple yet effective method for zero-shot text-to-shape generation based on a
two-stage training process, which only depends on an unlabelled shape dataset
and a pre-trained image-text network such as CLIP. Our method not only
demonstrates promising zero-shot generalization, but also avoids expensive
inference time optimization and can generate multiple shapes for a given text.

    

### [[2110.02640] Bach Style Music Authoring System based on Deep Learning](http://arxiv.org/abs/2110.02640)


  With the continuous improvement in various aspects in the field of artificial
intelligence, the momentum of artificial intelligence with deep learning
capabilities into the field of music is coming. The research purpose of this
paper is to design a Bach style music authoring system based on deep learning.
We use a LSTM neural network to train serialized and standardized music feature
data. By repeated experiments, we find the optimal LSTM model which can
generate imitation of Bach music. Finally the generated music is
comprehensively evaluated in the form of online audition and Turing test. The
repertoires which the music generation system constructed in this article are
very close to the style of Bach's original music, and it is relatively
difficult for ordinary people to distinguish the musics Bach authored and AI
created.

    

### [[2110.02687] Objects in Semantic Topology](http://arxiv.org/abs/2110.02687)


  A more realistic object detection paradigm, Open-World Object Detection, has
arisen increasing research interests in the community recently. A qualified
open-world object detector can not only identify objects of known categories,
but also discover unknown objects, and incrementally learn to categorize them
when their annotations progressively arrive. Previous works rely on independent
modules to recognize unknown categories and perform incremental learning,
respectively. In this paper, we provide a unified perspective: Semantic
Topology. During the life-long learning of an open-world object detector, all
object instances from the same category are assigned to their corresponding
pre-defined node in the semantic topology, including the `unknown' category.
This constraint builds up discriminative feature representations and consistent
relationships among objects, thus enabling the detector to distinguish unknown
objects out of the known categories, as well as making learned features of
known objects undistorted when learning new categories incrementally. Extensive
experiments demonstrate that semantic topology, either randomly-generated or
derived from a well-trained language model, could outperform the current
state-of-the-art open-world object detectors by a large margin, e.g., the
absolute open-set error is reduced from 7832 to 2546, exhibiting the inherent
superiority of semantic topology on open-world object detection.

    

### [[2110.02707] Trustworthy Artificial Intelligence and Process Mining: Challenges and Opportunities](http://arxiv.org/abs/2110.02707)


  The premise of this paper is that compliance with Trustworthy AI governance
best practices and regulatory frameworks is an inherently fragmented process
spanning across diverse organizational units, external stakeholders, and
systems of record, resulting in process uncertainties and in compliance gaps
that may expose organizations to reputational and regulatory risks. Moreover,
there are complexities associated with meeting the specific dimensions of
Trustworthy AI best practices such as data governance, conformance testing,
quality assurance of AI model behaviors, transparency, accountability, and
confidentiality requirements. These processes involve multiple steps,
hand-offs, re-works, and human-in-the-loop oversight. In this paper, we
demonstrate that process mining can provide a useful framework for gaining
fact-based visibility to AI compliance process execution, surfacing compliance
bottlenecks, and providing for an automated approach to analyze, remediate and
monitor uncertainty in AI regulatory compliance processes.

    

### [[2110.02776] SIRe-Networks: Skip Connections over Interlaced Multi-Task Learning and Residual Connections for Structure Preserving Object Classification](http://arxiv.org/abs/2110.02776)


  Improving existing neural network architectures can involve several design
choices such as manipulating the loss functions, employing a diverse learning
strategy, exploiting gradient evolution at training time, optimizing the
network hyper-parameters, or increasing the architecture depth. The latter
approach is a straightforward solution, since it directly enhances the
representation capabilities of a network; however, the increased depth
generally incurs in the well-known vanishing gradient problem. In this paper,
borrowing from different methods addressing this issue, we introduce an
interlaced multi-task learning strategy, defined SIRe, to reduce the vanishing
gradient in relation to the object classification task. The presented
methodology directly improves a convolutional neural network (CNN) by enforcing
the input image structure preservation through interlaced auto-encoders, and
further refines the base network architecture by means of skip and residual
connections. To validate the presented methodology, a simple CNN and various
implementations of famous networks are extended via the SIRe strategy and
extensively tested on the CIFAR100 dataset; where the SIRe-extended
architectures achieve significantly increased performances across all models,
thus confirming the presented approach effectiveness.

    

### [[2110.02793] Multi-Agent Constrained Policy Optimisation](http://arxiv.org/abs/2110.02793)


  Developing reinforcement learning algorithms that satisfy safety constraints
is becoming increasingly important in real-world applications. In multi-agent
reinforcement learning (MARL) settings, policy optimisation with safety
awareness is particularly challenging because each individual agent has to not
only meet its own safety constraints, but also consider those of others so that
their joint behaviour can be guaranteed safe. Despite its importance, the
problem of safe multi-agent learning has not been rigorously studied; very few
solutions have been proposed, nor a sharable testing environment or benchmarks.
To fill these gaps, in this work, we formulate the safe MARL problem as a
constrained Markov game and solve it with policy optimisation methods. Our
solutions -- Multi-Agent Constrained Policy Optimisation (MACPO) and
MAPPO-Lagrangian -- leverage the theories from both constrained policy
optimisation and multi-agent trust region learning. Crucially, our methods
enjoy theoretical guarantees of both monotonic improvement in reward and
satisfaction of safety constraints at every iteration. To examine the
effectiveness of our methods, we develop the benchmark suite of Safe
Multi-Agent MuJoCo that involves a variety of MARL baselines. Experimental
results justify that MACPO/MAPPO-Lagrangian can consistently satisfy safety
constraints, meanwhile achieving comparable performance to strong baselines.

    

### [[2110.02814] Efficient and High-quality Prehensile Rearrangement in Cluttered and Confined Spaces](http://arxiv.org/abs/2110.02814)


  Prehensile object rearrangement in cluttered and confined spaces has broad
applications but is also challenging. For instance, rearranging products in a
grocery or home shelf means that the robot cannot directly access all objects
and has limited free space. This is harder than tabletop rearrangement where
objects are easily accessible with top-down grasps, which simplifies
robot-object interactions. This work focuses on problems where such
interactions are critical for completing tasks and extends state-of-the-art
results in rearrangement planning. It proposes a new efficient and complete
solver under general constraints for monotone instances, which can be solved by
moving each object at most once. The monotone solver reasons about robot-object
constraints and uses them to effectively prune the search space. The new
monotone solver is integrated with a global planner to solve non-monotone
instances with high-quality solutions fast. Furthermore, this work contributes
an effective pre-processing tool to speed up arm motion planning for
rearrangement in confined spaces. The pre-processing tool provide significant
speed-ups (49.1% faster on average) in online query resolution. Comparisons in
simulations further demonstrate that the proposed monotone solver, equipped
with the pre-processing tool, results in 57.3% faster computation and 3 times
higher success rate than alternatives. Similarly, the resulting global planner
is computationally more efficient and has a higher success rate given the more
powerful monotone solver and the pre-processing tool, while producing
high-quality solutions for non-monotone instances (i.e., only 1.3 buffers are
needed on average). Videos of demonstrating solutions on a real robotic system
and codes can be found at
this https URL.

    

### [[2110.02834] Relation Prediction as an Auxiliary Training Objective for Improving Multi-Relational Graph Representations](http://arxiv.org/abs/2110.02834)


  Learning good representations on multi-relational graphs is essential to
knowledge base completion (KBC). In this paper, we propose a new
self-supervised training objective for multi-relational graph representation
learning, via simply incorporating relation prediction into the commonly used
1vsAll objective. The new training objective contains not only terms for
predicting the subject and object of a given triple, but also a term for
predicting the relation type. We analyse how this new objective impacts
multi-relational learning in KBC: experiments on a variety of datasets and
models show that relation prediction can significantly improve entity ranking,
the most widely used evaluation task for KBC, yielding a 6.1% increase in MRR
and 9.9% increase in Hits@1 on FB15k-237 as well as a 3.1% increase in MRR and
3.4% in Hits@1 on Aristo-v4. Moreover, we observe that the proposed objective
is especially effective on highly multi-relational datasets, i.e. datasets with
a large number of predicates, and generates better representations when larger
embedding sizes are used.

    

### [[2110.02871] ClimateGAN: Raising Climate Change Awareness by Generating Images of Floods](http://arxiv.org/abs/2110.02871)


  Climate change is a major threat to humanity, and the actions required to
prevent its catastrophic consequences include changes in both policy-making and
individual behaviour. However, taking action requires understanding the effects
of climate change, even though they may seem abstract and distant. Projecting
the potential consequences of extreme climate events such as flooding in
familiar places can help make the abstract impacts of climate change more
concrete and encourage action. As part of a larger initiative to build a
website that projects extreme climate events onto user-chosen photos, we
present our solution to simulate photo-realistic floods on authentic images. To
address this complex task in the absence of suitable training data, we propose
ClimateGAN, a model that leverages both simulated and real data for
unsupervised domain adaptation and conditional image generation. In this paper,
we describe the details of our framework, thoroughly evaluate components of our
architecture and demonstrate that our model is capable of robustly generating
photo-realistic flooding.

    

### [[2002.01080] Bridging the Gap: Providing Post-Hoc Symbolic Explanations for Sequential Decision-Making Problems with Inscrutable Representations](http://arxiv.org/abs/2002.01080)


  As increasingly complex AI systems are introduced into our daily lives, it
becomes important for such systems to be capable of explaining the rationale
for their decisions and allowing users to contest these decisions. A
significant hurdle to allowing for such explanatory dialogue could be the
vocabulary mismatch between the user and the AI system. This paper introduces
methods for providing contrastive explanations in terms of user-specified
concepts for sequential decision-making settings where the system's model of
the task may be best represented as an inscrutable model. We do this by
building partial symbolic models of a local approximation of the task that can
be leveraged to answer the user queries. We test these methods on a popular
Atari game (Montezuma's Revenge) and variants of Sokoban (a well-known planning
benchmark) and report the results of user studies to evaluate whether people
find explanations generated in this form useful.

    

### [[2106.00266] Did I do that? Blame as a means to identify controlled effects in reinforcement learning](http://arxiv.org/abs/2106.00266)


  Identifying controllable aspects of the environment has proven to be an
extraordinary intrinsic motivator to reinforcement learning agents. Despite
repeatedly achieving State-of-the-Art results, this approach has only been
studied as a proxy to a reward-based task and has not yet been evaluated on its
own. We show that solutions relying on action-prediction fail to model critical
controlled events. Humans, on the other hand, assign blame to their actions to
decide what they controlled. This work proposes Controlled Effect Network
(CEN), an unsupervised method based on counterfactual measures of blame to
identify effects on the environment controlled by the agent. CEN is evaluated
in a wide range of environments showing that it can accurately identify
controlled effects. Moreover, we demonstrate CEN's capabilities as intrinsic
motivator by integrating it in the state-of-the-art exploration method,
achieving substantially better performance than action-prediction models.

    

### [[2106.10561] EMG Signal Classification Using Reflection Coefficients and Extreme Value Machine](http://arxiv.org/abs/2106.10561)


  Electromyography is a promising approach to the gesture recognition of humans
if an efficient classifier with high accuracy is available. In this paper, we
propose to utilize Extreme Value Machine (EVM) as a high-performance algorithm
for the classification of EMG signals. We employ reflection coefficients
obtained from an Autoregressive (AR) model to train a set of classifiers. Our
experimental results indicate that EVM has better accuracy in comparison to the
conventional classifiers approved in the literature based on K-Nearest
Neighbors (KNN) and Support Vector Machine (SVM).

    

### [[2110.01434] A curated, ontology-based, large-scale knowledge graph of artificial intelligence tasks and benchmarks](http://arxiv.org/abs/2110.01434)


  Research in artificial intelligence (AI) is addressing a growing number of
tasks through a rapidly growing number of models and methodologies. This makes
it difficult to keep track of where novel AI methods are successfully -- or
still unsuccessfully -- applied, how progress is measured, how different
advances might synergize with each other, and how future research should be
prioritized.
To help address these issues, we created the Intelligence Task Ontology and
Knowledge Graph (ITO), a comprehensive, richly structured and manually curated
resource on artificial intelligence tasks, benchmark results and performance
metrics. The current version of ITO contain 685,560 edges, 1,100 classes
representing AI processes and 1,995 properties representing performance
metrics.
The goal of ITO is to enable precise and network-based analyses of the global
landscape of AI tasks and capabilities. ITO is based on technologies that allow
for easy integration and enrichment with external data, automated inference and
continuous, collaborative expert curation of underlying ontological models. We
make the ITO dataset and a collection of Jupyter notebooks utilising ITO openly
available.

    

### [[2110.02769] Visibility Reasoning for Concurrent Snapshot Algorithms](http://arxiv.org/abs/2110.02769)


  Visibility relations have been proposed by Henzinger et al. as an abstraction
for proving linearizability of concurrent algorithms that obtains modular and
reusable proofs. This is in contrast to the customary approach based on
exhibiting the algorithm's linearization points. In this paper we apply
visibility relations to develop modular proofs for three elegant concurrent
snapshot algorithms of Jayanti. The proofs are divided into components of
increasing level of abstraction, using type-theoretic notions of signatures and
functors (i.e., dependent $\Sigma$ and $\Pi$ types) as interfaces. The proofs
are modular because the components at higher abstraction levels are shared,
i.e., they apply to all three algorithms simultaneously. Importantly, the
interface properties mathematically capture Jayanti's original intuitions that
have previously been given only informally.

    

### [<title>Error during installation R GPU win64: 'R' is not recognized as an internal or external command, operable program or batch file - XGBoost</title>](https://discuss.xgboost.ai/t/error-during-installation-r-gpu-win64-r-is-not-recognized-as-an-internal-or-external-command-operable-program-or-batch-file/2487/6)

### [<title>Error during installation R GPU win64: 'R' is not recognized as an internal or external command, operable program or batch file - XGBoost</title>](https://discuss.xgboost.ai/t/error-during-installation-r-gpu-win64-r-is-not-recognized-as-an-internal-or-external-command-operable-program-or-batch-file/2487/5)