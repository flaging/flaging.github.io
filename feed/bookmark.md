
## 2021-12-13

### [<title>C API make install - RFC - XGBoost</title>](https://discuss.xgboost.ai/t/c-api-make-install/2589/6)

### [[2112.05199] This internet, on the ground](http://arxiv.org/abs/2112.05199)


  The internet's key points of global control lie in the hands of a few people,
primarily private organizations based in the United States. These control
points, as they exist today, raise structural risks to the global internet's
long-term stability. I argue: the problem isn't that these control points
exist, it's that there is no popular governance over them. I advocate for a
localist approach to internet governance: small internets deployed on municipal
scales, interoperating selectively, carefully, with this internet and one
another.

    

### [[2112.05286] SmartCon: Deep Probabilistic Learning Based Intelligent Link-Configuration in Narrowband-IoT Towards 5G and B5G](http://arxiv.org/abs/2112.05286)


  To enhance the coverage and transmission reliability, repetitions adopted by
Narrowband Internet of Things (NB-IoT) allow repeating transmissions several
times. However, this results in a waste of radio resources when the signal
strength is high. In addition, in low signal quality, the selection of a higher
modulation and coding scheme (MCS) level leads to a huge packet loss in the
network. Moreover, the number of physical resource blocks (PRBs) per-user needs
to be chosen dynamically, such that the utilization of radio resources can be
improved on per-user basis. Therefore, in NB-IoT systems, dynamic adaptation of
repetitions, MCS, and radio resources, known as auto link-configuration, is
crucial. Accordingly, in this paper, we propose SmartCon which is a Generative
Adversarial Network (GAN)-based deep learning approach for auto
link-configuration during uplink or downlink scheduling, such that the packet
loss rate is significantly reduced in NB-IoT networks. For the training purpose
of the GAN, we use a Multi-Armed Bandit (MAB)-based reinforcement learning
mechanism that intelligently tunes its output depending on the present network
condition. The performance of SmartCon is thoroughly evaluated through
simulations where it is shown to significantly improve the performance of
NB-IoT systems compared to baseline schemes.

    

### [[2112.05450] Evaluating BDP FRAME extension for QUIC](http://arxiv.org/abs/2112.05450)


  The first version of QUIC has recently been standardized by the IETF. The
framework of QUIC enables the proposition, negociation and exploitation of
extensions to adapt some of its mechanisms. As one example, the DATAGRAM
extension enables the unreliable transmission of data. The BDP FRAME extension
is a method that can improve traffic delivery by allowing a QUIC connection to
remember the knowledge of path characteristics and exploit them when resuming a
session. This technical report presents the rationale behind fast convergence
in SATCOM systems and evaluate the BDP FRAME extension in emulated and live
environments.

    

### [[2112.05593] A Review of Indoor Millimeter Wave Device-based Localization and Device-free Sensing Technologies](http://arxiv.org/abs/2112.05593)


  The commercial availability of low-cost millimeter wave (mmWave)
communication and radar devices is starting to improve the penetration of such
technologies in consumer markets, paving the way for large-scale and dense
deployments in fifth-generation (5G)-and-beyond as well as 6G networks. At the
same time, pervasive mmWave access will enable device localization and
device-free sensing with unprecedented accuracy, especially with respect to
sub-6 GHz commercial-grade devices. This paper surveys the state of the art in
device-based localization and device-free sensing using mmWave communication
and radar devices, with a focus on indoor deployments. We first overview key
concepts about mmWave signal propagation and system design. Then, we provide a
detailed account of approaches and algorithms for localization and sensing
enabled by mmWaves. We consider several dimensions in our analysis, including
the main objectives, techniques, and performance of each work, whether each
research reached some degree of implementation, and which hardware platforms
were used for this purpose. We conclude by discussing that better algorithms
for consumer-grade devices, data fusion methods for dense deployments, as well
as an educated application of machine learning methods are promising, relevant
and timely research directions.

    

### [[2001.03665] Classification of Traffic Using Neural Networks by Rejecting: a Novel Approach in Classifying VPN Traffic](http://arxiv.org/abs/2001.03665)


  In this paper, we introduce a novel end-to-end traffic classification method
to distinguish between traffic classes including VPN traffic in three layers of
the Open Systems Interconnection (OSI) model. Classification of VPN traffic is
not trivial using traditional classification approaches due to its encrypted
nature. We utilize two well-known neural networks, namely multi-layer
perceptron and recurrent neural network to create our cascade neural network
focused on two metrics: class scores and distance from the center of the
classes. Such approach combines extraction, selection, and classification
functionality into a single end-to-end system to systematically learn the
non-linear relationship between input and predicted performance. Therefore, we
could distinguish VPN traffics from non-VPN traffics by rejecting the unrelated
features of the VPN class. Moreover, we obtain the application type of non-VPN
traffics at the same time. The approach is evaluated using the general traffic
dataset ISCX VPN-nonVPN, and an acquired dataset. The results demonstrate the
efficacy of the framework approach for encrypting traffic classification while
also achieving extreme accuracy, $95$ percent, which is higher than the
accuracy of the state-of-the-art models, and strong generalization
capabilities.

    

### [[2104.14589] User-centric Cell-free Massive MIMO Networks: A Survey of Opportunities, Challenges and Solutions](http://arxiv.org/abs/2104.14589)


  Densification of network base stations is indispensable to achieve the
stringent Quality of Service (QoS) requirements of future mobile networks.
However, with a dense deployment of transmitters, interference management
becomes an arduous task. To solve this issue, exploring radically new network
architectures with intelligent coordination and cooperation capabilities is
crucial. This survey paper investigates the emerging user-centric cell-free
massive Multiple-input multiple-output (MIMO) network architecture that sets a
foundation for future mobile networks. Such networks use a dense deployment of
distributed units (DUs) to serve users; the crucial difference from the
traditional cellular paradigm is that a specific serving cluster of DUs is
defined for each user. This framework provides macro diversity, power
efficiency, interference management, and robust connectivity. Most importantly,
the user-centric approach eliminates cell edges, thus contributing to uniform
coverage and performance for users across the network area. We present here a
guide to the key challenges facing the deployment of this network scheme and
contemplate the solutions being proposed for the main bottlenecks facing
cell-free communications. Specifically, we survey the literature targeting the
fronthaul, then we scan the details of the channel estimation required,
resource allocation, delay, and scalability issues. Furthermore, we highlight
some technologies that can provide a management platform for this scheme such
as distributed software-defined network (SDN). Our article serves as a check
point that delineates the current status and indicates future directions for
this area in a comprehensive manner.

    

### [[2105.14221] On the Performance of Blockchain-enabled RAN-as-a-service in Beyond 5G Networks](http://arxiv.org/abs/2105.14221)


  Blockchain (BC) technology can revolutionize the future of communications by
enabling decentralized and open sharing networks. In this paper, we propose the
application of BC to facilitate Mobile Network Operators (MNOs) and other
players such as Verticals or Over-The-Top (OTT) service providers to exchange
Radio Access Network (RAN) resources (e.g., infrastructure, spectrum) in a
secure, flexible and autonomous manner. In particular, we propose a BC-enabled
reverse auction mechanism for RAN sharing and dynamic users' service provision
in Beyond 5G networks, and we analyze its potential advantages with respect to
current service provisioning and RAN sharing schemes. Moreover, we study the
delay and overheads incurred by the BC in the whole process, when running over
both wireless and wired interfaces.

    

### [[2107.02005] Blockchain-enabled Network Sharing for O-RAN in 5G and Beyond](http://arxiv.org/abs/2107.02005)


  The innovation provided by network virtualization in 5G, together with
standardization and openness boosted by the Open Radio Access Network (O-RAN)
Alliance, has paved the way to a collaborative future in cellular systems,
driven by flexible network sharing. Such advents are expected to attract new
players like content providers and verticals, increasing competitiveness in the
telecom market. However, scalability and trust issues are expected to arise,
given the criticality of ownership traceability and resource exchanging in a
sharing ecosystem. To address that, we propose integrating blockchain
technology for enabling mobile operators and other players to exchange RAN
resources (e.g., infrastructure) in the form of virtual network functions (VNF)
autonomously and dynamically. Blockchain will provide automation, robustness,
trustworthiness, and reliability to mobile networks, thus bringing confidence
to open RAN environments. In particular, we define a novel O-RAN-based
blockchain-enabled architecture that allows automating RAN sharing procedures
through either auction or marketplace-based mechanisms. The potential
advantages of the proposed solution are demonstrated through simulation
results. The used simulation platform is openly released.

    

### [[2112.05146] Come-Closer-Diffuse-Faster: Accelerating Conditional Diffusion Models for Inverse Problems through Stochastic Contraction](http://arxiv.org/abs/2112.05146)


  Diffusion models have recently attained significant interest within the
community owing to their strong performance as generative models. Furthermore,
its application to inverse problems have demonstrated state-of-the-art
performance. Unfortunately, diffusion models have a critical downside - they
are inherently slow to sample from, needing few thousand steps of iteration to
generate images from pure Gaussian noise. In this work, we show that starting
from Gaussian noise is unnecessary. Instead, starting from a single forward
diffusion with better initialization significantly reduces the number of
sampling steps in the reverse conditional diffusion. This phenomenon is
formally explained by the contraction theory of the stochastic difference
equations like our conditional diffusion strategy - the alternating
applications of reverse diffusion followed by a non-expansive data consistency
step. The new sampling strategy, dubbed Come-Closer-Diffuse-Faster (CCDF), also
reveals a new insight on how the existing feed-forward neural network
approaches for inverse problems can be synergistically combined with the
diffusion models. Experimental results with super-resolution, image inpainting,
and compressed sensing MRI demonstrate that our method can achieve
state-of-the-art reconstruction performance at significantly reduced sampling
steps.

    

### [[2112.05148] Classification of Anuran Frog Species Using Machine Learning](http://arxiv.org/abs/2112.05148)


  Acoustic classification of frogs has gotten a lot of attention recently due
to its potential applicability in ecological investigations. Numerous studies
have been presented for identifying frog species, although the majority of
recorded species are thought to be monotypic. The purpose of this study is to
demonstrate a method for classifying various frog species using an audio
recording. To be more exact, continuous frog recordings are cut into audio
snippets first (10 seconds). Then, for each ten-second recording, several
time-frequency representations are constructed. Following that, rather than
using manually created features, Machine Learning methods are employed to
classify the frog species. Data reduction techniques; Principal Component
Analysis (PCA) and Independent Component Analysis (ICA) are used to extract the
most important features before classification. Finally, to validate our
classification accuracy, cross validation and prediction accuracy are used.
Experimental results show that PCA extracted features that achieved better
classification accuracy both with cross validation and prediction accuracy.

    

### [[2112.05149] DiffuseMorph: Unsupervised Deformable Image Registration Along Continuous Trajectory Using Diffusion Models](http://arxiv.org/abs/2112.05149)


  Deformable image registration is one of the fundamental tasks for medical
imaging and computer vision. Classical registration algorithms usually rely on
iterative optimization approaches to provide accurate deformation, which
requires high computational cost. Although many deep-learning-based methods
have been developed to carry out fast image registration, it is still
challenging to estimate the deformation field with less topological folding
problem. Furthermore, these approaches only enable registration to a single
fixed image, and it is not possible to obtain continuously varying registration
results between the moving and fixed images. To address this, here we present a
novel approach of diffusion model-based probabilistic image registration,
called DiffuseMorph. Specifically, our model learns the score function of the
deformation between moving and fixed images. Similar to the existing diffusion
models, DiffuseMorph not only provides synthetic deformed images through a
reverse diffusion process, but also enables various levels of deformation of
the moving image along with the latent space. Experimental results on 2D face
expression image and 3D brain image registration tasks demonstrate that our
method can provide flexible and accurate deformation with a capability of
topology preservation.

    

### [[2112.05195] Context-aware Health Event Prediction via Transition Functions on Dynamic Disease Graphs](http://arxiv.org/abs/2112.05195)


  With the wide application of electronic health records (EHR) in healthcare
facilities, health event prediction with deep learning has gained more and more
attention. A common feature of EHR data used for deep-learning-based
predictions is historical diagnoses. Existing work mainly regards a diagnosis
as an independent disease and does not consider clinical relations among
diseases in a visit. Many machine learning approaches assume disease
representations are static in different visits of a patient. However, in real
practice, multiple diseases that are frequently diagnosed at the same time
reflect hidden patterns that are conducive to prognosis. Moreover, the
development of a disease is not static since some diseases can emerge or
disappear and show various symptoms in different visits of a patient. To
effectively utilize this combinational disease information and explore the
dynamics of diseases, we propose a novel context-aware learning framework using
transition functions on dynamic disease graphs. Specifically, we construct a
global disease co-occurrence graph with multiple node properties for disease
combinations. We design dynamic subgraphs for each patient's visit to leverage
global and local contexts. We further define three diagnosis roles in each
visit based on the variation of node properties to model disease transition
processes. Experimental results on two real-world EHR datasets show that the
proposed model outperforms state of the art in predicting health events.

    

### [[2112.05198] Reinforcement Learning with Almost Sure Constraints](http://arxiv.org/abs/2112.05198)


  In this work we address the problem of finding feasible policies for
Constrained Markov Decision Processes under probability one constraints. We
argue that stationary policies are not sufficient for solving this problem, and
that a rich class of policies can be found by endowing the controller with a
scalar quantity, so called budget, that tracks how close the agent is to
violating the constraint. We show that the minimal budget required to act
safely can be obtained as the smallest fixed point of a Bellman-like operator,
for which we analyze its convergence properties. We also show how to learn this
quantity when the true kernel of the Markov decision process is not known,
while providing sample-complexity bounds. The utility of knowing this minimal
budget relies in that it can aid in the search of optimal or near-optimal
policies by shrinking down the region of the state space the agent must
navigate. Simulations illustrate the different nature of probability one
constraints against the typically used constraints in expectation.

    

### [[2112.05210] 7th AI Driving Olympics: 1st Place Report for Panoptic Tracking](http://arxiv.org/abs/2112.05210)


  In this technical report, we describe our EfficientLPT architecture that won
the panoptic tracking challenge in the 7th AI Driving Olympics at NeurIPS 2021.
Our architecture builds upon the top-down EfficientLPS panoptic segmentation
approach. EfficientLPT consists of a shared backbone with a modified
EfficientNet-B5 model comprising the proximity convolution module as the
encoder followed by the range-aware FPN to aggregate semantically rich
range-aware multi-scale features. Subsequently, we employ two task-specific
heads, the scale-invariant semantic head and hybrid task cascade with feedback
from the semantic head as the instance head. Further, we employ a novel
panoptic fusion module to adaptively fuse logits from each of the heads to
yield the panoptic tracking output. Our approach exploits three consecutive
accumulated scans to predict locally consistent panoptic tracking IDs and also
the overlap between the scans to predict globally consistent panoptic tracking
IDs for a given sequence. The benchmarking results from the 7th AI Driving
Olympics at NeurIPS 2021 show that our model is ranked #1 for the panoptic
tracking task on the Panoptic nuScenes dataset.

    

### [[2112.05215] Road Extraction from Overhead Images with Graph Neural Networks](http://arxiv.org/abs/2112.05215)


  Automatic road graph extraction from aerial and satellite images is a
long-standing challenge. Existing algorithms are either based on pixel-level
segmentation followed by vectorization, or on iterative graph construction
using next move prediction. Both of these strategies suffer from severe
drawbacks, in particular high computing resources and incomplete outputs. By
contrast, we propose a method that directly infers the final road graph in a
single pass. The key idea consists in combining a Fully Convolutional Network
in charge of locating points of interest such as intersections, dead ends and
turns, and a Graph Neural Network which predicts links between these points.
Such a strategy is more efficient than iterative methods and allows us to
streamline the training process by removing the need for generation of starting
locations while keeping the training end-to-end. We evaluate our method against
existing works on the popular RoadTracer dataset and achieve competitive
results. We also benchmark the speed of our method and show that it outperforms
existing approaches. This opens the possibility of in-flight processing on
embedded devices.

    

### [[2112.05224] Spinning Language Models for Propaganda-As-A-Service](http://arxiv.org/abs/2112.05224)


  We investigate a new threat to neural sequence-to-sequence (seq2seq) models:
training-time attacks that cause models to "spin" their outputs so as to
support an adversary-chosen sentiment or point of view, but only when the input
contains adversary-chosen trigger words. For example, a spinned summarization
model would output positive summaries of any text that mentions the name of
some individual or organization.
Model spinning enables propaganda-as-a-service. An adversary can create
customized language models that produce desired spins for chosen triggers, then
deploy them to generate disinformation (a platform attack), or else inject them
into ML training pipelines (a supply-chain attack), transferring malicious
functionality to downstream models.
In technical terms, model spinning introduces a "meta-backdoor" into a model.
Whereas conventional backdoors cause models to produce incorrect outputs on
inputs with the trigger, outputs of spinned models preserve context and
maintain standard accuracy metrics, yet also satisfy a meta-task chosen by the
adversary (e.g., positive sentiment).
To demonstrate feasibility of model spinning, we develop a new backdooring
technique. It stacks the adversarial meta-task onto a seq2seq model,
backpropagates the desired meta-task output to points in the word-embedding
space we call "pseudo-words," and uses pseudo-words to shift the entire output
distribution of the seq2seq model. We evaluate this attack on language
generation, summarization, and translation models with different triggers and
meta-tasks such as sentiment, toxicity, and entailment. Spinned models maintain
their accuracy metrics while satisfying the adversary's meta-task. In supply
chain attack the spin transfers to downstream models.
Finally, we propose a black-box, meta-task-independent defense to detect
models that selectively apply spin to inputs with a certain trigger.

    

### [[2112.05235] The Fundamental Limits of Interval Arithmetic for Neural Networks](http://arxiv.org/abs/2112.05235)


  Interval analysis (or interval bound propagation, IBP) is a popular technique
for verifying and training provably robust deep neural networks, a fundamental
challenge in the area of reliable machine learning. However, despite
substantial efforts, progress on addressing this key challenge has stagnated,
calling into question whether interval arithmetic is a viable path forward.
In this paper we present two fundamental results on the limitations of
interval arithmetic for analyzing neural networks. Our main impossibility
theorem states that for any neural network classifying just three points, there
is a valid specification over these points that interval analysis can not
prove. Further, in the restricted case of one-hidden-layer neural networks we
show a stronger impossibility result: given any radius $\alpha < 1$, there is a
set of $O(\alpha^{-1})$ points with robust radius $\alpha$, separated by
distance $2$, that no one-hidden-layer network can be proven to classify
robustly via interval analysis.

    

### [[2112.05239] On multivariate randomized classification trees: $l_0$-based sparsity, VC~dimension and decomposition methods](http://arxiv.org/abs/2112.05239)


  Decision trees are widely-used classification and regression models because
of their interpretability and good accuracy. Classical methods such as CART are
based on greedy approaches but a growing attention has recently been devoted to
optimal decision trees. We investigate the nonlinear continuous optimization
formulation proposed in Blanquero et al. (EJOR, vol. 284, 2020; COR, vol. 132,
2021) for (sparse) optimal randomized classification trees. Sparsity is
important not only for feature selection but also to improve interpretability.
We first consider alternative methods to sparsify such trees based on concave
approximations of the $l_{0}$ ``norm". Promising results are obtained on 24
datasets in comparison with $l_1$ and $l_{\infty}$ regularizations. Then, we
derive bounds on the VC dimension of multivariate randomized classification
trees. Finally, since training is computationally challenging for large
datasets, we propose a general decomposition scheme and an efficient version of
it. Experiments on larger datasets show that the proposed decomposition method
is able to significantly reduce the training times without compromising the
accuracy.

    

### [[2112.05240] Label-free virtual HER2 immunohistochemical staining of breast tissue using deep learning](http://arxiv.org/abs/2112.05240)


  The immunohistochemical (IHC) staining of the human epidermal growth factor
receptor 2 (HER2) biomarker is widely practiced in breast tissue analysis,
preclinical studies and diagnostic decisions, guiding cancer treatment and
investigation of pathogenesis. HER2 staining demands laborious tissue treatment
and chemical processing performed by a histotechnologist, which typically takes
one day to prepare in a laboratory, increasing analysis time and associated
costs. Here, we describe a deep learning-based virtual HER2 IHC staining method
using a conditional generative adversarial network that is trained to rapidly
transform autofluorescence microscopic images of unlabeled/label-free breast
tissue sections into bright-field equivalent microscopic images, matching the
standard HER2 IHC staining that is chemically performed on the same tissue
sections. The efficacy of this virtual HER2 staining framework was demonstrated
by quantitative analysis, in which three board-certified breast pathologists
blindly graded the HER2 scores of virtually stained and immunohistochemically
stained HER2 whole slide images (WSIs) to reveal that the HER2 scores
determined by inspecting virtual IHC images are as accurate as their
immunohistochemically stained counterparts. A second quantitative blinded study
performed by the same diagnosticians further revealed that the virtually
stained HER2 images exhibit a comparable staining quality in the level of
nuclear detail, membrane clearness, and absence of staining artifacts with
respect to their immunohistochemically stained counterparts. This virtual HER2
staining framework bypasses the costly, laborious, and time-consuming IHC
staining procedures in laboratory, and can be extended to other types of
biomarkers to accelerate the IHC tissue staining used in life sciences and
biomedical workflow.

    

### [[2112.05244] An Experimental Design Perspective on Model-Based Reinforcement Learning](http://arxiv.org/abs/2112.05244)


  In many practical applications of RL, it is expensive to observe state
transitions from the environment. For example, in the problem of plasma control
for nuclear fusion, computing the next state for a given state-action pair
requires querying an expensive transition function which can lead to many hours
of computer simulation or dollars of scientific research. Such expensive data
collection prohibits application of standard RL algorithms which usually
require a large number of observations to learn. In this work, we address the
problem of efficiently learning a policy while making a minimal number of
state-action queries to the transition function. In particular, we leverage
ideas from Bayesian optimal experimental design to guide the selection of
state-action queries for efficient learning. We propose an acquisition function
that quantifies how much information a state-action pair would provide about
the optimal solution to a Markov decision process. At each iteration, our
algorithm maximizes this acquisition function, to choose the most informative
state-action pair to be queried, thus yielding a data-efficient RL approach. We
experiment with a variety of simulated continuous control problems and show
that our approach learns an optimal policy with up to $5$ -- $1,000\times$ less
data than model-based RL baselines and $10^3$ -- $10^5\times$ less data than
model-free RL baselines. We also provide several ablated comparisons which
point to substantial improvements arising from the principled method of
obtaining data.

    

### [[2112.05248] On the Relation between Prediction and Imputation Accuracy under Missing Covariates](http://arxiv.org/abs/2112.05248)


  Missing covariates in regression or classification problems can prohibit the
direct use of advanced tools for further analysis. Recent research has realized
an increasing trend towards the usage of modern Machine Learning algorithms for
imputation. It originates from their capability of showing favourable
prediction accuracy in different learning problems. In this work, we analyze
through simulation the interaction between imputation accuracy and prediction
accuracy in regression learning problems with missing covariates when Machine
Learning based methods for both, imputation and prediction are used. In
addition, we explore imputation performance when using statistical inference
procedures in prediction settings, such as coverage rates of (valid) prediction
intervals. Our analysis is based on empirical datasets provided by the UCI
Machine Learning repository and an extensive simulation study.

    

### [[2112.05251] Error-Aware Imitation Learning from Teleoperation Data for Mobile Manipulation](http://arxiv.org/abs/2112.05251)


  In mobile manipulation (MM), robots can both navigate within and interact
with their environment and are thus able to complete many more tasks than
robots only capable of navigation or manipulation. In this work, we explore how
to apply imitation learning (IL) to learn continuous visuo-motor policies for
MM tasks. Much prior work has shown that IL can train visuo-motor policies for
either manipulation or navigation domains, but few works have applied IL to the
MM domain. Doing this is challenging for two reasons: on the data side, current
interfaces make collecting high-quality human demonstrations difficult, and on
the learning side, policies trained on limited data can suffer from covariate
shift when deployed. To address these problems, we first propose Mobile
Manipulation RoboTurk (MoMaRT), a novel teleoperation framework allowing
simultaneous navigation and manipulation of mobile manipulators, and collect a
first-of-its-kind large scale dataset in a realistic simulated kitchen setting.
We then propose a learned error detection system to address the covariate shift
by detecting when an agent is in a potential failure state. We train performant
IL policies and error detectors from this data, and achieve over 45% task
success rate and 85% error detection success rate across multiple multi-stage
tasks when trained on expert data. Codebase, datasets, visualization, and more
available at this https URL.

    

### [[2112.05254] Addressing Deep Learning Model Uncertainty in Long-Range Climate Forecasting with Late Fusion](http://arxiv.org/abs/2112.05254)


  Global warming leads to the increase in frequency and intensity of climate
extremes that cause tremendous loss of lives and property. Accurate long-range
climate prediction allows more time for preparation and disaster risk
management for such extreme events. Although machine learning approaches have
shown promising results in long-range climate forecasting, the associated model
uncertainties may reduce their reliability. To address this issue, we propose a
late fusion approach that systematically combines the predictions from multiple
models to reduce the expected errors of the fused results. We also propose a
network architecture with the novel denormalization layer to gain the benefits
of data normalization without actually normalizing the data. The experimental
results on long-range 2m temperature forecasting show that the framework
outperforms the 30-year climate normals, and the accuracy can be improved by
increasing the number of models.

    

### [[2112.05261] Equivariant Quantum Graph Circuits](http://arxiv.org/abs/2112.05261)


  We investigate quantum circuits for graph representation learning, and
propose equivariant quantum graph circuits (EQGCs), as a class of parameterized
quantum circuits with strong relational inductive bias for learning over
graph-structured data. Conceptually, EQGCs serve as a unifying framework for
quantum graph representation learning, allowing us to define several
interesting subclasses subsuming existing proposals. In terms of the
representation power, we prove that the subclasses of interest are universal
approximators for functions over the bounded graph domain, and provide
experimental evidence. Our theoretical perspective on quantum graph machine
learning methods opens many directions for further work, and could lead to
models with capabilities beyond those of classical approaches.

    

### [[2112.05267] The Many Faces of Anger: A Multicultural Video Dataset of Negative Emotions in the Wild (MFA-Wild)](http://arxiv.org/abs/2112.05267)


  The portrayal of negative emotions such as anger can vary widely between
cultures and contexts, depending on the acceptability of expressing full-blown
emotions rather than suppression to maintain harmony. The majority of emotional
datasets collect data under the broad label ``anger", but social signals can
range from annoyed, contemptuous, angry, furious, hateful, and more. In this
work, we curated the first in-the-wild multicultural video dataset of emotions,
and deeply explored anger-related emotional expressions by asking
culture-fluent annotators to label the videos with 6 labels and 13 emojis in a
multi-label framework. We provide a baseline multi-label classifier on our
dataset, and show how emojis can be effectively used as a language-agnostic
tool for annotation.

    

### [[2112.05282] RamBoAttack: A Robust Query Efficient Deep Neural Network Decision Exploit](http://arxiv.org/abs/2112.05282)


  Machine learning models are critically susceptible to evasion attacks from
adversarial examples. Generally, adversarial examples, modified inputs
deceptively similar to the original input, are constructed under whitebox
settings by adversaries with full access to the model. However, recent attacks
have shown a remarkable reduction in query numbers to craft adversarial
examples using blackbox attacks. Particularly, alarming is the ability to
exploit the classification decision from the access interface of a trained
model provided by a growing number of Machine Learning as a Service providers
including Google, Microsoft, IBM and used by a plethora of applications
incorporating these models. The ability of an adversary to exploit only the
predicted label from a model to craft adversarial examples is distinguished as
a decision-based attack. In our study, we first deep dive into recent
state-of-the-art decision-based attacks in ICLR and SP to highlight the costly
nature of discovering low distortion adversarial employing gradient estimation
methods. We develop a robust query efficient attack capable of avoiding
entrapment in a local minimum and misdirection from noisy gradients seen in
gradient estimation methods. The attack method we propose, RamBoAttack,
exploits the notion of Randomized Block Coordinate Descent to explore the
hidden classifier manifold, targeting perturbations to manipulate only
localized input features to address the issues of gradient estimation methods.
Importantly, the RamBoAttack is more robust to the different sample inputs
available to an adversary and the targeted class. Overall, for a given target
class, RamBoAttack is demonstrated to be more robust at achieving a lower
distortion within a given query budget. We curate our extensive results using
the large-scale high-resolution ImageNet dataset and open-source our attack,
test samples and artifacts on GitHub.

    

### [[2112.05300] Representing 3D Shapes with Probabilistic Directed Distance Fields](http://arxiv.org/abs/2112.05300)


  Differentiable rendering is an essential operation in modern vision, allowing
inverse graphics approaches to 3D understanding to be utilized in modern
machine learning frameworks. Explicit shape representations (voxels, point
clouds, or meshes), while relatively easily rendered, often suffer from limited
geometric fidelity or topological constraints. On the other hand, implicit
representations (occupancy, distance, or radiance fields) preserve greater
fidelity, but suffer from complex or inefficient rendering processes, limiting
scalability. In this work, we endeavour to address both shortcomings with a
novel shape representation that allows fast differentiable rendering within an
implicit architecture. Building on implicit distance representations, we define
Directed Distance Fields (DDFs), which map an oriented point (position and
direction) to surface visibility and depth. Such a field can render a depth map
with a single forward pass per pixel, enable differential surface geometry
extraction (e.g., surface normals and curvatures) via network derivatives, be
easily composed, and permit extraction of classical unsigned distance fields.
Using probabilistic DDFs (PDDFs), we show how to model inherent discontinuities
in the underlying field. Finally, we apply our method to fitting single shapes,
unpaired 3D-aware generative image modelling, and single-image 3D
reconstruction tasks, showcasing strong performance with simple architectural
components via the versatility of our representation.

    

### [[2112.05310] Robustness Certificates for Implicit Neural Networks: A Mixed Monotone Contractive Approach](http://arxiv.org/abs/2112.05310)


  Implicit neural networks are a general class of learning models that replace
the layers in traditional feedforward models with implicit algebraic equations.
Compared to traditional learning models, implicit networks offer competitive
performance and reduced memory consumption. However, they can remain brittle
with respect to input adversarial perturbations.
This paper proposes a theoretical and computational framework for robustness
verification of implicit neural networks; our framework blends together mixed
monotone systems theory and contraction theory. First, given an implicit neural
network, we introduce a related embedded network and show that, given an
$\ell_\infty$-norm box constraint on the input, the embedded network provides
an $\ell_\infty$-norm box overapproximation for the output of the given
network. Second, using $\ell_{\infty}$-matrix measures, we propose sufficient
conditions for well-posedness of both the original and embedded system and
design an iterative algorithm to compute the $\ell_{\infty}$-norm box
robustness margins for reachability and classification problems. Third, of
independent value, we propose a novel relative classifier variable that leads
to tighter bounds on the certified adversarial robustness in classification
problems. Finally, we perform numerical simulations on a Non-Euclidean Monotone
Operator Network (NEMON) trained on the MNIST dataset. In these simulations, we
compare the accuracy and run time of our mixed monotone contractive approach
with the existing robustness verification approaches in the literature for
estimating the certified adversarial robustness.

    

### [[2112.05313] Building Autocorrelation-Aware Representations for Fine-Scale Spatiotemporal Prediction](http://arxiv.org/abs/2112.05313)


  Many scientific prediction problems have spatiotemporal data- and
modeling-related challenges in handling complex variations in space and time
using only sparse and unevenly distributed observations. This paper presents a
novel deep learning architecture, Deep learning predictions for
LocATion-dependent Time-sEries data (DeepLATTE), that explicitly incorporates
theories of spatial statistics into neural networks to address these
challenges. In addition to a feature selection module and a spatiotemporal
learning module, DeepLATTE contains an autocorrelation-guided semi-supervised
learning strategy to enforce both local autocorrelation patterns and global
autocorrelation trends of the predictions in the learned spatiotemporal
embedding space to be consistent with the observed data, overcoming the
limitation of sparse and unevenly distributed observations. During the training
process, both supervised and semi-supervised losses guide the updates of the
entire network to: 1) prevent overfitting, 2) refine feature selection, 3)
learn useful spatiotemporal representations, and 4) improve overall prediction.
We conduct a demonstration of DeepLATTE using publicly available data for an
important public health topic, air quality prediction, in a well-studied,
complex physical environment - Los Angeles. The experiment demonstrates that
the proposed approach provides accurate fine-spatial-scale air quality
predictions and reveals the critical environmental factors affecting the
results.

    

### [[2112.05321] PMFL: Partial Meta-Federated Learning for heterogeneous tasks and its applications on real-world medical records](http://arxiv.org/abs/2112.05321)


  Federated machine learning is a versatile and flexible tool to utilize
distributed data from different sources, especially when communication
technology develops rapidly and an unprecedented amount of data could be
collected on mobile devices nowadays. Federated learning method exploits not
only the data but the computational power of all devices in the network to
achieve more efficient model training. Nevertheless, while most traditional
federated learning methods work well for homogeneous data and tasks, adapting
the method to a different heterogeneous data and task distribution is
challenging. This limitation has constrained the applications of federated
learning in real-world contexts, especially in healthcare settings. Inspired by
the fundamental idea of meta-learning, in this study we propose a new
algorithm, which is an integration of federated learning and meta-learning, to
tackle this issue. In addition, owing to the advantage of transfer learning for
model generalization, we further improve our algorithm by introducing partial
parameter sharing. We name this method partial meta-federated learning (PMFL).
Finally, we apply the algorithms to two medical datasets. We show that our
algorithm could obtain the fastest training speed and achieve the best
performance when dealing with heterogeneous medical datasets.

    

### [[2112.05335] Uncertainty, Edge, and Reverse-Attention Guided Generative Adversarial Network for Automatic Building Detection in Remotely Sensed Images](http://arxiv.org/abs/2112.05335)


  Despite recent advances in deep-learning based semantic segmentation,
automatic building detection from remotely sensed imagery is still a
challenging problem owing to large variability in the appearance of buildings
across the globe. The errors occur mostly around the boundaries of the building
footprints, in shadow areas, and when detecting buildings whose exterior
surfaces have reflectivity properties that are very similar to those of the
surrounding regions. To overcome these problems, we propose a generative
adversarial network based segmentation framework with uncertainty attention
unit and refinement module embedded in the generator. The refinement module,
composed of edge and reverse attention units, is designed to refine the
predicted building map. The edge attention enhances the boundary features to
estimate building boundaries with greater precision, and the reverse attention
allows the network to explore the features missing in the previously estimated
regions. The uncertainty attention unit assists the network in resolving
uncertainties in classification. As a measure of the power of our approach, as
of December 4, 2021, it ranks at the second place on DeepGlobe's public
leaderboard despite the fact that main focus of our approach -- refinement of
the building edges -- does not align exactly with the metrics used for
leaderboard rankings. Our overall F1-score on DeepGlobe's challenging dataset
is 0.745. We also report improvements on the previous-best results for the
challenging INRIA Validation Dataset for which our network achieves an overall
IoU of 81.28% and an overall accuracy of 97.03%. Along the same lines, for the
official INRIA Test Dataset, our network scores 77.86% and 96.41% in overall
IoU and accuracy.

    

### [[2112.05340] Tradeoffs Between Contrastive and Supervised Learning: An Empirical Study](http://arxiv.org/abs/2112.05340)


  Contrastive learning has made considerable progress in computer vision,
outperforming supervised pretraining on a range of downstream datasets.
However, is contrastive learning the better choice in all situations? We
demonstrate two cases where it is not. First, under sufficiently small
pretraining budgets, supervised pretraining on ImageNet consistently
outperforms a comparable contrastive model on eight diverse image
classification datasets. This suggests that the common practice of comparing
pretraining approaches at hundreds or thousands of epochs may not produce
actionable insights for those with more limited compute budgets. Second, even
with larger pretraining budgets we identify tasks where supervised learning
prevails, perhaps because the object-centric bias of supervised pretraining
makes the model more resilient to common corruptions and spurious
foreground-background correlations. These results underscore the need to
characterize tradeoffs of different pretraining objectives across a wider range
of contexts and training regimes.

    

### [[2112.05343] Blockwise Sequential Model Learning for Partially Observable Reinforcement Learning](http://arxiv.org/abs/2112.05343)


  This paper proposes a new sequential model learning architecture to solve
partially observable Markov decision problems. Rather than compressing
sequential information at every timestep as in conventional recurrent neural
network-based methods, the proposed architecture generates a latent variable in
each data block with a length of multiple timesteps and passes the most
relevant information to the next block for policy optimization. The proposed
blockwise sequential model is implemented based on self-attention, making the
model capable of detailed sequential learning in partial observable settings.
The proposed model builds an additional learning network to efficiently
implement gradient estimation by using self-normalized importance sampling,
which does not require the complex blockwise input data reconstruction in the
model learning. Numerical results show that the proposed method significantly
outperforms previous methods in various partially observable environments.

    

### [[2112.05353] Learning-Augmented Algorithms for Online Steiner Tree](http://arxiv.org/abs/2112.05353)


  This paper considers the recently popular beyond-worst-case algorithm
analysis model which integrates machine-learned predictions with online
algorithm design. We consider the online Steiner tree problem in this model for
both directed and undirected graphs. Steiner tree is known to have strong lower
bounds in the online setting and any algorithm's worst-case guarantee is far
from desirable. This paper considers algorithms that predict which terminal
arrives online. The predictions may be incorrect and the algorithms'
performance is parameterized by the number of incorrectly predicted terminals.
These guarantees ensure that algorithms break through the online lower bounds
with good predictions and the competitive ratio gracefully degrades as the
prediction error grows. We then observe that the theory is predictive of what
will occur empirically. We show on graphs where terminals are drawn from a
distribution, the new online algorithms have strong performance even with
modestly correct predictions.

    

### [[2112.05355] LUNAR: Unifying Local Outlier Detection Methods via Graph Neural Networks](http://arxiv.org/abs/2112.05355)


  Many well-established anomaly detection methods use the distance of a sample
to those in its local neighbourhood: so-called `local outlier methods', such as
LOF and DBSCAN. They are popular for their simple principles and strong
performance on unstructured, feature-based data that is commonplace in many
practical applications. However, they cannot learn to adapt for a particular
set of data due to their lack of trainable parameters. In this paper, we begin
by unifying local outlier methods by showing that they are particular cases of
the more general message passing framework used in graph neural networks. This
allows us to introduce learnability into local outlier methods, in the form of
a neural network, for greater flexibility and expressivity: specifically, we
propose LUNAR, a novel, graph neural network-based anomaly detection method.
LUNAR learns to use information from the nearest neighbours of each node in a
trainable way to find anomalies. We show that our method performs significantly
better than existing local outlier methods, as well as state-of-the-art deep
baselines. We also show that the performance of our method is much more robust
to different settings of the local neighbourhood size.

    

### [[2112.05359] Sketching as a Tool for Understanding and Accelerating Self-attention for Long Sequences](http://arxiv.org/abs/2112.05359)


  Transformer-based models are not efficient in processing long sequences due
to the quadratic space and time complexity of the self-attention modules. To
address this limitation, Linformer and Informer are proposed to reduce the
quadratic complexity to linear (modulo logarithmic factors) via low-dimensional
projection and row selection respectively. These two models are intrinsically
connected, and to understand their connection, we introduce a theoretical
framework of matrix sketching. Based on the theoretical analysis, we propose
Skeinformer to accelerate self-attention and further improve the accuracy of
matrix approximation to self-attention with three carefully designed
components: column sampling, adaptive row normalization and pilot sampling
reutilization. Experiments on the Long Range Arena (LRA) benchmark demonstrate
that our methods outperform alternatives with a consistently smaller time/space
footprint.

    

### [[2112.05367] Efficient Action Poisoning Attacks on Linear Contextual Bandits](http://arxiv.org/abs/2112.05367)


  Contextual bandit algorithms have many applicants in a variety of scenarios.
In order to develop trustworthy contextual bandit systems, understanding the
impacts of various adversarial attacks on contextual bandit algorithms is
essential. In this paper, we propose a new class of attacks: action poisoning
attacks, where an adversary can change the action signal selected by the agent.
We design action poisoning attack schemes against linear contextual bandit
algorithms in both white-box and black-box settings. We further analyze the
cost of the proposed attack strategies for a very popular and widely used
bandit algorithm: LinUCB. We show that, in both white-box and black-box
settings, the proposed attack schemes can force the LinUCB agent to pull a
target arm very frequently by spending only logarithm cost.

    

### [[2112.05379] Cross-Modal Transferable Adversarial Attacks from Images to Videos](http://arxiv.org/abs/2112.05379)


  Recent studies have shown that adversarial examples hand-crafted on one
white-box model can be used to attack other black-box models. Such cross-model
transferability makes it feasible to perform black-box attacks, which has
raised security concerns for real-world DNNs applications. Nevertheless,
existing works mostly focus on investigating the adversarial transferability
across different deep models that share the same modality of input data. The
cross-modal transferability of adversarial perturbation has never been
explored. This paper investigates the transferability of adversarial
perturbation across different modalities, i.e., leveraging adversarial
perturbation generated on white-box image models to attack black-box video
models. Specifically, motivated by the observation that the low-level feature
space between images and video frames are similar, we propose a simple yet
effective cross-modal attack method, named as Image To Video (I2V) attack. I2V
generates adversarial frames by minimizing the cosine similarity between
features of pre-trained image models from adversarial and benign examples, then
combines the generated adversarial frames to perform black-box attacks on video
recognition models. Extensive experiments demonstrate that I2V can achieve high
attack success rates on different black-box video recognition models. On
Kinetics-400 and UCF-101, I2V achieves an average attack success rate of 77.88%
and 65.68%, respectively, which sheds light on the feasibility of cross-modal
adversarial attacks.

    

### [[2112.05387] Layer-Parallel Training of Residual Networks with Auxiliary-Variable Networks](http://arxiv.org/abs/2112.05387)


  Gradient-based methods for the distributed training of residual networks
(ResNets) typically require a forward pass of the input data, followed by
back-propagating the error gradient to update model parameters, which becomes
time-consuming as the network goes deeper. To break the algorithmic locking and
exploit synchronous module parallelism in both the forward and backward modes,
auxiliary-variable methods have attracted much interest lately but suffer from
significant communication overhead and lack of data augmentation. In this work,
a novel joint learning framework for training realistic ResNets across multiple
compute devices is established by trading off the storage and recomputation of
external auxiliary variables. More specifically, the input data of each
independent processor is generated from its low-capacity auxiliary network
(AuxNet), which permits the use of data augmentation and realizes forward
unlocking. The backward passes are then executed in parallel, each with a local
loss function that originates from the penalty or augmented Lagrangian (AL)
methods. Finally, the proposed AuxNet is employed to reproduce the updated
auxiliary variables through an end-to-end training process. We demonstrate the
effectiveness of our methods on ResNets and WideResNets across CIFAR-10,
CIFAR-100, and ImageNet datasets, achieving speedup over the traditional
layer-serial training method while maintaining comparable testing accuracy.

    

### [[2112.05393] A Self-supervised Mixed-curvature Graph Neural Network](http://arxiv.org/abs/2112.05393)


  Graph representation learning received increasing attentions in recent years.
Most of existing methods ignore the complexity of the graph structures and
restrict graphs in a single constant-curvature representation space, which is
only suitable to particular kinds of graph structure indeed. Additionally,
these methods follow the supervised or semi-supervised learning paradigm, and
thereby notably limit their deployment on the unlabeled graphs in real
applications. To address these aforementioned limitations, we take the first
attempt to study the self-supervised graph representation learning in the
mixed-curvature spaces. In this paper, we present a novel Self-supervised
Mixed-curvature Graph Neural Network (SelfMGNN). Instead of working on one
single constant-curvature space, we construct a mixed-curvature space via the
Cartesian product of multiple Riemannian component spaces and design
hierarchical attention mechanisms for learning and fusing the representations
across these component spaces. To enable the self-supervisd learning, we
propose a novel dual contrastive approach. The mixed-curvature Riemannian space
actually provides multiple Riemannian views for the contrastive learning. We
introduce a Riemannian projector to reveal these views, and utilize a
well-designed Riemannian discriminator for the single-view and cross-view
contrastive learning within and across the Riemannian views. Finally, extensive
experiments show that SelfMGNN captures the complicated graph structures in
reality and outperforms state-of-the-art baselines.

    

### [[2112.05399] A Generative Car-following Model Conditioned On Driving Styles](http://arxiv.org/abs/2112.05399)


  Car-following (CF) modeling, an essential component in simulating human CF
behaviors, has attracted increasing research interest in the past decades. This
paper pushes the state of the art by proposing a novel generative hybrid CF
model, which achieves high accuracy in characterizing dynamic human CF
behaviors and is able to generate realistic human CF behaviors for any given
observed or even unobserved driving style. Specifically, the ability of
accurately capturing human CF behaviors is ensured by designing and calibrating
an Intelligent Driver Model (IDM) with time-varying parameters. The reason
behind is that such time-varying parameters can express both the inter-driver
heterogeneity, i.e., diverse driving styles of different drivers, and the
intra-driver heterogeneity, i.e., changing driving styles of the same driver.
The ability of generating realistic human CF behaviors of any given observed
driving style is achieved by applying a neural process (NP) based model. The
ability of inferring CF behaviors of unobserved driving styles is supported by
exploring the relationship between the calibrated time-varying IDM parameters
and an intermediate variable of NP. To demonstrate the effectiveness of our
proposed models, we conduct extensive experiments and comparisons, including CF
model parameter calibration, CF behavior prediction, and trajectory simulation
for different driving styles.

    

### [[2112.05404] The Large Labelled Logo Dataset (L3D): A Multipurpose and Hand-Labelled Continuously Growing Dataset](http://arxiv.org/abs/2112.05404)


  In this work, we present the Large Labelled Logo Dataset (L3D), a
multipurpose, hand-labelled, continuously growing dataset. It is composed of
around 770k of color 256x256 RGB images extracted from the European Union
Intellectual Property Office (EUIPO) open registry. Each of them is associated
to multiple labels that classify the figurative and textual elements that
appear in the images. These annotations have been classified by the EUIPO
evaluators using the Vienna classification, a hierarchical classification of
figurative marks. We suggest two direct applications of this dataset, namely,
logo classification and logo generation.

    

### [[2112.05409] Defending Label Inference and Backdoor Attacks in Vertical Federated Learning](http://arxiv.org/abs/2112.05409)


  In collaborative learning settings like federated learning, curious parities
might be honest but are attempting to infer other parties' private data through
inference attacks while malicious parties might manipulate the learning process
for their own purposes through backdoor attacks. However, most existing works
only consider the federated learning scenario where data are partitioned by
samples (HFL). The feature-partitioned federated learning (VFL) can be another
important scenario in many real-world applications. Attacks and defenses in
such scenarios are especially challenging when the attackers and the defenders
are not able to access the features or model parameters of other participants.
Previous works have only shown that private labels can be reconstructed from
per-sample gradients. In this paper, we first show that private labels can be
reconstructed when only batch-averaged gradients are revealed, which is against
the common presumption. In addition, we show that a passive party in VFL can
even replace its corresponding labels in the active party with a target label
through a gradient-replacement attack. To defend against the first attack, we
introduce a novel technique termed confusional autoencoder (CoAE), based on
autoencoder and entropy regularization. We demonstrate that label inference
attacks can be successfully blocked by this technique while hurting less main
task accuracy compared to existing methods. Our CoAE technique is also
effective in defending the gradient-replacement backdoor attack, making it an
universal and practical defense strategy with no change to the original VFL
protocol. We demonstrate the effectiveness of our approaches under both
two-party and multi-party VFL settings. To the best of our knowledge, this is
the first systematic study to deal with label inference and backdoor attacks in
the feature-partitioned federated learning framework.

    

### [[2112.05419] Predicting Physical World Destinations for Commands Given to Self-Driving Cars](http://arxiv.org/abs/2112.05419)


  In recent years, we have seen significant steps taken in the development of
self-driving cars. Multiple companies are starting to roll out impressive
systems that work in a variety of settings. These systems can sometimes give
the impression that full self-driving is just around the corner and that we
would soon build cars without even a steering wheel. The increase in the level
of autonomy and control given to an AI provides an opportunity for new modes of
human-vehicle interaction. However, surveys have shown that giving more control
to an AI in self-driving cars is accompanied by a degree of uneasiness by
passengers. In an attempt to alleviate this issue, recent works have taken a
natural language-oriented approach by allowing the passenger to give commands
that refer to specific objects in the visual scene. Nevertheless, this is only
half the task as the car should also understand the physical destination of the
command, which is what we focus on in this paper. We propose an extension in
which we annotate the 3D destination that the car needs to reach after
executing the given command and evaluate multiple different baselines on
predicting this destination location. Additionally, we introduce a model that
outperforms the prior works adapted for this particular setting.

    

### [[2112.05422] Robustification of Online Graph Exploration Methods](http://arxiv.org/abs/2112.05422)


  Exploring unknown environments is a fundamental task in many domains, e.g.,
robot navigation, network security, and internet search. We initiate the study
of a learning-augmented variant of the classical, notoriously hard online graph
exploration problem by adding access to machine-learned predictions. We propose
an algorithm that naturally integrates predictions into the well-known Nearest
Neighbor (NN) algorithm and significantly outperforms any known online
algorithm if the prediction is of high accuracy while maintaining good
guarantees when the prediction is of poor quality. We provide theoretical
worst-case bounds that gracefully degrade with the prediction error, and we
complement them by computational experiments that confirm our results. Further,
we extend our concept to a general framework to robustify algorithms. By
interpolating carefully between a given algorithm and NN, we prove new
performance bounds that leverage the individual good performance on particular
inputs while establishing robustness to arbitrary inputs.

    

### [[2112.05438] DEBACER: a method for slicing moderated debates](http://arxiv.org/abs/2112.05438)


  Subjects change frequently in moderated debates with several participants,
such as in parliamentary sessions, electoral debates, and trials. Partitioning
a debate into blocks with the same subject is essential for understanding.
Often a moderator is responsible for defining when a new block begins so that
the task of automatically partitioning a moderated debate can focus solely on
the moderator's behavior. In this paper, we (i) propose a new algorithm,
DEBACER, which partitions moderated debates; (ii) carry out a comparative study
between conventional and BERTimbau pipelines; and (iii) validate DEBACER
applying it to the minutes of the Assembly of the Republic of Portugal. Our
results show the effectiveness of DEBACER. Keywords: Natural Language
Processing, Political Documents, Spoken Text Processing, Speech Split, Dialogue
Partitioning.

    

### [[2112.05445] Beyond Parallel Pancakes: Quasi-Polynomial Time Guarantees for Non-Spherical Gaussian Mixtures](http://arxiv.org/abs/2112.05445)


  We consider mixtures of $k\geq 2$ Gaussian components with unknown means and
unknown covariance (identical for all components) that are well-separated,
i.e., distinct components have statistical overlap at most $k^{-C}$ for a large
enough constant $C\ge 1$. Previous statistical-query lower bounds [DKS17] give
formal evidence that even distinguishing such mixtures from (pure) Gaussians
may be exponentially hard (in $k$).
We show that this kind of hardness can only appear if mixing weights are
allowed to be exponentially small, and that for polynomially lower bounded
mixing weights non-trivial algorithmic guarantees are possible in
quasi-polynomial time.
Concretely, we develop an algorithm based on the sum-of-squares method with
running time quasi-polynomial in the minimum mixing weight. The algorithm can
reliably distinguish between a mixture of $k\ge 2$ well-separated Gaussian
components and a (pure) Gaussian distribution. As a certificate, the algorithm
computes a bipartition of the input sample that separates a pair of mixture
components, i.e., both sides of the bipartition contain most of the sample
points of at least one component.
For the special case of colinear means, our algorithm outputs a $k$
clustering of the input sample that is approximately consistent with the
components of the mixture.
A significant challenge for our results is that they appear to be inherently
sensitive to small fractions of adversarial outliers unlike most previous
results for Gaussian mixtures. The reason is that such outliers can simulate
exponentially small mixing weights even for mixtures with polynomially lower
bounded mixing weights.
A key technical ingredient is a characterization of separating directions for
well-separated Gaussian components in terms of ratios of polynomials that
correspond to moments of two carefully chosen orders logarithmic in the minimum
mixing weight.

    

### [[2112.05451] Structure-Preserving Learning Using Gaussian Processes and Variational Integrators](http://arxiv.org/abs/2112.05451)


  Gaussian process regression is often applied for learning unknown systems and
specifying the uncertainty of the learned model. When using Gaussian process
regression to learn unknown systems, a commonly considered approach consists of
learning the residual dynamics after applying some standard discretization,
which might however not be appropriate for the system at hand. Variational
integrators are a less common yet promising approach to discretization, as they
retain physical properties of the underlying system, such as energy
conservation or satisfaction of explicit constraints. In this work, we propose
the combination of a variational integrator for the nominal dynamics of a
mechanical system and learning residual dynamics with Gaussian process
regression. We extend our approach to systems with known kinematic constraints
and provide formal bounds on the prediction uncertainty. The simulative
evaluation of the proposed method shows desirable energy conservation
properties in accordance with the theoretical results and demonstrates the
capability of treating constrained dynamical systems.

    

### [[2112.05477] Modelling DDoS Attacks in IoT Networks using Machine Learning](http://arxiv.org/abs/2112.05477)


  In current Internet-of-Things (IoT) deployments, a mix of traditional IP
networking and IoT specific protocols, both relying on the TCP protocol, can be
used to transport data from a source to a destination. Therefore, TCP-specific
attacks, such as the Distributed Denial of Service (DDoS) using the TCP SYN
attack, are one of the most plausible tools that attackers can use on
Cyber-Physical Systems (CPS). This may be done by launching an attack from its
IoT subsystem, here referred to as the "CPS-IoT", with potential propagation to
the different servers located in both fog and the cloud infrastructures of the
CPS. This study compares the effectiveness of supervised, unsupervised, and
semi-supervised machine learning algorithms for detecting DDoS attacks in
CPS-IoT, particularly during data transmission to and from the physical space
to the cyber space via the Internet. The algorithms considered are broadly
grouped into two: i) Detection algorithms, which include Logistic Regression
(LGR), K-Means, and Artificial Neural Networks (ANN). We also looked into the
effectiveness of semi-supervised hybrid learning models, which use unsupervised
K-Means to label data, then feed the output to a supervised learning model for
attack detection. ii.) Prediction algorithms - LGR, Kernel Ridge Regression
(KRR) and Support Vector Regression (SVR), which were used to predict imminent
attacks. Experimental tests were carried out and obtained results showed that
the hybrid model was able to achieve 100% accuracy with zero false positives;
while all the prediction models were able to achieve over 94% attack prediction
accuracy.

    

### [[2112.05489] Surrogate-data-enriched Physics-Aware Neural Networks](http://arxiv.org/abs/2112.05489)


  Neural networks can be used as surrogates for PDE models. They can be made
physics-aware by penalizing underlying equations or the conservation of
physical properties in the loss function during training. Current approaches
allow to additionally respect data from numerical simulations or experiments in
the training process. However, this data is frequently expensive to obtain and
thus only scarcely available for complex models. In this work, we investigate
how physics-aware models can be enriched with computationally cheaper, but
inexact, data from other surrogate models like Reduced-Order Models (ROMs). In
order to avoid trusting too-low-fidelity surrogate solutions, we develop an
approach that is sensitive to the error in inexact data. As a proof of concept,
we consider the one-dimensional wave equation and show that the training
accuracy is increased by two orders of magnitude when inexact data from ROMs is
incorporated.

    

### [[2112.05493] Network Compression via Central Filter](http://arxiv.org/abs/2112.05493)


  Neural network pruning has remarkable performance for reducing the complexity
of deep network models. Recent network pruning methods usually focused on
removing unimportant or redundant filters in the network. In this paper, by
exploring the similarities between feature maps, we propose a novel filter
pruning method, Central Filter (CF), which suggests that a filter is
approximately equal to a set of other filters after appropriate adjustments.
Our method is based on the discovery that the average similarity between
feature maps changes very little, regardless of the number of input images.
Based on this finding, we establish similarity graphs on feature maps and
calculate the closeness centrality of each node to select the Central Filter.
Moreover, we design a method to directly adjust weights in the next layer
corresponding to the Central Filter, effectively minimizing the error caused by
pruning. Through experiments on various benchmark networks and datasets, CF
yields state-of-the-art performance. For example, with ResNet-56, CF reduces
approximately 39.7% of FLOPs by removing 47.1% of the parameters, with even
0.33% accuracy improvement on CIFAR-10. With GoogLeNet, CF reduces
approximately 63.2% of FLOPs by removing 55.6% of the parameters, with only a
small loss of 0.35% in top-1 accuracy on CIFAR-10. With ResNet-50, CF reduces
approximately 47.9% of FLOPs by removing 36.9% of the parameters, with only a
small loss of 1.07% in top-1 accuracy on ImageNet. The codes can be available
at this https URL.

    

### [[2112.05495] How Private Is Your RL Policy? An Inverse RL Based Analysis Framework](http://arxiv.org/abs/2112.05495)


  Reinforcement Learning (RL) enables agents to learn how to perform various
tasks from scratch. In domains like autonomous driving, recommendation systems,
and more, optimal RL policies learned could cause a privacy breach if the
policies memorize any part of the private reward. We study the set of existing
differentially-private RL policies derived from various RL algorithms such as
Value Iteration, Deep Q Networks, and Vanilla Proximal Policy Optimization. We
propose a new Privacy-Aware Inverse RL (PRIL) analysis framework, that performs
reward reconstruction as an adversarial attack on private policies that the
agents may deploy. For this, we introduce the reward reconstruction attack,
wherein we seek to reconstruct the original reward from a privacy-preserving
policy using an Inverse RL algorithm. An adversary must do poorly at
reconstructing the original reward function if the agent uses a tightly private
policy. Using this framework, we empirically test the effectiveness of the
privacy guarantee offered by the private algorithms on multiple instances of
the FrozenLake domain of varying complexities. Based on the analysis performed,
we infer a gap between the current standard of privacy offered and the standard
of privacy needed to protect reward functions in RL. We do so by quantifying
the extent to which each private policy protects the reward function by
measuring distances between the original and reconstructed rewards.

    

### [[2112.05519] A Validation Tool for Designing Reinforcement Learning Environments](http://arxiv.org/abs/2112.05519)


  Reinforcement learning (RL) has gained increasing attraction in the academia
and tech industry with launches to a variety of impactful applications and
products. Although research is being actively conducted on many fronts (e.g.,
offline RL, performance, etc.), many RL practitioners face a challenge that has
been largely ignored: determine whether a designed Markov Decision Process
(MDP) is valid and meaningful. This study proposes a heuristic-based feature
analysis method to validate whether an MDP is well formulated. We believe an
MDP suitable for applying RL should contain a set of state features that are
both sensitive to actions and predictive in rewards. We tested our method in
constructed environments showing that our approach can identify certain invalid
environment formulations. As far as we know, performing validity analysis for
RL problem formulation is a novel direction. We envision that our tool will
serve as a motivational example to help practitioners apply RL in real-world
problems more easily.

    

### [[2112.05547] PACMAN: PAC-style bounds accounting for the Mismatch between Accuracy and Negative log-loss](http://arxiv.org/abs/2112.05547)


  The ultimate performance of machine learning algorithms for classification
tasks is usually measured in terms of the empirical error probability (or
accuracy) based on a testing dataset. Whereas, these algorithms are optimized
through the minimization of a typically different--more convenient--loss
function based on a training set. For classification tasks, this loss function
is often the negative log-loss that leads to the well-known cross-entropy risk
which is typically better behaved (from a numerical perspective) than the error
probability. Conventional studies on the generalization error do not usually
take into account the underlying mismatch between losses at training and
testing phases. In this work, we introduce an analysis based on point-wise PAC
approach over the generalization gap considering the mismatch of testing based
on the accuracy metric and training on the negative log-loss. We label this
analysis PACMAN. Building on the fact that the mentioned mismatch can be
written as a likelihood ratio, concentration inequalities can be used to
provide some insights for the generalization problem in terms of some
point-wise PAC bounds depending on some meaningful information-theoretic
quantities. An analysis of the obtained bounds and a comparison with available
results in the literature are also provided.

    

### [[2112.05554] Using Machine Learning to Find New Density Functionals](http://arxiv.org/abs/2112.05554)


  Machine learning has now become an integral part of research and innovation.
The field of machine learning density functional theory has continuously
expanded over the years while making several noticeable advances. We briefly
discuss the status of this field and point out some current and future
challenges. We also talk about how state-of-the-art science and technology
tools can help overcome these challenges. This draft is a part of the "Roadmap
on Machine Learning in Electronic Structure" to be published in Electronic
Structure (EST).

    

### [[2112.05559] Collaborative Learning over Wireless Networks: An Introductory Overview](http://arxiv.org/abs/2112.05559)


  In this chapter, we will mainly focus on collaborative training across
wireless devices. Training a ML model is equivalent to solving an optimization
problem, and many distributed optimization algorithms have been developed over
the last decades. These distributed ML algorithms provide data locality; that
is, a joint model can be trained collaboratively while the data available at
each participating device remains local. This addresses, to some extend, the
privacy concern. They also provide computational scalability as they allow
exploiting computational resources distributed across many edge devices.
However, in practice, this does not directly lead to a linear gain in the
overall learning speed with the number of devices. This is partly due to the
communication bottleneck limiting the overall computation speed. Additionally,
wireless devices are highly heterogeneous in their computational capabilities,
and both their computation speed and communication rate can be highly
time-varying due to physical factors. Therefore, distributed learning
algorithms, particularly those to be implemented at the wireless network edge,
must be carefully designed taking into account the impact of time-varying
communication network as well as the heterogeneous and stochastic computation
capabilities of devices.

    

### [[2112.05587] Unified Multimodal Pre-training and Prompt-based Tuning for Vision-Language Understanding and Generation](http://arxiv.org/abs/2112.05587)


  Most existing vision-language pre-training methods focus on understanding
tasks and use BERT-like objectives (masked language modeling and image-text
matching) during pretraining. Although they perform well in many understanding
downstream tasks, e.g., visual question answering, image-text retrieval and
visual entailment, they do not possess the ability to generate. To tackle this
problem, we propose Unified multimodal pre-training for both Vision-Language
understanding and generation (UniVL). The proposed UniVL is capable of handling
both understanding tasks and generative tasks. We augment existing pretraining
paradigms that only use random masks with causal masks, i.e., triangular masks
that mask out future tokens, such that the pre-trained models can have
autoregressive generation abilities by design. We formulate several previous
understanding tasks as a text generation task and propose to use prompt-based
method for fine-tuning on different downstream tasks. Our experiments show that
there is a trade-off between understanding tasks and generation tasks while
using the same model, and a feasible way to improve both tasks is to use more
data. Our UniVL framework attains comparable performance to recent
vision-language pre-training methods on both understanding tasks and generation
tasks. Moreover, we demostrate that prompt-based finetuning is more
data-efficient - it outperforms discriminative methods in few-shot scenarios.

    

### [[2112.05604] Faster Single-loop Algorithms for Minimax Optimization without Strong Concavity](http://arxiv.org/abs/2112.05604)


  Gradient descent ascent (GDA), the simplest single-loop algorithm for
nonconvex minimax optimization, is widely used in practical applications such
as generative adversarial networks (GANs) and adversarial training. Albeit its
desirable simplicity, recent work shows inferior convergence rates of GDA in
theory even assuming strong concavity of the objective on one side. This paper
establishes new convergence results for two alternative single-loop algorithms
-- alternating GDA and smoothed GDA -- under the mild assumption that the
objective satisfies the Polyak-Lojasiewicz (PL) condition about one variable.
We prove that, to find an $\epsilon$-stationary point, (i) alternating GDA and
its stochastic variant (without mini batch) respectively require $O(\kappa^{2}
\epsilon^{-2})$ and $O(\kappa^{4} \epsilon^{-4})$ iterations, while (ii)
smoothed GDA and its stochastic variant (without mini batch) respectively
require $O(\kappa \epsilon^{-2})$ and $O(\kappa^{2} \epsilon^{-4})$ iterations.
The latter greatly improves over the vanilla GDA and gives the hitherto best
known complexity results among single-loop algorithms under similar settings.
We further showcase the empirical efficiency of these algorithms in training
GANs and robust nonlinear regression.

    

### [[2112.05605] Comparison of Markov chains via weak Poincar inequalities with application to pseudo-marginal MCMC](http://arxiv.org/abs/2112.05605)


  We investigate the use of a certain class of functional inequalities known as
weak Poincar inequalities to bound convergence of Markov chains to
equilibrium. We show that this enables the straightforward and transparent
derivation of subgeometric convergence bounds for methods such as the
Independent Metropolis--Hastings sampler and pseudo-marginal methods for
intractable likelihoods, the latter being subgeometric in many practical
settings. These results rely on novel quantitative comparison theorems between
Markov chains. Associated proofs are simpler than those relying on
drift/minorization conditions and the tools developed allow us to recover and
further extend known results as particular cases. We are then able to provide
new insights into the practical use of pseudo-marginal algorithms, analyse the
effect of averaging in Approximate Bayesian Computation (ABC) and the use of
products of independent averages, and also to study the case of lognormal
weights relevant to particle marginal Metropolis--Hastings (PMMH).

    

### [[2112.05609] Interaction-Aware Sensitivity Analysis for Aerodynamic Optimization Results using Information Theory](http://arxiv.org/abs/2112.05609)


  An important issue during an engineering design process is to develop an
understanding which design parameters have the most influence on the
performance. Especially in the context of optimization approaches this
knowledge is crucial in order to realize an efficient design process and
achieve high-performing results. Information theory provides powerful tools to
investigate these relationships because measures are model-free and thus also
capture non-linear relationships, while requiring only minimal assumptions on
the input data. We therefore propose to use recently introduced
information-theoretic methods and estimation algorithms to find the most
influential input parameters in optimization results. The proposed methods are
in particular able to account for interactions between parameters, which are
often neglected but may lead to redundant or synergistic contributions of
multiple parameters. We demonstrate the application of these methods on
optimization data from aerospace engineering, where we first identify the most
relevant optimization parameters using a recently introduced
information-theoretic feature-selection algorithm that accounts for
interactions between parameters. Second, we use the novel partial information
decomposition (PID) framework that allows to quantify redundant and synergistic
contributions between selected parameters with respect to the optimization
outcome to identify parameter interactions. We thus demonstrate the power of
novel information-theoretic approaches in identifying relevant parameters in
optimization runs and highlight how these methods avoid the selection of
redundant parameters, while detecting interactions that result in synergistic
contributions of multiple parameters.

    

### [[2112.05611] Eigenspace Restructuring: a Principle of Space and Frequency in Neural Networks](http://arxiv.org/abs/2112.05611)


  Understanding the fundamental principles behind the massive success of neural
networks is one of the most important open questions in deep learning. However,
due to the highly complex nature of the problem, progress has been relatively
slow. In this note, through the lens of infinite-width networks, a.k.a. neural
kernels, we present one such principle resulting from hierarchical localities.
It is well-known that the eigenstructure of infinite-width multilayer
perceptrons (MLPs) depends solely on the concept frequency, which measures the
order of interactions. We show that the topologies from deep convolutional
networks (CNNs) restructure the associated eigenspaces into finer subspaces. In
addition to frequency, the new structure also depends on the concept space,
which measures the spatial distance among nonlinear interaction terms. The
resulting fine-grained eigenstructure dramatically improves the network's
learnability, empowering them to simultaneously model a much richer class of
interactions, including Long-Range-Low-Frequency interactions,
Short-Range-High-Frequency interactions, and various interpolations and
extrapolations in-between. Additionally, model scaling can improve the
resolutions of interpolations and extrapolations and, therefore, the network's
learnability. Finally, we prove a sharp characterization of the generalization
error for infinite-width CNNs of any depth in the high-dimensional setting. Two
corollaries follow: (1) infinite-width deep CNNs can break the curse of
dimensionality without losing their expressivity, and (2) scaling improves
performance in both the finite and infinite data regimes.

    

### [[2112.05620] How to Avoid Trivial Solutions in Physics-Informed Neural Networks](http://arxiv.org/abs/2112.05620)


  The advent of scientific machine learning (SciML) has opened up a new field
with many promises and challenges in the field of simulation science by
developing approaches at the interface of physics- and data-based modelling. To
this end, physics-informed neural networks (PINNs) have been introduced in
recent years, which cope for the scarcity in training data by incorporating
physics knowledge of the problem at so-called collocation points. In this work,
we investigate the prediction performance of PINNs with respect to the number
of collocation points used to enforce the physics-based penalty terms. We show
that PINNs can fail, learning a trivial solution that fulfills the
physics-derived penalty term by definition. We have developed an alternative
sampling approach and a new penalty term enabling us to remedy this core
problem of PINNs in data-scarce settings with competitive results while
reducing the amount of collocation points needed by up to 80 \% for benchmark
problems.

    

### [[2112.05630] On Fair Selection in the Presence of Implicit and Differential Variance](http://arxiv.org/abs/2112.05630)


  Discrimination in selection problems such as hiring or college admission is
often explained by implicit bias from the decision maker against disadvantaged
demographic groups. In this paper, we consider a model where the decision maker
receives a noisy estimate of each candidate's quality, whose variance depends
on the candidate's group -- we argue that such differential variance is a key
feature of many selection problems. We analyze two notable settings: in the
first, the noise variances are unknown to the decision maker who simply picks
the candidates with the highest estimated quality independently of their group;
in the second, the variances are known and the decision maker picks candidates
having the highest expected quality given the noisy estimate. We show that both
baseline decision makers yield discrimination, although in opposite directions:
the first leads to underrepresentation of the low-variance group while the
second leads to underrepresentation of the high-variance group. We study the
effect on the selection utility of imposing a fairness mechanism that we term
the $\gamma$-rule (it is an extension of the classical four-fifths rule and it
also includes demographic parity). In the first setting (with unknown
variances), we prove that under mild conditions, imposing the $\gamma$-rule
increases the selection utility -- here there is no trade-off between fairness
and utility. In the second setting (with known variances), imposing the
$\gamma$-rule decreases the utility but we prove a bound on the utility loss
due to the fairness mechanism.

    

### [[2112.05634] Preemptive Image Robustification for Protecting Users against Man-in-the-Middle Adversarial Attacks](http://arxiv.org/abs/2112.05634)


  Deep neural networks have become the driving force of modern image
recognition systems. However, the vulnerability of neural networks against
adversarial attacks poses a serious threat to the people affected by these
systems. In this paper, we focus on a real-world threat model where a
Man-in-the-Middle adversary maliciously intercepts and perturbs images web
users upload online. This type of attack can raise severe ethical concerns on
top of simple performance degradation. To prevent this attack, we devise a
novel bi-level optimization algorithm that finds points in the vicinity of
natural images that are robust to adversarial perturbations. Experiments on
CIFAR-10 and ImageNet show our method can effectively robustify natural images
within the given modification budget. We also show the proposed method can
improve robustness when jointly used with randomized smoothing.

    

### [[2112.05653] Interpretable Clustering via Multi-Polytope Machines](http://arxiv.org/abs/2112.05653)


  Clustering is a popular unsupervised learning tool often used to discover
groups within a larger population such as customer segments, or patient
subtypes. However, despite its use as a tool for subgroup discovery and
description - few state-of-the-art algorithms provide any rationale or
description behind the clusters found. We propose a novel approach for
interpretable clustering that both clusters data points and constructs
polytopes around the discovered clusters to explain them. Our framework allows
for additional constraints on the polytopes - including ensuring that the
hyperplanes constructing the polytope are axis-parallel or sparse with integer
coefficients. We formulate the problem of constructing clusters via polytopes
as a Mixed-Integer Non-Linear Program (MINLP). To solve our formulation we
propose a two phase approach where we first initialize clusters and polytopes
using alternating minimization, and then use coordinate descent to boost
clustering performance. We benchmark our approach on a suite of synthetic and
real world clustering problems, where our algorithm outperforms state of the
art interpretable and non-interpretable clustering algorithms.

    

### [[2112.05657] Artificial Intellgence -- Application in Life Sciences and Beyond. The Upper Rhine Artificial Intelligence Symposium UR-AI 2021](http://arxiv.org/abs/2112.05657)


  The TriRhenaTech alliance presents the accepted papers of the 'Upper-Rhine
Artificial Intelligence Symposium' held on October 27th 2021 in Kaiserslautern,
Germany. Topics of the conference are applications of Artificial Intellgence in
life sciences, intelligent systems, industry 4.0, mobility and others. The
TriRhenaTech alliance is a network of universities in the Upper-Rhine
Trinational Metropolitan Region comprising of the German universities of
applied sciences in Furtwangen, Kaiserslautern, Karlsruhe, Offenburg and Trier,
the Baden-Wuerttemberg Cooperative State University Loerrach, the French
university network Alsace Tech (comprised of 14 'grandes coles' in the
fields of engineering, architecture and management) and the University of
Applied Sciences and Arts Northwestern Switzerland. The alliance's common goal
is to reinforce the transfer of knowledge, research, and technology, as well as
the cross-border mobility of students.

    

### [[2112.05664] On the Relationships between Transform-Learning NMF and Joint-Diagonalization](http://arxiv.org/abs/2112.05664)


  Non-negative matrix factorization with transform learning (TL-NMF) is a
recent idea that aims at learning data representations suited to NMF. In this
work, we relate TL-NMF to the classical matrix joint-diagonalization (JD)
problem. We show that, when the number of data realizations is sufficiently
large, TL-NMF can be replaced by a two-step approach -- termed as JD+NMF --
that estimates the transform through JD, prior to NMF computation. In contrast,
we found that when the number of data realizations is limited, not only is
JD+NMF no longer equivalent to TL-NMF, but the inherent low-rank constraint of
TL-NMF turns out to be an essential ingredient to learn meaningful transforms
for NMF.

    

### [[2112.05667] A Deep Learning Based Automated Hand Hygiene Training System](http://arxiv.org/abs/2112.05667)


  Hand hygiene is crucial for preventing viruses and infections. Due to the
pervasive outbreak of COVID-19, wearing a mask and hand hygiene appear to be
the most effective ways for the public to curb the spread of these viruses. The
World Health Organization (WHO) recommends a guideline for alcohol-based hand
rub in eight steps to ensure that all surfaces of hands are entirely clean. As
these steps involve complex gestures, human assessment of them lacks enough
accuracy. However, Deep Neural Network (DNN) and machine vision have made it
possible to accurately evaluate hand rubbing quality for the purposes of
training and feedback. In this paper, an automated deep learning based hand rub
assessment system with real-time feedback is presented. The system evaluates
the compliance with the 8-step guideline using a DNN architecture trained on a
dataset of videos collected from volunteers with various skin tones and hand
characteristics following the hand rubbing guideline. Various DNN architectures
were tested, and an Inception-ResNet model led to the best results with 97%
test accuracy. In the proposed system, an NVIDIA Jetson AGX Xavier embedded
board runs the software. The efficacy of the system is evaluated in a concrete
situation of being used by various users, and challenging steps are identified.
In this experiment, the average time taken by the hand rubbing steps among
volunteers is 27.2 seconds, which conforms to the WHO guidelines.

    

### [[2112.05673] Neural Multi-Quantile Forecasting for Optimal Inventory Management](http://arxiv.org/abs/2112.05673)


  In this work we propose the use of quantile regression and dilated recurrent
neural networks with temporal scaling (MQ-DRNN-s) and apply it to the inventory
management task. This model showed a better performance of up to 3.2\% over a
statistical benchmark (the quantile autoregressive model with exogenous
variables, QAR-X), being better than the MQ-DRNN without temporal scaling by
6\%. The above on a set of 10,000 time series of sales of El Globo over a
53-week horizon using rolling windows of 7-day ahead each week.

    

### [[2112.05677] Concept Representation Learning with Contrastive Self-Supervised Learning](http://arxiv.org/abs/2112.05677)


  Concept-oriented deep learning (CODL) is a general approach to meet the
future challenges for deep learning: (1) learning with little or no external
supervision, (2) coping with test examples that come from a different
distribution than the training examples, and (3) integrating deep learning with
symbolic AI. In CODL, as in human learning, concept representations are learned
based on concept exemplars. Contrastive self-supervised learning (CSSL)
provides a promising approach to do so, since it: (1) uses data-driven
associations, to get away from semantic labels, (2) supports incremental and
continual learning, to get away from (large) fixed datasets, and (3)
accommodates emergent objectives, to get away from fixed objectives (tasks). We
discuss major aspects of concept representation learning using CSSL. These
include dual-level concept representations, CSSL for feature representations,
exemplar similarity measures and self-supervised relational reasoning,
incremental and continual CSSL, and contrastive self-supervised concept (class)
incremental learning. The discussion leverages recent findings from cognitive
neural science and CSSL.

    

### [[2112.05682] Self-attention Does Not Need $O(n^2)$ Memory](http://arxiv.org/abs/2112.05682)


  We present a very simple algorithm for attention that requires $O(1)$ memory
with respect to sequence length and an extension to self-attention that
requires $O(\log n)$ memory. This is in contrast with the frequently stated
belief that self-attention requires $O(n^2)$ memory. While the time complexity
is still $O(n^2)$, device memory rather than compute capability is often the
limiting factor on modern accelerators. Thus, reducing the memory requirements
of attention allows processing of longer sequences than might otherwise be
feasible. We provide a practical implementation for accelerators that requires
$O(\sqrt{n})$ memory, is numerically stable, and is within a few percent of the
runtime of the standard implementation of attention. We also demonstrate how to
differentiate the function while remaining memory-efficient. For sequence
length 16384, the memory overhead of self-attention is reduced by 59X for
inference and by 32X for differentiation.

    

### [[2112.05683] Boosting Active Learning via Improving Test Performance](http://arxiv.org/abs/2112.05683)


  Central to active learning (AL) is what data should be selected for
annotation. Existing works attempt to select highly uncertain or informative
data for annotation. Nevertheless, it remains unclear how selected data impacts
the test performance of the task model used in AL. In this work, we explore
such an impact by theoretically proving that selecting unlabeled data of higher
gradient norm leads to a lower upper bound of test loss, resulting in a better
test performance. However, due to the lack of label information, directly
computing gradient norm for unlabeled data is infeasible. To address this
challenge, we propose two schemes, namely expected-gradnorm and
entropy-gradnorm. The former computes the gradient norm by constructing an
expected empirical loss while the latter constructs an unsupervised loss with
entropy. Furthermore, we integrate the two schemes in a universal AL framework.
We evaluate our method on classical image classification and semantic
segmentation tasks. To demonstrate its competency in domain applications and
its robustness to noise, we also validate our method on a cellular imaging
analysis task, namely cryo-Electron Tomography subtomogram classification.
Results demonstrate that our method achieves superior performance against the
state-of-the-art. Our source code is available at
this https URL


### [[2112.05687] Federated Two-stage Learning with Sign-based Voting](http://arxiv.org/abs/2112.05687)


  Federated learning is a distributed machine learning mechanism where local
devices collaboratively train a shared global model under the orchestration of
a central server, while keeping all private data decentralized. In the system,
model parameters and its updates are transmitted instead of raw data, and thus
the communication bottleneck has become a key challenge. Besides, recent larger
and deeper machine learning models also pose more difficulties in deploying
them in a federated environment. In this paper, we design a federated two-stage
learning framework that augments prototypical federated learning with a cut
layer on devices and uses sign-based stochastic gradient descent with the
majority vote method on model updates. Cut layer on devices learns informative
and low-dimension representations of raw data locally, which helps reduce
global model parameters and prevents data leakage. Sign-based SGD with the
majority vote method for model updates also helps alleviate communication
limitations. Empirically, we show that our system is an efficient and privacy
preserving federated learning scheme and suits for general application
scenarios.

    

### [[2112.05692] VUT: Versatile UI Transformer for Multi-Modal Multi-Task User Interface Modeling](http://arxiv.org/abs/2112.05692)


  User interface modeling is inherently multimodal, which involves several
distinct types of data: images, structures and language. The tasks are also
diverse, including object detection, language generation and grounding. In this
paper, we present VUT, a Versatile UI Transformer that takes multimodal input
and simultaneously accomplishes 5 distinct tasks with the same model. Our model
consists of a multimodal Transformer encoder that jointly encodes UI images and
structures, and performs UI object detection when the UI structures are absent
in the input. Our model also consists of an auto-regressive Transformer model
that encodes the language input and decodes output, for both question-answering
and command grounding with respect to the UI. Our experiments show that for
most of the tasks, when trained jointly for multi-tasks, VUT substantially
reduces the number of models and footprints needed for performing multiple
tasks, while achieving accuracy exceeding or on par with baseline models
trained for each individual task.

    

### [[2112.05694] unrolling palm for sparse semi-blind source separation](http://arxiv.org/abs/2112.05694)


  Sparse Blind Source Separation (BSS) has become a well established tool for a
wide range of applications - for instance, in astrophysics and remote sensing.
Classical sparse BSS methods, such as the Proximal Alternating Linearized
Minimization (PALM) algorithm, nevertheless often suffer from a difficult
hyperparameter choice, which undermines their results. To bypass this pitfall,
we propose in this work to build on the thriving field of algorithm
unfolding/unrolling. Unrolling PALM enables to leverage the data-driven
knowledge stemming from realistic simulations or ground-truth data by learning
both PALM hyperparameters and variables. In contrast to most existing unrolled
algorithms, which assume a fixed known dictionary during the training and
testing phases, this article further emphasizes on the ability to deal with
variable mixing matrices (a.k.a. dictionaries). The proposed Learned PALM
(LPALM) algorithm thus enables to perform semi-blind source separation, which
is key to increase the generalization of the learnt model in real-world
applications. We illustrate the relevance of LPALM in astrophysical
multispectral imaging: the algorithm not only needs up to $10^4-10^5$ times
fewer iterations than PALM, but also improves the separation quality, while
avoiding the cumbersome hyperparameter and initialization choice of PALM. We
further show that LPALM outperforms other unrolled source separation methods in
the semi-blind setting.

    

### [[2112.05695] Causal Knowledge Guided Societal Event Forecasting](http://arxiv.org/abs/2112.05695)


  Data-driven societal event forecasting methods exploit relevant historical
information to predict future events. These methods rely on historical labeled
data and cannot accurately predict events when data are limited or of poor
quality. Studying causal effects between events goes beyond correlation
analysis and can contribute to a more robust prediction of events. However,
incorporating causality analysis in data-driven event forecasting is
challenging due to several factors: (i) Events occur in a complex and dynamic
social environment. Many unobserved variables, i.e., hidden confounders, affect
both potential causes and outcomes. (ii) Given spatiotemporal non-independent
and identically distributed (non-IID) data, modeling hidden confounders for
accurate causal effect estimation is not trivial. In this work, we introduce a
deep learning framework that integrates causal effect estimation into event
forecasting. We first study the problem of Individual Treatment Effect (ITE)
estimation from observational event data with spatiotemporal attributes and
present a novel causal inference model to estimate ITEs. We then incorporate
the learned event-related causal information into event prediction as prior
knowledge. Two robust learning modules, including a feature reweighting module
and an approximate constraint loss, are introduced to enable prior knowledge
injection. We evaluate the proposed causal inference model on real-world event
datasets and validate the effectiveness of proposed robust learning modules in
event prediction by feeding learned causal information into different deep
learning methods. Experimental results demonstrate the strengths of the
proposed causal inference model for ITE estimation in societal events and
showcase the beneficial properties of robust learning modules in societal event
forecasting.

    

### [[2112.05702] Sampling from Discrete Energy-Based Models with Quality/Efficiency Trade-offs](http://arxiv.org/abs/2112.05702)


  Energy-Based Models (EBMs) allow for extremely flexible specifications of
probability distributions. However, they do not provide a mechanism for
obtaining exact samples from these distributions. Monte Carlo techniques can
aid us in obtaining samples if some proposal distribution that we can easily
sample from is available. For instance, rejection sampling can provide exact
samples but is often difficult or impossible to apply due to the need to find a
proposal distribution that upper-bounds the target distribution everywhere.
Approximate Markov chain Monte Carlo sampling techniques like
Metropolis-Hastings are usually easier to design, exploiting a local proposal
distribution that performs local edits on an evolving sample. However, these
techniques can be inefficient due to the local nature of the proposal
distribution and do not provide an estimate of the quality of their samples. In
this work, we propose a new approximate sampling technique, Quasi Rejection
Sampling (QRS), that allows for a trade-off between sampling efficiency and
sampling quality, while providing explicit convergence bounds and diagnostics.
QRS capitalizes on the availability of high-quality global proposal
distributions obtained from deep learning models. We demonstrate the
effectiveness of QRS sampling for discrete EBMs over text for the tasks of
controlled text generation with distributional constraints and paraphrase
generation. We show that we can sample from such EBMs with arbitrary precision
at the cost of sampling efficiency.

    

### [[2112.05705] Pruning Pretrained Encoders with a Multitask Objective](http://arxiv.org/abs/2112.05705)


  The sizes of pretrained language models make them challenging and expensive
to use when there are multiple desired downstream tasks. In this work, we adopt
recent strategies for model pruning during finetuning to explore the question
of whether it is possible to prune a single encoder so that it can be used for
multiple tasks. We allocate a fixed parameter budget and compare pruning a
single model with a multitask objective against the best ensemble of
single-task models. We find that under two pruning strategies (element-wise and
rank pruning), the approach with the multitask objective outperforms training
models separately when averaged across all tasks, and it is competitive on each
individual one. Additional analysis finds that using a multitask objective
during pruning can also be an effective method for reducing model sizes for
low-resource tasks.

    

### [[2112.05717] Discourse-Aware Prompt Design for Text Generation](http://arxiv.org/abs/2112.05717)


  Current efficient fine-tuning methods (e.g., adapters, prefix-tuning, etc.)
have optimized conditional text generation via training a small set of extra
parameters of the neural language model, while freezing the rest for
efficiency. While showing strong performance on some generation tasks, they
don't generalize across all generation tasks. In this work, we show that prompt
based conditional text generation can be improved with simple and efficient
methods that simulate modeling the discourse structure of human written text.
We introduce two key design choices: First we show that a higher-level
discourse structure of human written text can be modelled with
\textit{hierarchical blocking} on prefix parameters that enable spanning
different parts of the input and output text and yield more coherent output
generations. Second, we propose sparse prefix tuning by introducing
\textit{attention sparsity} on the prefix parameters at different layers of the
network and learn sparse transformations on the softmax-function, respectively.
We find that sparse attention enables the prefix-tuning to better control of
the input contents (salient facts) yielding more efficient tuning of the
prefix-parameters. Experiments on a wide-variety of text generation tasks show
that structured design of prefix parameters can achieve comparable results to
fine-tuning all parameters while outperforming standard prefix-tuning on all
generation tasks even in low-resource settings.

    

### [[2112.05729] Learning soft interventions in complex equilibrium systems](http://arxiv.org/abs/2112.05729)


  Complex systems often contain feedback loops that can be described as cyclic
causal models. Intervening in such systems may lead to counter-intuitive
effects, which cannot be inferred directly from the graph structure. After
establishing a framework for differentiable interventions based on Lie groups,
we take advantage of modern automatic differentiation techniques and their
application to implicit functions in order to optimize interventions in cyclic
causal models. We illustrate the use of this framework by investigating
scenarios of transition to sustainable economies.

    

### [[2112.05745] A Simple and Efficient Sampling-based Algorithm for General Reachability Analysis](http://arxiv.org/abs/2112.05745)


  In this work, we analyze an efficient sampling-based algorithm for
general-purpose reachability analysis, which remains a notoriously challenging
problem with applications ranging from neural network verification to safety
analysis of dynamical systems. By sampling inputs, evaluating their images in
the true reachable set, and taking their $\epsilon$-padded convex hull as a set
estimator, this algorithm applies to general problem settings and is simple to
implement. Our main contribution is the derivation of asymptotic and
finite-sample accuracy guarantees using random set theory. This analysis
informs algorithmic design to obtain an $\epsilon$-close reachable set
approximation with high probability, provides insights into which reachability
problems are most challenging, and motivates safety-critical applications of
the technique. On a neural network verification task, we show that this
approach is more accurate and significantly faster than prior work. Informed by
our analysis, we also design a robust model predictive controller that we
demonstrate in hardware experiments.

    

### [[2112.05746] On Causally Disentangled Representations](http://arxiv.org/abs/2112.05746)


  Representation learners that disentangle factors of variation have already
proven to be important in addressing various real world concerns such as
fairness and interpretability. Initially consisting of unsupervised models with
independence assumptions, more recently, weak supervision and correlated
features have been explored, but without a causal view of the generative
process. In contrast, we work under the regime of a causal generative process
where generative factors are either independent or can be potentially
confounded by a set of observed or unobserved confounders. We present an
analysis of disentangled representations through the notion of disentangled
causal process. We motivate the need for new metrics and datasets to study
causal disentanglement and propose two evaluation metrics and a dataset. We
show that our metrics capture the desiderata of disentangled causal process.
Finally, we perform an empirical study on state of the art disentangled
representation learners using our metrics and dataset to evaluate them from
causal perspective.

    

### [[1906.07125] Replacing the do-calculus with Bayes rule](http://arxiv.org/abs/1906.07125)


  The concept of causality has a controversial history. The question of whether
it is possible to represent and address causal problems with probability
theory, or if fundamentally new mathematics such as the do calculus is required
has been hotly debated, e.g. Pearl (2001) states "the building blocks of our
scientific and everyday knowledge are elementary facts such as "mud does not
cause rain" and "symptoms do not cause disease" and those facts, strangely
enough, cannot be expressed in the vocabulary of probability calculus". This
has lead to a dichotomy between advocates of causal graphical modeling and the
do calculus, and researchers applying Bayesian methods. In this paper we
demonstrate that, while it is critical to explicitly model our assumptions on
the impact of intervening in a system, provided we do so, estimating causal
effects can be done entirely within the standard Bayesian paradigm. The
invariance assumptions underlying causal graphical models can be encoded in
ordinary Probabilistic graphical models, allowing causal estimation with
Bayesian statistics, equivalent to the do calculus. Elucidating the connections
between these approaches is a key step toward enabling the insights provided by
each to be combined to solve real problems.

    

### [[2006.10885] The Dilemma Between Data Transformations and Adversarial Robustness for Time Series Application Systems](http://arxiv.org/abs/2006.10885)


  Adversarial examples, or nearly indistinguishable inputs created by an
attacker, significantly reduce machine learning accuracy. Theoretical evidence
has shown that the high intrinsic dimensionality of datasets facilitates an
adversary's ability to develop effective adversarial examples in classification
models. Adjacently, the presentation of data to a learning model impacts its
performance. For example, we have seen this through dimensionality reduction
techniques used to aid with the generalization of features in machine learning
applications. Thus, data transformation techniques go hand-in-hand with
state-of-the-art learning models in decision-making applications such as
intelligent medical or military systems. With this work, we explore how data
transformations techniques such as feature selection, dimensionality reduction,
or trend extraction techniques may impact an adversary's ability to create
effective adversarial samples on a recurrent neural network. Specifically, we
analyze it from the perspective of the data manifold and the presentation of
its intrinsic features. Our evaluation empirically shows that feature selection
and trend extraction techniques may increase the RNN's vulnerability. A data
transformation technique reduces the vulnerability to adversarial examples only
if it approximates the dataset's intrinsic dimension, minimizes codimension,
and maintains higher manifold coverage.

    

### [[2007.01386] Posterior Model Adaptation With Updated Priors](http://arxiv.org/abs/2007.01386)


  Classification approaches based on the direct estimation and analysis of
posterior probabilities will degrade if the original class priors begin to
change. We prove that a unique (up to scale) solution is possible to recover
the data likelihoods for a test example from its original class posteriors and
dataset priors. Given the recovered likelihoods and a set of new priors, the
posteriors can be re-computed using Bayes' Rule to reflect the influence of the
new priors. The method is simple to compute and allows a dynamic update of the
original posteriors.

    

### [[2007.02519] FLUID: A Unified Evaluation Framework for Flexible Sequential Data](http://arxiv.org/abs/2007.02519)


  Modern ML methods excel when training data is IID, large-scale, and well
labeled. Learning in less ideal conditions remains an open challenge. The
sub-fields of few-shot, continual, transfer, and representation learning have
made substantial strides in learning under adverse conditions; each affording
distinct advantages through methods and insights. These methods address
different challenges such as data arriving sequentially or scarce training
examples, however often the difficult conditions an ML system will face over
its lifetime cannot be anticipated prior to deployment. Therefore, general ML
systems which can handle the many challenges of learning in practical settings
are needed. To foster research towards the goal of general ML methods, we
introduce a new unified evaluation framework - FLUID (Flexible Sequential
Data). FLUID integrates the objectives of few-shot, continual, transfer, and
representation learning while enabling comparison and integration of techniques
across these subfields. In FLUID, a learner faces a stream of data and must
make sequential predictions while choosing how to update itself, adapt quickly
to novel classes, and deal with changing data distributions; while accounting
for the total amount of compute. We conduct experiments on a broad set of
methods which shed new insight on the advantages and limitations of current
solutions and indicate new research problems to solve. As a starting point
towards more general methods, we present two new baselines which outperform
other evaluated methods on FLUID. Project page:
this https URL.

    

### [[2009.04614] End-to-end Kernel Learning via Generative Random Fourier Features](http://arxiv.org/abs/2009.04614)


  Random Fourier features (RFFs) provide a promising way for kernel learning in
a spectral case. Current RFFs-based kernel learning methods usually work in a
two-stage way. In the first-stage process, learning the optimal feature map is
often formulated as a target alignment problem, which aims to align the learned
kernel with the pre-defined target kernel (usually the ideal kernel). In the
second-stage process, a linear learner is conducted with respect to the mapped
random features. Nevertheless, the pre-defined kernel in target alignment is
not necessarily optimal for the generalization of the linear learner. Instead,
in this paper, we consider a one-stage process that incorporates the kernel
learning and linear learner into a unifying framework. To be specific, a
generative network via RFFs is devised to implicitly learn the kernel, followed
by a linear classifier parameterized as a full-connected layer. Then the
generative network and the classifier are jointly trained by solving the
empirical risk minimization (ERM) problem to reach a one-stage solution. This
end-to-end scheme naturally allows deeper features, in correspondence to a
multi-layer structure, and shows superior generalization performance over the
classical two-stage, RFFs-based methods in real-world classification tasks.
Moreover, inspired by the randomized resampling mechanism of the proposed
method, its enhanced adversarial robustness is investigated and experimentally
verified.

    

### [[2102.04323] Discovering a set of policies for the worst case reward](http://arxiv.org/abs/2102.04323)


  We study the problem of how to construct a set of policies that can be
composed together to solve a collection of reinforcement learning tasks. Each
task is a different reward function defined as a linear combination of known
features. We consider a specific class of policy compositions which we call set
improving policies (SIPs): given a set of policies and a set of tasks, a SIP is
any composition of the former whose performance is at least as good as that of
its constituents across all the tasks. We focus on the most conservative
instantiation of SIPs, set-max policies (SMPs), so our analysis extends to any
SIP. This includes known policy-composition operators like generalized policy
improvement. Our main contribution is a policy iteration algorithm that builds
a set of policies in order to maximize the worst-case performance of the
resulting SMP on the set of tasks. The algorithm works by successively adding
new policies to the set. We show that the worst-case performance of the
resulting SMP strictly improves at each iteration, and the algorithm only stops
when there does not exist a policy that leads to improved performance. We
empirically evaluate our algorithm on a grid world and also on a set of domains
from the DeepMind control suite. We confirm our theoretical results regarding
the monotonically improving performance of our algorithm. Interestingly, we
also show empirically that the sets of policies computed by the algorithm are
diverse, leading to different trajectories in the grid world and very distinct
locomotion skills in the control suite.

    

### [[2103.00039] Practical and Private (Deep) Learning without Sampling or Shuffling](http://arxiv.org/abs/2103.00039)


  We consider training models with differential privacy (DP) using mini-batch
gradients. The existing state-of-the-art, Differentially Private Stochastic
Gradient Descent (DP-SGD), requires privacy amplification by sampling or
shuffling to obtain the best privacy/accuracy/computation trade-offs.
Unfortunately, the precise requirements on exact sampling and shuffling can be
hard to obtain in important practical scenarios, particularly federated
learning (FL). We design and analyze a DP variant of
Follow-The-Regularized-Leader (DP-FTRL) that compares favorably (both
theoretically and empirically) to amplified DP-SGD, while allowing for much
more flexible data access patterns. DP-FTRL does not use any form of privacy
amplification.
The code is available at
this https URL and
this https URL .

    

### [[2104.01924] DexDeepFM: Ensemble Diversity Enhanced Extreme Deep Factorization Machine Model](http://arxiv.org/abs/2104.01924)


  Predicting user positive response (e.g., purchases and clicks) probability is
a critical task in Web applications. To identify predictive features from raw
data, the state-of-the-art extreme deep factorization machine model (xDeepFM)
introduces a new interaction network to leverage feature interactions at the
vector-wise level explicitly. However, since each hidden layer in the
interaction network is a collection of feature maps, it can be viewed
essentially as an ensemble of different feature maps. In this case, only using
a single objective to minimize the prediction loss may lead to overfitting and
generate correlated errors. In this paper, an ensemble diversity enhanced
extreme deep factorization machine model (DexDeepFM) is proposed, which designs
the ensemble diversity measure in each hidden layer and considers both ensemble
diversity and prediction accuracy in the objective function. In addition, the
attention mechanism is introduced to discriminate the importance of ensemble
diversity measures with different feature interaction orders. Extensive
experiments on three public real-world datasets are conducted to show the
effectiveness of the proposed model.

    

### [[2104.02811] C2CL: Contact to Contactless Fingerprint Matching](http://arxiv.org/abs/2104.02811)


  Matching contactless fingerprints or finger photos to contact-based
fingerprint impressions has received increased attention in the wake of
COVID-19 due to the superior hygiene of the contactless acquisition and the
widespread availability of low cost mobile phones capable of capturing photos
of fingerprints with sufficient resolution for verification purposes. This
paper presents an end-to-end automated system, called C2CL, comprised of a
mobile finger photo capture app, preprocessing, and matching algorithms to
handle the challenges inhibiting previous cross-matching methods; namely i) low
ridge-valley contrast of contactless fingerprints, ii) varying roll, pitch,
yaw, and distance of the finger to the camera, iii) non-linear distortion of
contact-based fingerprints, and vi) different image qualities of smartphone
cameras. Our preprocessing algorithm segments, enhances, scales, and unwarps
contactless fingerprints, while our matching algorithm extracts both minutiae
and texture representations. A sequestered dataset of 9,888 contactless 2D
fingerprints and corresponding contact-based fingerprints from 206 subjects (2
thumbs and 2 index fingers for each subject) acquired using our mobile capture
app is used to evaluate the cross-database performance of our proposed
algorithm. Furthermore, additional experimental results on 3 publicly available
datasets show substantial improvement in the state-of-the-art for contact to
contactless fingerprint matching (TAR in the range of 96.67% to 98.30% at
FAR=0.01%).

    

### [[2104.11186] Stochastic Shortest Path: Minimax, Parameter-Free and Towards Horizon-Free Regret](http://arxiv.org/abs/2104.11186)


  We study the problem of learning in the stochastic shortest path (SSP)
setting, where an agent seeks to minimize the expected cost accumulated before
reaching a goal state. We design a novel model-based algorithm EB-SSP that
carefully skews the empirical transitions and perturbs the empirical costs with
an exploration bonus to induce an optimistic SSP problem whose associated value
iteration scheme is guaranteed to converge. We prove that EB-SSP achieves the
minimax regret rate $\tilde{O}(B_{\star} \sqrt{S A K})$, where $K$ is the
number of episodes, $S$ is the number of states, $A$ is the number of actions,
and $B_{\star}$ bounds the expected cumulative cost of the optimal policy from
any state, thus closing the gap with the lower bound. Interestingly, EB-SSP
obtains this result while being parameter-free, i.e., it does not require any
prior knowledge of $B_{\star}$, nor of $T_{\star}$, which bounds the expected
time-to-goal of the optimal policy from any state. Furthermore, we illustrate
various cases (e.g., positive costs, or general costs when an order-accurate
estimate of $T_{\star}$ is available) where the regret only contains a
logarithmic dependence on $T_{\star}$, thus yielding the first (nearly)
horizon-free regret bound beyond the finite-horizon MDP setting.

    

### [[2106.00753] Is good old GRAPPA dead?](http://arxiv.org/abs/2106.00753)


  We perform a qualitative analysis of performance of XPDNet, a
state-of-the-art deep learning approach for MRI reconstruction, compared to
GRAPPA, a classical approach. We do this in multiple settings, in particular
testing the robustness of the XPDNet to unseen settings, and show that the
XPDNet can to some degree generalize well.

    

### [[2106.05586] Data augmentation in Bayesian neural networks and the cold posterior effect](http://arxiv.org/abs/2106.05586)


  Bayesian neural networks that incorporate data augmentation implicitly use a
``randomly perturbed log-likelihood [which] does not have a clean
interpretation as a valid likelihood function'' (Izmailov et al. 2021). Here,
we provide several approaches to developing principled Bayesian neural networks
incorporating data augmentation. We introduce a ``finite orbit'' setting which
allows likelihoods to be computed exactly, and give tight multi-sample bounds
in the more usual ``full orbit'' setting. These models cast light on the origin
of the cold posterior effect. In particular, we find that the cold posterior
effect persists even in these principled models incorporating data
augmentation. This suggests that the cold posterior effect cannot be dismissed
as an artifact of data augmentation using incorrect likelihoods.

    

### [[2112.05322] Dynamic hardware system for cascade SVM classification of melanoma](http://arxiv.org/abs/2112.05322)


  Melanoma is the most dangerous form of skin cancer, which is responsible for
the majority of skin cancer-related deaths. Early diagnosis of melanoma can
significantly reduce mortality rates and treatment costs. Therefore, skin
cancer specialists are using image-based diagnostic tools for detecting
melanoma earlier. We aim to develop a handheld device featured with low cost
and high performance to enhance early detection of melanoma at the primary
healthcare. But, developing this device is very challenging due to the
complicated computations required by the embedded diagnosis system. Thus, we
aim to exploit the recent hardware technology in reconfigurable computing to
achieve a high-performance embedded system at low cost. Support vector machine
(SVM) is a common classifier that shows high accuracy for classifying melanoma
within the diagnosis system and is considered as the most compute-intensive
task in the system. In this paper, we propose a dynamic hardware system for
implementing a cascade SVM classifier on FPGA for early melanoma detection. A
multi-core architecture is proposed to implement a two-stage cascade classifier
using two classifiers with accuracies of 98% and 73%. The hardware
implementation results were optimized by using the dynamic partial
reconfiguration technology, where very low resource utilization of 1% slices
and power consumption of 1.5 W were achieved. Consequently, the implemented
dynamic hardware system meets vital embedded system constraints of high
performance and low cost, resource utilization, and power consumption, while
achieving efficient classification with high accuracy.

    

### [[2112.05607] FLiMS: a Fast Lightweight 2-way Merge Sorter](http://arxiv.org/abs/2112.05607)


  In this paper, we present FLiMS, a highly-efficient and simple parallel
algorithms for merging two sorted lists residing in banked and/or wide memory.
On FPGAs, its implementation uses fewer hardware resources than the
state-of-the-art alternatives, due to the reduced number of comparators and
elimination of redundant logic found on prior attempts. In combination with the
distributed nature of the selector stage, a higher performance is achieved for
the same amount of parallelism or higher. This is useful in many applications
such as in parallel merge trees to achieve high-throughput sorting, where the
resource utilisation of the merger is critical for building larger trees and
internalising the workload for faster computation. Also presented are efficient
variations of FLiMS for optimizing throughput for skewed datasets, achieving
stable sorting or using fewer dequeue signals. FLiMS is also shown to perform
well as conventional software on modern CPUs supporting single-instruction
multiple-data (SIMD) instructions, surpassing the performance of some standard
libraries for sorting.

    

### [[2112.05660] DPU: DAG Processing Unit for Irregular Graphs with Precision-Scalable Posit Arithmetic in 28nm](http://arxiv.org/abs/2112.05660)


  Computation in several real-world applications like probabilistic machine
learning, sparse linear algebra, and robotic navigation, can be modeled as
irregular directed acyclic graphs (DAGs). The irregular data dependencies in
DAGs pose challenges to parallel execution on general-purpose CPUs and GPUs,
resulting in severe under-utilization of the hardware. This paper proposes DPU,
a specialized processor designed for the efficient execution of irregular DAGs.
The DPU is equipped with parallel compute units that execute different
subgraphs of a DAG independently. The compute units can synchronize within a
cycle using a hardware-supported synchronization primitive, and communicate via
an efficient interconnect to a global banked scratchpad. Furthermore, a
precision-scalable posit arithmetic unit is developed to enable
application-dependent precision. The DPU is taped-out in 28nm CMOS, achieving a
speedup of 5.1$\times$ and 20.6$\times$ over state-of-the-art CPU and GPU
implementations on DAGs of sparse linear algebra and probabilistic machine
learning workloads. This performance is achieved while operating at a power
budget of 0.23W, as opposed to 55W and 98W of the CPU and GPU, resulting in a
peak efficiency of 538 GOPS/W with DPU, which is 1350$\times$ and 9000$\times$
higher than the CPU and GPU, respectively. Thus, with specialized architecture,
DPU enables low-power execution of irregular DAG workloads.

    

### [[2112.05719] Attacks on Wireless Coexistence: Exploiting Cross-Technology Performance Features for Inter-Chip Privilege Escalation](http://arxiv.org/abs/2112.05719)


  Modern mobile devices feature multiple wireless technologies, such as
Bluetooth, Wi-Fi, and LTE. Each of them is implemented within a separate
wireless chip, sometimes packaged as combo chips. However, these chips share
components and resources, such as the same antenna or wireless spectrum.
Wireless coexistence interfaces enable them to schedule packets without
collisions despite shared resources, essential to maximizing networking
performance. Today's hardwired coexistence interfaces hinder clear security
boundaries and separation between chips and chip components. This paper shows
practical coexistence attacks on Broadcom, Cypress, and Silicon Labs chips
deployed in billions of devices. For example, we demonstrate that a Bluetooth
chip can directly extract network passwords and manipulate traffic on a Wi-Fi
chip. Coexistence attacks enable a novel type of lateral privilege escalation
across chip boundaries. We responsibly disclosed the vulnerabilities to the
vendors. Yet, only partial fixes were released for existing hardware since
wireless chips would need to be redesigned from the ground up to prevent the
presented attacks on coexistence.

    

### [[2112.05216] Is Disaggregation possible for HPC Cognitive Simulation?](http://arxiv.org/abs/2112.05216)


  Cognitive simulation (CogSim) is an important and emerging workflow for HPC
scientific exploration and scientific machine learning (SciML). One challenging
workload for CogSim is the replacement of one component in a complex physical
simulation with a fast, learned, surrogate model that is "inside" of the
computational loop. The execution of this in-the-loop inference is particularly
challenging because it requires frequent inference across multiple possible
target models, can be on the simulation's critical path (latency bound), is
subject to requests from multiple MPI ranks, and typically contains a small
number of samples per request. In this paper we explore the use of large,
dedicated Deep Learning / AI accelerators that are disaggregated from compute
nodes for this CogSim workload. We compare the trade-offs of using these
accelerators versus the node-local GPU accelerators on leadership-class HPC
systems.

    

### [[2112.05344] Sleeping Model: Local and Dynamic Algorithms](http://arxiv.org/abs/2112.05344)


  In recent years the sleeping model came to the focus of researchers. In this
model nodes can go into a sleep state in which they spend no energy but at the
same time cannot receive or send messages, nor can they perform internal
computations. This model captures energy considerations of a problem. A problem
P is an O-LOCAL problem if, given an acyclic orientation on the edges of the
input graph, one can solve the problem as follows. Each vertex awaits the
decisions of its parents according to the given orientation and can make its
own decision in regard to P using only the information about its parents
decisions. problems and showed that for this class of problems there is a
deterministic algorithm that runs in $O(\log \Delta)$ awake time. The clock
round complexity of that algorithm is $O(\Delta^2)$.
In this work we offer three algorithms for the bf O-LOCAL class of problems
with a trade off between awake complexity and clock round complexity. One of
these algorithms requires only $O(\Delta^{1+\epsilon})$ clock rounds for some
constant $\epsilon>0$ but still only $O(\log \Delta)$ awake time which improves
on the algorithm in \cite{BM21}. We add to this two other algorithms that trade
a higher awake complexity for lower clock round complexity. We note that the
awake time incurred is not that significant. We offer dynamic algorithms in the
sleeping model. We show three algorithms for solving dynamic problems in the
O-LOCAL class as well as an algorithm for solving any dynamic decidable
problem. We show that one can solve any {\bf O-LOCAL} problem in constant awake
time in graphs with constant neighborhood independence. Specifically, our
algorithm requires $O(K)$ awake time where $K$ is the neighborhood independence
of the input graph. Graphs with bounded neighborhood independence are well
studied with several results in recent years for several core problem in the
distributed setting.

    

### [[2112.05612] Decentralized Spectrum Access System: Vision, Challenges, and a Blockchain Solution](http://arxiv.org/abs/2112.05612)


  Spectrum access system (SAS) is widely considered the de facto solution to
coordinating dynamic spectrum sharing (DSS) and protecting incumbent users. The
current SAS paradigm prescribed by the FCC for the CBRS band and standardized
by the WInnForum follows a centralized service model in that a spectrum user
subscribes to a SAS server for spectrum allocation service. This model,
however, neither tolerates SAS server failures (crash or Byzantine) nor resists
dishonest SAS administrators, leading to serious concerns on SAS system
reliability and trustworthiness. This is especially concerning for the evolving
DSS landscape where an increasing number of SAS service providers and
heterogeneous user requirements are coming up. To address these challenges, we
propose a novel blockchain-based decentralized SAS architecture called BD-SAS
that provides SAS services securely and efficiently, without relying on the
trust of each individual SAS server for the overall system trustworthiness. In
BD-SAS, a global blockchain (G-Chain) is used for spectrum regulatory
compliance while smart contract-enabled local blockchains (L-Chains) are
instantiated in individual spectrum zones for automating spectrum access
assignment per user request. We hope our vision of a decentralized SAS, the
BD-SAS architecture, and discussion on future challenges can open up a new
direction towards reliable spectrum management in a decentralized manner.

    

### [[2112.05615] Intelligent Transportation Systems With The Use of External Infrastructure: A Literature Survey](http://arxiv.org/abs/2112.05615)


  Increasing problems in the transportation segment are accidents, bad traffic
flow and pollution. The Intelligent Transportation System with the use of
external infrastructure (ITS) can tackle these problems. To the best of our
knowledge, there exists no current systematic review of the existing solutions.
To fill this knowledge gap, this paper provides an overview about existing ITS
which use external infrastructure. Furthermore, this paper discovers the
currently not adequately answered research questions. For this reason, we
performed a literature review to documents, which describes existing ITS
solutions since 2009 until today. We categorized the results according to his
technology level and analyzed their properties. Thereby, we made the several
ITS comparable and highlighted the past development as well as the current
trends. According to the mentioned method, we analyzed more than 346 papers,
which includes 40 test bed projects. In summary, the current ITS can deliver
high accurate information about individuals in traffic situations in real-time.
However, further research in ITS should focus on more reliable perception of
the traffic with the use of modern sensors, plug and play mechanism as well as
secure real-time distribution in decentralized manner for a high amount of
data. With addressing these topics, the development of Intelligent
Transportation Systems is in a correction direction for the comprehensive
roll-out.

    

### [[1901.02441] Lower bounds for maximal matchings and maximal independent sets](http://arxiv.org/abs/1901.02441)


  There are distributed graph algorithms for finding maximal matchings and
maximal independent sets in $O(\Delta + \log^* n)$ communication rounds; here
$n$ is the number of nodes and $\Delta$ is the maximum degree. The lower bound
by Linial (1987, 1992) shows that the dependency on $n$ is optimal: these
problems cannot be solved in $o(\log^* n)$ rounds even if $\Delta = 2$.
However, the dependency on $\Delta$ is a long-standing open question, and there
is currently an exponential gap between the upper and lower bounds.
We prove that the upper bounds are tight. We show that any algorithm that
finds a maximal matching or maximal independent set with probability at least
$1-1/n$ requires $\Omega(\min\{\Delta,\log \log n / \log \log \log n\})$ rounds
in the LOCAL model of distributed computing. As a corollary, it follows that
any deterministic algorithm that finds a maximal matching or maximal
independent set requires $\Omega(\min\{\Delta, \log n / \log \log n\})$ rounds;
this is an improvement over prior lower bounds also as a function of $n$.

    

### [[1904.11563] Array BP-XOR Codes for Hierarchically Distributed Matrix Multiplication](http://arxiv.org/abs/1904.11563)


  A novel fault-tolerant computation technique based on array Belief
Propagation (BP)-decodable XOR (BP-XOR) codes is proposed for distributed
matrix-matrix multiplication. The proposed scheme is shown to be configurable
and suited for modern hierarchical compute architectures such as Graphical
Processing Units (GPUs) equipped with multiple nodes, whereby each has many
small independent processing units with increased core-to-core communications.
The proposed scheme is shown to outperform a few of the well--known earlier
strategies in terms of total end-to-end execution time while in presence of
slow nodes, called $stragglers$. This performance advantage is due to the
careful design of array codes which distributes the encoding operation over the
cluster (slave) nodes at the expense of increased master-slave communication.
An interesting trade-off between end-to-end latency and total communication
cost is precisely described. In addition, to be able to address an identified
problem of scaling stragglers, an asymptotic version of array BP-XOR codes
based on projection geometry is proposed at the expense of some computation
overhead. A thorough latency analysis is conducted for all schemes to
demonstrate that the proposed scheme achieves order-optimal computation in both
the sublinear as well as the linear regimes in the size of the computed product
from an end-to-end delay perspective.

    

### [[2112.05218] Learning Generalizable Behavior via Visual Rewrite Rules](http://arxiv.org/abs/2112.05218)


  Though deep reinforcement learning agents have achieved unprecedented success
in recent years, their learned policies can be brittle, failing to generalize
to even slight modifications of their environments or unfamiliar situations.
The black-box nature of the neural network learning dynamics makes it
impossible to audit trained deep agents and recover from such failures. In this
paper, we propose a novel representation and learning approach to capture
environment dynamics without using neural networks. It originates from the
observation that, in games designed for people, the effect of an action can
often be perceived in the form of local changes in consecutive visual
observations. Our algorithm is designed to extract such vision-based changes
and condense them into a set of action-dependent descriptive rules, which we
call ''visual rewrite rules'' (VRRs). We also present preliminary results from
a VRR agent that can explore, expand its rule set, and solve a game via
planning with its learned VRR world model. In several classical games, our
non-deep agent demonstrates superior performance, extreme sample efficiency,
and robust generalization ability compared with several mainstream deep agents.

    

### [[2112.05256] Semantic Construction Grammar: Bridging the NL / Logic Divide](http://arxiv.org/abs/2112.05256)


  In this paper, we discuss Semantic Construction Grammar (SCG), a system
developed over the past several years to facilitate translation between natural
language and logical representations. Crucially, SCG is designed to support a
variety of different methods of representation, ranging from those that are
fairly close to the NL structure (e.g. so-called 'logical forms'), to those
that are quite different from the NL structure, with higher-order and
high-arity relations. Semantic constraints and checks on representations are
integral to the process of NL understanding with SCG, and are easily carried
out due to the SCG's integration with Cyc's Knowledge Base and inference
engine.

    

### [[2112.05298] IFR-Explore: Learning Inter-object Functional Relationships in 3D Indoor Scenes](http://arxiv.org/abs/2112.05298)


  Building embodied intelligent agents that can interact with 3D indoor
environments has received increasing research attention in recent years. While
most works focus on single-object or agent-object visual functionality and
affordances, our work proposes to study a new kind of visual relationship that
is also important to perceive and model -- inter-object functional
relationships (e.g., a switch on the wall turns on or off the light, a remote
control operates the TV). Humans often spend little or no effort to infer these
relationships, even when entering a new room, by using our strong prior
knowledge (e.g., we know that buttons control electrical devices) or using only
a few exploratory interactions in cases of uncertainty (e.g., multiple switches
and lights in the same room). In this paper, we take the first step in building
AI system learning inter-object functional relationships in 3D indoor
environments with key technical contributions of modeling prior knowledge by
training over large-scale scenes and designing interactive policies for
effectively exploring the training scenes and quickly adapting to novel test
scenes. We create a new benchmark based on the AI2Thor and PartNet datasets and
perform extensive experiments that prove the effectiveness of our proposed
method. Results show that our model successfully learns priors and
fast-interactive-adaptation strategies for exploring inter-object functional
relationships in complex 3D scenes. Several ablation studies further validate
the usefulness of each proposed module.

    

### [[2112.05299] Zero-Shot Uncertainty-Aware Deployment of Simulation Trained Policies on Real-World Robots](http://arxiv.org/abs/2112.05299)


  While deep reinforcement learning (RL) agents have demonstrated incredible
potential in attaining dexterous behaviours for robotics, they tend to make
errors when deployed in the real world due to mismatches between the training
and execution environments. In contrast, the classical robotics community have
developed a range of controllers that can safely operate across most states in
the real world given their explicit derivation. These controllers however lack
the dexterity required for complex tasks given limitations in analytical
modelling and approximations. In this paper, we propose Bayesian Controller
Fusion (BCF), a novel uncertainty-aware deployment strategy that combines the
strengths of deep RL policies and traditional handcrafted controllers. In this
framework, we can perform zero-shot sim-to-real transfer, where our uncertainty
based formulation allows the robot to reliably act within out-of-distribution
states by leveraging the handcrafted controller while gaining the dexterity of
the learned system otherwise. We show promising results on two real-world
continuous control tasks, where BCF outperforms both the standalone policy and
controller, surpassing what either can achieve independently. A supplementary
video demonstrating our system is provided at this https URL.

    

### [[2112.05328] Multimodal Interactions Using Pretrained Unimodal Models for SIMMC 2.0](http://arxiv.org/abs/2112.05328)


  This paper presents our work on the Situated Interactive MultiModal
Conversations 2.0 challenge held at Dialog State Tracking Challenge 10. SIMMC
2.0 includes 4 subtasks, and we introduce our multimodal approaches for the
subtask \#1, \#2 and the generation of subtask \#4. SIMMC 2.0 dataset is a
multimodal dataset containing image and text information, which is more
challenging than the problem of only text-based conversations because it must
be solved by understanding the relationship between image and text. Therefore,
since there is a limit to solving only text models such as BERT or GPT2, we
propose a multimodal model combining image and text. We first pretrain the
multimodal model to understand the relationship between image and text, then
finetune our model for each task. We achieve the 3rd best performance in
subtask \#1, \#2 and a runner-up in the generation of subtask \#4. The source
code is available at this https URL.

    

### [[2112.05341] Hyperdimensional Feature Fusion for Out-Of-Distribution Detection](http://arxiv.org/abs/2112.05341)


  We introduce powerful ideas from Hyperdimensional Computing into the
challenging field of Out-of-Distribution (OOD) detection. In contrast to most
existing work that performs OOD detection based on only a single layer of a
neural network, we use similarity-preserving semi-orthogonal projection
matrices to project the feature maps from multiple layers into a common vector
space. By repeatedly applying the bundling operation $\oplus$, we create
expressive class-specific descriptor vectors for all in-distribution classes.
At test time, a simple and efficient cosine similarity calculation between
descriptor vectors consistently identifies OOD samples with better performance
than the current state-of-the-art. We show that the hyperdimensional fusion of
multiple network layers is critical to achieve best general performance.

    

### [[2112.05362] Where is Memory Information Stored in the Brain?](http://arxiv.org/abs/2112.05362)


  Within the scientific research community, memory information in the brain is
commonly believed to be stored in the synapse - a hypothesis famously
attributed to psychologist Donald Hebb. However, there is a growing minority
who postulate that memory is stored inside the neuron at the molecular (RNA or
DNA) level - an alternative postulation known as the cell-intrinsic hypothesis,
coined by psychologist Randy Gallistel. In this paper, we review a selection of
key experimental evidence from both sides of the argument. We begin with Eric
Kandel's studies on sea slugs, which provided the first evidence in support of
the synaptic hypothesis. Next, we touch on experiments in mice by John O'Keefe
(declarative memory and the hippocampus) and Joseph LeDoux (procedural fear
memory and the amygdala). Then, we introduce the synapse as the basic building
block of today's artificial intelligence neural networks. After that, we
describe David Glanzman's study on dissociating memory storage and synaptic
change in sea slugs, and Susumu Tonegawa's experiment on reactivating
retrograde amnesia in mice using laser. From there, we highlight Germund
Hesslow's experiment on conditioned pauses in ferrets, and Beatrice Gelber's
experiment on conditioning in single-celled organisms without synapses
(Paramecium aurelia). This is followed by a description of David Glanzman's
experiment on transplanting memory between sea slugs using RNA. Finally, we
provide an overview of Brian Dias and Kerry Ressler's experiment on DNA
transfer of fear in mice from parents to offspring. We conclude with some
potential implications for the wider field of psychology.

    

### [[2112.05364] Human Interpretation and Exploitation of Self-attention Patterns in Transformers: A Case Study in Extractive Summarization](http://arxiv.org/abs/2112.05364)


  The transformer multi-head self-attention mechanism has been thoroughly
investigated recently. On one hand, researchers are interested in understanding
why and how transformers work. On the other hand, they propose new attention
augmentation methods to make transformers more accurate, efficient and
interpretable. In this paper, we synergize these two lines of research in a
human-in-the-loop pipeline to first find important task-specific attention
patterns. Then those patterns are applied, not only to the original model, but
also to smaller models, as a human-guided knowledge distillation process. The
benefits of our pipeline are demonstrated in a case study with the extractive
summarization task. After finding three meaningful attention patterns in the
popular BERTSum model, experiments indicate that when we inject such patterns,
both the original and the smaller model show improvements in performance and
arguably interpretability.

    

### [[2112.05403] Computing Diverse Shortest Paths Efficiently: A Theoretical and Experimental Study](http://arxiv.org/abs/2112.05403)


  Finding diverse solutions in combinatorial problems recently has received
considerable attention (Baste et al. 2020; Fomin et al. 2020; Hanaka et al.
2021). In this paper we study the following type of problems: given an integer
$k$, the problem asks for $k$ solutions such that the sum of pairwise
(weighted) Hamming distances between these solutions is maximized. Such
solutions are called diverse solutions. We present a polynomial-time algorithm
for finding diverse shortest $st$-paths in weighted directed graphs. Moreover,
we study the diverse version of other classical combinatorial problems such as
diverse weighted matroid bases, diverse weighted arborescences, and diverse
bipartite matchings. We show that these problems can be solved in polynomial
time as well. To evaluate the practical performance of our algorithm for
finding diverse shortest $st$-paths, we conduct a computational experiment with
synthetic and real-world instances.The experiment shows that our algorithm
successfully computes diverse solutions within reasonable computational time.

    

### [[2112.05417] Unsupervised Editing for Counterfactual Stories](http://arxiv.org/abs/2112.05417)


  Creating what-if stories requires reasoning about prior statements and
possible outcomes of the changed conditions. One can easily generate coherent
endings under new conditions, but it would be challenging for current systems
to do it with minimal changes to the original story. Therefore, one major
challenge is the trade-off between generating a logical story and rewriting
with minimal-edits. In this paper, we propose EDUCAT, an editing-based
unsupervised approach for counterfactual story rewriting. EDUCAT includes a
target position detection strategy based on estimating causal effects of the
what-if conditions, which keeps the causal invariant parts of the story. EDUCAT
then generates the stories under fluency, coherence and minimal-edits
constraints. We also propose a new metric to alleviate the shortcomings of
current automatic metrics and better evaluate the trade-off. We evaluate EDUCAT
on a public counterfactual story rewriting benchmark. Experiments show that
EDUCAT achieves the best trade-off over unsupervised SOTA methods according to
both automatic and human evaluation. The resources of EDUCAT are available at:
this https URL.

    

### [[2112.05434] A Reinforcement Learning-based Adaptive Control Model for Future Street Planning, An Algorithm and A Case Study](http://arxiv.org/abs/2112.05434)


  With the emerging technologies in Intelligent Transportation System (ITS),
the adaptive operation of road space is likely to be realised within decades.
An intelligent street can learn and improve its decision-making on the
right-of-way (ROW) for road users, liberating more active pedestrian space
while maintaining traffic safety and efficiency. However, there is a lack of
effective controlling techniques for these adaptive street infrastructures. To
fill this gap in existing studies, we formulate this control problem as a
Markov Game and develop a solution based on the multi-agent Deep Deterministic
Policy Gradient (MADDPG) algorithm. The proposed model can dynamically assign
ROW for sidewalks, autonomous vehicles (AVs) driving lanes and on-street
parking areas in real-time. Integrated with the SUMO traffic simulator, this
model was evaluated using the road network of the South Kensington District
against three cases of divergent traffic conditions: pedestrian flow rates, AVs
traffic flow rates and parking demands. Results reveal that our model can
achieve an average reduction of 3.87% and 6.26% in street space assigned for
on-street parking and vehicular operations. Combined with space gained by
limiting the number of driving lanes, the average proportion of sidewalks to
total widths of streets can significantly increase by 10.13%.

    

### [[2112.05465] Autonomous Aerial Robot for High-Speed Search and Intercept Applications](http://arxiv.org/abs/2112.05465)


  In recent years, high-speed navigation and environment interaction in the
context of aerial robotics has become a field of interest for several academic
and industrial research studies. In particular, Search and Intercept (SaI)
applications for aerial robots pose a compelling research area due to their
potential usability in several environments. Nevertheless, SaI tasks involve a
challenging development regarding sensory weight, on-board computation
resources, actuation design and algorithms for perception and control, among
others. In this work, a fully-autonomous aerial robot for high-speed object
grasping has been proposed. As an additional sub-task, our system is able to
autonomously pierce balloons located in poles close to the surface. Our first
contribution is the design of the aerial robot at an actuation and sensory
level consisting of a novel gripper design with additional sensors enabling the
robot to grasp objects at high speeds. The second contribution is a complete
software framework consisting of perception, state estimation, motion planning,
motion control and mission control in order to rapid- and robustly perform the
autonomous grasping mission. Our approach has been validated in a challenging
international competition and has shown outstanding results, being able to
autonomously search, follow and grasp a moving object at 6 m/s in an outdoor
environment

    

### [[2112.05504] CityNeRF: Building NeRF at City Scale](http://arxiv.org/abs/2112.05504)


  Neural Radiance Field (NeRF) has achieved outstanding performance in modeling
3D objects and controlled scenes, usually under a single scale. In this work,
we make the first attempt to bring NeRF to city-scale, with views ranging from
satellite-level that captures the overview of a city, to ground-level imagery
showing complex details of an architecture. The wide span of camera distance to
the scene yields multi-scale data with different levels of detail and spatial
coverage, which casts great challenges to vanilla NeRF and biases it towards
compromised results. To address these issues, we introduce CityNeRF, a
progressive learning paradigm that grows the NeRF model and training set
synchronously. Starting from fitting distant views with a shallow base block,
as training progresses, new blocks are appended to accommodate the emerging
details in the increasingly closer views. The strategy effectively activates
high-frequency channels in the positional encoding and unfolds more complex
details as the training proceeds. We demonstrate the superiority of CityNeRF in
modeling diverse city-scale scenes with drastically varying views, and its
support for rendering views in different levels of detail.

    

### [[2112.05575] Paradigms of Computational Agency](http://arxiv.org/abs/2112.05575)


  Agent-based models have emerged as a promising paradigm for addressing ever
increasing complexity of information systems. In its initial days in the 1990s
when object-oriented modeling was at its peak, an agent was treated as a
special kind of "object" that had a persistent state and its own independent
thread of execution. Since then, agent-based models have diversified enormously
to even open new conceptual insights about the nature of systems in general.
This paper presents a perspective on the disparate ways in which our
understanding of agency, as well as computational models of agency have
evolved. Advances in hardware like GPUs, that brought neural networks back to
life, may also similarly infuse new life into agent-based models, as well as
pave the way for advancements in research on Artificial General Intelligence
(AGI).

    

### [[2112.05577] Towards autonomous artificial agents with an active self: modeling sense of control in situated action](http://arxiv.org/abs/2112.05577)


  In this paper we present a computational modeling account of an active self
in artificial agents. In particular we focus on how an agent can be equipped
with a sense of control and how it arises in autonomous situated action and, in
turn, influences action control. We argue that this requires laying out an
embodied cognitive model that combines bottom-up processes (sensorimotor
learning and fine-grained adaptation of control) with top-down processes
(cognitive processes for strategy selection and decision-making). We present
such a conceptual computational architecture based on principles of predictive
processing and free energy minimization. Using this general model, we describe
how a sense of control can form across the levels of a control hierarchy and
how this can support action control in an unpredictable environment. We present
an implementation of this model as well as first evaluations in a simulated
task scenario, in which an autonomous agent has to cope with un-/predictable
situations and experiences corresponding sense of control. We explore different
model parameter settings that lead to different ways of combining low-level and
high-level action control. The results show the importance of appropriately
weighting information in situations where the need for low/high-level action
control varies and they demonstrate how the sense of control can facilitate
this.

    

### [[2112.05596] Automated tabulation of clinical trial results: A joint entity and relation extraction approach with transformer-based language representations](http://arxiv.org/abs/2112.05596)


  Evidence-based medicine, the practice in which healthcare professionals refer
to the best available evidence when making decisions, forms the foundation of
modern healthcare. However, it relies on labour-intensive systematic reviews,
where domain specialists must aggregate and extract information from thousands
of publications, primarily of randomised controlled trial (RCT) results, into
evidence tables. This paper investigates automating evidence table generation
by decomposing the problem across two language processing tasks: \textit{named
entity recognition}, which identifies key entities within text, such as drug
names, and \textit{relation extraction}, which maps their relationships for
separating them into ordered tuples. We focus on the automatic tabulation of
sentences from published RCT abstracts that report the results of the study
outcomes. Two deep neural net models were developed as part of a joint
extraction pipeline, using the principles of transfer learning and
transformer-based language representations. To train and test these models, a
new gold-standard corpus was developed, comprising almost 600 result sentences
from six disease areas. This approach demonstrated significant advantages, with
our system performing well across multiple natural language processing tasks
and disease areas, as well as in generalising to disease domains unseen during
training. Furthermore, we show these results were achievable through training
our models on as few as 200 example sentences. The final system is a proof of
concept that the generation of evidence tables can be semi-automated,
representing a step towards fully automating systematic reviews.

    

### [[2112.05597] Marvin: Innovative Omni-Directional Robotic Assistant for Domestic Environments](http://arxiv.org/abs/2112.05597)


  Technology is progressively reshaping the domestic environment as we know it,
enhancing home security and the overall ambient quality through smart connected
devices. However, demographic shift and pandemics recently demonstrate to cause
isolation of elderly people in their houses, generating the need for a reliable
assistive figure. Robotic assistants are the new frontier of innovation for
domestic welfare. Elderly monitoring is only one of the possible service
applications an intelligent robotic platform can handle for collective
wellbeing. In this paper, we present Marvin, a novel assistive robot we
developed with a modular layer-based architecture, merging a flexible
mechanical design with state-of-the-art Artificial Intelligence for perception
and vocal control. With respect to previous works on robotic assistants, we
propose an omnidirectional platform provided with four mecanum wheels, which
enable autonomous navigation in conjunction with efficient obstacle avoidance
in cluttered environments. Moreover, we design a controllable positioning
device to extend the visual range of sensors and to improve the access to the
user interface for telepresence and connectivity. Lightweight deep learning
solutions for visual perception, person pose classification and vocal command
completely run on the embedded hardware of the robot, avoiding privacy issues
arising from private data collection on cloud services.

    

### [[2112.05614] AAAI FSS-21: Artificial Intelligence in Government and Public Sector Proceedings](http://arxiv.org/abs/2112.05614)


  Proceedings of the AAAI Fall Symposium on Artificial Intelligence in
Government and Public Sector, Washington, DC, USA, November 4-6, 2021

    

### [[2112.05638] DisCo: Effective Knowledge Distillation For Contrastive Learning of Sentence Embeddings](http://arxiv.org/abs/2112.05638)


  Contrastive learning has been proven suitable for learning sentence
embeddings and can significantly improve the semantic textual similarity (STS)
tasks. Recently, large contrastive learning models, e.g., Sentence-T5, tend to
be proposed to learn more powerful sentence embeddings. Though effective, such
large models are hard to serve online due to computational resources or time
cost limits. To tackle that, knowledge distillation (KD) is commonly adopted,
which can compress a large "teacher" model into a small "student" model but
generally suffer from some performance loss. Here we propose an enhanced KD
framework termed Distill-Contrast (DisCo). The proposed DisCo framework firstly
utilizes KD to transfer the capability of a large sentence embedding model to a
small student model on large unlabelled data, and then finetunes the student
model with contrastive learning on labelled training data. For the KD process
in DisCo, we further propose Contrastive Knowledge Distillation (CKD) to
enhance the consistencies among teacher model training, KD, and student model
finetuning, which can probably improve performance like prompt learning.
Extensive experiments on 7 STS benchmarks show that student models trained with
the proposed DisCo and CKD suffer from little or even no performance loss and
consistently outperform the corresponding counterparts of the same parameter
size. Amazingly, our 110M student model can even outperform the latest
state-of-the-art (SOTA) model, i.e., Sentence-T5(11B), with only 1% parameters.

    

### [[2112.05640] Fast and scalable neuroevolution deep learning architecture search for multivariate anomaly detection](http://arxiv.org/abs/2112.05640)


  The neuroevolution is one of the methodologies that can be used for learning
optimal architecture during the training. It uses evolutionary algorithms to
generate topology of artificial neural networks (ANN) and its parameters. In
this work, a modified neuroevolution technique is presented which incorporates
multi-level optimization. The presented approach adapts evolution strategies
for evolving ensemble model based on bagging technique, using genetic operators
for optimizing single anomaly detection models, reducing the training dataset
to speedup the search process and performs non gradient fine tuning. The
multivariate anomaly detection as an unsupervised learning task is the case
study on which presented approach is tested. Single model optimization is based
on mutation, crossover operators and focuses on finding optimal window sizes,
the number of layers, layer depths, hyperparameters etc. to boost the anomaly
detection scores of new and already known models. The proposed framework and
its protocol shows that it is possible to find architecture in a reasonable
time which can boost all well known multivariate anomaly detection deep
learning architectures. The work concentrates on improvements to multi-level
neuroevolution approach for anomaly detection. The main modifications are in
the methods of mixing groups and single models evolution, non gradient fine
tuning and voting mechanism. The presented framework can be used as an
efficient learning network architecture method for any different unsupervised
task where autoencoder architectures can be used. The tests were run on SWAT
and WADI datasets and presented approach evolved architectures that achieve
best scores among other deep learning models.

    

### [[2112.05675] Assessing the Fairness of AI Systems: AI Practitioners' Processes, Challenges, and Needs for Support](http://arxiv.org/abs/2112.05675)


  Various tools and practices have been developed to support practitioners in
identifying, assessing, and mitigating fairness-related harms caused by AI
systems. However, prior research has highlighted gaps between the intended
design of these tools and practices and their use within particular contexts,
including gaps caused by the role that organizational factors play in shaping
fairness work. In this paper, we investigate these gaps for one such practice:
disaggregated evaluations of AI systems, intended to uncover performance
disparities between demographic groups. By conducting semi-structured
interviews and structured workshops with thirty-three AI practitioners from ten
teams at three technology companies, we identify practitioners' processes,
challenges, and needs for support when designing disaggregated evaluations. We
find that practitioners face challenges when choosing performance metrics,
identifying the most relevant direct stakeholders and demographic groups on
which to focus, and collecting datasets with which to conduct disaggregated
evaluations. More generally, we identify impacts on fairness work stemming from
a lack of engagement with direct stakeholders, business imperatives that
prioritize customers over marginalized groups, and the drive to deploy AI
systems at scale.

    

### [[2112.05700] A Framework for Fairness: A Systematic Review of Existing Fair AI Solutions](http://arxiv.org/abs/2112.05700)


  In a world of daily emerging scientific inquisition and discovery, the
prolific launch of machine learning across industries comes to little surprise
for those familiar with the potential of ML. Neither so should the congruent
expansion of ethics-focused research that emerged as a response to issues of
bias and unfairness that stemmed from those very same applications. Fairness
research, which focuses on techniques to combat algorithmic bias, is now more
supported than ever before. A large portion of fairness research has gone to
producing tools that machine learning practitioners can use to audit for bias
while designing their algorithms. Nonetheless, there is a lack of application
of these fairness solutions in practice. This systematic review provides an
in-depth summary of the algorithmic bias issues that have been defined and the
fairness solution space that has been proposed. Moreover, this review provides
an in-depth breakdown of the caveats to the solution space that have arisen
since their release and a taxonomy of needs that have been proposed by machine
learning practitioners, fairness researchers, and institutional stakeholders.
These needs have been organized and addressed to the parties most influential
to their implementation, which includes fairness researchers, organizations
that produce ML algorithms, and the machine learning practitioners themselves.
These findings can be used in the future to bridge the gap between
practitioners and fairness experts and inform the creation of usable fair ML
toolkits.

    

### [[2112.05742] A Puzzle-Based Dataset for Natural Language Inference](http://arxiv.org/abs/2112.05742)


  We provide here a dataset for tasks related to natural language understanding
and natural language inference. The dataset contains logical puzzles in natural
language from three domains: comparing puzzles, knighs and knaves, and zebra
puzzles. Each puzzle is associated with the entire set of atomic questions that
can be generated based on the relations and individuals occurring in the text.
For each question we provide the correct answer: entailment, contradiction or
ambiguity. The answer's correctness is verified against theorem provers. Good
puzzles have two properties: (i) each piece of information is necessary and
(ii) no unnecessary information is provided. These properties make puzzles
interesting candidates for machine comprehension tasks.

    

### [[2104.14283] Uncertainty Principles in Risk-Aware Statistical Estimation](http://arxiv.org/abs/2104.14283)


  We present a new uncertainty principle for risk-aware statistical estimation,
effectively quantifying the inherent trade-off between mean squared error
($\mse$) and risk, the latter measured by the associated average predictive
squared error variance ($\sev$), for every admissible estimator of choice. Our
uncertainty principle has a familiar form and resembles fundamental and
classical results arising in several other areas, such as the Heisenberg
principle in statistical and quantum mechanics, and the Gabor limit (time-scale
trade-offs) in harmonic analysis. In particular, we prove that, provided a
joint generative model of states and observables, the product between $\mse$
and $\sev$ is bounded from below by a computable model-dependent constant,
which is explicitly related to the Pareto frontier of a recently studied
$\sev$-constrained minimum $\mse$ (MMSE) estimation problem. Further, we show
that the aforementioned constant is inherently connected to an intuitive new
and rigorously topologically grounded statistical measure of distribution
skewness in multiple dimensions, consistent with Pearson's moment coefficient
of skewness for variables on the line. Our results are also illustrated via
numerical simulations.

    

### [[2112.02814] A Survey of Deep Learning for Low-Shot Object Detection](http://arxiv.org/abs/2112.02814)


  Object detection is a fundamental task in computer vision and image
processing. Current deep learning based object detectors have been highly
successful with abundant labeled data. But in real life, it is not guaranteed
that each object category has enough labeled samples for training. These large
object detectors are easy to overfit when the training data is limited.
Therefore, it is necessary to introduce few-shot learning and zero-shot
learning into object detection, which can be named low-shot object detection
together. Low-Shot Object Detection (LSOD) aims to detect objects from a few or
even zero labeled data, which can be categorized into few-shot object detection
(FSOD) and zero-shot object detection (ZSD), respectively. This paper conducts
a comprehensive survey for deep learning based FSOD and ZSD. First, this survey
classifies methods for FSOD and ZSD into different categories and discusses the
pros and cons of them. Second, this survey reviews dataset settings and
evaluation metrics for FSOD and ZSD, then analyzes the performance of different
methods on these benchmarks. Finally, this survey discusses future challenges
and promising directions for FSOD and ZSD.

    

### [[2112.05304] Inferring Invariants with Quantifier Alternations: Taming the Search Space Explosion](http://arxiv.org/abs/2112.05304)


  We present a PDR/IC3 algorithm for finding inductive invariants with
quantifier alternations. We tackle scalability issues that arise due to the
large search space of quantified invariants by combining a breadth-first search
strategy and a new syntactic form for quantifier-free bodies. The breadth-first
strategy prevents inductive generalization from getting stuck in regions of the
search space that are expensive to search and focuses instead on lemmas that
are easy to discover. The new syntactic form is well-suited to lemmas with
quantifier alternations by allowing both limited conjunction and disjunction in
the quantifier-free body, while carefully controlling the size of the search
space. Combining the breadth-first strategy with the new syntactic form results
in useful inductive bias by prioritizing lemmas according to: (i) well-defined
syntactic metrics for simple quantifier structures and quantifier-free bodies,
and (ii) the empirically useful heuristic of preferring lemmas that are fast to
discover. On a benchmark suite of primarily distributed protocols and complex
Paxos variants, we demonstrate that our algorithm can solve more of the most
complicated examples than state-of-the-art techniques.

    

### [[2112.05492] BCD: A Cross-Architecture Binary Comparison Database Experiment Using Locality Sensitive Hashing Algorithms](http://arxiv.org/abs/2112.05492)


  Given a binary executable without source code, it is difficult to determine
what each function in the binary does by reverse engineering it, and even
harder without prior experience and context. In this paper, we performed a
comparison of different hashing functions' effectiveness at detecting similar
lifted snippets of LLVM IR code, and present the design and implementation of a
framework for cross-architecture binary code similarity search database using
MinHash as the chosen hashing algorithm, over SimHash, SSDEEP and TLSH. The
motivation is to help reverse engineers to quickly gain context of functions in
an unknown binary by comparing it against a database of known functions. The
code for this project is open source and can be found at
this https URL


### [<title>Parameters: { scale_post_weight } might not be used - XGBoost</title>](https://discuss.xgboost.ai/t/parameters-scale-post-weight-might-not-be-used/2597/1)