
## 2021-9-13

### [[2109.04784] A Dynamic Scheduling Policy for a Network with Heterogeneous Time-Sensitive Traffic](http://arxiv.org/abs/2109.04784)


  In 5G and beyond systems, the notion of latency gets a great momentum in
wireless connectivity as a metric for serving real-time communications
requirements. However, in many applications, research has pointed out that
latency could be inefficient to handle applications with data freshness
requirements. Recently, the notion of Age of Information (AoI) that can capture
the freshness of the data has attracted a lot of attention. In this work, we
consider mixed traffic with time-sensitive users; a deadline-constrained user,
and an AoI-oriented user. To develop an efficient scheduling policy, we cast a
novel optimization problem formulation for minimizing the average AoI while
satisfying the timely throughput constraints. The formulated problem is cast as
a Constrained Markov Decision Process (CMDP). We relax the constrained problem
to an unconstrained Markov Decision Process (MDP) problem by utilizing Lyapunov
optimization theory and it can be proved that it is solved per frame by
applying backward dynamic programming algorithms with optimality guarantees.
Simulation results show that the timely throughput constraints are satisfied
while minimizing the average AoI. Also, simulation results show the convergence
of the algorithm for different values of the weighted factor and the trade-off
between the AoI and the timely throughput.

    

### [[2109.04786] WiFi Meets ML: A Survey on Improving IEEE 802.11 Performance with Machine Learning](http://arxiv.org/abs/2109.04786)


  Wireless local area networks (WLANs) empowered by IEEE 802.11 (WiFi) hold a
dominant position in providing Internet access thanks to their freedom of
deployment and configuration as well as affordable and highly interoperable
devices. The WiFi community is currently deploying WiFi 6 and developing WiFi
7, which will bring higher data rates, better multi-user and multi-AP support,
and, most importantly, improved configuration flexibility. These technical
innovations, including the plethora of configuration parameters, are making
next-generation WLANs exceedingly complex as the dependencies between
parameters and their joint optimization usually have a non-linear impact on
network performance. The complexity is further increased in the case of dense
deployments and coexistence in shared bands. While classic optimization
approaches fail in such conditions, machine learning (ML) is well known for
being able to handle complexity. Much research has been published on using ML
to improve WiFi performance and solutions are slowly being adopted in existing
deployments. In this survey, we adopt a structured approach to describing the
various areas where WiFi can be enhanced using ML. To this end, we analyze over
200 papers in the field providing readers with an overview of the main trends.
Based on this review, we identify both open challenges in each WiFi performance
area as well as general future research directions.

    

### [[1902.04561] Mitigating Traffic Remapping Attacks in Autonomous Multi-hop Wireless Networks](http://arxiv.org/abs/1902.04561)


  Multi-hop wireless networks with autonomous nodes are susceptible to selfish
traffic remapping attacks (TRAs). Nodes launching TRAs leverage the underlying
channel access function to receive unduly high quality of service (QoS) for
packet flows traversing source-to-destination routes. TRAs are easy to execute,
impossible to prevent, difficult to detect, and harmful to the QoS of honest
nodes. Recognizing the need for providing QoS security, we use a novel
network-oriented QoS metric to propose a self-enforcing game-theoretic
mitigation approach. By switching between TRA and honest behavior, selfish
nodes engage in a noncooperative multistage game in pursuit of high QoS. We
analyze feasible node strategies and design a distributed signaling mechanism
called DISTRESS, under which, given certain conditions, the game produces a
desirable outcome: after an upper-bounded play time, honesty tends to become a
selfish node's best-reply behavior, while yielding acceptable QoS to most or
all nodes. We verify these findings by Monte Carlo and ns-3 simulations of
static and mobile nodes.

    

### [[2104.13813] MOVO: a dApp for DLT-based Smart Mobility](http://arxiv.org/abs/2104.13813)


  Plenty of research on smart mobility is currently devoted to the inclusion of
novel decentralized software architectures to these systems, due to the
inherent advantages in terms of transparency, traceability, trustworthiness.
MOVO is a decentralized application (dApp) for smart mobility. It includes: (i)
a module for collecting data from vehicles and smartphones sensors; (ii) a
component for interacting with Distributed Ledger Technologies (DLT) and
Decentralized File Storages (DFS), for storing and validating sensor data;
(iii) a module for "offline" interaction between devices. The dApp consists of
an Android application intended for use inside a vehicle, which helps the
user/driver collect contextually generated data (e.g. a driver's stress level,
an electric vehicle's battery level), which can then be shared through the use
of DLT (i.e., IOTA DLT and Ethereum smart contracts) and DFS (i.e., IPFS). The
third module consists of an implementation of a communication channel that, via
Wi-Fi Direct, allows two devices to exchange data and payment information with
respect to DLT (i.e. cryptocurrency and token) assets. In this paper, we
describe the main software components and provide an experimental evaluation
that confirms the viability of the MOVO dApp in real mobility scenarios.

    

### [[2104.13819] Towards Decentralized Complex Queries over Distributed Ledgers: a Data Marketplace Use-case](http://arxiv.org/abs/2104.13819)


  Distributed Ledger Technologies (DLT) and Decentralized File Storages (DFS)
are becoming increasingly used to create common, decentralized and trustless
infrastructures where participants interact and collaborate in Peer-to-Peer
interactions. A prominent use case is represented by decentralized data
marketplaces, where users are consumers and providers at the same time, and
trustless interactions are required. However, data in DLTs and DFS are usually
unstructured and there are no efficient mechanisms to query a certain type of
data for the search in the market. In this paper, we propose the use of a
Distributed Hash Table (DHT) as a layer on top of DLTs where, once the data are
acquired and stored in the ledger, these can be searched through multiple
keyword based queries, thanks to the lookup functionalities offered by the DHT.
The DHT network is a hypercube overlay structure, organized for an efficient
processing of multiple keyword-based queries. We provide the architecture of
such solution for a decentralized data marketplace and an analysis based on a
simulation that proves the viability of the proposed approach.

    

### [[2105.00884] RL-IoT: Reinforcement Learning to Interact with IoT Devices](http://arxiv.org/abs/2105.00884)


  Our life is getting filled by Internet of Things (IoT) devices. These devices
often rely on closed or poorly documented protocols, with unknown formats and
semantics. Learning how to interact with such devices in an autonomous manner
is the key for interoperability and automatic verification of their
capabilities. In this paper, we propose RL-IoT, a system that explores how to
automatically interact with possibly unknown IoT devices. We leverage
reinforcement learning (RL) to recover the semantics of protocol messages and
to take control of the device to reach a given goal, while minimizing the
number of interactions. We assume to know only a database of possible IoT
protocol messages, whose semantics are however unknown. RL-IoT exchanges
messages with the target IoT device, learning those commands that are useful to
reach the given goal. Our results show that RL-IoT is able to solve both simple
and complex tasks. With properly tuned parameters, RL-IoT learns how to perform
actions with the target device, a Yeelight smart bulb in our case study,
completing non-trivial patterns with as few as 400 interactions. RL-IoT paves
the road for automatic interactions with poorly documented IoT protocols, thus
enabling interoperable systems.

    

### [[2106.10963] Wireless Communication Aided by Intelligent Reflecting Surface: Active or Passive?](http://arxiv.org/abs/2106.10963)


  In this letter, we consider an intelligent reflecting surface (IRS)-aided
wireless communication system, where an active or passive IRS is employed to
assist the communication between an access point and a user. First, we consider
the downlink/uplink communication separately and optimize the IRS placement for
rate maximization with an active or passive IRS. We show that the active IRS
should be deployed closer to the receiver with the IRS's decreasing
amplification power; while in contrast, the passive IRS should be deployed near
either the transmitter or receiver. Moreover, with optimized IRS placement, the
passive IRS is shown to outperform its active counterpart when the number of
reflecting elements is sufficiently large and/or the active-IRS amplification
power is too small. Next, we optimize the IRS placement for both active and
passive IRSs to maximize the weighted sum-rate of uplink and downlink
communications. We show that in this case, the passive IRS is more likely to
achieve superior rate performance. This is because the optimal active-IRS
placement needs to balance the rate performance in the uplink and downlink,
while deploying the passive IRS near the transmitter or receiver is optimal
regardless of the uplink or downlink.

    

### [[2109.04470] Truth Discovery in Sequence Labels from Crowds](http://arxiv.org/abs/2109.04470)


  Annotations quality and quantity positively affect the performance of
sequence labeling, a vital task in Natural Language Processing. Hiring domain
experts to annotate a corpus set is very costly in terms of money and time.
Crowdsourcing platforms, such as Amazon Mechanical Turk (AMT), have been
deployed to assist in this purpose. However, these platforms are prone to human
errors due to the lack of expertise; hence, one worker's annotations cannot be
directly used to train the model. Existing literature in annotation aggregation
more focuses on binary or multi-choice problems. In recent years, handling the
sequential label aggregation tasks on imbalanced datasets with complex
dependencies between tokens has been challenging. To conquer the challenge, we
propose an optimization-based method that infers the best set of aggregated
annotations using labels provided by workers. The proposed Aggregation method
for Sequential Labels from Crowds ($AggSLC$) jointly considers the
characteristics of sequential labeling tasks, workers' reliabilities, and
advanced machine learning techniques. We evaluate $AggSLC$ on different
crowdsourced data for Named Entity Recognition (NER), Information Extraction
tasks in biomedical (PICO), and the simulated dataset. Our results show that
the proposed method outperforms the state-of-the-art aggregation methods. To
achieve insights into the framework, we study $AggSLC$ components'
effectiveness through ablation studies by evaluating our model in the absence
of the prediction module and inconsistency loss function. Theoretical analysis
of our algorithm's convergence points that the proposed $AggSLC$ halts after a
finite number of iterations.

    

### [[2109.04504] Bootstrapped Meta-Learning](http://arxiv.org/abs/2109.04504)


  Meta-learning empowers artificial intelligence to increase its efficiency by
learning how to learn. Unlocking this potential involves overcoming a
challenging meta-optimisation problem that often exhibits ill-conditioning, and
myopic meta-objectives. We propose an algorithm that tackles these issues by
letting the meta-learner teach itself. The algorithm first bootstraps a target
from the meta-learner, then optimises the meta-learner by minimising the
distance to that target under a chosen (pseudo-)metric. Focusing on
meta-learning with gradients, we establish conditions that guarantee
performance improvements and show that the improvement is related to the target
distance. Thus, by controlling curvature, the distance measure can be used to
ease meta-optimization, for instance by reducing ill-conditioning. Further, the
bootstrapping mechanism can extend the effective meta-learning horizon without
requiring backpropagation through all updates. The algorithm is versatile and
easy to implement. We achieve a new state-of-the art for model-free agents on
the Atari ALE benchmark, improve upon MAML in few-shot learning, and
demonstrate how our approach opens up new possibilities by meta-learning
efficient exploration in a Q-learning agent.

    

### [[2109.04518] Unsupervised Causal Binary Concepts Discovery with VAE for Black-box Model Explanation](http://arxiv.org/abs/2109.04518)


  We aim to explain a black-box classifier with the form: `data X is classified
as class Y because X \textit{has} A, B and \textit{does not have} C' in which
A, B, and C are high-level concepts. The challenge is that we have to discover
in an unsupervised manner a set of concepts, i.e., A, B and C, that is useful
for the explaining the classifier. We first introduce a structural generative
model that is suitable to express and discover such concepts. We then propose a
learning process that simultaneously learns the data distribution and
encourages certain concepts to have a large causal influence on the classifier
output. Our method also allows easy integration of user's prior knowledge to
induce high interpretability of concepts. Using multiple datasets, we
demonstrate that our method can discover useful binary concepts for
explanation.

    

### [[2109.04522] Asynchronous Iterations in Optimization: New Sequence Results and Sharper Algorithmic Guarantees](http://arxiv.org/abs/2109.04522)


  We introduce novel convergence results for asynchronous iterations which
appear in the analysis of parallel and distributed optimization algorithms. The
results are simple to apply and give explicit estimates for how the degree of
asynchrony impacts the convergence rates of the iterates. Our results shorten,
streamline and strengthen existing convergence proofs for several asynchronous
optimization methods, and allow us to establish convergence guarantees for
popular algorithms that were thus far lacking a complete theoretical
understanding. Specifically, we use our results to derive better iteration
complexity bounds for proximal incremental aggregated gradient methods, to
provide less conservative analyses of the speedup conditions for asynchronous
block-coordinate implementations of Krasnoselskii-Mann iterations, and to
quantify the convergence rates for totally asynchronous iterations under
various assumptions on communication delays and update rates.

    

### [[2109.04526] Ergodic Limits, Relaxations, and Geometric Properties of Random Walk Node Embeddings](http://arxiv.org/abs/2109.04526)


  Random walk based node embedding algorithms learn vector representations of
nodes by optimizing an objective function of node embedding vectors and
skip-bigram statistics computed from random walks on the network. They have
been applied to many supervised learning problems such as link prediction and
node classification and have demonstrated state-of-the-art performance. Yet,
their properties remain poorly understood. This paper studies properties of
random walk based node embeddings in the unsupervised setting of discovering
hidden block structure in the network, i.e., learning node representations
whose cluster structure in Euclidean space reflects their adjacency structure
within the network. We characterize the ergodic limits of the embedding
objective, its generalization, and related convex relaxations to derive
corresponding non-randomized versions of the node embedding objectives. We also
characterize the optimal node embedding Grammians of the non-randomized
objectives for the expected graph of a two-community Stochastic Block Model
(SBM). We prove that the solution Grammian has rank $1$ for a suitable nuclear
norm relaxation of the non-randomized objective. Comprehensive experimental
results on SBM random networks reveal that our non-randomized ergodic
objectives yield node embeddings whose distribution is Gaussian-like, centered
at the node embeddings of the expected network within each community, and
concentrate in the linear degree-scaling regime as the number of nodes
increases.

    

### [[2109.04530] Notes on Generalizing the Maximum Entropy Principle to Uncertain Data](http://arxiv.org/abs/2109.04530)


  The principle of maximum entropy is a broadly applicable technique for
computing a distribution with the least amount of information possible while
commonly constrained to match empirically estimated feature expectations. We
seek to generalize this principle to scenarios where the empirical feature
expectations cannot be computed because the model variables are only partially
observed, which introduces a dependency on the learned model. Extending and
generalizing the principle of latent maximum entropy, we introduce uncertain
maximum entropy and describe an expectation-maximization based solution to
approximately solve these problems. We show that our technique generalizes the
principle of maximum entropy and latent maximum entropy and discuss a generally
applicable regularization technique for adding error terms to feature
expectation constraints in the event of limited data.

    

### [[2109.04533] FedCon: A Contrastive Framework for Federated Semi-Supervised Learning](http://arxiv.org/abs/2109.04533)


  Federated Semi-Supervised Learning (FedSSL) has gained rising attention from
both academic and industrial researchers, due to its unique characteristics of
co-training machine learning models with isolated yet unlabeled data. Most
existing FedSSL methods focus on the classical scenario, i.e, the labeled and
unlabeled data are stored at the client side. However, in real world
applications, client users may not provide labels without any incentive. Thus,
the scenario of labels at the server side is more practical. Since unlabeled
data and labeled data are decoupled, most existing FedSSL approaches may fail
to deal with such a scenario. To overcome this problem, in this paper, we
propose FedCon, which introduces a new learning paradigm, i.e., contractive
learning, to FedSSL. Experimental results on three datasets show that FedCon
achieves the best performance with the contractive framework compared with
state-of-the-art baselines under both IID and Non-IID settings. Besides,
ablation studies demonstrate the characteristics of the proposed FedCon
framework.

    

### [[2109.04535] Identifying Morality Frames in Political Tweets using Relational Learning](http://arxiv.org/abs/2109.04535)


  Extracting moral sentiment from text is a vital component in understanding
public opinion, social movements, and policy decisions. The Moral Foundation
Theory identifies five moral foundations, each associated with a positive and
negative polarity. However, moral sentiment is often motivated by its targets,
which can correspond to individuals or collective entities. In this paper, we
introduce morality frames, a representation framework for organizing moral
attitudes directed at different entities, and come up with a novel and
high-quality annotated dataset of tweets written by US politicians. Then, we
propose a relational learning model to predict moral attitudes towards entities
and moral foundations jointly. We do qualitative and quantitative evaluations,
showing that moral sentiment towards entities differs highly across political
ideologies.

    

### [[2109.04550] SeDyT: A General Framework for Multi-Step Event Forecasting via Sequence Modeling on Dynamic Entity Embeddings](http://arxiv.org/abs/2109.04550)


  Temporal Knowledge Graphs store events in the form of subjects, relations,
objects, and timestamps which are often represented by dynamic heterogeneous
graphs. Event forecasting is a critical and challenging task in Temporal
Knowledge Graph reasoning that predicts the subject or object of an event in
the future. To obtain temporal embeddings multi-step away in the future,
existing methods learn generative models that capture the joint distribution of
the observed events. To reduce the high computation costs, these methods rely
on unrealistic assumptions of independence and approximations in training and
inference. In this work, we propose SeDyT, a discriminative framework that
performs sequence modeling on the dynamic entity embeddings to solve the
multi-step event forecasting problem. SeDyT consists of two components: a
Temporal Graph Neural Network that generates dynamic entity embeddings in the
past and a sequence model that predicts the entity embeddings in the future.
Compared with the generative models, SeDyT does not rely on any heuristic-based
probability model and has low computation complexity in both training and
inference. SeDyT is compatible with most Temporal Graph Neural Networks and
sequence models. We also design an efficient training method that trains the
two components in one gradient descent propagation. We evaluate the performance
of SeDyT on five popular datasets. By combining temporal Graph Neural Network
models and sequence models, SeDyT achieves an average of 2.4% MRR improvement
when not using the validation set and more than 10% MRR improvement when using
the validation set.

    

### [[2109.04552] SPECTRA: Sparse Structured Text Rationalization](http://arxiv.org/abs/2109.04552)


  Selective rationalization aims to produce decisions along with rationales
(e.g., text highlights or word alignments between two sentences). Commonly,
rationales are modeled as stochastic binary masks, requiring sampling-based
gradient estimators, which complicates training and requires careful
hyperparameter tuning. Sparse attention mechanisms are a deterministic
alternative, but they lack a way to regularize the rationale extraction (e.g.,
to control the sparsity of a text highlight or the number of alignments). In
this paper, we present a unified framework for deterministic extraction of
structured explanations via constrained inference on a factor graph, forming a
differentiable layer. Our approach greatly eases training and rationale
regularization, generally outperforming previous work on what comes to
performance and plausibility of the extracted rationales. We further provide a
comparative study of stochastic and deterministic methods for rationale
extraction for classification and natural language inference tasks, jointly
assessing their predictive power, quality of the explanations, and model
variability.

    

### [[2109.04553] Is Attention Better Than Matrix Decomposition?](http://arxiv.org/abs/2109.04553)


  As an essential ingredient of modern deep learning, attention mechanism,
especially self-attention, plays a vital role in the global correlation
discovery. However, is hand-crafted attention irreplaceable when modeling the
global context? Our intriguing finding is that self-attention is not better
than the matrix decomposition (MD) model developed 20 years ago regarding the
performance and computational cost for encoding the long-distance dependencies.
We model the global context issue as a low-rank recovery problem and show that
its optimization algorithms can help design global information blocks. This
paper then proposes a series of Hamburgers, in which we employ the optimization
algorithms for solving MDs to factorize the input representations into
sub-matrices and reconstruct a low-rank embedding. Hamburgers with different
MDs can perform favorably against the popular global context module
self-attention when carefully coping with gradients back-propagated through
MDs. Comprehensive experiments are conducted in the vision tasks where it is
crucial to learn the global context, including semantic segmentation and image
generation, demonstrating significant improvements over self-attention and its
variants.

    

### [[2109.04554] Feature-based Individual Fairness in k-Clustering](http://arxiv.org/abs/2109.04554)


  Ensuring fairness in machine learning algorithms is a challenging and
important task. We consider the problem of clustering a set of points while
ensuring fairness constraints. While there have been several attempts to
capture group fairness in the k-clustering problem, fairness at an individual
level is not well-studied. We introduce a new notion of individual fairness in
k-clustering based on features that are not necessarily used for clustering. We
show that this problem is NP-hard and does not admit a constant factor
approximation. We then design a randomized algorithm that guarantees
approximation both in terms of minimizing the clustering distance objective as
well as individual fairness under natural restrictions on the distance metric
and fairness constraints. Finally, our experimental results validate that our
algorithm produces lower clustering costs compared to existing algorithms while
being competitive in individual fairness.

    

### [[2109.04561] Supervising the Decoder of Variational Autoencoders to Improve Scientific Utility](http://arxiv.org/abs/2109.04561)


  Probabilistic generative models are attractive for scientific modeling
because their inferred parameters can be used to generate hypotheses and design
experiments. This requires that the learned model provide an accurate
representation of the input data and yield a latent space that effectively
predicts outcomes relevant to the scientific question. Supervised Variational
Autoencoders (SVAEs) have previously been used for this purpose, where a
carefully designed decoder can be used as an interpretable generative model
while the supervised objective ensures a predictive latent representation.
Unfortunately, the supervised objective forces the encoder to learn a biased
approximation to the generative posterior distribution, which renders the
generative parameters unreliable when used in scientific models. This issue has
remained undetected as reconstruction losses commonly used to evaluate model
performance do not detect bias in the encoder. We address this
previously-unreported issue by developing a second order supervision framework
(SOS-VAE) that influences the decoder to induce a predictive latent
representation. This ensures that the associated encoder maintains a reliable
generative interpretation. We extend this technique to allow the user to
trade-off some bias in the generative parameters for improved predictive
performance, acting as an intermediate option between SVAEs and our new
SOS-VAE. We also use this methodology to address missing data issues that often
arise when combining recordings from multiple scientific experiments. We
demonstrate the effectiveness of these developments using synthetic data and
electrophysiological recordings with an emphasis on how our learned
representations can be used to design scientific experiments.

    

### [[2109.04565] TENET: Temporal CNN with Attention for Anomaly Detection in Automotive Cyber-Physical Systems](http://arxiv.org/abs/2109.04565)


  Modern vehicles have multiple electronic control units (ECUs) that are
connected together as part of a complex distributed cyber-physical system
(CPS). The ever-increasing communication between ECUs and external electronic
systems has made these vehicles particularly susceptible to a variety of
cyber-attacks. In this work, we present a novel anomaly detection framework
called TENET to detect anomalies induced by cyber-attacks on vehicles. TENET
uses temporal convolutional neural networks with an integrated attention
mechanism to detect anomalous attack patterns. TENET is able to achieve an
improvement of 32.70% in False Negative Rate, 19.14% in the Mathews Correlation
Coefficient, and 17.25% in the ROC-AUC metric, with 94.62% fewer model
parameters, 86.95% decrease in memory footprint, and 48.14% lower inference
time when compared to the best performing prior work on automotive anomaly
detection.

    

### [[2109.04566] SanitAIs: Unsupervised Data Augmentation to Sanitize Trojaned Neural Networks](http://arxiv.org/abs/2109.04566)


  The application of self-supervised methods has resulted in broad improvements
to neural network performance by leveraging large, untapped collections of
unlabeled data to learn generalized underlying structure. In this work, we
harness unsupervised data augmentation (UDA) to mitigate backdoor or Trojan
attacks on deep neural networks. We show that UDA is more effective at removing
the effects of a trigger than current state-of-the-art methods for both feature
space and point triggers. These results demonstrate that UDA is both an
effective and practical approach to mitigating the effects of backdoors on
neural networks.

    

### [[2109.04572] Deciphering Environmental Air Pollution with Large Scale City Data](http://arxiv.org/abs/2109.04572)


  Out of the numerous hazards posing a threat to sustainable environmental
conditions in the 21st century, only a few have a graver impact than air
pollution. Its importance in determining the health and living standards in
urban settings is only expected to increase with time. Various factors ranging
from emissions from traffic and power plants, household emissions, natural
causes are known to be primary causal agents or influencers behind rising air
pollution levels. However, the lack of large scale data involving the major
factors has hindered the research on the causes and relations governing the
variability of the different air pollutants. Through this work, we introduce a
large scale city-wise dataset for exploring the relationships among these
agents over a long period of time. We analyze and explore the dataset to bring
out inferences which we can derive by modeling the data. Also, we provide a set
of benchmarks for the problem of estimating or forecasting pollutant levels
with a set of diverse models and methodologies. Through our paper, we seek to
provide a ground base for further research into this domain that will demand
critical attention of ours in the near future.

    

### [[2109.04584] Trust your neighbors: A comprehensive survey of neighborhood-based methods for recommender systems](http://arxiv.org/abs/2109.04584)


  Collaborative recommendation approaches based on nearest-neighbors are still
highly popular today due to their simplicity, their efficiency, and their
ability to produce accurate and personalized recommendations. This chapter
offers a comprehensive survey of neighborhood-based methods for the item
recommendation problem. It presents the main characteristics and benefits of
such methods, describes key design choices for implementing a
neighborhood-based recommender system, and gives practical information on how
to make these choices. A broad range of methods is covered in the chapter,
including traditional algorithms like k-nearest neighbors as well as advanced
approaches based on matrix factorization, sparse coding and random walks.

    

### [[2109.04593] A Large-Scale Study of Machine Translation in the Turkic Languages](http://arxiv.org/abs/2109.04593)


  Recent advances in neural machine translation (NMT) have pushed the quality
of machine translation systems to the point where they are becoming widely
adopted to build competitive systems. However, there is still a large number of
languages that are yet to reap the benefits of NMT. In this paper, we provide
the first large-scale case study of the practical application of MT in the
Turkic language family in order to realize the gains of NMT for Turkic
languages under high-resource to extremely low-resource scenarios. In addition
to presenting an extensive analysis that identifies the bottlenecks towards
building competitive systems to ameliorate data scarcity, our study has several
key contributions, including, i) a large parallel corpus covering 22 Turkic
languages consisting of common public datasets in combination with new datasets
of approximately 2 million parallel sentences, ii) bilingual baselines for 26
language pairs, iii) novel high-quality test sets in three different
translation domains and iv) human evaluation scores. All models, scripts, and
data will be released to the public.

    

### [[2109.04595] C-MinHash: Practically Reducing Two Permutations to Just One](http://arxiv.org/abs/2109.04595)


  Traditional minwise hashing (MinHash) requires applying $K$ independent
permutations to estimate the Jaccard similarity in massive binary (0/1) data,
where $K$ can be (e.g.,) 1024 or even larger, depending on applications. The
recent work on C-MinHash (Li and Li, 2021) has shown, with rigorous proofs,
that only two permutations are needed. An initial permutation is applied to
break whatever structures which might exist in the data, and a second
permutation is re-used $K$ times to produce $K$ hashes, via a circulant
shifting fashion. (Li and Li, 2021) has proved that, perhaps surprisingly, even
though the $K$ hashes are correlated, the estimation variance is strictly
smaller than the variance of the traditional MinHash.
It has been demonstrated in (Li and Li, 2021) that the initial permutation in
C-MinHash is indeed necessary. For the ease of theoretical analysis, they have
used two independent permutations. In this paper, we show that one can actually
simply use one permutation. That is, one single permutation is used for both
the initial pre-processing step to break the structures in the data and the
circulant hashing step to generate $K$ hashes. Although the theoretical
analysis becomes very complicated, we are able to explicitly write down the
expression for the expectation of the estimator. The new estimator is no longer
unbiased but the bias is extremely small and has essentially no impact on the
estimation accuracy (mean square errors). An extensive set of experiments are
provided to verify our claim for using just one permutation.

    

### [[2109.04608] Spatially Focused Attack against Spatiotemporal Graph Neural Networks](http://arxiv.org/abs/2109.04608)


  Spatiotemporal forecasting plays an essential role in various applications in
intelligent transportation systems (ITS), such as route planning, navigation,
and traffic control and management. Deep Spatiotemporal graph neural networks
(GNNs), which capture both spatial and temporal patterns, have achieved great
success in traffic forecasting applications. Understanding how GNNs-based
forecasting work and the vulnerability and robustness of these models becomes
critical to real-world applications. For example, if spatiotemporal GNNs are
vulnerable in real-world traffic prediction applications, a hacker can easily
manipulate the results and cause serious traffic congestion and even a
city-scale breakdown. However, despite that recent studies have demonstrated
that deep neural networks (DNNs) are vulnerable to carefully designed
perturbations in multiple domains like objection classification and graph
representation, current adversarial works cannot be directly applied to
spatiotemporal forecasting due to the causal nature and spatiotemporal
mechanisms in forecasting models. To fill this gap, in this paper we design
Spatially Focused Attack (SFA) to break spatiotemporal GNNs by attacking a
single vertex. To achieve this, we first propose the inverse estimation to
address the causality issue; then, we apply genetic algorithms with a universal
attack method as the evaluation function to locate the weakest vertex; finally,
perturbations are generated by solving an inverse estimation-based optimization
problem. We conduct experiments on real-world traffic data and our results show
that perturbations in one vertex designed by SA can be diffused into a large
part of the graph.

    

### [[2109.04611] Query-driven Segment Selection for Ranking Long Documents](http://arxiv.org/abs/2109.04611)


  Transformer-based rankers have shown state-of-the-art performance. However,
their self-attention operation is mostly unable to process long sequences. One
of the common approaches to train these rankers is to heuristically select some
segments of each document, such as the first segment, as training data.
However, these segments may not contain the query-related parts of documents.
To address this problem, we propose query-driven segment selection from long
documents to build training data. The segment selector provides relevant
samples with more accurate labels and non-relevant samples which are harder to
be predicted. The experimental results show that the basic BERT-based ranker
trained with the proposed segment selector significantly outperforms that
trained by the heuristically selected segments, and performs equally to the
state-of-the-art model with localized self-attention that can process longer
input sequences. Our findings open up new direction to design efficient
transformer-based rankers.

    

### [[2109.04615] Differential Privacy in Personalized Pricing with Nonparametric Demand Models](http://arxiv.org/abs/2109.04615)


  In the recent decades, the advance of information technology and abundant
personal data facilitate the application of algorithmic personalized pricing.
However, this leads to the growing concern of potential violation of privacy
due to adversarial attack. To address the privacy issue, this paper studies a
dynamic personalized pricing problem with \textit{unknown} nonparametric demand
models under data privacy protection. Two concepts of data privacy, which have
been widely applied in practices, are introduced: \textit{central differential
privacy (CDP)} and \textit{local differential privacy (LDP)}, which is proved
to be stronger than CDP in many cases. We develop two algorithms which make
pricing decisions and learn the unknown demand on the fly, while satisfying the
CDP and LDP gurantees respectively. In particular, for the algorithm with CDP
guarantee, the regret is proved to be at most $\tilde
O(T^{(d+2)/(d+4)}+\varepsilon^{-1}T^{d/(d+4)})$. Here, the parameter $T$
denotes the length of the time horizon, $d$ is the dimension of the
personalized information vector, and the key parameter $\varepsilon>0$ measures
the strength of privacy (smaller $\varepsilon$ indicates a stronger privacy
protection). On the other hand, for the algorithm with LDP guarantee, its
regret is proved to be at most $\tilde
O(\varepsilon^{-2/(d+2)}T^{(d+1)/(d+2)})$, which is near-optimal as we prove a
lower bound of $\Omega(\varepsilon^{-2/(d+2)}T^{(d+1)/(d+2)})$ for any
algorithm with LDP guarantee.

    

### [[2109.04617] Efficiently Identifying Task Groupings for Multi-Task Learning](http://arxiv.org/abs/2109.04617)


  Multi-task learning can leverage information learned by one task to benefit
the training of other tasks. Despite this capacity, naively training all tasks
together in one model often degrades performance, and exhaustively searching
through combinations of task groupings can be prohibitively expensive. As a
result, efficiently identifying the tasks that would benefit from co-training
remains a challenging design question without a clear solution. In this paper,
we suggest an approach to select which tasks should train together in
multi-task learning models. Our method determines task groupings in a single
training run by co-training all tasks together and quantifying the effect to
which one task's gradient would affect another task's loss. On the large-scale
Taskonomy computer vision dataset, we find this method can decrease test loss
by 10.0\% compared to simply training all tasks together while operating 11.6
times faster than a state-of-the-art task grouping method.

    

### [[2109.04623] ReLU Regression with Massart Noise](http://arxiv.org/abs/2109.04623)


  We study the fundamental problem of ReLU regression, where the goal is to fit
Rectified Linear Units (ReLUs) to data. This supervised learning task is
efficiently solvable in the realizable setting, but is known to be
computationally hard with adversarial label noise. In this work, we focus on
ReLU regression in the Massart noise model, a natural and well-studied
semi-random noise model. In this model, the label of every point is generated
according to a function in the class, but an adversary is allowed to change
this value arbitrarily with some probability, which is {\em at most} $\eta <
1/2$. We develop an efficient algorithm that achieves exact parameter recovery
in this model under mild anti-concentration assumptions on the underlying
distribution. Such assumptions are necessary for exact recovery to be
information-theoretically possible. We demonstrate that our algorithm
significantly outperforms naive applications of $\ell_1$ and $\ell_2$
regression on both synthetic and real data.

    

### [[2109.04624] Style Pooling: Automatic Text Style Obfuscation for Improved Classification Fairness](http://arxiv.org/abs/2109.04624)


  Text style can reveal sensitive attributes of the author (e.g. race or age)
to the reader, which can, in turn, lead to privacy violations and bias in both
human and algorithmic decisions based on text. For example, the style of
writing in job applications might reveal protected attributes of the candidate
which could lead to bias in hiring decisions, regardless of whether hiring
decisions are made algorithmically or by humans. We propose a VAE-based
framework that obfuscates stylistic features of human-generated text through
style transfer by automatically re-writing the text itself. Our framework
operationalizes the notion of obfuscated style in a flexible way that enables
two distinct notions of obfuscated style: (1) a minimal notion that effectively
intersects the various styles seen in training, and (2) a maximal notion that
seeks to obfuscate by adding stylistic features of all sensitive attributes to
text, in effect, computing a union of styles. Our style-obfuscation framework
can be used for multiple purposes, however, we demonstrate its effectiveness in
improving the fairness of downstream classifiers. We also conduct a
comprehensive study on style pooling's effect on fluency, semantic consistency,
and attribute removal from text, in two and three domain style obfuscation.

    

### [[2109.04626] A Fast PC Algorithm with Reversed-order Pruning and A Parallelization Strategy](http://arxiv.org/abs/2109.04626)


  The PC algorithm is the state-of-the-art algorithm for causal structure
discovery on observational data. It can be computationally expensive in the
worst case due to the conditional independence tests are performed in an
exhaustive-searching manner. This makes the algorithm computationally
intractable when the task contains several hundred or thousand nodes,
particularly when the true underlying causal graph is dense. We propose a
critical observation that the conditional set rendering two nodes independent
is non-unique, and including certain redundant nodes do not sacrifice result
accuracy. Based on this finding, the innovations of our work are two-folds.
First, we innovate on a reserve order linkage pruning PC algorithm which
significantly increases the algorithm's efficiency. Second, we propose a
parallel computing strategy for statistical independence tests by leveraging
tensor computation, which brings further speedup. We also prove the proposed
algorithm does not induce statistical power loss under mild graph and data
dimensionality assumptions. Experimental results show that the single-threaded
version of the proposed algorithm can achieve a 6-fold speedup compared to the
PC algorithm on a dense 95-node graph, and the parallel version can make a
825-fold speed-up. We also provide proof that the proposed algorithm is
consistent under the same set of conditions with conventional PC algorithm.

    

### [[2109.04640] Projected State-action Balancing Weights for Offline Reinforcement Learning](http://arxiv.org/abs/2109.04640)


  Offline policy evaluation (OPE) is considered a fundamental and challenging
problem in reinforcement learning (RL). This paper focuses on the value
estimation of a target policy based on pre-collected data generated from a
possibly different policy, under the framework of infinite-horizon Markov
decision processes. Motivated by the recently developed marginal importance
sampling method in RL and the covariate balancing idea in causal inference, we
propose a novel estimator with approximately projected state-action balancing
weights for the policy value estimation. We obtain the convergence rate of
these weights, and show that the proposed value estimator is semi-parametric
efficient under technical conditions. In terms of asymptotics, our results
scale with both the number of trajectories and the number of decision points at
each trajectory. As such, consistency can still be achieved with a limited
number of subjects when the number of decision points diverges. In addition, we
make a first attempt towards characterizing the difficulty of OPE problems,
which may be of independent interest. Numerical experiments demonstrate the
promising performance of our proposed estimator.

    

### [[2109.04641] Learning to Teach with Student Feedback](http://arxiv.org/abs/2109.04641)


  Knowledge distillation (KD) has gained much attention due to its
effectiveness in compressing large-scale pre-trained models. In typical KD
methods, the small student model is trained to match the soft targets generated
by the big teacher model. However, the interaction between student and teacher
is one-way. The teacher is usually fixed once trained, resulting in static soft
targets to be distilled. This one-way interaction leads to the teacher's
inability to perceive the characteristics of the student and its training
progress. To address this issue, we propose Interactive Knowledge Distillation
(IKD), which also allows the teacher to learn to teach from the feedback of the
student. In particular, IKD trains the teacher model to generate specific soft
target at each training step for a certain student. Joint optimization for both
teacher and student is achieved by two iterative steps: a course step to
optimize student with the soft target of teacher, and an exam step to optimize
teacher with the feedback of student. IKD is a general framework that is
orthogonal to most existing knowledge distillation methods. Experimental
results show that IKD outperforms traditional KD methods on various NLP tasks.

    

### [[2109.04645] CINS: Comprehensive Instruction for Few-shot Learning in Task-orientedDialog Systems](http://arxiv.org/abs/2109.04645)


  As labeling cost for different modules in task-oriented dialog (ToD) systems
is high, a major challenge in practice is to learn different tasks with the
least amount of labeled data. Recently, prompting methods over pre-trained
language models (PLMs) have shown promising results for few-shot learning in
ToD. To better utilize the power of PLMs, this paper proposes Comprehensive
Instruction (CINS) that exploits PLMs with extra task-specific instructions. We
design a schema(definition, constraint, prompt) of instructions and their
customized realizations for three important downstream tasks in ToD, i.e.
intent classification, dialog state tracking, and natural language generation.
A sequence-to-sequence model (T5)is adopted to solve these three tasks in a
unified framework. Extensive experiments are conducted on these ToD tasks in
realistic few-shot learning scenarios with small validation data. Empirical
results demonstrate that the proposed CINS approach consistently improves
techniques that finetune PLMs with raw input or short prompts.

    

### [[2109.04660] Dynamic Collective Intelligence Learning: Finding Efficient Sparse Model via Refined Gradients for Pruned Weights](http://arxiv.org/abs/2109.04660)


  With the growth of deep neural networks (DNN), the number of DNN parameters
has drastically increased. This makes DNN models hard to be deployed on
resource-limited embedded systems. To alleviate this problem, dynamic pruning
methods have emerged, which try to find diverse sparsity patterns during
training by utilizing Straight-Through-Estimator (STE) to approximate gradients
of pruned weights. STE can help the pruned weights revive in the process of
finding dynamic sparsity patterns. However, using these coarse gradients causes
training instability and performance degradation owing to the unreliable
gradient signal of the STE approximation. In this work, to tackle this issue,
we introduce refined gradients to update the pruned weights by forming dual
forwarding paths from two sets (pruned and unpruned) of weights. We propose a
novel Dynamic Collective Intelligence Learning (DCIL) which makes use of the
learning synergy between the collective intelligence of both weight sets. We
verify the usefulness of the refined gradients by showing enhancements in the
training stability and the model performance on the CIFAR and ImageNet
datasets. DCIL outperforms various previously proposed pruning schemes
including other dynamic pruning methods with enhanced stability during
training.

    

### [[2109.04672] Investigating Numeracy Learning Ability of a Text-to-Text Transfer Model](http://arxiv.org/abs/2109.04672)


  The transformer-based pre-trained language models have been tremendously
successful in most of the conventional NLP tasks. But they often struggle in
those tasks where numerical understanding is required. Some possible reasons
can be the tokenizers and pre-training objectives which are not specifically
designed to learn and preserve numeracy. Here we investigate the ability of
text-to-text transfer learning model (T5), which has outperformed its
predecessors in the conventional NLP tasks, to learn numeracy. We consider four
numeracy tasks: numeration, magnitude order prediction, finding minimum and
maximum in a series, and sorting. We find that, although T5 models perform
reasonably well in the interpolation setting, they struggle considerably in the
extrapolation setting across all four tasks.

    

### [[2109.04684] Enhancing Unsupervised Anomaly Detection with Score-Guided Network](http://arxiv.org/abs/2109.04684)


  Anomaly detection plays a crucial role in various real-world applications,
including healthcare and finance systems. Owing to the limited number of
anomaly labels in these complex systems, unsupervised anomaly detection methods
have attracted great attention in recent years. Two major challenges faced by
the existing unsupervised methods are: (i) distinguishing between normal and
abnormal data in the transition field, where normal and abnormal data are
highly mixed together; (ii) defining an effective metric to maximize the gap
between normal and abnormal data in a hypothesis space, which is built by a
representation learner. To that end, this work proposes a novel scoring network
with a score-guided regularization to learn and enlarge the anomaly score
disparities between normal and abnormal data. With such score-guided strategy,
the representation learner can gradually learn more informative representation
during the model training stage, especially for the samples in the transition
field. We next propose a score-guided autoencoder (SG-AE), incorporating the
scoring network into an autoencoder framework for anomaly detection, as well as
other three state-of-the-art models, to further demonstrate the effectiveness
and transferability of the design. Extensive experiments on both synthetic and
real-world datasets demonstrate the state-of-the-art performance of these
score-guided models (SGMs).

    

### [[2109.04689] Generating Self-Contained and Summary-Centric Question Answer Pairs via Differentiable Reward Imitation Learning](http://arxiv.org/abs/2109.04689)


  Motivated by suggested question generation in conversational news
recommendation systems, we propose a model for generating question-answer pairs
(QA pairs) with self-contained, summary-centric questions and
length-constrained, article-summarizing answers. We begin by collecting a new
dataset of news articles with questions as titles and pairing them with
summaries of varying length. This dataset is used to learn a QA pair generation
model producing summaries as answers that balance brevity with sufficiency
jointly with their corresponding questions. We then reinforce the QA pair
generation process with a differentiable reward function to mitigate exposure
bias, a common problem in natural language generation. Both automatic metrics
and human evaluation demonstrate these QA pairs successfully capture the
central gists of the articles and achieve high answer accuracy.

    

### [[2109.04697] Unfolding Projection-free SDP Relaxation of Binary Graph Classifier via GDPA Linearization](http://arxiv.org/abs/2109.04697)


  Algorithm unfolding creates an interpretable and parsimonious neural network
architecture by implementing each iteration of a model-based algorithm as a
neural layer. However, unfolding a proximal splitting algorithm with a positive
semi-definite (PSD) cone projection operator per iteration is expensive, due to
the required full matrix eigen-decomposition. In this paper, leveraging a
recent linear algebraic theorem called Gershgorin disc perfect alignment
(GDPA), we unroll a projection-free algorithm for semi-definite programming
relaxation (SDR) of a binary graph classifier, where the PSD cone constraint is
replaced by a set of "tightest possible" linear constraints per iteration. As a
result, each iteration only requires computing a linear program (LP) and one
extreme eigenvector. Inside the unrolled network, we optimize parameters via
stochastic gradient descent (SGD) that determine graph edge weights in two
ways: i) a metric matrix that computes feature distances, and ii) a sparse
weight matrix computed via local linear embedding (LLE). Experimental results
show that our unrolled network outperformed pure model-based graph classifiers,
and achieved comparable performance to pure data-driven networks but using far
fewer parameters.

    

### [[2109.04699] EfficientCLIP: Efficient Cross-Modal Pre-training by Ensemble Confident Learning and Language Modeling](http://arxiv.org/abs/2109.04699)


  While large scale pre-training has achieved great achievements in bridging
the gap between vision and language, it still faces several challenges. First,
the cost for pre-training is expensive. Second, there is no efficient way to
handle the data noise which degrades model performance. Third, previous methods
only leverage limited image-text paired data, while ignoring richer
single-modal data, which may result in poor generalization to single-modal
downstream tasks. In this work, we propose an EfficientCLIP method via Ensemble
Confident Learning to obtain a less noisy data subset. Extra rich non-paired
single-modal text data is used for boosting the generalization of text branch.
We achieve the state-of-the-art performance on Chinese cross-modal retrieval
tasks with only 1/10 training resources compared to CLIP and WenLan, while
showing excellent generalization to single-modal tasks, including text
retrieval and text classification.

    

### [[2109.04707] Knowledge-Aware Meta-learning for Low-Resource Text Classification](http://arxiv.org/abs/2109.04707)


  Meta-learning has achieved great success in leveraging the historical learned
knowledge to facilitate the learning process of the new task. However, merely
learning the knowledge from the historical tasks, adopted by current
meta-learning algorithms, may not generalize well to testing tasks when they
are not well-supported by training tasks. This paper studies a low-resource
text classification problem and bridges the gap between meta-training and
meta-testing tasks by leveraging the external knowledge bases. Specifically, we
propose KGML to introduce additional representation for each sentence learned
from the extracted sentence-specific knowledge graph. The extensive experiments
on three datasets demonstrate the effectiveness of KGML under both supervised
adaptation and unsupervised adaptation settings.

    

### [[2109.04720] 6MapNet: Representing soccer players from tracking data by a triplet network](http://arxiv.org/abs/2109.04720)


  Although the values of individual soccer players have become astronomical,
subjective judgments still play a big part in the player analysis. Recently,
there have been new attempts to quantitatively grasp players' styles using
video-based event stream data. However, they have some limitations in
scalability due to high annotation costs and sparsity of event stream data. In
this paper, we build a triplet network named 6MapNet that can effectively
capture the movement styles of players using in-game GPS data. Without any
annotation of soccer-specific actions, we use players' locations and velocities
to generate two types of heatmaps. Our subnetworks then map these heatmap pairs
into feature vectors whose similarity corresponds to the actual similarity of
playing styles. The experimental results show that players can be accurately
identified with only a small number of matches by our method.

    

### [[2109.04738] On the validity of pre-trained transformers for natural language processing in the software engineering domain](http://arxiv.org/abs/2109.04738)


  Transformers are the current state-of-the-art of natural language processing
in many domains and are using traction within software engineering research as
well. Such models are pre-trained on large amounts of data, usually from the
general domain. However, we only have a limited understanding regarding the
validity of transformers within the software engineering domain, i.e., how good
such models are at understanding words and sentences within a software
engineering context and how this improves the state-of-the-art. Within this
article, we shed light on this complex, but crucial issue. We compare BERT
transformer models trained with software engineering data with transformers
based on general domain data in multiple dimensions: their vocabulary, their
ability to understand which words are missing, and their performance in
classification tasks. Our results show that for tasks that require
understanding of the software engineering context, pre-training with software
engineering data is valuable, while general domain models are sufficient for
general language understanding, also within the software engineering domain.

    

### [[2109.04744] Automated Machine Learning, Bounded Rationality, and Rational Metareasoning](http://arxiv.org/abs/2109.04744)


  The notion of bounded rationality originated from the insight that perfectly
rational behavior cannot be realized by agents with limited cognitive or
computational resources. Research on bounded rationality, mainly initiated by
Herbert Simon, has a longstanding tradition in economics and the social
sciences, but also plays a major role in modern AI and intelligent agent
design. Taking actions under bounded resources requires an agent to reflect on
how to use these resources in an optimal way - hence, to reason and make
decisions on a meta-level. In this paper, we will look at automated machine
learning (AutoML) and related problems from the perspective of bounded
rationality, essentially viewing an AutoML tool as an agent that has to train a
model on a given set of data, and the search for a good way of doing so (a
suitable "ML pipeline") as deliberation on a meta-level.

    

### [[2109.04746] Counterfactual Adversarial Learning with Representation Interpolation](http://arxiv.org/abs/2109.04746)


  Deep learning models exhibit a preference for statistical fitting over
logical reasoning. Spurious correlations might be memorized when there exists
statistical bias in training data, which severely limits the model performance
especially in small data scenarios. In this work, we introduce Counterfactual
Adversarial Training framework (CAT) to tackle the problem from a causality
perspective. Particularly, for a specific sample, CAT first generates a
counterfactual representation through latent space interpolation in an
adversarial manner, and then performs Counterfactual Risk Minimization (CRM) on
each original-counterfactual pair to adjust sample-wise loss weight
dynamically, which encourages the model to explore the true causal effect.
Extensive experiments demonstrate that CAT achieves substantial performance
improvement over SOTA across different downstream tasks, including sentence
classification, natural language inference and question answering.

    

### [[2109.04762] Dual-State Capsule Networks for Text Classification](http://arxiv.org/abs/2109.04762)


  Text classification systems based on contextual embeddings are not viable
options for many of the low resource languages. On the other hand, recently
introduced capsule networks have shown performance in par with these text
classification models. Thus, they could be considered as a viable alternative
for text classification for languages that do not have pre-trained contextual
embedding models. However, current capsule networks depend upon spatial
patterns without considering the sequential features of the text. They are also
sub-optimal in capturing the context-level information in longer sequences.
This paper presents a novel Dual-State Capsule (DS-Caps) network-based
technique for text classification, which is optimized to mitigate these issues.
Two varieties of states, namely sentence-level and word-level, are integrated
with capsule layers to capture deeper context-level information for language
modeling. The dynamic routing process among capsules was also optimized using
the context-level information obtained through sentence-level states. The
DS-Caps networks outperform the existing capsule network architectures for
multiple datasets, particularly for tasks with longer sequences of text. We
also demonstrate the superiority of DS-Caps in text classification for a low
resource language.

    

### [[2109.04767] Multi-label Classification of Aircraft Heading Changes Using Neural Network to Resolve Conflicts](http://arxiv.org/abs/2109.04767)


  An aircraft conflict occurs when two or more aircraft cross at a certain
distance at the same time. Specific air traffic controllers are assigned to
solve such conflicts. A controller needs to consider various types of
information in order to solve a conflict. The most common and preliminary
information is the coordinate position of the involved aircraft. Additionally,
a controller has to take into account more information such as flight planning,
weather, restricted territory, etc. The most important challenges a controller
has to face are: to think about the issues involved and make a decision in a
very short time. Due to the increased number of aircraft, it is crucial to
reduce the workload of the controllers and help them make quick decisions. A
conflict can be solved in many ways, therefore, we consider this problem as a
multi-label classification problem. In doing so, we are proposing a multi-label
classification model which provides multiple heading advisories for a given
conflict. This model we named CRMLnet is based on a novel application of a
multi-layer neural network and helps the controllers in their decisions. When
compared to other machine learning models, our CRMLnet has achieved the best
results with an accuracy of 98.72% and ROC of 0.999. The simulated data set
that we have developed and used in our experiments will be delivered to the
research community.

    

### [[2109.04783] Self-Attention Channel Combinator Frontend for End-to-End Multichannel Far-field Speech Recognition](http://arxiv.org/abs/2109.04783)


  When a sufficiently large far-field training data is presented, jointly
optimizing a multichannel frontend and an end-to-end (E2E) Automatic Speech
Recognition (ASR) backend shows promising results. Recent literature has shown
traditional beamformer designs, such as MVDR (Minimum Variance Distortionless
Response) or fixed beamformers can be successfully integrated as the frontend
into an E2E ASR system with learnable parameters. In this work, we propose the
self-attention channel combinator (SACC) ASR frontend, which leverages the
self-attention mechanism to combine multichannel audio signals in the magnitude
spectral domain. Experiments conducted on a multichannel playback test data
shows that the SACC achieved a 9.3% WERR compared to a state-of-the-art fixed
beamformer-based frontend, both jointly optimized with a ContextNet-based ASR
backend. We also demonstrate the connection between the SACC and the
traditional beamformers, and analyze the intermediate outputs of the SACC.

    

### [[2109.04797] Mesh convolutional neural networks for wall shear stress estimation in 3D artery models](http://arxiv.org/abs/2109.04797)


  Computational fluid dynamics (CFD) is a valuable tool for personalised,
non-invasive evaluation of hemodynamics in arteries, but its complexity and
time-consuming nature prohibit large-scale use in practice. Recently, the use
of deep learning for rapid estimation of CFD parameters like wall shear stress
(WSS) on surface meshes has been investigated. However, existing approaches
typically depend on a hand-crafted re-parametrisation of the surface mesh to
match convolutional neural network architectures. In this work, we propose to
instead use mesh convolutional neural networks that directly operate on the
same finite-element surface mesh as used in CFD. We train and evaluate our
method on two datasets of synthetic coronary artery models with and without
bifurcation, using a ground truth obtained from CFD simulation. We show that
our flexible deep learning model can accurately predict 3D WSS vectors on this
surface mesh. Our method processes new meshes in less than 5 [s], consistently
achieves a normalised mean absolute error of $\leq$ 1.6 [%], and peaks at 90.5
[%] median approximation accuracy over the held-out test set, comparing
favorably to previously published work. This shows the feasibility of CFD
surrogate modelling using mesh convolutional neural networks for hemodynamic
parameter estimation in artery models.

    

### [[2109.04809] Efficient Locally Optimal Number Set Partitioning for Scheduling, Allocation and Fair Selection](http://arxiv.org/abs/2109.04809)


  We study the optimization version of the set partition problem (where the
difference between the partition sums are minimized), which has numerous
applications in decision theory literature. While the set partitioning problem
is NP-hard and requires exponential complexity to solve (i.e., intractable); we
formulate a weaker version of this NP-hard problem, where the goal is to find a
locally optimal solution. We show that our proposed algorithms can find a
locally optimal solution in near linear time. Our algorithms require neither
positive nor integer elements in the input set, hence, they are more widely
applicable.

    

### [[2109.04821] KNODE-MPC: A Knowledge-based Data-driven Predictive Control Framework for Aerial Robots](http://arxiv.org/abs/2109.04821)


  In this work, we consider the problem of deriving and incorporating accurate
dynamic models for model predictive control (MPC) with an application to
quadrotor control. MPC relies on precise dynamic models to achieve the desired
closed-loop performance. However, the presence of uncertainties in complex
systems and the environments they operate in poses a challenge in obtaining
sufficiently accurate representations of the system dynamics. In this work, we
make use of a deep learning tool, knowledge-based neural ordinary differential
equations (KNODE), to augment a model obtained from first principles. The
resulting hybrid model encompasses both a nominal first-principle model and a
neural network learnt from simulated or real-world experimental data. Using a
quadrotor, we benchmark our hybrid model against a state-of-the-art Gaussian
Process (GP) model and show that the hybrid model provides more accurate
predictions of the quadrotor dynamics and is able to generalize beyond the
training data. To improve closed-loop performance, the hybrid model is
integrated into a novel MPC framework, known as KNODE-MPC. Results show that
the integrated framework achieves 73% improvement in simulations and more than
14% in physical experiments, in terms of trajectory tracking performance.

    

### [[2109.04824] Inverse design of 3d molecular structures with conditional generative neural networks](http://arxiv.org/abs/2109.04824)


  The rational design of molecules with desired properties is a long-standing
challenge in chemistry. Generative neural networks have emerged as a powerful
approach to sample novel molecules from a learned distribution. Here, we
propose a conditional generative neural network for 3d molecular structures
with specified structural and chemical properties. This approach is agnostic to
chemical bonding and enables targeted sampling of novel molecules from
conditional distributions, even in domains where reference calculations are
sparse. We demonstrate the utility of our method for inverse design by
generating molecules with specified composition or motifs, discovering
particularly stable molecules, and jointly targeting multiple electronic
properties beyond the training regime.

    

### [[2109.04825] Artificial Text Detection via Examining the Topology of Attention Maps](http://arxiv.org/abs/2109.04825)


  The impressive capabilities of recent generative models to create texts that
are challenging to distinguish from the human-written ones can be misused for
generating fake news, product reviews, and even abusive content. Despite the
prominent performance of existing methods for artificial text detection, they
still lack interpretability and robustness towards unseen models. To this end,
we propose three novel types of interpretable topological features for this
task based on Topological Data Analysis (TDA) which is currently understudied
in the field of NLP. We empirically show that the features derived from the
BERT model outperform count- and neural-based baselines up to 10\% on three
common datasets, and tend to be the most robust towards unseen GPT-style
generation models as opposed to existing methods. The probing analysis of the
features reveals their sensitivity to the surface and syntactic properties. The
results demonstrate that TDA is a promising line with respect to NLP tasks,
specifically the ones that incorporate surface and structural information.

    

### [[2109.04831] Simulating the Effects of Eco-Friendly Transportation Selections for Air Pollution Reduction](http://arxiv.org/abs/2109.04831)


  Reducing air pollution, such as CO2 and PM2.5 emissions, is one of the most
important issues for many countries worldwide. Selecting an environmentally
friendly transport mode can be an effective approach of individuals to reduce
air pollution in daily life. In this study, we propose a method to simulate the
effectiveness of an eco-friendly transport mode selection for reducing air
pollution by using map search logs. We formulate the transport mode selection
as a combinatorial optimization problem with the constraints regarding the
total amount of CO2 emissions as an example of air pollution and the average
travel time. The optimization results show that the total amount of CO2
emissions can be reduced by 9.23%, whereas the average travel time can in fact
be reduced by 9.96%. Our research proposal won first prize in Regular Machine
Learning Competition Track Task 2 at KDD Cup 2019.

    

### [[2109.04833] Multimodal Federated Learning](http://arxiv.org/abs/2109.04833)


  Federated learning is proposed as an alternative to centralized machine
learning since its client-server structure provides better privacy protection
and scalability in real-world applications. In many applications, such as smart
homes with IoT devices, local data on clients are generated from different
modalities such as sensory, visual, and audio data. Existing federated learning
systems only work on local data from a single modality, which limits the
scalability of the systems.
In this paper, we propose a multimodal and semi-supervised federated learning
framework that trains autoencoders to extract shared or correlated
representations from different local data modalities on clients. In addition,
we propose a multimodal FedAvg algorithm to aggregate local autoencoders
trained on different data modalities. We use the learned global autoencoder for
a downstream classification task with the help of auxiliary labelled data on
the server. We empirically evaluate our framework on different modalities
including sensory data, depth camera videos, and RGB camera videos. Our
experimental results demonstrate that introducing data from multiple modalities
into federated learning can improve its accuracy. In addition, we can use
labelled data from only one modality for supervised learning on the server and
apply the learned model to testing data from other modalities to achieve decent
accuracy (e.g., approximately 70% as the best performance), especially when
combining contributions from both unimodal clients and multimodal clients.

    

### [[2109.04835] FR-Detect: A Multi-Modal Framework for Early Fake News Detection on Social Media Using Publishers Features](http://arxiv.org/abs/2109.04835)


  In recent years, with the expansion of the Internet and attractive social
media infrastructures, people prefer to follow the news through these media.
Despite the many advantages of these media in the news field, the lack of any
control and verification mechanism has led to the spread of fake news, as one
of the most important threats to democracy, economy, journalism and freedom of
expression. Designing and using automatic methods to detect fake news on social
media has become a significant challenge. In this paper, we examine the
publishers' role in detecting fake news on social media. We also suggest a high
accurate multi-modal framework, namely FR-Detect, using user-related and
content-related features with early detection capability. For this purpose, two
new user-related features, namely Activity Credibility and Influence, have been
introduced for publishers. Furthermore, a sentence-level convolutional neural
network is provided to combine these features with latent textual content
features properly. Experimental results have shown that the publishers'
features can improve the performance of content-based models by up to 13% and
29% in accuracy and F1-score, respectively.

    

### [[2109.04838] Block Pruning For Faster Transformers](http://arxiv.org/abs/2109.04838)


  Pre-training has improved model accuracy for both classification and
generation tasks at the cost of introducing much larger and slower models.
Pruning methods have proven to be an effective way of reducing model size,
whereas distillation methods are proven for speeding up inference. We introduce
a block pruning approach targeting both small and fast models. Our approach
extends structured methods by considering blocks of any size and integrates
this structure into the movement pruning paradigm for fine-tuning. We find that
this approach learns to prune out full components of the underlying model, such
as attention heads. Experiments consider classification and generation tasks,
yielding among other results a pruned model that is a 2.4x faster, 74% smaller
BERT on SQuAD v1, with a 1% drop on F1, competitive both with distilled models
in speed and pruned models in size.

    

### [[2109.04847] Active learning for reducing labeling effort in text classification tasks](http://arxiv.org/abs/2109.04847)


  Labeling data can be an expensive task as it is usually performed manually by
domain experts. This is cumbersome for deep learning, as it is dependent on
large labeled datasets. Active learning (AL) is a paradigm that aims to reduce
labeling effort by only using the data which the used model deems most
informative. Little research has been done on AL in a text classification
setting and next to none has involved the more recent, state-of-the-art NLP
models. Here, we present an empirical study that compares different
uncertainty-based algorithms with BERT$_{base}$ as the used classifier. We
evaluate the algorithms on two NLP classification datasets: Stanford Sentiment
Treebank and KvK-Frontpages. Additionally, we explore heuristics that aim to
solve presupposed problems of uncertainty-based AL; namely, that it is
unscalable and that it is prone to selecting outliers. Furthermore, we explore
the influence of the query-pool size on the performance of AL. Whereas it was
found that the proposed heuristics for AL did not improve performance of AL;
our results show that using uncertainty-based AL with BERT$_{base}$ outperforms
random sampling of data. This difference in performance can decrease as the
query-pool size gets larger.

    

### [[2109.04868] Heading Estimation Using Ultra-Wideband Received Signal Strength and Gaussian Processes](http://arxiv.org/abs/2109.04868)


  It is essential that a robot has the ability to determine its position and
orientation to execute tasks autonomously. Heading estimation is especially
challenging in indoor environments where magnetic distortions make
magnetometer-based heading estimation difficult. Ultra-wideband (UWB)
transceivers are common in indoor localization problems. This letter
experimentally demonstrates how to use UWB range and received signal strength
(RSS) measurements to estimate robot heading. The RSS of a UWB antenna varies
with its orientation. As such, a Gaussian process (GP) is used to learn a
data-driven relationship from UWB range and RSS inputs to orientation outputs.
Combined with a gyroscope in an invariant extended Kalman filter, this realizes
a heading estimation method that uses only UWB and gyroscope measurements.

    

### [[2109.04875] Neural Networks for Latent Budget Analysis of Compositional Data](http://arxiv.org/abs/2109.04875)


  Compositional data are non-negative data collected in a rectangular matrix
with a constant row sum. Due to the non-negativity the focus is on conditional
proportions that add up to 1 for each row. A row of conditional proportions is
called an observed budget. Latent budget analysis (LBA) assumes a mixture of
latent budgets that explains the observed budgets. LBA is usually fitted to a
contingency table, where the rows are levels of one or more explanatory
variables and the columns the levels of a response variable. In prospective
studies, there is only knowledge about the explanatory variables of individuals
and interest goes out to predicting the response variable. Thus, a form of LBA
is needed that has the functionality of prediction. Previous studies proposed a
constrained neural network (NN) extension of LBA that was hampered by an
unsatisfying prediction ability. Here we propose LBA-NN, a feed forward NN
model that yields a similar interpretation to LBA but equips LBA with a better
ability of prediction. A stable and plausible interpretation of LBA-NN is
obtained through the use of importance plots and table, that show the relative
importance of all explanatory variables on the response variable. An LBA-NN-K-
means approach that applies K-means clustering on the importance table is used
to produce K clusters that are comparable to K latent budgets in LBA. Here we
provide different experiments where LBA-NN is implemented and compared with
LBA. In our analysis, LBA-NN outperforms LBA in prediction in terms of
accuracy, specificity, recall and mean square error. We provide open-source
software at GitHub.

    

### [[2109.04876] Integrating Approaches to Word Representation](http://arxiv.org/abs/2109.04876)


  The problem of representing the atomic elements of language in modern neural
learning systems is one of the central challenges of the field of natural
language processing. I present a survey of the distributional, compositional,
and relational approaches to addressing this task, and discuss various means of
integrating them into systems, with special emphasis on the word level and the
out-of-vocabulary phenomenon.

    

### [[2109.04880] Hybrid modeling of the human cardiovascular system using NeuralFMUs](http://arxiv.org/abs/2109.04880)


  Hybrid modeling, the combination of first principle and machine learning
models, is an emerging research field that gathers more and more attention.
Even if hybrid models produce formidable results for academic examples, there
are still different technical challenges that hinder the use of hybrid modeling
in real-world applications. By presenting NeuralFMUs, the fusion of a FMU, a
numerical ODE solver and an ANN, we are paving the way for the use of a variety
of first principle models from different modeling tools as parts of hybrid
models. This contribution handles the hybrid modeling of a complex, real-world
example: Starting with a simplified 1D-fluid model of the human cardiovascular
system (arterial side), the aim is to learn neglected physical effects like
arterial elasticity from data. We will show that the hybrid modeling process is
more comfortable, needs less system knowledge and is therefore less error-prone
compared to modeling solely based on first principle. Further, the resulting
hybrid model has improved in computation performance, compared to a pure first
principle white-box model, while still fulfilling the requirements regarding
accuracy of the considered hemodynamic quantities. The use of the presented
techniques is explained in a general manner and the considered use-case can
serve as example for other modeling and simulation applications in and beyond
the medical domain.

    

### [[2109.04881] ProcK: Machine Learning for Knowledge-Intensive Processes](http://arxiv.org/abs/2109.04881)


  Process mining deals with extraction of knowledge from business process
execution logs. Traditional process mining tasks, like process model generation
or conformance checking, rely on a minimalistic feature set where each event is
characterized only by its case identifier, activity type, and timestamp. In
contrast, the success of modern machine learning is based on models that take
any available data as direct input and build layers of features automatically
during training. In this work, we introduce ProcK (Process & Knowledge), a
novel pipeline to build business process prediction models that take into
account both sequential data in the form of event logs and rich semantic
information represented in a graph-structured knowledge base. The hybrid
approach enables ProcK to flexibly make use of all information residing in the
databases of organizations. Components to extract inter-linked event logs and
knowledge bases from relational databases are part of the pipeline. We
demonstrate the power of ProcK by training it for prediction tasks on the OULAD
e-learning dataset, where we achieve state-of-the-art performance on the tasks
of predicting student dropout from courses and predicting their success. We
also apply our method on a number of additional machine learning tasks,
including exam score prediction and early predictions that only take into
account data recorded during the first weeks of the courses.

    

### [[2109.04912] ReasonBERT: Pre-trained to Reason with Distant Supervision](http://arxiv.org/abs/2109.04912)


  We present ReasonBert, a pre-training method that augments language models
with the ability to reason over long-range relations and multiple, possibly
hybrid contexts. Unlike existing pre-training methods that only harvest
learning signals from local contexts of naturally occurring texts, we propose a
generalized notion of distant supervision to automatically connect multiple
pieces of text and tables to create pre-training examples that require
long-range reasoning. Different types of reasoning are simulated, including
intersecting multiple pieces of evidence, bridging from one piece of evidence
to another, and detecting unanswerable cases. We conduct a comprehensive
evaluation on a variety of extractive question answering datasets ranging from
single-hop to multi-hop and from text-only to table-only to hybrid that require
various reasoning capabilities and show that ReasonBert achieves remarkable
improvement over an array of strong baselines. Few-shot experiments further
demonstrate that our pre-training method substantially improves sample
efficiency.

    

### [[2109.04916] Unsupervised classification of simulated magnetospheric regions](http://arxiv.org/abs/2109.04916)


  In magnetospheric missions, burst mode data sampling should be triggered in
the presence of processes of scientific or operational interest. We present an
unsupervised classification method for magnetospheric regions, that could
constitute the first-step of a multi-step method for the automatic
identification of magnetospheric processes of interest. Our method is based on
Self Organizing Maps (SOMs), and we test it preliminarily on data points from
global magnetospheric simulations obtained with the OpenGGCM-CTIM-RCM code. The
dimensionality of the data is reduced with Principal Component Analysis before
classification. The classification relies exclusively on local plasma
properties at the selected data points, without information on their
neighborhood or on their temporal evolution. We classify the SOM nodes into an
automatically selected number of classes, and we obtain clusters that map to
well defined magnetospheric regions. We validate our classification results by
plotting the classified data in the simulated space and by comparing with
K-means classification. For the sake of result interpretability, we examine the
SOM feature maps (magnetospheric variables are called features in the context
of classification), and we use them to unlock information on the clusters. We
repeat the classification experiments using different sets of features, we
quantitatively compare different classification results, and we obtain insights
on which magnetospheric variables make more effective features for unsupervised
classification.

    

### [[2109.04925] Rapid Model Architecture Adaption for Meta-Learning](http://arxiv.org/abs/2109.04925)


  Network Architecture Search (NAS) methods have recently gathered much
attention. They design networks with better performance and use a much shorter
search time compared to traditional manual tuning. Despite their efficiency in
model deployments, most NAS algorithms target a single task on a fixed hardware
system. However, real-life few-shot learning environments often cover a great
number of tasks (T ) and deployments on a wide variety of hardware platforms (H
).
The combinatorial search complexity T times H creates a fundamental search
efficiency challenge if one naively applies existing NAS methods to these
scenarios. To overcome this issue, we show, for the first time, how to rapidly
adapt model architectures to new tasks in a many-task many-hardware few-shot
learning setup by integrating Model Agnostic Meta Learning (MAML) into the NAS
flow. The proposed NAS method (H-Meta-NAS) is hardware-aware and performs
optimisation in the MAML framework. H-Meta-NAS shows a Pareto dominance
compared to a variety of NAS and manual baselines in popular few-shot learning
benchmarks with various hardware platforms and constraints. In particular, on
the 5-way 1-shot Mini-ImageNet classification task, the proposed method
outperforms the best manual baseline by a large margin (5.21% in accuracy)
using 60% less computation.

    

### [[2109.04941] Best-Arm Identification in Correlated Multi-Armed Bandits](http://arxiv.org/abs/2109.04941)


  In this paper we consider the problem of best-arm identification in
multi-armed bandits in the fixed confidence setting, where the goal is to
identify, with probability $1-\delta$ for some $\delta>0$, the arm with the
highest mean reward in minimum possible samples from the set of arms
$\mathcal{K}$. Most existing best-arm identification algorithms and analyses
operate under the assumption that the rewards corresponding to different arms
are independent of each other. We propose a novel correlated bandit framework
that captures domain knowledge about correlation between arms in the form of
upper bounds on expected conditional reward of an arm, given a reward
realization from another arm. Our proposed algorithm C-LUCB, which generalizes
the LUCB algorithm utilizes this partial knowledge of correlations to sharply
reduce the sample complexity of best-arm identification. More interestingly, we
show that the total samples obtained by C-LUCB are of the form
$\mathcal{O}\left(\sum_{k \in \mathcal{C}}
\log\left(\frac{1}{\delta}\right)\right)$ as opposed to the typical
$\mathcal{O}\left(\sum_{k \in \mathcal{K}}
\log\left(\frac{1}{\delta}\right)\right)$ samples required in the independent
reward setting. The improvement comes, as the $\mathcal{O}(\log(1/\delta))$
term is summed only for the set of competitive arms $\mathcal{C}$, which is a
subset of the original set of arms $\mathcal{K}$. The size of the set
$\mathcal{C}$, depending on the problem setting, can be as small as $2$, and
hence using C-LUCB in the correlated bandits setting can lead to significant
performance improvements. Our theoretical findings are supported by experiments
on the Movielens and Goodreads recommendation datasets.

    

### [[2109.04953] Does Pretraining for Summarization Require Knowledge Transfer?](http://arxiv.org/abs/2109.04953)


  Pretraining techniques leveraging enormous datasets have driven recent
advances in text summarization. While folk explanations suggest that knowledge
transfer accounts for pretraining's benefits, little is known about why it
works or what makes a pretraining task or dataset suitable. In this paper, we
challenge the knowledge transfer story, showing that pretraining on documents
consisting of character n-grams selected at random, we can nearly match the
performance of models pretrained on real corpora. This work holds the promise
of eliminating upstream corpora, which may alleviate some concerns over
offensive language, bias, and copyright issues. To see whether the small
residual benefit of using real data could be accounted for by the structure of
the pretraining task, we design several tasks motivated by a qualitative study
of summarization corpora. However, these tasks confer no appreciable benefit,
leaving open the possibility of a small role for knowledge transfer.

    

### [[2109.04954] Saliency Guided Experience Packing for Replay in Continual Learning](http://arxiv.org/abs/2109.04954)


  Artificial learning systems aspire to mimic human intelligence by continually
learning from a stream of tasks without forgetting past knowledge. One way to
enable such learning is to store past experiences in the form of input examples
in episodic memory and replay them when learning new tasks. However,
performance of such method suffers as the size of the memory becomes smaller.
In this paper, we propose a new approach for experience replay, where we select
the past experiences by looking at the saliency maps which provide visual
explanations for the model's decision. Guided by these saliency maps, we pack
the memory with only the parts or patches of the input images important for the
model's prediction. While learning a new task, we replay these memory patches
with appropriate zero-padding to remind the model about its past decisions. We
evaluate our algorithm on diverse image classification datasets and report
better performance than the state-of-the-art approaches. With qualitative and
quantitative analyses we show that our method captures richer summary of past
experiences without any memory increase, and hence performs well with small
episodic memory.

    

### [[2109.04975] Citizen centric optimal electric vehicle charging stations locations in a full city: case of Malaga](http://arxiv.org/abs/2109.04975)


  This article presents the problem of locating electric vehicle (EV) charging
stations in a city by defining the Electric Vehicle Charging Stations Locations
(EV-CSL) problem. The idea is to minimize the distance the citizens have to
travel to charge their vehicles. EV-CSL takes into account the maximum number
of charging stations to install and the electric power requirements. Two
metaheuristics are applied to address the relying optimization problem: a
genetic algorithm (GA) and a variable neighborhood search (VNS). The
experimental analysis over a realistic scenario of Malaga city, Spain, shows
that the metaheuristics are able to find competitive solutions which
dramatically improve the actual installation of the stations in Malaga. GA
provided statistically the best results.

    

### [[2109.04979] A Study of Joint Graph Inference and Forecasting](http://arxiv.org/abs/2109.04979)


  We study a recent class of models which uses graph neural networks (GNNs) to
improve forecasting in multivariate time series.
The core assumption behind these models is that there is a latent graph
between the time series (nodes) that governs the evolution of the multivariate
time series.
By parameterizing a graph in a differentiable way, the models aim to improve
forecasting quality.
We compare four recent models of this class on the forecasting task. Further,
we perform ablations to study their behavior under changing conditions, e.g.,
when disabling the graph-learning modules and providing the ground-truth
relations instead. Based on our findings, we propose novel ways of combining
the existing architectures.

    

### [[2109.04983] A Neural Tangent Kernel Perspective of Infinite Tree Ensembles](http://arxiv.org/abs/2109.04983)


  In practical situations, the ensemble tree model is one of the most popular
models along with neural networks. A soft tree is one of the variants of a
decision tree. Instead of using a greedy method for searching splitting rules,
the soft tree is trained using a gradient method in which the whole splitting
operation is formulated in a differentiable form. Although ensembles of such
soft trees have been increasingly used in recent years, little theoretical work
has been done for understanding their behavior. In this paper, by considering
an ensemble of infinite soft trees, we introduce and study the Tree Neural
Tangent Kernel (TNTK), which provides new insights into the behavior of the
infinite ensemble of soft trees. Using the TNTK, we succeed in theoretically
finding several non-trivial properties, such as the effect of the oblivious
tree structure and the degeneracy of the TNTK induced by the deepening of the
trees. Moreover, we empirically examine the performance of an ensemble of
infinite soft trees using the TNTK.

    

### [[2109.04986] Multi-agent deep reinforcement learning (MADRL) meets multi-user MIMO systems](http://arxiv.org/abs/2109.04986)


  A multi-agent deep reinforcement learning (MADRL) is a promising approach to
challenging problems in wireless environments involving multiple
decision-makers (or actors) with high-dimensional continuous action space. In
this paper, we present a MADRL-based approach that can jointly optimize
precoders to achieve the outer-boundary, called pareto-boundary, of the
achievable rate region for a multiple-input single-output (MISO) interference
channel (IFC). In order to address two main challenges, namely, multiple actors
(or agents) with partial observability and multi-dimensional continuous action
space in MISO IFC setup, we adopt a multi-agent deep deterministic policy
gradient (MA-DDPG) framework in which decentralized actors with partial
observability can learn a multi-dimensional continuous policy in a centralized
manner with the aid of shared critic with global information. Meanwhile, we
will also address a phase ambiguity issue with the conventional complex
baseband representation of signals widely used in radio communications. In
order to mitigate the impact of phase ambiguity on training performance, we
propose a training method, called phase ambiguity elimination (PAE), that leads
to faster learning and better performance of MA-DDPG in wireless communication
systems. The simulation results exhibit that MA-DDPG is capable of learning a
near-optimal precoding strategy in a MISO IFC environment. To the best of our
knowledge, this is the first work to demonstrate that the MA-DDPG framework can
jointly optimize precoders to achieve the pareto-boundary of achievable rate
region in a multi-cell multi-user multi-antenna system.

    

### [[2109.04990] Unsupervised Change Detection in Hyperspectral Images using Feature Fusion Deep Convolutional Autoencoders](http://arxiv.org/abs/2109.04990)


  Binary change detection in bi-temporal co-registered hyperspectral images is
a challenging task due to a large number of spectral bands present in the data.
Researchers, therefore, try to handle it by reducing dimensions. The proposed
work aims to build a novel feature extraction system using a feature fusion
deep convolutional autoencoder for detecting changes between a pair of such
bi-temporal co-registered hyperspectral images. The feature fusion considers
features across successive levels and multiple receptive fields and therefore
adds a competitive edge over the existing feature extraction methods. The
change detection technique described is completely unsupervised and is much
more elegant than other supervised or semi-supervised methods which require
some amount of label information. Different methods have been applied to the
extracted features to find the changes in the two images and it is found that
the proposed method clearly outperformed the state of the art methods in
unsupervised change detection for all the datasets.

    

### [[2109.04994] Topic-Aware Contrastive Learning for Abstractive Dialogue Summarization](http://arxiv.org/abs/2109.04994)


  Unlike well-structured text, such as news reports and encyclopedia articles,
dialogue content often comes from two or more interlocutors, exchanging
information with each other. In such a scenario, the topic of a conversation
can vary upon progression and the key information for a certain topic is often
scattered across multiple utterances of different speakers, which poses
challenges to abstractly summarize dialogues. To capture the various topic
information of a conversation and outline salient facts for the captured
topics, this work proposes two topic-aware contrastive learning objectives,
namely coherence detection and sub-summary generation objectives, which are
expected to implicitly model the topic change and handle information scattering
challenges for the dialogue summarization task. The proposed contrastive
objectives are framed as auxiliary tasks for the primary dialogue summarization
task, united via an alternative parameter updating strategy. Extensive
experiments on benchmark datasets demonstrate that the proposed simple method
significantly outperforms strong baselines and achieves new state-of-the-art
performance. The code and trained models are publicly available via
\href{this https URL}{this https URL}.

    

### [[2109.04997] Box Embeddings: An open-source library for representation learning using geometric structures](http://arxiv.org/abs/2109.04997)


  A major factor contributing to the success of modern representation learning
is the ease of performing various vector operations. Recently, objects with
geometric structures (eg. distributions, complex or hyperbolic vectors, or
regions such as cones, disks, or boxes) have been explored for their
alternative inductive biases and additional representational capacities. In
this work, we introduce Box Embeddings, a Python library that enables
researchers to easily apply and extend probabilistic box embeddings.

    

### [[2109.04999] Fairness without the sensitive attribute via Causal Variational Autoencoder](http://arxiv.org/abs/2109.04999)


  In recent years, most fairness strategies in machine learning models focus on
mitigating unwanted biases by assuming that the sensitive information is
observed. However this is not always possible in practice. Due to privacy
purposes and var-ious regulations such as RGPD in EU, many personal sensitive
attributes are frequently not collected. We notice a lack of approaches for
mitigating bias in such difficult settings, in particular for achieving
classical fairness objectives such as Demographic Parity and Equalized Odds. By
leveraging recent developments for approximate inference, we propose an
approach to fill this gap. Based on a causal graph, we rely on a new
variational auto-encoding based framework named SRCVAE to infer a sensitive
information proxy, that serve for bias mitigation in an adversarial fairness
approach. We empirically demonstrate significant improvements over existing
works in the field. We observe that the generated proxy's latent space recovers
sensitive information and that our approach achieves a higher accuracy while
obtaining the same level of fairness on two real datasets, as measured using
com-mon fairness definitions.

    

### [[2109.05000] Assessing the Quality of the Datasets by Identifying Mislabeled Samples](http://arxiv.org/abs/2109.05000)


  Due to the over-emphasize of the quantity of data, the data quality has often
been overlooked. However, not all training data points contribute equally to
learning. In particular, if mislabeled, it might actively damage the
performance of the model and the ability to generalize out of distribution, as
the model might end up learning spurious artifacts present in the dataset. This
problem gets compounded by the prevalence of heavily parameterized and complex
deep neural networks, which can, with their high capacity, end up memorizing
the noise present in the dataset. This paper proposes a novel statistic --
noise score, as a measure for the quality of each data point to identify such
mislabeled samples based on the variations in the latent space representation.
In our work, we use the representations derived by the inference network of
data quality supervised variational autoencoder (AQUAVS). Our method leverages
the fact that samples belonging to the same class will have similar latent
representations. Therefore, by identifying the outliers in the latent space, we
can find the mislabeled samples. We validate our proposed statistic through
experimentation by corrupting MNIST, FashionMNIST, and CIFAR10/100 datasets in
different noise settings for the task of identifying mislabelled samples. We
further show significant improvements in accuracy for the classification task
for each dataset.

    

### [[2109.05003] Distantly-Supervised Named Entity Recognition with Noise-Robust Learning and Language Model Augmented Self-Training](http://arxiv.org/abs/2109.05003)


  We study the problem of training named entity recognition (NER) models using
only distantly-labeled data, which can be automatically obtained by matching
entity mentions in the raw text with entity types in a knowledge base. The
biggest challenge of distantly-supervised NER is that the distant supervision
may induce incomplete and noisy labels, rendering the straightforward
application of supervised learning ineffective. In this paper, we propose (1) a
noise-robust learning scheme comprised of a new loss function and a noisy label
removal step, for training NER models on distantly-labeled data, and (2) a
self-training method that uses contextualized augmentations created by
pre-trained language models to improve the generalization ability of the NER
model. On three benchmark datasets, our method achieves superior performance,
outperforming existing distantly-supervised NER models by significant margins.

    

### [[2109.05013] PWPAE: An Ensemble Framework for Concept Drift Adaptation in IoT Data Streams](http://arxiv.org/abs/2109.05013)


  As the number of Internet of Things (IoT) devices and systems have surged,
IoT data analytics techniques have been developed to detect malicious
cyber-attacks and secure IoT systems; however, concept drift issues often occur
in IoT data analytics, as IoT data is often dynamic data streams that change
over time, causing model degradation and attack detection failure. This is
because traditional data analytics models are static models that cannot adapt
to data distribution changes. In this paper, we propose a Performance Weighted
Probability Averaging Ensemble (PWPAE) framework for drift adaptive IoT anomaly
detection through IoT data stream analytics. Experiments on two public datasets
show the effectiveness of our proposed PWPAE method compared against
state-of-the-art methods.

    

### [[2109.05019] Spike2Vec: An Efficient and Scalable Embedding Approach for COVID-19 Spike Sequences](http://arxiv.org/abs/2109.05019)


  With the rapid global spread of COVID-19, more and more data related to this
virus is becoming available, including genomic sequence data. The total number
of genomic sequences that are publicly available on platforms such as GISAID is
currently several million, and is increasing with every day. The availability
of such \textit{Big Data} creates a new opportunity for researchers to study
this virus in detail. This is particularly important with all of the dynamics
of the COVID-19 variants which emerge and circulate. This rich data source will
give us insights on the best ways to perform genomic surveillance for this and
future pandemic threats, with the ultimate goal of mitigating or eliminating
such threats. Analyzing and processing the several million genomic sequences is
a challenging task. Although traditional methods for sequence classification
are proven to be effective, they are not designed to deal with these specific
types of genomic sequences. Moreover, most of the existing methods also face
the issue of scalability. Previous studies which were tailored to coronavirus
genomic data proposed to use spike sequences (corresponding to a subsequence of
the genome), rather than using the complete genomic sequence, to perform
different machine learning (ML) tasks such as classification and clustering.
However, those methods suffer from scalability issues. In this paper, we
propose an approach called Spike2Vec, an efficient and scalable feature vector
representation for each spike sequence that can be used for downstream ML
tasks. Through experiments, we show that Spike2Vec is not only scalable on
several million spike sequences, but also outperforms the baseline models in
terms of prediction accuracy, F1-score, etc.

    

### [[1910.06002] Optimal Clustering from Noisy Binary Feedback](http://arxiv.org/abs/1910.06002)


  We study the problem of clustering a set of items from binary user feedback.
Such a problem arises in crowdsourcing platforms solving large-scale labeling
tasks with minimal effort put on the users. For example, in some of the recent
reCAPTCHA systems, users clicks (binary answers) can be used to efficiently
label images. In our inference problem, items are grouped into initially
unknown non-overlapping clusters. To recover these clusters, the learner
sequentially presents to users a finite list of items together with a question
with a binary answer selected from a fixed finite set. For each of these items,
the user provides a noisy answer whose expectation is determined by the item
cluster and the question and by an item-specific parameter characterizing the
{\it hardness} of classifying the item. The objective is to devise an algorithm
with a minimal cluster recovery error rate. We derive problem-specific
information-theoretical lower bounds on the error rate satisfied by any
algorithm, for both uniform and adaptive (list, question) selection strategies.
For uniform selection, we present a simple algorithm built upon the K-means
algorithm and whose performance almost matches the fundamental limits. For
adaptive selection, we develop an adaptive algorithm that is inspired by the
derivation of the information-theoretical error lower bounds, and in turn
allocates the budget in an efficient way. The algorithm learns to select items
hard to cluster and relevant questions more often. We compare the performance
of our algorithms with or without the adaptive selection strategy numerically
and illustrate the gain achieved by being adaptive.

    

### [[1911.00804] Generalizing to unseen domains via distribution matching](http://arxiv.org/abs/1911.00804)


  Supervised learning results typically rely on assumptions of i.i.d. data.
Unfortunately, those assumptions are commonly violated in practice. In this
work, we tackle such problem by focusing on domain generalization: a
formalization where the data generating process at test time may yield samples
from never-before-seen domains (distributions). Our work relies on the
following lemma: by minimizing a notion of discrepancy between all pairs from a
set of given domains, we also minimize the discrepancy between any pairs of
mixtures of domains. Using this result, we derive a generalization bound for
our setting. We then show that low risk over unseen domains can be achieved by
representing the data in a space where (i) the training distributions are
indistinguishable, and (ii) relevant information for the task at hand is
preserved. Minimizing the terms in our bound yields an adversarial formulation
which estimates and minimizes pairwise discrepancies. We validate our proposed
strategy on standard domain generalization benchmarks, outperforming a number
of recently introduced methods. Notably, we tackle a real-world application
where the underlying data corresponds to multi-channel electroencephalography
time series from different subjects, each considered as a distinct domain.

    

### [[1911.03959] Multi-Armed Bandits with Correlated Arms](http://arxiv.org/abs/1911.03959)


  We consider a multi-armed bandit framework where the rewards obtained by
pulling different arms are correlated. We develop a unified approach to
leverage these reward correlations and present fundamental generalizations of
classic bandit algorithms to the correlated setting. We present a unified proof
technique to analyze the proposed algorithms. Rigorous analysis of C-UCB (the
correlated bandit version of Upper-confidence-bound) reveals that the algorithm
ends up pulling certain sub-optimal arms, termed as non-competitive, only O(1)
times, as opposed to the O(log T) pulls required by classic bandit algorithms
such as UCB, TS etc. We present regret-lower bound and show that when arms are
correlated through a latent random source, our algorithms obtain order-optimal
regret. We validate the proposed algorithms via experiments on the MovieLens
and Goodreads datasets, and show significant improvement over classical bandit
algorithms.

    

### [[1912.04265] In Defense of Uniform Convergence: Generalization via derandomization with an application to interpolating predictors](http://arxiv.org/abs/1912.04265)


  We propose to study the generalization error of a learned predictor $\hat h$
in terms of that of a surrogate (potentially randomized) predictor that is
coupled to $\hat h$ and designed to trade empirical risk for control of
generalization error. In the case where $\hat h$ interpolates the data, it is
interesting to consider theoretical surrogate classifiers that are partially
derandomized or rerandomized, e.g., fit to the training data but with modified
label noise. We also show that replacing $\hat h$ by its conditional
distribution with respect to an arbitrary $\sigma$-field is a convenient way to
derandomize. We study two examples, inspired by the work of Nagarajan and
Kolter (2019) and Bartlett et al. (2019), where the learned classifier $\hat h$
interpolates the training data with high probability, has small risk, and, yet,
does not belong to a nonrandom class with a tight uniform bound on two-sided
generalization error. At the same time, we bound the risk of $\hat h$ in terms
of surrogates constructed by conditioning and denoising, respectively, and
shown to belong to nonrandom classes with uniformly small generalization error.

    

### [[2001.09532] Learning the Hypotheses Space from data: Learning Space and U-curve Property](http://arxiv.org/abs/2001.09532)


  This paper presents an extension of the classical agnostic PAC learning model
in which learning problems are modelled not only by a Hypothesis Space
$\mathcal{H}$, but also by a Learning Space $\mathbb{L}(\mathcal{H})$, which is
a cover of $\mathcal{H}$, constrained by a VC-dimension property, that is a
suitable domain for Model Selection algorithms. Our main contribution is a data
driven general learning algorithm to perform regularized Model Selection on
$\mathbb{L}(\mathcal{H})$. A remarkable, formally proved, consequence of this
approach are conditions on $\mathbb{L}(\mathcal{H})$ and on the loss function
that lead to estimated out-of-sample error surfaces which are true U-curves on
$\mathbb{L}(\mathcal{H})$ chains, enabling a more efficient search on
$\mathbb{L}(\mathcal{H})$. To our knowledge, this is the first rigorous result
asserting that a non exhaustive search of a family of candidate models can
return an optimal solution. In this new framework, an U-curve optimization
algorithm becomes a natural component of Model Selection, hence of learning
algorithms. The abstract general framework proposed here may have important
implications on modern learning models and on areas such as Neural Architecture
Search.

    

### [[2001.11107] Hamiltonian neural networks for solving equations of motion](http://arxiv.org/abs/2001.11107)


  There has been a wave of interest in applying machine learning to study
dynamical systems. In particular, neural networks have been applied to solve
the equations of motion, and therefore, track the evolution of a system. In
contrast to other applications of neural networks and machine learning,
dynamical systems possess invariants such as energy, momentum, and angular
momentum, depending on their underlying symmetries. Traditional numerical
integration methods sometimes violate these conservation laws, propagating
errors in time, ultimately reducing the predictability of the method. We
present a data-free Hamiltonian neural network that solves the differential
equations that govern dynamical systems. This is an equation-driven
unsupervised learning method where the optimization process of the network
depends solely on the predicted functions without using any ground truth data.
This unsupervised model learns solutions that satisfy identically, up to an
arbitrarily small error, Hamilton's equations and, therefore, conserve the
Hamiltonian invariants. Once the network is optimized, the proposed
architecture is considered a symplectic unit due to the introduction of an
efficient parametric form of solutions. In addition, the choice of an
appropriate activation function drastically improves the predictability of the
network. An error analysis is derived and states that the numerical errors
depend on the overall network performance. The symplectic architecture is then
employed to solve the equations for the nonlinear oscillator and the chaotic
Henon-Heiles dynamical system. In both systems, a symplectic Euler integrator
requires two orders more evaluation points than the Hamiltonian network in
order to achieve the same order of the numerical error in the predicted phase
space trajectories.

    

### [[2001.11578] Learning the Hypotheses Space from data Part II: Convergence and Feasibility](http://arxiv.org/abs/2001.11578)


  In part \textit{I} we proposed a structure for a general Hypotheses Space
$\mathcal{H}$, the Learning Space $\mathbb{L}(\mathcal{H})$, which can be
employed to avoid \textit{overfitting} when estimating in a complex space with
relative shortage of examples. Also, we presented the U-curve property, which
can be taken advantage of in order to select a Hypotheses Space without
exhaustively searching $\mathbb{L}(\mathcal{H})$. In this paper, we carry
further our agenda, by showing the consistency of a model selection framework
based on Learning Spaces, in which one selects from data the Hypotheses Space
on which to learn. The method developed in this paper adds to the
state-of-the-art in model selection, by extending Vapnik-Chervonenkis Theory to
\textit{random} Hypotheses Spaces, i.e., Hypotheses Spaces learned from data.
In this framework, one estimates a random subspace $\hat{\mathcal{M}} \in
\mathbb{L}(\mathcal{H})$ which converges with probability one to a target
Hypotheses Space $\mathcal{M}^{\star} \in \mathbb{L}(\mathcal{H})$ with desired
properties. As the convergence implies asymptotic unbiased estimators, we have
a consistent framework for model selection, showing that it is feasible to
learn the Hypotheses Space from data. Furthermore, we show that the
generalization errors of learning on $\hat{\mathcal{M}}$ are lesser than those
we commit when learning on $\mathcal{H}$, so it is more efficient to learn on a
subspace learned from data.

    

### [[2002.05809] Variational Conditional Dependence Hidden Markov Models for Skeleton-Based Action Recognition](http://arxiv.org/abs/2002.05809)


  Hidden Markov Models (HMMs) comprise a powerful generative approach for
modeling sequential data and time-series in general. However, the commonly
employed assumption of the dependence of the current time frame to a single or
multiple immediately preceding frames is unrealistic; more complicated dynamics
potentially exist in real world scenarios. This paper revisits conventional
sequential modeling approaches, aiming to address the problem of capturing
time-varying temporal dependency patterns. To this end, we propose a different
formulation of HMMs, whereby the dependence on past frames is dynamically
inferred from the data. Specifically, we introduce a hierarchical extension by
postulating an additional latent variable layer; therein, the (time-varying)
temporal dependence patterns are treated as latent variables over which
inference is performed. We leverage solid arguments from the Variational Bayes
framework and derive a tractable inference algorithm based on the
forward-backward algorithm. As we experimentally show, our approach can model
highly complex sequential data and can effectively handle data with missing
values.

    

### [[2005.00218] Differentially Private Federated Learning with Laplacian Smoothing](http://arxiv.org/abs/2005.00218)


  Federated learning aims to protect data privacy by collaboratively learning a
model without sharing private data among users. However, an adversary may still
be able to infer the private training data by attacking the released model.
Differential privacy provides a statistical protection against such attacks at
the price of significantly degrading the accuracy or utility of the trained
models. In this paper, we investigate a utility enhancement scheme based on
Laplacian smoothing for differentially private federated learning (DP-Fed-LS),
where the parameter aggregation with injected Gaussian noise is improved in
statistical precision without losing privacy budget. Our key observation is
that the aggregated gradients in federated learning often enjoy a type of
smoothness, i.e. sparsity in the graph Fourier basis with polynomial decays of
Fourier coefficients as frequency grows, which can be exploited by the
Laplacian smoothing efficiently. Under a prescribed differential privacy
budget, convergence error bounds with tight rates are provided for DP-Fed-LS
with uniform subsampling of heterogeneous Non-IID data, revealing possible
utility improvement of Laplacian smoothing in effective dimensionality and
variance reduction, among others. Experiments over MNIST, SVHN, and Shakespeare
datasets show that the proposed method can improve model accuracy with
DP-guarantee and membership privacy under both uniform and Poisson subsampling
mechanisms.

    

### [[2006.03495] A conditional one-output likelihood formulation for multitask Gaussian processes](http://arxiv.org/abs/2006.03495)


  Multitask Gaussian processes (MTGP) are the Gaussian process (GP) framework's
solution for multioutput regression problems in which the $T$ elements of the
regressors cannot be considered conditionally independent given the
observations. Standard MTGP models assume that there exist both a multitask
covariance matrix as a function of an intertask matrix, and a noise covariance
matrix. These matrices need to be approximated by a low rank simplification of
order $P$ in order to reduce the number of parameters to be learnt from $T^2$
to $TP$. Here we introduce a novel approach that simplifies the multitask
learning by reducing it to a set of conditioned univariate GPs without the need
for any low rank approximations, therefore completely eliminating the
requirement to select an adequate value for hyperparameter $P$. At the same
time, by extending this approach with both a hierarchical and an approximate
model, the proposed extensions are capable of recovering the multitask
covariance and noise matrices after learning only $2T$ parameters, avoiding the
validation of any model hyperparameter and reducing the overall complexity of
the model as well as the risk of overfitting. Experimental results over
synthetic and real problems confirm the advantages of this inference approach
in its ability to accurately recover the original noise and signal matrices, as
well as the achieved performance improvement in comparison to other state of
art MTGP approaches. We have also integrated the model with standard GP
toolboxes, showing that it is computationally competitive with state of the art
options.

    

### [[2006.05500] Foreseeing the Benefits of Incidental Supervision](http://arxiv.org/abs/2006.05500)


  Real-world applications often require improved models by leveraging a range
of cheap incidental supervision signals. These could include partial labels,
noisy labels, knowledge-based constraints, and cross-domain or cross-task
annotations -- all having statistical associations with gold annotations but
not exactly the same. However, we currently lack a principled way to measure
the benefits of these signals to a given target task, and the common practice
of evaluating these benefits is through exhaustive experiments with various
models and hyperparameters. This paper studies whether we can, in a single
framework, quantify the benefits of various types of incidental signals for a
given target task without going through combinatorial experiments. We propose a
unified PAC-Bayesian motivated informativeness measure, PABI, that
characterizes the uncertainty reduction provided by incidental supervision
signals. We demonstrate PABI's effectiveness by quantifying the value added by
various types of incidental signals to sequence tagging tasks. Experiments on
named entity recognition (NER) and question answering (QA) show that PABI's
predictions correlate well with learning performance, providing a promising way
to determine, ahead of learning, which supervision signals would be beneficial.

    

### [[2006.07265] Towards control of opinion diversity by introducing zealots into a polarised social group](http://arxiv.org/abs/2006.07265)


  We explore a method to influence or even control the diversity of opinions
within a polarised social group. We leverage the voter model in which users
hold binary opinions and repeatedly update their beliefs based on others they
connect with. Stubborn agents who never change their minds ("zealots") are also
disseminated through the network, which is modelled by a connected graph.
Building on earlier results, we provide a closed-form expression for the
average opinion of the group at equilibrium. This leads us to a strategy to
inject zealots into a polarised network in order to shift the average opinion
towards any target value. We account for the possible presence of a backfire
effect, which may lead the group to react negatively and reinforce its level of
polarisation in response. Our results are supported by numerical experiments on
synthetic data.

    

### [[2006.16144] Estimates on the generalization error of Physics Informed Neural Networks (PINNs) for approximating PDEs](http://arxiv.org/abs/2006.16144)


  Physics informed neural networks (PINNs) have recently been widely used for
robust and accurate approximation of PDEs. We provide rigorous upper bounds on
the generalization error of PINNs approximating solutions of the forward
problem for PDEs. An abstract formalism is introduced and stability properties
of the underlying PDE are leveraged to derive an estimate for the
generalization error in terms of the training error and number of training
samples. This abstract framework is illustrated with several examples of
nonlinear PDEs. Numerical experiments, validating the proposed theory, are also
presented.

    

### [[2010.02501] A Unifying View on Implicit Bias in Training Linear Neural Networks](http://arxiv.org/abs/2010.02501)


  We study the implicit bias of gradient flow (i.e., gradient descent with
infinitesimal step size) on linear neural network training. We propose a tensor
formulation of neural networks that includes fully-connected, diagonal, and
convolutional networks as special cases, and investigate the linear version of
the formulation called linear tensor networks. With this formulation, we can
characterize the convergence direction of the network parameters as singular
vectors of a tensor defined by the network. For $L$-layer linear tensor
networks that are orthogonally decomposable, we show that gradient flow on
separable classification finds a stationary point of the $\ell_{2/L}$
max-margin problem in a "transformed" input space defined by the network. For
underdetermined regression, we prove that gradient flow finds a global minimum
which minimizes a norm-like function that interpolates between weighted
$\ell_1$ and $\ell_2$ norms in the transformed input space. Our theorems
subsume existing results in the literature while removing standard convergence
assumptions. We also provide experiments that corroborate our analysis.

    

### [[2010.03258] Global Optimization of Objective Functions Represented by ReLU Networks](http://arxiv.org/abs/2010.03258)


  Neural networks can learn complex, non-convex functions, and it is
challenging to guarantee their correct behavior in safety-critical contexts.
Many approaches exist to find failures in networks (e.g., adversarial
examples), but these cannot guarantee the absence of failures. Verification
algorithms address this need and provide formal guarantees about a neural
network by answering "yes or no" questions. For example, they can answer
whether a violation exists within certain bounds. However, individual "yes or
no" questions cannot answer qualitative questions such as "what is the largest
error within these bounds"; the answers to these lie in the domain of
optimization. Therefore, we propose strategies to extend existing verifiers to
perform optimization and find: (i) the most extreme failure in a given input
region and (ii) the minimum input perturbation required to cause a failure. A
naive approach using a bisection search with an off-the-shelf verifier results
in many expensive and overlapping calls to the verifier. Instead, we propose an
approach that tightly integrates the optimization process into the verification
procedure, achieving better runtime performance than the naive approach. We
evaluate our approach implemented as an extension of Marabou, a
state-of-the-art neural network verifier, and compare its performance with the
bisection approach and MIPVerify, an optimization-based verifier. We observe
complementary performance between our extension of Marabou and MIPVerify.

    

### [[2010.06127] Model Selection for Cross-Lingual Transfer](http://arxiv.org/abs/2010.06127)


  Transformers that are pre-trained on multilingual corpora, such as, mBERT and
XLM-RoBERTa, have achieved impressive cross-lingual transfer capabilities. In
the zero-shot transfer setting, only English training data is used, and the
fine-tuned model is evaluated on another target language. While this works
surprisingly well, substantial variance has been observed in target language
performance between different fine-tuning runs, and in the zero-shot setup, no
target-language development data is available to select among multiple
fine-tuned models. Prior work has relied on English dev data to select among
models that are fine-tuned with different learning rates, number of steps and
other hyperparameters, often resulting in suboptimal choices. In this paper, we
show that it is possible to select consistently better models when small
amounts of annotated data are available in auxiliary pivot languages. We
propose a machine learning approach to model selection that uses the fine-tuned
model's own internal representations to predict its cross-lingual capabilities.
In extensive experiments we find that this method consistently selects better
models than English validation data across twenty five languages (including
eight low-resource languages), and often achieves results that are comparable
to model selection using target language development data.

    

### [[2010.09697] Effects of Parameter Norm Growth During Transformer Training: Inductive Bias from Gradient Descent](http://arxiv.org/abs/2010.09697)


  The capacity of neural networks like the widely adopted transformer is known
to be very high. Evidence is emerging that they learn successfully due to
inductive bias in the training routine, typically a variant of gradient descent
(GD). To better understand this bias, we study the tendency for transformer
parameters to grow in magnitude ($\ell_2$ norm) during training, and its
implications for the emergent representations within self attention layers.
Empirically, we document norm growth in the training of transformer language
models, including T5 during its pretraining. As the parameters grow in
magnitude, we prove that the network approximates a discretized network with
saturated activation functions. Such "saturated" networks are known to have a
reduced capacity compared to the full network family that can be described in
terms of formal languages and automata. Our results suggest saturation is a new
characterization of an inductive bias implicit in GD of particular interest for
NLP. We leverage the emergent discrete structure in a saturated transformer to
analyze the role of different attention heads, finding that some focus locally
on a small number of positions, while other heads compute global averages,
allowing counting. We believe understanding the interplay between these two
capabilities may shed further light on the structure of computation within
large transformers.

    

### [[2010.15413] Measuring and Harnessing Transference in Multi-Task Learning](http://arxiv.org/abs/2010.15413)


  Multi-task learning can leverage information learned by one task to benefit
the training of other tasks. Despite this capacity, naive formulations often
degrade performance and in particular, identifying the tasks that would benefit
from co-training remains a challenging design question. In this paper, we
analyze the dynamics of information transfer, or transference, across tasks
throughout training. Specifically, we develop a similarity measure that can
quantify transference among tasks and use this quantity to both better
understand the optimization dynamics of multi-task learning as well as improve
overall learning performance. In the latter case, we propose two methods to
leverage our transference metric. The first operates at a macro-level by
selecting which tasks should train together while the second functions at a
micro-level by determining how to combine task gradients at each training step.
We find these methods can lead to significant improvement over prior work on
three supervised multi-task learning benchmarks and one multi-task
reinforcement learning paradigm.

    

### [[2010.16410] Semi-supervised Relation Extraction via Incremental Meta Self-Training](http://arxiv.org/abs/2010.16410)


  To alleviate human efforts from obtaining large-scale annotations,
Semi-Supervised Relation Extraction methods aim to leverage unlabeled data in
addition to learning from limited samples. Existing self-training methods
suffer from the gradual drift problem, where noisy pseudo labels on unlabeled
data are incorporated during training. To alleviate the noise in pseudo labels,
we propose a method called MetaSRE, where a Relation Label Generation Network
generates quality assessment on pseudo labels by (meta) learning from the
successful and failed attempts on Relation Classification Network as an
additional meta-objective. To reduce the influence of noisy pseudo labels,
MetaSRE adopts a pseudo label selection and exploitation scheme which assesses
pseudo label quality on unlabeled samples and only exploits high-quality pseudo
labels in a self-training fashion to incrementally augment labeled samples for
both robustness and accuracy. Experimental results on two public datasets
demonstrate the effectiveness of the proposed approach.

    

### [[2011.07497] NegatER: Unsupervised Discovery of Negatives in Commonsense Knowledge Bases](http://arxiv.org/abs/2011.07497)


  Codifying commonsense knowledge in machines is a longstanding goal of
artificial intelligence. Recently, much progress toward this goal has been made
with automatic knowledge base (KB) construction techniques. However, such
techniques focus primarily on the acquisition of positive (true) KB statements,
even though negative (false) statements are often also important for
discriminative reasoning over commonsense KBs. As a first step toward the
latter, this paper proposes NegatER, a framework that ranks potential negatives
in commonsense KBs using a contextual language model (LM). Importantly, as most
KBs do not contain negatives, NegatER relies only on the positive knowledge in
the LM and does not require ground-truth negative examples. Experiments
demonstrate that, compared to multiple contrastive data augmentation
approaches, NegatER yields negatives that are more grammatical, coherent, and
informative -- leading to statistically significant accuracy improvements in a
challenging KB completion task and confirming that the positive knowledge in
LMs can be "re-purposed" to generate negative knowledge.

    

### [[2012.05649] Concept Generalization in Visual Representation Learning](http://arxiv.org/abs/2012.05649)


  Measuring concept generalization, i.e., the extent to which models trained on
a set of (seen) visual concepts can be leveraged to recognize a new set of
(unseen) concepts, is a popular way of evaluating visual representations,
especially in a self-supervised learning framework. Nonetheless, the choice of
unseen concepts for such an evaluation is usually made arbitrarily, and
independently from the seen concepts used to train representations, thus
ignoring any semantic relationships between the two. In this paper, we argue
that the semantic relationships between seen and unseen concepts affect
generalization performance and propose ImageNet-CoG, a novel benchmark on the
ImageNet-21K (IN-21K) dataset that enables measuring concept generalization in
a principled way. Our benchmark leverages expert knowledge that comes from
WordNet in order to define a sequence of unseen IN-21K concept sets that are
semantically more and more distant from the ImageNet-1K (IN-1K) subset, a
ubiquitous training set. This allows us to benchmark visual representations
learned on IN-1K out-of-the box. We conduct a large-scale study encompassing 31
convolution and transformer-based models and show how different architectures,
levels of supervision, regularization techniques and use of web data impact the
concept generalization performance.

    

### [[2012.15781] FastIF: Scalable Influence Functions for Efficient Model Interpretation and Debugging](http://arxiv.org/abs/2012.15781)


  Influence functions approximate the "influences" of training data-points for
test predictions and have a wide variety of applications. Despite the
popularity, their computational cost does not scale well with model and
training data size. We present FastIF, a set of simple modifications to
influence functions that significantly improves their run-time. We use
k-Nearest Neighbors (kNN) to narrow the search space down to a subset of good
candidate data points, identify the configurations that best balance the
speed-quality trade-off in estimating the inverse Hessian-vector product, and
introduce a fast parallel variant. Our proposed method achieves about 80X
speedup while being highly correlated with the original influence values. With
the availability of the fast influence functions, we demonstrate their
usefulness in four applications. First, we examine whether influential
data-points can "explain" test time behavior using the framework of
simulatability. Second, we visualize the influence interactions between
training and test data-points. Third, we show that we can correct model errors
by additional fine-tuning on certain influential data-points, improving the
accuracy of a trained MultiNLI model by 2.5% on the HANS dataset. Finally, we
experiment with a similar setup but fine-tuning on datapoints not seen during
training, improving the model accuracy by 2.8% and 1.7% on HANS and ANLI
datasets respectively. Overall, our fast influence functions can be efficiently
applied to large models and datasets, and our experiments demonstrate the
potential of influence functions in model interpretation and correcting model
errors. Code is available at
this https URL


### [[2102.01733] FedProf: Selective Federated Learning with Representation Profiling](http://arxiv.org/abs/2102.01733)


  Federated Learning (FL) has shown great potential as a privacy-preserving
solution to learning from decentralized data that are only accessible to end
devices (i.e., clients). In many scenarios however, a large proportion of the
clients are probably in possession of low-quality data that are biased, noisy
or even irrelevant. As a result, they could significantly slow down the
convergence of the global model we aim to build and also compromise its
quality. In light of this, we propose FedProf, a novel algorithm for optimizing
FL under such circumstances without breaching data privacy. The key of our
approach is a data representation profiling and matching scheme that uses the
global model to dynamically profile data representations and allows for
low-cost, lightweight representation matching. Based on the scheme we
adaptively score each client and adjust its participation probability so as to
mitigate the impact of low-value clients on the training process. We have
conducted extensive experiments on public datasets using various FL settings.
The results show that FedProf effectively reduces the number of communication
rounds and overall time (up to 4.5x speedup) for the global model to converge
and provides accuracy gain.

    

### [[2102.02618] Optimised one-class classification performance](http://arxiv.org/abs/2102.02618)


  We provide a thorough treatment of one-class classification with
hyperparameter optimisation for five data descriptors: Support Vector Machine
(SVM), Nearest Neighbour Distance (NND), Localised Nearest Neighbour Distance
(LNND), Local Outlier Factor (LOF) and Average Localised Proximity (ALP). The
hyperparameters of SVM and LOF have to be optimised through cross-validation,
while NND, LNND and ALP allow an efficient form of leave-one-out validation and
the reuse of a single nearest-neighbour query. We experimentally evaluate the
effect of hyperparameter optimisation with 246 classification problems drawn
from 50 datasets. From a selection of optimisation algorithms, the recent
Malherbe-Powell proposal optimises the hyperparameters of all data descriptors
most efficiently. We calculate the increase in test AUROC and the amount of
overfitting as a function of the number of hyperparameter evaluations. After 50
evaluations, ALP and SVM significantly outperform LOF, NND and LNND, and LOF
and NND outperform LNND. The performance of ALP and SVM is comparable, but ALP
can be optimised more efficiently so constitutes a good default choice.
Alternatively, using validation AUROC as a selection criterion between ALP or
SVM gives the best overall result, and NND is the least computationally
demanding option. We thus end up with a clear trade-off between three choices,
allowing practitioners to make an informed decision.

    

### [[2102.03973] Solid Texture Synthesis using Generative Adversarial Networks](http://arxiv.org/abs/2102.03973)


  Solid texture synthesis (STS), as an effective way to extend 2D exemplar to a
3D solid volume, exhibits advantages in numerous application domains. However,
existing methods generally synthesize solid texture with specific features,
which may result in the failure of capturing diversified textural information.
In this paper, we propose a novel generative adversarial nets-based approach
(STS-GAN) to hierarchically learn solid texture with a feature-free nature. Our
multi-scale discriminators evaluate the similarity between patch from exemplar
and slice from the generated volume, promoting the generator to synthesize
realistic solid textures. Experimental results demonstrate that the proposed
method can generate high-quality solid textures with similar visual
characteristics to the exemplar.

    

### [[2102.09206] Less is More: Pre-training a Strong Siamese Encoder Using a Weak Decoder](http://arxiv.org/abs/2102.09206)


  Dense retrieval requires high-quality text sequence embeddings to support
effective search in the representation space. Autoencoder-based language models
are appealing in dense retrieval as they train the encoder to output
high-quality embedding that can reconstruct the input texts. However, in this
paper, we provide theoretical analyses and show empirically that an autoencoder
language model with a low reconstruction loss may not provide good sequence
representations because the decoder may take shortcuts by exploiting language
patterns. To address this, we propose a new self-learning method that
pre-trains the autoencoder using a \textit{weak} decoder, with restricted
capacity and attention flexibility to push the encoder to provide better text
representations. Our experiments on web search, news recommendation, and open
domain question answering show that our pre-trained model significantly boosts
the effectiveness and few-shot ability of dense retrieval models. Our code is
available at this https URL.

    

### [[2102.11861] Generative Modelling of BRDF Textures from Flash Images](http://arxiv.org/abs/2102.11861)


  We learn a latent space for easy capture, consistent interpolation, and
efficient reproduction of visual material appearance. When users provide a
photo of a stationary natural material captured under flashlight illumination,
first it is converted into a latent material code. Then, in the second step,
conditioned on the material code, our method produces an infinite and diverse
spatial field of BRDF model parameters (diffuse albedo, normals, roughness,
specular albedo) that subsequently allows rendering in complex scenes and
illuminations, matching the appearance of the input photograph. Technically, we
jointly embed all flash images into a latent space using a convolutional
encoder, and -- conditioned on these latent codes -- convert random spatial
fields into fields of BRDF parameters using a convolutional neural network
(CNN). We condition these BRDF parameters to match the visual characteristics
(statistics and spectra of visual features) of the input under matching light.
A user study compares our approach favorably to previous work, even those with
access to BRDF supervision.

    

### [[2102.13605] ECO: Enabling Energy-Neutral IoT Devices through Runtime Allocation of Harvested Energy](http://arxiv.org/abs/2102.13605)


  Energy harvesting offers an attractive and promising mechanism to power
low-energy devices. However, it alone is insufficient to enable an
energy-neutral operation, which can eliminate tedious battery charging and
replacement requirements. Achieving an energy-neutral operation is challenging
since the uncertainties in harvested energy undermine the quality of service
requirements. To address this challenge, we present a runtime energy-allocation
framework that optimizes the utility of the target device under energy
constraints using a rollout algorithm, which is a sequential approach to solve
dynamic optimization problems. The proposed framework uses an efficient
iterative algorithm to compute initial energy allocations at the beginning of a
day. The initial allocations are then corrected at every interval to compensate
for the deviations from the expected energy harvesting pattern. We evaluate
this framework using solar and motion energy harvesting modalities and American
Time Use Survey data from 4772 different users. Compared to prior techniques,
the proposed framework achieves up to 35% higher utility even under
energy-limited scenarios. Moreover, measurements on a wearable device prototype
show that the proposed framework has 1000x smaller energy overhead than
iterative approaches with a negligible loss in utility.

    

### [[2103.01378] Contrastive Explanations for Model Interpretability](http://arxiv.org/abs/2103.01378)


  Contrastive explanations clarify why an event occurred in contrast to
another. They are more inherently intuitive to humans to both produce and
comprehend. We propose a methodology to produce contrastive explanations for
classification models by modifying the representation to disregard
non-contrastive information, and modifying model behavior to only be based on
contrastive reasoning. Our method is based on projecting model representation
to a latent space that captures only the features that are useful (to the
model) to differentiate two potential decisions. We demonstrate the value of
contrastive explanations by analyzing two different scenarios, using both
high-level abstract concept attribution and low-level input token/span
attribution, on two widely used text classification tasks. Specifically, we
produce explanations for answering: for which label, and against which
alternative label, is some aspect of the input useful? And which aspects of the
input are useful for and against particular decisions? Overall, our findings
shed light on the ability of label-contrastive explanations to provide a more
accurate and finer-grained interpretability of a model's decision.

    

### [[2103.08713] Multi-task learning for virtual flow metering](http://arxiv.org/abs/2103.08713)


  Virtual flow metering (VFM) is a cost-effective and non-intrusive technology
for inferring multiphase flow rates in petroleum assets. Inferences about flow
rates are fundamental to decision support systems that operators extensively
rely on. Data-driven VFM, where mechanistic models are replaced with machine
learning models, has recently gained attention due to its promise of lower
maintenance costs. While excellent performances in small sample studies have
been reported in the literature, there is still considerable doubt about the
robustness of data-driven VFM. In this paper, we propose a new multi-task
learning (MTL) architecture for data-driven VFM. Our method differs from
previous methods in that it enables learning across oil and gas wells. We study
the method by modeling 55 wells from four petroleum assets and compare the
results with two single-task baseline models. Our findings show that MTL
improves robustness over single-task methods, without sacrificing performance.
MTL yields a 25-50% error reduction on average for the assets where single-task
architectures are struggling.

    

### [[2104.05094] Constructing Contrastive samples via Summarization for Text Classification with limited annotations](http://arxiv.org/abs/2104.05094)


  Contrastive Learning has emerged as a powerful representation learning method
and facilitates various downstream tasks especially when supervised data is
limited. How to construct efficient contrastive samples through data
augmentation is key to its success. Unlike vision tasks, the data augmentation
method for contrastive learning has not been investigated sufficiently in
language tasks. In this paper, we propose a novel approach to construct
contrastive samples for language tasks using text summarization. We use these
samples for supervised contrastive learning to gain better text representations
which greatly benefit text classification tasks with limited annotations. To
further improve the method, we mix up samples from different classes and add an
extra regularization, named Mixsum, in addition to the cross-entropy-loss.
Experiments on real-world text classification datasets (Amazon-5, Yelp-5, AG
News, and IMDb) demonstrate the effectiveness of the proposed contrastive
learning framework with summarization-based data augmentation and Mixsum
regularization.

    

### [[2104.05837] Relational World Knowledge Representation in Contextual Language Models: A Review](http://arxiv.org/abs/2104.05837)


  Relational knowledge bases (KBs) are commonly used to represent world
knowledge in machines. However, while advantageous for their high degree of
precision and interpretability, KBs are usually organized according to
manually-defined schemas, which limit their expressiveness and require
significant human efforts to engineer and maintain. In this review, we take a
natural language processing perspective to these limitations, examining how
they may be addressed in part by training deep contextual language models (LMs)
to internalize and express relational knowledge in more flexible forms. We
propose to organize knowledge representation strategies in LMs by the level of
KB supervision provided, from no KB supervision at all to entity- and
relation-level supervision. Our contributions are threefold: (1) We provide a
high-level, extensible taxonomy for knowledge representation in LMs; (2) Within
our taxonomy, we highlight notable models, evaluation tasks, and findings, in
order to provide an up-to-date review of current knowledge representation
capabilities in LMs; and (3) We suggest future research directions that build
upon the complementary aspects of LMs and KBs as knowledge representations.

    

### [[2104.05845] Visual Goal-Step Inference using wikiHow](http://arxiv.org/abs/2104.05845)


  Understanding what sequence of steps are needed to complete a goal can help
artificial intelligence systems reason about human activities. Past work in NLP
has examined the task of goal-step inference for text. We introduce the visual
analogue. We propose the Visual Goal-Step Inference (VGSI) task, where a model
is given a textual goal and must choose which of four images represents a
plausible step towards that goal. With a new dataset harvested from wikiHow
consisting of 772,277 images representing human actions, we show that our task
is challenging for state-of-the-art multimodal models. Moreover, the multimodal
representation learned from our data can be effectively transferred to other
datasets like HowTo100m, increasing the VGSI accuracy by 15 - 20%. Our task
will facilitate multimodal reasoning about procedural events.

    

### [[2104.06022] Lessons on Parameter Sharing across Layers in Transformers](http://arxiv.org/abs/2104.06022)


  We propose a parameter sharing method for Transformers (Vaswani et al.,
2017). The proposed approach relaxes a widely used technique, which shares
parameters for one layer with all layers such as Universal Transformers
(Dehghani et al., 2019), to increase the efficiency in the computational time.
We propose three strategies: Sequence, Cycle, and Cycle (rev) to assign
parameters to each layer. Experimental results show that the proposed
strategies are efficient in the parameter size and computational time.
Moreover, we indicate that the proposed strategies are also effective in the
configuration where we use many training data such as the recent WMT
competition.

    

### [[2104.06644] Masked Language Modeling and the Distributional Hypothesis: Order Word Matters Pre-training for Little](http://arxiv.org/abs/2104.06644)


  A possible explanation for the impressive performance of masked language
model (MLM) pre-training is that such models have learned to represent the
syntactic structures prevalent in classical NLP pipelines. In this paper, we
propose a different explanation: MLMs succeed on downstream tasks almost
entirely due to their ability to model higher-order word co-occurrence
statistics. To demonstrate this, we pre-train MLMs on sentences with randomly
shuffled word order, and show that these models still achieve high accuracy
after fine-tuning on many downstream tasks -- including on tasks specifically
designed to be challenging for models that ignore word order. Our models
perform surprisingly well according to some parametric syntactic probes,
indicating possible deficiencies in how we test representations for syntactic
information. Overall, our results show that purely distributional information
largely explains the success of pre-training, and underscore the importance of
curating challenging evaluation datasets that require deeper linguistic
knowledge.

    

### [[2104.07566] BAM: A Balanced Attention Mechanism for Single Image Super Resolution](http://arxiv.org/abs/2104.07566)


  Recovering texture information from the aliasing regions has always been a
major challenge for Single Image Super Resolution (SISR) task. These regions
are often submerged in noise so that we have to restore texture details while
suppressing noise. To address this issue, we propose a Balanced Attention
Mechanism (BAM), which consists of Avgpool Channel Attention Module (ACAM) and
Maxpool Spatial Attention Module (MSAM) in parallel. ACAM is designed to
suppress extreme noise in the large scale feature maps while MSAM preserves
high-frequency texture details. Thanks to the parallel structure, these two
modules not only conduct self-optimization, but also mutual optimization to
obtain the balance of noise reduction and high-frequency texture restoration
during the back propagation process, and the parallel structure makes the
inference faster. To verify the effectiveness and robustness of BAM, we applied
it to 10 SOTA SISR networks. The results demonstrate that BAM can efficiently
improve the networks performance, and for those originally with attention
mechanism, the substitution with BAM further reduces the amount of parameters
and increases the inference speed. Moreover, we present a dataset with rich
texture aliasing regions in real scenes, named realSR7. Experiments prove that
BAM achieves better super-resolution results on the aliasing area.

    

### [[2104.07637] The Effect of Efficient Messaging and Input Variability on Neural-Agent Iterated Language Learning](http://arxiv.org/abs/2104.07637)


  Natural languages display a trade-off among different strategies to convey
syntactic structure, such as word order or inflection. This trade-off, however,
has not appeared in recent simulations of iterated language learning with
neural network agents (Chaabouni et al., 2019b). We re-evaluate this result in
light of three factors that play an important role in comparable experiments
from the Language Evolution field: (i) speaker bias towards efficient
messaging, (ii) non systematic input languages, and (iii) learning bottleneck.
Our simulations show that neural agents mainly strive to maintain the utterance
type distribution observed during learning, instead of developing a more
efficient or systematic language.

    

### [[2104.07789] Detect and Classify -- Joint Span Detection and Classification for Health Outcomes](http://arxiv.org/abs/2104.07789)


  A health outcome is a measurement or an observation used to capture and
assess the effect of a treatment. Automatic detection of health outcomes from
text would undoubtedly speed up access to evidence necessary in healthcare
decision making. Prior work on outcome detection has modelled this task as
either (a) a sequence labelling task, where the goal is to detect which text
spans describe health outcomes, or (b) a classification task, where the goal is
to classify a text into a pre-defined set of categories depending on an outcome
that is mentioned somewhere in that text. However, this decoupling of span
detection and classification is problematic from a modelling perspective and
ignores global structural correspondences between sentence-level and word-level
information present in a given text. To address this, we propose a method that
uses both word-level and sentence-level information to simultaneously perform
outcome span detection and outcome type classification. In addition to
injecting contextual information to hidden vectors, we use label attention to
appropriately weight both word and sentence level information. Experimental
results on several benchmark datasets for health outcome detection show that
our proposed method consistently outperforms decoupled methods, reporting
competitive results.

    

### [[2105.03432] Generalising Multilingual Concept-to-Text NLG with Language Agnostic Delexicalisation](http://arxiv.org/abs/2105.03432)


  Concept-to-text Natural Language Generation is the task of expressing an
input meaning representation in natural language. Previous approaches in this
task have been able to generalise to rare or unseen instances by relying on a
delexicalisation of the input. However, this often requires that the input
appears verbatim in the output text. This poses challenges in multilingual
settings, where the task expands to generate the output text in multiple
languages given the same input. In this paper, we explore the application of
multilingual models in concept-to-text and propose Language Agnostic
Delexicalisation, a novel delexicalisation method that uses multilingual
pretrained embeddings, and employs a character-level post-editing model to
inflect words in their correct form during relexicalisation. Our experiments
across five datasets and five languages show that multilingual models
outperform monolingual models in concept-to-text and that our framework
outperforms previous approaches, especially for low resource languages.

    

### [[2105.03824] FNet: Mixing Tokens with Fourier Transforms](http://arxiv.org/abs/2105.03824)


  We show that Transformer encoder architectures can be sped up, with limited
accuracy costs, by replacing the self-attention sublayers with simple linear
transformations that "mix" input tokens. These linear mixers, along with
standard nonlinearities in feed-forward layers, prove competent at modeling
semantic relationships in several text classification tasks. Most surprisingly,
we find that replacing the self-attention sublayer in a Transformer encoder
with a standard, unparameterized Fourier Transform achieves 92-97% of the
accuracy of BERT counterparts on the GLUE benchmark, but trains 80% faster on
GPUs and 70% faster on TPUs at standard 512 input lengths. At longer input
lengths, our FNet model is significantly faster: when compared to the
"efficient" Transformers on the Long Range Arena benchmark, FNet matches the
accuracy of the most accurate models, while outpacing the fastest models across
all sequence lengths on GPUs (and across relatively shorter lengths on TPUs).
Finally, FNet has a light memory footprint and is particularly efficient at
smaller model sizes; for a fixed speed and accuracy budget, small FNet models
outperform Transformer counterparts.

    

### [[2105.11702] Transfer Learning and Curriculum Learning in Sokoban](http://arxiv.org/abs/2105.11702)


  Transfer learning can speed up training in machine learning and is regularly
used in classification tasks. It reuses prior knowledge from other tasks to
pre-train networks for new tasks. In reinforcement learning, learning actions
for a behavior policy that can be applied to new environments is still a
challenge, especially for tasks that involve much planning. Sokoban is a
challenging puzzle game. It has been used widely as a benchmark in
planning-based reinforcement learning. In this paper, we show how prior
knowledge improves learning in Sokoban tasks. We find that reusing feature
representations learned previously can accelerate learning new, more complex,
instances. In effect, we show how curriculum learning, from simple to complex
tasks, works in Sokoban. Furthermore, feature representations learned in
simpler instances are more general, and thus lead to positive transfers towards
more complex tasks, but not vice versa. We have also studied which part of the
knowledge is most important for transfer to succeed, and identify which layers
should be used for pre-training.

    

### [[2106.07806] Highdicom: A Python library for standardized encoding of image annotations and machine learning model outputs in pathology and radiology](http://arxiv.org/abs/2106.07806)


  Machine learning is revolutionizing image-based diagnostics in pathology and
radiology. ML models have shown promising results in research settings, but
their lack of interoperability has been a major barrier for clinical
integration and evaluation. The DICOM a standard specifies Information Object
Definitions and Services for the representation and communication of digital
images and related information, including image-derived annotations and
analysis results. However, the complexity of the standard represents an
obstacle for its adoption in the ML community and creates a need for software
libraries and tools that simplify working with data sets in DICOM format. Here
we present the highdicom library, which provides a high-level application
programming interface for the Python programming language that abstracts
low-level details of the standard and enables encoding and decoding of
image-derived information in DICOM format in a few lines of Python code. The
highdicom library ties into the extensive Python ecosystem for image processing
and machine learning. Simultaneously, by simplifying creation and parsing of
DICOM-compliant files, highdicom achieves interoperability with the medical
imaging systems that hold the data used to train and run ML models, and
ultimately communicate and store model outputs for clinical use. We demonstrate
through experiments with slide microscopy and computed tomography imaging,
that, by bridging these two ecosystems, highdicom enables developers to train
and evaluate state-of-the-art ML models in pathology and radiology while
remaining compliant with the DICOM standard and interoperable with clinical
systems at all stages. To promote standardization of ML research and streamline
the ML model development and deployment process, we made the library available
free and open-source.

    

### [[2107.02174] What Makes for Hierarchical Vision Transformer?](http://arxiv.org/abs/2107.02174)


  Recent studies indicate that hierarchical Vision Transformer with a macro
architecture of interleaved non-overlapped window-based self-attention \&
shifted-window operation is able to achieve state-of-the-art performance in
various visual recognition tasks, and challenges the ubiquitous convolutional
neural networks (CNNs) using densely slid kernels. Most follow-up works attempt
to replace the shifted-window operation with other kinds of cross-window
communication paradigms, while treating self-attention as the de-facto standard
for window-based information aggregation. In this manuscript, we question
whether self-attention is the only choice for hierarchical Vision Transformer
to attain strong performance, and the effects of different kinds of
cross-window communication. To this end, we replace self-attention layers with
embarrassingly simple linear mapping layers, and the resulting proof-of-concept
architecture termed as LinMapper can achieve very strong performance in
ImageNet-1k image recognition. Moreover, we find that LinMapper is able to
better leverage the pre-trained representations from image recognition and
demonstrates excellent transfer learning properties on downstream dense
prediction tasks such as object detection and instance segmentation. We also
experiment with other alternatives to self-attention for content aggregation
inside each non-overlapped window under different cross-window communication
approaches, which all give similar competitive results. Our study reveals that
the \textbf{macro architecture} of Swin model families, other than specific
aggregation layers or specific means of cross-window communication, may be more
responsible for its strong performance and is the real challenger to the
ubiquitous CNN's dense sliding window paradigm. Code and models will be
publicly available to facilitate future research.

    

### [[2109.04614] A Fast-and-Effective Early-Stage Multi-level Cache Optimization Method Based on Reuse-Distance Analysis](http://arxiv.org/abs/2109.04614)


  In this paper, we propose a practical and effective approach allowing
designers to optimize multi-level cache size at the early system design phase.
Our key contribution is to generalize the reuse distance analysis method and
develop an effective and practical cache design optimization approach. We adopt
a simple scanning search method to locate optimal cache solutions in terms of
cache size, power consumption, or average data access delay. The proposed
approach is particularly useful for early-phase system designers and is
verified to be 150 to 250 times faster than the traditional simulation-based
approach. In addition, we also introduce a simplified analytical model and
provide designers insights about how cache design parameters may affect the
expected results. As a result, designers can make an adequate decision in the
early system design phase.

    

### [[2109.04532] 3D Real-Time Supercomputer Monitoring](http://arxiv.org/abs/2109.04532)


  Supercomputers are complex systems producing vast quantities of performance
data from multiple sources and of varying types. Performance data from each of
the thousands of nodes in a supercomputer tracks multiple forms of storage,
memory, networks, processors, and accelerators. Optimization of application
performance is critical for cost effective usage of a supercomputer and
requires efficient methods for effectively viewing performance data. The
combination of supercomputing analytics and 3D gaming visualization enables
real-time processing and visual data display of massive amounts of information
that humans can process quickly with little training. Our system fully utilizes
the capabilities of modern 3D gaming environments to create novel
representations of computing hardware which intuitively represent the physical
attributes of the supercomputer while displaying real-time alerts and component
utilization. This system allows operators to quickly assess how the
supercomputer is being used, gives users visibility into the resources they are
consuming, and provides instructors new ways to interactively teach the
computing architecture concepts necessary for efficient computing

    

### [[2109.04536] Performance Analysis of CP2K Code for Ab Initio Molecular Dynamics](http://arxiv.org/abs/2109.04536)


  Using a realistic molecular catalyst system, we conduct scaling studies of ab
initio molecular dynamics simulations using the CP2K code on both Intel Xeon
CPU and NVIDIA V100 GPU architectures. We explore using process placement and
affinity to gain additional performance improvements. We also use statistical
methods to understand performance changes in spite of the variability in
runtime for each molecular dynamics timestep. We found ideal conditions for CPU
runs included at least four MPI ranks per node, bound evenly across each
socket, and fully utilizing processing cores with one OpenMP thread per core,
no benefit was shown from reserving cores for the system. The CPU-only
simulations scaled at 70% or more of the ideal scaling up to 10 compute nodes,
after which the returns began to diminish more quickly. Simulations on a single
40-core node with two NVIDIA V100 GPUs for acceleration achieved over 3.7x
speedup compared to the fastest single 36-core node CPU-only version, and
showed 13% speedup over the fastest time we achieved across five CPU-only
nodes.

    

### [[2109.04605] Analytical Process Scheduling Optimization for Heterogeneous Multi-core Systems](http://arxiv.org/abs/2109.04605)


  In this paper, we propose the first optimum process scheduling algorithm for
an increasingly prevalent type of heterogeneous multicore (HEMC) system that
combines high-performance big cores and energy-efficient small cores with the
same instruction-set architecture (ISA). Existing algorithms are all
heuristics-based, and the well-known IPC-driven approach essentially tries to
schedule high scaling factor processes on big cores. Our analysis shows that,
for optimum solutions, it is also critical to consider placing long running
processes on big cores. Tests of SPEC 2006 cases on various big-small core
combinations show that our proposed optimum approach is up to 34% faster than
the IPC-driven heuristic approach in terms of total workload completion time.
The complexity of our algorithm is O(NlogN) where N is the number of processes.
Therefore, the proposed optimum algorithm is practical for use.

    

### [[2109.04646] AI Agents in Emergency Response Applications](http://arxiv.org/abs/2109.04646)


  Emergency personnel respond to various situations ranging from fire, medical,
hazardous materials, industrial accidents, to natural disasters. Situations
such as natural disasters or terrorist acts require a multifaceted response of
firefighters, paramedics, hazmat teams, and other agencies. Engineering AI
systems that aid emergency personnel proves to be a difficult system
engineering problem. Mission-critical "edge AI" situations require low-latency,
reliable analytics. To further add complexity, a high degree of model accuracy
is required when lives are at stake, creating a need for the deployment of
highly accurate, however computationally intensive models to
resource-constrained devices. To address all these issues, we propose an
agent-based architecture for deployment of AI agents via 5G service-based
architecture.

    

### [[2109.04766] An Execution Fingerprint Dictionary for HPC Application Recognition](http://arxiv.org/abs/2109.04766)


  Applications running on HPC systems waste time and energy if they: (a) use
resources inefficiently, (b) deviate from allocation purpose (e.g.
cryptocurrency mining), or (c) encounter errors and failures. It is important
to know which applications are running on the system, how they use the system,
and whether they have been executed before. To recognize known applications
during execution on a noisy system, we draw inspiration from the way Shazam
recognizes known songs playing in a crowded bar. Our contribution is an
Execution Fingerprint Dictionary (EFD) that stores execution fingerprints of
system metrics (keys) linked to application and input size information (values)
as key-value pairs for application recognition. Related work often relies on
extensive system monitoring (many system metrics collected over large time
windows) and employs machine learning methods to identify applications. Our
solution only uses the first 2 minutes and a single system metric to achieve
F-scores above 95 percent, providing comparable results to related work but
with a fraction of the necessary data and a straightforward mechanism of
recognition.

    

### [[2109.04848] How Does Blockchain Security Dictate Blockchain Implementation?](http://arxiv.org/abs/2109.04848)


  Blockchain protocols come with a variety of security guarantees. For example,
BFT-inspired protocols such as Algorand tend to be secure in the partially
synchronous setting, while longest chain protocols like Bitcoin will normally
require stronger synchronicity to be secure. Another fundamental distinction,
directly relevant to scalability solutions such as sharding, is whether or not
a single untrusted user is able to point to *certificates*, which provide
incontrovertible proof of block confirmation. Algorand produces such
certificates, while Bitcoin does not. Are these properties accidental? Or are
they inherent consequences of the paradigm of protocol design? Our aim in this
paper is to understand what, fundamentally, governs the nature of security for
permissionless blockchain protocols. Using the framework developed in
(Lewis-Pye and Roughgarden, 2021), we prove general results showing that these
questions relate directly to properties of the user selection process, i.e.,
the method (such as proof-of-work or proof-of-stake) which is used to select
users with the task of updating state. Our results suffice to establish, for
example, that the production of certificates is impossible for proof-of-work
protocols, but is automatic for standard forms of proof-of-stake protocols. As
a byproduct of our work, we also define a number of security notions and
identify the equivalences and inequivalences among them.

    

### [[2109.04911] RandSolomon: optimally resilient multi-party random number generation protocol](http://arxiv.org/abs/2109.04911)


  Multi-party random number generation is a key building-block in many
practical protocols. While straightforward to solve when all parties are
trusted to behave correctly, the problem becomes much more difficult in the
presence of faults. In this context, this paper presents RandSolomon, a
protocol that allows a network of N processes to produce an unpredictable
common random number among the non-faulty of them. We provide optimal
resilience for partially-synchronous systems where less than a third of the
participants might behave arbitrarily and, contrary to many solutions, we do
not require at any point faulty-processes to be responsive.

    

### [[2109.04996] Efficient Exascale Discretizations: High-Order Finite Element Methods](http://arxiv.org/abs/2109.04996)


  Efficient exploitation of exascale architectures requires rethinking of the
numerical algorithms used in many large-scale applications. These architectures
favor algorithms that expose ultra fine-grain parallelism and maximize the
ratio of floating point operations to energy intensive data movement. One of
the few viable approaches to achieve high efficiency in the area of PDE
discretizations on unstructured grids is to use matrix-free/partially-assembled
high-order finite element methods, since these methods can increase the
accuracy and/or lower the computational time due to reduced data motion. In
this paper we provide an overview of the research and development activities in
the Center for Efficient Exascale Discretizations (CEED), a co-design center in
the Exascale Computing Project that is focused on the development of
next-generation discretization software and algorithms to enable a wide range
of finite element applications to run efficiently on future hardware. CEED is a
research partnership involving more than 30 computational scientists from two
US national labs and five universities, including members of the Nek5000, MFEM,
MAGMA and PETSc projects. We discuss the CEED co-design activities based on
targeted benchmarks, miniapps and discretization libraries and our work on
performance optimizations for large-scale GPU architectures. We also provide a
broad overview of research and development activities in areas such as
unstructured adaptive mesh refinement algorithms, matrix-free linear solvers,
high-order data visualization, and list examples of collaborations with several
ECP and external applications.

    

### [[2105.00110] Triangle Centrality](http://arxiv.org/abs/2105.00110)


  Triangle centrality is introduced for finding important vertices in a graph
based on the concentration of triangles surrounding each vertex. An important
vertex in triangle centrality is at the center of many triangles, and therefore
it may be in many triangles or none at all.
We give optimal algorithms that compute triangle centrality in $O(m\sqrt{m})$
time and $O(m+n)$ space. Using fast matrix multiplication it takes
$n^{\omega+o(1)}$ time where $\omega$ is the matrix product exponent.
On a Concurrent Read Exclusive Write (CREW) Parallel Random Access Memory
(PRAM) machine, we give a near work-optimal algorithm that takes $O(\log n)$
time using $O(m\sqrt{m})$ CREW PRAM processors. In MapReduce, we show it takes
four rounds using $O(m\sqrt{m})$ communication bits, and is therefore optimal.
We also give a deterministic algorithm to find the triangle neighborhood and
triangle count of each vertex in $O(m\sqrt{m})$ time and $O(m+n)$ space.
Our empirical results demonstrate that triangle centrality uniquely
identified central vertices thirty-percent of the time in comparison to five
other well-known centrality measures, while being asymptotically faster to
compute on sparse graphs than all but the most trivial of these other measures.

    

### [[2109.04600] EVOQUER: Enhancing Temporal Grounding with Video-Pivoted BackQuery Generation](http://arxiv.org/abs/2109.04600)


  Temporal grounding aims to predict a time interval of a video clip
corresponding to a natural language query input. In this work, we present
EVOQUER, a temporal grounding framework incorporating an existing text-to-video
grounding model and a video-assisted query generation network. Given a query
and an untrimmed video, the temporal grounding model predicts the target
interval, and the predicted video clip is fed into a video translation task by
generating a simplified version of the input query. EVOQUER forms closed-loop
learning by incorporating loss functions from both temporal grounding and query
generation serving as feedback. Our experiments on two widely used datasets,
Charades-STA and ActivityNet, show that EVOQUER achieves promising improvements
by 1.05 and 1.31 at R@0.7. We also discuss how the query generation task could
facilitate error analysis by explaining temporal grounding model behavior.

    

### [[2109.04634] Knowledge-Assisted Reasoning of Model-Augmented System Requirements with Event Calculus and Goal-Directed Answer Set Programming](http://arxiv.org/abs/2109.04634)


  We consider requirements for cyber-physical systems represented in
constrained natural language. We present novel automated techniques for aiding
in the development of these requirements so that they are consistent and can
withstand perceived failures. We show how cyber-physical systems' requirements
can be modeled using the event calculus (EC), a formalism used in AI for
representing actions and change. We also show how answer set programming (ASP)
and its query-driven implementation s(CASP) can be used to directly realize the
event calculus model of the requirements. This event calculus model can be used
to automatically validate the requirements. Since ASP is an expressive
knowledge representation language, it can also be used to represent contextual
knowledge about cyber-physical systems, which, in turn, can be used to find
gaps in their requirements specifications. We illustrate our approach through
an altitude alerting system from the avionics domain.

    

### [[2109.04683] PIP: Physical Interaction Prediction via Mental Imagery with Span Selection](http://arxiv.org/abs/2109.04683)


  To align advanced artificial intelligence (AI) with human values and promote
safe AI, it is important for AI to predict the outcome of physical
interactions. Even with the ongoing debates on how humans predict the outcomes
of physical interactions among objects in the real world, there are works
attempting to tackle this task via cognitive-inspired AI approaches. However,
there is still a lack of AI approaches that mimic the mental imagery humans use
to predict physical interactions in the real world. In this work, we propose a
novel PIP scheme: Physical Interaction Prediction via Mental Imagery with Span
Selection. PIP utilizes a deep generative model to output future frames of
physical interactions among objects before extracting crucial information for
predicting physical interactions by focusing on salient frames using span
selection. To evaluate our model, we propose a large-scale SPACE+ dataset of
synthetic video frames, including three physical interaction events in a 3D
environment. Our experiments show that PIP outperforms baselines and human
performance in physical interaction prediction for both seen and unseen
objects. Furthermore, PIP's span selection scheme can effectively identify the
frames where physical interactions among objects occur within the generated
frames, allowing for added interpretability.

    

### [[2109.04703] Heterogeneous Graph Neural Networks for Keyphrase Generation](http://arxiv.org/abs/2109.04703)


  The encoder-decoder framework achieves state-of-the-art results in keyphrase
generation (KG) tasks by predicting both present keyphrases that appear in the
source document and absent keyphrases that do not. However, relying solely on
the source document can result in generating uncontrollable and inaccurate
absent keyphrases. To address these problems, we propose a novel graph-based
method that can capture explicit knowledge from related references. Our model
first retrieves some document-keyphrases pairs similar to the source document
from a pre-defined index as references. Then a heterogeneous graph is
constructed to capture relationships of different granularities between the
source document and its references. To guide the decoding process, a
hierarchical attention and copy mechanism is introduced, which directly copies
appropriate words from both the source document and its references based on
their relevance and significance. The experimental results on multiple KG
benchmarks show that the proposed model achieves significant improvements
against other baseline models, especially with regard to the absent keyphrase
prediction.

    

### [[2109.04727] A Simple and Effective Method To Eliminate the Self Language Bias in Multilingual Representations](http://arxiv.org/abs/2109.04727)


  Language agnostic and semantic-language information isolation is an emerging
research direction for multilingual representations models. We explore this
problem from a novel angle of geometric algebra and semantic space. A simple
but highly effective method "Language Information Removal (LIR)" factors out
language identity information from semantic related components in multilingual
representations pre-trained on multi-monolingual data. A post-training and
model-agnostic method, LIR only uses simple linear operations, e.g. matrix
factorization and orthogonal projection. LIR reveals that for weak-alignment
multilingual systems, the principal components of semantic spaces primarily
encodes language identity information. We first evaluate the LIR on a
cross-lingual question answer retrieval task (LAReQA), which requires the
strong alignment for the multilingual embedding space. Experiment shows that
LIR is highly effectively on this task, yielding almost 100% relative
improvement in MAP for weak-alignment models. We then evaluate the LIR on
Amazon Reviews and XEVAL dataset, with the observation that removing language
information is able to improve the cross-lingual transfer performance.

    

### [[2109.04730] Boosting Graph Search with Attention Network for Solving the General Orienteering Problem](http://arxiv.org/abs/2109.04730)


  Recently, several studies have explored the use of neural network to solve
different routing problems, which is an auspicious direction. These studies
usually design an encoder-decoder based framework that uses encoder embeddings
of nodes and the problem-specific context to produce node sequence(path), and
further optimize the produced result on top by beam search. However, existing
models can only support node coordinates as input, ignore the self-referential
property of the studied routing problems, and lack the consideration about the
low reliability in the initial stage of node selection, thus are hard to be
applied in real-world.
In this paper, we take the orienteering problem as an example to tackle these
limitations. We propose a novel combination of a variant beam search algorithm
and a learned heuristic for solving the general orienteering problem. We
acquire the heuristic with an attention network that takes the distances among
nodes as input, and learn it via a reinforcement learning framework. The
empirical studies show that our method can surpass a wide range of baselines
and achieve results close to the optimal or highly specialized approach. Also,
our proposed framework can be easily applied to other routing problems. Our
code is publicly available.

    

### [[2109.04778] Improving Multilingual Translation by Representation and Gradient Regularization](http://arxiv.org/abs/2109.04778)


  Multilingual Neural Machine Translation (NMT) enables one model to serve all
translation directions, including ones that are unseen during training, i.e.
zero-shot translation. Despite being theoretically attractive, current models
often produce low quality translations -- commonly failing to even produce
outputs in the right target language. In this work, we observe that off-target
translation is dominant even in strong multilingual systems, trained on massive
multilingual corpora. To address this issue, we propose a joint approach to
regularize NMT models at both representation-level and gradient-level. At the
representation level, we leverage an auxiliary target language prediction task
to regularize decoder outputs to retain information about the target language.
At the gradient level, we leverage a small amount of direct data (in thousands
of sentence pairs) to regularize model gradients. Our results demonstrate that
our approach is highly effective in both reducing off-target translation
occurrences and improving zero-shot translation performance by +5.59 and +10.38
BLEU on WMT and OPUS datasets respectively. Moreover, experiments show that our
method also works well when the small amount of direct data is not available.

    

### [[2109.04802] Secondary control activation analysed and predicted with explainable AI](http://arxiv.org/abs/2109.04802)


  The transition to a renewable energy system poses challenges for power grid
operation and stability. Secondary control is key in restoring the power system
to its reference following a disturbance. Underestimating the necessary control
capacity may require emergency measures, such as load shedding. Hence, a solid
understanding of the emerging risks and the driving factors of control is
needed. In this contribution, we establish an explainable machine learning
model for the activation of secondary control power in Germany. Training
gradient boosted trees, we obtain an accurate description of control
activation. Using SHapely Additive exPlanation (SHAP) values, we investigate
the dependency between control activation and external features such as the
generation mix, forecasting errors, and electricity market data. Thereby, our
analysis reveals drivers that lead to high reserve requirements in the German
power system. Our transparent approach, utilizing open data and making machine
learning models interpretable, opens new scientific discovery avenues.

    

### [[2109.04830] Solving the Extended Job Shop Scheduling Problem with AGVs -- Classical and Quantum Approaches](http://arxiv.org/abs/2109.04830)


  The subject of Job Scheduling Optimisation (JSO) deals with the scheduling of
jobs in an organization, so that the single working steps are optimally
organized regarding the postulated targets. In this paper a use case is
provided which deals with a sub-aspect of JSO, the Job Shop Scheduling Problem
(JSSP or JSP). As many optimization problems JSSP is NP-complete, which means
the complexity increases with every node in the system exponentially. The goal
of the use case is to show how to create an optimized duty rooster for certain
workpieces in a flexible organized machinery, combined with an Autonomous
Ground Vehicle (AGV), using Constraint Programming (CP) and Quantum Computing
(QC) alternatively. The results of a classical solution based on CP and on a
Quantum Annealing model are presented and discussed. All presented results have
been elaborated in the research project PlanQK.

    

### [[2109.04834] An Evaluation Dataset and Strategy for Building Robust Multi-turn Response Selection Model](http://arxiv.org/abs/2109.04834)


  Multi-turn response selection models have recently shown comparable
performance to humans in several benchmark datasets. However, in the real
environment, these models often have weaknesses, such as making incorrect
predictions based heavily on superficial patterns without a comprehensive
understanding of the context. For example, these models often give a high score
to the wrong response candidate containing several keywords related to the
context but using the inconsistent tense. In this study, we analyze the
weaknesses of the open-domain Korean Multi-turn response selection models and
publish an adversarial dataset to evaluate these weaknesses. We also suggest a
strategy to build a robust model in this adversarial environment.

    

### [[2109.04865] Emerging AI Security Threats for Autonomous Cars -- Case Studies](http://arxiv.org/abs/2109.04865)


  Artificial Intelligence has made a significant contribution to autonomous
vehicles, from object detection to path planning. However, AI models require a
large amount of sensitive training data and are usually computationally
intensive to build. The commercial value of such models motivates attackers to
mount various attacks. Adversaries can launch model extraction attacks for
monetization purposes or step-ping-stone towards other attacks like model
evasion. In specific cases, it even results in destroying brand reputation,
differentiation, and value proposition. In addition, IP laws and AI-related
legalities are still evolving and are not uniform across countries. We discuss
model extraction attacks in detail with two use-cases and a generic kill-chain
that can compromise autonomous cars. It is essential to investigate strategies
to manage and mitigate the risk of model theft.

    

### [[2109.04870] MultiAzterTest: a Multilingual Analyzer on Multiple Levels of Language for Readability Assessment](http://arxiv.org/abs/2109.04870)


  Readability assessment is the task of determining how difficult or easy a
text is or which level/grade it has. Traditionally, language dependent
readability formula have been used, but these formulae take few text
characteristics into account. However, Natural Language Processing (NLP) tools
that assess the complexity of texts are able to measure more different features
and can be adapted to different languages. In this paper, we present the
MultiAzterTest tool: (i) an open source NLP tool which analyzes texts on over
125 measures of cohesion,language, and readability for English, Spanish and
Basque, but whose architecture is designed to easily adapt other languages;
(ii) readability assessment classifiers that improve the performance of
Coh-Metrix in English, Coh-Metrix-Esp in Spanish and ErreXail in Basque; iii) a
web tool. MultiAzterTest obtains 90.09 % in accuracy when classifying into
three reading levels (elementary, intermediate, and advanced) in English and
95.50 % in Basque and 90 % in Spanish when classifying into two reading levels
(simple and complex) using a SMO classifier. Using cross-lingual features,
MultiAzterTest also obtains competitive results above all in a complex vs
simple distinction.

    

### [[2109.04877] Efficient Test Time Adapter Ensembling for Low-resource Language Varieties](http://arxiv.org/abs/2109.04877)


  Adapters are light-weight modules that allow parameter-efficient fine-tuning
of pretrained models. Specialized language and task adapters have recently been
proposed to facilitate cross-lingual transfer of multilingual pretrained models
(Pfeiffer et al., 2020b). However, this approach requires training a separate
language adapter for every language one wishes to support, which can be
impractical for languages with limited data. An intuitive solution is to use a
related language adapter for the new language variety, but we observe that this
solution can lead to sub-optimal performance. In this paper, we aim to improve
the robustness of language adapters to uncovered languages without training new
adapters. We find that ensembling multiple existing language adapters makes the
fine-tuned model significantly more robust to other language varieties not
included in these adapters. Building upon this observation, we propose Entropy
Minimized Ensemble of Adapters (EMEA), a method that optimizes the ensemble
weights of the pretrained language adapters for each test sentence by
minimizing the entropy of its predictions. Experiments on three diverse groups
of language varieties show that our method leads to significant improvements on
both named entity recognition and part-of-speech tagging across all languages.

    

### [[2109.04884] SO-SLAM: Semantic Object SLAM with Scale Proportional and Symmetrical Texture Constraints](http://arxiv.org/abs/2109.04884)


  Object SLAM introduces the concept of objects into Simultaneous Localization
and Mapping (SLAM) and helps understand indoor scenes for mobile robots and
object-level interactive applications. The state-of-art object SLAM systems
face challenges such as partial observations, occlusions, unobservable
problems, limiting the mapping accuracy and robustness. This paper proposes a
novel monocular Semantic Object SLAM (SO-SLAM) system that addresses the
introduction of object spatial constraints. We explore three representative
spatial constraints, including scale proportional constraint, symmetrical
texture constraint and plane supporting constraint. Based on these semantic
constraints, we propose two new methods - a more robust object initialization
method and an orientation fine optimization method. We have verified the
performance of the algorithm on the public datasets and an author-recorded
mobile robot dataset and achieved a significant improvement on mapping effects.
We will release the code here: this https URL.

    

### [[2109.04909] How Can Subgroup Discovery Help AIOps?](http://arxiv.org/abs/2109.04909)


  The genuine supervision of modern IT systems brings new challenges as it
requires higher standards of scalability, reliability and efficiency when
analysing and monitoring big data streams. Rule-based inference engines are a
key component of maintenance systems in detecting anomalies and automating
their resolution. However, they remain confined to simple and general rules and
cannot handle the huge amount of data, nor the large number of alerts raised by
IT systems, a lesson learned from expert systems era. Artificial Intelligence
for Operation Systems (AIOps) proposes to take advantage of advanced analytics
and machine learning on big data to improve and automate every step of
supervision systems and aid incident management in detecting outages,
identifying root causes and applying appropriate healing actions. Nevertheless,
the best AIOps techniques rely on opaque models, strongly limiting their
adoption. As a part of this PhD thesis, we study how Subgroup Discovery can
help AIOps. This promising data mining technique offers possibilities to
extract interesting hypothesis from data and understand the underlying process
behind predictive models. To ensure relevancy of our propositions, this project
involves both data mining researchers and practitioners from Infologic, a
French software editor.

    

### [[2109.04921] Examining Cross-lingual Contextual Embeddings with Orthogonal Structural Probes](http://arxiv.org/abs/2109.04921)


  State-of-the-art contextual embeddings are obtained from large language
models available only for a few languages. For others, we need to learn
representations using a multilingual model. There is an ongoing debate on
whether multilingual embeddings can be aligned in a space shared across many
languages. The novel Orthogonal Structural Probe (Limisiewicz and Mareek,
2021) allows us to answer this question for specific linguistic features and
learn a projection based only on mono-lingual annotated datasets. We evaluate
syntactic (UD) and lexical (WordNet) structural information encoded inmBERT's
contextual representations for nine diverse languages. We observe that for
languages closely related to English, no transformation is needed. The
evaluated information is encoded in a shared cross-lingual embedding space. For
other languages, it is beneficial to apply orthogonal transformation learned
separately for each language. We successfully apply our findings to zero-shot
and few-shot cross-lingual parsing.

    

### [[2109.04991] Detection of GAN-synthesized street videos](http://arxiv.org/abs/2109.04991)


  Research on the detection of AI-generated videos has focused almost
exclusively on face videos, usually referred to as deepfakes. Manipulations
like face swapping, face reenactment and expression manipulation have been the
subject of an intense research with the development of a number of efficient
tools to distinguish artificial videos from genuine ones. Much less attention
has been paid to the detection of artificial non-facial videos. Yet, new tools
for the generation of such kind of videos are being developed at a fast pace
and will soon reach the quality level of deepfake videos. The goal of this
paper is to investigate the detectability of a new kind of AI-generated videos
framing driving street sequences (here referred to as DeepStreets videos),
which, by their nature, can not be analysed with the same tools used for facial
deepfakes. Specifically, we present a simple frame-based detector, achieving
very good performance on state-of-the-art DeepStreets videos generated by the
Vid2vid architecture. Noticeably, the detector retains very good performance on
compressed videos, even when the compression level used during training does
not match that used for the test videos.

    

### [[2109.04993] LAViTeR: Learning Aligned Visual and Textual Representations Assisted by Image and Caption Generation](http://arxiv.org/abs/2109.04993)


  Pre-training visual and textual representations from large-scale image-text
pairs is becoming a standard approach for many downstream vision-language
tasks. The transformer-based models learn inter and intra-modal attention
through a list of self-supervised learning tasks. This paper proposes LAViTeR,
a novel architecture for visual and textual representation learning. The main
module, Visual Textual Alignment (VTA) will be assisted by two auxiliary tasks,
GAN-based image synthesis and Image Captioning. We also propose a new
evaluation metric measuring the similarity between the learnt visual and
textual embedding. The experimental results on two public datasets, CUB and
MS-COCO, demonstrate superior visual and textual representation alignment in
the joint feature embedding space

    

### [[2005.00782] RICA: Evaluating Robust Inference Capabilities Based on Commonsense Axioms](http://arxiv.org/abs/2005.00782)


  Pre-trained language models (PTLMs) have achieved impressive performance on
commonsense inference benchmarks, but their ability to employ commonsense to
make robust inferences, which is crucial for effective communications with
humans, is debated. In the pursuit of advancing fluid human-AI communication,
we propose a new challenge, RICA: Robust Inference capability based on
Commonsense Axioms, that evaluates robust commonsense inference despite textual
perturbations. To generate data for this challenge, we develop a systematic and
scalable procedure using commonsense knowledge bases and probe PTLMs across two
different evaluation settings. Extensive experiments on our generated probe
sets with more than 10k statements show that PTLMs perform no better than
random guessing on the zero-shot setting, are heavily impacted by statistical
biases, and are not robust to perturbation attacks. We also find that
fine-tuning on similar statements offer limited gains, as PTLMs still fail to
generalize to unseen inferences. Our new large-scale benchmark exposes a
significant gap between PTLMs and human-level language understanding and offers
a new challenge for PTLMs to demonstrate commonsense.

    

### [[2010.11796] CryptoGRU: Low Latency Privacy-Preserving Text Analysis With GRU](http://arxiv.org/abs/2010.11796)


  Billions of text analysis requests containing private emails, personal text
messages, and sensitive online reviews, are processed by recurrent neural
networks (RNNs) deployed on public clouds every day. Although prior secure
networks combine homomorphic encryption (HE) and garbled circuit (GC) to
preserve users' privacy, naively adopting the HE and GC hybrid technique to
implement RNNs suffers from long inference latency due to slow activation
functions. In this paper, we present a HE and GC hybrid gated recurrent unit
(GRU) network, CryptoGRU, for low-latency secure inferences. CryptoGRU replaces
computationally expensive GC-based $tanh$ with fast GC-based $ReLU$, and then
quantizes $sigmoid$ and $ReLU$ with a smaller bit length to accelerate
activations in a GRU. We evaluate CryptoGRU with multiple GRU models trained on
4 public datasets. Experimental results show CryptoGRU achieves top-notch
accuracy and improves the secure inference latency by up to $138\times$ over
one of state-of-the-art secure networks on the Penn Treebank dataset.

    

### [[2012.01410] Ontological Smart Contracts in OASIS: Ontology for Agents, Systems, and Integration of Services](http://arxiv.org/abs/2012.01410)


  In this contribution we extend an ontology for modelling agents and their
interactions, called Ontology for Agents, Systems, and Integration of Services
(in short, OASIS), with conditionals and ontological smart contracts (in short,
OSCs). OSCs are ontological representations of smart contracts that allow to
establish responsibilities and authorizations among agents and set agreements,
whereas conditionals allow one to restrict and limit agent interactions, define
activation mechanisms that trigger agent actions, and define constraints and
contract terms on OSCs. Conditionals and OSCs, as defined in OASIS, are applied
to extend with ontological capabilities digital public ledgers such as the
blockchain and smart contracts implemented on it. We will also sketch the
architecture of a framework based on the OASIS definition of OSCs that exploits
the Ethereum platform and the Interplanetary File System.

    

### [[2102.09761] Scaling Creative Inspiration with Fine-Grained Functional Facets of Ideas](http://arxiv.org/abs/2102.09761)


  Large repositories of products, patents and scientific papers offer an
opportunity for building systems that scour millions of ideas and help users
discover inspirations. However, idea descriptions are typically in the form of
unstructured text, lacking key structure that is required for supporting
creative innovation interactions. Prior work has explored idea representations
that were limited in expressivity, required significant manual effort from
users, or dependent on curated knowledge bases with poor coverage. We explore a
novel representation that automatically breaks up products into fine-grained
functional facets capturing the purposes and mechanisms of ideas, and use it to
support important creative innovation interactions: functional search for
ideas, and exploration of the design space around a focal problem by viewing
related problem perspectives pooled from across many products. In user studies,
our approach boosts the quality of creative search and inspirations,
outperforming strong baselines by 50-60%.

    

### [[2106.08826] A discrete optimisation approach for target path planning whilst evading sensors](http://arxiv.org/abs/2106.08826)


  In this paper we deal with a practical problem that arises in military
situations. The problem is to plan a path for one, or more, agents to reach a
target without being detected by enemy sensors.
Agents are not passive, rather they can initiate actions which aid evasion.
They can knockout, completely disable, sensors. They can also confuse sensors,
so reduce sensor detection probabilities. Agent actions are path dependent and
time limited. By path dependent we mean that an agent needs to be sufficiently
close to a sensor to knock it out. By time limited we mean that a limit is
imposed on how long a sensor is knocked out or confused before it reverts back
to its original operating state.
The approach adopted breaks the continuous space in which agents move into a
discrete space. This enables the problem to be formulated as a zero-one integer
program with linear constraints. The advantage of representing the problem in
this manner is that powerful commercial software optimisation packages exist to
solve the problem to proven global optimality. A heuristic for the problem
based on successive shortest paths is also presented.
Computational results are presented for a number of randomly generated test
problems.

    

### [[2108.13301] Web image search engine based on LSH index and CNN Resnet50](http://arxiv.org/abs/2108.13301)


  To implement a good Content Based Image Retrieval (CBIR) system, it is
essential to adopt efficient search methods. One way to achieve this results is
by exploiting approximate search techniques. In fact, when we deal with very
large collections of data, using an exact search method makes the system very
slow. In this project, we adopt the Locality Sensitive Hashing (LSH) index to
implement a CBIR system that allows us to perform fast similarity search on
deep features. Specifically, we exploit transfer learning techniques to extract
deep features from images; this phase is done using two famous Convolutional
Neural Networks (CNNs) as features extractors: Resnet50 and Resnet50v2, both
pre-trained on ImageNet. Then we try out several fully connected deep neural
networks, built on top of both of the previously mentioned CNNs in order to
fine-tuned them on our dataset. In both of previous cases, we index the
features within our LSH index implementation and within a sequential scan, to
better understand how much the introduction of the index affects the results.
Finally, we carry out a performance analysis: we evaluate the relevance of the
result set, computing the mAP (mean Average Precision) value obtained during
the different experiments with respect to the number of done comparison and
varying the hyper-parameter values of the LSH index.

    

### [[2109.04621] An Effective Early Multi-core System Shared Cache Design Method Based on Reuse-distance Analysis](http://arxiv.org/abs/2109.04621)


  In this paper, we proposed an effective and efficient multi-core shared-cache
design optimization approach based on reuse-distance analysis of the data
traces of target applications. Since data traces are independent of system
hardware architectures, a designer can easily compute the best cache design at
the early system design phase using our approach. We devise a very efficient
and yet accurate method to derive the aggregated reuse-distance histograms of
concurrent applications for accurate cache performance analysis and
optimization. Essentially, the actual shared-cache contention results of
concurrent applications are embedded in the aggregated reuse-distance
histograms and therefore the approach is very effective. The experimental
results show that the average error rate of shared-cache miss-count estimations
of our approach is less than 2.4%. Using a simple scanning search method, one
can easily determine the true optimal cache configurations at the early system
design phase.

    

### [[2109.04629] An Overview of the HFL Model Checking Project](http://arxiv.org/abs/2109.04629)


  In this article, we give an overview of our project on higher-order program
verification based on HFL (higher-order fixpoint logic) model checking. After a
brief introduction to HFL, we explain how it can be applied to program
verification, and summarize the current status of the project.

    

### [[2109.04630] Termination Analysis of Programs with Multiphase Control-Flow](http://arxiv.org/abs/2109.04630)


  Programs with multiphase control-flow are programs where the execution passes
through several (possibly implicit) phases. Proving termination of such
programs (or inferring corresponding runtime bounds) is often challenging since
it requires reasoning on these phases separately. In this paper we discuss
techniques for proving termination of such programs, in particular: (1) using
multiphase ranking functions, where we will discuss theoretical aspects of such
ranking functions for several kinds of program representations; and (2) using
control-flow refinement, in particular partial evaluation of Constrained Horn
Clauses, to simplify the control-flow allowing, among other things, to prove
termination with simpler ranking functions.

    

### [[2109.04632] Reducing Higher-order Recursion Scheme Equivalence to Coinductive Higher-order Constrained Horn Clauses](http://arxiv.org/abs/2109.04632)


  Higher-order constrained Horn clauses (HoCHC) are a semantically-invariant
system of higher-order logic modulo theories. With semi-decidable unsolvability
over a semi-decidable background theory, HoCHC is suitable for safety
verification. Less is known about its relation to larger classes of
higher-order verification problems. Motivated by program equivalence, we
introduce a coinductive version of HoCHC that enjoys a greatest model property.
We define an encoding of higher-order recursion schemes (HoRS) into HoCHC logic
programs. Correctness of this encoding reduces decidability of the open HoRS
equivalence problem -- and, thus, the LambdaY-calculus Bhm tree equivalence
problem -- to semi-decidability of coinductive HoCHC over a complete and
decidable theory of trees.

    

### [[1910.08607] Exorcising Spectres with Secure Compilers](http://arxiv.org/abs/1910.08607)


  Attackers can access sensitive information of programs by exploiting the
side-effects of speculatively-executed instructions using Spectre attacks. To
mitigate theses attacks, popular compilers deployed a wide range of
countermeasures. The security of these countermeasures, however, has not been
ascertained: while some of them are believed to be secure, others are known to
be insecure and result in vulnerable programs. To reason about the security
guarantees of these compiler-inserted countermeasures, this paper presents a
framework comprising several secure compilation criteria characterizing when
compilers produce code resistant against Spectre attacks. With this framework,
we perform a comprehensive security analysis of compiler-level countermeasures
against Spectre attacks implemented in major compilers. This work provides
sound foundations to formally reason about the security of compiler-level
countermeasures against Spectre attacks as well as the first proofs of security
and insecurity of said countermeasures.

    