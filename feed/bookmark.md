
## 2021-9-16

### [[2109.06923] Research Project 2: Drone-supported AI-based Generation of 3D Maps of Indoor Radio Environments](http://arxiv.org/abs/2109.06923)


  A Radio Environment Map (REM) is a powerful tool in enhancing the experience
of radio-enabled agents but building such a REM can be a laborious undertaking,
especially in three dimensions. This project shows how such a REM of an indoor
three-dimensional space can be generated in an autonomous and scalable way.
Building on the results of the preceding Research Project 1, multiple drones
are used to map the WiFi signals present in such a space in a real-world
environment where the drones are each able to visit 36 waypoints and
collectively gather thousands of WiFi beacon data samples. This report also
includes an analysis of the collected data and concludes by proposing
machine-learning based techniques to predict the signal strength of known
access points in locations not visited by the drones.

    

### [[2109.07041] Coalition Game based User Association for mmWave Mobile Relay Systems in Rail Traffic Scenarios](http://arxiv.org/abs/2109.07041)


  Rail transportation, especially, high-speed rails (HSR), is an important
infrastructure for the development of national economy and the promotion of
passenger experience. Due to the large bandwidth, millimeter wave (mmWave)
communication is regarded as a promising technology to meet the demand of high
data rates. However, since mmWave communication has the characteristic of high
attenuation, mobile relay (MR) is considered in this paper. Also, full-duplex
(FD) communications have been proposed to improve the spectral efficiency.
However, because of the high speed, as well as the problem of penetration loss,
passengers on the train have a poor quality of service. Consequently, an
effective user association scheme for HSR in mmWave band is necessary. In this
paper, we investigate the user association optimization problem in mmWave
mobilerelay systems where the MRs operate in the FD mode. To maximize the
system capacity, we propose a cooperative user association approach based on
coalition formation game, and develop a coalition formation algorithm to solve
the challenging NP-hard problem. We also prove the convergence and Nashstable
property of the proposed algorithm. Extensive simulations are done to show the
system performance of the proposed scheme under various network settings. It is
demonstrated that the proposed distributed low complexity scheme achieves a
nearoptimal performance and outperforms two baseline schemes in terms of
average system throughput.

    

### [[2109.07061] Scalable Cell-Free Massive MIMO Systems with Finite Resolution ADCs/DACs over Spatially Correlated Rician Fading Channels](http://arxiv.org/abs/2109.07061)


  In this paper, an analytical framework for evaluating the performance of
scalable cell-free massive MIMO (SCF-mMIMO) systems in which all user
equipments (UEs) and access points (APs) employ finite resolution
digital-to-analog converters (DACs) and analog-to-digital converters (ADCs) and
operates under correlated Rician fading, is presented. By using maximal-ratio
combining (MRC) detection, generic expressions for the uplink (UL) spectral
efficiency (SE) for both distributed and centralized schemes are derived. In
order to further reduce the computational complexity (CC) of the original local
partial MMSE (LP-MMSE) and partial MMSE (P-MMSE) detectors, two novel scalable
low complexity MMSE detectors are proposed for distributed and centralized
schemes respectively, which achieves very similar SE performance. Furthermore,
for the distributed scheme a novel partial large-scale fading decoding (P-LSFD)
weighting vector is introduced and its analytical SE performance is very
similar to the performance of an equivalent unscalable LSFD vector. Finally, a
scalable algorithm jointly consisting of AP cluster formation, pilot
assignment, and power control is proposed, which outperforms the conventional
random pilot assignment and user-group based pilot assignment policies and,
contrary to an equal power transmit strategy, it guarantees quality of service
(QoS) fairness for all accessing UEs.

    

### [[2109.07074] Anti-Tamper Protection for Internet of Things System Using Hyperledger Fabric Blockchain Technology](http://arxiv.org/abs/2109.07074)


  Automated and industrial Internet of Things (IoT) devices are increasing
daily. As the number of IoT devices grows, the volume of data generated by them
will also grow. Managing these rapidly expanding IoT devices and enormous data
efficiently to be available to all authorized users without compromising its
integrity will become essential in the near future. On the other side, many
information security incidents have been recorded, increasing the requirement
for countermeasures. While safeguards against hostile third parties have been
commonplace until now, operators and parties have seen an increase in demand
for data falsification detection and blocking. Blockchain technology is
well-known for its privacy, immutability, and decentralized nature.
Single-board computers are becoming more powerful while also becoming more
affordable as IoT platforms. These single-board computers are gaining traction
in the automation industry. This study focuses on a paradigm of IoT-Blockchain
integration where the blockchain node runs autonomously on the IoT platform
itself. It enables the system to conduct machine-to-machine transactions
without the intervention of a person and to exert direct access control over
IoT devices. This paper assumed that the readers are familiar with Hyperledger
Fabric basic operations and focus on the practical approach of integration. A
basic introduction is provided for the newbie on the blockchain.

    

### [[2109.07206] Signaling Design for Cooperative Resource Allocation and its Impact to Reliability](http://arxiv.org/abs/2109.07206)


  Decentralized cooperative resource allocation schemes for robotic swarms are
essential to enable high reliability in high throughput data exchanges. These
cooperative schemes require control signaling with the aim to avoid half-duplex
problems at the receiver and mitigate interference. We propose two cooperative
resource allocation schemes, device sequential and group scheduling, and
introduce a control signaling design. We observe that failure in the reception
of these control signals leads to non-cooperative behavior and to significant
performance degradation. The cause of these failures are identified and
specific countermeasures are proposed and evaluated. We compare the proposed
resource allocation schemes against the NR sidelink mode 2 resource allocation
and show that even though signaling has an important impact on the resource
allocation performance, our proposed device sequential and group scheduling
resource allocation schemes improve reliability by an order of magnitude
compared to sidelink mode 2.

    

### [[2109.07316] Reinshard: An optimally sharded dual-blockchain for concurrency resolution](http://arxiv.org/abs/2109.07316)


  Decentralized control, low-complexity, flexible and efficient communications
are the requirements of an architecture that aims to scale blockchains beyond
the current state. Such properties are attainable by reducing ledger size and
providing parallel operations in the blockchain. Sharding is one of the
approaches that lower the burden of the nodes and enhance performance. However,
the current solutions lack the features for resolving concurrency during
cross-shard communications. With multiple participants belonging to different
shards, handling concurrent operations is essential for optimal sharding. This
issue becomes prominent due to the lack of architectural support and requires
additional consensus for cross-shard communications. Inspired by hybrid
Proof-of-Work/Proof-of-Stake (PoW/PoS), like Ethereum, hybrid consensus and
2-hop blockchain, we propose Reinshard, a new blockchain that inherits the
properties of hybrid consensus for optimal sharding. Reinshard uses PoW and PoS
chain-pairs with PoS sub-chains for all the valid chain-pairs where the hybrid
consensus is attained through Verifiable Delay Function (VDF). Our architecture
provides a secure method of arranging nodes in shards and resolves concurrency
conflicts using the delay factor of VDF. The applicability of Reinshard is
demonstrated through security and experimental evaluations. A practical
concurrency problem is considered to show the efficacy of Reinshard in
providing optimal sharding.

    

### [[2109.07459] Timely Updating with Intermittent Energy and Data for Multiple Sources over Erasure Channels](http://arxiv.org/abs/2109.07459)


  A status updating system is considered in which multiple data sources
generate packets to be delivered to a destination through a shared energy
harvesting sensor. Only one source's data, when available, can be transmitted
by the sensor at a time, subject to energy availability. Transmissions are
prune to erasures, and each successful transmission constitutes a status update
for its corresponding source at the destination. The goal is to schedule source
transmissions such that the collective long-term average age-of-information
(AoI) is minimized. AoI is defined as the time elapsed since the latest
successfully-received data has been generated at its source. To solve this
problem, the case with a single source is first considered, with a focus on
threshold waiting policies, in which the sensor attempts transmission only if
the time until both energy and data are available grows above a certain
threshold. The distribution of the AoI is fully characterized under such a
policy. This is then used to analyze the performance of the multiple sources
case under maximum-age-first scheduling, in which the sensor's resources are
dedicated to the source with the maximum AoI at any given time. The achievable
collective long-term average AoI is derived in closed-form. Multiple numerical
evaluations are demonstrated to show how the optimal threshold value behaves as
a function of the system parameters, and showcase the benefits of a
threshold-based waiting policy with intermittent energy and data arrivals.

    

### [[2012.13537] LSTM-Aided Hybrid Random Access Scheme for 6G Machine Type Communication Networks](http://arxiv.org/abs/2012.13537)


  In this paper, an LSTM-aided hybrid random access scheme (LSTMH-RA) is
proposed to support diverse quality of service (QoS) requirements in 6G
machine-type communication (MTC) networks, where massive MTC (mMTC) devices and
ultra-reliable low latency communications (URLLC) devices coexist. In the
proposed LSTMH-RA scheme, mMTC devices access the network via a timing advance
(TA)-aided four-step procedure to meet massive access requirement, while the
access procedure of the URLLC devices is completed in two steps coupled with
the mMTC devices' access procedure to reduce latency. Furthermore, we propose
an attention-based LSTM prediction model to predict the number of active URLLC
devices, thereby determining the parameters of the multi-user detection
algorithm to guarantee the latency and reliability access requirements of URLLC
devices. We analyze the successful access probability of the LSTMH-RA scheme.
Numerical results show that, compared with the benchmark schemes, the proposed
LSTMH-RA scheme can significantly improve the successful access probability,
and thus satisfy the diverse QoS requirements of URLLC and mMTC devices.

    

### [[2105.07605] Utility Maximization for Multihop Wireless Networks Employing BATS Codes](http://arxiv.org/abs/2105.07605)


  BATS (BATched Sparse) codes are a class of efficient random linear network
coding variation that has been studied for multihop wireless networks mostly in
scenarios of a single communication flow. Towards sophisticated multi-flow
network communications, we formulate a network utility maximization (NUM)
problem that jointly optimizes the BATS code parameters of all the flows and
network scheduling. The NUM problem adopts a batch-wise packet loss model that
can be obtained from the network local statistics without any constraints on
packet loss patterns. Moreover, the NUM problem allows a different number of
recoded packets to be transmitted for different batches in a flow, which is
called adaptive recoding. Due to both the probably nonconcave objective and the
BATS code-related variables, the algorithms developed for the existing flow
optimization problems cannot be applied directly to solve our NUM problem. We
introduce a two-step algorithm to solve our NUM problem, where the first step
solves the problem with nonadaptive recoding schemes, and the second step
optimizes adaptive recoding hop-by-hop from upstream to downstream in each
flow. We perform various numerical evaluations and simulations to verify the
effectiveness and efficiency of the algorithm.

    

### [[2105.07609] Intrablock Interleaving for Batched Network Coding with Blockwise Adaptive Recoding](http://arxiv.org/abs/2105.07609)


  Batched network coding (BNC) is a low-complexity solution to network
transmission in multi-hop packet networks with packet loss. BNC encodes the
source data into batches of packets. As a network coding scheme, the
intermediate nodes perform recoding on the received packets belonging to the
same batch instead of just forwarding them. A recoding scheme that may generate
more recoded packets for batches of a higher rank is also called adaptive
recoding. Meanwhile, in order to combat burst packet loss, the transmission of
a block of batches can be interleaved. Stream interleaving studied in
literature achieves the maximum separation among any two consecutive packets of
a batch, but permutes packets across blocks and hence cannot bound the buffer
size and the latency. To resolve the issue of stream interleaver, we design an
intrablock interleaver for adaptive recoding that can preserve the advantages
of using a block interleaver when the number of recoded packets is the same for
all batches. We use potential energy in classical mechanics to measure the
performance of an interleaver, and propose an algorithm to optimize the
interleaver with this performance measure. Our problem formulation and
algorithm for intrablock interleaving are also of independent interest.

    

### [[2105.07614] A Unified Adaptive Recoding Framework for Batched Network Coding](http://arxiv.org/abs/2105.07614)


  Batched network coding is a variation of random linear network coding which
has low computational and storage costs. In order to adapt to random
fluctuations in the number of erasures in individual batches, it is not optimal
to recode and transmit the same number of packets for all batches. Different
distributed optimization models, which are called adaptive recoding schemes,
were formulated for this purpose. The key component of these optimization
problems is the expected value of the rank distribution of a batch at the next
network node, which is also known as the expected rank. In this paper, we put
forth a unified adaptive recoding framework with an arbitrary recoding field
size. We show that the expected rank functions are concave when the packet loss
pattern is a stationary stochastic process, which covers but not limited to
independent packet loss and Gilbert-Elliott packet loss model. Under this
concavity assumption, we show that there always exists a solution which not
only can minimize the randomness on the number of recoded packets but also can
tolerate rank distribution errors due to inaccurate measurements or limited
precision of the machine. We provide an algorithm to obtain such an optimal
optimal solution, and propose tuning schemes that can turn any feasible
solution into a desired optimal solution.

    

### [[2109.06873] Improving Robustness and Efficiency in Active Learning with Contrastive Loss](http://arxiv.org/abs/2109.06873)


  This paper introduces supervised contrastive active learning (SCAL) by
leveraging the contrastive loss for active learning in a supervised setting. We
propose efficient query strategies in active learning to select unbiased and
informative data samples of diverse feature representations. We demonstrate our
proposed method reduces sampling bias, achieves state-of-the-art accuracy and
model calibration in an active learning setup with the query computation 11x
faster than CoreSet and 26x faster than Bayesian active learning by
disagreement. Our method yields well-calibrated models even with imbalanced
datasets. We also evaluate robustness to dataset shift and out-of-distribution
in active learning setup and demonstrate our proposed SCAL method outperforms
high performing compute-intensive methods by a bigger margin (average 8.9%
higher AUROC for out-of-distribution detection and average 7.2% lower ECE under
dataset shift).

    

### [[2109.06911] Learning and Decision-Making with Data: Optimal Formulations and Phase Transitions](http://arxiv.org/abs/2109.06911)


  We study the problem of designing optimal learning and decision-making
formulations when only historical data is available. Prior work typically
commits to a particular class of data-driven formulation and subsequently tries
to establish out-of-sample performance guarantees. We take here the opposite
approach. We define first a sensible yard stick with which to measure the
quality of any data-driven formulation and subsequently seek to find an optimal
such formulation. Informally, any data-driven formulation can be seen to
balance a measure of proximity of the estimated cost to the actual cost while
guaranteeing a level of out-of-sample performance. Given an acceptable level of
out-of-sample performance, we construct explicitly a data-driven formulation
that is uniformly closer to the true cost than any other formulation enjoying
the same out-of-sample performance. We show the existence of three distinct
out-of-sample performance regimes (a superexponential regime, an exponential
regime and a subexponential regime) between which the nature of the optimal
data-driven formulation experiences a phase transition. The optimal data-driven
formulations can be interpreted as a classically robust formulation in the
superexponential regime, an entropic distributionally robust formulation in the
exponential regime and finally a variance penalized formulation in the
subexponential regime. This final observation unveils a surprising connection
between these three, at first glance seemingly unrelated, data-driven
formulations which until now remained hidden.

    

### [[2109.06915] Reconstruction on Trees and Low-Degree Polynomials](http://arxiv.org/abs/2109.06915)


  The study of Markov processes and broadcasting on trees has deep connections
to a variety of areas including statistical physics, phylogenetic
reconstruction, MCMC algorithms, and community detection in random graphs.
Notably, the celebrated Belief Propagation (BP) algorithm achieves
Bayes-optimal performance for the reconstruction problem of predicting the
value of the Markov process at the root of the tree from its values at the
leaves.
Recently, the analysis of low-degree polynomials has emerged as a valuable
tool for predicting computational-to-statistical gaps. In this work, we
investigate the performance of low-degree polynomials for the reconstruction
problem on trees. Perhaps surprisingly, we show that there are simple tree
models with $N$ leaves where (1) nontrivial reconstruction of the root value is
possible with a simple polynomial time algorithm and with robustness to noise,
but not with any polynomial of degree $N^{c}$ for $c > 0$ a constant, and (2)
when the tree is unknown and given multiple samples with correlated root
assignments, nontrivial reconstruction of the root value is possible with a
simple, noise-robust, and computationally efficient SQ (Statistical Query)
algorithm but not with any polynomial of degree $N^c$. These results clarify
some of the limitations of low-degree polynomials vs. polynomial time
algorithms for Bayesian estimation problems. They also complement recent work
of Moitra, Mossel, and Sandon who studied the circuit complexity of Belief
Propagation. We pose related open questions about low-degree polynomials and
the Kesten-Stigum threshold.

    

### [[2109.06919] Deploying clinical machine learning? Consider the following...](http://arxiv.org/abs/2109.06919)


  Despite the intense attention and investment into clinical machine learning
(CML) research, relatively few applications convert to clinical practice. While
research is important in advancing the state-of-the-art, translation is equally
important in bringing these technologies into a position to ultimately impact
patient care and live up to extensive expectations surrounding AI in
healthcare. To better characterize a holistic perspective among researchers and
practitioners, we survey several participants with experience in developing CML
for clinical deployment about their learned experiences. We collate these
insights and identify several main categories of barriers and pitfalls in order
to better design and develop clinical machine learning applications.

    

### [[2109.06932] A Crawler Architecture for Harvesting the Clear, Social, and Dark Web for IoT-Related Cyber-Threat Intelligence](http://arxiv.org/abs/2109.06932)


  The clear, social, and dark web have lately been identified as rich sources
of valuable cyber-security information that -given the appropriate tools and
methods-may be identified, crawled and subsequently leveraged to actionable
cyber-threat intelligence. In this work, we focus on the information gathering
task, and present a novel crawling architecture for transparently harvesting
data from security websites in the clear web, security forums in the social
web, and hacker forums/marketplaces in the dark web. The proposed architecture
adopts a two-phase approach to data harvesting. Initially a machine
learning-based crawler is used to direct the harvesting towards websites of
interest, while in the second phase state-of-the-art statistical language
modelling techniques are used to represent the harvested information in a
latent low-dimensional feature space and rank it based on its potential
relevance to the task at hand. The proposed architecture is realised using
exclusively open-source tools, and a preliminary evaluation with crowdsourced
results demonstrates its effectiveness.

    

### [[2109.06949] Targeted Cross-Validation](http://arxiv.org/abs/2109.06949)


  In many applications, we have access to the complete dataset but are only
interested in the prediction of a particular region of predictor variables. A
standard approach is to find the globally best modeling method from a set of
candidate methods. However, it is perhaps rare in reality that one candidate
method is uniformly better than the others. A natural approach for this
scenario is to apply a weighted $L_2$ loss in performance assessment to reflect
the region-specific interest. We propose a targeted cross-validation (TCV) to
select models or procedures based on a general weighted $L_2$ loss. We show
that the TCV is consistent in selecting the best performing candidate under the
weighted $L_2$ loss. Experimental studies are used to demonstrate the use of
TCV and its potential advantage over the global CV or the approach of using
only local data for modeling a local region.
Previous investigations on CV have relied on the condition that when the
sample size is large enough, the ranking of two candidates stays the same.
However, in many applications with the setup of changing data-generating
processes or highly adaptive modeling methods, the relative performance of the
methods is not static as the sample size varies. Even with a fixed
data-generating process, it is possible that the ranking of two methods
switches infinitely many times. In this work, we broaden the concept of the
selection consistency by allowing the best candidate to switch as the sample
size varies, and then establish the consistency of the TCV. This flexible
framework can be applied to high-dimensional and complex machine learning
scenarios where the relative performances of modeling procedures are dynamic.

    

### [[2109.06961] Building Accurate Simple Models with Multihop](http://arxiv.org/abs/2109.06961)


  Knowledge transfer from a complex high performing model to a simpler and
potentially low performing one in order to enhance its performance has been of
great interest over the last few years as it finds applications in important
problems such as explainable artificial intelligence, model compression, robust
model building and learning from small data. Known approaches to this problem
(viz. Knowledge Distillation, Model compression, ProfWeight, etc.) typically
transfer information directly (i.e. in a single/one hop) from the complex model
to the chosen simple model through schemes that modify the target or reweight
training examples on which the simple model is trained. In this paper, we
propose a meta-approach where we transfer information from the complex model to
the simple model by dynamically selecting and/or constructing a sequence of
intermediate models of decreasing complexity that are less intricate than the
original complex model. Our approach can transfer information between
consecutive models in the sequence using any of the previously mentioned
approaches as well as work in 1-hop fashion, thus generalizing these
approaches. In the experiments on real data, we observe that we get consistent
gains for different choices of models over 1-hop, which on average is more than
2\% and reaches up to 8\% in a particular case. We also empirically analyze
conditions under which the multi-hop approach is likely to be beneficial over
the traditional 1-hop approach, and report other interesting insights. To the
best of our knowledge, this is the first work that proposes such a multi-hop
approach to perform knowledge transfer given a single high performing complex
model, making it in our opinion, an important methodological contribution.

    

### [[2109.06972] Combining GEDI and Sentinel-2 for wall-to-wall mapping of tall and short crops](http://arxiv.org/abs/2109.06972)


  High resolution crop type maps are an important tool for improving food
security, and remote sensing is increasingly used to create such maps in
regions that possess ground truth labels for model training. However, these
labels are absent in many regions, and models trained in other regions on
typical satellite features, such as those from optical sensors, often exhibit
low performance when transferred. Here we explore the use of NASA's Global
Ecosystem Dynamics Investigation (GEDI) spaceborne lidar instrument, combined
with Sentinel-2 optical data, for crop type mapping. Using data from three
major cropped regions (in China, France, and the United States) we first
demonstrate that GEDI energy profiles are capable of reliably distinguishing
maize, a crop typically above 2m in height, from crops like rice and soybean
that are shorter. We further show that these GEDI profiles provide much more
invariant features across geographies compared to spectral and phenological
features detected by passive optical sensors. GEDI is able to distinguish maize
from other crops within each region with accuracies higher than 84%, and able
to transfer across regions with accuracies higher than 82% compared to 64% for
transfer of optical features. Finally, we show that GEDI profiles can be used
to generate training labels for models based on optical imagery from
Sentinel-2, thereby enabling the creation of 10m wall-to-wall maps of tall
versus short crops in label-scarce regions. As maize is the second most widely
grown crop in the world and often the only tall crop grown within a landscape,
we conclude that GEDI offers great promise for improving global crop type maps.

    

### [[2109.06980] Explainable Identification of Dementia from Transcripts using Transformer Networks](http://arxiv.org/abs/2109.06980)


  Alzheimer's disease (AD) is the main cause of dementia which is accompanied
by loss of memory and may lead to severe consequences in peoples' everyday life
if not diagnosed on time. Very few works have exploited transformer-based
networks and despite the high accuracy achieved, little work has been done in
terms of model interpretability. In addition, although Mini-Mental State Exam
(MMSE) scores are inextricably linked with the identification of dementia,
research works face the task of dementia identification and the task of the
prediction of MMSE scores as two separate tasks. In order to address these
limitations, we employ several transformer-based models, with BERT achieving
the highest accuracy accounting for 85.56%. Concurrently, we propose an
interpretable method to detect AD patients based on siamese networks reaching
accuracy up to 81.18%. Next, we introduce two multi-task learning models, where
the main task refers to the identification of dementia (binary classification),
while the auxiliary one corresponds to the identification of the severity of
dementia (multiclass classification). Our model obtains accuracy equal to
84.99% on the detection of AD patients in the multi-task learning setting.
Finally, we present some new methods to identify the linguistic patterns used
by AD patients and non-AD ones, including text statistics, vocabulary
uniqueness, word usage, correlations via a detailed linguistic analysis, and
explainability techniques (LIME). Findings indicate significant differences in
language between AD and non-AD patients.

    

### [[2109.06996] Scalable Average Consensus with Compressed Communications](http://arxiv.org/abs/2109.06996)


  We propose a new decentralized average consensus algorithm with compressed
communication that scales linearly with the network size n. We prove that the
proposed method converges to the average of the initial values held locally by
the agents of a network when agents are allowed to communicate with compressed
messages. The proposed algorithm works for a broad class of compression
operators (possibly biased), where agents interact over arbitrary static,
undirected, and connected networks. We further present numerical experiments
that confirm our theoretical results and illustrate the scalability and
communication efficiency of our algorithm.

    

### [[2109.06999] Behavior of k-NN as an Instance-Based Explanation Method](http://arxiv.org/abs/2109.06999)


  Adoption of DL models in critical areas has led to an escalating demand for
sound explanation methods. Instance-based explanation methods are a popular
type that return selective instances from the training set to explain the
predictions for a test sample. One way to connect these explanations with
prediction is to ask the following counterfactual question - how does the loss
and prediction for a test sample change when explanations are removed from the
training set? Our paper answers this question for k-NNs which are natural
contenders for an instance-based explanation method. We first demonstrate
empirically that the representation space induced by last layer of a neural
network is the best to perform k-NN in. Using this layer, we conduct our
experiments and compare them to influence functions (IFs)
~\cite{koh2017understanding} which try to answer a similar question. Our
evaluations do indicate change in loss and predictions when explanations are
removed but we do not find a trend between $k$ and loss or prediction change.
We find significant stability in the predictions and loss of MNIST vs.
CIFAR-10. Surprisingly, we do not observe much difference in the behavior of
k-NNs vs. IFs on this question. We attribute this to training set subsampling
for IFs.

    

### [[2109.07005] WaveCorr: Correlation-savvy Deep Reinforcement Learning for Portfolio Management](http://arxiv.org/abs/2109.07005)


  The problem of portfolio management represents an important and challenging
class of dynamic decision making problems, where rebalancing decisions need to
be made over time with the consideration of many factors such as investors
preferences, trading environments, and market conditions. In this paper, we
present a new portfolio policy network architecture for deep reinforcement
learning (DRL)that can exploit more effectively cross-asset dependency
information and achieve better performance than state-of-the-art architectures.
In particular, we introduce a new property, referred to as \textit{asset
permutation invariance}, for portfolio policy networks that exploit multi-asset
time series data, and design the first portfolio policy network, named
WaveCorr, that preserves this invariance property when treating asset
correlation information. At the core of our design is an innovative permutation
invariant correlation processing layer. An extensive set of experiments are
conducted using data from both Canadian (TSX) and American stock markets (S&P
500), and WaveCorr consistently outperforms other architectures with an
impressive 3%-25% absolute improvement in terms of average annual return, and
up to more than 200% relative improvement in average Sharpe ratio. We also
measured an improvement of a factor of up to 5 in the stability of performance
under random choices of initial asset ordering and weights. The stability of
the network has been found as particularly valuable by our industrial partner.

    

### [[2109.07008] HeMI: Multi-view Embedding in Heterogeneous Graphs](http://arxiv.org/abs/2109.07008)


  Many real-world graphs involve different types of nodes and relations between
nodes, being heterogeneous by nature. The representation learning of
heterogeneous graphs (HGs) embeds the rich structure and semantics of such
graphs into a low-dimensional space and facilitates various data mining tasks,
such as node classification, node clustering, and link prediction. In this
paper, we propose a self-supervised method that learns HG representations by
relying on knowledge exchange and discovery among different HG structural
semantics (meta-paths). Specifically, by maximizing the mutual information of
meta-path representations, we promote meta-path information fusion and
consensus, and ensure that globally shared semantics are encoded. By extensive
experiments on node classification, node clustering, and link prediction tasks,
we show that the proposed self-supervision both outperforms and improves
competing methods by 1% and up to 10% for all tasks.

    

### [[2109.07011] Testing Self-Organized Criticality Across the Main Sequence using Stellar Flares from TESS](http://arxiv.org/abs/2109.07011)


  Stars produce explosive flares, which are believed to be powered by the
release of energy stored in coronal magnetic field configurations. It has been
shown that solar flares exhibit energy distributions typical of self-organized
critical systems. This study applies a novel flare detection technique to data
obtained by NASA's TESS mission and identifies $\sim10^6$ flaring events on
$\sim10^5$ stars across spectral types. Our results suggest that magnetic
reconnection events that maintain the topology of the magnetic field in a
self-organized critical state are ubiquitous among stellar coronae.

    

### [[2109.07016] Graph Embedding via Diffusion-Wavelets-Based Node Feature Distribution Characterization](http://arxiv.org/abs/2109.07016)


  Recent years have seen a rise in the development of representational learning
methods for graph data. Most of these methods, however, focus on node-level
representation learning at various scales (e.g., microscopic, mesoscopic, and
macroscopic node embedding). In comparison, methods for representation learning
on whole graphs are currently relatively sparse. In this paper, we propose a
novel unsupervised whole graph embedding method. Our method uses spectral graph
wavelets to capture topological similarities on each k-hop sub-graph between
nodes and uses them to learn embeddings for the whole graph. We evaluate our
method against 12 well-known baselines on 4 real-world datasets and show that
our method achieves the best performance across all experiments, outperforming
the current state-of-the-art by a considerable margin.

    

### [[2109.07018] Non-linear Independent Dual System (NIDS) for Discretization-independent Surrogate Modeling over Complex Geometries](http://arxiv.org/abs/2109.07018)


  Numerical solution of partial differential equations (PDEs) require expensive
simulations, limiting their application in design optimization routines,
model-based control, or solution of large-scale inverse problems. Existing
Convolutional Neural Network-based frameworks for surrogate modeling require
lossy pixelization and data-preprocessing, which is not suitable for realistic
engineering applications. Therefore, we propose non-linear independent dual
system (NIDS), which is a deep learning surrogate model for
discretization-independent, continuous representation of PDE solutions, and can
be used for prediction over domains with complex, variable geometries and mesh
topologies. NIDS leverages implicit neural representations to develop a
non-linear mapping between problem parameters and spatial coordinates to state
predictions by combining evaluations of a case-wise parameter network and a
point-wise spatial network in a linear output layer. The input features of the
spatial network include physical coordinates augmented by a minimum distance
function evaluation to implicitly encode the problem geometry. The form of the
overall output layer induces a dual system, where each term in the map is
non-linear and independent. Further, we propose a minimum distance
function-driven weighted sum of NIDS models using a shared parameter network to
enforce boundary conditions by construction under certain restrictions. The
framework is applied to predict solutions around complex,
parametrically-defined geometries on non-parametrically-defined meshes with
solution obtained many orders of magnitude faster than the full order models.
Test cases include a vehicle aerodynamics problem with complex geometry and
data scarcity, enabled by a training method in which more cases are gradually
added as training progresses.

    

### [[2109.07023] Embedding Node Structural Role Identity Using Stress Majorization](http://arxiv.org/abs/2109.07023)


  Nodes in networks may have one or more functions that determine their role in
the system. As opposed to local proximity, which captures the local context of
nodes, the role identity captures the functional "role" that nodes play in a
network, such as being the center of a group, or the bridge between two groups.
This means that nodes far apart in a network can have similar structural role
identities. Several recent works have explored methods for embedding the roles
of nodes in networks. However, these methods all rely on either approximating
or indirect modeling of structural equivalence. In this paper, we present a
novel and flexible framework using stress majorization, to transform the
high-dimensional role identities in networks directly (without approximation or
indirect modeling) to a low-dimensional embedding space. Our method is also
flexible, in that it does not rely on specific structural similarity
definitions. We evaluated our method on the tasks of node classification,
clustering, and visualization, using three real-world and five synthetic
networks. Our experiments show that our framework achieves superior results
than existing methods in learning node role representations.

    

### [[2109.07028] Avengers Ensemble! Improving Transferability of Authorship Obfuscation](http://arxiv.org/abs/2109.07028)


  Stylometric approaches have been shown to be quite effective for real-world
authorship attribution. To mitigate the privacy threat posed by authorship
attribution, researchers have proposed automated authorship obfuscation
approaches that aim to conceal the stylometric artefacts that give away the
identity of an anonymous document's author. Recent work has focused on
authorship obfuscation approaches that rely on black-box access to an
attribution classifier to evade attribution while preserving semantics.
However, to be useful under a realistic threat model, it is important that
these obfuscation approaches work well even when the adversary's attribution
classifier is different from the one used internally by the obfuscator.
Unfortunately, existing authorship obfuscation approaches do not transfer well
to unseen attribution classifiers. In this paper, we propose an ensemble-based
approach for transferable authorship obfuscation. Our experiments show that if
an obfuscator can evade an ensemble attribution classifier, which is based on
multiple base attribution classifiers, it is more likely to transfer to
different attribution classifiers. Our analysis shows that ensemble-based
authorship obfuscation achieves better transferability because it combines the
knowledge from each of the base attribution classifiers by essentially
averaging their decision boundaries.

    

### [[2109.07043] Attention Is Indeed All You Need: Semantically Attention-Guided Decoding for Data-to-Text NLG](http://arxiv.org/abs/2109.07043)


  Ever since neural models were adopted in data-to-text language generation,
they have invariably been reliant on extrinsic components to improve their
semantic accuracy, because the models normally do not exhibit the ability to
generate text that reliably mentions all of the information provided in the
input. In this paper, we propose a novel decoding method that extracts
interpretable information from encoder-decoder models' cross-attention, and
uses it to infer which attributes are mentioned in the generated text, which is
subsequently used to rescore beam hypotheses. Using this decoding method with
T5 and BART, we show on three datasets its ability to dramatically reduce
semantic errors in the generated outputs, while maintaining their
state-of-the-art quality.

    

### [[2109.07049] Self-Training with Differentiable Teacher](http://arxiv.org/abs/2109.07049)


  Self-training achieves enormous success in various semi-supervised and
weakly-supervised learning tasks. The method can be interpreted as a
teacher-student framework, where the teacher generates pseudo-labels, and the
student makes predictions. The two models are updated alternatingly. However,
such a straightforward alternating update rule leads to training instability.
This is because a small change in the teacher may result in a significant
change in the student. To address this issue, we propose {\ours}, short for
differentiable self-training, that treats teacher-student as a Stackelberg
game. In this game, a leader is always in a more advantageous position than a
follower. In self-training, the student contributes to the prediction
performance, and the teacher controls the training process by generating
pseudo-labels. Therefore, we treat the student as the leader and the teacher as
the follower. The leader procures its advantage by acknowledging the follower's
strategy, which involves differentiable pseudo-labels and differentiable sample
weights. Consequently, the leader-follower interaction can be effectively
captured via Stackelberg gradient, obtained by differentiating the follower's
strategy. Experimental results on semi- and weakly-supervised classification
and named entity recognition tasks show that our model outperforms existing
approaches by large margins.

    

### [[2109.07054] Convergence of a Human-in-the-Loop Policy-Gradient Algorithm With Eligibility Trace Under Reward, Policy, and Advantage Feedback](http://arxiv.org/abs/2109.07054)


  Fluid human-agent communication is essential for the future of
human-in-the-loop reinforcement learning. An agent must respond appropriately
to feedback from its human trainer even before they have significant experience
working together. Therefore, it is important that learning agents respond well
to various feedback schemes human trainers are likely to provide. This work
analyzes the COnvergent Actor-Critic by Humans (COACH) algorithm under three
different types of feedback-policy feedback, reward feedback, and advantage
feedback. For these three feedback types, we find that COACH can behave
sub-optimally. We propose a variant of COACH, episodic COACH (E-COACH), which
we prove converges for all three types. We compare our COACH variant with two
other reinforcement-learning algorithms: Q-learning and TAMER.

    

### [[2109.07069] F-CAM: Full Resolution CAM via Guided Parametric Upscaling](http://arxiv.org/abs/2109.07069)


  Class Activation Mapping (CAM) methods have recently gained much attention
for weakly-supervised object localization (WSOL) tasks, allowing for CNN
visualization and interpretation without training on fully annotated image
datasets. CAM methods are typically integrated within off-the-shelf CNN
backbones, such as ResNet50. Due to convolution and downsampling/pooling
operations, these backbones yield low resolution CAMs with a down-scaling
factor of up to 32, making accurate localization more difficult. Interpolation
is required to restore a full size CAMs, but without considering the
statistical properties of the objects, leading to activations with inconsistent
boundaries and inaccurate localizations. As an alternative, we introduce a
generic method for parametric upscaling of CAMs that allows constructing
accurate full resolution CAMs (F-CAMs). In particular, we propose a trainable
decoding architecture that can be connected to any CNN classifier to produce
more accurate CAMs. Given an original (low resolution) CAM, foreground and
background pixels are randomly sampled for fine-tuning the decoder. Additional
priors such as image statistics, and size constraints are also considered to
expand and refine object boundaries. Extensive experiments using three CNN
backbones and six WSOL baselines on the CUB-200-2011 and OpenImages datasets,
indicate that our F-CAM method yields a significant improvement in CAM
localization accuracy. F-CAM performance is competitive with state-of-art WSOL
methods, yet it requires fewer computational resources during inference.

    

### [[2109.07103] Automatic Symmetry Discovery with Lie Algebra Convolutional Network](http://arxiv.org/abs/2109.07103)


  Existing equivariant neural networks for continuous groups require
discretization or group representations. All these approaches require detailed
knowledge of the group parametrization and cannot learn entirely new
symmetries. We propose to work with the Lie algebra (infinitesimal generators)
instead of the Lie group.Our model, the Lie algebra convolutional network
(L-conv) can learn potential symmetries and does not require discretization of
the group. We show that L-conv can serve as a building block to construct any
group equivariant architecture. We discuss how CNNs and Graph Convolutional
Networks are related to and can be expressed as L-conv with appropriate groups.
We also derive the MSE loss for a single L-conv layer and find a deep relation
with Lagrangians used in physics, with some of the physics aiding in defining
generalization and symmetries in the loss landscape. Conversely, L-conv could
be used to propose more general equivariant ansätze for scientific machine
learning.

    

### [[2109.07106] WIP: Medical Incident Prediction Through Analysis of Electronic Medical Records Using Machine Lerning: Fall Prediction](http://arxiv.org/abs/2109.07106)


  This paper reports our preliminary work on medical incident prediction in
general, and fall risk prediction in specific, using machine learning. Data for
the machine learning are generated only from the particular subset of the
electronic medical records (EMR) at Osaka Medical and Pharmaceutical University
Hospital. As a result of conducting three experiments such as (1) machine
learning algorithm comparison, (2) handling imbalance, and (3) investigation of
explanatory variable contribution to the fall incident prediction, we find the
investigation of explanatory variables the most effective.

    

### [[2109.07117] Non-Asymptotic Analysis of Stochastic Approximation Algorithms for Streaming Data](http://arxiv.org/abs/2109.07117)


  Motivated by the high-frequency data streams continuously generated,
real-time learning is becoming increasingly important. These data streams
should be processed sequentially with the property that the stream may change
over time. In this streaming setting, we propose techniques for minimizing a
convex objective through unbiased estimates of its gradients, commonly referred
to as stochastic approximation problems. Our methods rely on stochastic
approximation algorithms due to their computationally advantage as they only
use the previous iterate as a parameter estimate. The reasoning includes
iterate averaging that guarantees optimal statistical efficiency under
classical conditions. Our non-asymptotic analysis shows accelerated convergence
by selecting the learning rate according to the expected data streams. We show
that the average estimate converges optimally and robustly to any data stream
rate. In addition, noise reduction can be achieved by processing the data in a
specific pattern, which is advantageous for large-scale machine learning. These
theoretical results are illustrated for various data streams, showing the
effectiveness of the proposed algorithms.

    

### [[2109.07129] What Does The User Want? Information Gain for Hierarchical Dialogue Policy Optimisation](http://arxiv.org/abs/2109.07129)


  The dialogue management component of a task-oriented dialogue system is
typically optimised via reinforcement learning (RL). Optimisation via RL is
highly susceptible to sample inefficiency and instability. The hierarchical
approach called Feudal Dialogue Management takes a step towards more efficient
learning by decomposing the action space. However, it still suffers from
instability due to the reward only being provided at the end of the dialogue.
We propose the usage of an intrinsic reward based on information gain to
address this issue. Our proposed reward favours actions that resolve
uncertainty or query the user whenever necessary. It enables the policy to
learn how to retrieve the users' needs efficiently, which is an integral aspect
in every task-oriented conversation. Our algorithm, which we call FeudalGain,
achieves state-of-the-art results in most environments of the PyDial framework,
outperforming much more complex approaches. We confirm the sample efficiency
and stability of our algorithm through experiments in simulation and a human
trial.

    

### [[2109.07132] Parallel Constraint-Driven Inductive Logic Programming](http://arxiv.org/abs/2109.07132)


  Multi-core machines are ubiquitous. However, most inductive logic programming
(ILP) approaches use only a single core, which severely limits their
scalability. To address this limitation, we introduce parallel techniques based
on constraint-driven ILP where the goal is to accumulate constraints to
restrict the hypothesis space. Our experiments on two domains (program
synthesis and inductive general game playing) show that (i) parallelisation can
substantially reduce learning times, and (ii) worker communication (i.e.
sharing constraints) is important for good performance.

    

### [[2109.07137] Optimal Cycling of a Heterogenous Battery Bank via Reinforcement Learning](http://arxiv.org/abs/2109.07137)


  We consider the problem of optimal charging/discharging of a bank of
heterogenous battery units, driven by stochastic electricity generation and
demand processes. The batteries in the battery bank may differ with respect to
their capacities, ramp constraints, losses, as well as cycling costs. The goal
is to minimize the degradation costs associated with battery cycling in the
long run; this is posed formally as a Markov decision process. We propose a
linear function approximation based Q-learning algorithm for learning the
optimal solution, using a specially designed class of kernel functions that
approximate the structure of the value functions associated with the MDP. The
proposed algorithm is validated via an extensive case study.

    

### [[2109.07142] Universal Adversarial Attack on Deep Learning Based Prognostics](http://arxiv.org/abs/2109.07142)


  Deep learning-based time series models are being extensively utilized in
engineering and manufacturing industries for process control and optimization,
asset monitoring, diagnostic and predictive maintenance. These models have
shown great improvement in the prediction of the remaining useful life (RUL) of
industrial equipment but suffer from inherent vulnerability to adversarial
attacks. These attacks can be easily exploited and can lead to catastrophic
failure of critical industrial equipment. In general, different adversarial
perturbations are computed for each instance of the input data. This is,
however, difficult for the attacker to achieve in real time due to higher
computational requirement and lack of uninterrupted access to the input data.
Hence, we present the concept of universal adversarial perturbation, a special
imperceptible noise to fool regression based RUL prediction models. Attackers
can easily utilize universal adversarial perturbations for real-time attack
since continuous access to input data and repetitive computation of adversarial
perturbations are not a prerequisite for the same. We evaluate the effect of
universal adversarial attacks using NASA turbofan engine dataset. We show that
addition of universal adversarial perturbation to any instance of the input
data increases error in the output predicted by the model. To the best of our
knowledge, we are the first to study the effect of the universal adversarial
perturbation on time series regression models. We further demonstrate the
effect of varying the strength of perturbations on RUL prediction models and
found that model accuracy decreases with the increase in perturbation strength
of the universal adversarial attack. We also showcase that universal
adversarial perturbation can be transferred across different models.

    

### [[2109.07143] Spline-PINN: Approaching PDEs without Data using Fast, Physics-Informed Hermite-Spline CNNs](http://arxiv.org/abs/2109.07143)


  Partial Differential Equations (PDEs) are notoriously difficult to solve. In
general, closed-form solutions are not available and numerical approximation
schemes are computationally expensive. In this paper, we propose to approach
the solution of PDEs based on a novel technique that combines the advantages of
two recently emerging machine learning based approaches. First,
physics-informed neural networks (PINNs) learn continuous solutions of PDEs and
can be trained with little to no ground truth data. However, PINNs do not
generalize well to unseen domains. Second, convolutional neural networks
provide fast inference and generalize but either require large amounts of
training data or a physics-constrained loss based on finite differences that
can lead to inaccuracies and discretization artifacts. We leverage the
advantages of both of these approaches by using Hermite spline kernels in order
to continuously interpolate a grid-based state representation that can be
handled by a CNN. This allows for training without any precomputed training
data using a physics-informed loss function only and provides fast, continuous
solutions that generalize to unseen domains. We demonstrate the potential of
our method at the examples of the incompressible Navier-Stokes equation and the
damped wave equation. Our models are able to learn several intriguing phenomena
such as Karman vortex streets, the Magnus effect, Doppler effect, interference
patterns and wave reflections. Our quantitative assessment and an interactive
real-time demo show that we are narrowing the gap in accuracy of unsupervised
ML based methods to industrial CFD solvers while being orders of magnitude
faster.

    

### [[2109.07149] Fusion with Hierarchical Graphs for Mulitmodal Emotion Recognition](http://arxiv.org/abs/2109.07149)


  Automatic emotion recognition (AER) based on enriched multimodal inputs,
including text, speech, and visual clues, is crucial in the development of
emotionally intelligent machines. Although complex modality relationships have
been proven effective for AER, they are still largely underexplored because
previous works predominantly relied on various fusion mechanisms with simply
concatenated features to learn multimodal representations for emotion
classification. This paper proposes a novel hierarchical fusion graph
convolutional network (HFGCN) model that learns more informative multimodal
representations by considering the modality dependencies during the feature
fusion procedure. Specifically, the proposed model fuses multimodality inputs
using a two-stage graph construction approach and encodes the modality
dependencies into the conversation representation. We verified the
interpretable capabilities of the proposed method by projecting the emotional
states to a 2D valence-arousal (VA) subspace. Extensive experiments showed the
effectiveness of our proposed model for more accurate AER, which yielded
state-of-the-art results on two public datasets, IEMOCAP and MELD.

    

### [[2109.07170] Powered Hawkes-Dirichlet Process: Challenging Textual Clustering using a Flexible Temporal Prior](http://arxiv.org/abs/2109.07170)


  The textual content of a document and its publication date are intertwined.
For example, the publication of a news article on a topic is influenced by
previous publications on similar issues, according to underlying temporal
dynamics. However, it can be challenging to retrieve meaningful information
when textual information conveys little information or when temporal dynamics
are hard to unveil. Furthermore, the textual content of a document is not
always linked to its temporal dynamics. We develop a flexible method to create
clusters of textual documents according to both their content and publication
time, the Powered Dirichlet-Hawkes process (PDHP). We show PDHP yields
significantly better results than state-of-the-art models when temporal
information or textual content is weakly informative. The PDHP also alleviates
the hypothesis that textual content and temporal dynamics are always perfectly
correlated. PDHP allows retrieving textual clusters, temporal clusters, or a
mixture of both with high accuracy when they are not. We demonstrate that PDHP
generalizes previous work --such as the Dirichlet-Hawkes process (DHP) and
Uniform process (UP). Finally, we illustrate the changes induced by PDHP over
DHP and UP in a real-world application using Reddit data.

    

### [[2109.07171] Balancing detectability and performance of attacks on the control channel of Markov Decision Processes](http://arxiv.org/abs/2109.07171)


  We investigate the problem of designing optimal stealthy poisoning attacks on
the control channel of Markov decision processes (MDPs). This research is
motivated by the recent interest of the research community for adversarial and
poisoning attacks applied to MDPs, and reinforcement learning (RL) methods. The
policies resulting from these methods have been shown to be vulnerable to
attacks perturbing the observations of the decision-maker. In such an attack,
drawing inspiration from adversarial examples used in supervised learning, the
amplitude of the adversarial perturbation is limited according to some norm,
with the hope that this constraint will make the attack imperceptible. However,
such constraints do not grant any level of undetectability and do not take into
account the dynamic nature of the underlying Markov process. In this paper, we
propose a new attack formulation, based on information-theoretical quantities,
that considers the objective of minimizing the detectability of the attack as
well as the performance of the controlled process. We analyze the trade-off
between the efficiency of the attack and its detectability. We conclude with
examples and numerical simulations illustrating this trade-off.

    

### [[2109.07177] Adversarial Mixing Policy for Relaxing Locally Linear Constraints in Mixup](http://arxiv.org/abs/2109.07177)


  Mixup is a recent regularizer for current deep classification networks.
Through training a neural network on convex combinations of pairs of examples
and their labels, it imposes locally linear constraints on the model's input
space. However, such strict linear constraints often lead to under-fitting
which degrades the effects of regularization. Noticeably, this issue is getting
more serious when the resource is extremely limited. To address these issues,
we propose the Adversarial Mixing Policy (AMP), organized in a min-max-rand
formulation, to relax the Locally Linear Constraints in Mixup. Specifically,
AMP adds a small adversarial perturbation to the mixing coefficients rather
than the examples. Thus, slight non-linearity is injected in-between the
synthetic examples and synthetic labels. By training on these data, the deep
networks are further regularized, and thus achieve a lower predictive error
rate. Experiments on five text classification benchmarks and five backbone
models have empirically shown that our methods reduce the error rate over Mixup
variants in a significant margin (up to 31.3%), especially in low-resource
conditions (up to 17.5%).

    

### [[2109.07180] Back to Basics: Deep Reinforcement Learning in Traffic Signal Control](http://arxiv.org/abs/2109.07180)


  In this paper we revisit some of the fundamental premises for a reinforcement
learning (RL) approach to self-learning traffic lights. We propose RLight, a
combination of choices that offers robust performance and good generalization
to unseen traffic flows. In particular, our main contributions are threefold:
our lightweight and cluster-aware state representation leads to improved
performance; we reformulate the MDP such that it skips redundant timesteps of
yellow light, speeding up learning by 30%; and we investigate the action space
and provide insight into the difference in performance between acyclic and
cyclic phase transitions. Additionally, we provide insights into the
generalisation of the methods to unseen traffic. Evaluations using the
real-world Hangzhou traffic dataset show that RLight outperforms
state-of-the-art rule-based and deep reinforcement learning algorithms,
demonstrating the potential of RL-based methods to improve urban traffic flows.

    

### [[2109.07211] Risk Measurement, Risk Entropy, and Autonomous Driving Risk Modeling](http://arxiv.org/abs/2109.07211)


  It has been for a long time to use big data of autonomous vehicles for
perception, prediction, planning, and control of driving. Naturally, it is
increasingly questioned why not using this big data for risk management and
actuarial modeling. This article examines the emerging technical difficulties,
new ideas, and methods of risk modeling under autonomous driving scenarios.
Compared with the traditional risk model, the novel model is more consistent
with the real road traffic and driving safety performance. More importantly, it
provides technical feasibility for realizing risk assessment and car insurance
pricing under a computer simulation environment.

    

### [[2109.07222] {E}fficient{BERT}: Progressively Searching Multilayer Perceptron via Warm-up Knowledge Distillation](http://arxiv.org/abs/2109.07222)


  Pre-trained language models have shown remarkable results on various NLP
tasks. Nevertheless, due to their bulky size and slow inference speed, it is
hard to deploy them on edge devices. In this paper, we have a critical insight
that improving the feed-forward network (FFN) in BERT has a higher gain than
improving the multi-head attention (MHA) since the computational cost of FFN is
2$\sim$3 times larger than MHA. Hence, to compact BERT, we are devoted to
designing efficient FFN as opposed to previous works that pay attention to MHA.
Since FFN comprises a multilayer perceptron (MLP) that is essential in BERT
optimization, we further design a thorough search space towards an advanced MLP
and perform a coarse-to-fine mechanism to search for an efficient BERT
architecture. Moreover, to accelerate searching and enhance model
transferability, we employ a novel warm-up knowledge distillation strategy at
each search stage. Extensive experiments show our searched EfficientBERT is
6.9$\times$ smaller and 4.4$\times$ faster than BERT$\rm_{BASE}$, and has
competitive performances on GLUE and SQuAD Benchmarks. Concretely,
EfficientBERT attains a 77.7 average score on GLUE \emph{test}, 0.7 higher than
MobileBERT$\rm_{TINY}$, and achieves an 85.3/74.5 F1 score on SQuAD v1.1/v2.0
\emph{dev}, 3.2/2.7 higher than TinyBERT$_4$ even without data augmentation.
The code is released at this https URL.

    

### [[2109.07230] Learning Mathematical Properties of Integers](http://arxiv.org/abs/2109.07230)


  Embedding words in high-dimensional vector spaces has proven valuable in many
natural language applications. In this work, we investigate whether
similarly-trained embeddings of integers can capture concepts that are useful
for mathematical applications. We probe the integer embeddings for mathematical
knowledge, apply them to a set of numerical reasoning tasks, and show that by
learning the representations from mathematical sequence data, we can
substantially improve over number embeddings learned from English text corpora.

    

### [[2109.07239] Internet of Behavior (IoB) and Explainable AI Systems for Influencing IoT Behavior](http://arxiv.org/abs/2109.07239)


  Pandemics and natural disasters over the years have changed the behavior of
people, which has had a tremendous impact on all life aspects. With the
technologies available in each era, governments, organizations, and companies
have used these technologies to track, control, and influence the behavior of
individuals for a benefit. Nowadays, the use of the Internet of Things (IoT),
cloud computing, and artificial intelligence (AI) have made it easier to track
and change the behavior of users through changing IoT behavior. This article
introduces and discusses the concept of the Internet of Behavior (IoB) and its
integration with Explainable AI (XAI) techniques to provide trusted and evident
experience in the process of changing IoT behavior to ultimately improving
users' behavior. Therefore, a system based on IoB and XAI has been proposed in
a use case scenario of electrical power consumption that aims to influence user
consuming behavior to reduce power consumption and cost. The scenario results
showed a decrease of 522.2 kW of active power when compared to original
consumption over a 200-hours period. It also showed a total power cost saving
of 95.04 Euro for the same period. Moreover, decreasing the global active power
will reduce the power intensity through the positive correlation.

    

### [[2109.07253] Integrating Sensing and Communication in Cellular Networks via NR Sidelink](http://arxiv.org/abs/2109.07253)


  RF-sensing, the analysis and interpretation of movement or
environment-induced patterns in received electromagnetic signals, has been
actively investigated for more than a decade. Since electromagnetic signals,
through cellular communication systems, are omnipresent, RF sensing has the
potential to become a universal sensing mechanism with applications in smart
home, retail, localization, gesture recognition, intrusion detection, etc.
Specifically, existing cellular network installations might be dual-used for
both communication and sensing. Such communications and sensing convergence is
envisioned for future communication networks. We propose the use of NR-sidelink
direct device-to-device communication to achieve device-initiated,flexible
sensing capabilities in beyond 5G cellular communication systems. In this
article, we specifically investigate a common issue related to sidelink-based
RF-sensing, which is its angle and rotation dependence. In particular, we
discuss transformations of mmWave point-cloud data which achieve rotational
invariance, as well as distributed processing based on such rotational
invariant inputs, at angle and distance diverse devices. To process the
distributed data, we propose a graph based encoder to capture spatio-temporal
features of the data and propose four approaches for multi-angle learning. The
approaches are compared on a newly recorded and openly available dataset
comprising 15 subjects, performing 21 gestures which are recorded from 8
angles.

    

### [[2109.07258] Federated Learning of Molecular Properties in a Heterogeneous Setting](http://arxiv.org/abs/2109.07258)


  Chemistry research has both high material and computational costs to conduct
experiments. Institutions thus consider chemical data to be valuable and there
have been few efforts to construct large public datasets for machine learning.
Another challenge is that different intuitions are interested in different
classes of molecules, creating heterogeneous data that cannot be easily joined
by conventional distributed training. In this work, we introduce federated
heterogeneous molecular learning to address these challenges. Federated
learning allows end-users to build a global model collaboratively while
preserving the training data distributed over isolated clients. Due to the lack
of related research, we first simulate a federated heterogeneous benchmark
called FedChem. FedChem is constructed by jointly performing scaffold splitting
and Latent Dirichlet Allocation on existing datasets. Our results on FedChem
show that significant learning challenges arise when working with heterogeneous
molecules. We then propose a method to alleviate the problem, namely Federated
Learning by Instance reweighTing (FLIT). FLIT can align the local training
across heterogeneous clients by improving the performance for uncertain
samples. Comprehensive experiments conducted on our new benchmark FedChem
validate the advantages of this method over other federated learning schemes.
FedChem should enable a new type of collaboration for improving AI in chemistry
that mitigates concerns about valuable chemical data.

    

### [[2109.07259] Evolutionary Reinforcement Learning Dynamics with Irreducible Environmental Uncertainty](http://arxiv.org/abs/2109.07259)


  In this work we derive and present evolutionary reinforcement learning
dynamics in which the agents are irreducibly uncertain about the current state
of the environment. We evaluate the dynamics across different classes of
partially observable agent-environment systems and find that irreducible
environmental uncertainty can lead to better learning outcomes faster,
stabilize the learning process and overcome social dilemmas. However, as
expected, we do also find that partial observability may cause worse learning
outcomes, for example, in the form of a catastrophic limit cycle. Compared to
fully observant agents, learning with irreducible environmental uncertainty
often requires more exploration and less weight on future rewards to obtain the
best learning outcomes. Furthermore, we find a range of dynamical effects
induced by partial observability, e.g., a critical slowing down of the learning
processes between reward regimes and the separation of the learning dynamics
into fast and slow directions. The presented dynamics are a practical tool for
researchers in biology, social science and machine learning to systematically
investigate the evolutionary effects of environmental uncertainty.

    

### [[2109.07263] End-to-End Learning of Flowchart Grounded Task-Oriented Dialogs](http://arxiv.org/abs/2109.07263)


  We propose a novel problem within end-to-end learning of task-oriented
dialogs (TOD), in which the dialog system mimics a troubleshooting agent who
helps a user by diagnosing their problem (e.g., car not starting). Such dialogs
are grounded in domain-specific flowcharts, which the agent is supposed to
follow during the conversation. Our task exposes novel technical challenges for
neural TOD, such as grounding an utterance to the flowchart without explicit
annotation, referring to additional manual pages when user asks a clarification
question, and ability to follow unseen flowcharts at test time. We release a
dataset (FloDial) consisting of 2,738 dialogs grounded on 12 different
troubleshooting flowcharts. We also design a neural model, FloNet, which uses a
retrieval-augmented generation architecture to train the dialog agent. Our
experiments find that FloNet can do zero-shot transfer to unseen flowcharts,
and sets a strong baseline for future research.

    

### [[2109.07266] Modelling Major Disease Outbreaks in the 21st Century: A Causal Approach](http://arxiv.org/abs/2109.07266)


  Epidemiologists aiming to model the dynamics of global events face a
significant challenge in identifying the factors linked with anomalies such as
disease outbreaks. In this paper, we present a novel method for identifying the
most important development sectors sensitive to disease outbreaks by using
global development indicators as markers. We use statistical methods to assess
the causative linkages between these indicators and disease outbreaks, as well
as to find the most often ranked indicators. We used data imputation techniques
in addition to statistical analysis to convert raw real-world data sets into
meaningful data for causal inference. The application of various algorithms for
the detection of causal linkages between the indicators is the subject of this
research. Despite the fact that disparities in governmental policies between
countries account for differences in causal linkages, several indicators emerge
as important determinants sensitive to disease outbreaks over the world in the
21st Century.

    

### [[2109.07273] NBcoded: network attack classifiers based on Encoder and Naive Bayes model for resource limited devices](http://arxiv.org/abs/2109.07273)


  In the recent years, cybersecurity has gained high relevance, converting the
detection of attacks or intrusions into a key task. In fact, a small breach in
a system, application, or network, can cause huge damage for the companies.
However, when this attack detection encounters the Artificial Intelligence
paradigm, it can be addressed using high-quality classifiers which often need
high resource demands in terms of computation or memory usage. This situation
has a high impact when the attack classifiers need to be used with limited
resourced devices or without overloading the performance of the devices, as it
happens for example in IoT devices, or in industrial systems. For overcoming
this issue, NBcoded, a novel light attack classification tool is proposed in
this work. NBcoded works in a pipeline combining the removal of noisy data
properties of the encoders with the low resources and timing consuming obtained
by the Naive Bayes classifier. This work compares three different NBcoded
implementations based on three different Naive Bayes likelihood distribution
assumptions (Gaussian, Complement and Bernoulli). Then, the best NBcoded is
compared with state of the art classifiers like Multilayer Perceptron and
Random Forest. Our implementation shows to be the best model reducing the
impact of training time and disk usage, even if it is outperformed by the other
two in terms of Accuracy and F1-score (~ 2%).

    

### [[2109.07275] DROMO: Distributionally Robust Offline Model-based Policy Optimization](http://arxiv.org/abs/2109.07275)


  We consider the problem of offline reinforcement learning with model-based
control, whose goal is to learn a dynamics model from the experience replay and
obtain a pessimism-oriented agent under the learned model. Current model-based
constraint includes explicit uncertainty penalty and implicit conservative
regularization that pushes Q-values of out-of-distribution state-action pairs
down and the in-distribution up. While the uncertainty estimation, on which the
former relies on, can be loosely calibrated for complex dynamics, the latter
performs slightly better. To extend the basic idea of regularization without
uncertainty quantification, we propose distributionally robust offline
model-based policy optimization (DROMO), which leverages the ideas in
distributionally robust optimization to penalize a broader range of
out-of-distribution state-action pairs beyond the standard empirical
out-of-distribution Q-value minimization. We theoretically show that our method
optimizes a lower bound on the ground-truth policy evaluation, and it can be
incorporated into any existing policy gradient algorithms. We also analyze the
theoretical properties of DROMO's linear and non-linear instantiations.

    

### [[2109.07277] Photon detection probability prediction using one-dimensional generative neural network](http://arxiv.org/abs/2109.07277)


  Photon detection is important for liquid argon detectors for direct dark
matter searches or neutrino property measurements. Precise simulation of photon
transport is widely used to understand the probability of photon detection in
liquid argon detectors. Traditional photon transport simulation, which tracks
every photon using theGeant4simulation toolkit, is a major computational
challenge for kilo-tonne-scale liquid argon detectors and GeV-level energy
depositions. In this work, we propose a one-dimensional generative model which
efficiently generates features using an OuterProduct-layer. This model bypasses
photon transport simulation and predicts the number of photons detected by
particular photon detectors at the same level of detail as theGeant4simulation.
The application to simulating photon detection systems in kilo-tonne-scale
liquid argon detectors demonstrates this novel generative model is able to
reproduceGeant4simulation with good accuracy and 20 to 50 times faster. This
generative model can be used to quickly predict photon detection probability in
huge liquid argon detectors like ProtoDUNE or DUNE.

    

### [[2109.07284] Quantitative reconstruction of defects in multi-layered bonded composites using fully convolutional network-based ultrasonic inversion](http://arxiv.org/abs/2109.07284)


  Ultrasonic methods have great potential applications to detect and
characterize defects in multi-layered bonded composites. However, it remains
challenging to quantitatively reconstruct defects, such as disbonds and kissing
bonds, that influence the integrity of adhesive bonds and seriously reduce the
strength of assemblies. In this work, an ultrasonic method based on the
supervised fully convolutional network (FCN) is proposed to quantitatively
reconstruct defects hidden in multi-layered bonded composites. In the training
process of this method, an FCN establishes a non-linear mapping from measured
ultrasonic data to the corresponding velocity models of multi-layered bonded
composites. In the predicting process, the trained network obtained from the
training process is used to directly reconstruct the velocity models from the
new measured ultrasonic data of adhesively bonded composites. The presented
FCN-based inversion method can automatically extract useful features in
multi-layered composites. Although this method is computationally expensive in
the training process, the prediction itself in the online phase takes only
seconds. The numerical results show that the FCN-based ultrasonic inversion
method is capable to accurately reconstruct ultrasonic velocity models of the
high contrast defects, which has great potential for online detection of
adhesively bonded composites.

    

### [[2109.07319] Embedding Convolutions for Short Text Extreme Classification with Millions of Labels](http://arxiv.org/abs/2109.07319)


  Automatic annotation of short-text data to a large number of target labels,
referred to as Short Text Extreme Classification, has recently found numerous
applications in prediction of related searches and product recommendation
tasks. The conventional usage of Convolutional Neural Network (CNN) to capture
n-grams in text-classification relies heavily on uniformity in word-ordering
and the presence of long input sequences to convolve over. However, this is
missing in short and unstructured text sequences encountered in search and
recommendation. In order to tackle this, we propose an orthogonal approach by
recasting the convolution operation to capture coupled semantics along the
embedding dimensions, and develop a word-order agnostic embedding enhancement
module to deal with the lack of structure in such queries. Benefitting from the
computational efficiency of the convolution operation, Embedding Convolutions,
when applied on the enriched word embeddings, result in a light-weight and yet
powerful encoder (InceptionXML) that is robust to the inherent lack of
structure in short-text extreme classification.
Towards scaling our model to problems with millions of labels, we also
propose InceptionXML+, which addresses the shortcomings of the dynamic
hard-negative mining framework in the recently proposed LightXML by improving
the alignment between the label-shortlister and extreme classifier. On popular
benchmark datasets, we empirically demonstrate that the proposed method
outperforms state-of-the-art deep extreme classifiers such as Astec by an
average of 5% and 8% on the P@k and propensity-scored PSP@k metrics
respectively.

    

### [[2109.07321] PoWareMatch: a Quality-aware Deep Learning Approach to Improve Human Schema Matching](http://arxiv.org/abs/2109.07321)


  Schema matching is a core task of any data integration process. Being
investigated in the fields of databases, AI, Semantic Web and data mining for
many years, the main challenge remains the ability to generate quality matches
among data concepts (e.g., database attributes). In this work, we examine a
novel angle on the behavior of humans as matchers, studying match creation as a
process. We analyze the dynamics of common evaluation measures (precision,
recall, and f-measure), with respect to this angle and highlight the need for
unbiased matching to support this analysis. Unbiased matching, a newly defined
concept that describes the common assumption that human decisions represent
reliable assessments of schemata correspondences, is, however, not an inherent
property of human matchers. In what follows, we design PoWareMatch that makes
use of a deep learning mechanism to calibrate and filter human matching
decisions adhering the quality of a match, which are then combined with
algorithmic matching to generate better match results. We provide an empirical
evidence, established based on an experiment with more than 200 human matchers
over common benchmarks, that PoWareMatch predicts well the benefit of extending
the match with an additional correspondence and generates high quality matches.
In addition, PoWareMatch outperforms state-of-the-art matching algorithms.

    

### [[2109.07322] DeFungi: Direct Mycological Examination of Microscopic Fungi Images](http://arxiv.org/abs/2109.07322)


  Traditionally, diagnosis and treatment of fungal infections in humans depend
heavily on face-to-face consultations or examinations made by specialized
laboratory scientists known as mycologists. In many cases, such as the recent
mucormycosis spread in the COVID-19 pandemic, an initial treatment can be
safely suggested to the patient during the earliest stage of the mycological
diagnostic process by performing a direct examination of biopsies or samples
through a microscope. Computer-aided diagnosis systems using deep learning
models have been trained and used for the late mycological diagnostic stages.
However, there are no reference literature works made for the early stages. A
mycological laboratory in Colombia donated the images used for the development
of this research work. They were manually labelled into five classes and
curated with a subject matter expert assistance. The images were later cropped
and patched with automated code routines to produce the final dataset. This
paper presents experimental results classifying five fungi types using two
different deep learning approaches and three different convolutional neural
network models, VGG16, Inception V3, and ResNet50. The first approach
benchmarks the classification performance for the models trained from scratch,
while the second approach benchmarks the classification performance using
pre-trained models based on the ImageNet dataset. Using k-fold cross-validation
testing on the 5-class dataset, the best performing model trained from scratch
was Inception V3, reporting 73.2% accuracy. Also, the best performing model
using transfer learning was VGG16 reporting 85.04%. The statistics provided by
the two approaches create an initial point of reference to encourage future
research works to improve classification performance. Furthermore, the dataset
built is published in Kaggle and GitHub to foster future research.

    

### [[2109.07323] FORTAP: Using Formulae for Numerical-Reasoning-Aware Table Pretraining](http://arxiv.org/abs/2109.07323)


  Tables store rich numerical data, but numerical reasoning over tables is
still a challenge. In this paper, we find that the spreadsheet formula, which
performs calculations on numerical values in tables, is naturally a strong
supervision of numerical reasoning. More importantly, large amounts of
spreadsheets with expert-made formulae are available on the web and can be
obtained easily. FORTAP is the first method for numerical-reasoning-aware table
pretraining by leveraging large corpus of spreadsheet formulae. We design two
formula pretraining tasks to explicitly guide FORTAP to learn numerical
reference and calculation in semi-structured tables. FORTAP achieves
state-of-the-art results on two representative downstream tasks, cell type
classification and formula prediction, showing great potential of
numerical-reasoning-aware pretraining.

    

### [[2109.07335] Comparing decision mining approaches with regard to the meaningfulness of their results](http://arxiv.org/abs/2109.07335)


  Decisions and the underlying rules are indispensable for driving process
execution during runtime, i.e., for routing process instances at alternative
branches based on the values of process data. Decision rules can comprise unary
data conditions, e.g., age > 40, binary data conditions where the relation
between two or more variables is relevant, e.g. temperature1 < temperature2,
and more complex conditions that refer to, for example, parts of a medical
image. Decision discovery aims at automatically deriving decision rules from
process event logs. Existing approaches focus on the discovery of unary, or in
some instances binary data conditions. The discovered decision rules are
usually evaluated using accuracy, but not with regards to their semantics and
meaningfulness, although this is crucial for validation and the subsequent
implementation/adaptation of the decision rules. Hence, this paper compares
three decision mining approaches, i.e., two existing ones and one newly
described approach, with respect to the meaningfulness of their results. For
comparison, we use one synthetic data set for a realistic manufacturing case
and the two real-world BPIC 2017/2020 logs. The discovered rules are discussed
with regards to their semantics and meaningfulness.

    

### [[2109.07340] Distribution-free Contextual Dynamic Pricing](http://arxiv.org/abs/2109.07340)


  Contextual dynamic pricing aims to set personalized prices based on
sequential interactions with customers. At each time period, a customer who is
interested in purchasing a product comes to the platform. The customer's
valuation for the product is a linear function of contexts, including product
and customer features, plus some random market noise. The seller does not
observe the customer's true valuation, but instead needs to learn the valuation
by leveraging contextual information and historical binary purchase feedbacks.
Existing models typically assume full or partial knowledge of the random noise
distribution. In this paper, we consider contextual dynamic pricing with
unknown random noise in the valuation model. Our distribution-free pricing
policy learns both the contextual function and the market noise simultaneously.
A key ingredient of our method is a novel perturbed linear bandit framework,
where a modified linear upper confidence bound algorithm is proposed to balance
the exploration of market noise and the exploitation of the current knowledge
for better pricing. We establish the regret upper bound and a matching lower
bound of our policy in the perturbed linear bandit framework and prove a
sub-linear regret bound in the considered pricing problem. Finally, we
demonstrate the superior performance of our policy on simulations and a
real-life auto-loan dataset.

    

### [[2109.07344] The potential of self-supervised networks for random noise suppression in seismic data](http://arxiv.org/abs/2109.07344)


  Noise suppression is an essential step in any seismic processing workflow. A
portion of this noise, particularly in land datasets, presents itself as random
noise. In recent years, neural networks have been successfully used to denoise
seismic data in a supervised fashion. However, supervised learning always comes
with the often unachievable requirement of having noisy-clean data pairs for
training. Using blind-spot networks, we redefine the denoising task as a
self-supervised procedure where the network uses the surrounding noisy samples
to estimate the noise-free value of a central sample. Based on the assumption
that noise is statistically independent between samples, the network struggles
to predict the noise component of the sample due to its randomnicity, whilst
the signal component is accurately predicted due to its spatio-temporal
coherency. Illustrated on synthetic examples, the blind-spot network is shown
to be an efficient denoiser of seismic data contaminated by random noise with
minimal damage to the signal; therefore, providing improvements in both the
image domain and down-the-line tasks, such as inversion. To conclude the study,
the suggested approach is applied to field data and the results are compared
with two commonly used random denoising techniques: FX-deconvolution and
Curvelet transform. By demonstrating that blind-spot networks are an efficient
suppressor of random noise, we believe this is just the beginning of utilising
self-supervised learning in seismic applications.

    

### [[2109.07348] Cross-lingual Transfer of Monolingual Models](http://arxiv.org/abs/2109.07348)


  Recent studies in zero-shot cross-lingual learning using multilingual models
have falsified the previous hypothesis that shared vocabulary and joint
pre-training are the keys to cross-lingual generalization. Inspired by this
advancement, we introduce a cross-lingual transfer method for monolingual
models based on domain adaptation. We study the effects of such transfer from
four different languages to English. Our experimental results on GLUE show that
the transferred models outperform the native English model independently of the
source language. After probing the English linguistic knowledge encoded in the
representations before and after transfer, we find that semantic information is
retained from the source language, while syntactic information is learned
during transfer. Additionally, the results of evaluating the transferred models
in source language tasks reveal that their performance in the source domain
deteriorates after transfer.

    

### [[2109.07359] Modular Neural Ordinary Differential Equations](http://arxiv.org/abs/2109.07359)


  The laws of physics have been written in the language of dif-ferential
equations for centuries. Neural Ordinary Differen-tial Equations (NODEs) are a
new machine learning architecture which allows these differential equations to
be learned from a dataset. These have been applied to classical dynamics
simulations in the form of Lagrangian Neural Net-works (LNNs) and Second Order
Neural Differential Equations (SONODEs). However, they either cannot represent
the most general equations of motion or lack interpretability. In this paper,
we propose Modular Neural ODEs, where each force component is learned with
separate modules. We show how physical priors can be easily incorporated into
these models. Through a number of experiments, we demonstrate these result in
better performance, are more interpretable, and add flexibility due to their
modularity.

    

### [[2109.07371] Self-learn to Explain Siamese Networks Robustly](http://arxiv.org/abs/2109.07371)


  Learning to compare two objects are essential in applications, such as
digital forensics, face recognition, and brain network analysis, especially
when labeled data is scarce and imbalanced. As these applications make
high-stake decisions and involve societal values like fairness and
transparency, it is critical to explain the learned models. We aim to study
post-hoc explanations of Siamese networks (SN) widely used in learning to
compare. We characterize the instability of gradient-based explanations due to
the additional compared object in SN, in contrast to architectures with a
single input instance. We propose an optimization framework that derives global
invariance from unlabeled data using self-learning to promote the stability of
local explanations tailored for specific query-reference pairs. The
optimization problems can be solved using gradient descent-ascent (GDA) for
constrained optimization, or SGD for KL-divergence regularized unconstrained
optimization, with convergence proofs, especially when the objective functions
are nonconvex due to the Siamese architecture. Quantitative results and case
studies on tabular and graph data from neuroscience and chemical engineering
show that the framework respects the self-learned invariance while robustly
optimizing the faithfulness and simplicity of the explanation. We further
demonstrate the convergence of GDA experimentally.

    

### [[2109.07380] DCUR: Data Curriculum for Teaching via Samples with Reinforcement Learning](http://arxiv.org/abs/2109.07380)


  Deep reinforcement learning (RL) has shown great empirical successes, but
suffers from brittleness and sample inefficiency. A potential remedy is to use
a previously-trained policy as a source of supervision. In this work, we refer
to these policies as teachers and study how to transfer their expertise to new
student policies by focusing on data usage. We propose a framework, Data
CUrriculum for Reinforcement learning (DCUR), which first trains teachers using
online deep RL, and stores the logged environment interaction history. Then,
students learn by running either offline RL or by using teacher data in
combination with a small amount of self-generated data. DCUR's central idea
involves defining a class of data curricula which, as a function of training
time, limits the student to sampling from a fixed subset of the full teacher
data. We test teachers and students using state-of-the-art deep RL algorithms
across a variety of data curricula. Results suggest that the choice of data
curricula significantly impacts student learning, and that it is beneficial to
limit the data during early training stages while gradually letting the data
availability grow over time. We identify when the student can learn offline and
match teacher performance without relying on specialized offline RL algorithms.
Furthermore, we show that collecting a small fraction of online data provides
complementary benefits with the data curriculum. Supplementary material is
available at this https URL.

    

### [[2109.07384] How to use KL-divergence to construct conjugate priors, with well-defined non-informative limits, for the multivariate Gaussian](http://arxiv.org/abs/2109.07384)


  The Wishart distribution is the standard conjugate prior for the precision of
the multivariate Gaussian likelihood, when the mean is known -- while the
normal-Wishart can be used when the mean is also unknown. It is however not so
obvious how to assign values to the hyperparameters of these distributions. In
particular, when forming non-informative limits of these distributions, the
shape (or degrees of freedom) parameter of the Wishart must be handled with
care. The intuitive solution of directly interpreting the shape as a
pseudocount and letting it go to zero, as proposed by some authors, violates
the restrictions on the shape parameter. We show how to use the scaled
KL-divergence between multivariate Gaussians as an energy function to construct
Wishart and normal-Wishart conjugate priors. When used as informative priors,
the salient feature of these distributions is the mode, while the KL scaling
factor serves as the pseudocount. The scale factor can be taken down to the
limit at zero, to form non-informative priors that do not violate the
restrictions on the Wishart shape parameter. This limit is non-informative in
the sense that the posterior mode is identical to the maximum likelihood
estimate of the Gaussian likelihood parameters.

    

### [[2109.07395] Can one hear the shape of a neural network?: Snooping the GPU via Magnetic Side Channel](http://arxiv.org/abs/2109.07395)


  Neural network applications have become popular in both enterprise and
personal settings. Network solutions are tuned meticulously for each task, and
designs that can robustly resolve queries end up in high demand. As the
commercial value of accurate and performant machine learning models increases,
so too does the demand to protect neural architectures as confidential
investments. We explore the vulnerability of neural networks deployed as black
boxes across accelerated hardware through electromagnetic side channels. We
examine the magnetic flux emanating from a graphics processing unit's power
cable, as acquired by a cheap $3 induction sensor, and find that this signal
betrays the detailed topology and hyperparameters of a black-box neural network
model. The attack acquires the magnetic signal for one query with unknown input
values, but known input dimensions. The network reconstruction is possible due
to the modular layer sequence in which deep neural networks are evaluated. We
find that each layer component's evaluation produces an identifiable magnetic
signal signature, from which layer topology, width, function type, and sequence
order can be inferred using a suitably trained classifier and a joint
consistency optimization based on integer programming. We study the extent to
which network specifications can be recovered, and consider metrics for
comparing network similarity. We demonstrate the potential accuracy of this
side channel attack in recovering the details for a broad range of network
architectures, including random designs. We consider applications that may
exploit this novel side channel exposure, such as adversarial transfer attacks.
In response, we discuss countermeasures to protect against our method and other
similar snooping techniques.

    

### [[2109.07396] Constraint based Knowledge Base Distillation in End-to-End Task Oriented Dialogs](http://arxiv.org/abs/2109.07396)


  End-to-End task-oriented dialogue systems generate responses based on dialog
history and an accompanying knowledge base (KB). Inferring those KB entities
that are most relevant for an utterance is crucial for response generation.
Existing state of the art scales to large KBs by softly filtering over
irrelevant KB information. In this paper, we propose a novel filtering
technique that consists of (1) a pairwise similarity based filter that
identifies relevant information by respecting the n-ary structure in a KB
record. and, (2) an auxiliary loss that helps in separating contextually
unrelated KB information. We also propose a new metric -- multiset entity F1
which fixes a correctness issue in the existing entity F1 metric. Experimental
results on three publicly available task-oriented dialog datasets show that our
proposed approach outperforms existing state-of-the-art models.

    

### [[2109.07399] Disentangling Generative Factors of Physical Fields Using Variational Autoencoders](http://arxiv.org/abs/2109.07399)


  The ability to extract generative parameters from high-dimensional fields of
data in an unsupervised manner is a highly desirable yet unrealized goal in
computational physics. This work explores the use of variational autoencoders
(VAEs) for non-linear dimension reduction with the aim of disentangling the
low-dimensional latent variables to identify independent physical parameters
that generated the data. A disentangled decomposition is interpretable and can
be transferred to a variety of tasks including generative modeling, design
optimization, and probabilistic reduced order modelling. A major emphasis of
this work is to characterize disentanglement using VAEs while minimally
modifying the classic VAE loss function (i.e. the ELBO) to maintain high
reconstruction accuracy. Disentanglement is shown to be highly sensitive to
rotations of the latent space, hyperparameters, random initializations and the
learning schedule. The loss landscape is characterized by over-regularized
local minima which surrounds desirable solutions. We illustrate comparisons
between disentangled and entangled representations by juxtaposing learned
latent distributions and the 'true' generative factors in a model porous flow
problem. Implementing hierarchical priors (HP) is shown to better facilitate
the learning of disentangled representations over the classic VAE. The choice
of the prior distribution is shown to have a dramatic effect on
disentanglement. In particular, the regularization loss is unaffected by latent
rotation when training with rotationally-invariant priors, and thus learning
non-rotationally-invariant priors aids greatly in capturing the properties of
generative factors, improving disentanglement. Some issues inherent to training
VAEs, such as the convergence to over-regularized local minima are illustrated
and investigated, and potential techniques for mitigation are presented.

    

### [[2109.07401] Matching with Transformers in MELT](http://arxiv.org/abs/2109.07401)


  One of the strongest signals for automated matching of ontologies and
knowledge graphs are the textual descriptions of the concepts. The methods that
are typically applied (such as character- or token-based comparisons) are
relatively simple, and therefore do not capture the actual meaning of the
texts. With the rise of transformer-based language models, text comparison
based on meaning (rather than lexical features) is possible. In this paper, we
model the ontology matching task as classification problem and present
approaches based on transformer models. We further provide an easy to use
implementation in the MELT framework which is suited for ontology and knowledge
graph matching. We show that a transformer-based filter helps to choose the
correct correspondences given a high-recall alignment and already achieves a
good result with simple alignment post-processing methods.

    

### [[2109.07402] Multi View Spatial-Temporal Model for Travel Time Estimation](http://arxiv.org/abs/2109.07402)


  Taxi arrival time prediction is an essential part of building intelligent
transportation systems. Traditional arrival time estimation methods mainly rely
on traffic map feature extraction, which can not model complex situations and
nonlinear spatial and temporal relationships. Therefore, we propose a
Multi-View Spatial-Temporal Model (MVSTM) to capture the dependence of
spatial-temporal and trajectory. Specifically, we use graph2vec to model the
spatial view, dual-channel temporal module to model the trajectory view, and
structural embedding to model the traffic semantics. Experiments on large-scale
taxi trajectory data show that our approach is more effective than the novel
method. The source code can be obtained from
this https URL.

    

### [[2109.07410] Assisting the Human Fact-Checkers: Detecting All Previously Fact-Checked Claims in a Document](http://arxiv.org/abs/2109.07410)


  Given the recent proliferation of false claims online, there has been a lot
of manual fact-checking effort. As this is very time-consuming, human
fact-checkers can benefit from tools that can support them and make them more
efficient. Here, we focus on building a system that could provide such support.
Given an input document, it aims to detect all sentences that contain a claim
that can be verified by some previously fact-checked claims (from a given
database). The output is a re-ranked list of the document sentences, so that
those that can be verified are ranked as high as possible, together with
corresponding evidence. Unlike previous work, which has looked into claim
retrieval, here we take a document-level perspective. We create a new manually
annotated dataset for the task, and we propose suitable evaluation measures. We
further experiment with a learning-to-rank approach, achieving sizable
performance gains over several strong baselines. Our analysis demonstrates the
importance of modeling text similarity and stance, while also taking into
account the veracity of the retrieved previously fact-checked claims. We
believe that this research would be of interest to fact-checkers, journalists,
media, and regulatory authorities.

    

### [[2109.07419] Union: A Unified HW-SW Co-Design Ecosystem in MLIR for Evaluating Tensor Operations on Spatial Accelerators](http://arxiv.org/abs/2109.07419)


  To meet the extreme compute demands for deep learning across commercial and
scientific applications, dataflow accelerators are becoming increasingly
popular. While these "domain-specific" accelerators are not fully programmable
like CPUs and GPUs, they retain varying levels of flexibility with respect to
data orchestration, i.e., dataflow and tiling optimizations to enhance
efficiency. There are several challenges when designing new algorithms and
mapping approaches to execute the algorithms for a target problem on new
hardware. Previous works have addressed these challenges individually. To
address this challenge as a whole, in this work, we present a HW-SW co-design
ecosystem for spatial accelerators called Union within the popular MLIR
compiler infrastructure. Our framework allows exploring different algorithms
and their mappings on several accelerator cost models. Union also includes a
plug-and-play library of accelerator cost models and mappers which can easily
be extended. The algorithms and accelerator cost models are connected via a
novel mapping abstraction that captures the map space of spatial accelerators
which can be systematically pruned based on constraints from the hardware,
workload, and mapper. We demonstrate the value of Union for the community with
several case studies which examine offloading different tensor
operations(CONV/GEMM/Tensor Contraction) on diverse accelerator architectures
using different mapping schemes.

    

### [[2109.07424] SupCL-Seq: Supervised Contrastive Learning for Downstream Optimized Sequence Representations](http://arxiv.org/abs/2109.07424)


  While contrastive learning is proven to be an effective training strategy in
computer vision, Natural Language Processing (NLP) is only recently adopting it
as a self-supervised alternative to Masked Language Modeling (MLM) for
improving sequence representations. This paper introduces SupCL-Seq, which
extends the supervised contrastive learning from computer vision to the
optimization of sequence representations in NLP. By altering the dropout mask
probability in standard Transformer architectures, for every representation
(anchor), we generate augmented altered views. A supervised contrastive loss is
then utilized to maximize the system's capability of pulling together similar
samples (e.g., anchors and their altered views) and pushing apart the samples
belonging to the other classes. Despite its simplicity, SupCLSeq leads to large
gains in many sequence classification tasks on the GLUE benchmark compared to a
standard BERTbase, including 6% absolute improvement on CoLA, 5.4% on MRPC,
4.7% on RTE and 2.6% on STSB. We also show consistent gains over self
supervised contrastively learned representations, especially in non-semantic
tasks. Finally we show that these gains are not solely due to augmentation, but
rather to a downstream optimized sequence representation. Code:
this https URL


### [[2109.07437] Should We Be Pre-training? An Argument for End-task Aware Training as an Alternative](http://arxiv.org/abs/2109.07437)


  Pre-training, where models are trained on an auxiliary objective with
abundant data before being fine-tuned on data from the downstream task, is now
the dominant paradigm in NLP. In general, the pre-training step relies on
little to no direct knowledge of the task on which the model will be
fine-tuned, even when the end-task is known in advance. Our work challenges
this status-quo of end-task agnostic pre-training. First, on three different
low-resource NLP tasks from two domains, we demonstrate that multi-tasking the
end-task and auxiliary objectives results in significantly better downstream
task performance than the widely-used task-agnostic continued pre-training
paradigm of Gururangan et al. (2020). We next introduce an online meta-learning
algorithm that learns a set of multi-task weights to better balance among our
multiple auxiliary objectives, achieving further improvements on end task
performance and data efficiency.

    

### [[2109.07438] CAMul: Calibrated and Accurate Multi-view Time-Series Forecasting](http://arxiv.org/abs/2109.07438)


  Probabilistic time-series forecasting enables reliable decision making across
many domains. Most forecasting problems have diverse sources of data containing
multiple modalities and structures. Leveraging information as well as
uncertainty from these data sources for well-calibrated and accurate forecasts
is an important challenging problem. Most previous work on multi-modal learning
and forecasting simply aggregate intermediate representations from each data
view by simple methods of summation or concatenation and do not explicitly
model uncertainty for each data-view. We propose a general probabilistic
multi-view forecasting framework CAMul, that can learn representations and
uncertainty from diverse data sources. It integrates the knowledge and
uncertainty from each data view in a dynamic context-specific manner assigning
more importance to useful views to model a well-calibrated forecast
distribution. We use CAMul for multiple domains with varied sources and
modalities and show that CAMul outperforms other state-of-art probabilistic
forecasting models by over 25\% in accuracy and calibration.

    

### [[2109.07445] Challenges in Detoxifying Language Models](http://arxiv.org/abs/2109.07445)


  Large language models (LM) generate remarkably fluent text and can be
efficiently adapted across NLP tasks. Measuring and guaranteeing the quality of
generated text in terms of safety is imperative for deploying LMs in the real
world; to this end, prior work often relies on automatic evaluation of LM
toxicity. We critically discuss this approach, evaluate several toxicity
mitigation strategies with respect to both automatic and human evaluation, and
analyze consequences of toxicity mitigation in terms of model bias and LM
quality. We demonstrate that while basic intervention strategies can
effectively optimize previously established automatic metrics on the
RealToxicityPrompts dataset, this comes at the cost of reduced LM coverage for
both texts about, and dialects of, marginalized groups. Additionally, we find
that human raters often disagree with high automatic toxicity scores after
strong toxicity reduction interventions -- highlighting further the nuances
involved in careful evaluation of LM toxicity.

    

### [[2109.07446] When Does Translation Require Context? A Data-driven, Multilingual Exploration](http://arxiv.org/abs/2109.07446)


  Although proper handling of discourse phenomena significantly contributes to
the quality of machine translation (MT), common translation quality metrics do
not adequately capture them. Recent works in context-aware MT attempt to target
a small set of these phenomena during evaluation. In this paper, we propose a
new metric, P-CXMI, which allows us to identify translations that require
context systematically and confirm the difficulty of previously studied
phenomena as well as uncover new ones that have not been addressed in previous
work. We then develop the Multilingual Discourse-Aware (MuDA) benchmark, a
series of taggers for these phenomena in 14 different language pairs, which we
use to evaluate context-aware MT. We find that state-of-the-art context-aware
MT models find marginal improvements over context-agnostic models on our
benchmark, which suggests current models do not handle these ambiguities
effectively. We release code and data to invite the MT research community to
increase efforts on context-aware translation on discourse phenomena and
languages that are currently overlooked.

    

### [[2109.07455] Deep Bregman Divergence for Contrastive Learning of Visual Representations](http://arxiv.org/abs/2109.07455)


  Deep Bregman divergence measures divergence of data points using neural
networks which is beyond Euclidean distance and capable of capturing divergence
over distributions. In this paper, we propose deep Bregman divergences for
contrastive learning of visual representation and we aim to enhance contrastive
loss used in self-supervised learning by training additional networks based on
functional Bregman divergence. In contrast to the conventional contrastive
learning methods which are solely based on divergences between single points,
our framework can capture the divergence between distributions which improves
the quality of learned representation. By combining conventional contrastive
loss with the proposed divergence loss, our method outperforms baseline and
most of previous methods for self-supervised and semi-supervised learning on
multiple classifications and object detection tasks and datasets. The source
code of the method and of all the experiments are available at supplementary.

    

### [[2109.07458] Comparing Text Representations: A Theory-Driven Approach](http://arxiv.org/abs/2109.07458)


  Much of the progress in contemporary NLP has come from learning
representations, such as masked language model (MLM) contextual embeddings,
that turn challenging problems into simple classification tasks. But how do we
quantify and explain this effect? We adapt general tools from computational
learning theory to fit the specific characteristics of text datasets and
present a method to evaluate the compatibility between representations and
tasks. Even though many tasks can be easily solved with simple bag-of-words
(BOW) representations, BOW does poorly on hard natural language inference
tasks. For one such task we find that BOW cannot distinguish between real and
randomized labelings, while pre-trained MLM representations show 72x greater
distinction between real and random labelings than BOW. This method provides a
calibrated, quantitative measure of the difficulty of a classification-based
NLP task, enabling comparisons between representations without requiring
empirical evaluations that may be sensitive to initializations and
hyperparameters. The method provides a fresh perspective on the patterns in a
dataset and the alignment of those patterns with specific labels.

    

### [[2109.07466] Neural network optimal feedback control with enhanced closed loop stability](http://arxiv.org/abs/2109.07466)


  Recent research has shown that supervised learning can be an effective tool
for designing optimal feedback controllers for high-dimensional nonlinear
dynamic systems. But the behavior of these neural network (NN) controllers is
still not well understood. In this paper we use numerical simulations to
demonstrate that typical test accuracy metrics do not effectively capture the
ability of an NN controller to stabilize a system. In particular, some NNs with
high test accuracy can fail to stabilize the dynamics. To address this we
propose two NN architectures which locally approximate a linear quadratic
regulator (LQR). Numerical simulations confirm our intuition that the proposed
architectures reliably produce stabilizing feedback controllers without
sacrificing performance. In addition, we introduce a preliminary theoretical
result describing some stability properties of such NN-controlled systems.

    

### [[1902.02060] On ADMM in Deep Learning: Convergence and Saturation-Avoidance](http://arxiv.org/abs/1902.02060)


  In this paper, we develop an alternating direction method of multipliers
(ADMM) for deep neural networks training with sigmoid-type activation functions
(called \textit{sigmoid-ADMM pair}), mainly motivated by the gradient-free
nature of ADMM in avoiding the saturation of sigmoid-type activations and the
advantages of deep neural networks with sigmoid-type activations (called deep
sigmoid nets) over their rectified linear unit (ReLU) counterparts (called deep
ReLU nets) in terms of approximation. In particular, we prove that the
approximation capability of deep sigmoid nets is not worse than that of deep
ReLU nets by showing that ReLU activation function can be well approximated by
deep sigmoid nets with two hidden layers and finitely many free parameters but
not vice-verse. We also establish the global convergence of the proposed ADMM
for the nonlinearly constrained formulation of the deep sigmoid nets training
from arbitrary initial points to a Karush-Kuhn-Tucker (KKT) point at a rate of
order ${\cal O}(1/k)$. Besides sigmoid activation, such a convergence theorem
holds for a general class of smooth activations. Compared with the widely used
stochastic gradient descent (SGD) algorithm for the deep ReLU nets training
(called ReLU-SGD pair), the proposed sigmoid-ADMM pair is practically stable
with respect to the algorithmic hyperparameters including the learning rate,
initial schemes and the pro-processing of the input data. Moreover, we find
that to approximate and learn simple but important functions the proposed
sigmoid-ADMM pair numerically outperforms the ReLU-SGD pair.

    

### [[1903.01287] Safety Verification and Robustness Analysis of Neural Networks via Quadratic Constraints and Semidefinite Programming](http://arxiv.org/abs/1903.01287)


  Certifying the safety or robustness of neural networks against input
uncertainties and adversarial attacks is an emerging challenge in the area of
safe machine learning and control. To provide such a guarantee, one must be
able to bound the output of neural networks when their input changes within a
bounded set. In this paper, we propose a semidefinite programming (SDP)
framework to address this problem for feed-forward neural networks with general
activation functions and input uncertainty sets. Our main idea is to abstract
various properties of activation functions (e.g., monotonicity, bounded slope,
bounded values, and repetition across layers) with the formalism of quadratic
constraints. We then analyze the safety properties of the abstracted network
via the S-procedure and semidefinite programming. Our framework spans the
trade-off between conservatism and computational efficiency and applies to
problems beyond safety verification. We evaluate the performance of our
approach via numerical problem instances of various sizes.

    

### [[1906.00389] Disparate Vulnerability to Membership Inference Attacks](http://arxiv.org/abs/1906.00389)


  A membership inference attack (MIA) against a machine-learning model enables
an attacker to determine whether a given data record was part of the model's
training data or not. In this paper, we provide an in-depth study of the
phenomenon of disparate vulnerability against MIAs: unequal success rate of
MIAs against different population subgroups. We first establish necessary and
sufficient conditions for MIAs to be prevented, both on average and for
population subgroups, using a notion of distributional generalization. Second,
we derive connections of disparate vulnerability to algorithmic fairness and to
differential privacy. We show that fairness can only prevent disparate
vulnerability against limited classes of adversaries. Differential privacy
bounds disparate vulnerability but can significantly reduce the accuracy of the
model. We show that estimating disparate vulnerability to MIAs by naïvely
applying existing attacks can lead to overestimation. We then establish which
attacks are suitable for estimating disparate vulnerability, and provide a
statistical framework for doing so reliably. We conduct experiments on
synthetic and real-world data finding statistically significant evidence of
disparate vulnerability in realistic settings.

    

### [[1906.03622] On a Combination of Alternating Minimization and Nesterov's Momentum](http://arxiv.org/abs/1906.03622)


  Alternating minimization (AM) procedures are practically efficient in many
applications for solving convex and non-convex optimization problems. On the
other hand, Nesterov's accelerated gradient is theoretically optimal
first-order method for convex optimization. In this paper we combine AM and
Nesterov's acceleration to propose an accelerated alternating minimization
algorithm. We prove $1/k^2$ convergence rate in terms of the objective for
convex problems and $1/k$ in terms of the squared gradient norm for non-convex
problems, where $k$ is the iteration counter. Our method does not require any
knowledge of neither convexity of the problem nor function parameters such as
Lipschitz constant of the gradient, i.e. it is adaptive to convexity and
smoothness and is uniformly optimal for smooth convex and non-convex problems.
Further, we develop its primal-dual modification for strongly convex problems
with linear constraints and prove the same $1/k^2$ for the primal objective
residual and constraints feasibility.

    

### [[1910.08288] Hierarchical Attentive Knowledge Graph Embedding for Personalized Recommendation](http://arxiv.org/abs/1910.08288)


  Knowledge graphs (KGs) have proven to be effective for high-quality
recommendation, where the connectivities between users and items provide rich
and complementary information to user-item interactions. Most existing methods,
however, are insufficient to exploit the KGs for capturing user preferences, as
they either represent the user-item connectivities via paths with limited
expressiveness or implicitly model them by propagating information over the
entire KG with inevitable noise. In this paper, we design a novel hierarchical
attentive knowledge graph embedding (HAKG) framework to exploit the KGs for
effective recommendation. Specifically, HAKG first extracts the expressive
subgraphs that link user-item pairs to characterize their connectivities, which
accommodate both the semantics and topology of KGs. The subgraphs are then
encoded via a hierarchical attentive subgraph encoding to generate effective
subgraph embeddings for enhanced user preference prediction. Extensive
experiments show the superiority of HAKG against state-of-the-art
recommendation methods, as well as its potential in alleviating the data
sparsity issue.

    

### [[2006.07218] An Accurate, Scalable and Verifiable Protocol for Federated Differentially Private Averaging](http://arxiv.org/abs/2006.07218)


  Learning from data owned by several parties, as in federated learning, raises
challenges regarding the privacy guarantees provided to participants and the
correctness of the computation in the presence of malicious parties. We tackle
these challenges in the context of distributed averaging, an essential building
block of federated learning algorithms. Our first contribution is a scalable
protocol in which participants exchange correlated Gaussian noise along the
edges of a network graph, complemented by independent noise added by each
party. We analyze the differential privacy guarantees of our protocol and the
impact of the graph topology under colluding malicious parties, showing that we
can nearly match the utility of the trusted curator model even when each honest
party communicates with only a logarithmic number of other parties chosen at
random. This is in contrast with protocols in the local model of privacy (with
lower utility) or based on secure aggregation (where all pairs of users need to
exchange messages). Our second contribution enables users to prove the
correctness of their computations without compromising the efficiency and
privacy guarantees of the protocol. Our verification protocol relies on
standard cryptographic primitives like commitment schemes and zero knowledge
proofs.

    

### [[2006.08251] Adversarial Weighting for Domain Adaptation in Regression](http://arxiv.org/abs/2006.08251)


  We present a novel instance-based approach to handle regression tasks in the
context of supervised domain adaptation under an assumption of covariate shift.
The approach developed in this paper is based on the assumption that the task
on the target domain can be efficiently learned by adequately reweighting the
source instances during training phase. We introduce a novel formulation of the
optimization objective for domain adaptation which relies on a discrepancy
distance characterizing the difference between domains according to a specific
task and a class of hypotheses. To solve this problem, we develop an
adversarial network algorithm which learns both the source weighting scheme and
the task in one feed-forward gradient descent. We provide numerical evidence of
the relevance of the method on public data sets for regression domain
adaptation through reproducible experiments.

    

### [[2007.04001] Supervised machine learning techniques for data matching based on similarity metrics](http://arxiv.org/abs/2007.04001)


  Businesses, governmental bodies and NGO's have an ever-increasing amount of
data at their disposal from which they try to extract valuable information.
Often, this needs to be done not only accurately but also within a short time
frame. Clean and consistent data is therefore crucial. Data matching is the
field that tries to identify instances in data that refer to the same
real-world entity. In this study, machine learning techniques are combined with
string similarity functions to the field of data matching. A dataset of
invoices from a variety of businesses and organizations was preprocessed with a
grouping scheme to reduce pair dimensionality and a set of similarity functions
was used to quantify similarity between invoice pairs. The resulting invoice
pair dataset was then used to train and validate a neural network and a boosted
decision tree. The performance was compared with a solution from FISCAL
Technologies as a benchmark against currently available deduplication
solutions. Both the neural network and boosted decision tree showed equal to
better performance.

    

### [[2008.01644] Queueing Network Controls via Deep Reinforcement Learning](http://arxiv.org/abs/2008.01644)


  Novel advanced policy gradient (APG) methods, such as Trust Region policy
optimization and Proximal policy optimization (PPO), have become the dominant
reinforcement learning algorithms because of their ease of implementation and
good practical performance. A conventional setup for notoriously difficult
queueing network control problems is a Markov decision problem (MDP) that has
three features: infinite state space, unbounded costs, and long-run average
cost objective. We extend the theoretical framework of these APG methods for
such MDP problems. The resulting PPO algorithm is tested on a parallel-server
system and large-size multiclass queueing networks. The algorithm consistently
generates control policies that outperform state-of-art heuristics in
literature in a variety of load conditions from light to heavy traffic. These
policies are demonstrated to be near-optimal when the optimal policy can be
computed.
A key to the successes of our PPO algorithm is the use of three variance
reduction techniques in estimating the relative value function via sampling.
First, we use a discounted relative value function as an approximation of the
relative value function. Second, we propose regenerative simulation to estimate
the discounted relative value function. Finally, we incorporate the
approximating martingale-process method into the regenerative estimator.

    

### [[2010.10343] Provenance Graph Kernel](http://arxiv.org/abs/2010.10343)


  Provenance is a record that describes how entities, activities, and agents
have influenced a piece of data; it is commonly represented as graphs with
relevant labels on both their nodes and edges. With the growing adoption of
provenance in a wide range of application domains, users are increasingly
confronted with an abundance of graph data, which may prove challenging to
process. Graph kernels, on the other hand, have been successfully used to
efficiently analyse graphs. In this paper, we introduce a novel graph kernel
called provenance kernel, which is inspired by and tailored for provenance
data. It decomposes a provenance graph into tree-patterns rooted at a given
node and considers the labels of edges and nodes up to a certain distance from
the root. We employ provenance kernels to classify provenance graphs from three
application domains. Our evaluation shows that they perform well in terms of
classification accuracy and yield competitive results when compared against
existing graph kernel methods and the provenance network analytics method while
more efficient in computing time. Moreover, the provenance types used by
provenance kernels also help improve the explainability of predictive models
built on them.

    

### [[2011.05953] $(f,Γ)$-Divergences: Interpolating between $f$-Divergences and Integral Probability Metrics](http://arxiv.org/abs/2011.05953)


  We develop a rigorous and general framework for constructing
information-theoretic divergences that subsume both $f$-divergences and
integral probability metrics (IPMs), such as the $1$-Wasserstein distance. We
prove under which assumptions these divergences, hereafter referred to as
$(f,\Gamma)$-divergences, provide a notion of `distance' between probability
measures and show that they can be expressed as a two-stage
mass-redistribution/mass-transport process. The $(f,\Gamma)$-divergences
inherit features from IPMs, such as the ability to compare distributions which
are not absolutely continuous, as well as from $f$-divergences, namely the
strict concavity of their variational representations and the ability to
control heavy-tailed distributions for particular choices of $f$. When
combined, these features establish a divergence with improved properties for
estimation, statistical learning, and uncertainty quantification applications.
Using statistical learning as an example, we demonstrate their advantage in
training generative adversarial networks (GANs) for heavy-tailed,
not-absolutely continuous sample distributions. We also show improved
performance and stability over gradient-penalized Wasserstein GAN in image
generation.

    

### [[2011.09148] Binary Classification of Gaussian Mixtures: Abundance of Support Vectors, Benign Overfitting and Regularization](http://arxiv.org/abs/2011.09148)


  Deep neural networks generalize well despite being exceedingly
overparameterized and being trained without explicit regularization. This
curious phenomenon has inspired extensive research activity in establishing its
statistical principles: Under what conditions is it observed? How do these
depend on the data and on the training algorithm? When does regularization
benefit generalization? While such questions remain wide open for deep neural
nets, recent works have attempted gaining insights by studying simpler, often
linear, models. Our paper contributes to this growing line of work by examining
binary linear classification under a generative Gaussian mixture model.
Motivated by recent results on the implicit bias of gradient descent, we study
both max-margin SVM classifiers (corresponding to logistic loss) and min-norm
interpolating classifiers (corresponding to least-squares loss). First, we
leverage an idea introduced in [V. Muthukumar et al., arXiv:2005.08054, (2020)]
to relate the SVM solution to the min-norm interpolating solution. Second, we
derive novel non-asymptotic bounds on the classification error of the latter.
Combining the two, we present novel sufficient conditions on the covariance
spectrum and on the signal-to-noise ratio (SNR) under which interpolating
estimators achieve asymptotically optimal performance as overparameterization
increases. Interestingly, our results extend to a noisy model with constant
probability noise flips. Contrary to previously studied discriminative data
models, our results emphasize the crucial role of the SNR and its interplay
with the data covariance. Finally, via a combination of analytical arguments
and numerical demonstrations we identify conditions under which the
interpolating estimator performs better than corresponding regularized
estimates.

    

### [[2011.15084] Likelihood-Based Diverse Sampling for Trajectory Forecasting](http://arxiv.org/abs/2011.15084)


  Forecasting complex vehicle and pedestrian multi-modal distributions requires
powerful probabilistic approaches. Normalizing flows (NF) have recently emerged
as an attractive tool to model such distributions. However, a key drawback is
that independent samples drawn from a flow model often do not adequately
capture all the modes in the underlying distribution. We propose
Likelihood-Based Diverse Sampling (LDS), a method for improving the quality and
the diversity of trajectory samples from a pre-trained flow model. Rather than
producing individual samples, LDS produces a set of trajectories in one shot.
Given a pre-trained forecasting flow model, we train LDS using gradients from
the model, to optimize an objective function that rewards high likelihood for
individual trajectories in the predicted set, together with high spatial
separation among trajectories. LDS outperforms state-of-art post-hoc neural
diverse forecasting methods for various pre-trained flow models as well as
conditional variational autoencoder (CVAE) models. Crucially, it can also be
used for transductive trajectory forecasting, where the diverse forecasts are
trained on-the-fly on unlabeled test examples. LDS is easy to implement, and we
show that it offers a simple plug-in improvement over baselines on two
challenging benchmarks. Code is at: this https URL


### [[2012.05688] DA-HGT: Domain Adaptive Heterogeneous Graph Transformer](http://arxiv.org/abs/2012.05688)


  Domain adaptation using graph networks learns label-discriminative and
network-invariant node embeddings by sharing graph parameters. Most existing
works focus on domain adaptation of homogeneous networks. The few works that
study heterogeneous cases only consider shared node types but ignore private
node types in individual networks. However, for given source and target
heterogeneous networks, they generally contain shared and private node types,
where private types bring an extra challenge for graph domain adaptation. In
this paper, we investigate Heterogeneous Information Networks (HINs) with
partially shared node types and propose a novel Domain Adaptive Heterogeneous
Graph Transformer (DA-HGT) to handle the domain shift between them. DA-HGT can
not only align the distribution of identical-type nodes and edges in two HINs
but also make full use of different-type nodes and edges to improve the
performance of knowledge transfer. Extensive experiments on several datasets
demonstrate that DA-HGT can outperform state-of-the-art methods in various
domain adaptation tasks across heterogeneous networks.

    

### [[2101.08248] Data-to-text Generation by Splicing Together Nearest Neighbors](http://arxiv.org/abs/2101.08248)


  We propose to tackle data-to-text generation tasks by directly splicing
together retrieved segments of text from "neighbor" source-target pairs. Unlike
recent work that conditions on retrieved neighbors but generates text
token-by-token, left-to-right, we learn a policy that directly manipulates
segments of neighbor text, by inserting or replacing them in partially
constructed generations. Standard techniques for training such a policy require
an oracle derivation for each generation, and we prove that finding the
shortest such derivation can be reduced to parsing under a particular weighted
context-free grammar. We find that policies learned in this way perform on par
with strong baselines in terms of automatic and human evaluation, but allow for
more interpretable and controllable generation.

    

### [[2102.00050] Sequential prediction under log-loss and misspecification](http://arxiv.org/abs/2102.00050)


  We consider the question of sequential prediction under the log-loss in terms
of cumulative regret. Namely, given a hypothesis class of distributions,
learner sequentially predicts the (distribution of the) next letter in sequence
and its performance is compared to the baseline of the best constant predictor
from the hypothesis class. The well-specified case corresponds to an additional
assumption that the data-generating distribution belongs to the hypothesis
class as well. Here we present results in the more general misspecified case.
Due to special properties of the log-loss, the same problem arises in the
context of competitive-optimality in density estimation, and model selection.
For the $d$-dimensional Gaussian location hypothesis class, we show that
cumulative regrets in the well-specified and misspecified cases asymptotically
coincide. In other words, we provide an $o(1)$ characterization of the
distribution-free (or PAC) regret in this case -- the first such result as far
as we know. We recall that the worst-case (or individual-sequence) regret in
this case is larger by an additive constant ${d\over 2} + o(1)$. Surprisingly,
neither the traditional Bayesian estimators, nor the Shtarkov's normalized
maximum likelihood achieve the PAC regret and our estimator requires special
"robustification" against heavy-tailed data. In addition, we show two general
results for misspecified regret: the existence and uniqueness of the optimal
estimator, and the bound sandwiching the misspecified regret between
well-specified regrets with (asymptotically) close hypotheses classes.

    

### [[2102.12459] When Attention Meets Fast Recurrence: Training Language Models with Reduced Compute](http://arxiv.org/abs/2102.12459)


  Large language models have become increasingly difficult to train because of
the growing computation time and cost. In this work, we present SRU++, a
highly-efficient architecture that combines fast recurrence and attention for
sequence modeling. SRU++ exhibits strong modeling capacity and training
efficiency. On standard language modeling tasks such as Enwik8, Wiki-103 and
Billion Word datasets, our model obtains better bits-per-character and
perplexity while using 3x-10x less training cost compared to top-performing
Transformer models. For instance, our model achieves a state-of-the-art result
on the Enwik8 dataset using 1.6 days of training on an 8-GPU machine. We
further demonstrate that SRU++ requires minimal attention for near
state-of-the-art performance. Our results suggest jointly leveraging fast
recurrence with little attention as a promising direction for accelerating
model training and inference.

    

### [[2103.02429] Land Cover Mapping in Limited Labels Scenario: A Survey](http://arxiv.org/abs/2103.02429)


  Land cover mapping is essential for monitoring global environmental change
and managing natural resources. Unfortunately, traditional classification
models are plagued by limited training data available in existing land cover
products and data heterogeneity over space and time. In this survey, we provide
a structured and comprehensive overview of challenges in land cover mapping and
machine learning methods used to address these problems. We also discuss the
gaps and opportunities that exist for advancing research in this promising
direction.

    

### [[2103.11648] D3p -- A Python Package for Differentially-Private Probabilistic Programming](http://arxiv.org/abs/2103.11648)


  We present d3p, a software package designed to help fielding runtime
efficient widely-applicable Bayesian inference under differential privacy
guarantees. d3p achieves general applicability to a wide range of probabilistic
modelling problems by implementing the differentially private variational
inference algorithm, allowing users to fit any parametric probabilistic model
with a differentiable density function. d3p adopts the probabilistic
programming paradigm as a powerful way for the user to flexibly define such
models. We demonstrate the use of our software on a hierarchical logistic
regression example, showing the expressiveness of the modelling approach as
well as the ease of running the parameter inference. We also perform an
empirical evaluation of the runtime of the private inference on a complex model
and find a $\sim$10 fold speed-up compared to an implementation using
TensorFlow Privacy.

    

### [[2103.15429] Efficient Explanations from Empirical Explainers](http://arxiv.org/abs/2103.15429)


  Amid a discussion about Green AI in which we see explainability neglected, we
explore the possibility to efficiently approximate computationally expensive
explainers. To this end, we propose feature attribution modelling with
Empirical Explainers. Empirical Explainers learn from data to predict the
attribution maps of expensive explainers. We train and test Empirical
Explainers in the language domain and find that they model their expensive
counterparts surprisingly well, at a fraction of the cost. They could thus
mitigate the computational burden of neural explanations significantly, in
applications that tolerate an approximation error.

    

### [[2104.04886] Adversarial Regularization as Stackelberg Game: An Unrolled Optimization Approach](http://arxiv.org/abs/2104.04886)


  Adversarial regularization has been shown to improve the generalization
performance of deep learning models in various natural language processing
tasks. Existing works usually formulate the method as a zero-sum game, which is
solved by alternating gradient descent/ascent algorithms. Such a formulation
treats the adversarial and the defending players equally, which is undesirable
because only the defending player contributes to the generalization
performance. To address this issue, we propose Stackelberg Adversarial
Regularization (SALT), which formulates adversarial regularization as a
Stackelberg game. This formulation induces a competition between a leader and a
follower, where the follower generates perturbations, and the leader trains the
model subject to the perturbations. Different from conventional approaches, in
SALT, the leader is in an advantageous position. When the leader moves, it
recognizes the strategy of the follower and takes the anticipated follower's
outcomes into consideration. Such a leader's advantage enables us to improve
the model fitting to the unperturbed data. The leader's strategic information
is captured by the Stackelberg gradient, which is obtained using an unrolling
algorithm. Our experimental results on a set of machine translation and natural
language understanding tasks show that SALT outperforms existing adversarial
regularization baselines across all tasks. Our code is publicly available.

    

### [[2104.05932] VR3Dense: Voxel Representation Learning for 3D Object Detection and Monocular Dense Depth Reconstruction](http://arxiv.org/abs/2104.05932)


  3D object detection and dense depth estimation are one of the most vital
tasks in autonomous driving. Multiple sensor modalities can jointly attribute
towards better robot perception, and to that end, we introduce a method for
jointly training 3D object detection and monocular dense depth reconstruction
neural networks. It takes as inputs, a LiDAR point-cloud, and a single RGB
image during inference and produces object pose predictions as well as a
densely reconstructed depth map. LiDAR point-cloud is converted into a set of
voxels, and its features are extracted using 3D convolution layers, from which
we regress object pose parameters. Corresponding RGB image features are
extracted using another 2D convolutional neural network. We further use these
combined features to predict a dense depth map. While our object detection is
trained in a supervised manner, the depth prediction network is trained with
both self-supervised and supervised loss functions. We also introduce a loss
function, edge-preserving smooth loss, and show that this results in better
depth estimation compared to the edge-aware smooth loss function, frequently
used in depth prediction works.

    

### [[2104.10157] VideoGPT: Video Generation using VQ-VAE and Transformers](http://arxiv.org/abs/2104.10157)


  We present VideoGPT: a conceptually simple architecture for scaling
likelihood based generative modeling to natural videos. VideoGPT uses VQ-VAE
that learns downsampled discrete latent representations of a raw video by
employing 3D convolutions and axial self-attention. A simple GPT-like
architecture is then used to autoregressively model the discrete latents using
spatio-temporal position encodings. Despite the simplicity in formulation and
ease of training, our architecture is able to generate samples competitive with
state-of-the-art GAN models for video generation on the BAIR Robot dataset, and
generate high fidelity natural videos from UCF-101 and Tumbler GIF Dataset
(TGIF). We hope our proposed architecture serves as a reproducible reference
for a minimalistic implementation of transformer based video generation models.
Samples and code are available at
this https URL


### [[2104.14282] VIRDOCD: a VIRtual DOCtor to Predict Dengue Fatality](http://arxiv.org/abs/2104.14282)


  Clinicians make routine diagnosis by scrutinizing patients' medical signs and
symptoms, a skill popularly referred to as "Clinical Eye". This skill evolves
through trial-and-error and improves with time. The success of the therapeutic
regime relies largely on the accuracy of interpretation of such sign-symptoms,
analyzing which a clinician assesses the severity of the illness. The present
study is an attempt to propose a complementary medical front by mathematically
modeling the "Clinical Eye" of a VIRtual DOCtor, using Statistical and Machine
Intelligence tools (SMI), to analyze Dengue epidemic infected patients (100
case studies with 11 weighted sign-symptoms). The SMI in VIRDOCD reads medical
data and translates these into a vector comprising Multiple Linear Regression
(MLR) coefficients to predict infection severity grades of dengue patients that
clone the clinician's experience-based assessment. Risk managed through ANOVA,
the dengue severity grade prediction accuracy from VIRDOCD is found higher (ca
75%) than conventional clinical practice (ca 71.4%, mean accuracy profile
assessed by a team of 10 senior consultants). Free of human errors and capable
of deciphering even minute differences from almost identical symptoms (to the
Clinical Eye), VIRDOCD is uniquely individualized in its decision-making
ability. The algorithm has been validated against Random Forest classification
(RF, ca 63%), another regression-based classifier similar to MLR that can be
trained through supervised learning. We find that MLR-based VIRDOCD is superior
to RF in predicting the grade of Dengue morbidity. VIRDOCD can be further
extended to analyze other epidemic infections, such as COVID-19.

    

### [[2105.01650] Stochastic gradient descent with noise of machine learning type. Part I: Discrete time analysis](http://arxiv.org/abs/2105.01650)


  Stochastic gradient descent (SGD) is one of the most popular algorithms in
modern machine learning. The noise encountered in these applications is
different from that in many theoretical analyses of stochastic gradient
algorithms. In this article, we discuss some of the common properties of energy
landscapes and stochastic noise encountered in machine learning problems, and
how they affect SGD-based optimization.
In particular, we show that the learning rate in SGD with machine learning
noise can be chosen to be small, but uniformly positive for all times if the
energy landscape resembles that of overparametrized deep learning problems. If
the objective function satisfies a Lojasiewicz inequality, SGD converges to the
global minimum exponentially fast, and even for functions which may have local
minima, we establish almost sure convergence to the global minimum at an
exponential rate from any finite energy initialization. The assumptions that we
make in this result concern the behavior where the objective function is either
small or large and the nature of the gradient noise, but the energy landscape
is fairly unconstrained on the domain where the objective function takes values
in an intermediate regime.

    

### [[2105.02132] Self-Supervised Learning from Automatically Separated Sound Scenes](http://arxiv.org/abs/2105.02132)


  Real-world sound scenes consist of time-varying collections of sound sources,
each generating characteristic sound events that are mixed together in audio
recordings. The association of these constituent sound events with their
mixture and each other is semantically constrained: the sound scene contains
the union of source classes and not all classes naturally co-occur. With this
motivation, this paper explores the use of unsupervised automatic sound
separation to decompose unlabeled sound scenes into multiple
semantically-linked views for use in self-supervised contrastive learning. We
find that learning to associate input mixtures with their automatically
separated outputs yields stronger representations than past approaches that use
the mixtures alone. Further, we discover that optimal source separation is not
required for successful contrastive learning by demonstrating that a range of
separation system convergence states all lead to useful and often complementary
example transformations. Our best system incorporates these unsupervised
separation models into a single augmentation front-end and jointly optimizes
similarity maximization and coincidence prediction objectives across the views.
The result is an unsupervised audio representation that rivals state-of-the-art
alternatives on the established shallow AudioSet classification benchmark.

    

### [[2105.07111] Prescriptive Process Monitoring for Cost-Aware Cycle Time Reduction](http://arxiv.org/abs/2105.07111)


  Reducing cycle time is a recurrent concern in the field of business process
management. Depending on the process, various interventions may be triggered to
reduce the cycle time of a case, for example, using a faster shipping service
in an order-to-delivery process or giving a phone call to a customer to obtain
missing information rather than waiting passively. Each of these interventions
comes with a cost. This paper tackles the problem of determining if and when to
trigger a time-reducing intervention in a way that maximizes the total net
gain. The paper proposes a prescriptive process monitoring method that uses
orthogonal random forest models to estimate the causal effect of triggering a
time-reducing intervention for each ongoing case of a process. Based on this
causal effect estimate, the method triggers interventions according to a
user-defined policy. The method is evaluated on two real-life logs.

    

### [[2105.09136] Periodic Freight Demand Estimation for Large-scale Tactical Planning](http://arxiv.org/abs/2105.09136)


  Freight carriers rely on tactical planning to design their service network to
satisfy demand in a cost-effective way. For computational tractability,
deterministic and cyclic Service Network Design (SND) formulations are used to
solve large-scale problems. A central input is the periodic demand, that is,
the demand expected to repeat in every period in the planning horizon. In
practice, demand is predicted by a time series forecasting model and the
periodic demand is the average of those forecasts. This is, however, only one
of many possible mappings. The problem consisting in selecting this mapping has
hitherto been overlooked in the literature. We propose to use the structure of
the downstream decision-making problem to select a good mapping. For this
purpose, we introduce a multilevel mathematical programming formulation that
explicitly links the time series forecasts to the SND problem of interest. The
solution is a periodic demand estimate that minimizes costs over the tactical
planning horizon. We report results in an extensive empirical study of a
large-scale application from the Canadian National Railway Company. They
clearly show the importance of the periodic demand estimation problem. Indeed,
the planning costs exhibit an important variation over different periodic
demand estimates and using an estimate different from the mean forecast can
lead to substantial cost reductions. Moreover, the costs associated with the
period demand estimates based on forecasts were comparable to, or even better
than those obtained using the mean of actual demand.

    

### [[2105.09601] See, Hear, Read: Leveraging Multimodality with Guided Attention for Abstractive Text Summarization](http://arxiv.org/abs/2105.09601)


  In recent years, abstractive text summarization with multimodal inputs has
started drawing attention due to its ability to accumulate information from
different source modalities and generate a fluent textual summary. However,
existing methods use short videos as the visual modality and short summary as
the ground-truth, therefore, perform poorly on lengthy videos and long
ground-truth summary. Additionally, there exists no benchmark dataset to
generalize this task on videos of varying lengths. In this paper, we introduce
AVIATE, the first large-scale dataset for abstractive text summarization with
videos of diverse duration, compiled from presentations in well-known academic
conferences like NDSS, ICML, NeurIPS, etc. We use the abstract of corresponding
research papers as the reference summaries, which ensure adequate quality and
uniformity of the ground-truth. We then propose FLORAL, a factorized
multi-modal Transformer based decoder-only language model, which inherently
captures the intra-modal and inter-modal dynamics within various input
modalities for the text summarization task. FLORAL utilizes an increasing
number of self-attentions to capture multimodality and performs significantly
better than traditional encoder-decoder based networks. Extensive experiments
illustrate that FLORAL achieves significant improvement over the baselines in
both qualitative and quantitative evaluations on the existing How2 dataset for
short videos and newly introduced AVIATE dataset for videos with diverse
duration, beating the best baseline on the two datasets by $1.39$ and $2.74$
ROUGE-L points respectively.

    

### [[2106.00589] Improving Long-Term Metrics in Recommendation Systems using Short-Horizon Reinforcement Learning](http://arxiv.org/abs/2106.00589)


  We study session-based recommendation scenarios where we want to recommend
items to users during sequential interactions to improve their long-term
utility. Optimizing a long-term metric is challenging because the learning
signal (whether the recommendations achieved their desired goals) is delayed
and confounded by other user interactions with the system. Targeting
immediately measurable proxies such as clicks can lead to suboptimal
recommendations due to misalignment with the long-term metric. We develop a new
reinforcement learning algorithm called Short Horizon Policy Improvement (SHPI)
that approximates policy-induced drift in user behavior across sessions. SHPI
is a straightforward modification of episodic RL algorithms for session-based
recommendation, that additionally gives an appropriate termination bonus in
each session. Empirical results on four recommendation tasks show that SHPI can
outperform state-of-the-art recommendation techniques like matrix factorization
with offline proxy signals, bandits with myopic online proxies, and RL
baselines with limited amounts of user interaction.

    

### [[2106.02588] Stochastic gradient descent with noise of machine learning type. Part II: Continuous time analysis](http://arxiv.org/abs/2106.02588)


  The representation of functions by artificial neural networks depends on a
large number of parameters in a non-linear fashion. Suitable parameters of
these are found by minimizing a 'loss functional', typically by stochastic
gradient descent (SGD) or an advanced SGD-based algorithm.
In a continuous time model for SGD with noise that follows the 'machine
learning scaling', we show that in a certain noise regime, the optimization
algorithm prefers 'flat' minima of the objective function in a sense which is
different from the flat minimum selection of continuous time SGD with
homogeneous noise.

    

### [[2106.04803] CoAtNet: Marrying Convolution and Attention for All Data Sizes](http://arxiv.org/abs/2106.04803)


  Transformers have attracted increasing interests in computer vision, but they
still fall behind state-of-the-art convolutional networks. In this work, we
show that while Transformers tend to have larger model capacity, their
generalization can be worse than convolutional networks due to the lack of the
right inductive bias. To effectively combine the strengths from both
architectures, we present CoAtNets(pronounced "coat" nets), a family of hybrid
models built from two key insights: (1) depthwise Convolution and
self-Attention can be naturally unified via simple relative attention; (2)
vertically stacking convolution layers and attention layers in a principled way
is surprisingly effective in improving generalization, capacity and efficiency.
Experiments show that our CoAtNets achieve state-of-the-art performance under
different resource constraints across various datasets: Without extra data,
CoAtNet achieves 86.0% ImageNet top-1 accuracy; When pre-trained with 13M
images from ImageNet-21K, our CoAtNet achieves 88.56% top-1 accuracy, matching
ViT-huge pre-trained with 300M images from JFT-300M while using 23x less data;
Notably, when we further scale up CoAtNet with JFT-3B, it achieves 90.88% top-1
accuracy on ImageNet, establishing a new state-of-the-art result.

    

### [[2106.07487] pix2rule: End-to-end Neuro-symbolic Rule Learning](http://arxiv.org/abs/2106.07487)


  Humans have the ability to seamlessly combine low-level visual input with
high-level symbolic reasoning often in the form of recognising objects,
learning relations between them and applying rules. Neuro-symbolic systems aim
to bring a unifying approach to connectionist and logic-based principles for
visual processing and abstract reasoning respectively. This paper presents a
complete neuro-symbolic method for processing images into objects, learning
relations and logical rules in an end-to-end fashion. The main contribution is
a differentiable layer in a deep learning architecture from which symbolic
relations and rules can be extracted by pruning and thresholding. We evaluate
our model using two datasets: subgraph isomorphism task for symbolic rule
learning and an image classification domain with compound relations for
learning objects, relations and rules. We demonstrate that our model scales
beyond state-of-the-art symbolic learners and outperforms deep relational
neural network architectures.

    

### [[2106.10533] Learning to Reach, Swim, Walk and Fly in One Trial: Data-Driven Control with Scarce Data and Side Information](http://arxiv.org/abs/2106.10533)


  We develop a learning-based control algorithm for unknown dynamical systems
under very severe data limitations. Specifically, the algorithm has access to
streaming data only from a single and ongoing trial. Despite the scarcity of
data, we show -- through a series of examples -- that the algorithm can provide
performance comparable to reinforcement learning algorithms trained over
millions of environment interactions. It accomplishes such performance by
effectively leveraging various forms of side information on the dynamics to
reduce the sample complexity. Such side information typically comes from
elementary laws of physics and qualitative properties of the system. More
precisely, the algorithm approximately solves an optimal control problem
encoding the system's desired behavior. To this end, it constructs and refines
a differential inclusion that contains the unknown vector field of the
dynamics. The differential inclusion, used in an interval Taylor-based method,
enables to over-approximate the set of states the system may reach.
Theoretically, we establish a bound on the suboptimality of the approximate
solution with respect to the case of known dynamics. We show that the longer
the trial or the more side information is available, the tighter the bound.
Empirically, experiments in a high-fidelity F-16 aircraft simulator and
MuJoCo's environments such as the Reacher, Swimmer, and Cheetah illustrate the
algorithm's effectiveness.

    

### [[2106.13233] Post-Selections in AI and How to Avoid Them](http://arxiv.org/abs/2106.13233)


  Neural network based Artificial Intelligence (AI) has reported increasing
scales in experiments. However, this paper raises a rarely reported stage in
such experiments called Post-Selection alter the reader to several possible
protocol flaws that may result in misleading results. All AI methods fall into
two broad schools, connectionist and symbolic. The Post-Selection fall into two
kinds, Post-Selection Using Validation Sets (PSUVS) and Post-Selection Using
Test Sets (PSUTS). Each kind has two types of post-selectors, machines and
humans. The connectionist school received criticisms for its "black box" and
now the Post-Selection; but the seemingly "clean" symbolic school seems more
brittle because of its human PSUTS. This paper first presents a controversial
view: all static "big data" are non-scalable. We then analyze why
error-backprop from randomly initialized weights suffers from severe local
minima, why PSUVS lacks cross-validation, why PSUTS violates well-established
protocols, and why every paper involved should transparently report the
Post-Selection stage. To avoid future pitfalls in AI competitions, this paper
proposes a new AI metrics, called developmental errors for all networks
trained, under Three Learning Conditions: (1) an incremental learning
architecture (due to a "big data" flaw), (2) a training experience and (3) a
limited amount of computational resources. Developmental Networks avoid
Post-Selections because they automatically discover context-rules on the fly by
generating emergent Turing machines (not black boxes) that are optimal in the
sense of maximum-likelihood across lifetime, conditioned on the Three Learning
Conditions.

    

### [[2108.13265] Predicting Road Flooding Risk with Machine Learning Approaches Using Crowdsourced Reports and Fine-grained Traffic Data](http://arxiv.org/abs/2108.13265)


  The objective of this study is to predict road flooding risks based on
topographic, hydrologic, and temporal precipitation features using machine
learning models. Predictive flood monitoring of road network flooding status
plays an essential role in community hazard mitigation, preparedness, and
response activities. Existing studies related to the estimation of road
inundations either lack observed road inundation data for model validations or
focus mainly on road inundation exposure assessment based on flood maps. This
study addresses this limitation by using crowdsourced and fine-grained traffic
data as an indicator of road inundation, and topographic, hydrologic, and
temporal precipitation features as predictor variables. Two tree-based machine
learning models (random forest and AdaBoost) were then tested and trained for
predicting road inundations in the contexts of 2017 Hurricane Harvey and 2019
Tropical Storm Imelda in Harris County, Texas. The findings from Hurricane
Harvey indicate that precipitation is the most important feature for predicting
road inundation susceptibility, and that topographic features are more
essential than hydrologic features for predicting road inundations in both
storm cases. The random forest and AdaBoost models had relatively high AUC
scores (0.860 and 0.810 for Harvey respectively and 0.790 and 0.720 for Imelda
respectively) with the random forest model performing better in both cases. The
random forest model showed stable performance for Harvey, while varying
significantly for Imelda. This study advances the emerging field of smart flood
resilience in terms of predictive flood risk mapping at the road level. For
example, such models could help impacted communities and emergency management
agencies develop better preparedness and response strategies with improved
situational awareness of road inundation likelihood as an extreme weather event
unfolds.

    

### [[2109.05700] Exploiting Heterogeneity in Robust Federated Best-Arm Identification](http://arxiv.org/abs/2109.05700)


  We study a federated variant of the best-arm identification problem in
stochastic multi-armed bandits: a set of clients, each of whom can sample only
a subset of the arms, collaborate via a server to identify the best arm (i.e.,
the arm with the highest mean reward) with prescribed confidence. For this
problem, we propose Fed-SEL, a simple communication-efficient algorithm that
builds on successive elimination techniques and involves local sampling steps
at the clients. To study the performance of Fed-SEL, we introduce a notion of
arm-heterogeneity that captures the level of dissimilarity between
distributions of arms corresponding to different clients. Interestingly, our
analysis reveals the benefits of arm-heterogeneity in reducing both the sample-
and communication-complexity of Fed-SEL. As a special case of our analysis, we
show that for certain heterogeneous problem instances, Fed-SEL outputs the
best-arm after just one round of communication. Our findings have the following
key implication: unlike federated supervised learning where recent work has
shown that statistical heterogeneity can lead to poor performance, one can
provably reap the benefits of both local computation and heterogeneity for
federated best-arm identification. As our final contribution, we develop
variants of Fed-SEL, both for federated and peer-to-peer settings, that are
robust to the presence of Byzantine clients, and hence suitable for deployment
in harsh, adversarial environments.

    

### [[2109.06160] Augmenting Decision Making via Interactive What-If Analysis](http://arxiv.org/abs/2109.06160)


  The fundamental goal of business data analysis is to improve business
decisions using data. Business users such as sales, marketing, product, or
operations managers often make decisions to achieve key performance indicator
(KPI) goals such as increasing customer retention, decreasing cost, and
increasing sales. To discover the relationship between data attributes
hypothesized to be drivers and those corresponding to KPIs of interest,
business users currently need to perform lengthy exploratory analyses,
considering multitudes of combinations and scenarios, slicing, dicing, and
transforming the data accordingly. For example, analyzing customer retention
across quarters of the year or suggesting optimal media channels across strata
of customers. However, the increasing complexity of datasets combined with the
cognitive limitations of humans makes it challenging to carry over multiple
hypotheses, even for simple datasets. Therefore mentally performing such
analyses is hard. Existing commercial tools either provide partial solutions
whose effectiveness remains unclear or fail to cater to business users.
Here we argue for four functionalities that we believe are necessary to
enable business users to interactively learn and reason about the relationships
(functions) between sets of data attributes, facilitating data-driven decision
making. We implement these functionalities in SystemD, an interactive visual
analysis system enabling business users to experiment with the data by asking
what-if questions. We evaluate the system through three business use cases:
marketing mix modeling analysis, customer retention analysis, and deal closing
analysis, and report on feedback from multiple business users. Overall,
business users find SystemD intuitive and useful for quick testing and
validation of their hypotheses around interested KPI as well as in making
effective and fast data-driven decisions.

    

### [[2109.07047] The Promise of Dataflow Architectures in the Design of Processing Systems for Autonomous Machines](http://arxiv.org/abs/2109.07047)


  The commercialization of autonomous machines is a thriving sector, and likely
to be the next major computing demand driver, after PC, cloud computing, and
mobile computing. Nevertheless, a suitable computer architecture for autonomous
machines is missing, and many companies are forced to develop ad hoc computing
solutions that are neither scalable nor extensible. In this article, we analyze
the demands of autonomous machine computing, and argue for the promise of
dataflow architectures in autonomous machines.

    

### [[2109.06931] Measurement and Analysis of GPU-accelerated Applications with HPCToolkit](http://arxiv.org/abs/2109.06931)


  To address the challenge of performance analysis on the US DOE's forthcoming
exascale supercomputers, Rice University has been extending its HPCToolkit
performance tools to support measurement and analysis of GPU-accelerated
applications. To help developers understand the performance of accelerated
applications as a whole, HPCToolkit's measurement and analysis tools attribute
metrics to calling contexts that span both CPUs and GPUs. To measure
GPU-accelerated applications efficiently, HPCToolkit employs a novel wait-free
data structure to coordinate monitoring and attribution of GPU performance. To
help developers understand the performance of complex GPU code generated from
high-level programming models, HPCToolkit constructs sophisticated
approximations of call path profiles for GPU computations. To support
fine-grained analysis and tuning, HPCToolkit uses PC sampling and
instrumentation to measure and attribute GPU performance metrics to source
lines, loops, and inlined code. To supplement fine-grained measurements,
HPCToolkit can measure GPU kernel executions using hardware performance
counters. To provide a view of how an execution evolves over time, HPCToolkit
can collect, analyze, and visualize call path traces within and across nodes.
Finally, on NVIDIA GPUs, HPCToolkit can derive and attribute a collection of
useful performance metrics based on measurements using GPU PC samples. We
illustrate HPCToolkit's new capabilities for analyzing GPU-accelerated
applications with several codes developed as part of the Exascale Computing
Project.

    

### [[2109.07260] Evaluation of Distributed Databases in Hybrid Clouds and Edge Computing: Energy, Bandwidth, and Storage Consumption](http://arxiv.org/abs/2109.07260)


  A benchmark study of modern distributed databases is an important source of
information to select the right technology for managing data in the cloud-edge
paradigms. To make the right decision, it is required to conduct an extensive
experimental study on a variety of hardware infrastructures. While most of the
state-of-the-art studies have investigated only response time and scalability
of distributed databases, focusing on other various metrics (e.g., energy,
bandwidth, and storage consumption) is essential to fully understand the
resources consumption of the distributed databases. Also, existing studies have
explored the response time and scalability of these databases either in private
or public cloud. Hence, there is a paucity of investigation into the evaluation
of these databases deployed in a hybrid cloud, which is the seamless
integration of public and private cloud. To address these research gaps, in
this paper, we investigate energy, bandwidth and storage consumption of the
most used and common distributed databases. For this purpose, we have evaluated
four open-source databases (Cassandra, Mongo, Redis and MySQL) on the hybrid
cloud spanning over local OpenStack and Microsoft Azure, and a variety of edge
computing nodes including Raspberry Pi, a cluster of Raspberry Pi, and low and
high power servers. Our extensive experimental results reveal several helpful
insights for the deployment selection of modern distributed databases in
edge-cloud environments.

    

### [[2109.06874] Agile, Antifragile, Artificial-Intelligence-Enabled, Command and Control](http://arxiv.org/abs/2109.06874)


  Artificial Intelligence (AI) is rapidly becoming integrated into military
Command and Control (C2) systems as a strategic priority for many defence
forces. The successful implementation of AI is promising to herald a
significant leap in C2 agility through automation. However, realistic
expectations need to be set on what AI can achieve in the foreseeable future.
This paper will argue that AI could lead to a fragility trap, whereby the
delegation of C2 functions to an AI could increase the fragility of C2,
resulting in catastrophic strategic failures. This calls for a new framework
for AI in C2 to avoid this trap. We will argue that antifragility along with
agility should form the core design principles for AI-enabled C2 systems. This
duality is termed Agile, Antifragile, AI-Enabled Command and Control (A3IC2).
An A3IC2 system continuously improves its capacity to perform in the face of
shocks and surprises through overcompensation from feedback during the C2
decision-making cycle. An A3IC2 system will not only be able to survive within
a complex operational environment, it will also thrive, benefiting from the
inevitable shocks and volatility of war.

    

### [[2109.06896] Decision-Focused Summarization](http://arxiv.org/abs/2109.06896)


  Relevance in summarization is typically defined based on textual information
alone, without incorporating insights about a particular decision. As a result,
to support risk analysis of pancreatic cancer, summaries of medical notes may
include irrelevant information such as a knee injury. We propose a novel
problem, decision-focused summarization, where the goal is to summarize
relevant information for a decision. We leverage a predictive model that makes
the decision based on the full text to provide valuable insights on how a
decision can be inferred from text. To build a summary, we then select
representative sentences that lead to similar model decisions as using the full
text while accounting for textual non-redundancy. To evaluate our method
(DecSum), we build a testbed where the task is to summarize the first ten
reviews of a restaurant in support of predicting its future rating on Yelp.
DecSum substantially outperforms text-only summarization methods and
model-based explanation methods in decision faithfulness and
representativeness. We further demonstrate that DecSum is the only method that
enables humans to outperform random chance in predicting which restaurant will
be better rated in the future.

    

### [[2109.06926] A trainable monogenic ConvNet layer robust in front of large contrast changes in image classification](http://arxiv.org/abs/2109.06926)


  Convolutional Neural Networks (ConvNets) at present achieve remarkable
performance in image classification tasks. However, current ConvNets cannot
guarantee the capabilities of the mammalian visual systems such as invariance
to contrast and illumination changes. Some ideas to overcome the illumination
and contrast variations usually have to be tuned manually and tend to fail when
tested with other types of data degradation. In this context, we present a new
bio-inspired {entry} layer, M6, which detects low-level geometric features
(lines, edges, and orientations) which are similar to patterns detected by the
V1 visual cortex. This new trainable layer is capable of coping with image
classification even with large contrast variations. The explanation for this
behavior is the monogenic signal geometry, which represents each pixel value in
a 3D space using quaternions, a fact that confers a degree of explainability to
the networks. We compare M6 with a conventional convolutional layer (C) and a
deterministic quaternion local phase layer (Q9). The experimental setup {is
designed to evaluate the robustness} of our M6 enriched ConvNet model and
includes three architectures, four datasets, three types of contrast
degradation (including non-uniform haze degradations). The numerical results
reveal that the models with M6 are the most robust in front of any kind of
contrast variations. This amounts to a significant enhancement of the C models,
which usually have reasonably good performance only when the same training and
test degradation are used, except for the case of maximum degradation.
Moreover, the Structural Similarity Index Measure (SSIM) is used to analyze and
explain the robustness effect of the M6 feature maps under any kind of contrast
degradations.

    

### [[2109.06939] The Stem Cell Hypothesis: Dilemma behind Multi-Task Learning with Transformer Encoders](http://arxiv.org/abs/2109.06939)


  Multi-task learning with transformer encoders (MTL) has emerged as a powerful
technique to improve performance on closely-related tasks for both accuracy and
efficiency while a question still remains whether or not it would perform as
well on tasks that are distinct in nature. We first present MTL results on five
NLP tasks, POS, NER, DEP, CON, and SRL, and depict its deficiency over
single-task learning. We then conduct an extensive pruning analysis to show
that a certain set of attention heads get claimed by most tasks during MTL, who
interfere with one another to fine-tune those heads for their own objectives.
Based on this finding, we propose the Stem Cell Hypothesis to reveal the
existence of attention heads naturally talented for many tasks that cannot be
jointly trained to create adequate embeddings for all of those tasks. Finally,
we design novel parameter-free probes to justify our hypothesis and demonstrate
how attention heads are transformed across the five tasks during MTL through
label analysis.

    

### [[2109.07006] A Three Step Training Approach with Data Augmentation for Morphological Inflection](http://arxiv.org/abs/2109.07006)


  We present the BME submission for the SIGMORPHON 2021 Task 0 Part 1,
Generalization Across Typologically Diverse Languages shared task. We use an
LSTM encoder-decoder model with three step training that is first trained on
all languages, then fine-tuned on each language families and finally finetuned
on individual languages. We use a different type of data augmentation technique
in the first two steps. Our system outperformed the only other submission.
Although it remains worse than the Transformer baseline released by the
organizers, our model is simpler and our data augmentation techniques are
easily applicable to new languages. We perform ablation studies and show that
the augmentation techniques and the three training steps often help but
sometimes have a negative effect.

    

### [[2109.07024] DPMPC-Planner: A real-time UAV trajectory planning framework for complex static environments with dynamic obstacles](http://arxiv.org/abs/2109.07024)


  Safe UAV navigation is challenging due to the complex environment structures,
dynamic obstacles, and uncertainties from measurement noises and unpredictable
moving obstacle behaviors. Although plenty of recent works achieve safe
navigation in complex static environments with sophisticated mapping
algorithms, such as occupancy map and ESDF map, these methods cannot reliably
handle dynamic environments due to the mapping limitation from moving
obstacles. To address the limitation, this paper proposes a trajectory planning
framework to achieve safe navigation considering complex static environments
with dynamic obstacles. To reliably handle dynamic obstacles, we divide the
environment representation into static mapping and dynamic object
representation, which can be obtained from computer vision methods. Our
framework first generates a static trajectory based on the proposed iterative
corridor shrinking algorithm. Then, reactive chance-constrained model
predictive control with temporal goal tracking is applied to avoid dynamic
obstacles with uncertainties. The simulation results in various environments
demonstrate the ability of our algorithm to navigate safely in complex static
environments with dynamic obstacles.

    

### [[2109.07045] Uncertainty Quantification in Medical Image Segmentation with Multi-decoder U-Net](http://arxiv.org/abs/2109.07045)


  Accurate medical image segmentation is crucial for diagnosis and analysis.
However, the models without calibrated uncertainty estimates might lead to
errors in downstream analysis and exhibit low levels of robustness. Estimating
the uncertainty in the measurement is vital to making definite, informed
conclusions. Especially, it is difficult to make accurate predictions on
ambiguous areas and focus boundaries for both models and radiologists, even
harder to reach a consensus with multiple annotations. In this work, the
uncertainty under these areas is studied, which introduces significant
information with anatomical structure and is as important as segmentation
performance. We exploit the medical image segmentation uncertainty
quantification by measuring segmentation performance with multiple annotations
in a supervised learning manner and propose a U-Net based architecture with
multiple decoders, where the image representation is encoded with the same
encoder, and segmentation referring to each annotation is estimated with
multiple decoders. Nevertheless, a cross-loss function is proposed for bridging
the gap between different branches. The proposed architecture is trained in an
end-to-end manner and able to improve predictive uncertainty estimates. The
model achieves comparable performance with fewer parameters to the integrated
training model that ranked the runner-up in the MICCAI-QUBIQ 2020 challenge.

    

### [[2109.07084] Fast Extraction of Word Embedding from Q-contexts](http://arxiv.org/abs/2109.07084)


  The notion of word embedding plays a fundamental role in natural language
processing (NLP). However, pre-training word embedding for very large-scale
vocabulary is computationally challenging for most existing methods. In this
work, we show that with merely a small fraction of contexts (Q-contexts)which
are typical in the whole corpus (and their mutual information with words), one
can construct high-quality word embedding with negligible errors. Mutual
information between contexts and words can be encoded canonically as a sampling
state, thus, Q-contexts can be fast constructed. Furthermore, we present an
efficient and effective WEQ method, which is capable of extracting word
embedding directly from these typical contexts. In practical scenarios, our
algorithm runs 11$\sim$13 times faster than well-established methods. By
comparing with well-known methods such as matrix factorization, word2vec,
GloVeand fasttext, we demonstrate that our method achieves comparable
performance on a variety of downstream NLP tasks, and in the meanwhile
maintains run-time and resource advantages over all these baselines.

    

### [[2109.07095] Towards Document-Level Paraphrase Generation with Sentence Rewriting and Reordering](http://arxiv.org/abs/2109.07095)


  Paraphrase generation is an important task in natural language processing.
Previous works focus on sentence-level paraphrase generation, while ignoring
document-level paraphrase generation, which is a more challenging and valuable
task. In this paper, we explore the task of document-level paraphrase
generation for the first time and focus on the inter-sentence diversity by
considering sentence rewriting and reordering. We propose CoRPG (Coherence
Relationship guided Paraphrase Generation), which leverages graph GRU to encode
the coherence relationship graph and get the coherence-aware representation for
each sentence, which can be used for re-arranging the multiple (possibly
modified) input sentences. We create a pseudo document-level paraphrase dataset
for training CoRPG. Automatic evaluation results show CoRPG outperforms several
strong baseline models on the BERTScore and diversity scores. Human evaluation
also shows our model can generate document paraphrase with more diversity and
semantic preservation.

    

### [[2109.07118] Low-Resource Named Entity Recognition Based on Multi-hop Dependency Trigger](http://arxiv.org/abs/2109.07118)


  This paper presents a simple and effective approach in low-resource named
entity recognition (NER) based on multi-hop dependency trigger. Dependency
trigger refer to salient nodes relative to a entity in the dependency graph of
a context sentence. Our main observation is that there often exists trigger
which play an important role to recognize the location and type of entity in
sentence. Previous research has used manual labelling of trigger. Our main
contribution is to propose use a syntactic parser to automatically annotate
trigger. Experiments on two English datasets (CONLL 2003 and BC5CDR) show that
the proposed method is comparable to the previous trigger-based NER model.

    

### [[2109.07135] Co-Embedding: Discovering Communities on Bipartite Graphs through Projection](http://arxiv.org/abs/2109.07135)


  Many datasets take the form of a bipartite graph where two types of nodes are
connected by relationships, like the movies watched by a user or the tags
associated with a file. The partitioning of the bipartite graph could be used
to fasten recommender systems, or reduce the information retrieval system's
index size, by identifying groups of items with similar properties. This type
of graph is often processed by algorithms using the Vector Space Model
representation, where a binary vector represents an item with 0 and 1. The main
problem with this representation is the dimension relatedness, like words'
synonymity, which is not considered. This article proposes a co-clustering
algorithm using items projection, allowing the measurement of features
similarity. We evaluated our algorithm on a cluster retrieval task. Over
various datasets, our algorithm produced well balanced clusters with coherent
items in, leading to high retrieval scores on this task.

    

### [[2109.07141] Beyond Glass-Box Features: Uncertainty Quantification Enhanced Quality Estimation for Neural Machine Translation](http://arxiv.org/abs/2109.07141)


  Quality Estimation (QE) plays an essential role in applications of Machine
Translation (MT). Traditionally, a QE system accepts the original source text
and translation from a black-box MT system as input. Recently, a few studies
indicate that as a by-product of translation, QE benefits from the model and
training data's information of the MT system where the translations come from,
and it is called the "glass-box QE". In this paper, we extend the definition of
"glass-box QE" generally to uncertainty quantification with both "black-box"
and "glass-box" approaches and design several features deduced from them to
blaze a new trial in improving QE's performance. We propose a framework to fuse
the feature engineering of uncertainty quantification into a pre-trained
cross-lingual language model to predict the translation quality. Experiment
results show that our method achieves state-of-the-art performances on the
datasets of WMT 2020 QE shared task.

    

### [[2109.07150] Solving Occlusion in Terrain Mapping with Neural Networks](http://arxiv.org/abs/2109.07150)


  Accurate and complete terrain maps enhance the awareness of autonomous robots
and enable safe and optimal path planning. Rocks and topography often create
occlusions and lead to missing elevation information in the Digital Elevation
Map (DEM). Currently, mostly traditional inpainting techniques based on
diffusion or patch-matching are used by autonomous mobile robots to fill-in
incomplete DEMs. These methods cannot leverage the high-level terrain
characteristics and the geometric constraints of line of sight we humans use
intuitively to predict occluded areas. We propose to use neural networks to
reconstruct the occluded areas in DEMs. We introduce a self-supervised learning
approach capable of training on real-world data without a need for ground-truth
information. We accomplish this by adding artificial occlusion to the
incomplete elevation maps constructed on a real robot by performing ray
casting. We first evaluate a supervised learning approach on synthetic data for
which we have the full ground-truth available and subsequently move to several
real-world datasets. These real-world datasets were recorded during autonomous
exploration of both structured and unstructured terrain with a legged robot,
and additionally in a planetary scenario on Lunar analogue terrain. We state a
significant improvement compared to the Telea and Navier-Stokes baseline
methods both on synthetic terrain and for the real-world datasets. Our neural
network is able to run in real-time on both CPU and GPU with suitable sampling
rates for autonomous ground robots.

    

### [[2109.07193] FCA: Learning a 3D Full-coverage Vehicle Camouflage for Multi-view Physical Adversarial Attack](http://arxiv.org/abs/2109.07193)


  Physical adversarial attacks in object detection have attracted increasing
attention. However, most previous works focus on hiding the objects from the
detector by generating an individual adversarial patch, which only covers the
planar part of the vehicle's surface and fails to attack the detector in
physical scenarios for multi-view, long-distance and partially occluded
objects. To bridge the gap between digital attacks and physical attacks, we
exploit the full 3D vehicle surface to propose a robust Full-coverage
Camouflage Attack (FCA) to fool detectors. Specifically, we first try rendering
the non-planar camouflage texture over the full vehicle surface. To mimic the
real-world environment conditions, we then introduce a transformation function
to transfer the rendered camouflaged vehicle into a photo-realistic scenario.
Finally, we design an efficient loss function to optimize the camouflage
texture. Experiments show that the full-coverage camouflage attack can not only
outperform state-of-the-art methods under various test cases but also
generalize to different environments, vehicles, and object detectors.

    

### [[2109.07194] Multiagent Multimodal Categorization for Symbol Emergence: Emergent Communication via Interpersonal Cross-modal Inference](http://arxiv.org/abs/2109.07194)


  This paper describes a computational model of multiagent multimodal
categorization that realizes emergent communication. We clarify whether the
computational model can reproduce the following functions in a symbol emergence
system, comprising two agents with different sensory modalities playing a
naming game. (1) Function for forming a shared lexical system that comprises
perceptual categories and corresponding signs, formed by agents through
individual learning and semiotic communication between agents. (2) Function to
improve the categorization accuracy in an agent via semiotic communication with
another agent, even when some sensory modalities of each agent are missing. (3)
Function that an agent infers unobserved sensory information based on a sign
sampled from another agent in the same manner as cross-modal inference. We
propose an interpersonal multimodal Dirichlet mixture (Inter-MDM), which is
derived by dividing an integrative probabilistic generative model, which is
obtained by integrating two Dirichlet mixtures (DMs). The Markov chain Monte
Carlo algorithm realizes emergent communication. The experimental results
demonstrated that Inter-MDM enables agents to form multimodal categories and
appropriately share signs between agents. It is shown that emergent
communication improves categorization accuracy, even when some sensory
modalities are missing. Inter-MDM enables an agent to predict unobserved
information based on a shared sign.

    

### [[2109.07195] Target Languages (vs. Inductive Biases) for Learning to Act and Plan](http://arxiv.org/abs/2109.07195)


  Recent breakthroughs in AI have shown the remarkable power of deep learning
and deep reinforcement learning. These developments, however, have been tied to
specific tasks, and progress in out-of-distribution generalization has been
limited. While it is assumed that these limitations can be overcome by
incorporating suitable inductive biases, the notion of inductive biases itself
is often left vague and does not provide meaningful guidance. In the paper, I
articulate a different learning approach where representations do not emerge
from biases in a neural architecture but are learned over a given target
language with a known semantics. The basic ideas are implicit in mainstream AI
where representations have been encoded in languages ranging from fragments of
first-order logic to probabilistic structural causal models. The challenge is
to learn from data, the representations that have traditionally been crafted by
hand. Generalization is then a result of the semantics of the language. The
goals of the paper and talk are to make these ideas explicit, to place them in
a broader context where the design of the target language is crucial, and to
illustrate them in the context of learning to act and plan. For this, after a
general discussion, I consider learning representations of actions, general
policies, and general decompositions. In these cases, learning is formulated as
a combinatorial optimization problem but nothing prevents the use deep learning
techniques instead. Indeed, learning representations over languages with a
known semantics provides an account of what is to be learned, while learning
representations with neural nets provides a complementary account of how
representations can be learned. The challenge and the opportunity is to bring
the two together.

    

### [[2109.07205] A Relation-Oriented Clustering Method for Open Relation Extraction](http://arxiv.org/abs/2109.07205)


  The clustering-based unsupervised relation discovery method has gradually
become one of the important methods of open relation extraction (OpenRE).
However, high-dimensional vectors can encode complex linguistic information
which leads to the problem that the derived clusters cannot explicitly align
with the relational semantic classes. In this work, we propose a
relation-oriented clustering model and use it to identify the novel relations
in the unlabeled data. Specifically, to enable the model to learn to cluster
relational data, our method leverages the readily available labeled data of
pre-defined relations to learn a relation-oriented representation. We minimize
distance between the instance with same relation by gathering the instances
towards their corresponding relation centroids to form a cluster structure, so
that the learned representation is cluster-friendly. To reduce the clustering
bias on predefined classes, we optimize the model by minimizing a joint
objective on both labeled and unlabeled data. Experimental results show that
our method reduces the error rate by 29.2% and 15.7%, on two datasets
respectively, compared with current SOTA methods.

    

### [[2109.07208] Channel Estimation Based on Machine Learning Paradigm for Spatial Modulation OFDM](http://arxiv.org/abs/2109.07208)


  In this paper, deep neural network (DNN) is integrated with spatial
modulation-orthogonal frequency division multiplexing (SM-OFDM) technique for
end-to-end data detection over Rayleigh fading channel. This proposed system
directly demodulates the received symbols, leaving the channel estimation done
only implicitly. Furthermore, an ensemble network is also proposed for this
system. Simulation results show that the proposed DNN detection scheme has a
significant advantage over classical methods when the pilot overhead and cyclic
prefix (CP) are reduced, owing to its ability to learn and adjust to
complicated channel conditions. Finally, the ensemble network is shown to
improve the generalization of the proposed scheme, while also showing a slight
improvement in its performance.

    

### [[2109.07212] Optimising Rolling Stock Planning including Maintenance with Constraint Programming and Quantum Annealing](http://arxiv.org/abs/2109.07212)


  We developed and compared Constraint Programming (CP) and Quantum Annealing
(QA) approaches for rolling stock optimisation considering necessary
maintenance tasks. To deal with such problems in CP we investigated specialised
pruning rules and implemented them in a global constraint. For the QA approach,
we developed quadratic unconstrained binary optimisation (QUBO) models. For
testing, we use data sets based on real data from Deutsche Bahn and run the QA
approach on real quantum computers from D-Wave. Classical computers are used to
run the CP approach as well as tabu search for the QUBO models. We find that
both approaches tend at the current development stage of the physical quantum
annealers to produce comparable results, with the caveat that QUBO does not
always guarantee that the maintenance constraints hold, which we fix by
adjusting the QUBO model in preprocessing, based on how close the trains are to
a maintenance threshold distance.

    

### [[2109.07228] Dialog speech sentiment classification for imbalanced datasets](http://arxiv.org/abs/2109.07228)


  Speech is the most common way humans express their feelings, and sentiment
analysis is the use of tools such as natural language processing and
computational algorithms to identify the polarity of these feelings. Even
though this field has seen tremendous advancements in the last two decades, the
task of effectively detecting under represented sentiments in different kinds
of datasets is still a challenging task. In this paper, we use single and
bi-modal analysis of short dialog utterances and gain insights on the main
factors that aid in sentiment detection, particularly in the underrepresented
classes, in datasets with and without inherent sentiment component.
Furthermore, we propose an architecture which uses a learning rate scheduler
and different monitoring criteria and provides state-of-the-art results for the
SWITCHBOARD imbalanced sentiment dataset.

    

### [[2109.07249] Temporal Parameter-free Deep Skinning of Animated Meshes](http://arxiv.org/abs/2109.07249)


  In computer graphics, animation compression is essential for efficient
storage, streaming and reproduction of animated meshes. Previous work has
presented efficient techniques for compression by deriving skinning
transformations and weights using clustering of vertices based on geometric
features of vertices over time. In this work we present a novel approach that
assigns vertices to bone-influenced clusters and derives weights using deep
learning through a training set that consists of pairs of vertex trajectories
(temporal vertex sequences) and the corresponding weights drawn from fully
rigged animated characters. The approximation error of the resulting linear
blend skinning scheme is significantly lower than the error of competent
previous methods by producing at the same time a minimal number of bones.
Furthermore, the optimal set of transformation and vertices is derived in fewer
iterations due to the better initial positioning in the multidimensional
variable space. Our method requires no parameters to be determined or tuned by
the user during the entire process of compressing a mesh animation sequence.

    

### [[2109.07373] A Unified Framework for Biphasic Facial Age Translation with Noisy-Semantic Guided Generative Adversarial Networks](http://arxiv.org/abs/2109.07373)


  Biphasic facial age translation aims at predicting the appearance of the
input face at any age. Facial age translation has received considerable
research attention in the last decade due to its practical value in cross-age
face recognition and various entertainment applications. However, most existing
methods model age changes between holistic images, regardless of the human face
structure and the age-changing patterns of individual facial components.
Consequently, the lack of semantic supervision will cause infidelity of
generated faces in detail. To this end, we propose a unified framework for
biphasic facial age translation with noisy-semantic guided generative
adversarial networks. Structurally, we project the class-aware noisy semantic
layouts to soft latent maps for the following injection operation on the
individual facial parts. In particular, we introduce two sub-networks,
ProjectionNet and ConstraintNet. ProjectionNet introduces the low-level
structural semantic information with noise map and produces soft latent maps.
ConstraintNet disentangles the high-level spatial features to constrain the
soft latent maps, which endows more age-related context into the soft latent
maps. Specifically, attention mechanism is employed in ConstraintNet for
feature disentanglement. Meanwhile, in order to mine the strongest mapping
ability of the network, we embed two types of learning strategies in the
training procedure, supervised self-driven generation and unsupervised
condition-driven cycle-consistent generation. As a result, extensive
experiments conducted on MORPH and CACD datasets demonstrate the prominent
ability of our proposed method which achieves state-of-the-art performance.

    

### [[2109.07377] Topic Transferable Table Question Answering](http://arxiv.org/abs/2109.07377)


  Weakly-supervised table question-answering(TableQA) models have achieved
state-of-art performance by using pre-trained BERT transformer to jointly
encoding a question and a table to produce structured query for the question.
However, in practical settings TableQA systems are deployed over table corpora
having topic and word distributions quite distinct from BERT's pretraining
corpus. In this work we simulate the practical topic shift scenario by
designing novel challenge benchmarks WikiSQL-TS and WikiTQ-TS, consisting of
train-dev-test splits in five distinct topic groups, based on the popular
WikiSQL and WikiTableQuestions datasets. We empirically show that, despite
pre-training on large open-domain text, performance of models degrades
significantly when they are evaluated on unseen topics. In response, we propose
T3QA (Topic Transferable Table Question Answering) a pragmatic adaptation
framework for TableQA comprising of: (1) topic-specific vocabulary injection
into BERT, (2) a novel text-to-text transformer generator (such as T5, GPT2)
based natural language question generation pipeline focused on generating topic
specific training data, and (3) a logical form reranker. We show that T3QA
provides a reasonably good baseline for our topic shift benchmarks. We believe
our topic split benchmarks will lead to robust TableQA solutions that are
better suited for practical deployment.

    

### [[2109.07411] AliMe MKG: A Multi-modal Knowledge Graph for Live-streaming E-commerce](http://arxiv.org/abs/2109.07411)


  Live streaming is becoming an increasingly popular trend of sales in
E-commerce. The core of live-streaming sales is to encourage customers to
purchase in an online broadcasting room. To enable customers to better
understand a product without jumping out, we propose AliMe MKG, a multi-modal
knowledge graph that aims at providing a cognitive profile for products,
through which customers are able to seek information about and understand a
product. Based on the MKG, we build an online live assistant that highlights
product search, product exhibition and question answering, allowing customers
to skim over item list, view item details, and ask item-related questions. Our
system has been launched online in the Taobao app, and currently serves
hundreds of thousands of customers per day.

    

### [[2109.07434] Discriminative and Generative Transformer-based Models For Situation Entity Classification](http://arxiv.org/abs/2109.07434)


  We re-examine the situation entity (SE) classification task with varying
amounts of available training data. We exploit a Transformer-based variational
autoencoder to encode sentences into a lower dimensional latent space, which is
used to generate the text and learn a SE classifier. Test set and cross-genre
evaluations show that when training data is plentiful, the proposed model can
improve over the previous discriminative state-of-the-art models. Our approach
performs disproportionately better with smaller amounts of training data, but
when faced with extremely small sets (4 instances per label), generative RNN
methods outperform transformers. Our work provides guidance for future efforts
on SE and semantic prediction tasks, and low-label training regimes.

    

### [[2109.07436] Synthesizing Policies That Account For Human Execution Errors Caused By StateAliasing In Markov Decision Processes](http://arxiv.org/abs/2109.07436)


  When humans are given a policy to execute, there can be pol-icy execution
errors and deviations in execution if there is un-certainty in identifying a
state. So an algorithm that computesa policy for a human to execute ought to
consider these effectsin its computations. An optimal MDP policy that is poorly
ex-ecuted (because of a human agent) maybe much worse thananother policy that
is executed with fewer errors. In this pa-per, we consider the problems of
erroneous execution and ex-ecution delay when computing policies for a human
agent thatwould act in a setting modeled by a Markov Decision Process(MDP). We
present a framework to model the likelihood ofpolicy execution errors and
likelihood of non-policy actionslike inaction (delays) due to state
uncertainty. This is followedby a hill climbing algorithm to search for good
policies thataccount for these errors. We then use the best policy found byhill
climbing with a branch and bound algorithm to find theoptimal policy. We show
experimental results in a Gridworlddomain and analyze the performance of the
two algorithms.We also present human studies that verify if our assumptionson
policy execution by humans under state-aliasing are rea-sonable.

    

### [[2109.07452] Can Machines Read Coding Manuals Yet? -- A Benchmark for Building Better Language Models for Code Understanding](http://arxiv.org/abs/2109.07452)


  Code understanding is an increasingly important application of Artificial
Intelligence. A fundamental aspect of understanding code is understanding text
about code, e.g., documentation and forum discussions. Pre-trained language
models (e.g., BERT) are a popular approach for various NLP tasks, and there are
now a variety of benchmarks, such as GLUE, to help improve the development of
such models for natural language understanding. However, little is known about
how well such models work on textual artifacts about code, and we are unaware
of any systematic set of downstream tasks for such an evaluation. In this
paper, we derive a set of benchmarks (BLANCA - Benchmarks for LANguage models
on Coding Artifacts) that assess code understanding based on tasks such as
predicting the best answer to a question in a forum post, finding related forum
posts, or predicting classes related in a hierarchy from class documentation.
We evaluate the performance of current state-of-the-art language models on
these tasks and show that there is a significant improvement on each task from
fine tuning. We also show that multi-task training over BLANCA tasks helps
build better language models for code understanding.

    

### [[2109.07461] MPC-Friendly Commitments for Publicly Verifiable Covert Security](http://arxiv.org/abs/2109.07461)


  We address the problem of efficiently verifying a commitment in a two-party
computation. This addresses the scenario where a party P1 commits to a value
$x$ to be used in a subsequent secure computation with another party P2 that
wants to receive assurance that P1 did not cheat, i.e. that $x$ was indeed the
value inputted into the secure computation. Our constructions operate in the
publicly verifiable covert (PVC) security model, which is a relaxation of the
malicious model of MPC appropriate in settings where P1 faces a reputational
harm if caught cheating.
We introduce the notion of PVC commitment scheme and indexed hash functions
to build commitments schemes tailored to the PVC framework, and propose
constructions for both arithmetic and Boolean circuits that result in very
efficient circuits. From a practical standpoint, our constructions for Boolean
circuits are $60\times$ faster to evaluate securely, and use $36\times$ less
communication than baseline methods based on hashing. Moreover, we show that
our constructions are tight in terms of required non-linear operations, by
proving lower bounds on the nonlinear gate count of commitment verification
circuits. Finally, we present a technique to amplify the security properties
our constructions that allows to efficiently recover malicious guarantees with
statistical security.

    

### [[2001.04425] Negative Statements Considered Useful](http://arxiv.org/abs/2001.04425)


  Knowledge bases (KBs) about notable entities and their properties are an
important asset in applications such as search, question answering and
dialogue. All popular KBs capture virtually only positive statements, and
abstain from taking any stance on statements not stored in the KB. This paper
makes the case for explicitly stating salient statements that do not hold.
Negative statements are useful to overcome limitations of question answering
systems that are mainly geared for positive questions; they can also contribute
to informative summaries of entities. Due to the abundance of such invalid
statements, any effort to compile them needs to address ranking by saliency. We
present a statisticalinference method for compiling and ranking negative
statements, based on expectations from positive statements of related entities
in peer groups. Experimental results, with a variety of datasets, show that the
method can effectively discover notable negative statements, and extrinsic
studies underline their usefulness for entity summarization. Datasets and code
are released as resources for further research.

    

### [[2102.02315] Real-Time Optimal Trajectory Planning for Autonomous Vehicles and Lap Time Simulation Using Machine Learning](http://arxiv.org/abs/2102.02315)


  Widespread development of driverless vehicles has led to the formation of
autonomous racing, where technological development is accelerated by the high
speeds and competitive environment of motorsport. A particular challenge for an
autonomous vehicle is that of identifying a target trajectory - or, in the case
of a competition vehicle, the racing line. Many existing approaches to finding
the racing line are either not time-optimal solutions, or are computationally
expensive - rendering them unsuitable for real-time application using on-board
processing hardware. This study describes a machine learning approach to
generating an accurate prediction of the racing line in real-time on desktop
processing hardware. The proposed algorithm is a feed-forward neural network,
trained using a dataset comprising racing lines for a large number of circuits
calculated via traditional optimal control lap time simulation. The network
predicts the racing line with a mean absolute error of +/-0.27m, and just
+/-0.11m at corner apex - comparable to human drivers, and autonomous vehicle
control subsystems. The approach generates predictions within 33ms, making it
over 9,000 times faster than traditional methods of finding the optimal
trajectory. Results suggest that for certain applications data-driven
approaches to find near-optimal racing lines may be favourable to traditional
computational methods.

    

### [[2104.08313] Does language help generalization in vision models?](http://arxiv.org/abs/2104.08313)


  Vision models trained on multimodal datasets can benefit from the wide
availability of large image-caption datasets. A recent model (CLIP) was found
to generalize well in zero-shot and transfer learning settings. This could
imply that linguistic or "semantic grounding" confers additional generalization
abilities to the visual feature space. Here, we systematically evaluate various
multimodal architectures and vision-only models in terms of unsupervised
clustering, few-shot learning, transfer learning and adversarial robustness. In
each setting, multimodal training produced no additional generalization
capability compared to standard supervised visual training. We conclude that
work is still required for semantic grounding to help improve vision models.

    

### [[2105.06232] Retrieval-Free Knowledge-Grounded Dialogue Response Generation with Adapters](http://arxiv.org/abs/2105.06232)


  To diversify and enrich generated dialogue responses, knowledge-grounded
dialogue has been investigated in recent years. The existing methods tackle the
knowledge grounding challenge by retrieving the relevant sentences over a large
corpus and augmenting the dialogues with explicit extra information. Despite
their success, however, the existing works have drawbacks on the inference
efficiency. This paper proposes KnowExpert, an end-to-end framework to bypass
the explicit retrieval process and inject knowledge into the pre-trained
language models with lightweight adapters and adapt to the knowledge-grounded
dialogue task. To the best of our knowledge, this is the first attempt to
tackle this challenge without retrieval in this task under an open-domain
chit-chat scenario. The experimental results show that KknowExpert performs
comparably with some retrieval-based baselines while being time-efficient in
inference, demonstrating the potential of our proposed direction.

    

### [[2109.02363] From Alignment to Assignment: Frustratingly Simple Unsupervised Entity Alignment](http://arxiv.org/abs/2109.02363)


  Cross-lingual entity alignment (EA) aims to find the equivalent entities
between crosslingual KGs, which is a crucial step for integrating KGs.
Recently, many GNN-based EA methods are proposed and show decent performance
improvements on several public datasets. Meanwhile, existing GNN-based EA
methods inevitably inherit poor interpretability and low efficiency from neural
networks. Motivated by the isomorphic assumption of GNNbased methods, we
successfully transform the cross-lingual EA problem into the assignment
problem. Based on this finding, we propose a frustratingly Simple but Effective
Unsupervised entity alignment method (SEU) without neural networks. Extensive
experiments show that our proposed unsupervised method even beats advanced
supervised methods across all public datasets and has high efficiency,
interpretability, and stability.

    

### [[2109.05958] Not All Models Localize Linguistic Knowledge in the Same Place: A Layer-wise Probing on BERToids' Representations](http://arxiv.org/abs/2109.05958)


  Most of the recent works on probing representations have focused on BERT,
with the presumption that the findings might be similar to the other models. In
this work, we extend the probing studies to two other models in the family,
namely ELECTRA and XLNet, showing that variations in the pre-training
objectives or architectural choices can result in different behaviors in
encoding linguistic information in the representations. Most notably, we
observe that ELECTRA tends to encode linguistic knowledge in the deeper layers,
whereas XLNet instead concentrates that in the earlier layers. Also, the former
model undergoes a slight change during fine-tuning, whereas the latter
experiences significant adjustments. Moreover, we show that drawing conclusions
based on the weight mixing evaluation strategy -- which is widely used in the
context of layer-wise probing -- can be misleading given the norm disparity of
the representations across different layers. Instead, we adopt an alternative
information-theoretic probing with minimum description length, which has
recently been proven to provide more reliable and informative results.

    

### [[2109.07173] A Comparison of Code Embeddings and Beyond](http://arxiv.org/abs/2109.07173)


  Program representation learning is a fundamental task in software engineering
applications. With the availability of "big code" and the development of deep
learning techniques, various program representation learning models have been
proposed to understand the semantic properties of programs and applied on
different software engineering tasks. However, no previous study has
comprehensively assessed the generalizability of these deep models on different
tasks, so that the pros and cons of the models are unclear. In this experience
paper, we try to bridge this gap by systemically evaluating the performance of
eight program representation learning models on three common tasks, where six
models are based on abstract syntax trees and two models are based on plain
text of source code. We kindly explain the criteria for selecting the models
and tasks, as well as the method for enabling end-to-end learning in each task.
The results of performance evaluation show that they perform diversely in each
task and the performance of the AST-based models is generally unstable over
different tasks. In order to further explain the results, we apply a prediction
attribution technique to find what elements are captured by the models and
responsible for the predictions in each task. Based on the findings, we discuss
some general principles for better capturing the information in the source
code, and hope to inspire researchers to improve program representation
learning methods for software engineering tasks.

    

### [[2109.07382] Toward Modern Fortran Tooling and a Thriving Developer Community](http://arxiv.org/abs/2109.07382)


  Fortran is the oldest high-level programming language that remains in use
today and is one of the dominant languages used for compute-intensive
scientific and engineering applications. However, Fortran has not kept up with
the modern software development practices and tooling in the internet era. As a
consequence, the Fortran developer experience has diminished. Specifically,
lack of a rich general-purpose library ecosystem, modern tools for building and
packaging Fortran libraries and applications, and online learning resources,
has made it difficult for Fortran to attract and retain new users. To address
this problem, an open source community has formed on GitHub in 2019 and began
to work on the initial set of core tools: a standard library, a build system
and package manager, and a community-curated website for Fortran. In this paper
we report on the progress to date and outline the next steps.

    

### [[2109.07441] DPGen: Automated Program Synthesis for Differential Privacy](http://arxiv.org/abs/2109.07441)


  Differential privacy has become a de facto standard for releasing data in a
privacy-preserving way. Creating a differentially private algorithm is a
process that often starts with a noise-free (non-private) algorithm. The
designer then decides where to add noise, and how much of it to add. This can
be a non-trivial process -- if not done carefully, the algorithm might either
violate differential privacy or have low utility.
In this paper, we present DPGen, a program synthesizer that takes in
non-private code (without any noise) and automatically synthesizes its
differentially private version (with carefully calibrated noise). Under the
hood, DPGen uses novel algorithms to automatically generate a sketch program
with candidate locations for noise, and then optimize privacy proof and noise
scales simultaneously on the sketch program. Moreover, DPGen can synthesize
sophisticated mechanisms that adaptively process queries until a specified
privacy budget is exhausted. When evaluated on standard benchmarks, DPGen is
able to generate differentially private mechanisms that optimize simple utility
functions within 120 seconds. It is also powerful enough to synthesize adaptive
privacy mechanisms.

    

### [[2010.01678] Optimal Neural Program Synthesis from Multimodal Specifications](http://arxiv.org/abs/2010.01678)


  Multimodal program synthesis, which leverages different types of user input
to synthesize a desired program, is an attractive way to scale program
synthesis to challenging settings; however, it requires integrating noisy
signals from the user, like natural language, with hard constraints on the
program's behavior. This paper proposes an optimal neural synthesis approach
where the goal is to find a program that satisfies user-provided constraints
while also maximizing the program's score with respect to a neural model.
Specifically, we focus on multimodal synthesis tasks in which the user intent
is expressed using a combination of natural language (NL) and input-output
examples. At the core of our method is a top-down recurrent neural model that
places distributions over abstract syntax trees conditioned on the NL input.
This model not only allows for efficient search over the space of syntactically
valid programs, but it allows us to leverage automated program analysis
techniques for pruning the search space based on infeasibility of partial
programs with respect to the user's constraints. The experimental results on a
multimodal synthesis dataset (StructuredRegex) show that our method
substantially outperforms prior state-of-the-art techniques in terms of
accuracy and efficiency, and finds model-optimal programs more frequently.

    

### [[2101.09783] Termination Analysis Without the Tears](http://arxiv.org/abs/2101.09783)


  Determining whether a given program terminates is the quintessential
undecidable problem. Algorithms for termination analysis are divided into two
groups: (1) algorithms with strong behavioral guarantees that work in limited
circumstances (e.g., complete synthesis of linear ranking functions for
polyhedral loops [Podelski and Rybalchenko, 2004]), and (2) algorithms that are
widely applicable, but have weak behavioral guarantees (e.g., Terminator [Cook
et al., 2006]). This paper investigates the space in between: how can we design
practical termination analyzers with useful behavioral guarantees?
This paper presents a termination analysis that is both compositional (the
result of analyzing a composite program is a function of the analysis results
of its components) and monotone ("more information into the analysis yields
more information out"). The paper has two key contributions. The first is an
extension of Tarjan's method for solving path problems in graphs to solve
infinite path problems. This provides a foundation upon which to build
compositional termination analyses. The second is a collection of monotone
conditional termination analyses based on this framework. We demonstrate that
our tool ComPACT (Compositional and Predictable Analysis for Conditional
Termination) is competitive with state-of-the-art termination tools while
providing stronger behavioral guarantees.

    

### [[2104.10749] Constantine: Automatic Side-Channel Resistance Using Efficient Control and Data Flow Linearization](http://arxiv.org/abs/2104.10749)


  In the era of microarchitectural side channels, vendors scramble to deploy
mitigations for transient execution attacks, but leave traditional side-channel
attacks against sensitive software (e.g., crypto programs) to be fixed by
developers by means of constant-time programming (i.e., absence of
secret-dependent code/data patterns). Unfortunately, writing constant-time code
by hand is hard, as evidenced by the many flaws discovered in production side
channel-resistant code. Prior efforts to automatically transform programs into
constant-time equivalents offer limited security or compatibility guarantees,
hindering their applicability to real-world software.
In this paper, we present Constantine, a compiler-based system to
automatically harden programs against microarchitectural side channels.
Constantine pursues a radical design point where secret-dependent control and
data flows are completely linearized (i.e., all involved code/data accesses are
always executed). This strategy provides strong security and compatibility
guarantees by construction, but its natural implementation leads to state
explosion in real-world programs. To address this challenge, Constantine relies
on carefully designed optimizations such as just-in-time loop linearization and
aggressive function cloning for fully context-sensitive points-to analysis,
which not only address state explosion, but also lead to an efficient and
compatible solution. Constantine yields overheads as low as 16% on standard
benchmarks and can handle a fully-fledged component from the production wolfSSL
library.

    

### [[2106.12995] Userfault Objects: Transparent Programmable Memory](http://arxiv.org/abs/2106.12995)


  The Userfault Object (UFO) framework explores avenues of cooperating with the
operating system to use memory in non-traditional ways. We implement a
framework that employs the Linux kernel's userfault mechanism to fill the
contents of runtime objects on demand. When an object's memory is accessed the
framework executes a user-defined function that generates a slice of the
object. The back-end can generate data from thin air, calculate it from a
formula, or retrieve it from persistent storage, the network, or other sources
(with or without post-processing). UFOs follow the memory layout of standard
runtime objects, so they can be introspected and written to safely. The
framework manages the loading and unloading of object segments to ensure that
memory is reclaimed as needed and data is never lost. This allows the UFO
framework to implement larger-than-memory data structures that never
materialize into memory in full. Implementing objects as UFOs also impacts
performance, since overhead of populating memory is amortized by loading entire
pages of data at a time. The host runtime can also rely on direct memory
accesses into userfault object obviating the need for a special dispatch
mechanism. We provide a proof-of-concept implementation of the UFO framework
for the R language.

    

### [<title>Debugging by starting a REPL at a breakpoint is fun</title>](https://jvns.ca/blog/2021/09/16/debugging-in-a-repl-is-fun/)