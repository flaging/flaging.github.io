
## 2021-11-4

### [<title>[医学分享]临汾代开医院免军训证明(免体育免测证明 - DockOne.io</title>](http://dockone.io/question/1581096)

### [<title>〖今日发布〗东莞开医院诊断证明(代开医院出院小结 - DockOne.io</title>](http://dockone.io/question/1581095)

### [<title>[医学分享]晋城代开医院免军训证明(免体育免测证明 - DockOne.io</title>](http://dockone.io/question/1581094)

### [<title>〖今日发布〗大连开医院诊断证明(代开医院出院小结 - DockOne.io</title>](http://dockone.io/question/1581093)

### [<title>〖今日发布〗郑州开医院诊断证明(代开医院出院小结 - DockOne.io</title>](http://dockone.io/question/1581092)

### [<title>[医学分享]长治代开医院免军训证明(免体育免测证明 - DockOne.io</title>](http://dockone.io/question/1581091)

### [<title>〖今日发布〗青岛开医院诊断证明(代开医院出院小结 - DockOne.io</title>](http://dockone.io/question/1581090)

### [<title>〖今日发布〗沈阳开医院诊断证明(代开医院出院小结 - DockOne.io</title>](http://dockone.io/question/1581089)

### [<title>[医学分享]晋中代开医院免军训证明(免体育免测证明 - DockOne.io</title>](http://dockone.io/question/1581088)

### [<title>〖今日发布〗长沙开医院诊断证明(代开医院出院小结 - DockOne.io</title>](http://dockone.io/question/1581087)

### [<title>[医学分享]吕梁代开医院免军训证明(免体育免测证明 - DockOne.io</title>](http://dockone.io/question/1581086)

### [<title>[医学分享]阳泉代开医院免军训证明(免体育免测证明 - DockOne.io</title>](http://dockone.io/question/1581085)

### [<title>[医学分享]忻州代开医院免军训证明(免体育免测证明 - DockOne.io</title>](http://dockone.io/question/1581084)

### [<title>〖今日发布〗西安开医院诊断证明(代开医院出院小结 - DockOne.io</title>](http://dockone.io/question/1581083)

### [<title>〖今日发布〗苏州开医院诊断证明(代开医院出院小结 - DockOne.io</title>](http://dockone.io/question/1581082)

### [<title>[医学分享]朔州代开医院免军训证明(免体育免测证明 - DockOne.io</title>](http://dockone.io/question/1581081)

### [<title>[医学分享]大同代开医院免军训证明(免体育免测证明 - DockOne.io</title>](http://dockone.io/question/1581080)

### [<title>〖今日发布〗天津开医院诊断证明(代开医院出院小结 - DockOne.io</title>](http://dockone.io/question/1581079)

### [<title>[医学分享]太原代开医院免军训证明(免体育免测证明 - DockOne.io</title>](http://dockone.io/question/1581078)

### [<title>[医学分享]衡水代开医院免军训证明(免体育免测证明 - DockOne.io</title>](http://dockone.io/question/1581077)

### [<title>Distributed XGBoost training on multi-node and multi-GPU cluster - XGBoost</title>](https://discuss.xgboost.ai/t/distributed-xgboost-training-on-multi-node-and-multi-gpu-cluster/2523/1)

### [[2111.01827] Equivalent Versions of Total Flow Analysis](http://arxiv.org/abs/2111.01827)


  Total Flow Analysis (TFA) is a method for conducting the worst-case analysis
of time sensitive networks without cyclic dependencies. In networks with cyclic
dependencies, Fixed-Point TFA introduces artificial cuts, analyses the
resulting cycle-free network with TFA, and iterates. If it converges, it does
provide valid performance bounds. We show that the choice of the specific cuts
used by Fixed-Point TFA does not affect its convergence nor the obtained
performance bounds, and that it can be replaced by an alternative algorithm
that does not use any cut at all, while still applying to cyclic dependencies.

    

### [[2111.02186] EASE: Energy-Aware job Scheduling for vehicular Edge networks with renewable energy resources](http://arxiv.org/abs/2111.02186)


  The energy sustainability of multi-access edge computing (MEC) platforms is
addressed in this paper, by developing Energy-Aware job Scheduling at the Edge
(EASE), a computing resource scheduler for edge servers co-powered by renewable
energy resources and the power grid. The scenario under study involves the
optimal allocation and migration of time-sensitive computing tasks in a
resource-constrained internet of vehicles (IoV) context. This is achieved by
tackling, as a main objective, the minimization of the carbon footprint of the
edge network, whilst delivering adequate quality of service (QoS) to the end
users (e.g., meeting task execution deadlines). EASE integrates a i)
centralized optimization step, solved through model predictive control (MPC),
to manage the renewable energy that is locally collected at the edge servers
and their local computing resources, estimating their future availability, and
ii) a distributed consensus step, solved via dual ascent in closed form, to
reach agreement on service migrations. EASE is compared with existing
strategies that always and never migrate the computing tasks. Quantitative
results demonstrate the greater energy efficiency achieved by EASE, which often
gets close to complete carbon neutrality, while also improving the QoS.

    

### [[2111.02268] Data-Plane Security Applications in Adversarial Settings](http://arxiv.org/abs/2111.02268)


  High-speed programmable switches have emerged as a promising building block
for developing performant data-plane applications. In this paper, we argue that
the resource constraints and programming model in hardware switches has led to
developers adopting problematic design patterns, whose security implications
are not widely understood. We bridge the gap by identifying the major
challenges and common design pitfalls in switch-based applications in
adversarial settings. Examining six recently-proposed switch-based security
applications, we find that adversaries can exploit these design pitfalls to
completely bypass the protection these applications were designed to provide,
or disrupt system operations by introducing collateral damage.

    

### [[2111.02309] Pull or Wait: How to Optimize Query Age of Information](http://arxiv.org/abs/2111.02309)


  We study a pull-based status update communication model where a source node
submits update packets to a channel with random transmission delay, at times
requested by a remote destination node. The objective is to minimize the
average query-age-of-information (QAoI), defined as the average
age-of-information (AoI) measured at query instants that occur at the
destination side according to a stochastic arrival process. In reference to a
push-based problem formulation defined in the literature where the source
decides to \textit{update or wait} at will, with the objective of minimizing
the time average AoI at the destination, we name this problem the
\textit{Pull-or-Wait} (PoW) problem. We provide a comparison of the two
formulations: (i) Under Poisson query arrivals, an optimal policy that
minimizes the time average AoI also minimizes the average QAoI, and these
minimum values are equal; and (ii) the optimal average QAoI under periodic
query arrivals is always less than or equal to the optimal time average AoI. We
identify the PoW problem in the case of a single query as a stochastic shortest
path (SSP) problem with uncountable state and action spaces, which has been not
solved in previous literature. We derive an optimal solution for this SSP
problem and use it as a building block for the solution of the PoW problem
under periodic query arrivals.

    

### [[1907.10331] Measuring ad value without bankrupting user privacy](http://arxiv.org/abs/1907.10331)


  The Real Time Bidding (RTB) protocol is by now more than a decade old. During
this time, a handful of measurement papers have looked at bidding strategies,
personal information flow, and cost of display advertising through RTB. In this
paper, we present YourAdvalue, a privacy-preserving tool for displaying to
end-users in a simple and intuitive manner their advertising value as seen
through RTB. Using YourAdvalue, we measure desktop RTB prices in the wild, and
compare them with desktop and mobile RTB prices reported by past work. We
present how it estimates ad prices that are encrypted, and how it preserves
user privacy while reporting results back to a data-server for analysis. We
deployed our system, disseminated its browser extension, and collected data
from 200 users, including 12000 ad impressions over 11 months.
By analyzing this dataset, we show that desktop RTB prices have grown 4.6X
over desktop RTB prices measured in 2013, and 3.8X over mobile RTB prices
measured in 2015. We also study how user demographics associate with the
intensity of RTB ecosystem tracking, leading to higher ad prices. We find that
exchanging data between advertisers and/or data brokers through
cookie-synchronization increases the median value of displayed ads by 19%. We
also find that female and younger users are more targeted, suffering more
tracking (via cookie synchronization) than male or elder users. As a result of
this targeting in our dataset, the advertising value (i) of women is 2.4X
higher than that of men, (ii) of 25-34 year-olds is 2.5X higher than that of
35-44 year-olds, (iii) is most expensive on weekends and early mornings.

    

### [[2104.11042] High-Accuracy Ranging and Localization with Ultra-Wideband Communications for Energy-Constrained Devices](http://arxiv.org/abs/2104.11042)


  Ultra-wideband (UWB) communications have gained popularity in recent years
for being able to provide distance measurements and localization with high
accuracy, which can enhance the capabilities of devices in the Internet of
Things (IoT). Since energy efficiency is of utmost concern in such
applications, in this work we evaluate the power and energy consumption,
distance measurements, and localization performance of two types of UWB
physical interfaces (PHYs), which use either a low- or high-rate pulse
repetition (LRP and HRP, respectively). The evaluation is done through
measurements acquired in identical conditions, which is crucial in order to
have a fair comparison between the devices. The LRP devices that we tested have
the same ranging and localization performance, but ten times (10x) lower power
consumption, 6x lower energy consumption per distance measurement, and at least
8x higher coverage than the HRP devices. Therefore, UWB LRP devices can offer
high-accuracy ranging and localization even to ultra-low-power devices in the
IoT. We performed measurements in typical LOS and NLOS scenarios and propose
theoretical models for the distance errors obtained in these situations. The
models can be used to simulate realistic building deployments and we illustrate
such an example. This paper, therefore, provides a comprehensive overview of
the energy demands, ranging characteristics, and localization performance of
state-of-the-art UWB devices.

    

### [[2106.12553] Femto-Containers: DevOps on Microcontrollers with Lightweight Virtualization & Isolation for IoT Software Modules](http://arxiv.org/abs/2106.12553)


  Development, deployment and maintenance of networked software has been
revolutionized by DevOps, which have become essential to boost system software
quality and to enable agile evolution. Meanwhile the Internet of Things (IoT)
connects more and more devices which are not covered by DevOps tools:
low-power, microcontroller-based devices. In this paper, we contribute to
bridge this gap by designing Femto-Containers, a new architecture which enables
containerization, virtualization and secure deployment of software modules
embedded on microcontrollers over low-power networks. As proof-of-concept, we
implemented and evaluated Femto-Containers on popular microcontroller
architectures (Arm Cortex-M, ESP32 and RISC-V), using eBPF virtualization, and
RIOT, a common operating system in this space. We show that Femto-Containers
can virtualize and isolate multiple software modules, executed concurrently,
with very small memory footprint overhead (below 10%) and very small startup
time (tens of microseconds) compared to native code execution. We show that
Femto-Containers can satisfy the constraints of both low-level debug logic
inserted in a hot code path, and high-level business logic coded in a variety
of common programming languages. Compared to prior work, Femto-Containers thus
offer an attractive trade-off in terms of memory footprint, energy consumption,
agility and security.

    

### [[2111.01842] Coordinate Linear Variance Reduction for Generalized Linear Programming](http://arxiv.org/abs/2111.01842)


  We study a class of generalized linear programs (GLP) in a large-scale
setting, which includes possibly simple nonsmooth convex regularizer and simple
convex set constraints. By reformulating GLP as an equivalent convex-concave
min-max problem, we show that the linear structure in the problem can be used
to design an efficient, scalable first-order algorithm, to which we give the
name \emph{Coordinate Linear Variance Reduction} (\textsc{clvr}; pronounced
``clever''). \textsc{clvr} is an incremental coordinate method with implicit
variance reduction that outputs an \emph{affine combination} of the dual
variable iterates. \textsc{clvr} yields improved complexity results for (GLP)
that depend on the max row norm of the linear constraint matrix in (GLP) rather
than the spectral norm. When the regularization terms and constraints are
separable, \textsc{clvr} admits an efficient lazy update strategy that makes
its complexity bounds scale with the number of nonzero elements of the linear
constraint matrix in (GLP) rather than the matrix dimensions. We show that
Distributionally Robust Optimization (DRO) problems with ambiguity sets based
on both $f$-divergence and Wasserstein metrics can be reformulated as (GLPs) by
introducing sparsely connected auxiliary variables. We complement our
theoretical guarantees with numerical experiments that verify our algorithm's
practical effectiveness, both in terms of wall-clock time and number of data
passes.

    

### [[2111.01847] Basis Matters: Better Communication-Efficient Second Order Methods for Federated Learning](http://arxiv.org/abs/2111.01847)


  Recent advances in distributed optimization have shown that Newton-type
methods with proper communication compression mechanisms can guarantee fast
local rates and low communication cost compared to first order methods. We
discover that the communication cost of these methods can be further reduced,
sometimes dramatically so, with a surprisingly simple trick: {\em Basis Learn
(BL)}. The idea is to transform the usual representation of the local Hessians
via a change of basis in the space of matrices and apply compression tools to
the new representation. To demonstrate the potential of using custom bases, we
design a new Newton-type method (BL1), which reduces communication cost via
both {\em BL} technique and bidirectional compression mechanism. Furthermore,
we present two alternative extensions (BL2 and BL3) to partial participation to
accommodate federated learning applications. We prove local linear and
superlinear rates independent of the condition number. Finally, we support our
claims with numerical experiments by comparing several first and
second~order~methods.

    

### [[2111.01853] Recursive Bayesian Networks: Generalising and Unifying Probabilistic Context-Free Grammars and Dynamic Bayesian Networks](http://arxiv.org/abs/2111.01853)


  Probabilistic context-free grammars (PCFGs) and dynamic Bayesian networks
(DBNs) are widely used sequence models with complementary strengths and
limitations. While PCFGs allow for nested hierarchical dependencies (tree
structures), their latent variables (non-terminal symbols) have to be discrete.
In contrast, DBNs allow for continuous latent variables, but the dependencies
are strictly sequential (chain structure). Therefore, neither can be applied if
the latent variables are assumed to be continuous and also to have a nested
hierarchical dependency structure. In this paper, we present Recursive Bayesian
Networks (RBNs), which generalise and unify PCFGs and DBNs, combining their
strengths and containing both as special cases. RBNs define a joint
distribution over tree-structured Bayesian networks with discrete or continuous
latent variables. The main challenge lies in performing joint inference over
the exponential number of possible structures and the continuous variables. We
provide two solutions: 1) For arbitrary RBNs, we generalise inside and outside
probabilities from PCFGs to the mixed discrete-continuous case, which allows
for maximum posterior estimates of the continuous latent variables via gradient
descent, while marginalising over network structures. 2) For Gaussian RBNs, we
additionally derive an analytic approximation, allowing for robust parameter
optimisation and Bayesian inference. The capacity and diverse applications of
RBNs are illustrated on two examples: In a quantitative evaluation on synthetic
data, we demonstrate and discuss the advantage of RBNs for segmentation and
tree induction from noisy sequences, compared to change point detection and
hierarchical clustering. In an application to musical data, we approach the
unsolved problem of hierarchical music analysis from the raw note level and
compare our results to expert annotations.

    

### [[2111.01861] Source-to-Source Automatic Differentiation of OpenMP Parallel Loops](http://arxiv.org/abs/2111.01861)


  This paper presents our work toward correct and efficient automatic
differentiation of OpenMP parallel worksharing loops in forward and reverse
mode. Automatic differentiation is a method to obtain gradients of numerical
programs, which are crucial in optimization, uncertainty quantification, and
machine learning. The computational cost to compute gradients is a common
bottleneck in practice. For applications that are parallelized for multicore
CPUs or GPUs using OpenMP, one also wishes to compute the gradients in
parallel. We propose a framework to reason about the correctness of the
generated derivative code, from which we justify our OpenMP extension to the
differentiation model. We implement this model in the automatic differentiation
tool Tapenade and present test cases that are differentiated following our
extended differentiation procedure. Performance of the generated derivative
programs in forward and reverse mode is better than sequential, although our
reverse mode often scales worse than the input programs.

    

### [[2111.01865] Off-Policy Correction for Deep Deterministic Policy Gradient Algorithms via Batch Prioritized Experience Replay](http://arxiv.org/abs/2111.01865)


  The experience replay mechanism allows agents to use the experiences multiple
times. In prior works, the sampling probability of the transitions was adjusted
according to their importance. Reassigning sampling probabilities for every
transition in the replay buffer after each iteration is highly inefficient.
Therefore, experience replay prioritization algorithms recalculate the
significance of a transition when the corresponding transition is sampled to
gain computational efficiency. However, the importance level of the transitions
changes dynamically as the policy and the value function of the agent are
updated. In addition, experience replay stores the transitions are generated by
the previous policies of the agent that may significantly deviate from the most
recent policy of the agent. Higher deviation from the most recent policy of the
agent leads to more off-policy updates, which is detrimental for the agent. In
this paper, we develop a novel algorithm, Batch Prioritizing Experience Replay
via KL Divergence (KLPER), which prioritizes batch of transitions rather than
directly prioritizing each transition. Moreover, to reduce the off-policyness
of the updates, our algorithm selects one batch among a certain number of
batches and forces the agent to learn through the batch that is most likely
generated by the most recent policy of the agent. We combine our algorithm with
Deep Deterministic Policy Gradient and Twin Delayed Deep Deterministic Policy
Gradient and evaluate it on various continuous control tasks. KLPER provides
promising improvements for deep deterministic continuous control algorithms in
terms of sample efficiency, final performance, and stability of the policy
during the training.

    

### [[2111.01866] 3-D PET Image Generation with tumour masks using TGAN](http://arxiv.org/abs/2111.01866)


  Training computer-vision related algorithms on medical images for disease
diagnosis or image segmentation is difficult due to the lack of training data,
labeled samples, and privacy concerns. For this reason, a robust generative
method to create synthetic data is highly sought after. However, most
three-dimensional image generators require additional image input or are
extremely memory intensive. To address these issues we propose adapting video
generation techniques for 3-D image generation. Using the temporal GAN (TGAN)
architecture, we show we are able to generate realistic head and neck PET
images. We also show that by conditioning the generator on tumour masks, we are
able to control the geometry and location of the tumour in the generated
images. To test the utility of the synthetic images, we train a segmentation
model using the synthetic images. Synthetic images conditioned on real tumour
masks are automatically segmented, and the corresponding real images are also
segmented. We evaluate the segmentations using the Dice score and find the
segmentation algorithm performs similarly on both datasets (0.65 synthetic
data, 0.70 real data). Various radionomic features are then calculated over the
segmented tumour volumes for each data set. A comparison of the real and
synthetic feature distributions show that seven of eight feature distributions
had statistically insignificant differences (p>0.05). Correlation coefficients
were also calculated between all radionomic features and it is shown that all
of the strong statistical correlations in the real data set are preserved in
the synthetic data set.

    

### [[2111.01867] FEM-based Real-Time Simulations of Large Deformations with Probabilistic Deep Learning](http://arxiv.org/abs/2111.01867)


  For many engineering applications, such as real-time simulations or control,
conventional solution techniques of the underlying nonlinear problems are
usually computationally too expensive. In this work, we propose a highly
efficient deep-learning surrogate framework that is able to predict the
response of hyper-elastic bodies under load. The surrogate model takes the form
of special convolutional neural network architecture, so-called U-Net, which is
trained with force-displacement data obtained with the finite element method.
We propose deterministic- and probabilistic versions of the framework and study
it for three benchmark problems. In particular, we check the capabilities of
the Maximum Likelihood and the Variational Bayes Inference formulations to
assess the confidence intervals of solutions.

    

### [[2111.01868] From Strings to Data Science: a Practical Framework for Automated String Handling](http://arxiv.org/abs/2111.01868)


  Many machine learning libraries require that string features be converted to
a numerical representation for the models to work as intended. Categorical
string features can represent a wide variety of data (e.g., zip codes, names,
marital status), and are notoriously difficult to preprocess automatically. In
this paper, we propose a framework to do so based on best practices, domain
knowledge, and novel techniques. It automatically identifies different types of
string features, processes them accordingly, and encodes them into numerical
representations. We also provide an open source Python implementation to
automatically preprocess categorical string data in tabular datasets and
demonstrate promising results on a wide range of datasets.

    

### [[2111.01872] A Survey of Fairness-Aware Federated Learning](http://arxiv.org/abs/2111.01872)


  Recent advances in Federated Learning (FL) have brought large-scale machine
learning opportunities for massive distributed clients with performance and
data privacy guarantees. However, most current works only focus on the interest
of the central controller in FL, and ignore the interests of clients. This may
result in unfairness which discourages clients from actively participating in
the learning process and damages the sustainability of the whole FL system.
Therefore, the topic of ensuring fairness in an FL is attracting a great deal
of research interest. In recent years, diverse Fairness-Aware FL (FAFL)
approaches have been proposed in an effort to achieve fairness in FL from
different viewpoints. However, there is no comprehensive survey which helps
readers gain insight into this interdisciplinary field. This paper aims to
provide such a survey. By examining the fundamental and simplifying
assumptions, as well as the notions of fairness adopted by existing literature
in this field, we propose a taxonomy of FAFL approaches covering major steps in
FL, including client selection, optimization, contribution evaluation and
incentive distribution. In addition, we discuss the main metrics for
experimentally evaluating the performance of FAFL approaches, and suggest some
promising future research directions.

    

### [[2111.01875] Subquadratic Overparameterization for Shallow Neural Networks](http://arxiv.org/abs/2111.01875)


  Overparameterization refers to the important phenomenon where the width of a
neural network is chosen such that learning algorithms can provably attain zero
loss in nonconvex training. The existing theory establishes such global
convergence using various initialization strategies, training modifications,
and width scalings. In particular, the state-of-the-art results require the
width to scale quadratically with the number of training data under standard
initialization strategies used in practice for best generalization performance.
In contrast, the most recent results obtain linear scaling either with
requiring initializations that lead to the "lazy-training", or training only a
single layer. In this work, we provide an analytical framework that allows us
to adopt standard initialization strategies, possibly avoid lazy training, and
train all layers simultaneously in basic shallow neural networks while
attaining a desirable subquadratic scaling on the network width. We achieve the
desiderata via Polyak-Lojasiewicz condition, smoothness, and standard
assumptions on data, and use tools from random matrix theory.

    

### [[2111.01878] Discovering Supply Chain Links with Augmented Intelligence](http://arxiv.org/abs/2111.01878)


  One of the key components in analyzing the risk of a company is understanding
a company's supply chain. Supply chains are constantly disrupted, whether by
tariffs, pandemics, severe weather, etc. In this paper, we tackle the problem
of predicting previously unknown suppliers and customers of companies using
graph neural networks (GNNs) and show strong performance in finding previously
unknown connections by combining the predictions of our model and the domain
expertise of supply chain analysts.

    

### [[2111.01885] Conformal testing: binary case with Markov alternatives](http://arxiv.org/abs/2111.01885)


  We continue study of conformal testing in binary model situations. In this
note we consider Markov alternatives to the null hypothesis of exchangeability.
We propose two new classes of conformal test martingales; one class is
statistically efficient in our experiments, and the other class partially
sacrifices statistical efficiency to gain computational efficiency.

    

### [[2111.01892] Equivariant Deep Dynamical Model for Motion Prediction](http://arxiv.org/abs/2111.01892)


  Learning representations through deep generative modeling is a powerful
approach for dynamical modeling to discover the most simplified and compressed
underlying description of the data, to then use it for other tasks such as
prediction. Most learning tasks have intrinsic symmetries, i.e., the input
transformations leave the output unchanged, or the output undergoes a similar
transformation. The learning process is, however, usually uninformed of these
symmetries. Therefore, the learned representations for individually transformed
inputs may not be meaningfully related. In this paper, we propose an SO(3)
equivariant deep dynamical model (EqDDM) for motion prediction that learns a
structured representation of the input space in the sense that the embedding
varies with symmetry transformations. EqDDM is equipped with equivariant
networks to parameterize the state-space emission and transition models. We
demonstrate the superior predictive performance of the proposed model on
various motion data.

    

### [[2111.01905] Audacity of huge: overcoming challenges of data scarcity and data quality for machine learning in computational materials discovery](http://arxiv.org/abs/2111.01905)


  Machine learning (ML)-accelerated discovery requires large amounts of
high-fidelity data to reveal predictive structure-property relationships. For
many properties of interest in materials discovery, the challenging nature and
high cost of data generation has resulted in a data landscape that is both
scarcely populated and of dubious quality. Data-driven techniques starting to
overcome these limitations include the use of consensus across functionals in
density functional theory, the development of new functionals or accelerated
electronic structure theories, and the detection of where computationally
demanding methods are most necessary. When properties cannot be reliably
simulated, large experimental data sets can be used to train ML models. In the
absence of manual curation, increasingly sophisticated natural language
processing and automated image analysis are making it possible to learn
structure-property relationships from the literature. Models trained on these
data sets will improve as they incorporate community feedback.

    

### [[2111.01908] Classifying YouTube Comments Based on Sentiment and Type of Sentence](http://arxiv.org/abs/2111.01908)


  As a YouTube channel grows, each video can potentially collect enormous
amounts of comments that provide direct feedback from the viewers. These
comments are a major means of understanding viewer expectations and improving
channel engagement. However, the comments only represent a general collection
of user opinions about the channel and the content. Many comments are poorly
constructed, trivial, and have improper spellings and grammatical errors. As a
result, it is a tedious job to identify the comments that best interest the
content creators. In this paper, we extract and classify the raw comments into
different categories based on both sentiment and sentence types that will help
YouTubers find relevant comments for growing their viewership. Existing studies
have focused either on sentiment analysis (positive and negative) or
classification of sub-types within the same sentence types (e.g., types of
questions) on a text corpus. These have limited application on non-traditional
text corpus like YouTube comments. We address this challenge of text extraction
and classification from YouTube comments using well-known statistical measures
and machine learning models. We evaluate each combination of statistical
measure and the machine learning model using cross validation and $F_1$ scores.
The results show that our approach that incorporates conventional methods
performs well on the classification task, validating its potential in assisting
content creators increase viewer engagement on their channel.

    

### [[2111.01912] Predicting Cancer Using Supervised Machine Learning: Mesothelioma](http://arxiv.org/abs/2111.01912)


  Background: Pleural Mesothelioma (PM) is an unusual, belligerent tumor that
rapidly develops into cancer in the pleura of the lungs. Pleural Mesothelioma
is a common type of Mesothelioma that accounts for about 75% of all
Mesothelioma diagnosed yearly in the U.S. Diagnosis of Mesothelioma takes
several months and is expensive. Given the risk and constraints associated with
PM diagnosis, early identification of this ailment is essential for patient
health. Objective: In this study, we use artificial intelligence algorithms
recommending the best fit model for early diagnosis and prognosis of MPM.
Methods: We retrospectively retrieved patients clinical data collected by Dicle
University, Turkey, and applied multilayered perceptron (MLP), voted perceptron
(VP), Clojure classifier (CC), kernel logistic regression (KLR), stochastic
gradient decent SGD), adaptive boosting (AdaBoost), Hoeffding tree (VFDT), and
primal estimated sub-gradient solver for support vector machine (s-Pegasos). We
evaluated the models, compared and tested using paired T-test (corrected) at
0.05 significance based on their respective classification accuracy, f-measure,
precision, recall, root mean squared error, receivers characteristic curve
(ROC), and precision-recall curve (PRC). Results: In phase-1, SGD, AdaBoost.
M1, KLR, MLP, VFDT generate optimal results with the highest possible
performance measures. In phase 2, AdaBoost, with a classification accuracy of
71.29%, outperformed all other algorithms. C-reactive protein, platelet count,
duration of symptoms, gender, and pleural protein were found to be the most
relevant predictors that can prognosticate Mesothelioma. Conclusion: This study
confirms that data obtained from Biopsy and imagining tests are strong
predictors of Mesothelioma but are associated with a high cost; however, they
can identify Mesothelioma with optimal accuracy.

    

### [[2111.01915] Decision Support Models for Predicting and Explaining Airport Passenger Connectivity from Data](http://arxiv.org/abs/2111.01915)


  Predicting if passengers in a connecting flight will lose their connection is
paramount for airline profitability. We present novel machine learning-based
decision support models for the different stages of connection flight
management, namely for strategic, pre-tactical, tactical and post-operations.
We predict missed flight connections in an airline's hub airport using
historical data on flights and passengers, and analyse the factors that
contribute additively to the predicted outcome for each decision horizon. Our
data is high-dimensional, heterogeneous, imbalanced and noisy, and does not
inform about passenger arrival/departure transit time. We employ probabilistic
encoding of categorical classes, data balancing with Gaussian Mixture Models,
and boosting. For all planning horizons, our models attain an AUC of the ROC
higher than 0.93. SHAP value explanations of our models indicate that
scheduled/perceived connection times contribute the most to the prediction,
followed by passenger age and whether border controls are required.

    

### [[2111.01919] Discovering and Exploiting Sparse Rewards in a Learned Behavior Space](http://arxiv.org/abs/2111.01919)


  Learning optimal policies in sparse rewards settings is difficult as the
learning agent has little to no feedback on the quality of its actions. In
these situations, a good strategy is to focus on exploration, hopefully leading
to the discovery of a reward signal to improve on. A learning algorithm capable
of dealing with this kind of settings has to be able to (1) explore possible
agent behaviors and (2) exploit any possible discovered reward. Efficient
exploration algorithms have been proposed that require to define a behavior
space, that associates to an agent its resulting behavior in a space that is
known to be worth exploring. The need to define this space is a limitation of
these algorithms. In this work, we introduce STAX, an algorithm designed to
learn a behavior space on-the-fly and to explore it while efficiently
optimizing any reward discovered. It does so by separating the exploration and
learning of the behavior space from the exploitation of the reward through an
alternating two-steps process. In the first step, STAX builds a repertoire of
diverse policies while learning a low-dimensional representation of the
high-dimensional observations generated during the policies evaluation. In the
exploitation step, emitters are used to optimize the performance of the
discovered rewarding solutions. Experiments conducted on three different sparse
reward environments show that STAX performs comparably to existing baselines
while requiring much less prior information about the task as it autonomously
builds the behavior space.

    

### [[2111.01932] HASHTAG: Hash Signatures for Online Detection of Fault-Injection Attacks on Deep Neural Networks](http://arxiv.org/abs/2111.01932)


  We propose HASHTAG, the first framework that enables high-accuracy detection
of fault-injection attacks on Deep Neural Networks (DNNs) with provable bounds
on detection performance. Recent literature in fault-injection attacks shows
the severe DNN accuracy degradation caused by bit flips. In this scenario, the
attacker changes a few weight bits during DNN execution by tampering with the
program's DRAM memory. To detect runtime bit flips, HASHTAG extracts a unique
signature from the benign DNN prior to deployment. The signature is later used
to validate the integrity of the DNN and verify the inference output on the
fly. We propose a novel sensitivity analysis scheme that accurately identifies
the most vulnerable DNN layers to the fault-injection attack. The DNN signature
is then constructed by encoding the underlying weights in the vulnerable layers
using a low-collision hash function. When the DNN is deployed, new hashes are
extracted from the target layers during inference and compared against the
ground-truth signatures. HASHTAG incorporates a lightweight methodology that
ensures a low-overhead and real-time fault detection on embedded platforms.
Extensive evaluations with the state-of-the-art bit-flip attack on various DNNs
demonstrate the competitive advantage of HASHTAG in terms of both attack
detection and execution overhead.

    

### [[2111.01939] A MIMO Radar-Based Metric Learning Approach for Activity Recognition](http://arxiv.org/abs/2111.01939)


  Human activity recognition is seen of great importance in the medical and
surveillance fields. Radar has shown great feasibility for this field based on
the captured micro-Doppler ({\mu}-D) signatures. In this paper, a MIMO radar is
used to formulate a novel micro-motion spectrogram for the angular velocity
({\mu}-{\omega}) in non-tangential scenarios. Combining both the {\mu}-D and
the {\mu}-{\omega} signatures have shown better performance. Classification
accuracy of 88.9% was achieved based on a metric learning approach. The
experimental setup was designed to capture micro-motion signatures on different
aspect angles and line of sight (LOS). The utilized training dataset was of
smaller size compared to the state-of-the-art techniques, where eight
activities were captured. A few-shot learning approach is used to adapt the
pre-trained model for fall detection. The final model has shown a
classification accuracy of 86.42% for ten activities.

    

### [[2111.01940] Learning Multiresolution Matrix Factorization and its Wavelet Networks on Graphs](http://arxiv.org/abs/2111.01940)


  Multiresolution Matrix Factorization (MMF) is unusual amongst fast matrix
factorization algorithms in that it does not make a low rank assumption. This
makes MMF especially well suited to modeling certain types of graphs with
complex multiscale or hierarchical strucutre. While MMF promises to yields a
useful wavelet basis, finding the factorization itself is hard, and existing
greedy methods tend to be brittle. In this paper we propose a learnable version
of MMF that carfully optimizes the factorization with a combination of
reinforcement learning and Stiefel manifold optimization through
backpropagating errors. We show that the resulting wavelet basis far
outperforms prior MMF algorithms and provides the first version of this type of
factorization that can be robustly deployed on standard learning tasks.

    

### [[2111.01946] Robust Dynamic Bus Control: A Distributional Multi-agent Reinforcement Learning Approach](http://arxiv.org/abs/2111.01946)


  Bus system is a critical component of sustainable urban transportation.
However, the operation of a bus fleet is unstable in nature, and bus bunching
has become a common phenomenon that undermines the efficiency and reliability
of bus systems. Recently research has demonstrated the promising application of
multi-agent reinforcement learning (MARL) to achieve efficient vehicle holding
control to avoid bus bunching. However, existing studies essentially overlook
the robustness issue resulting from various events, perturbations and anomalies
in a transit system, which is of utmost importance when transferring the models
for real-world deployment/application. In this study, we integrate implicit
quantile network and meta-learning to develop a distributional MARL framework
-- IQNC-M -- to learn continuous control. The proposed IQNC-M framework
achieves efficient and reliable control decisions through better handling
various uncertainties/events in real-time transit operations. Specifically, we
introduce an interpretable meta-learning module to incorporate global
information into the distributional MARL framework, which is an effective
solution to circumvent the credit assignment issue in the transit system. In
addition, we design a specific learning procedure to train each agent within
the framework to pursue a robust control policy. We develop simulation
environments based on real-world bus services and passenger demand data and
evaluate the proposed framework against both traditional holding control models
and state-of-the-art MARL models. Our results show that the proposed IQNC-M
framework can effectively handle the various extreme events, such as traffic
state perturbations, service interruptions, and demand surges, thus improving
both efficiency and reliability of the system.

    

### [[2111.01950] Machine-Learning Identification of Hemodynamics in Coronary Arteries in the Presence of Stenosis](http://arxiv.org/abs/2111.01950)


  Prediction of the blood flow characteristics is of utmost importance for
understanding the behavior of the blood arterial network, especially in the
presence of vascular diseases such as stenosis. Computational fluid dynamics
(CFD) has provided a powerful and efficient tool to determine these
characteristics including the pressure and velocity fields within the network.
Despite numerous studies in the field, the extremely high computational cost of
CFD has led the researchers to develop new platforms including Machine Learning
approaches that instead provide faster analyses at a much lower cost. In this
study, we put forth a Deep Neural Network framework to predict flow behavior in
a coronary arterial network with different properties in the presence of any
abnormality like stenosis. To this end, an artificial neural network (ANN)
model is trained using synthetic data so that it can predict the pressure and
velocity within the arterial network. The data required to train the neural
network were obtained from the CFD analysis of several geometries of arteries
with specific features in ABAQUS software. Blood pressure drop caused by
stenosis, which is one of the most important factors in the diagnosis of heart
diseases, can be predicted using our proposed model knowing the geometrical and
flow boundary conditions of any section of the coronary arteries. The
efficiency of the model was verified using three real geometries of LAD's
vessels. The proposed approach precisely predicts the hemodynamic behavior of
the blood flow. The average accuracy of the pressure prediction was 98.7% and
the average velocity magnitude accuracy was 93.2%. According to the results of
testing the model on three patient-specific geometries, model can be considered
as an alternative to finite element methods as well as other hard-to-implement
and time-consuming numerical simulations.

    

### [[2111.01956] One Pass ImageNet](http://arxiv.org/abs/2111.01956)


  We present the One Pass ImageNet (OPIN) problem, which aims to study the
effectiveness of deep learning in a streaming setting. ImageNet is a widely
known benchmark dataset that has helped drive and evaluate recent advancements
in deep learning. Typically, deep learning methods are trained on static data
that the models have random access to, using multiple passes over the dataset
with a random shuffle at each epoch of training. Such data access assumption
does not hold in many real-world scenarios where massive data is collected from
a stream and storing and accessing all the data becomes impractical due to
storage costs and privacy concerns. For OPIN, we treat the ImageNet data as
arriving sequentially, and there is limited memory budget to store a small
subset of the data. We observe that training a deep network in a single pass
with the same training settings used for multi-epoch training results in a huge
drop in prediction accuracy. We show that the performance gap can be
significantly decreased by paying a small memory cost and utilizing techniques
developed for continual learning, despite the fact that OPIN differs from
typical continual problem settings. We propose using OPIN to study
resource-efficient deep learning.

    

### [[2111.01968] A Survey on Epistemic (Model) Uncertainty in Supervised Learning: Recent Advances and Applications](http://arxiv.org/abs/2111.01968)


  Quantifying the uncertainty of supervised learning models plays an important
role in making more reliable predictions. Epistemic uncertainty, which usually
is due to insufficient knowledge about the model, can be reduced by collecting
more data or refining the learning models. Over the last few years, scholars
have proposed many epistemic uncertainty handling techniques which can be
roughly grouped into two categories, i.e., Bayesian and ensemble. This paper
provides a comprehensive review of epistemic uncertainty learning techniques in
supervised learning over the last five years. As such, we, first, decompose the
epistemic uncertainty into bias and variance terms. Then, a hierarchical
categorization of epistemic uncertainty learning techniques along with their
representative models is introduced. In addition, several applications such as
computer vision (CV) and natural language processing (NLP) are presented,
followed by a discussion on research gaps and possible future research
directions.

    

### [[2111.01969] PhyloTransformer: A Discriminative Model for Mutation Prediction Based on a Multi-head Self-attention Mechanism](http://arxiv.org/abs/2111.01969)


  Severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2) has caused an
ongoing pandemic infecting 219 million people as of 10/19/21, with a 3.6%
mortality rate. Natural selection can generate favorable mutations with
improved fitness advantages; however, the identified coronaviruses may be the
tip of the iceberg, and potentially more fatal variants of concern (VOCs) may
emerge over time. Understanding the patterns of emerging VOCs and forecasting
mutations that may lead to gain of function or immune escape is urgently
required. Here we developed PhyloTransformer, a Transformer-based
discriminative model that engages a multi-head self-attention mechanism to
model genetic mutations that may lead to viral reproductive advantage. In order
to identify complex dependencies between the elements of each input sequence,
PhyloTransformer utilizes advanced modeling techniques, including a novel Fast
Attention Via positive Orthogonal Random features approach (FAVOR+) from
Performer, and the Masked Language Model (MLM) from Bidirectional Encoder
Representations from Transformers (BERT). PhyloTransformer was trained with
1,765,297 genetic sequences retrieved from the Global Initiative for Sharing
All Influenza Data (GISAID) database. Firstly, we compared the prediction
accuracy of novel mutations and novel combinations using extensive baseline
models; we found that PhyloTransformer outperformed every baseline method with
statistical significance. Secondly, we examined predictions of mutations in
each nucleotide of the receptor binding motif (RBM), and we found our
predictions were precise and accurate. Thirdly, we predicted modifications of
N-glycosylation sites to identify mutations associated with altered
glycosylation that may be favored during viral evolution. We anticipate that
PhyloTransformer may guide proactive vaccine design for effective targeting of
future SARS-CoV-2 variants.

    

### [[2111.01975] Binary classification of proteins by a Machine Learning approach](http://arxiv.org/abs/2111.01975)


  In this work we present a system based on a Deep Learning approach, by using
a Convolutional Neural Network, capable of classifying protein chains of amino
acids based on the protein description contained in the Protein Data Bank. Each
protein is fully described in its chemical-physical-geometric properties in a
file in XML format. The aim of the work is to design a prototypical Deep
Learning machinery for the collection and management of a huge amount of data
and to validate it through its application to the classification of a sequences
of amino acids. We envisage applying the described approach to more general
classification problems in biomolecules, related to structural properties and
similarities.

    

### [[2111.01976] A new method for binary classification of proteins with Machine Learning](http://arxiv.org/abs/2111.01976)


  In this work we set out to find a method to classify protein structures using
a Deep Learning methodology. Our Artificial Intelligence has been trained to
recognize complex biomolecule structures extrapolated from the Protein Data
Bank (PDB) database and reprocessed as images; for this purpose various tests
have been conducted with pre-trained Convolutional Neural Networks, such as
InceptionResNetV2 or InceptionV3, in order to extract significant features from
these images and correctly classify the molecule. A comparative analysis of the
performances of the various networks will therefore be produced.

    

### [[2111.01996] Pareto Adversarial Robustness: Balancing Spatial Robustness and Sensitivity-based Robustness](http://arxiv.org/abs/2111.01996)


  Adversarial robustness, which mainly contains sensitivity-based robustness
and spatial robustness, plays an integral part in the robust generalization. In
this paper, we endeavor to design strategies to achieve universal adversarial
robustness. To hit this target, we firstly investigate the less-studied spatial
robustness and then integrate existing spatial robustness methods by
incorporating both local and global spatial vulnerability into one spatial
attack and adversarial training. Based on this exploration, we further present
a comprehensive relationship between natural accuracy, sensitivity-based and
different spatial robustness, supported by the strong evidence from the
perspective of robust representation. More importantly, in order to balance
these mutual impacts of different robustness into one unified framework, we
incorporate \textit{Pareto criterion} into the adversarial robustness analysis,
yielding a novel strategy called \textit{Pareto Adversarial Training} towards
universal robustness. The resulting Pareto front, the set of optimal solutions,
provides the set of optimal balance among natural accuracy and different
adversarial robustness, shedding light on solutions towards universal
robustness in the future. To the best of our knowledge, we are the first to
consider the universal adversarial robustness via multi-objective optimization.

    

### [[2111.01998] OpenPrompt: An Open-source Framework for Prompt-learning](http://arxiv.org/abs/2111.01998)


  Prompt-learning has become a new paradigm in modern natural language
processing, which directly adapts pre-trained language models (PLMs) to
$cloze$-style prediction, autoregressive modeling, or sequence to sequence
generation, resulting in promising performances on various tasks. However, no
standard implementation framework of prompt-learning is proposed yet, and most
existing prompt-learning codebases, often unregulated, only provide limited
implementations for specific scenarios. Since there are many details such as
templating strategy, initializing strategy, and verbalizing strategy, etc. need
to be considered in prompt-learning, practitioners face impediments to quickly
adapting the desired prompt learning methods to their applications. In this
paper, we present {OpenPrompt}, a unified easy-to-use toolkit to conduct
prompt-learning over PLMs. OpenPrompt is a research-friendly framework that is
equipped with efficiency, modularity, and extendibility, and its combinability
allows the freedom to combine different PLMs, task formats, and prompting
modules in a unified paradigm. Users could expediently deploy prompt-learning
frameworks and evaluate the generalization of them on different NLP tasks
without constraints. OpenPrompt is publicly released at {\url{
this https URL}}.

    

### [[2111.01999] Automated, real-time hospital ICU emergency signaling: A field-level implementation](http://arxiv.org/abs/2111.01999)


  Contemporary patient surveillance systems have streamlined central
surveillance into the electronic health record interface. They are able to
process the sheer volume of patient data by adopting machine learning
approaches. However, these systems are not suitable for implementation in many
hospitals, mostly in developing countries, with limited human, financial, and
technological resources. Through conducting thorough research on intensive care
facilities, we designed a novel central patient monitoring system and in this
paper, we describe the working prototype of our system. The proposed prototype
comprises of inexpensive peripherals and simplistic user interface. Our central
patient monitoring system implements Kernel-based On-line Anomaly Detection
(KOAD) algorithm for emergency event signaling. By evaluating continuous
patient data, we show that the system is able to detect critical events in
real-time reliably and has low false alarm rate.

    

### [[2111.02010] Ensembles of Double Random Forest](http://arxiv.org/abs/2111.02010)


  An ensemble of decision trees is known as Random Forest. As suggested by
Breiman, the strength of unstable learners and the diversity among them are the
ensemble models' core strength. In this paper, we propose two approaches for
generating ensembles of double random forest. In the first approach, we propose
a rotation based ensemble of double random forest. In rotation based double
random forests, transformation or rotation of the feature space is generated at
each node. At each node different random feature subspace is chosen for
evaluation, hence the transformation at each node is different. Different
transformations result in better diversity among the base learners and hence,
better generalization performance. With the double random forest as base
learner, the data at each node is transformed via two different transformations
namely, principal component analysis and linear discriminant analysis. In the
second approach, we propose oblique ensembles of double random forest. Decision
trees in random forest and double random forest are univariate, and this
results in the generation of axis parallel split which fails to capture the
geometric structure of the data. Also, the standard random forest may not grow
sufficiently large decision trees resulting in suboptimal performance. To
capture the geometric properties and to grow the decision trees of sufficient
depth, we propose oblique ensembles of double random forest. The oblique
ensembles of double random forest models are multivariate decision trees. At
each non-leaf node, multisurface proximal support vector machine generates the
optimal plane for better generalization performance. Also, different
regularization techniques (Tikhonov regularisation and axis-parallel split
regularisation) are employed for tackling the small sample size problems in the
decision trees of oblique ensembles of double random forest.

    

### [[2111.02014] Neural network is heterogeneous: Phase matters more](http://arxiv.org/abs/2111.02014)


  We find a heterogeneity in both complex and real valued neural networks with
the insight from wave optics, claiming a much more important role of phase in
the weight matrix than its amplitude counterpart. In complex-valued neural
networks, we show that among different types of pruning, the weight matrix with
only phase information preserved achieves the best accuracy, which holds
robustly under various depths and widths. The conclusion can be generalized to
real-valued neural networks, where signs take the place of phases. These
inspiring findings enrich the techniques of network pruning and binary
computation.

    

### [[2111.02019] Scalable mixed-domain Gaussian processes](http://arxiv.org/abs/2111.02019)


  Gaussian process (GP) models that combine both categorical and continuous
input variables have found use e.g. in longitudinal data analysis and computer
experiments. However, standard inference for these models has the typical cubic
scaling, and common scalable approximation schemes for GPs cannot be applied
since the covariance function is non-continuous. In this work, we derive a
basis function approximation scheme for mixed-domain covariance functions,
which scales linearly with respect to the number of observations and total
number of basis functions. The proposed approach is naturally applicable to
Bayesian GP regression with arbitrary observation models. We demonstrate the
approach in a longitudinal data modelling context and show that it approximates
the exact GP model accurately, requiring only a fraction of the runtime
compared to fitting the corresponding exact model.

    

### [[2111.02024] Online Learning in Adversarial MDPs: Is the Communicating Case Harder than Ergodic?](http://arxiv.org/abs/2111.02024)


  We study online learning in adversarial communicating Markov Decision
Processes with full information. We give an algorithm that achieves a regret of
$O(\sqrt{T})$ with respect to the best fixed deterministic policy in hindsight
when the transitions are deterministic. We also prove a regret lower bound in
this setting which is tight up to polynomial factors in the MDP parameters. We
also give an inefficient algorithm that achieves $O(\sqrt{T})$ regret in
communicating MDPs (with an additional mild restriction on the transition
dynamics).

    

### [[2111.02034] Building Legal Datasets](http://arxiv.org/abs/2111.02034)


  Data-centric AI calls for better, not just bigger, datasets. As data
protection laws with extra-territorial reach proliferate worldwide, ensuring
datasets are legal is an increasingly crucial yet overlooked component of
``better''. To help dataset builders become more willing and able to navigate
this complex legal space, this paper reviews key legal obligations surrounding
ML datasets, examines the practical impact of data laws on ML pipelines, and
offers a framework for building legal datasets.

    

### [[2111.02038] Can We Achieve Fairness Using Semi-Supervised Learning?](http://arxiv.org/abs/2111.02038)


  Ethical bias in machine learning models has become a matter of concern in the
software engineering community. Most of the prior software engineering works
concentrated on finding ethical bias in models rather than fixing it. After
finding bias, the next step is mitigation. Prior researchers mainly tried to
use supervised approaches to achieve fairness. However, in the real world,
getting data with trustworthy ground truth is challenging and also ground truth
can contain human bias. Semi-supervised learning is a machine learning
technique where, incrementally, labeled data is used to generate pseudo-labels
for the rest of data (and then all that data is used for model training). In
this work, we apply four popular semi-supervised techniques as pseudo-labelers
to create fair classification models. Our framework, Fair-SSL, takes a very
small amount (10\%) of labeled data as input and generates pseudo-labels for
the unlabeled data. We then synthetically generate new data points to balance
the training data based on class and protected attribute as proposed by
Chakraborty et al. in FSE 2021. Finally, the classification model is trained on
the balanced pseudo-labeled data and validated on test data. After
experimenting on ten datasets and three learners, we find that Fair-SSL
achieves similar performance as three state-of-the-art bias mitigation
algorithms. That said, the clear advantage of Fair-SSL is that it requires only
10\% of the labeled training data. To the best of our knowledge, this is the
first SE work where semi-supervised techniques are used to fight against
ethical bias in SE ML models.

    

### [[2111.02042] Recent Advancements in Self-Supervised Paradigms for Visual Feature Representation](http://arxiv.org/abs/2111.02042)


  We witnessed a massive growth in the supervised learning paradigm in the past
decade. Supervised learning requires a large amount of labeled data to reach
state-of-the-art performance. However, labeling the samples requires a lot of
human annotation. To avoid the cost of labeling data, self-supervised methods
were proposed to make use of largely available unlabeled data. This study
conducts a comprehensive and insightful survey and analysis of recent
developments in the self-supervised paradigm for feature representation. In
this paper, we investigate the factors affecting the usefulness of
self-supervision under different settings. We present some of the key insights
concerning two different approaches in self-supervision, generative and
contrastive methods. We also investigate the limitations of supervised
adversarial training and how self-supervision can help overcome those
limitations. We then move on to discuss the limitations and challenges in
effectively using self-supervision for visual tasks. Finally, we highlight some
open problems and point out future research directions.

    

### [[2111.02056] Curriculum Offline Imitation Learning](http://arxiv.org/abs/2111.02056)


  Offline reinforcement learning (RL) tasks require the agent to learn from a
pre-collected dataset with no further interactions with the environment.
Despite the potential to surpass the behavioral policies, RL-based methods are
generally impractical due to the training instability and bootstrapping the
extrapolation errors, which always require careful hyperparameter tuning via
online evaluation. In contrast, offline imitation learning (IL) has no such
issues since it learns the policy directly without estimating the value
function by bootstrapping. However, IL is usually limited in the capability of
the behavioral policy and tends to learn a mediocre behavior from the dataset
collected by the mixture of policies. In this paper, we aim to take advantage
of IL but mitigate such a drawback. Observing that behavior cloning is able to
imitate neighboring policies with less data, we propose \textit{Curriculum
Offline Imitation Learning (COIL)}, which utilizes an experience picking
strategy for imitating from adaptive neighboring policies with a higher return,
and improves the current policy along curriculum stages. On continuous control
benchmarks, we compare COIL against both imitation-based and RL-based methods,
showing that it not only avoids just learning a mediocre behavior on mixed
datasets but is also even competitive with state-of-the-art offline RL methods.

    

### [[2111.02062] Linking Across Data Granularity: Fitting Multivariate Hawkes Processes to Partially Interval-Censored Data](http://arxiv.org/abs/2111.02062)


  This work introduces a novel multivariate temporal point process, the Partial
Mean Behavior Poisson (PMBP) process, which can be leveraged to fit the
multivariate Hawkes process to partially interval-censored data consisting of a
mix of event timestamps on a subset of dimensions and interval-censored event
counts on the complementary dimensions. First, we define the PMBP process via
its conditional intensity and derive the regularity conditions for
subcriticality. We show that both the Hawkes process and the MBP process
(Rizoiu et al. (2021)) are special cases of the PMBP process. Second, we
provide numerical schemes that enable calculating the conditional intensity and
sampling event histories of the PMBP process. Third, we demonstrate the
applicability of the PMBP process by empirical testing using synthetic and
real-world datasets: We test the capability of the PMBP process to recover
multivariate Hawkes parameters given sample event histories of the Hawkes
process. Next, we evaluate the PMBP process on the Youtube popularity
prediction task and show that it outperforms the current state-of-the-art
Hawkes Intensity process (Rizoiu et al. (2017b)). Lastly, on a curated dataset
of COVID19 daily case counts and COVID19-related news articles for a sample of
countries, we show that clustering on the PMBP-fitted parameters enables a
categorization of countries with respect to the country-level interaction of
cases and news reporting.

    

### [[2111.02064] Event and Activity Recognition in Video Surveillance for Cyber-Physical Systems](http://arxiv.org/abs/2111.02064)


  This chapter aims to aid the development of Cyber-Physical Systems (CPS) in
automated understanding of events and activities in various applications of
video-surveillance. These events are mostly captured by drones, CCTVs or novice
and unskilled individuals on low-end devices. Being unconstrained, these videos
are immensely challenging due to a number of quality factors. We present an
extensive account of the various approaches taken to solve the problem over the
years. This ranges from methods as early as Structure from Motion (SFM) based
approaches to recent solution frameworks involving deep neural networks. We
show that the long-term motion patterns alone play a pivotal role in the task
of recognizing an event. Consequently each video is significantly represented
by a fixed number of key-frames using a graph-based approach. Only the temporal
features are exploited using a hybrid Convolutional Neural Network (CNN) +
Recurrent Neural Network (RNN) architecture. The results we obtain are
encouraging as they outperform standard temporal CNNs and are at par with those
using spatial information along with motion cues. Further exploring multistream
models, we conceive a multi-tier fusion strategy for the spatial and temporal
wings of a network. A consolidated representation of the respective individual
prediction vectors on video and frame levels is obtained using a biased
conflation technique. The fusion strategy endows us with greater rise in
precision on each stage as compared to the state-of-the-art methods, and thus a
powerful consensus is achieved in classification. Results are recorded on four
benchmark datasets widely used in the domain of action recognition, namely CCV,
HMDB, UCF-101 and KCV. It is inferable that focusing on better classification
of the video sequences certainly leads to robust actuation of a system designed
for event surveillance and object cum activity tracking.

    

### [[2111.02071] The Impact of Batch Learning in Stochastic Bandits](http://arxiv.org/abs/2111.02071)


  We consider a special case of bandit problems, namely batched bandits.
Motivated by natural restrictions of recommender systems and e-commerce
platforms, we assume that a learning agent observes responses batched in groups
over a certain time period. Unlike previous work, we consider a more
practically relevant batch-centric scenario of batch learning. We provide a
policy-agnostic regret analysis and demonstrate upper and lower bounds for the
regret of a candidate policy. Our main theoretical results show that the impact
of batch learning can be measured in terms of online behavior. Finally, we
demonstrate the consistency of theoretical results by conducting empirical
experiments and reflect on the optimal batch size choice.

    

### [[2111.02078] FaceQvec: Vector Quality Assessment for Face Biometrics based on ISO Compliance](http://arxiv.org/abs/2111.02078)


  In this paper we develop FaceQvec, a software component for estimating the
conformity of facial images with each of the points contemplated in the ISO/IEC
19794-5, a quality standard that defines general quality guidelines for face
images that would make them acceptable or unacceptable for use in official
documents such as passports or ID cards. This type of tool for quality
assessment can help to improve the accuracy of face recognition, as well as to
identify which factors are affecting the quality of a given face image and to
take actions to eliminate or reduce those factors, e.g., with postprocessing
techniques or re-acquisition of the image. FaceQvec consists of the automation
of 25 individual tests related to different points contemplated in the
aforementioned standard, as well as other characteristics of the images that
have been considered to be related to facial quality. We first include the
results of the quality tests evaluated on a development dataset captured under
realistic conditions. We used those results to adjust the decision threshold of
each test. Then we checked again their accuracy on a evaluation database that
contains new face images not seen during development. The evaluation results
demonstrate the accuracy of the individual tests for checking compliance with
ISO/IEC 19794-5. FaceQvec is available online
(this https URL).

    

### [[2111.02080] An Explanation of In-context Learning as Implicit Bayesian Inference](http://arxiv.org/abs/2111.02080)


  Large pretrained language models such as GPT-3 have the surprising ability to
do in-context learning, where the model learns to do a downstream task simply
by conditioning on a prompt consisting of input-output examples. Without being
explicitly pretrained to do so, the language model learns from these examples
during its forward pass without parameter updates on "out-of-distribution"
prompts. Thus, it is unclear what mechanism enables in-context learning. In
this paper, we study the role of the pretraining distribution on the emergence
of in-context learning under a mathematical setting where the pretraining texts
have long-range coherence. Here, language model pretraining requires inferring
a latent document-level concept from the conditioning text to generate coherent
next tokens. At test time, this mechanism enables in-context learning by
inferring the shared latent concept between prompt examples and applying it to
make a prediction on the test example. Concretely, we prove that in-context
learning occurs implicitly via Bayesian inference of the latent concept when
the pretraining distribution is a mixture of HMMs. This can occur despite the
distribution mismatch between prompts and pretraining data. In contrast to
messy large-scale pretraining datasets for in-context learning in natural
language, we generate a family of small-scale synthetic datasets (GINC) where
Transformer and LSTM language models both exhibit in-context learning. Beyond
the theory which focuses on the effect of the pretraining distribution, we
empirically find that scaling model size improves in-context accuracy even when
the pretraining loss is the same.

    

### [[2111.02083] Federated Expectation Maximization with heterogeneity mitigation and variance reduction](http://arxiv.org/abs/2111.02083)


  The Expectation Maximization (EM) algorithm is the default algorithm for
inference in latent variable models. As in any other field of machine learning,
applications of latent variable models to very large datasets make the use of
advanced parallel and distributed architectures mandatory. This paper
introduces FedEM, which is the first extension of the EM algorithm to the
federated learning context. FedEM is a new communication efficient method,
which handles partial participation of local devices, and is robust to
heterogeneous distributions of the datasets. To alleviate the communication
bottleneck, FedEM compresses appropriately defined complete data sufficient
statistics. We also develop and analyze an extension of FedEM to further
incorporate a variance reduction scheme. In all cases, we derive finite-time
complexity bounds for smooth non-convex problems. Numerical results are
presented to support our theoretical findings, as well as an application to
federated missing values imputation for biodiversity monitoring.

    

### [[2111.02100] Conditional Attention Networks for Distilling Knowledge Graphs in Recommendation](http://arxiv.org/abs/2111.02100)


  Knowledge graph is generally incorporated into recommender systems to improve
overall performance. Due to the generalization and scale of the knowledge
graph, most knowledge relationships are not helpful for a target user-item
prediction. To exploit the knowledge graph to capture target-specific knowledge
relationships in recommender systems, we need to distill the knowledge graph to
reserve the useful information and refine the knowledge to capture the users'
preferences. To address the issues, we propose Knowledge-aware Conditional
Attention Networks (KCAN), which is an end-to-end model to incorporate
knowledge graph into a recommender system. Specifically, we use a
knowledge-aware attention propagation manner to obtain the node representation
first, which captures the global semantic similarity on the user-item network
and the knowledge graph. Then given a target, i.e., a user-item pair, we
automatically distill the knowledge graph into the target-specific subgraph
based on the knowledge-aware attention. Afterward, by applying a conditional
attention aggregation on the subgraph, we refine the knowledge graph to obtain
target-specific node representations. Therefore, we can gain both
representability and personalization to achieve overall performance.
Experimental results on real-world datasets demonstrate the effectiveness of
our framework over the state-of-the-art algorithms.

    

### [[2111.02104] Model-Based Episodic Memory Induces Dynamic Hybrid Controls](http://arxiv.org/abs/2111.02104)


  Episodic control enables sample efficiency in reinforcement learning by
recalling past experiences from an episodic memory. We propose a new
model-based episodic memory of trajectories addressing current limitations of
episodic control. Our memory estimates trajectory values, guiding the agent
towards good policies. Built upon the memory, we construct a complementary
learning model via a dynamic hybrid control unifying model-based, episodic and
habitual learning into a single architecture. Experiments demonstrate that our
model allows significantly faster and better learning than other strong
reinforcement learning agents across a variety of environments including
stochastic and non-Markovian settings.

    

### [[2111.02114] LAION-400M: Open Dataset of CLIP-Filtered 400 Million Image-Text Pairs](http://arxiv.org/abs/2111.02114)


  Multi-modal language-vision models trained on hundreds of millions of
image-text pairs (e.g. CLIP, DALL-E) gained a recent surge, showing remarkable
capability to perform zero- or few-shot learning and transfer even in absence
of per-sample labels on target image data. Despite this trend, to date there
has been no publicly available datasets of sufficient scale for training such
models from scratch. To address this issue, in a community effort we build and
release for public LAION-400M, a dataset with CLIP-filtered 400 million
image-text pairs, their CLIP embeddings and kNN indices that allow efficient
similarity search.

    

### [[2111.02115] Multistep traffic speed prediction: A deep learning based approach using latent space mapping considering spatio-temporal dependencies](http://arxiv.org/abs/2111.02115)


  Traffic management in a city has become a major problem due to the increasing
number of vehicles on roads. Intelligent Transportation System (ITS) can help
the city traffic managers to tackle the problem by providing accurate traffic
forecasts. For this, ITS requires a reliable traffic prediction algorithm that
can provide accurate traffic prediction at multiple time steps based on past
and current traffic data. In recent years, a number of different methods for
traffic prediction have been proposed which have proved their effectiveness in
terms of accuracy. However, most of these methods have either considered
spatial information or temporal information only and overlooked the effect of
other. In this paper, to address the above problem a deep learning based
approach has been developed using both the spatial and temporal dependencies.
To consider spatio-temporal dependencies, nearby road sensors at a particular
instant are selected based on the attributes like traffic similarity and
distance. Two pre-trained deep auto-encoders were cross-connected using the
concept of latent space mapping and the resultant model was trained using the
traffic data from the selected nearby sensors as input. The proposed deep
learning based approach was trained using the real-world traffic data collected
from loop detector sensors installed on different highways of Los Angeles and
Bay Area. The traffic data is freely available from the web portal of the
California Department of Transportation Performance Measurement System (PeMS).
The effectiveness of the proposed approach was verified by comparing it with a
number of machine/deep learning approaches. It has been found that the proposed
approach provides accurate traffic prediction results even for 60-min ahead
prediction with least error than other techniques.

    

### [[2111.02121] Spatiotemporal Weather Data Predictions with Shortcut Recurrent-Convolutional Networks: A Solution for the Weather4cast challenge](http://arxiv.org/abs/2111.02121)


  This paper presents the neural network model that was used by the author in
the Weather4cast 2021 Challenge Stage 1, where the objective was to predict the
time evolution of satellite-based weather data images. The network is based on
an encoder-forecaster architecture making use of gated recurrent units (GRU),
residual blocks and a contracting/expanding architecture with shortcuts similar
to U-Net. A GRU variant utilizing residual blocks in place of convolutions is
also introduced. Example predictions and evaluation metrics for the model are
presented. These demonstrate that the model can retain sharp features of the
input for the first predictions, while the later predictions become more
blurred to reflect the increasing uncertainty.

    

### [[2111.02133] Predictive Auto-scaling with OpenStack Monasca](http://arxiv.org/abs/2111.02133)


  Cloud auto-scaling mechanisms are typically based on reactive automation
rules that scale a cluster whenever some metric, e.g., the average CPU usage
among instances, exceeds a predefined threshold. Tuning these rules becomes
particularly cumbersome when scaling-up a cluster involves non-negligible times
to bootstrap new instances, as it happens frequently in production cloud
services.
To deal with this problem, we propose an architecture for auto-scaling cloud
services based on the status in which the system is expected to evolve in the
near future. Our approach leverages on time-series forecasting techniques, like
those based on machine learning and artificial neural networks, to predict the
future dynamics of key metrics, e.g., resource consumption metrics, and apply a
threshold-based scaling policy on them. The result is a predictive automation
policy that is able, for instance, to automatically anticipate peaks in the
load of a cloud application and trigger ahead of time appropriate scaling
actions to accommodate the expected increase in traffic.
We prototyped our approach as an open-source OpenStack component, which
relies on, and extends, the monitoring capabilities offered by Monasca,
resulting in the addition of predictive metrics that can be leveraged by
orchestration components like Heat or Senlin. We show experimental results
using a recurrent neural network and a multi-layer perceptron as predictor,
which are compared with a simple linear regression and a traditional
non-predictive auto-scaling policy. However, the proposed framework allows for
the easy customization of the prediction policy as needed.

    

### [[2111.02139] An Entropy-guided Reinforced Partial Convolutional Network for Zero-Shot Learning](http://arxiv.org/abs/2111.02139)


  Zero-Shot Learning (ZSL) aims to transfer learned knowledge from observed
classes to unseen classes via semantic correlations. A promising strategy is to
learn a global-local representation that incorporates global information with
extra localities (i.e., small parts/regions of inputs). However, existing
methods discover localities based on explicit features without digging into the
inherent properties and relationships among regions. In this work, we propose a
novel Entropy-guided Reinforced Partial Convolutional Network (ERPCNet), which
extracts and aggregates localities progressively based on semantic relevance
and visual correlations without human-annotated regions. ERPCNet uses
reinforced partial convolution and entropy guidance; it not only discovers
global-cooperative localities dynamically but also converges faster for policy
gradient optimization. We conduct extensive experiments to demonstrate
ERPCNet's performance through comparisons with state-of-the-art methods under
ZSL and Generalized Zero-Shot Learning (GZSL) settings on four benchmark
datasets. We also show ERPCNet is time efficient and explainable through
visualization analysis.

    

### [[2111.02149] Deployment Optimization for Shared e-Mobility Systems with Multi-agent Deep Neural Search](http://arxiv.org/abs/2111.02149)


  Shared e-mobility services have been widely tested and piloted in cities
across the globe, and already woven into the fabric of modern urban planning.
This paper studies a practical yet important problem in those systems: how to
deploy and manage their infrastructure across space and time, so that the
services are ubiquitous to the users while sustainable in profitability.
However, in real-world systems evaluating the performance of different
deployment strategies and then finding the optimal plan is prohibitively
expensive, as it is often infeasible to conduct many iterations of
trial-and-error. We tackle this by designing a high-fidelity simulation
environment, which abstracts the key operation details of the shared e-mobility
systems at fine-granularity, and is calibrated using data collected from the
real-world. This allows us to try out arbitrary deployment plans to learn the
optimal given specific context, before actually implementing any in the
real-world systems. In particular, we propose a novel multi-agent neural search
approach, in which we design a hierarchical controller to produce tentative
deployment plans. The generated deployment plans are then tested using a
multi-simulation paradigm, i.e., evaluated in parallel, where the results are
used to train the controller with deep reinforcement learning. With this closed
loop, the controller can be steered to have higher probability of generating
better deployment plans in future iterations. The proposed approach has been
evaluated extensively in our simulation environment, and experimental results
show that it outperforms baselines e.g., human knowledge, and state-of-the-art
heuristic-based optimization approaches in both service coverage and net
revenue.

    

### [[2111.02154] Regularization by Misclassification in ReLU Neural Networks](http://arxiv.org/abs/2111.02154)


  We study the implicit bias of ReLU neural networks trained by a variant of
SGD where at each step, the label is changed with probability $p$ to a random
label (label smoothing being a close variant of this procedure). Our
experiments demonstrate that label noise propels the network to a sparse
solution in the following sense: for a typical input, a small fraction of
neurons are active, and the firing pattern of the hidden layers is sparser. In
fact, for some instances, an appropriate amount of label noise does not only
sparsify the network but further reduces the test error. We then turn to the
theoretical analysis of such sparsification mechanisms, focusing on the
extremal case of $p=1$. We show that in this case, the network withers as
anticipated from experiments, but surprisingly, in different ways that depend
on the learning rate and the presence of bias, with either weights vanishing or
neurons ceasing to fire.

    

### [[2111.02155] A Johnson--Lindenstrauss Framework for Randomly Initialized CNNs](http://arxiv.org/abs/2111.02155)


  How does the geometric representation of a dataset change after the
application of each randomly initialized layer of a neural network? The
celebrated Johnson--Lindenstrauss lemma answers this question for linear
fully-connected neural networks (FNNs), stating that the geometry is
essentially preserved. For FNNs with the ReLU activation, the angle between two
inputs contracts according to a known mapping. The question for non-linear
convolutional neural networks (CNNs) becomes much more intricate. To answer
this question, we introduce a geometric framework. For linear CNNs, we show
that the Johnson--Lindenstrauss lemma continues to hold, namely, that the angle
between two inputs is preserved. For CNNs with ReLU activation, on the other
hand, the behavior is richer: The angle between the outputs contracts, where
the level of contraction depends on the nature of the inputs. In particular,
after one layer, the geometry of natural images is essentially preserved,
whereas for Gaussian correlated inputs, CNNs exhibit the same contracting
behavior as FNNs with ReLU activation.

    

### [[2111.02161] Data Synthesis for Testing Black-Box Machine Learning Models](http://arxiv.org/abs/2111.02161)


  The increasing usage of machine learning models raises the question of the
reliability of these models. The current practice of testing with limited data
is often insufficient. In this paper, we provide a framework for automated test
data synthesis to test black-box ML/DL models. We address an important
challenge of generating realistic user-controllable data with model agnostic
coverage criteria to test a varied set of properties, essentially to increase
trust in machine learning models. We experimentally demonstrate the
effectiveness of our technique.

    

### [[2111.02164] Heuristical choice of SVM parameters](http://arxiv.org/abs/2111.02164)


  Support Vector Machine (SVM) is one of the most popular classification
methods, and a de-facto reference for many Machine Learning approaches. Its
performance is determined by parameter selection, which is usually achieved by
a time-consuming grid search cross-validation procedure. There exist, however,
several unsupervised heuristics that take advantage of the characteristics of
the dataset for selecting parameters instead of using class label information.
Unsupervised heuristics, while an order of magnitude faster, are scarcely used
under the assumption that their results are significantly worse than those of
grid search. To challenge that assumption we have conducted a wide study of
various heuristics for SVM parameter selection on over thirty datasets, in both
supervised and semi-supervised scenarios. In most cases, the cross-validation
grid search did not achieve a significant advantage over the heuristics. In
particular, heuristical parameter selection may be preferable for high
dimensional and unbalanced datasets or when a small number of examples is
available. Our results also show that using a heuristic to determine the
starting point of further cross-validation does not yield significantly better
results than the default start.

    

### [[2111.02168] The Klarna Product Page Dataset: A RealisticBenchmark for Web Representation Learning](http://arxiv.org/abs/2111.02168)


  This paper tackles the under-explored problem of DOM tree element
representation learning. We advance the field of machine learning-based web
automation and hope to spur further research regarding this crucial area with
two contributions. First, we adapt several popular Graph-based Neural Network
models and apply them to embed elements in website DOM trees. Second, we
present a large-scale and realistic dataset of webpages. By providing this
open-access resource, we lower the entry barrier to this area of research. The
dataset contains $51,701$ manually labeled product pages from $8,175$ real
e-commerce websites. The pages can be rendered entirely in a web browser and
are suitable for computer vision applications. This makes it substantially
richer and more diverse than other datasets proposed for element representation
learning, classification and prediction on the web. Finally, using our proposed
dataset, we show that the embeddings produced by a Graph Convolutional Neural
Network outperform representations produced by other state-of-the-art methods
in a web element prediction task.

    

### [[2111.02169] Power Flow Balancing with Decentralized Graph Neural Networks](http://arxiv.org/abs/2111.02169)


  We propose an end-to-end framework based on a Graph Neural Network (GNN) to
balance the power flows in a generic grid. The optimization is framed as a
supervised vertex regression task, where the GNN is trained to predict the
current and power injections at each grid branch that yield a power flow
balance. By representing the power grid as a line graph with branches as
vertices, we can train a GNN that is more accurate and robust to changes in the
underlying topology. In addition, by using specialized GNN layers, we are able
to build a very deep architecture that accounts for large neighborhoods on the
graph, while implementing only localized operations. We perform three different
experiments to evaluate: i) the benefits of using localized rather than global
operations and the tendency to oversmooth when using deep GNN models; ii) the
resilience to perturbations in the graph topology; and iii) the capability to
train the model simultaneously on multiple grid topologies and the
consequential improvement in generalization to new, unseen grids. The proposed
framework is efficient and, compared to other solvers based on deep learning,
is robust to perturbations not only to the physical quantities on the grid
components, but also to the topology.

    

### [[2111.02175] Discriminator Synthesis: On reusing the other half of Generative Adversarial Networks](http://arxiv.org/abs/2111.02175)


  Generative Adversarial Networks have long since revolutionized the world of
computer vision and, tied to it, the world of art. Arduous efforts have gone
into fully utilizing and stabilizing training so that outputs of the Generator
network have the highest possible fidelity, but little has gone into using the
Discriminator after training is complete. In this work, we propose to use the
latter and show a way to use the features it has learned from the training
dataset to both alter an image and generate one from scratch. We name this
method Discriminator Dreaming, and the full code can be found at
this https URL.

    

### [[2111.02202] Proximal Policy Optimization with Continuous Bounded Action Space via the Beta Distribution](http://arxiv.org/abs/2111.02202)


  Reinforcement learning methods for continuous control tasks have evolved in
recent years generating a family of policy gradient methods that rely primarily
on a Gaussian distribution for modeling a stochastic policy. However, the
Gaussian distribution has an infinite support, whereas real world applications
usually have a bounded action space. This dissonance causes an estimation bias
that can be eliminated if the Beta distribution is used for the policy instead,
as it presents a finite support. In this work, we investigate how this Beta
policy performs when it is trained by the Proximal Policy Optimization (PPO)
algorithm on two continuous control tasks from OpenAI gym. For both tasks, the
Beta policy is superior to the Gaussian policy in terms of agent's final
expected reward, also showing more stability and faster convergence of the
training process. For the CarRacing environment with high-dimensional image
input, the agent's success rate was improved by 63% over the Gaussian policy.

    

### [[2111.02207] Deep Least Squares Alignment for Unsupervised Domain Adaptation](http://arxiv.org/abs/2111.02207)


  Unsupervised domain adaptation leverages rich information from a labeled
source domain to model an unlabeled target domain. Existing methods attempt to
align the cross-domain distributions. However, the statistical representations
of the alignment of the two domains are not well addressed. In this paper, we
propose deep least squares alignment (DLSA) to estimate the distribution of the
two domains in a latent space by parameterizing a linear model. We further
develop marginal and conditional adaptation loss to reduce the domain
discrepancy by minimizing the angle between fitting lines and intercept
differences and further learning domain invariant features. Extensive
experiments demonstrate that the proposed DLSA model is effective in aligning
domain distributions and outperforms state-of-the-art methods.

    

### [[2111.02216] Automatic Embedding of Stories Into Collections of Independent Media](http://arxiv.org/abs/2111.02216)


  We look at how machine learning techniques that derive properties of items in
a collection of independent media can be used to automatically embed stories
into such collections. To do so, we use models that extract the tempo of songs
to make a music playlist follow a narrative arc. Our work specifies an
open-source tool that uses pre-trained neural network models to extract the
global tempo of a set of raw audio files and applies these measures to create a
narrative-following playlist. This tool is available at
this https URL


### [[2111.02218] From global to local MDI variable importances for random forests and when they are Shapley values](http://arxiv.org/abs/2111.02218)


  Random forests have been widely used for their ability to provide so-called
importance measures, which give insight at a global (per dataset) level on the
relevance of input variables to predict a certain output. On the other hand,
methods based on Shapley values have been introduced to refine the analysis of
feature relevance in tree-based models to a local (per instance) level. In this
context, we first show that the global Mean Decrease of Impurity (MDI) variable
importance scores correspond to Shapley values under some conditions. Then, we
derive a local MDI importance measure of variable relevance, which has a very
natural connection with the global MDI measure and can be related to a new
notion of local feature relevance. We further link local MDI importances with
Shapley values and discuss them in the light of related measures from the
literature. The measures are illustrated through experiments on several
classification and regression problems.

    

### [[2111.02246] Brain-inspired Cognition in Next Generation Racetrack Memories](http://arxiv.org/abs/2111.02246)


  Hyperdimensional computing (HDC) is an emerging computational framework
inspired by the brain that operates on vectors with thousands of dimensions to
emulate cognition. Unlike conventional computational frameworks that operate on
numbers, HDC, like the brain, uses high dimensional random vectors and is
capable of one-shot learning. HDC is based on a well-defined set of arithmetic
operations and is highly error-resilient. The core operations of HDC manipulate
HD vectors in bulk bit-wise fashion, offering many opportunities to leverage
parallelism. Unfortunately, on conventional Von-Neuman architectures, the
continuous movement of HD vectors among the processor and the memory can make
the cognition task prohibitively slow and energy-intensive. Hardware
accelerators only marginally improve related metrics. On the contrary, only
partial implementation of an HDC framework inside memory, using emerging
memristive devices, has reported considerable performance/energy gains. This
paper presents an architecture based on racetrack memory (RTM) to conduct and
accelerate the entire HDC framework within the memory. The proposed solution
requires minimal additional CMOS circuitry and uses a read operation across
multiple domains in RTMs called transverse read (TR) to realize exclusive-or
(XOR) and addition operations. To minimize the overhead the CMOS circuitry, we
propose an RTM nanowires-based counting mechanism that leverages the TR
operation and the standard RTM operations. Using language recognition as the
use case demonstrates 7.8x and 5.3x reduction in the overall runtime and energy
consumption compared to the FPGA design, respectively. Compared to the
state-of-the-art in-memory implementation, the proposed HDC system reduces the
energy consumption by 8.6x.

    

### [[2111.02258] Multi-Agent Deep Reinforcement Learning For Optimising Energy Efficiency of Fixed-Wing UAV Cellular Access Points](http://arxiv.org/abs/2111.02258)


  Unmanned Aerial Vehicles (UAVs) promise to become an intrinsic part of next
generation communications, as they can be deployed to provide wireless
connectivity to ground users to supplement existing terrestrial networks. The
majority of the existing research into the use of UAV access points for
cellular coverage considers rotary-wing UAV designs (i.e. quadcopters).
However, we expect fixed-wing UAVs to be more appropriate for connectivity
purposes in scenarios where long flight times are necessary (such as for rural
coverage), as fixed-wing UAVs rely on a more energy-efficient form of flight
when compared to the rotary-wing design. As fixed-wing UAVs are typically
incapable of hovering in place, their deployment optimisation involves
optimising their individual flight trajectories in a way that allows them to
deliver high quality service to the ground users in an energy-efficient manner.
In this paper, we propose a multi-agent deep reinforcement learning approach to
optimise the energy efficiency of fixed-wing UAV cellular access points while
still allowing them to deliver high-quality service to users on the ground. In
our decentralized approach, each UAV is equipped with a Dueling Deep Q-Network
(DDQN) agent which can adjust the 3D trajectory of the UAV over a series of
timesteps. By coordinating with their neighbours, the UAVs adjust their
individual flight trajectories in a manner that optimises the total system
energy efficiency. We benchmark the performance of our approach against a
series of heuristic trajectory planning strategies, and demonstrate that our
method can improve the system energy efficiency by as much as 70%.

    

### [[2111.02272] Convolutional Motif Kernel Networks](http://arxiv.org/abs/2111.02272)


  Artificial neural networks are exceptionally good in learning to detect
correlations within data that are associated with specified outcomes. However
to deepen knowledge and support further research, researchers have to be able
to explain predicted outcomes within the data's domain. Furthermore, domain
experts like Healthcare Providers need these explanations to assess whether a
predicted outcome can be trusted in high stakes scenarios and to help them
incorporating a model into their own routine. In this paper we introduce
Convolutional Motif Kernel Networks, a neural network architecture that
incorporates learning a feature representation within a subspace of the
reproducing kernel Hilbert space of the motif kernel function. The resulting
model has state-of-the-art performance and enables researchers and domain
experts to directly interpret and verify prediction outcomes without the need
for a post hoc explainability method.

    

### [[2111.02274] Manipulation of granular materials by learning particle interactions](http://arxiv.org/abs/2111.02274)


  Manipulation of granular materials such as sand or rice remains an unsolved
challenge due to the difficulty of modeling material particles interacting with
each other. Current approaches tend to simplify the material dynamics and omit
the interactions between the particles. In this paper, we propose to use a
graph-based representation to model the interaction dynamics of the material
and rigid bodies manipulating it. This allows the planning of manipulation
trajectories to reach a desired configuration of the material. We use a graph
neural network (GNN) to model the particle interactions via message-passing. To
plan manipulation trajectories, we propose to minimise the Wasserstein distance
between the distribution of granular particles and the desired configuration.
We demonstrate that the proposed method is able to pour granular materials into
the desired configuration both in simulated and real scenarios.

    

### [[2111.02275] Causal-BALD: Deep Bayesian Active Learning of Outcomes to Infer Treatment-Effects from Observational Data](http://arxiv.org/abs/2111.02275)


  Estimating personalized treatment effects from high-dimensional observational
data is essential in situations where experimental designs are infeasible,
unethical, or expensive. Existing approaches rely on fitting deep models on
outcomes observed for treated and control populations. However, when measuring
individual outcomes is costly, as is the case of a tumor biopsy, a
sample-efficient strategy for acquiring each result is required. Deep Bayesian
active learning provides a framework for efficient data acquisition by
selecting points with high uncertainty. However, existing methods bias training
data acquisition towards regions of non-overlapping support between the treated
and control populations. These are not sample-efficient because the treatment
effect is not identifiable in such regions. We introduce causal, Bayesian
acquisition functions grounded in information theory that bias data acquisition
towards regions with overlapping support to maximize sample efficiency for
learning personalized treatment effects. We demonstrate the performance of the
proposed acquisition strategies on synthetic and semi-synthetic datasets IHDP
and CMNIST and their extensions, which aim to simulate common dataset biases
and pathologies.

    

### [[2111.02278] Mean-field Analysis of Piecewise Linear Solutions for Wide ReLU Networks](http://arxiv.org/abs/2111.02278)


  Understanding the properties of neural networks trained via stochastic
gradient descent (SGD) is at the heart of the theory of deep learning. In this
work, we take a mean-field view, and consider a two-layer ReLU network trained
via SGD for a univariate regularized regression problem. Our main result is
that SGD is biased towards a simple solution: at convergence, the ReLU network
implements a piecewise linear map of the inputs, and the number of "knot"
points - i.e., points where the tangent of the ReLU network estimator changes -
between two consecutive training inputs is at most three. In particular, as the
number of neurons of the network grows, the SGD dynamics is captured by the
solution of a gradient flow and, at convergence, the distribution of the
weights approaches the unique minimizer of a related free energy, which has a
Gibbs form. Our key technical contribution consists in the analysis of the
estimator resulting from this minimizer: we show that its second derivative
vanishes everywhere, except at some specific locations which represent the
"knot" points. We also provide empirical evidence that knots at locations
distinct from the data points might occur, as predicted by our theory.

    

### [[2111.02281] Privately Publishable Per-instance Privacy](http://arxiv.org/abs/2111.02281)


  We consider how to privately share the personalized privacy losses incurred
by objective perturbation, using per-instance differential privacy (pDP).
Standard differential privacy (DP) gives us a worst-case bound that might be
orders of magnitude larger than the privacy loss to a particular individual
relative to a fixed dataset. The pDP framework provides a more fine-grained
analysis of the privacy guarantee to a target individual, but the per-instance
privacy loss itself might be a function of sensitive data. In this paper, we
analyze the per-instance privacy loss of releasing a private empirical risk
minimizer learned via objective perturbation, and propose a group of methods to
privately and accurately publish the pDP losses at little to no additional
privacy cost.

    

### [[2111.02293] Photometric Search for Exomoons by using Convolutional Neural Networks](http://arxiv.org/abs/2111.02293)


  Until now, there is no confirmed moon beyond our solar system (exomoon).
Exomoons offer us new possibly habitable places which might also be outside the
classical habitable zone. But until now, the search for exomoons needs much
computational power because classical statistical methods are employed. It is
shown that exomoon signatures can be found by using deep learning and
Convolutional Neural Networks (CNNs), respectively, trained with synthetic
light curves combined with real light curves with no transits. It is found that
CNNs trained by combined synthetic and observed light curves may be used to
find moons bigger or equal to roughly 2-3 earth radii in the Kepler data set or
comparable data sets. Using neural networks in future missions like Planetary
Transits and Oscillation of stars (PLATO) might enable the detection of
exomoons.

    

### [[2111.02298] STC speaker recognition systems for the NIST SRE 2021](http://arxiv.org/abs/2111.02298)


  This paper presents a description of STC Ltd. systems submitted to the NIST
2021 Speaker Recognition Evaluation for both fixed and open training
conditions. These systems consists of a number of diverse subsystems based on
using deep neural networks as feature extractors. During the NIST 2021 SRE
challenge we focused on the training of the state-of-the-art deep speaker
embeddings extractors like ResNets and ECAPA networks by using additive angular
margin based loss functions. Additionally, inspired by the recent success of
the wav2vec 2.0 features in automatic speech recognition we explored the
effectiveness of this approach for the speaker verification filed. According to
our observation the fine-tuning of the pretrained large wav2vec 2.0 model
provides our best performing systems for open track condition. Our experiments
with wav2vec 2.0 based extractors for the fixed condition showed that
unsupervised autoregressive pretraining with Contrastive Predictive Coding loss
opens the door to training powerful transformer-based extractors from raw
speech signals. For video modality we developed our best solution with
RetinaFace face detector and deep ResNet face embeddings extractor trained on
large face image datasets. The final results for primary systems were obtained
by different configurations of subsystems fusion on the score level followed by
score calibration.

    

### [[2111.02302] Selecting the number of clusters, clustering models, and algorithms. A unifying approach based on the quadratic discriminant score](http://arxiv.org/abs/2111.02302)


  Cluster analysis requires many decisions: the clustering method and the
implied reference model, the number of clusters and, often, several
hyper-parameters and algorithms' tunings. In practice, one produces several
partitions, and a final one is chosen based on validation or selection
criteria. There exist an abundance of validation methods that, implicitly or
explicitly, assume a certain clustering notion. Moreover, they are often
restricted to operate on partitions obtained from a specific method. In this
paper, we focus on groups that can be well separated by quadratic or linear
boundaries. The reference cluster concept is defined through the quadratic
discriminant score function and parameters describing clusters' size, center
and scatter. We develop two cluster-quality criteria called quadratic scores.
We show that these criteria are consistent with groups generated from a general
class of elliptically-symmetric distributions. The quest for this type of
groups is common in applications. The connection with likelihood theory for
mixture models and model-based clustering is investigated. Based on bootstrap
resampling of the quadratic scores, we propose a selection rule that allows
choosing among many clustering solutions. The proposed method has the
distinctive advantage that it can compare partitions that cannot be compared
with other state-of-the-art methods. Extensive numerical experiments and the
analysis of real data show that, even if some competing methods turn out to be
superior in some setups, the proposed methodology achieves a better overall
performance.

    

### [[2111.02303] On the Effectiveness of Interpretable Feedforward Neural Network](http://arxiv.org/abs/2111.02303)


  Deep learning models have achieved state-of-the-art performance in many
classification tasks. However, most of them cannot provide an interpretation
for their classification results. Machine learning models that are
interpretable are usually linear or piecewise linear and yield inferior
performance. Non-linear models achieve much better classification performance,
but it is hard to interpret their classification results. This may have been
changed by an interpretable feedforward neural network (IFFNN) proposed that
achieves both high classification performance and interpretability for malware
detection. If the IFFNN can perform well in a more flexible and general form
for other classification tasks while providing meaningful interpretations, it
may be of great interest to the applied machine learning community. In this
paper, we propose a way to generalize the interpretable feedforward neural
network to multi-class classification scenarios and any type of feedforward
neural networks, and evaluate its classification performance and
interpretability on intrinsic interpretable datasets. We conclude by finding
that the generalized IFFNNs achieve comparable classification performance to
their normal feedforward neural network counterparts and provide meaningful
interpretations. Thus, this kind of neural network architecture has great
practical use.

    

### [[2111.02306] A Causality-based Graphical Test to obtain an Optimal Blocking Set for Randomized Experiments](http://arxiv.org/abs/2111.02306)


  Randomized experiments are often performed to study the causal effects of
interest. Blocking is a technique to precisely estimate the causal effects when
the experimental material is not homogeneous. We formalize the problem of
obtaining a statistically optimal set of covariates to be used to create blocks
while performing a randomized experiment. We provide a graphical test to obtain
such a set for a general semi-Markovian causal model. We also propose and
provide ideas towards solving a more general problem of obtaining an optimal
blocking set that considers both the statistical and economic costs of
blocking.

    

### [[2111.02314] Online Learning of Energy Consumption for Navigation of Electric Vehicles](http://arxiv.org/abs/2111.02314)


  Energy-efficient navigation constitutes an important challenge in electric
vehicles, due to their limited battery capacity. We employ a Bayesian approach
to model the energy consumption at road segments for efficient navigation. In
order to learn the model parameters, we develop an online learning framework
and investigate several exploration strategies such as Thompson Sampling and
Upper Confidence Bound. We then extend our online learning framework to
multi-agent setting, where multiple vehicles adaptively navigate and learn the
parameters of the energy model. We analyze Thompson Sampling and establish
rigorous regret bounds on its performance in the single-agent and multi-agent
settings, through an analysis of the algorithm under batched feedback. Finally,
we demonstrate the performance of our methods via experiments on several
real-world city road networks.

    

### [[2111.02316] Improving Model Compatibility of Generative Adversarial Networks by Boundary Calibration](http://arxiv.org/abs/2111.02316)


  Generative Adversarial Networks (GANs) is a powerful family of models that
learn an underlying distribution to generate synthetic data. Many existing
studies of GANs focus on improving the realness of the generated image data for
visual applications, and few of them concern about improving the quality of the
generated data for training other classifiers -- a task known as the model
compatibility problem. As a consequence, existing GANs often prefer generating
`easier' synthetic data that are far from the boundaries of the classifiers,
and refrain from generating near-boundary data, which are known to play an
important roles in training the classifiers. To improve GAN in terms of model
compatibility, we propose Boundary-Calibration GANs (BCGANs), which leverage
the boundary information from a set of pre-trained classifiers using the
original data. In particular, we introduce an auxiliary Boundary-Calibration
loss (BC-loss) into the generator of GAN to match the statistics between the
posterior distributions of original data and generated data with respect to the
boundaries of the pre-trained classifiers. The BC-loss is provably unbiased and
can be easily coupled with different GAN variants to improve their model
compatibility. Experimental results demonstrate that BCGANs not only generate
realistic images like original GANs but also achieves superior model
compatibility than the original GANs.

    

### [[2111.02326] End-to-End Annotator Bias Approximation on Crowdsourced Single-Label Sentiment Analysis](http://arxiv.org/abs/2111.02326)


  Sentiment analysis is often a crowdsourcing task prone to subjective labels
given by many annotators. It is not yet fully understood how the annotation
bias of each annotator can be modeled correctly with state-of-the-art methods.
However, resolving annotator bias precisely and reliably is the key to
understand annotators' labeling behavior and to successfully resolve
corresponding individual misconceptions and wrongdoings regarding the
annotation task. Our contribution is an explanation and improvement for precise
neural end-to-end bias modeling and ground truth estimation, which reduces an
undesired mismatch in that regard of the existing state-of-the-art.
Classification experiments show that it has potential to improve accuracy in
cases where each sample is annotated only by one single annotator. We provide
the whole source code publicly and release an own domain-specific sentiment
dataset containing 10,000 sentences discussing organic food products. These are
crawled from social media and are singly labeled by 10 non-expert annotators.

    

### [[2111.02329] Implicit Deep Adaptive Design: Policy-Based Experimental Design without Likelihoods](http://arxiv.org/abs/2111.02329)


  We introduce implicit Deep Adaptive Design (iDAD), a new method for
performing adaptive experiments in real-time with implicit models. iDAD
amortizes the cost of Bayesian optimal experimental design (BOED) by learning a
design policy network upfront, which can then be deployed quickly at the time
of the experiment. The iDAD network can be trained on any model which simulates
differentiable samples, unlike previous design policy work that requires a
closed form likelihood and conditionally independent experiments. At
deployment, iDAD allows design decisions to be made in milliseconds, in
contrast to traditional BOED approaches that require heavy computation during
the experiment itself. We illustrate the applicability of iDAD on a number of
experiments, and show that it provides a fast and effective mechanism for
performing adaptive design with implicit models.

    

### [[2111.02331] LTD: Low Temperature Distillation for Robust Adversarial Training](http://arxiv.org/abs/2111.02331)


  Adversarial training has been widely used to enhance the robustness of the
neural network models against adversarial attacks. However, there still a
notable gap between the nature accuracy and the robust accuracy. We found one
of the reasons is the commonly used labels, one-hot vectors, hinder the
learning process for image recognition. In this paper, we proposed a method,
called Low Temperature Distillation (LTD), which is based on the knowledge
distillation framework to generate the desired soft labels. Unlike the previous
work, LTD uses relatively low temperature in the teacher model, and employs
different, but fixed, temperatures for the teacher model and the student model.
Moreover, we have investigated the methods to synergize the use of nature data
and adversarial ones in LTD. Experimental results show that without extra
unlabeled data, the proposed method combined with the previous work can achieve
57.72\% and 30.36\% robust accuracy on CIFAR-10 and CIFAR-100 dataset
respectively, which is about 1.21\% improvement of the state-of-the-art methods
in average.

    

### [[2111.02338] Drop, Swap, and Generate: A Self-Supervised Approach for Generating Neural Activity](http://arxiv.org/abs/2111.02338)


  Meaningful and simplified representations of neural activity can yield
insights into how and what information is being processed within a neural
circuit. However, without labels, finding representations that reveal the link
between the brain and behavior can be challenging. Here, we introduce a novel
unsupervised approach for learning disentangled representations of neural
activity called Swap-VAE. Our approach combines a generative modeling framework
with an instance-specific alignment loss that tries to maximize the
representational similarity between transformed views of the input (brain
state). These transformed (or augmented) views are created by dropping out
neurons and jittering samples in time, which intuitively should lead the
network to a representation that maintains both temporal consistency and
invariance to the specific neurons used to represent the neural state. Through
evaluations on both synthetic data and neural recordings from hundreds of
neurons in different primate brains, we show that it is possible to build
representations that disentangle neural datasets along relevant latent
dimensions linked to behavior.

    

### [[2111.02351] Weight, Block or Unit? Exploring Sparsity Tradeoffs for Speech Enhancement on Tiny Neural Accelerators](http://arxiv.org/abs/2111.02351)


  We explore network sparsification strategies with the aim of compressing
neural speech enhancement (SE) down to an optimal configuration for a new
generation of low power microcontroller based neural accelerators (microNPU's).
We examine three unique sparsity structures: weight pruning, block pruning and
unit pruning; and discuss their benefits and drawbacks when applied to SE. We
focus on the interplay between computational throughput, memory footprint and
model quality. Our method supports all three structures above and jointly
learns integer quantized weights along with sparsity. Additionally, we
demonstrate offline magnitude based pruning of integer quantized models as a
performance baseline. Although efficient speech enhancement is an active area
of research, our work is the first to apply block pruning to SE and the first
to address SE model compression in the context of microNPU's. Using weight
pruning, we show that we are able to compress an already compact model's memory
footprint by a factor of 42x from 3.7MB to 87kB while only losing 0.1 dB SDR in
performance. We also show a computational speedup of 6.7x with a corresponding
SDR drop of only 0.59 dB SDR using block pruning.

    

### [[2111.02354] Smooth Imitation Learning via Smooth Costs and Smooth Policies](http://arxiv.org/abs/2111.02354)


  Imitation learning (IL) is a popular approach in the continuous control
setting as among other reasons it circumvents the problems of reward
mis-specification and exploration in reinforcement learning (RL). In IL from
demonstrations, an important challenge is to obtain agent policies that are
smooth with respect to the inputs. Learning through imitation a policy that is
smooth as a function of a large state-action ($s$-$a$) space (typical of high
dimensional continuous control environments) can be challenging. We take a
first step towards tackling this issue by using smoothness inducing
regularizers on \textit{both} the policy and the cost models of adversarial
imitation learning. Our regularizers work by ensuring that the cost function
changes in a controlled manner as a function of $s$-$a$ space; and the agent
policy is well behaved with respect to the state space. We call our new smooth
IL algorithm \textit{Smooth Policy and Cost Imitation Learning} (SPaCIL,
pronounced 'Special'). We introduce a novel metric to quantify the smoothness
of the learned policies. We demonstrate SPaCIL's superior performance on
continuous control tasks from MuJoCo. The algorithm not just outperforms the
state-of-the-art IL algorithm on our proposed smoothness metric, but, enjoys
added benefits of faster learning and substantially higher average return.

    

### [[2111.02355] Why Stable Learning Works? A Theory of Covariate Shift Generalization](http://arxiv.org/abs/2111.02355)


  Covariate shift generalization, a typical case in out-of-distribution (OOD)
generalization, requires a good performance on the unknown testing
distribution, which varies from the accessible training distribution in the
form of covariate shift. Recently, stable learning algorithms have shown
empirical effectiveness to deal with covariate shift generalization on several
learning models involving regression algorithms and deep neural networks.
However, the theoretical explanations for such effectiveness are still missing.
In this paper, we take a step further towards the theoretical analysis of
stable learning algorithms by explaining them as feature selection processes.
We first specify a set of variables, named minimal stable variable set, that is
minimal and optimal to deal with covariate shift generalization for common loss
functions, including the mean squared loss and binary cross entropy loss. Then
we prove that under ideal conditions, stable learning algorithms could identify
the variables in this set. Further analysis on asymptotic properties and error
propagation are also provided. These theories shed light on why stable learning
works for covariate shift generalization.

    

### [[2111.02356] Towards Sparse Federated Analytics: Location Heatmaps under Distributed Differential Privacy with Secure Aggregation](http://arxiv.org/abs/2111.02356)


  We design a scalable algorithm to privately generate location heatmaps over
decentralized data from millions of user devices. It aims to ensure
differential privacy before data becomes visible to a service provider while
maintaining high data accuracy and minimizing resource consumption on users'
devices. To achieve this, we revisit the distributed differential privacy
concept based on recent results in the secure multiparty computation field and
design a scalable and adaptive distributed differential privacy approach for
location analytics. Evaluation on public location datasets shows that this
approach successfully generates metropolitan-scale heatmaps from millions of
user samples with a worst-case client communication overhead that is
significantly smaller than existing state-of-the-art private protocols of
similar accuracy.

    

### [[2111.02357] Multivariate feature ranking of gene expression data](http://arxiv.org/abs/2111.02357)


  Gene expression datasets are usually of high dimensionality and therefore
require efficient and effective methods for identifying the relative importance
of their attributes. Due to the huge size of the search space of the possible
solutions, the attribute subset evaluation feature selection methods tend to be
not applicable, so in these scenarios feature ranking methods are used. Most of
the feature ranking methods described in the literature are univariate methods,
so they do not detect interactions between factors. In this paper we propose
two new multivariate feature ranking methods based on pairwise correlation and
pairwise consistency, which we have applied in three gene expression
classification problems. We statistically prove that the proposed methods
outperform the state of the art feature ranking methods Clustering Variation,
Chi Squared, Correlation, Information Gain, ReliefF and Significance, as well
as feature selection methods of attribute subset evaluation based on
correlation and consistency with multi-objective evolutionary search strategy.

    

### [[2111.02358] VLMo: Unified Vision-Language Pre-Training with Mixture-of-Modality-Experts](http://arxiv.org/abs/2111.02358)


  We present a unified Vision-Language pretrained Model (VLMo) that jointly
learns a dual encoder and a fusion encoder with a modular Transformer network.
Specifically, we introduce Mixture-of-Modality-Experts (MoME) Transformer,
where each block contains a pool of modality-specific experts and a shared
self-attention layer. Because of the modeling flexibility of MoME, pretrained
VLMo can be fine-tuned as a fusion encoder for vision-language classification
tasks, or used as a dual encoder for efficient image-text retrieval. Moreover,
we propose a stagewise pre-training strategy, which effectively leverages
large-scale image-only and text-only data besides image-text pairs.
Experimental results show that VLMo achieves state-of-the-art results on
various vision-language tasks, including VQA and NLVR2. The code and pretrained
models are available at this https URL.

    

### [[2111.02359] SVD-Embedded Deep Autoencoder for MIMO Communications](http://arxiv.org/abs/2111.02359)


  Using a deep autoencoder (DAE) for end-to-end communication in multiple-input
multiple-output (MIMO) systems is a novel concept with significant potential.
DAE-aided MIMO has been shown to outperform singular-value decomposition
(SVD)-based precoded MIMO in terms of bit error rate (BER). This paper proposes
embedding left- and right-singular vectors of the channel matrix into DAE
encoder and decoder to further improve the performance of MIMO spatial
multiplexing. SVD-embedded DAE largely outperforms theoretic linear precoding
in terms of BER. This is remarkable since it demonstrates that the proposed
DAEs have significant potential to exceed the limits of current system design
by treating the communication system as a single, end-to-end optimization
block. Based on the simulation results, at SNR=10dB, the proposed SVD-embedded
design can achieve BER nearly $10^{-5}$ and reduce the BER at least 10 times
compared with existing DAE without SVD, and up to 18 times improvement compared
with theoretical linear precoding. We attribute this to the fact that the
proposed DAE can match the input and output as an adaptive modulation structure
with finite alphabet input. We also observe that adding residual connections to
the DAE further improves the performance.

    

### [[2111.02363] Deep Learning-based Non-Intrusive Multi-Objective Speech Assessment Model with Cross-Domain Features](http://arxiv.org/abs/2111.02363)


  In this study, we propose a cross-domain multi-objective speech assessment
model, i.e., the MOSA-Net, which can estimate multiple speech assessment
metrics simultaneously. More specifically, the MOSA-Net is designed to estimate
speech quality, intelligibility, and distortion assessment scores based on a
test speech signal as input. It comprises a convolutional neural network and
bidirectional long short-term memory (CNN-BLSTM) architecture for
representation extraction, as well as a multiplicative attention layer and a
fully-connected layer for each assessment metric. In addition, cross-domain
features (spectral and time-domain features) and latent representations from
self-supervised learned models are used as inputs to combine rich acoustic
information from different speech representations to obtain more accurate
assessments. Experimental results reveal that the MOSA-Net can precisely
predict perceptual evaluation of speech quality (PESQ), short-time objective
intelligibility (STOI), and speech distortion index (SDI) scores when tested on
both noisy and enhanced speech utterances under either seen test conditions
(where the test speakers and noise types are involved in the training set) or
unseen test conditions (where the test speakers and noise types are not
involved in the training set). In light of the confirmed prediction capability,
we further adopt the latent representations of the MOSA-Net to guide the speech
enhancement (SE) process and derive a quality-intelligibility (QI)-aware SE
(QIA-SE) approach accordingly. Experimental results show that QIA-SE provides
superior enhancement performance compared with the baseline SE system in terms
of objective evaluation metrics and qualitative evaluation test.

    

### [[2111.02371] What Robot do I Need? Fast Co-Adaptation of Morphology and Control using Graph Neural Networks](http://arxiv.org/abs/2111.02371)


  The co-adaptation of robot morphology and behaviour becomes increasingly
important with the advent of fast 3D-manufacturing methods and efficient deep
reinforcement learning algorithms. A major challenge for the application of
co-adaptation methods to the real world is the simulation-to-reality-gap due to
model and simulation inaccuracies. However, prior work focuses primarily on the
study of evolutionary adaptation of morphologies exploiting analytical models
and (differentiable) simulators with large population sizes, neglecting the
existence of the simulation-to-reality-gap and the cost of manufacturing cycles
in the real world. This paper presents a new approach combining classic
high-frequency deep neural networks with computational expensive Graph Neural
Networks for the data-efficient co-adaptation of agents with varying numbers of
degrees-of-freedom. Evaluations in simulation show that the new method can
co-adapt agents within such a limited number of production cycles by
efficiently combining design optimization with offline reinforcement learning,
that it allows for the direct application to real-world co-adaptation tasks in
future work

    

### [[2111.02374] Can I use this publicly available dataset to build commercial AI software? Most likely not](http://arxiv.org/abs/2111.02374)


  Publicly available datasets are one of the key drivers for commercial AI
software. The use of publicly available datasets (particularly for commercial
purposes) is governed by dataset licenses. These dataset licenses outline the
rights one is entitled to on a given dataset and the obligations that one must
fulfil to enjoy such rights without any license compliance violations. However,
unlike standardized Open Source Software (OSS) licenses, existing dataset
licenses are defined in an ad-hoc manner and do not clearly outline the rights
and obligations associated with their usage. This makes checking for potential
license compliance violations difficult. Further, a public dataset may be
hosted in multiple locations and created from multiple data sources each of
which may have different licenses. Hence, existing approaches on checking OSS
license compliance cannot be used. In this paper, we propose a new approach to
assess the potential license compliance violations if a given publicly
available dataset were to be used for building commercial AI software. We
conduct trials of our approach on two product groups within Huawei on 6
commonly used publicly available datasets. Our results show that there are
risks of license violations on 5 of these 6 studied datasets if they were used
for commercial purposes. Consequently, we provide recommendations for AI
engineers on how to better assess publicly available datasets for license
compliance violations.

    

### [[2111.02375] Virus-MNIST: Machine Learning Baseline Calculations for Image Classification](http://arxiv.org/abs/2111.02375)


  The Virus-MNIST data set is a collection of thumbnail images that is similar
in style to the ubiquitous MNIST hand-written digits. These, however, are cast
by reshaping possible malware code into an image array. Naturally, it is poised
to take on a role in benchmarking progress of virus classifier model training.
Ten types are present: nine classified as malware and one benign. Cursory
examination reveals unequal class populations and other key aspects that must
be considered when selecting classification and pre-processing methods.
Exploratory analyses show possible identifiable characteristics from aggregate
metrics (e.g., the pixel median values), and ways to reduce the number of
features by identifying strong correlations. A model comparison shows that
Light Gradient Boosting Machine, Gradient Boosting Classifier, and Random
Forest algorithms produced the highest accuracy scores, thus showing promise
for deeper scrutiny.

    

### [[2111.02378] Intrusion Detection: Machine Learning Baseline Calculations for Image Classification](http://arxiv.org/abs/2111.02378)


  Cyber security can be enhanced through application of machine learning by
recasting network attack data into an image format, then applying supervised
computer vision and other machine learning techniques to detect malicious
specimens. Exploratory data analysis reveals little correlation and few
distinguishing characteristics between the ten classes of malware used in this
study. A general model comparison demonstrates that the most promising
candidates for consideration are Light Gradient Boosting Machine, Random Forest
Classifier, and Extra Trees Classifier. Convolutional networks fail to deliver
their outstanding classification ability, being surpassed by a simple, fully
connected architecture. Most tests fail to break 80% categorical accuracy and
present low F1 scores, indicating more sophisticated approaches (e.g.,
bootstrapping, random samples, and feature selection) may be required to
maximize performance.

    

### [[2111.02387] An Empirical Study of Training End-to-End Vision-and-Language Transformers](http://arxiv.org/abs/2111.02387)


  Vision-and-language (VL) pre-training has proven to be highly effective on
various VL downstream tasks. While recent work has shown that fully
transformer-based VL models can be more efficient than previous
region-feature-based methods, their performance on downstream tasks are often
degraded significantly. In this paper, we present METER~(\textbf{M}ultimodal
\textbf{E}nd-to-end \textbf{T}ransform\textbf{ER}), through which we
systematically investigate how to design and pre-train a fully
transformer-based VL model in an end-to-end manner. Specifically, we dissect
the model designs along multiple dimensions: vision encoders (e.g., CLIP-ViT,
Swin transformer), text encoders (e.g., RoBERTa, DeBERTa), multimodal fusion
(e.g., merged attention vs. co-attention), architecture design (e.g.,
encoder-only vs. encoder-decoder), and pre-training objectives (e.g., masked
image modeling). We conduct comprehensive experiments on a wide range of VL
tasks, and provide insights on how to train a performant VL transformer while
maintaining fast inference speed. Notably, METER~achieves an accuracy of
77.64\% on the VQAv2 test-std set using only 4M images for pre-training,
surpassing the state-of-the-art region-feature-based VinVL model by +1.04\%,
and outperforming the previous best fully transformer-based ALBEF model by
+1.6\%.

    

### [[2111.02388] A Survey of Machine Learning Algorithms for Detecting Malware in IoT Firmware](http://arxiv.org/abs/2111.02388)


  This work explores the use of machine learning techniques on an
Internet-of-Things firmware dataset to detect malicious attempts to infect edge
devices or subsequently corrupt an entire network. Firmware updates are
uncommon in IoT devices; hence, they abound with vulnerabilities. Attacks
against such devices can go unnoticed, and users can become a weak point in
security. Malware can cause DDoS attacks and even spy on sensitive areas like
peoples' homes. To help mitigate this threat, this paper employs a number of
machine learning algorithms to classify IoT firmware and the best performing
models are reported. In a general comparison, the top three algorithms are
Gradient Boosting, Logistic Regression, and Random Forest classifiers. Deep
learning approaches including Convolutional and Fully Connected Neural Networks
with both experimental and proven successful architectures are also explored.

    

### [[1810.04879] Generating Shared Latent Variables for Robots to Imitate Human Movements and Understand their Physical Limitations](http://arxiv.org/abs/1810.04879)


  Assistive robotics and particularly robot coaches may be very helpful for
rehabilitation healthcare. In this context, we propose a method based on
Gaussian Process Latent Variable Model (GP-LVM) to transfer knowledge between a
physiotherapist, a robot coach and a patient. Our model is able to map visual
human body features to robot data in order to facilitate the robot learning and
imitation. In addition , we propose to extend the model to adapt robots'
understanding to patient's physical limitations during the assessment of
rehabilitation exercises. Experimental evaluation demonstrates promising
results for both robot imitation and model adaptation according to the
patients' limitations.

    

### [[1908.07822] A Multi-level Neural Network for Implicit Causality Detection in Web Texts](http://arxiv.org/abs/1908.07822)


  Mining causality from text is a complex and crucial natural language
understanding task corresponding to the human cognition. Existing studies at
its solution can be grouped into two primary categories: feature engineering
based and neural model based methods. In this paper, we find that the former
has incomplete coverage and inherent errors but provide prior knowledge; while
the latter leverages context information but causal inference of which is
insufficiency. To handle the limitations, we propose a novel causality
detection model named MCDN to explicitly model causal reasoning process, and
furthermore, to exploit the advantages of both methods. Specifically, we adopt
multi-head self-attention to acquire semantic feature at word level and develop
the SCRN to infer causality at segment level. To the best of our knowledge,
with regards to the causality tasks, this is the first time that the Relation
Network is applied. The experimental results show that: 1) the proposed
approach performs prominent performance on causality detection; 2) further
analysis manifests the effectiveness and robustness of MCDN.

    

### [[1908.11853] BooVAE: Boosting Approach for Continual Learning of VAE](http://arxiv.org/abs/1908.11853)


  Variational autoencoder (VAE) is a deep generative model for unsupervised
learning, allowing to encode observations into the meaningful latent space. VAE
is prone to catastrophic forgetting when tasks arrive sequentially, and only
the data for the current one is available. We address this problem of continual
learning for VAEs. It is known that the choice of the prior distribution over
the latent space is crucial for VAE in the non-continual setting. We argue that
it can also be helpful to avoid catastrophic forgetting. We learn the
approximation of the aggregated posterior as a prior for each task. This
approximation is parametrised as an additive mixture of distributions induced
by encoder evaluated at trainable pseudo-inputs. We use a greedy boosting-like
approach with entropy regularisation to learn the components. This method
encourages components diversity, which is essential as we aim at memorising the
current task with the fewest components possible. Based on the learnable prior,
we introduce an end-to-end approach for continual learning of VAEs and provide
empirical studies on commonly used benchmarks (MNIST, Fashion MNIST, NotMNIST)
and CelebA datasets. For each dataset, the proposed method avoids catastrophic
forgetting in a fully automatic way.

    

### [[1912.07702] Complexity of Stochastic Dual Dynamic Programming](http://arxiv.org/abs/1912.07702)


  Stochastic dual dynamic programming is a cutting plane type algorithm for
multi-stage stochastic optimization originated about 30 years ago. In spite of
its popularity in practice, there does not exist any analysis on the
convergence rates of this method. In this paper, we first establish the number
of iterations, i.e., iteration complexity, required by a basic dynamic cutting
plane method for solving relatively simple multi-stage optimization problems,
by introducing novel mathematical tools including the saturation of search
points. We then refine these basic tools and establish the iteration complexity
for both deterministic and stochastic dual dynamic programming methods for
solving more general multi-stage stochastic optimization problems under the
standard stage-wise independence assumption. Our results indicate that the
complexity of some of these methods mildly increases with the number of stages
$T$, in fact linearly dependent on $T$ for discounted problems. Therefore, they
are efficient for strategic decision making which involves a large number of
stages, but with a relatively small number of decision variables in each stage.
Without explicitly discretizing the state and action spaces, these methods
might also be pertinent to the related reinforcement learning and stochastic
control areas.

    

### [[2003.11154] A Systematic Evaluation: Fine-Grained CNN vs. Traditional CNN Classifiers](http://arxiv.org/abs/2003.11154)


  To make the best use of the underlying minute and subtle differences,
fine-grained classifiers collect information about inter-class variations. The
task is very challenging due to the small differences between the colors,
viewpoint, and structure in the same class entities. The classification becomes
more difficult due to the similarities between the differences in viewpoint
with other classes and differences with its own. In this work, we investigate
the performance of the landmark general CNN classifiers, which presented
top-notch results on large scale classification datasets, on the fine-grained
datasets, and compare it against state-of-the-art fine-grained classifiers. In
this paper, we pose two specific questions: (i) Do the general CNN classifiers
achieve comparable results to fine-grained classifiers? (ii) Do general CNN
classifiers require any specific information to improve upon the fine-grained
ones? Throughout this work, we train the general CNN classifiers without
introducing any aspect that is specific to fine-grained datasets. We show an
extensive evaluation on six datasets to determine whether the fine-grained
classifier is able to elevate the baseline in their experiments.

    

### [[2006.06879] Active Sampling for Min-Max Fairness](http://arxiv.org/abs/2006.06879)


  We propose simple active sampling and reweighting strategies for optimizing
min-max fairness that can be applied to any classification or regression model
that is learned via loss minimization. The key intuition behind our approach is
to use at each timestep a datapoint from the group that is worst off under the
current model for updating the model. The ease of implementation and the
generality of our robust formulation make it an attractive option for improving
model performance on badly performing groups. For convex learning problems,
such as linear or logistic regression, we provide a fine-grained analysis of
our strategy, proving its rate of convergence to a min-max fair solution.

    

### [[2006.07721] Beyond Random Matrix Theory for Deep Networks](http://arxiv.org/abs/2006.07721)


  We investigate whether the Wigner semi-circle and Marcenko-Pastur
distributions, often used for deep neural network theoretical analysis, match
empirically observed spectral densities. We find that even allowing for
outliers, the observed spectral shapes strongly deviate from such theoretical
predictions. This raises major questions about the usefulness of these models
in deep learning. We further show that theoretical results, such as the layered
nature of critical points, are strongly dependent on the use of the exact form
of these limiting spectral densities. We consider two new classes of matrix
ensembles; random Wigner/Wishart ensemble products and percolated
Wigner/Wishart ensembles, both of which better match observed spectra. They
also give large discrete spectral peaks at the origin, providing a theoretical
explanation for the observation that various optima can be connected by one
dimensional of low loss values. We further show that, in the case of a random
matrix product, the weight of the discrete spectral component at $0$ depends on
the ratio of the dimensions of the weight matrices.

    

### [[2006.10259] On Path Integration of Grid Cells: Group Representation and Isotropic Scaling](http://arxiv.org/abs/2006.10259)


  Understanding how grid cells perform path integration calculations remains a
fundamental problem. In this paper, we conduct theoretical analysis of a
general representation model of path integration by grid cells, where the 2D
self-position is encoded as a higher dimensional vector, and the 2D self-motion
is represented by a general transformation of the vector. We identify two
conditions on the transformation. One is a group representation condition that
is necessary for path integration. The other is an isotropic scaling condition
that ensures locally conformal embedding, so that the error in the vector
representation translates conformally to the error in the 2D self-position.
Then we investigate the simplest transformation, i.e., the linear
transformation, uncover its explicit algebraic and geometric structure as
matrix Lie group of rotation, and explore the connection between the isotropic
scaling condition and a special class of hexagon grid patterns. Finally, with
our optimization-based approach, we manage to learn hexagon grid patterns that
share similar properties of the grid cells in the rodent brain. The learned
model is capable of accurate long distance path integration. Code is available
at this https URL.

    

### [[2006.13726] Imbalanced Gradients: A Subtle Cause of Overestimated Adversarial Robustness](http://arxiv.org/abs/2006.13726)


  Evaluating the robustness of a defense model is a challenging task in
adversarial robustness research. Obfuscated gradients, a type of gradient
masking, have previously been found to exist in many defense methods and cause
a false signal of robustness. In this paper, we identify a more subtle
situation called Imbalanced Gradients that can also cause overestimated
adversarial robustness. The phenomenon of imbalanced gradients occurs when the
gradient of one term of the margin loss dominates and pushes the attack towards
to a suboptimal direction. To exploit imbalanced gradients, we formulate a
Margin Decomposition (MD) attack that decomposes a margin loss into individual
terms and then explores the attackability of these terms separately via a
two-stage process. We also propose a MultiTargeted and an ensemble version of
our MD attack. By investigating 17 defense models proposed since 2018, we find
that 6 models are susceptible to imbalanced gradients and our MD attack can
decrease their robustness evaluated by the best baseline standalone attack by
another 2%. We also provide an in-depth analysis of the likely causes of
imbalanced gradients and effective countermeasures.

    

### [[2007.00816] Multi-resolution Super Learner for Voxel-wise Classification of Prostate Cancer Using Multi-parametric MRI](http://arxiv.org/abs/2007.00816)


  While current research has shown the importance of Multi-parametric MRI
(mpMRI) in diagnosing prostate cancer (PCa), further investigation is needed
for how to incorporate the specific structures of the mpMRI data, such as the
regional heterogeneity and between-voxel correlation within a subject. This
paper proposes a machine learning-based method for improved voxel-wise PCa
classification by taking into account the unique structures of the data. We
propose a multi-resolution modeling approach to account for regional
heterogeneity, where base learners trained locally at multiple resolutions are
combined using the super learner, and account for between-voxel correlation by
efficient spatial Gaussian kernel smoothing. The method is flexible in that the
super learner framework allows implementation of any classifier as the base
learner, and can be easily extended to classifying cancer into more
sub-categories. We describe detailed classification algorithm for the binary
PCa status, as well as the ordinal clinical significance of PCa for which a
weighted likelihood approach is implemented to enhance the detection of the
less prevalent cancer categories. We illustrate the advantages of the proposed
approach over conventional modeling and machine learning approaches through
simulations and application to in vivo data.

    

### [[2008.01722] Fast and Near-Optimal Diagonal Preconditioning](http://arxiv.org/abs/2008.01722)


  The convergence rates of iterative methods for solving a linear system
$\mathbf{A} x = b$ typically depend on the condition number of the matrix
$\mathbf{A}$. Preconditioning is a common way of speeding up these methods by
reducing that condition number in a computationally inexpensive way. In this
paper, we revisit the decades-old problem of how to best improve $\mathbf{A}$'s
condition number by left or right diagonal rescaling. We make progress on this
problem in several directions.
First, we provide new bounds for the classic heuristic of scaling
$\mathbf{A}$ by its diagonal values (a.k.a. Jacobi preconditioning). We prove
that this approach reduces $\mathbf{A}$'s condition number to within a
quadratic factor of the best possible scaling. Second, we give a solver for
structured mixed packing and covering semidefinite programs (MPC SDPs) which
computes a constant-factor optimal scaling for $\mathbf{A}$ in
$\widetilde{O}(\text{nnz}(\mathbf{A}) \cdot \text{poly}(\kappa^\star))$ time;
this matches the cost of solving the linear system after scaling up to a
$\widetilde{O}(\text{poly}(\kappa^\star))$ factor. Third, we demonstrate that a
sufficiently general width-independent MPC SDP solver would imply near-optimal
runtimes for the scaling problems we consider, and natural variants concerned
with measures of average conditioning.
Finally, we highlight connections of our preconditioning techniques to
semi-random noise models, as well as applications in reducing risk in several
statistical regression models.

    

### [[2010.15942] Machine versus Human Attention in Deep Reinforcement Learning Tasks](http://arxiv.org/abs/2010.15942)


  Deep reinforcement learning (RL) algorithms are powerful tools for solving
visuomotor decision tasks. However, the trained models are often difficult to
interpret, because they are represented as end-to-end deep neural networks. In
this paper, we shed light on the inner workings of such trained models by
analyzing the pixels that they attend to during task execution, and comparing
them with the pixels attended to by humans executing the same tasks. To this
end, we investigate the following two questions that, to the best of our
knowledge, have not been previously studied. 1) How similar are the visual
representations learned by RL agents and humans when performing the same task?
and, 2) How do similarities and differences in these learned representations
explain RL agents' performance on these tasks? Specifically, we compare the
saliency maps of RL agents against visual attention models of human experts
when learning to play Atari games. Further, we analyze how hyperparameters of
the deep RL algorithm affect the learned representations and saliency maps of
the trained agents. The insights provided have the potential to inform novel
algorithms for closing the performance gap between human experts and RL agents.

    

### [[2012.06405] Attack Agnostic Detection of Adversarial Examples via Random Subspace Analysis](http://arxiv.org/abs/2012.06405)


  Whilst adversarial attack detection has received considerable attention, it
remains a fundamentally challenging problem from two perspectives. First, while
threat models can be well-defined, attacker strategies may still vary widely
within those constraints. Therefore, detection should be considered as an
open-set problem, standing in contrast to most current detection approaches.
These methods take a closed-set view and train binary detectors, thus biasing
detection toward attacks seen during detector training. Second, limited
information is available at test time and typically confounded by nuisance
factors including the label and underlying content of the image. We address
these challenges via a novel strategy based on random subspace analysis. We
present a technique that utilizes properties of random projections to
characterize the behavior of clean and adversarial examples across a diverse
set of subspaces. The self-consistency (or inconsistency) of model activations
is leveraged to discern clean from adversarial examples. Performance
evaluations demonstrate that our technique ($AUC\in[0.92, 0.98]$) outperforms
competing detection strategies ($AUC\in[0.30,0.79]$), while remaining truly
agnostic to the attack strategy (for both targeted/untargeted attacks). It also
requires significantly less calibration data (composed only of clean examples)
than competing approaches to achieve this performance.

    

### [[2102.09645] SVRG Meets AdaGrad: Painless Variance Reduction](http://arxiv.org/abs/2102.09645)


  Variance reduction (VR) methods for finite-sum minimization typically require
the knowledge of problem-dependent constants that are often unknown and
difficult to estimate. To address this, we use ideas from adaptive gradient
methods to propose AdaSVRG, which is a more robust variant of SVRG, a common VR
method. AdaSVRG uses AdaGrad in the inner loop of SVRG, making it robust to the
choice of step-size. When minimizing a sum of n smooth convex functions, we
prove that a variant of AdaSVRG requires $\tilde{O}(n + 1/\epsilon)$ gradient
evaluations to achieve an $O(\epsilon)$-suboptimality, matching the typical
rate, but without needing to know problem-dependent constants. Next, we
leverage the properties of AdaGrad to propose a heuristic that adaptively
determines the length of each inner-loop in AdaSVRG. Via experiments on
synthetic and real-world datasets, we validate the robustness and effectiveness
of AdaSVRG, demonstrating its superior performance over standard and other
"tune-free" VR methods.

    

### [[2102.10490] Stronger NAS with Weaker Predictors](http://arxiv.org/abs/2102.10490)


  Neural Architecture Search (NAS) often trains and evaluates a large number of
architectures. Recent predictor-based NAS approaches attempt to alleviate such
heavy computation costs with two key steps: sampling some
architecture-performance pairs and fitting a proxy accuracy predictor. Given
limited samples, these predictors, however, are far from accurate to locate top
architectures due to the difficulty of fitting the huge search space. This
paper reflects on a simple yet crucial question: if our final goal is to find
the best architecture, do we really need to model the whole space well?. We
propose a paradigm shift from fitting the whole architecture space using one
strong predictor, to progressively fitting a search path towards the
high-performance sub-space through a set of weaker predictors. As a key
property of the weak predictors, their probabilities of sampling better
architectures keep increasing. Hence we only sample a few well-performed
architectures guided by the previously learned predictor and estimate a new
better weak predictor. This embarrassingly easy framework, dubbed WeakNAS,
produces coarse-to-fine iteration to gradually refine the ranking of sampling
space. Extensive experiments demonstrate that WeakNAS costs fewer samples to
find top-performance architectures on NAS-Bench-101 and NAS-Bench-201. Compared
to state-of-the-art (SOTA) predictor-based NAS methods, WeakNAS outperforms all
with notable margins, e.g., requiring at least 7.5x less samples to find global
optimal on NAS-Bench-101. WeakNAS can also absorb their ideas to boost
performance more. Further, WeakNAS strikes the new SOTA result of 81.3% in the
ImageNet MobileNet Search Space. The code is available at
this https URL.

    

### [[2102.11494] Sample-Efficient Learning of Stackelberg Equilibria in General-Sum Games](http://arxiv.org/abs/2102.11494)


  Real world applications such as economics and policy making often involve
solving multi-agent games with two unique features: (1) The agents are
inherently asymmetric and partitioned into leaders and followers; (2) The
agents have different reward functions, thus the game is general-sum. The
majority of existing results in this field focuses on either symmetric solution
concepts (e.g. Nash equilibrium) or zero-sum games. It remains open how to
learn the Stackelberg equilibrium -- an asymmetric analog of the Nash
equilibrium -- in general-sum games efficiently from noisy samples.
This paper initiates the theoretical study of sample-efficient learning of
the Stackelberg equilibrium, in the bandit feedback setting where we only
observe noisy samples of the reward. We consider three representative
two-player general-sum games: bandit games, bandit-reinforcement learning
(bandit-RL) games, and linear bandit games. In all these games, we identify a
fundamental gap between the exact value of the Stackelberg equilibrium and its
estimated version using finitely many noisy samples, which can not be closed
information-theoretically regardless of the algorithm. We then establish sharp
positive results on sample-efficient learning of Stackelberg equilibrium with
value optimal up to the gap identified above, with matching lower bounds in the
dependency on the gap, error tolerance, and the size of the action spaces.
Overall, our results unveil unique challenges in learning Stackelberg
equilibria under noisy bandit feedback, which we hope could shed light on
future research on this topic.

    

### [[2103.05147] Model-free Policy Learning with Reward Gradients](http://arxiv.org/abs/2103.05147)


  Despite the increasing popularity of policy gradient methods, they are yet to
be widely utilized in sample-scarce applications, such as robotics. The sample
efficiency could be improved by making best usage of available information. As
a key component in reinforcement learning, the reward function is usually
devised carefully to guide the agent. Hence, the reward function is usually
known, allowing access to not only scalar reward signals but also reward
gradients. To benefit from reward gradients, previous works require the
knowledge of environment dynamics, which are hard to obtain. In this work, we
develop the \textit{Reward Policy Gradient} estimator, a novel approach that
integrates reward gradients without learning a model. Bypassing the model
dynamics allows our estimator to achieve a better bias-variance trade-off,
which results in a higher sample efficiency, as shown in the empirical
analysis. Our method also boosts the performance of Proximal Policy
Optimization on different MuJoCo control tasks.

    

### [[2103.10478] Unsupervised Doppler Radar-Based Activity Recognition for e-Healthcare](http://arxiv.org/abs/2103.10478)


  Passive radio frequency (RF) sensing and monitoring of human daily activities
in elderly care homes is an emerging topic. Micro-Doppler radars are an
appealing solution considering their non-intrusiveness, deep penetration, and
high-distance range. Unsupervised activity recognition using Doppler radar data
has not received attention, in spite of its importance in case of unlabelled or
poorly labelled activities in real scenarios. This study proposes two
unsupervised feature extraction methods for the purpose of human activity
monitoring using Doppler-streams. These include a local Discrete Cosine
Transform (DCT)-based feature extraction method and a local entropy-based
feature extraction method. In addition, a novel application of Convolutional
Variational Autoencoder (CVAE) feature extraction is employed for the first
time for Doppler radar data. The three feature extraction architectures are
compared with the previously used Convolutional Autoencoder (CAE) and linear
feature extraction based on Principal Component Analysis (PCA) and 2DPCA.
Unsupervised clustering is performed using K-Means and K-Medoids. The results
show the superiority of DCT-based method, entropy-based method, and CVAE
features compared to CAE, PCA, and 2DPCA, with more than 5\%-20\% average
accuracy. In regards to computation time, the two proposed methods are
noticeably much faster than the existing CVAE. Furthermore, for
high-dimensional data visualisation, three manifold learning techniques are
considered. The methods are compared for the projection of raw data as well as
the encoded CVAE features. All three methods show an improved visualisation
ability when applied to the encoded CVAE features.

    

### [[2104.00535] Data-Driven Optimization for Atlanta Police Zone Design](http://arxiv.org/abs/2104.00535)


  We present a data-driven optimization framework for redesigning police patrol
zones in an urban environment. The objectives are to rebalance police workload
among geographical areas and to reduce response time to emergency calls. We
develop a stochastic model for police emergency response by integrating
multiple data sources, including police incidents reports, demographic surveys,
and traffic data. Using this stochastic model, we optimize zone redesign plans
using mixed-integer linear programming. Our proposed design was implemented by
the Atlanta Police Department in March 2019. By analyzing data before and after
the zone redesign, we show that the new design has reduced the response time to
high priority 911 calls by 5.8\% and the imbalance of police workload among
different zones by 43\%.

    

### [[2104.06763] Oracle Complexity in Nonsmooth Nonconvex Optimization](http://arxiv.org/abs/2104.06763)


  It is well-known that given a smooth, bounded-from-below, and possibly
nonconvex function, standard gradient-based methods can find
$\epsilon$-stationary points (with gradient norm less than $\epsilon$) in
$\mathcal{O}(1/\epsilon^2)$ iterations. However, many important nonconvex
optimization problems, such as those associated with training modern neural
networks, are inherently not smooth, making these results inapplicable. In this
paper, we study nonsmooth nonconvex optimization from an oracle complexity
viewpoint, where the algorithm is assumed to be given access only to local
information about the function at various points. We provide two main results:
First, we consider the problem of getting near $\epsilon$-stationary points.
This is perhaps the most natural relaxation of finding $\epsilon$-stationary
points, which is impossible in the nonsmooth nonconvex case. We prove that this
relaxed goal cannot be achieved efficiently, for any distance and $\epsilon$
smaller than some constants. Our second result deals with the possibility of
tackling nonsmooth nonconvex optimization by reduction to smooth optimization:
Namely, applying smooth optimization methods on a smooth approximation of the
objective function. For this approach, we prove under a mild assumption an
inherent trade-off between oracle complexity and smoothness: On the one hand,
smoothing a nonsmooth nonconvex function can be done very efficiently (e.g., by
randomized smoothing), but with dimension-dependent factors in the smoothness
parameter, which can strongly affect iteration complexity when plugging into
standard smooth optimization methods. On the other hand, these dimension
factors can be eliminated with suitable smoothing methods, but only by making
the oracle complexity of the smoothing process exponentially large.

    

### [[2104.08698] A Simple and Effective Positional Encoding for Transformers](http://arxiv.org/abs/2104.08698)


  Transformer models are permutation equivariant. To supply the order and type
information of the input tokens, position and segment embeddings are usually
added to the input. Recent works proposed variations of positional encodings
with relative position encodings achieving better performance. Our analysis
shows that the gain actually comes from moving positional information to
attention layer from the input. Motivated by this, we introduce Decoupled
Positional Attention for Transformers (DIET), a simple yet effective mechanism
to encode position and segment information into the Transformer models. The
proposed method has faster training and inference time, while achieving
competitive performance on GLUE, XTREME and WMT benchmarks. We further
generalize our method to long-range transformers and show performance gain.

    

### [[2106.00477] Tight Accounting in the Shuffle Model of Differential Privacy](http://arxiv.org/abs/2106.00477)


  Shuffle model of differential privacy is a novel distributed privacy model
based on a combination of local privacy mechanisms and a trusted shuffler. It
has been shown that the additional randomisation provided by the shuffler
improves privacy bounds compared to the purely local mechanisms. Accounting
tight bounds, especially for multi-message protocols, is complicated by the
complexity brought by the shuffler. The recently proposed Fourier Accountant
for evaluating $(\varepsilon,\delta)$-differential privacy guarantees has been
shown to give tighter bounds than commonly used methods for non-adaptive
compositions of various complex mechanisms. In this paper we show how to
compute tight privacy bounds using the Fourier Accountant for multi-message
versions of several ubiquitous mechanisms in the shuffle model and demonstrate
looseness of the existing bounds in the literature.

    

### [[2106.00545] Counterfactual Invariance to Spurious Correlations: Why and How to Pass Stress Tests](http://arxiv.org/abs/2106.00545)


  Informally, a 'spurious correlation' is the dependence of a model on some
aspect of the input data that an analyst thinks shouldn't matter. In machine
learning, these have a know-it-when-you-see-it character; e.g., changing the
gender of a sentence's subject changes a sentiment predictor's output. To check
for spurious correlations, we can 'stress test' models by perturbing irrelevant
parts of input data and seeing if model predictions change. In this paper, we
study stress testing using the tools of causal inference. We introduce
counterfactual invariance as a formalization of the requirement that changing
irrelevant parts of the input shouldn't change model predictions. We connect
counterfactual invariance to out-of-domain model performance, and provide
practical schemes for learning (approximately) counterfactual invariant
predictors (without access to counterfactual examples). It turns out that both
the means and implications of counterfactual invariance depend fundamentally on
the true underlying causal structure of the data -- in particular, whether the
label causes the features or the features cause the label. Distinct causal
structures require distinct regularization schemes to induce counterfactual
invariance. Similarly, counterfactual invariance implies different domain shift
guarantees depending on the underlying causal structure. This theory is
supported by empirical results on text classification.

    

### [[2106.00967] Multiresolution Equivariant Graph Variational Autoencoder](http://arxiv.org/abs/2106.00967)


  In this paper, we propose Multiresolution Equivariant Graph Variational
Autoencoders (MGVAE), the first hierarchical generative model to learn and
generate graphs in a multiresolution and equivariant manner. At each resolution
level, MGVAE employs higher order message passing to encode the graph while
learning to partition it into mutually exclusive clusters and coarsening into a
lower resolution that eventually creates a hierarchy of latent distributions.
MGVAE then constructs a hierarchical generative model to variationally decode
into a hierarchy of coarsened graphs. Importantly, our proposed framework is
end-to-end permutation equivariant with respect to node ordering. MGVAE
achieves competitive results with several generative tasks including general
graph generation, molecular generation, unsupervised molecular representation
learning to predict molecular properties, link prediction on citation graphs,
and graph-based image generation.

    

### [[2106.01540] Luna: Linear Unified Nested Attention](http://arxiv.org/abs/2106.01540)


  The quadratic computational and memory complexities of the Transformer's
attention mechanism have limited its scalability for modeling long sequences.
In this paper, we propose Luna, a linear unified nested attention mechanism
that approximates softmax attention with two nested linear attention functions,
yielding only linear (as opposed to quadratic) time and space complexity.
Specifically, with the first attention function, Luna packs the input sequence
into a sequence of fixed length. Then, the packed sequence is unpacked using
the second attention function. As compared to a more traditional attention
mechanism, Luna introduces an additional sequence with a fixed length as input
and an additional corresponding output, which allows Luna to perform attention
operation linearly, while also storing adequate contextual information. We
perform extensive evaluations on three benchmarks of sequence modeling tasks:
long-context sequence modeling, neural machine translation and masked language
modeling for large-scale pretraining. Competitive or even better experimental
results demonstrate both the effectiveness and efficiency of Luna compared to a
variety

    

### [[2106.05819] Adversarial Graph Augmentation to Improve Graph Contrastive Learning](http://arxiv.org/abs/2106.05819)


  Self-supervised learning of graph neural networks (GNN) is in great need
because of the widespread label scarcity issue in real-world graph/network
data. Graph contrastive learning (GCL), by training GNNs to maximize the
correspondence between the representations of the same graph in its different
augmented forms, may yield robust and transferable GNNs even without using
labels. However, GNNs trained by traditional GCL often risk capturing redundant
graph features and thus may be brittle and provide sub-par performance in
downstream tasks. Here, we propose a novel principle, termed adversarial-GCL
(AD-GCL), which enables GNNs to avoid capturing redundant information during
the training by optimizing adversarial graph augmentation strategies used in
GCL. We pair AD-GCL with theoretical explanations and design a practical
instantiation based on trainable edge-dropping graph augmentation. We
experimentally validate AD-GCL by comparing with the state-of-the-art GCL
methods and achieve performance gains of up-to $14\%$ in unsupervised, $6\%$ in
transfer, and $3\%$ in semi-supervised learning settings overall with 18
different benchmark datasets for the tasks of molecule property regression and
classification, and social network classification.

    

### [[2106.07138] Self-Supervised Metric Learning in Multi-View Data: A Downstream Task Perspective](http://arxiv.org/abs/2106.07138)


  Self-supervised metric learning has been a successful approach for learning a
distance from an unlabeled dataset. The resulting distance is broadly useful
for improving various distance-based downstream tasks, even when no information
from downstream tasks is utilized in the metric learning stage. To gain
insights into this approach, we develop a statistical framework to
theoretically study how self-supervised metric learning can benefit downstream
tasks in the context of multi-view data. Under this framework, we show that the
target distance of metric learning satisfies several desired properties for the
downstream tasks. On the other hand, our investigation suggests the target
distance can be further improved by moderating each direction's weights. In
addition, our analysis precisely characterizes the improvement by
self-supervised metric learning on four commonly used downstream tasks: sample
identification, two-sample testing, $k$-means clustering, and $k$-nearest
neighbor classification. As a by-product, we propose a simple spectral method
for self-supervised metric learning, which is computationally efficient and
minimax optimal for estimating target distance. Finally, numerical experiments
are presented to support the theoretical results in the paper.

    

### [[2106.08750] Quasi-Bayesian Dual Instrumental Variable Regression](http://arxiv.org/abs/2106.08750)


  Recent years have witnessed an upsurge of interest in employing flexible
machine learning models for instrumental variable (IV) regression, but the
development of uncertainty quantification methodology is still lacking. In this
work we present a novel quasi-Bayesian procedure for IV regression, building
upon the recently developed kernelized IV models and the dual/minimax
formulation of IV regression. We analyze the frequentist behavior of the
proposed method, by establishing minimax optimal contraction rates in $L_2$ and
Sobolev norms, and discussing the frequentist validity of credible balls. We
further derive a scalable inference algorithm which can be extended to work
with wide neural network models. Empirical evaluation shows that our method
produces informative uncertainty estimates on complex high-dimensional
problems.

    

### [[2106.12566] Stable, Fast and Accurate: Kernelized Attention with Relative Positional Encoding](http://arxiv.org/abs/2106.12566)


  The attention module, which is a crucial component in Transformer, cannot
scale efficiently to long sequences due to its quadratic complexity. Many works
focus on approximating the dot-then-exponentiate softmax function in the
original attention, leading to sub-quadratic or even linear-complexity
Transformer architectures. However, we show that these methods cannot be
applied to more powerful attention modules that go beyond the
dot-then-exponentiate style, e.g., Transformers with relative positional
encoding (RPE). Since in many state-of-the-art models, relative positional
encoding is used as default, designing efficient Transformers that can
incorporate RPE is appealing. In this paper, we propose a novel way to
accelerate attention calculation for Transformers with RPE on top of the
kernelized attention. Based upon the observation that relative positional
encoding forms a Toeplitz matrix, we mathematically show that kernelized
attention with RPE can be calculated efficiently using Fast Fourier Transform
(FFT). With FFT, our method achieves $\mathcal{O}(n\log n)$ time complexity.
Interestingly, we further demonstrate that properly using relative positional
encoding can mitigate the training instability problem of vanilla kernelized
attention. On a wide range of tasks, we empirically show that our models can be
trained from scratch without any optimization issues. The learned model
performs better than many efficient Transformer variants and is faster than
standard Transformer in the long-sequence regime.

    

### [[2106.13125] Unifying Gradient Estimators for Meta-Reinforcement Learning via Off-Policy Evaluation](http://arxiv.org/abs/2106.13125)


  Model-agnostic meta-reinforcement learning requires estimating the Hessian
matrix of value functions. This is challenging from an implementation
perspective, as repeatedly differentiating policy gradient estimates may lead
to biased Hessian estimates. In this work, we provide a unifying framework for
estimating higher-order derivatives of value functions, based on off-policy
evaluation. Our framework interprets a number of prior approaches as special
cases and elucidates the bias and variance trade-off of Hessian estimates. This
framework also opens the door to a new family of estimates, which can be easily
implemented with auto-differentiation libraries, and lead to performance gains
in practice.

    

### [[2106.15127] Evolving-Graph Gaussian Processes](http://arxiv.org/abs/2106.15127)


  Graph Gaussian Processes (GGPs) provide a data-efficient solution on graph
structured domains. Existing approaches have focused on static structures,
whereas many real graph data represent a dynamic structure, limiting the
applications of GGPs. To overcome this we propose evolving-Graph Gaussian
Processes (e-GGPs). The proposed method is capable of learning the transition
function of graph vertices over time with a neighbourhood kernel to model the
connectivity and interaction changes between vertices. We assess the
performance of our method on time-series regression problems where graphs
evolve over time. We demonstrate the benefits of e-GGPs over static graph
Gaussian Process approaches.

    

### [[2106.15324] Effective Evaluation of Deep Active Learning on Image Classification Tasks](http://arxiv.org/abs/2106.15324)


  With the goal of making deep learning more label-efficient, a growing number
of papers have been studying active learning (AL) for deep models. However,
there are a number of issues in the prevalent experimental settings, mainly
stemming from a lack of unified implementation and benchmarking. Issues in the
current literature include sometimes contradictory observations on the
performance of different AL algorithms, unintended exclusion of important
generalization approaches such as data augmentation and SGD for optimization, a
lack of study of evaluation facets like the labeling efficiency of AL, and
little or no clarity on the scenarios in which AL outperforms random sampling
(RS). In this work, we present a unified re-implementation of state-of-the-art
AL algorithms in the context of image classification via our new open-source AL
toolkit DISTIL, and we carefully study these issues as facets of effective
evaluation. On the positive side, we show that AL techniques are $2\times$ to
$4\times$ more label-efficient compared to RS with the use of data
augmentation. Surprisingly, when data augmentation is included, there is no
longer a consistent gain in using BADGE, a state-of-the-art approach, over
simple uncertainty sampling. We then do a careful analysis of how existing
approaches perform with varying amounts of redundancy and number of examples
per class. Finally, we provide several insights for AL practitioners to
consider in future work, such as the effect of the AL batch size, the effect of
initialization, the importance of retraining the model at every round, and
other insights.

    

### [[2107.12342] Sisyphus: A Cautionary Tale of Using Low-Degree Polynomial Activations in Privacy-Preserving Deep Learning](http://arxiv.org/abs/2107.12342)


  Privacy concerns in client-server machine learning have given rise to private
inference (PI), where neural inference occurs directly on encrypted inputs. PI
protects clients' personal data and the server's intellectual property. A
common practice in PI is to use garbled circuits to compute nonlinear functions
privately, namely ReLUs. However, garbled circuits suffer from high storage,
bandwidth, and latency costs. To mitigate these issues, PI-friendly polynomial
activation functions have been employed to replace ReLU. In this work, we ask:
Is it feasible to substitute all ReLUs with low-degree polynomial activation
functions for building deep, privacy-friendly neural networks? We explore this
question by analyzing the challenges of substituting ReLUs with polynomials,
starting with simple drop-and-replace solutions to novel, more involved
replace-and-retrain strategies. We examine the limitations of each method and
provide commentary on the use of polynomial activation functions for PI. We
find all evaluated solutions suffer from the escaping activation problem:
forward activation values inevitably begin to expand at an exponential rate
away from stable regions of the polynomials, which leads to exploding values
(NaNs) or poor approximations.

    

### [[2110.01359] CENN: Conservative energy method based on neural networks with subdomains for solving heterogeneous problems involving complex geometries](http://arxiv.org/abs/2110.01359)


  We propose a conservative energy method based on neural networks with
subdomains (CENN), where the admissible function satisfying the essential
boundary condition without boundary penalty is constructed by the radial basis
function (RBF), particular solution neural network, and general neural network.
The loss term at the interfaces has the lower order derivative compared to the
strong form PINN with subdomains. The advantage of the proposed method is
higher efficiency, more accurate, and less hyperparameters than the strong form
PINN with subdomains. Another advantage of the proposed method is that it can
apply to complex geometries based on the special construction of the admissible
function. To analyze its performance, the proposed method CENN is used to model
representative PDEs, the examples include strong discontinuity, singularity,
complex boundary, non-linear, and heterogeneous problems. Furthermore, it
outperforms other methods when dealing with heterogeneous problems.

    

### [[2110.05231] Multi-modal Self-supervised Pre-training for Regulatory Genome Across Cell Types](http://arxiv.org/abs/2110.05231)


  In the genome biology research, regulatory genome modeling is an important
topic for many regulatory downstream tasks, such as promoter classification,
transaction factor binding sites prediction. The core problem is to model how
regulatory elements interact with each other and its variability across
different cell types. However, current deep learning methods often focus on
modeling genome sequences of a fixed set of cell types and do not account for
the interaction between multiple regulatory elements, making them only perform
well on the cell types in the training set and lack the generalizability
required in biological applications. In this work, we propose a simple yet
effective approach for pre-training genome data in a multi-modal and
self-supervised manner, which we call GeneBERT. Specifically, we simultaneously
take the 1d sequence of genome data and a 2d matrix of (transcription factors x
regions) as the input, where three pre-training tasks are proposed to improve
the robustness and generalizability of our model. We pre-train our model on the
ATAC-seq dataset with 17 million genome sequences. We evaluate our GeneBERT on
regulatory downstream tasks across different cell types, including promoter
classification, transaction factor binding sites prediction, disease risk
estimation, and splicing sites prediction. Extensive experiments demonstrate
the effectiveness of multi-modal and self-supervised pre-training for
large-scale regulatory genomics data.

    

### [[2110.08765] Temporal Knowledge Graph Reasoning Triggered by Memories](http://arxiv.org/abs/2110.08765)


  Inferring missing facts in temporal knowledge graphs is a critical task and
has been widely explored. Extrapolation in temporal reasoning tasks is more
challenging and gradually attracts the attention of researchers since no direct
history facts for prediction. Previous works attempted to apply evolutionary
representation learning to solve the extrapolation problem. However, these
techniques do not explicitly leverage various time-aware attribute
representations, i.e. the reasoning performance is significantly affected by
the history length. To alleviate the time dependence when reasoning future
missing facts, we propose a memory-triggered decision-making (MTDM) network,
which incorporates transient memories, long-short-term memories, and deep
memories. Specifically, the transient learning network considers transient
memories as a static knowledge graph, and the time-aware recurrent evolution
network learns representations through a sequence of recurrent evolution units
from long-short-term memories. Each evolution unit consists of a structural
encoder to aggregate edge information, a time encoder with a gating unit to
update attribute representations of entities. MTDM utilizes the crafted
residual multi-relational aggregator as the structural encoder to solve the
multi-hop coverage problem. We also introduce the dissolution learning
constraint for better understanding the event dissolution process. Extensive
experiments demonstrate the MTDM alleviates the history dependence and achieves
state-of-the-art prediction performance. Moreover, compared with the most
advanced baseline, MTDM shows a faster convergence speed and training speed.

    

### [[2110.11303] Survival-oriented embeddings for improving accessibility to complex data structures](http://arxiv.org/abs/2110.11303)


  Deep learning excels in the analysis of unstructured data and recent
advancements allow to extend these techniques to survival analysis. In the
context of clinical radiology, this enables, e.g., to relate unstructured
volumetric images to a risk score or a prognosis of life expectancy and support
clinical decision making. Medical applications are, however, associated with
high criticality and consequently, neither medical personnel nor patients do
usually accept black box models as reason or basis for decisions. Apart from
averseness to new technologies, this is due to missing interpretability,
transparency and accountability of many machine learning methods. We propose a
hazard-regularized variational autoencoder that supports straightforward
interpretation of deep neural architectures in the context of survival
analysis, a field highly relevant in healthcare. We apply the proposed approach
to abdominal CT scans of patients with liver tumors and their corresponding
survival times.

    

### [[2111.00684] Graph Structural Attack by Spectral Distance](http://arxiv.org/abs/2111.00684)


  Graph Convolutional Networks (GCNs) have fueled a surge of interest due to
their superior performance on graph learning tasks, but are also shown
vulnerability to adversarial attacks. In this paper, an effective graph
structural attack is investigated to disrupt graph spectral filters in the
Fourier domain. We define the spectral distance based on the eigenvalues of
graph Laplacian to measure the disruption of spectral filters. We then generate
edge perturbations by simultaneously maximizing a task-specific attack
objective and the proposed spectral distance. The experiments demonstrate
remarkable effectiveness of the proposed attack in the white-box setting at
both training and test time. Our qualitative analysis shows the connection
between the attack behavior and the imposed changes on the spectral
distribution, which provides empirical evidence that maximizing spectral
distance is an effective manner to change the structural property of graphs in
the spatial domain and perturb the frequency components in the Fourier domain.

    

### [[2111.00960] gtfs2vec -- Learning GTFS Embeddings for comparing Public Transport Offer in Microregions](http://arxiv.org/abs/2111.00960)


  We selected 48 European cities and gathered their public transport timetables
in the GTFS format. We utilized Uber's H3 spatial index to divide each city
into hexagonal micro-regions. Based on the timetables data we created certain
features describing the quantity and variety of public transport availability
in each region. Next, we trained an auto-associative deep neural network to
embed each of the regions. Having such prepared representations, we then used a
hierarchical clustering approach to identify similar regions. To do so, we
utilized an agglomerative clustering algorithm with a euclidean distance
between regions and Ward's method to minimize in-cluster variance. Finally, we
analyzed the obtained clusters at different levels to identify some number of
clusters that qualitatively describe public transport availability. We showed
that our typology matches the characteristics of analyzed cities and allows
succesful searching for areas with similar public transport schedule
characteristics.

    

### [[2111.01037] Interpretable and Explainable Machine Learning for Materials Science and Chemistry](http://arxiv.org/abs/2111.01037)


  While the uptake of data-driven approaches for materials science and
chemistry is at an exciting, early stage, to realise the true potential of
machine learning models for successful scientific discovery, they must have
qualities beyond purely predictive power. The predictions and inner workings of
models should provide a certain degree of explainability by human experts,
permitting the identification of potential model issues or limitations,
building trust on model predictions and unveiling unexpected correlations that
may lead to scientific insights. In this work, we summarize applications of
interpretability and explainability techniques for materials science and
chemistry and discuss how these techniques can improve the outcome of
scientific studies. We discuss various challenges for interpretable machine
learning in materials science and, more broadly, in scientific settings. In
particular, we emphasize the risks of inferring causation or reaching
generalization by purely interpreting machine learning models and the need of
uncertainty estimates for model explanations. Finally, we showcase a number of
exciting developments in other fields that could benefit interpretability in
material science and chemistry problems.

    

### [[2006.10424] An Investigation of the Weight Space to Monitor the Training Progress of Neural Networks](http://arxiv.org/abs/2006.10424)


  Safe use of Deep Neural Networks (DNNs) requires careful testing. However,
deployed models are often trained further to improve in performance. As
rigorous testing and evaluation is expensive, triggers are in need to determine
the degree of change of a model. In this paper we investigate the weight space
of DNN models for structure that can be exploited to that end. Our results show
that DNN models evolve on unique, smooth trajectories in weight space which can
be used to track DNN training progress. We hypothesize that curvature and
smoothness of the trajectories as well as step length along it may contain
information on the state of training as well as potential domain shifts. We
show that the model trajectories can be separated and the order of checkpoints
on the trajectories recovered, which may serve as a first step towards DNN
model versioning.

    

### [[2111.01916] Accelerating Genome Sequence Analysis via Efficient Hardware/Algorithm Co-Design](http://arxiv.org/abs/2111.01916)


  Genome sequence analysis plays a pivotal role in enabling many medical and
scientific advancements in personalized medicine, outbreak tracing, and
forensics. However, the analysis of genome sequencing data is currently
bottlenecked by the computational power and memory bandwidth limitations of
existing systems. In this dissertation, we propose four major works, where we
characterize the real-system behavior of the genome sequence analysis pipeline
and its associated tools, expose the bottlenecks and tradeoffs, and co-design
fast and efficient algorithms along with scalable and energy-efficient
customized hardware accelerators for the key bottlenecks to enable faster
genome sequence analysis.
First, we comprehensively analyze the tools in the genome assembly pipeline
for long reads in multiple dimensions, uncovering bottlenecks and tradeoffs
that different combinations of tools and different underlying systems lead to.
Second, we propose GenASM, an acceleration framework that builds upon
bitvector-based approximate string matching to accelerate multiple steps of the
genome sequence analysis pipeline. We co-design our highly-parallel, scalable
and memory-efficient algorithms with low-power and area-efficient hardware
accelerators. Third, we implement an FPGA-based prototype for GenASM, where
state-of-the-art 3D-stacked memory offers high memory bandwidth and FPGA
resources offer high parallelism. Fourth, we propose SeGraM, the first hardware
acceleration framework for sequence-to-graph mapping and alignment. We
co-design algorithms and accelerators for memory-efficient minimizer-based
seeding and bitvector-based, highly-parallel sequence-to-graph alignment.
Overall, we demonstrate that genome sequence analysis can be accelerated by
co-designing scalable and energy-efficient customized accelerators along with
efficient algorithms for the key steps of genome sequence analysis.

    

### [[2111.01947] An Evaluation of WebAssembly and eBPF as Offloading Mechanisms in the Context of Computational Storage](http://arxiv.org/abs/2111.01947)


  As the volume of data that needs to be processed continues to increase, we
also see renewed interests in near-data processing in the form of computational
storage, with eBPF (extended Berkeley Packet Filter) being proposed as a
vehicle for computation offloading. However, discussions in this regard have so
far ignored viable alternatives, and no convincing analysis has been provided.
As such, we qualitatively and quantitatively evaluated eBPF against
WebAssembly, a seemingly similar technology, in the context of computation
offloading. This report presents our findings.

    

### [[2111.01948] Design and implementation of an out-of-order execution engine of floating-point arithmetic operations](http://arxiv.org/abs/2111.01948)


  In this thesis, work is undertaken towards the design in hardware description
languages and implementation in FPGA of an out-of-order execution engine of
floating-point arithmetic operations for the Lagarto II core. A first proposal
covers the design of a low power consumption issue queue for out-of-order
processors, register bank, bypass network, and the functional units for
addition/subtraction, multiplication, division/reciprocal, and Fused Multiply
Accumulate (FMAC) confirming with the IEEE-754 standard. The design supports
double-precision format and denormalized numbers; A second proposal is based on
a pair of FMAC as functional units which can perform almost all Floating-point
operations, this design is more beneficial in area, performance, and energy
efficiency compared with the first version.

    

### [[2111.01949] A RISC-V Simulator and Benchmark Suite for Designing and Evaluating Vector Architectures](http://arxiv.org/abs/2111.01949)


  Vector architectures lack tools for research. Consider the gem5 simulator,
which is possibly the leading platform for computer-system architecture
research. Unfortunately, gem5 does not have an available distribution that
includes a flexible and customizable vector architecture model. In consequence,
researchers have to develop their own simulation platform to test their ideas,
which consume much research time. However, once the base simulator platform is
developed, another question is the following: Which applications should be
tested to perform the experiments? The lack of Vectorized Benchmark Suites is
another limitation. To face these problems, this work presents a set of tools
for designing and evaluating vector architectures. First, the gem5 simulator
was extended to support the execution of RISC-V Vector instructions by adding a
parameterizable Vector Architecture model for designers to evaluate different
approaches according to the target they pursue. Second, a novel Vectorized
Benchmark Suite is presented: a collection composed of seven data-parallel
applications from different domains that can be classified according to the
modules that are stressed in the vector architecture. Finally, a study of the
Vectorized Benchmark Suite executing on the gem5-based Vector Architecture
model is highlighted. This suite is the first in its category that covers the
different possible usage scenarios that may occur within different vector
architecture designs such as embedded systems, mainly focused on short vectors,
or High-Performance-Computing (HPC), usually designed for large vectors.

    

### [[2111.01972] Implementing a scalable and elastic computing environment based on Cloud Containers](http://arxiv.org/abs/2111.01972)


  In this article we look at the potential of cloud containers and we provide
some guidelines for companies and organisations that are starting to look at
how to migrate their legacy infrastructure to something modern, reliable and
scalable. We propose an architecture that has an excellent relationship between
the cost of implementation and the benefits it can bring, based on the "Pilot
Light" topology. The services are reconfigured inside small docker containers
and the workload is balanced using load balancers that allow horizontal
autoscaling techniques to be exploited in the future. By generating additional
containers and utilizing the possibilities given by load balancers, companies
and network systems experts may model and calibrate infrastructures based on
the projected number of users. Containers offer the opportunity to expand the
infrastructure and increase processing capacity in a very short time. The
proposed approach results in an easily maintainable and fault-tolerant system
that could help and simplify the work in particular of small and medium-sized
organisations.

    

### [[2111.02325] Extending Memory Capacity in Consumer Devices with Emerging Non-Volatile Memory: An Experimental Study](http://arxiv.org/abs/2111.02325)


  The number and diversity of consumer devices are growing rapidly, alongside
their target applications' memory consumption. Unfortunately, DRAM scalability
is becoming a limiting factor to the available memory capacity in consumer
devices. As a potential solution, manufacturers have introduced emerging
non-volatile memories (NVMs) into the market, which can be used to increase the
memory capacity of consumer devices by augmenting or replacing DRAM. Since
entirely replacing DRAM with NVM in consumer devices imposes large system
integration and design challenges, recent works propose extending the total
main memory space available to applications by using NVM as swap space for
DRAM. However, no prior work analyzes the implications of enabling a real
NVM-based swap space in real consumer devices.
In this work, we provide the first analysis of the impact of extending the
main memory space of consumer devices using off-the-shelf NVMs. We extensively
examine system performance and energy consumption when the NVM device is used
as swap space for DRAM main memory to effectively extend the main memory
capacity. For our analyses, we equip real web-based Chromebook computers with
the Intel Optane SSD, which is a state-of-the-art low-latency NVM-based SSD
device. We compare the performance and energy consumption of interactive
workloads running on our Chromebook with NVM-based swap space, where the Intel
Optane SSD capacity is used as swap space to extend main memory capacity,
against two state-of-the-art systems: (i) a baseline system with double the
amount of DRAM than the system with the NVM-based swap space; and (ii) a system
where the Intel Optane SSD is naively replaced with a state-of-the-art (yet
slower) off-the-shelf NAND-flash-based SSD, which we use as a swap space of
equivalent size as the NVM-based swap space.

    

### [[2111.01904] Adaptive Massively Parallel Constant-round Tree Contraction](http://arxiv.org/abs/2111.01904)


  Miller and Reif's FOCS'85 classic and fundamental tree contraction algorithm
is a broadly applicable technique for the parallel solution of a large number
of tree problems. Additionally it is also used as an algorithmic design
technique for a large number of parallel graph algorithms. In all previously
explored models of computation, however, tree contractions have only been
achieved in $\Omega(\log n)$ rounds of parallel run time. In this work, we not
only introduce a generalized tree contraction method but also show it can be
computed highly efficiently in $O(1/\epsilon^3)$ rounds in the Adaptive
Massively Parallel Computing (AMPC) setting, where each machine has
$O(n^\epsilon)$ local memory for some $0 < \epsilon < 1$. AMPC is a practical
extension of Massively Parallel Computing (MPC) which utilizes distributed hash
tables. In general, MPC is an abstract model for MapReduce, Hadoop, Spark, and
Flume which are currently widely used across industry and has been studied
extensively in the theory community in recent years. Last but not least, we
show that our results extend to multiple problems on trees, including but not
limited to maximum and maximal matching, maximum and maximal independent set,
tree isomorphism testing, and more.

    

### [[2111.02055] Salt-based autopeering for DLT-networks](http://arxiv.org/abs/2111.02055)


  The security of any Distributed Ledger Technology (DLT) depends on the safety
of the network layer. Much effort has been put into understanding the consensus
layer of DLTs. However, many network layer designs seem ad-hoc and lack a
careful analysis of the influence of the design decisions on the whole DLT
system. We propose a salt-based automated neighbor selection protocol that
shows the inherent tradeoffs of certain design decisions and allows a
quantitative treatment of some network topology requirements. This example may
serve as a design framework and facilitate future research. We provide a
selection of results from simulations to highlight some tradeoffs in the design
decisions.

    

### [[2111.02162] Byzantine Agreement with Less Communication: Recent Advances](http://arxiv.org/abs/2111.02162)


  In recent years, Byzantine Agreement is being considered in increasing scales
due to the proliferation of blockchains and other decentralized financial
technologies. Consequently, a number of works have improved its communication
complexity in various network models. In this short paper we survey recent
advances and outline some open research questions on the subject.

    

### [[2111.02251] Fair Mutual Exclusion for N Processes (extended version)](http://arxiv.org/abs/2111.02251)


  Peterson's mutual exclusion algorithm for two processes has been generalized
to $N$ processes in various ways. As far as we know, no such generalization is
starvation free without making any fairness assumptions. In this paper, we
study the generalization of Peterson's algorithm to $N$ processes using a
tournament tree. Using the mCRL2 language and toolset we prove that it is not
starvation free unless weak fairness assumptions are incorporated. Inspired by
the counterexample for starvation freedom, we propose a fair $N$-process
generalization of Peterson's algorithm. We use model checking to show that our
new algorithm is correct for small $N$. For arbitrary $N$, model checking is
infeasible due to the state space explosion problem, and instead, we present a
general proof that, for $N \geq 4$, when a process requests access to the
critical section, other processes can enter first at most $(N-1)(N-2)$ times.

    

### [[2111.02257] Chirotonia: A Scalable and Secure e-Voting Framework based on Blockchains and Linkable Ring Signatures](http://arxiv.org/abs/2111.02257)


  In this paper we propose a comprehensive and scalable framework to build
secure-by-design e-voting systems. Decentralization, transparency, determinism,
and untamperability of votes are granted by dedicated smart contracts on a
blockchain, while voter authenticity and anonymity are achieved through
(provable secure) linkable ring signatures. These, in combination with suitable
smart contract constraints, also grant protection from double voting. Our
design is presented in detail, focusing on its security guarantees and the
design choices that allow it to scale to a large number of voters. Finally, we
present a proof-of-concept implementation of the proposed framework, made
available as open source.

    

### [[1605.09513] Evaluating Distributed Execution of Workloads](http://arxiv.org/abs/1605.09513)


  Resource selection and task placement for distributed execution poses
conceptual and implementation difficulties. Although resource selection and
task placement are at the core of many tools and workflow systems, the methods
are ad hoc rather than being based on models. Consequently, partial and
non-interoperable implementations proliferate. We address both the conceptual
and implementation difficulties by experimentally characterizing diverse
modalities of resource selection and task placement. We compare the
architectures and capabilities of two systems: the AIMES middleware and Swift
workflow scripting language and runtime. We integrate these systems to enable
the distributed execution of Swift workflows on Pilot-Jobs managed by the AIMES
middleware. Our experiments characterize and compare alternative execution
strategies by measuring the time to completion of heterogeneous uncoupled
workloads executed at diverse scale and on multiple resources. We measure the
adverse effects of pilot fragmentation and early binding of tasks to resources
and the benefits of backfill scheduling across pilots on multiple resources. We
then use this insight to execute a multi-stage workflow across five
production-grade resources. We discuss the importance and implications for
other tools and workflow systems.

    

### [[2111.01856] Detecting Logical Relation In Contract Clauses](http://arxiv.org/abs/2111.01856)


  Contracts underlie most modern commercial transactions defining define the
duties and obligations of the related parties in an agreement. Ensuring such
agreements are error free is crucial for modern society and their analysis of a
contract requires understanding the logical relations between clauses and
identifying potential contradictions. This analysis depends on error-prone
human effort to understand each contract clause. In this work, we develop an
approach to automate the extraction of logical relations between clauses in a
contract. We address this problem as a Natural Language Inference task to
detect the entailment type between two clauses in a contract. The resulting
approach should help contract authors detecting potential logical conflicts
between clauses.

    

### [[2111.01906] A trained humanoid robot can perform human-like crossmodal social attention conflict resolution](http://arxiv.org/abs/2111.01906)


  Due to the COVID-19 pandemic, robots could be seen as potential resources in
tasks like helping people work remotely, sustaining social distancing, and
improving mental or physical health. To enhance human-robot interaction, it is
essential for robots to become more socialised, via processing multiple social
cues in a complex real-world environment. Our study adopted a neurorobotic
paradigm of gaze-triggered audio-visual crossmodal integration to make an iCub
robot express human-like social attention responses. At first, a behavioural
experiment was conducted on 37 human participants. To improve ecological
validity, a round-table meeting scenario with three masked animated avatars was
designed with the middle one capable of performing gaze shift, and the other
two capable of generating sound. The gaze direction and the sound location are
either congruent or incongruent. Masks were used to cover all facial visual
cues other than the avatars' eyes. We observed that the avatar's gaze could
trigger crossmodal social attention with better human performance in the
audio-visual congruent condition than in the incongruent condition. Then, our
computational model, GASP, was trained to implement social cue detection,
audio-visual saliency prediction, and selective attention. After finishing the
model training, the iCub robot was exposed to similar laboratory conditions as
human participants, demonstrating that it can replicate similar attention
responses as humans regarding the congruency and incongruency performance,
while overall the human performance was still superior. Therefore, this
interdisciplinary work provides new insights on mechanisms of crossmodal social
attention and how it can be modelled in robots in a complex environment.

    

### [[2111.01911] Parameterized Explanations for Investor / Company Matching](http://arxiv.org/abs/2111.01911)


  Matching companies and investors is usually considered a highly specialized
decision making process. Building an AI agent that can automate such
recommendation process can significantly help reduce costs, and eliminate human
biases and errors. However, limited sample size of financial data-sets and the
need for not only good recommendations, but also explaining why a particular
recommendation is being made, makes this a challenging problem. In this work we
propose a representation learning based recommendation engine that works
extremely well with small datasets and demonstrate how it can be coupled with a
parameterized explanation generation engine to build an explainable
recommendation system for investor-company matching. We compare the performance
of our system with human generated recommendations and demonstrate the ability
of our algorithm to perform extremely well on this task. We also highlight how
explainability helps with real-life adoption of our system.

    

### [[2111.01934] Dehumanizing Voice Technology: Phonetic & Experiential Consequences of Restricted Human-Machine Interaction](http://arxiv.org/abs/2111.01934)


  The use of natural language and voice-based interfaces gradu-ally transforms
how consumers search, shop, and express their preferences. The current work
explores how changes in the syntactical structure of the interaction with
conversational interfaces (command vs. request based expression modalities)
negatively affects consumers' subjective task enjoyment and systematically
alters objective vocal features in the human voice. We show that requests (vs.
commands) lead to an in-crease in phonetic convergence and lower phonetic
latency, and ultimately a more natural task experience for consumers. To the
best of our knowledge, this is the first work docu-menting that altering the
input modality of how consumers interact with smart objects systematically
affects consumers' IoT experience. We provide evidence that altering the
required input to initiate a conversation with smart objects provokes
systematic changes both in terms of consumers' subjective experience and
objective phonetic changes in the human voice. The current research also makes
a methodological con-tribution by highlighting the unexplored potential of
feature extraction in human voice as a novel data format linking consumers'
vocal features during speech formation and their sub-jective task experiences.

    

### [[2111.01983] Obvious Manipulability of Voting Rules](http://arxiv.org/abs/2111.01983)


  The Gibbard-Satterthwaite theorem states that no unanimous and
non-dictatorial voting rule is strategyproof. We revisit voting rules and
consider a weaker notion of strategyproofness called not obvious manipulability
that was proposed by Troyan and Morrill (2020). We identify several classes of
voting rules that satisfy this notion. We also show that several voting rules
including k-approval fail to satisfy this property. We characterize conditions
under which voting rules are obviously manipulable. One of our insights is that
certain rules are obviously manipulable when the number of alternatives is
relatively large compared to the number of voters. In contrast to the
Gibbard-Satterthwaite theorem, many of the rules we examined are not obviously
manipulable. This reflects the relatively easier satisfiability of the notion
and the zero information assumption of not obvious manipulability, as opposed
to the perfect information assumption of strategyproofness. We also present
algorithmic results for computing obvious manipulations and report on
experiments.

    

### [[2111.02001] Certifiable Artificial Intelligence Through Data Fusion](http://arxiv.org/abs/2111.02001)


  This paper reviews and proposes concerns in adopting, fielding, and
maintaining artificial intelligence (AI) systems. While the AI community has
made rapid progress, there are challenges in certifying AI systems. Using
procedures from design and operational test and evaluation, there are
opportunities towards determining performance bounds to manage expectations of
intended use. A notional use case is presented with image data fusion to
support AI object recognition certifiability considering precision versus
distance.

    

### [[2111.02026] The Powerful Use of AI in the Energy Sector: Intelligent Forecasting](http://arxiv.org/abs/2111.02026)


  Artificial Intelligence (AI) techniques continue to broaden across
governmental and public sectors, such as power and energy - which serve as
critical infrastructures for most societal operations. However, due to the
requirements of reliability, accountability, and explainability, it is risky to
directly apply AI-based methods to power systems because society cannot afford
cascading failures and large-scale blackouts, which easily cost billions of
dollars. To meet society requirements, this paper proposes a methodology to
develop, deploy, and evaluate AI systems in the energy sector by: (1)
understanding the power system measurements with physics, (2) designing AI
algorithms to forecast the need, (3) developing robust and accountable AI
methods, and (4) creating reliable measures to evaluate the performance of the
AI model. The goal is to provide a high level of confidence to energy utility
users. For illustration purposes, the paper uses power system event forecasting
(PEF) as an example, which carefully analyzes synchrophasor patterns measured
by the Phasor Measurement Units (PMUs). Such a physical understanding leads to
a data-driven framework that reduces the dimensionality with physics and
forecasts the event with high credibility. Specifically, for dimensionality
reduction, machine learning arranges physical information from different
dimensions, resulting inefficient information extraction. For event
forecasting, the supervised learning model fuses the results of different
models to increase the confidence. Finally, comprehensive experiments
demonstrate the high accuracy, efficiency, and reliability as compared to other
state-of-the-art machine learning methods.

    

### [[2111.02044] Categorical Difference and Related Brain Regions of the Attentional Blink Effect](http://arxiv.org/abs/2111.02044)


  Attentional blink (AB) is a biological effect, showing that for 200 to 500ms
after paying attention to one visual target, it is difficult to notice another
target that appears next, and attentional blink magnitude (ABM) is a indicating
parameter to measure the degree of this effect. Researchers have shown that
different categories of images can access the consciousness of human mind
differently, and produce different ranges of ABM values. So in this paper, we
compare two different types of images, categorized as animal and object, by
predicting ABM values directly from image features extracted from convolutional
neural network (CNN), and indirectly from functional magnetic resonance imaging
(fMRI) data. First, for two sets of images, we separately extract their average
features from layers of Alexnet, a classic model of CNN, then input the
features into a trained linear regression model to predict ABM values, and we
find higher-level instead of lower-level image features determine the
categorical difference in AB effect, and mid-level image features predict ABM
values more correctly than low-level and high-level image features. Then we
employ fMRI data from different brain regions collected when the subjects
viewed 50 test images to predict ABM values, and conclude that brain regions
covering relatively broader areas, like LVC, HVC and VC, perform better than
other smaller brain regions, which means AB effect is more related to synthetic
impact of several visual brain regions than only one particular visual regions.

    

### [[2111.02058] Rethinking the Image Feature Biases Exhibited by Deep CNN Models](http://arxiv.org/abs/2111.02058)


  In recent years, convolutional neural networks (CNNs) have been applied
successfully in many fields. However, such deep neural models are still
regarded as black box in most tasks. One of the fundamental issues underlying
this problem is understanding which features are most influential in image
recognition tasks and how they are processed by CNNs. It is widely accepted
that CNN models combine low-level features to form complex shapes until the
object can be readily classified, however, several recent studies have argued
that texture features are more important than other features. In this paper, we
assume that the importance of certain features varies depending on specific
tasks, i.e., specific tasks exhibit a feature bias. We designed two
classification tasks based on human intuition to train deep neural models to
identify anticipated biases. We devised experiments comprising many tasks to
test these biases for the ResNet and DenseNet models. From the results, we
conclude that (1) the combined effect of certain features is typically far more
influential than any single feature; (2) in different tasks, neural models can
perform different biases, that is, we can design a specific task to make a
neural model biased toward a specific anticipated feature.

    

### [[2111.02120] Lingua Custodia's participation at the WMT 2021 Machine Translation using Terminologies shared task](http://arxiv.org/abs/2111.02120)


  This paper describes Lingua Custodia's submission to the WMT21 shared task on
machine translation using terminologies. We consider three directions, namely
English to French, Russian, and Chinese. We rely on a Transformer-based
architecture as a building block, and we explore a method which introduces two
main changes to the standard procedure to handle terminologies. The first one
consists in augmenting the training data in such a way as to encourage the
model to learn a copy behavior when it encounters terminology constraint terms.
The second change is constraint token masking, whose purpose is to ease copy
behavior learning and to improve model generalization. Empirical results show
that our method satisfies most terminology constraints while maintaining high
translation quality.

    

### [[2111.02123] Marriage is a Peach and a Chalice: Modelling Cultural Symbolism on the SemanticWeb](http://arxiv.org/abs/2111.02123)


  In this work, we fill the gap in the Semantic Web in the context of Cultural
Symbolism. Building upon earlier work in, we introduce the Simulation Ontology,
an ontology that models the background knowledge of symbolic meanings,
developed by combining the concepts taken from the authoritative theory of
Simulacra and Simulations of Jean Baudrillard with symbolic structures and
content taken from "Symbolism: a Comprehensive Dictionary" by Steven Olderr. We
re-engineered the symbolic knowledge already present in heterogeneous resources
by converting it into our ontology schema to create HyperReal, the first
knowledge graph completely dedicated to cultural symbolism. A first experiment
run on the knowledge graph is presented to show the potential of quantitative
research on symbolism.

    

### [[2111.02167] Image-Guided Navigation of a Robotic Ultrasound Probe for Autonomous Spinal Sonography Using a Shadow-aware Dual-Agent Framework](http://arxiv.org/abs/2111.02167)


  Ultrasound (US) imaging is commonly used to assist in the diagnosis and
interventions of spine diseases, while the standardized US acquisitions
performed by manually operating the probe require substantial experience and
training of sonographers. In this work, we propose a novel dual-agent framework
that integrates a reinforcement learning (RL) agent and a deep learning (DL)
agent to jointly determine the movement of the US probe based on the real-time
US images, in order to mimic the decision-making process of an expert
sonographer to achieve autonomous standard view acquisitions in spinal
sonography. Moreover, inspired by the nature of US propagation and the
characteristics of the spinal anatomy, we introduce a view-specific acoustic
shadow reward to utilize the shadow information to implicitly guide the
navigation of the probe toward different standard views of the spine. Our
method is validated in both quantitative and qualitative experiments in a
simulation environment built with US data acquired from $17$ volunteers. The
average navigation accuracy toward different standard views achieves
$5.18mm/5.25^\circ$ and $12.87mm/17.49^\circ$ in the intra- and inter-subject
settings, respectively. The results demonstrate that our method can effectively
interpret the US images and navigate the probe to acquire multiple standard
views of the spine.

    

### [[2111.02194] Learning Implicit Sentiment in Aspect-based Sentiment Analysis with Supervised Contrastive Pre-Training](http://arxiv.org/abs/2111.02194)


  Aspect-based sentiment analysis aims to identify the sentiment polarity of a
specific aspect in product reviews. We notice that about 30% of reviews do not
contain obvious opinion words, but still convey clear human-aware sentiment
orientation, which is known as implicit sentiment. However, recent neural
network-based approaches paid little attention to implicit sentiment entailed
in the reviews. To overcome this issue, we adopt Supervised Contrastive
Pre-training on large-scale sentiment-annotated corpora retrieved from
in-domain language resources. By aligning the representation of implicit
sentiment expressions to those with the same sentiment label, the pre-training
process leads to better capture of both implicit and explicit sentiment
orientation towards aspects in reviews. Experimental results show that our
method achieves state-of-the-art performance on SemEval2014 benchmarks, and
comprehensive analysis validates its effectiveness on learning implicit
sentiment.

    

### [[2111.02244] Exploring Explainable AI in the Financial Sector: Perspectives of Banks and Supervisory Authorities](http://arxiv.org/abs/2111.02244)


  Explainable artificial intelligence (xAI) is seen as a solution to making AI
systems less of a black box. It is essential to ensure transparency, fairness,
and accountability, which are especially paramount in the financial sector. The
aim of this study was a preliminary investigation of the perspectives of
supervisory authorities and regulated entities regarding the application of xAI
in the fi-nancial sector. Three use cases (consumer credit, credit risk, and
anti-money laundering) were examined using semi-structured interviews at three
banks and two supervisory authorities in the Netherlands. We found that for the
investigated use cases a disparity exists between supervisory authorities and
banks regarding the desired scope of explainability of AI systems. We argue
that the financial sector could benefit from clear differentiation between
technical AI (model) ex-plainability requirements and explainability
requirements of the broader AI system in relation to applicable laws and
regulations.

    

### [[2111.02353] Graph Tree Memory Networks](http://arxiv.org/abs/2111.02353)


  We introduce Graph Tree Memory Networks that memorize and remember any data.
This neural network has two memories. One consists of a queue-structured
short-term memory to solve the class imbalance problem and long-term memory to
store the distribution of objects, introducing the contents of storing and
generating various datasets.

    

### [[2111.02364] HoneyCar: A Framework to Configure HoneypotVulnerabilities on the Internet of Vehicles](http://arxiv.org/abs/2111.02364)


  The Internet of Vehicles (IoV), whereby interconnected vehicles communicate
with each other and with road infrastructure on a common network, has promising
socio-economic benefits but also poses new cyber-physical threats. Data on
vehicular attackers can be realistically gathered through cyber threat
intelligence using systems like honeypots. Admittedly, configuring honeypots
introduces a trade-off between the level of honeypot-attacker interactions and
any incurred overheads and costs for implementing and monitoring these
honeypots. We argue that effective deception can be achieved through
strategically configuring the honeypots to represent components of the IoV and
engage attackers to collect cyber threat intelligence. In this paper, we
present HoneyCar, a novel decision support framework for honeypot deception in
IoV. HoneyCar builds upon a repository of known vulnerabilities of the
autonomous and connected vehicles found in the Common Vulnerabilities and
Exposure (CVE) data within the National Vulnerability Database (NVD) to compute
optimal honeypot configuration strategies. By taking a game-theoretic approach,
we model the adversarial interaction as a repeated imperfect-information
zero-sum game in which the IoV network administrator chooses a set of
vulnerabilities to offer in a honeypot and a strategic attacker chooses a
vulnerability of the IoV to exploit under uncertainty. Our investigation is
substantiated by examining two different versions of the game, with and without
the re-configuration cost to empower the network administrator to determine
optimal honeypot configurations. We evaluate HoneyCar in a realistic use case
to support decision makers with determining optimal honeypot configuration
strategies for strategic deployment in IoV.

    

### [[2012.06968] Multi-Interactive Attention Network for Fine-grained Feature Learning in CTR Prediction](http://arxiv.org/abs/2012.06968)


  In the Click-Through Rate (CTR) prediction scenario, user's sequential
behaviors are well utilized to capture the user interest in the recent
literature. However, despite being extensively studied, these sequential
methods still suffer from three limitations. First, existing methods mostly
utilize attention on the behavior of users, which is not always suitable for
CTR prediction, because users often click on new products that are irrelevant
to any historical behaviors. Second, in the real scenario, there exist numerous
users that have operations a long time ago, but turn relatively inactive in
recent times. Thus, it is hard to precisely capture user's current preferences
through early behaviors. Third, multiple representations of user's historical
behaviors in different feature subspaces are largely ignored. To remedy these
issues, we propose a Multi-Interactive Attention Network (MIAN) to
comprehensively extract the latent relationship among all kinds of fine-grained
features (e.g., gender, age and occupation in user-profile). Specifically, MIAN
contains a Multi-Interactive Layer (MIL) that integrates three local
interaction modules to capture multiple representations of user preference
through sequential behaviors and simultaneously utilize the fine-grained
user-specific as well as context information. In addition, we design a Global
Interaction Module (GIM) to learn the high-order interactions and balance the
different impacts of multiple features. Finally, Offline experiment results
from three datasets, together with an Online A/B test in a large-scale
recommendation system, demonstrate the effectiveness of our proposed approach.

    

### [[2106.04715] Measurable Monte Carlo Search Error Bounds](http://arxiv.org/abs/2106.04715)


  Monte Carlo planners can often return sub-optimal actions, even if they are
guaranteed to converge in the limit of infinite samples. Known asymptotic
regret bounds do not provide any way to measure confidence of a recommended
action at the conclusion of search. In this work, we prove bounds on the
sub-optimality of Monte Carlo estimates for non-stationary bandits and Markov
decision processes. These bounds can be directly computed at the conclusion of
the search and do not require knowledge of the true action-value. The presented
bound holds for general Monte Carlo solvers meeting mild convergence
conditions. We empirically test the tightness of the bounds through experiments
on a multi-armed bandit and a discrete Markov decision process for both a
simple solver and Monte Carlo tree search.

    

### [<title data-react-helmet="true">速收！来自港中文、港科大、杜克等高校的全奖PhD招生，你不试试吗？ - 知乎</title>](https://zhuanlan.zhihu.com/p/429313927)

### [<title>Distributed XGBoost training on multi-node and multi-GPU cluster - XGBoost</title>](https://discuss.xgboost.ai/t/distributed-xgboost-training-on-multi-node-and-multi-gpu-cluster/2523/2)

### [<title>Xgboost Booster vs future for DaskXGBRegressor.predict() - RFC - XGBoost</title>](https://discuss.xgboost.ai/t/xgboost-booster-vs-future-for-daskxgbregressor-predict/2516/3)

### [<title>How do you tell if a problem is caused by DNS?</title>](https://jvns.ca/blog/2021/11/04/how-do-you-tell-if-a-problem-is-caused-by-dns/)