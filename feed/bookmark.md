
## 2021-8-30

### [[2108.12161] SPARROW: A Novel Covert Communication Scheme Exploiting Broadcast Signals in LTE, 5G & Beyond](http://arxiv.org/abs/2108.12161)


  This work proposes a novel framework to identify and exploit vulnerable MAC
layer procedures in commercial wireless technologies for covert communication.
Examples of covert communication include data exfiltration, remote
command-and-control (CnC) and espionage. In this framework, the SPARROW schemes
use the broadcast power of incumbent wireless networks to covertly relay
messages across a long distance without connecting to them. This enables the
SPARROW schemes to bypass all security and lawful-intercept systems and gain
ample advantage over existing covert techniques in terms of maximum anonymity,
more miles per Watts and less hardware. The SPARROW schemes can also serve as
an efficient solution for long-range M2M applications. This paper details one
recently disclosed vulnerability (CVD-2021-0045 in GSMA coordinated
vulnerability disclosure program) in the common random-access procedure in the
LTE and 5G standards This work also proposes a rigorous remediation for similar
access procedures in current and future standards that disrupts the most
sophisticated SPARROW schemes with minimal impact on other users.

    

### [[2108.12198] Deep Reinforcement Learning for Wireless Resource Allocation Using Buffer State Information](http://arxiv.org/abs/2108.12198)


  As the number of user equipments (UEs) with various data rate and latency
requirements increases in wireless networks, the resource allocation problem
for orthogonal frequency-division multiple access (OFDMA) becomes challenging.
In particular, varying requirements lead to a non-convex optimization problem
when maximizing the systems data rate while preserving fairness between UEs. In
this paper, we solve the non-convex optimization problem using deep
reinforcement learning (DRL). We outline, train and evaluate a DRL agent, which
performs the task of media access control scheduling for a downlink OFDMA
scenario. To kickstart training of our agent, we introduce mimicking learning.
For improvement of scheduling performance, full buffer state information at the
base station (e.g. packet age, packet size) is taken into account. Techniques
like input feature compression, packet shuffling and age capping further
improve the performance of the agent. We train and evaluate our agents using
Nokia's wireless suite and evaluate against different benchmark agents. We show
that our agents clearly outperform the benchmark agents.

    

### [[2108.12418] Group Testing with Non-identical Infection Probabilities](http://arxiv.org/abs/2108.12418)


  We consider a zero-error probabilistic group testing problem where
individuals are defective independently but not with identical probabilities.
We propose a greedy set formation method to build sets of individuals to be
tested together. We develop an adaptive group testing algorithm that uses the
proposed set formation method recursively. We prove novel upper bounds on the
number of tests for the proposed algorithm. Via numerical results, we show that
our algorithm outperforms the state of the art, and performs close to the
entropy lower bound.

    

### [[1805.08357] Multi-UAV Trajectory Cooperation for Servicing Dynamic Demands and Charging Battery](http://arxiv.org/abs/1805.08357)


  Unmanned Aerial Vehicle (UAV) technology is a promising solution for
providing high-quality mobile services to ground users, where a UAV with
limited service coverage travels among multiple geographical user locations
(e.g., hotspots) for servicing their demands locally. How to dynamically
determine a UAV swarm's cooperative path planning to best meet many users'
spatio-temporally distributed demands is an important question but is
unaddressed in the literature. To our best knowledge, this paper is the first
to design and analyze cooperative path planning algorithms of a large UAV swarm
for optimally servicing many spatial locations, where ground users' demands are
released dynamically in the long time horizon. Regarding a single UAV's path
planning design, we manage to substantially simplify the traditional dynamic
program and propose an optimal algorithm of low computation complexity, which
is only polynomial with respect to both the numbers of spatial locations and
user demands. After coordinating a large number $K$ of UAVs, this simplified
dynamic optimization problem becomes intractable and we alternatively present a
fast iterative cooperation algorithm with provable approximation ratio
$1-(1-\frac{1}{K})^{K}$ in the worst case, which is proved to obviously
outperform the traditional approach of partitioning UAVs to serve different
location clusters separately. To relax UAVs' battery capacity limit for
sustainable service provisioning, we further allow UAVs to travel to charging
stations in the mean time and thus jointly design UAVs' path planning over
users' locations and charging stations. Despite of the problem difficulty, for
the optimal solution, we successfully transform the problem to an integer
linear program by creating novel directed acyclic graph of the UAV-state
transition diagram, and propose an iterative algorithm with constant
approximation ratio.

    

### [[2108.11959] Finite-time System Identification and Adaptive Control in Autoregressive Exogenous Systems](http://arxiv.org/abs/2108.11959)


  Autoregressive exogenous (ARX) systems are the general class of input-output
dynamical systems used for modeling stochastic linear dynamical systems (LDS)
including partially observable LDS such as LQG systems. In this work, we study
the problem of system identification and adaptive control of unknown ARX
systems. We provide finite-time learning guarantees for the ARX systems under
both open-loop and closed-loop data collection. Using these guarantees, we
design adaptive control algorithms for unknown ARX systems with arbitrary
strongly convex or convex quadratic regulating costs. Under strongly convex
cost functions, we design an adaptive control algorithm based on online
gradient descent to design and update the controllers that are constructed via
a convex controller reparametrization. We show that our algorithm has
$\tilde{\mathcal{O}}(\sqrt{T})$ regret via explore and commit approach and if
the model estimates are updated in epochs using closed-loop data collection, it
attains the optimal regret of $\text{polylog}(T)$ after $T$ time-steps of
interaction. For the case of convex quadratic cost functions, we propose an
adaptive control algorithm that deploys the optimism in the face of uncertainty
principle to design the controller. In this setting, we show that the explore
and commit approach has a regret upper bound of $\tilde{\mathcal{O}}(T^{2/3})$,
and the adaptive control with continuous model estimate updates attains
$\tilde{\mathcal{O}}(\sqrt{T})$ regret after $T$ time-steps.

    

### [[2108.11976] JUWELS Booster -- A Supercomputer for Large-Scale AI Research](http://arxiv.org/abs/2108.11976)


  In this article, we present JUWELS Booster, a recently commissioned
high-performance computing system at the JÃ¼lich Supercomputing Center. With
its system architecture, most importantly its large number of powerful Graphics
Processing Units (GPUs) and its fast interconnect via InfiniBand, it is an
ideal machine for large-scale Artificial Intelligence (AI) research and
applications. We detail its system architecture, parallel, distributed model
training, and benchmarks indicating its outstanding performance. We exemplify
its potential for research application by presenting large-scale AI research
highlights from various scientific fields that require such a facility.

    

### [[2108.11979] Resource allocation method using tug-of-war-based synchronization](http://arxiv.org/abs/2108.11979)


  We propose a simple channel-allocation method based on tug-of-war (TOW)
dynamics, combined with the time scheduling based on nonlinear oscillator
synchronization to efficiently use of the space (channel) and time resources in
wireless communications. This study demonstrates that synchronization groups,
where each node selects a different channel, are non-uniformly distributed in
phase space such that every distance between groups is larger than the area of
influence. New type of self-organized spatiotemporal patterns can be formed for
resource allocation according to channel rewards.

    

### [[2108.11981] Classification of Emotions and Evaluation of Customer Satisfaction from Speech in Real World Acoustic Environments](http://arxiv.org/abs/2108.11981)


  This paper focuses on finding suitable features to robustly recognize
emotions and evaluate customer satisfaction from speech in real acoustic
scenarios. The classification of emotions is based on standard and well-known
corpora and the evaluation of customer satisfaction is based on recordings of
real opinions given by customers about the received service during phone calls
with call-center agents. The feature sets considered in this study include two
speaker models, namely x-vectors and i-vectors, and also the well known feature
set introduced in the Interspeech 2010 Paralinguistics Challenge (I2010PC).
Additionally, we introduce the use of phonation, articulation and prosody
features extracted with the DisVoice framework as alternative feature sets to
robustly model emotions and customer satisfaction from speech. The results
indicate that the I2010PC feature set is the best approach to classify emotions
in the standard databases typically used in the literature. When considering
the recordings collected in the call-center, without any control over the
acoustic conditions, the best results are obtained with our articulation
features. The I2010PC feature set includes 1584 measures while the articulation
approach only includes 488 measures. We think that the proposed approach is
more suitable for real-world applications where the acoustic conditions are not
controlled and also it is potentially more convenient for industrial
applications.

    

### [[2108.11985] Simulating progressive intramural damage leading to aortic dissection using an operator-regression neural network](http://arxiv.org/abs/2108.11985)


  Aortic dissection progresses via delamination of the medial layer of the
wall. Notwithstanding the complexity of this process, insight has been gleaned
by studying in vitro and in silico the progression of dissection driven by
quasi-static pressurization of the intramural space by fluid injection, which
demonstrates that the differential propensity of dissection can be affected by
spatial distributions of structurally significant interlamellar struts that
connect adjacent elastic lamellae. In particular, diverse histological
microstructures may lead to differential mechanical behavior during dissection,
including the pressure--volume relationship of the injected fluid and the
displacement field between adjacent lamellae. In this study, we develop a
data-driven surrogate model for the delamination process for differential strut
distributions using DeepONet, a new operator--regression neural network. The
surrogate model is trained to predict the pressure--volume curve of the
injected fluid and the damage progression field of the wall given a spatial
distribution of struts, with in silico data generated with a phase-field finite
element model. The results show that DeepONet can provide accurate predictions
for diverse strut distributions, indicating that this composite branch-trunk
neural network can effectively extract the underlying functional relationship
between distinctive microstructures and their mechanical properties. More
broadly, DeepONet can facilitate surrogate model-based analyses to quantify
biological variability, improve inverse design, and predict mechanical
properties based on multi-modality experimental data.

    

### [[2108.11986] Anomaly Detection in Medical Imaging -- A Mini Review](http://arxiv.org/abs/2108.11986)


  The increasing digitization of medical imaging enables machine learning based
improvements in detecting, visualizing and segmenting lesions, easing the
workload for medical experts. However, supervised machine learning requires
reliable labelled data, which is is often difficult or impossible to collect or
at least time consuming and thereby costly. Therefore methods requiring only
partly labeled data (semi-supervised) or no labeling at all (unsupervised
methods) have been applied more regularly. Anomaly detection is one possible
methodology that is able to leverage semi-supervised and unsupervised methods
to handle medical imaging tasks like classification and segmentation. This
paper uses a semi-exhaustive literature review of relevant anomaly detection
papers in medical imaging to cluster into applications, highlight important
results, establish lessons learned and give further advice on how to approach
anomaly detection in medical imaging. The qualitative analysis is based on
google scholar and 4 different search terms, resulting in 120 different
analysed papers. The main results showed that the current research is mostly
motivated by reducing the need for labelled data. Also, the successful and
substantial amount of research in the brain MRI domain shows the potential for
applications in further domains like OCT and chest X-ray.

    

### [[2108.12001] Understanding the Logit Distributions of Adversarially-Trained Deep Neural Networks](http://arxiv.org/abs/2108.12001)


  Adversarial defenses train deep neural networks to be invariant to the input
perturbations from adversarial attacks. Almost all defense strategies achieve
this invariance through adversarial training i.e. training on inputs with
adversarial perturbations. Although adversarial training is successful at
mitigating adversarial attacks, the behavioral differences between
adversarially-trained (AT) models and standard models are still poorly
understood. Motivated by a recent study on learning robustness without input
perturbations by distilling an AT model, we explore what is learned during
adversarial training by analyzing the distribution of logits in AT models. We
identify three logit characteristics essential to learning adversarial
robustness. First, we provide a theoretical justification for the finding that
adversarial training shrinks two important characteristics of the logit
distribution: the max logit values and the "logit gaps" (difference between the
logit max and next largest values) are on average lower for AT models. Second,
we show that AT and standard models differ significantly on which samples are
high or low confidence, then illustrate clear qualitative differences by
visualizing samples with the largest confidence difference. Finally, we find
learning information about incorrect classes to be essential to learning
robustness by manipulating the non-max logit information during distillation
and measuring the impact on the student's robustness. Our results indicate that
learning some adversarial robustness without input perturbations requires a
model to learn specific sample-wise confidences and incorrect class orderings
that follow complex distributions.

    

### [[2108.12006] When and how epochwise double descent happens](http://arxiv.org/abs/2108.12006)


  Deep neural networks are known to exhibit a `double descent' behavior as the
number of parameters increases. Recently, it has also been shown that an
`epochwise double descent' effect exists in which the generalization error
initially drops, then rises, and finally drops again with increasing training
time. This presents a practical problem in that the amount of time required for
training is long, and early stopping based on validation performance may result
in suboptimal generalization. In this work we develop an analytically tractable
model of epochwise double descent that allows us to characterise theoretically
when this effect is likely to occur. This model is based on the hypothesis that
the training data contains features that are slow to learn but informative. We
then show experimentally that deep neural networks behave similarly to our
theoretical model. Our findings indicate that epochwise double descent requires
a critical amount of noise to occur, but above a second critical noise level
early stopping remains effective. Using insights from theory, we give two
methods by which epochwise double descent can be removed: one that removes slow
to learn features from the input and reduces generalization performance, and
another that instead modifies the training dynamics and matches or exceeds the
generalization performance of standard training. Taken together, our results
suggest a new picture of how epochwise double descent emerges from the
interplay between the dynamics of training and noise in the training data.

    

### [[2108.12016] DeepFlow: Abnormal Traffic Flow Detection Using Siamese Networks](http://arxiv.org/abs/2108.12016)


  Nowadays, many cities are equipped with surveillance systems and traffic
control centers to monitor vehicular traffic for road safety and efficiency.
The monitoring process is mostly done manually which is inefficient and
expensive. In recent years, several data-driven solutions have been proposed in
the literature to automatically analyze traffic flow data using machine
learning techniques. However, existing solutions require large and
comprehensive datasets for training which are not readily available, thus
limiting their application. In this paper, we develop a traffic anomaly
detection system, referred to as DeepFlow, based on Siamese neural networks,
which are suitable in scenarios where only small datasets are available for
training. Our model can detect abnormal traffic flows by analyzing the
trajectory data collected from the vehicles in a fleet. To evaluate DeepFlow,
we use realistic vehicular traffic simulations in SUMO. Our results show that
DeepFlow detects abnormal traffic patterns with an F1 score of 78%, while
outperforming other existing approaches including: Dynamic Time Warping (DTW),
Global Alignment Kernels (GAK), and iForest.

    

### [[2108.12055] Towards Self-Explainable Graph Neural Network](http://arxiv.org/abs/2108.12055)


  Graph Neural Networks (GNNs), which generalize the deep neural networks to
graph-structured data, have achieved great success in modeling graphs. However,
as an extension of deep learning for graphs, GNNs lack explainability, which
largely limits their adoption in scenarios that demand the transparency of
models. Though many efforts are taken to improve the explainability of deep
learning, they mainly focus on i.i.d data, which cannot be directly applied to
explain the predictions of GNNs because GNNs utilize both node features and
graph topology to make predictions. There are only very few work on the
explainability of GNNs and they focus on post-hoc explanations. Since post-hoc
explanations are not directly obtained from the GNNs, they can be biased and
misrepresent the true explanations. Therefore, in this paper, we study a novel
problem of self-explainable GNNs which can simultaneously give predictions and
explanations. We propose a new framework which can find $K$-nearest labeled
nodes for each unlabeled node to give explainable node classification, where
nearest labeled nodes are found by interpretable similarity module in terms of
both node similarity and local structure similarity. Extensive experiments on
real-world and synthetic datasets demonstrate the effectiveness of the proposed
framework for explainable node classification.

    

### [[2108.12056] Continual learning under domain transfer with sparse synaptic bursting](http://arxiv.org/abs/2108.12056)


  Existing machines are functionally specific tools that were made for easy
prediction and control. Tomorrow's machines may be closer to biological systems
in their mutability, resilience, and autonomy. But first they must be capable
of learning, and retaining, new information without repeated exposure to it.
Past efforts to engineer such systems have sought to build or regulate
artificial neural networks using task-specific modules with constrained
circumstances of application. This has not yet enabled continual learning over
long sequences of previously unseen data without corrupting existing knowledge:
a problem known as catastrophic forgetting. In this paper, we introduce a
system that can learn sequentially over previously unseen datasets (ImageNet,
CIFAR-100) with little forgetting over time. This is accomplished by regulating
the activity of weights in a convolutional neural network on the basis of
inputs using top-down modulation generated by a second feed-forward neural
network. We find that our method learns continually under domain transfer with
sparse bursts of activity in weights that are recycled across tasks, rather
than by maintaining task-specific modules. Sparse synaptic bursting is found to
balance enhanced and diminished activity in a way that facilitates adaptation
to new inputs without corrupting previously acquired functions. This behavior
emerges during a prior meta-learning phase in which regulated synapses are
selectively disinhibited, or grown, from an initial state of uniform
suppression.

    

### [[2108.12061] Using GAN-based models to sentimental analysis on imbalanced datasets in education domain](http://arxiv.org/abs/2108.12061)


  While the whole world is still struggling with the COVID-19 pandemic, online
learning and home office become more common. Many schools transfer their
courses teaching to the online classroom. Therefore, it is significant to mine
the students' feedback and opinions from their reviews towards studies so that
both schools and teachers can know where they need to improve. This paper
trains machine learning and deep learning models using both balanced and
imbalanced datasets for sentiment classification. Two SOTA category-aware text
generation GAN models: CatGAN and SentiGAN, are utilized to synthesize text
used to balance the highly imbalanced dataset. Results on three datasets with
different imbalance degree from distinct domains show that when using generated
text to balance the dataset, the F1-score of machine learning and deep learning
model on sentiment classification increases 2.79% ~ 9.28%. Also, the results
indicate that the average growth degree for CR100k is higher than CR23k, the
average growth degree for deep learning is more increased than machine learning
algorithms, and the average growth degree for more complex deep learning models
is more increased than simpler deep learning models in experiments.

    

### [[2108.12068] An Automatic Image Content Retrieval Method for better Mobile Device Display User Experiences](http://arxiv.org/abs/2108.12068)


  A growing number of commercially available mobile phones come with integrated
high-resolution digital cameras. That enables a new class of dedicated
applications to image analysis such as mobile visual search, image cropping,
object detection, content-based image retrieval, image classification. In this
paper, a new mobile application for image content retrieval and classification
for mobile device display is proposed to enrich the visual experience of users.
The mobile application can extract a certain number of images based on the
content of an image with visual saliency methods aiming at detecting the most
critical regions in a given image from a perceptual viewpoint. First, the most
critical areas from a perceptual perspective are extracted using the local
maxima of a 2D saliency function. Next, a salient region is cropped using the
bounding box centred on the local maxima of the thresholded Saliency Map of the
image. Then, each image crop feds into an Image Classification system based on
SVM and SIFT descriptors to detect the class of object present in the image.
ImageNet repository was used as the reference for semantic category
classification. Android platform was used to implement the mobile application
on a client-server architecture. A mobile client sends the photo taken by the
camera to the server, which processes the image and returns the results (image
contents such as image crops and related target classes) to the mobile client.
The application was run on thousands of pictures and showed encouraging results
towards a better user visual experience with mobile displays.

    

### [[2108.12074] 4-bit Quantization of LSTM-based Speech Recognition Models](http://arxiv.org/abs/2108.12074)


  We investigate the impact of aggressive low-precision representations of
weights and activations in two families of large LSTM-based architectures for
Automatic Speech Recognition (ASR): hybrid Deep Bidirectional LSTM - Hidden
Markov Models (DBLSTM-HMMs) and Recurrent Neural Network - Transducers
(RNN-Ts). Using a 4-bit integer representation, a naÃ¯ve quantization approach
applied to the LSTM portion of these models results in significant Word Error
Rate (WER) degradation. On the other hand, we show that minimal accuracy loss
is achievable with an appropriate choice of quantizers and initializations. In
particular, we customize quantization schemes depending on the local properties
of the network, improving recognition performance while limiting computational
time. We demonstrate our solution on the Switchboard (SWB) and CallHome (CH)
test sets of the NIST Hub5-2000 evaluation. DBLSTM-HMMs trained with 300 or
2000 hours of SWB data achieves $<$0.5% and $<$1% average WER degradation,
respectively. On the more challenging RNN-T models, our quantization strategy
limits degradation in 4-bit inference to 1.3%.

    

### [[2108.12084] Harms of Gender Exclusivity and Challenges in Non-Binary Representation in Language Technologies](http://arxiv.org/abs/2108.12084)


  Gender is widely discussed in the context of language tasks and when
examining the stereotypes propagated by language models. However, current
discussions primarily treat gender as binary, which can perpetuate harms such
as the cyclical erasure of non-binary gender identities. These harms are driven
by model and dataset biases, which are consequences of the non-recognition and
lack of understanding of non-binary genders in society. In this paper, we
explain the complexity of gender and language around it, and survey non-binary
persons to understand harms associated with the treatment of gender as binary
in English language technologies. We also detail how current language
representations (e.g., GloVe, BERT) capture and perpetuate these harms and
related challenges that need to be acknowledged and addressed for
representations to equitably encode gender information.

    

### [[2108.12093] Anomaly Detection on IT Operation Series via Online Matrix Profile](http://arxiv.org/abs/2108.12093)


  Anomaly detection on time series is a fundamental task in monitoring the Key
Performance Indicators (KPIs) of IT systems. The existing approaches in the
literature either require a lot of training resources or are hard to be
deployed in real scenarios. In this paper, the online matrix profile, which
requires no training, is proposed to address this issue. The anomalies are
detected by referring to the past subsequence that is the closest to the
current one. The distance significance is introduced based on the online matrix
profile, which demonstrates a prominent pattern when an anomaly occurs. Another
training-free approach spectral residual is integrated into our approach to
further enhance the detection accuracy. Moreover, the proposed approach is sped
up by at least four times for long time series by the introduced cache
strategy. In comparison to the existing approaches, the online matrix profile
makes a good trade-off between accuracy and efficiency. More importantly, it is
generic to various types of time series in the sense that it works without the
constraint from any trained model.

    

### [[2108.12099] Learning to Give Checkable Answers with Prover-Verifier Games](http://arxiv.org/abs/2108.12099)


  Our ability to know when to trust the decisions made by machine learning
systems has not kept up with the staggering improvements in their performance,
limiting their applicability in high-stakes domains. We introduce
Prover-Verifier Games (PVGs), a game-theoretic framework to encourage learning
agents to solve decision problems in a verifiable manner. The PVG consists of
two learners with competing objectives: a trusted verifier network tries to
choose the correct answer, and a more powerful but untrusted prover network
attempts to persuade the verifier of a particular answer, regardless of its
correctness. The goal is for a reliable justification protocol to emerge from
this game. We analyze variants of the framework, including simultaneous and
sequential games, and narrow the space down to a subset of games which provably
have the desired equilibria. We develop instantiations of the PVG for two
algorithmic tasks, and show that in practice, the verifier learns a robust
decision rule that is able to receive useful and reliable information from an
untrusted prover. Importantly, the protocol still works even when the verifier
is frozen and the prover's messages are directly optimized to convince the
verifier.

    

### [[2108.12100] A framework for massive scale personalized promotion](http://arxiv.org/abs/2108.12100)


  Technology companies building consumer-facing platforms may have access to
massive-scale user population. In recent years, promotion with quantifiable
incentive has become a popular approach for increasing active users on such
platforms. On one hand, increased user activities can introduce network effect,
bring in advertisement audience, and produce other benefits. On the other hand,
massive-scale promotion causes massive cost. Therefore making promotion
campaigns efficient in terms of return-on-investment (ROI) is of great interest
to many companies.
This paper proposes a practical two-stage framework that can optimize the ROI
of various massive-scale promotion campaigns. In the first stage, users'
personal promotion-response curves are modeled by machine learning techniques.
In the second stage, business objectives and resource constraints are
formulated into an optimization problem, the decision variables of which are
how much incentive to give to each user. In order to do effective optimization
in the second stage, counterfactual prediction and noise-reduction are
essential for the first stage. We leverage existing counterfactual prediction
techniques to correct treatment bias in data. We also introduce a novel deep
neural network (DNN) architecture, the deep-isotonic-promotion-network (DIPN),
to reduce noise in the promotion response curves. The DIPN architecture
incorporates our prior knowledge of response curve shape, by enforcing
isotonicity and smoothness. It out-performed regular DNN and other
state-of-the-art shape-constrained models in our experiments.

    

### [[2108.12105] Full Attention Bidirectional Deep Learning Structure for Single Channel Speech Enhancement](http://arxiv.org/abs/2108.12105)


  As the cornerstone of other important technologies, such as speech
recognition and speech synthesis, speech enhancement is a critical area in
audio signal processing. In this paper, a new deep learning structure for
speech enhancement is demonstrated. The model introduces a "full" attention
mechanism to a bidirectional sequence-to-sequence method to make use of latent
information after each focal frame. This is an extension of the previous
attention-based RNN method. The proposed bidirectional attention-based
architecture achieves better performance in terms of speech quality (PESQ),
compared with OM-LSA, CNN-LSTM, T-GSA and the unidirectional attention-based
LSTM baseline.

    

### [[2108.12107] An Introduction to Hamiltonian Monte Carlo Method for Sampling](http://arxiv.org/abs/2108.12107)


  The goal of this article is to introduce the Hamiltonian Monte Carlo (HMC)
method -- a Hamiltonian dynamics-inspired algorithm for sampling from a Gibbs
density $\pi(x) \propto e^{-f(x)}$. We focus on the "idealized" case, where one
can compute continuous trajectories exactly. We show that idealized HMC
preserves $\pi$ and we establish its convergence when $f$ is strongly convex
and smooth.

    

### [[2108.12112] Targeting Underrepresented Populations in Precision Medicine: A Federated Transfer Learning Approach](http://arxiv.org/abs/2108.12112)


  The limited representation of minorities and disadvantaged populations in
large-scale clinical and genomics research has become a barrier to translating
precision medicine research into practice. Due to heterogeneity across
populations, risk prediction models are often found to be underperformed in
these underrepresented populations, and therefore may further exacerbate known
health disparities. In this paper, we propose a two-way data integration
strategy that integrates heterogeneous data from diverse populations and from
multiple healthcare institutions via a federated transfer learning approach.
The proposed method can handle the challenging setting where sample sizes from
different populations are highly unbalanced. With only a small number of
communications across participating sites, the proposed method can achieve
performance comparable to the pooled analysis where individual-level data are
directly pooled together. We show that the proposed method improves the
estimation and prediction accuracy in underrepresented populations, and reduces
the gap of model performance across populations. Our theoretical analysis
reveals how estimation accuracy is influenced by communication budgets, privacy
restrictions, and heterogeneity across populations. We demonstrate the
feasibility and validity of our methods through numerical experiments and a
real application to a multi-center study, in which we construct polygenic risk
prediction models for Type II diabetes in AA population.

    

### [[2108.12113] Subjective Learning for Open-Ended Data](http://arxiv.org/abs/2108.12113)


  Conventional machine learning methods typically assume that data is split
according to tasks, and the data in each task can be modeled by a single target
function. However, this assumption is invalid in open-ended environments where
no manual task definition is available. In this paper, we present a novel
supervised learning paradigm of learning from open-ended data. Open-ended data
inherently requires multiple single-valued deterministic mapping functions to
capture all its input-output relations, exhibiting an essential structural
difference from conventional supervised data. We formally expound this
structural property with a novel concept termed as mapping rank, and show that
open-ended data poses a fundamental difficulty for conventional supervised
learning, since different data samples may conflict with each other if the
mapping rank of data is larger than one. To address this issue, we devise an
Open-ended Supervised Learning (OSL) framework, of which the key innovation is
a subjective function that automatically allocates the data among multiple
candidate models to resolve the conflict, developing a natural cognition
hierarchy. We demonstrate the efficacy of OSL both theoretically and
empirically, and show that OSL achieves human-like task cognition without
task-level supervision.

    

### [[2108.12114] Identification of Vehicle Dynamics Parameters Using Simulation-based Inference](http://arxiv.org/abs/2108.12114)


  Identifying tire and vehicle parameters is an essential step in designing
control and planning algorithms for autonomous vehicles. This paper proposes a
new method: Simulation-Based Inference (SBI), a modern interpretation of
Approximate Bayesian Computation methods (ABC) for parameter identification.
The simulation-based inference is an emerging method in the machine learning
literature and has proven to yield accurate results for many parameter sets in
complex problems. We demonstrate in this paper that it can handle the
identification of highly nonlinear vehicle dynamics parameters and gives
accurate estimates of the parameters for the governing equations.

    

### [[2108.12118] Densely-Populated Traffic Detection using YOLOv5 and Non-Maximum Suppression Ensembling](http://arxiv.org/abs/2108.12118)


  Vehicular object detection is the heart of any intelligent traffic system. It
is essential for urban traffic management. R-CNN, Fast R-CNN, Faster R-CNN and
YOLO were some of the earlier state-of-the-art models. Region based CNN methods
have the problem of higher inference time which makes it unrealistic to use the
model in real-time. YOLO on the other hand struggles to detect small objects
that appear in groups. In this paper, we propose a method that can locate and
classify vehicular objects from a given densely crowded image using YOLOv5. The
shortcoming of YOLO was solved my ensembling 4 different models. Our proposed
model performs well on images taken from both top view and side view of the
street in both day and night. The performance of our proposed model was
measured on Dhaka AI dataset which contains densely crowded vehicular images.
Our experiment shows that our model achieved mAP@0.5 of 0.458 with inference
time of 0.75 sec which outperforms other state-of-the-art models on
performance. Hence, the model can be implemented in the street for real-time
traffic detection which can be used for traffic control and data collection.

    

### [[2108.12121] Reinforcement Learning-powered Semantic Communication via Semantic Similarity](http://arxiv.org/abs/2108.12121)


  We introduce a new semantic communication mechanism, whose key idea is to
preserve the semantic information instead of strictly securing the bit-level
precision. Starting by analyzing the defects of existing joint source channel
coding (JSCC) methods, we show that the commonly used bit-level metrics are
vulnerable of catching important semantic meaning and structures. To address
this problem, we take advantage of learning from semantic similarity, instead
of relying on conventional paired bit-level supervisions like cross entropy and
bit error rate. However, to develop such a semantic communication system is
indeed a nontrivial task, considering the nondifferentiability of most semantic
metrics as well as the instability from noisy channels. To further resolve
these issues, we put forward a reinforcement learning (RL)-based solution which
allows us to simultaneously optimize any user-defined semantic measurement by
using the policy gradient technique, and to interact with the surrounding noisy
environment in a natural way. We have testified the proposed method in the
challenging European-parliament dataset. Experiments on both AWGN and
phase-invariant fading channel have confirmed the superiority of our method in
revealing the semantic meanings, and better handling the channel noise
especially in low-SNR situations. Apart from the experimental results, we
further provide an indepth look at how the semantics model behaves, along with
its superb generalization ability in real-life examples. As a brand new method
in learning-based JSCC tasks, we also exemplify an RL-based image transmission
paradigm, both to prove the generalization ability, and to leave this new topic
for future discussion.

    

### [[2108.12124] Canoe : A System for Collaborative Learning for Neural Nets](http://arxiv.org/abs/2108.12124)


  For highly distributed environments such as edge computing, collaborative
learning approaches eschew the dependence on a global, shared model, in favor
of models tailored for each location. Creating tailored models for individual
learning contexts reduces the amount of data transfer, while collaboration
among peers provides acceptable model performance. Collaboration assumes,
however, the availability of knowledge transfer mechanisms, which are not
trivial for deep learning models where knowledge isn't easily attributed to
precise model slices. We present Canoe - a framework that facilitates knowledge
transfer for neural networks. Canoe provides new system support for dynamically
extracting significant parameters from a helper node's neural network and uses
this with a multi-model boosting-based approach to improve the predictive
performance of the target node. The evaluation of Canoe with different PyTorch
and TensorFlow neural network models demonstrates that the knowledge transfer
mechanism improves the model's adaptiveness to changes up to 3.5X compared to
learning in isolation, while affording several magnitudes reduction in data
movement costs compared to federated learning.

    

### [[2108.12129] Parallel Machine Learning for Forecasting the Dynamics of Complex Networks](http://arxiv.org/abs/2108.12129)


  Forecasting the dynamics of large complex networks from previous time-series
data is important in a wide range of contexts. Here we present a machine
learning scheme for this task using a parallel architecture that mimics the
topology of the network of interest. We demonstrate the utility and scalability
of our method implemented using reservoir computing on a chaotic network of
oscillators. Two levels of prior knowledge are considered: (i) the network
links are known; and (ii) the network links are unknown and inferred via a
data-driven approach to approximately optimize prediction.

    

### [[2108.12156] Improving callsign recognition with air-surveillance data in air-traffic communication](http://arxiv.org/abs/2108.12156)


  Automatic Speech Recognition (ASR) can be used as the assistance of speech
communication between pilots and air-traffic controllers. Its application can
significantly reduce the complexity of the task and increase the reliability of
transmitted information. Evidently, high accuracy predictions are needed to
minimize the risk of errors. Especially, high accuracy is required in
recognition of key information, such as commands and callsigns, used to
navigate pilots. Our results prove that the surveillance data containing
callsigns can help to considerably improve the recognition of a callsign in an
utterance when the weights of probable callsign n-grams are reduced per
utterance. In this paper, we investigate two approaches: (1) G-boosting, when
callsigns weights are adjusted at language model level (G) and followed by the
dynamic decoder with an on-the-fly composition, and (2) lattice rescoring when
callsign information is introduced on top of lattices generated using a
conventional decoder. Boosting callsign n-grams with the combination of two
methods allowed us to gain 28.4% of absolute improvement in callsign
recognition accuracy and up to 74.2% of relative improvement in WER of callsign
recognition.

    

### [[2108.12159] Anomaly Detection of Defect using Energy of Point Pattern Features within Random Finite Set Framework](http://arxiv.org/abs/2108.12159)


  In this paper, we propose an efficient approach for industrial defect
detection that is modeled based on anomaly detection using point pattern data.
Most recent works use \textit{global features} for feature extraction to
summarize image content. However, global features are not robust against
lighting and viewpoint changes and do not describe the image's geometrical
information to be fully utilized in the manufacturing industry. To the best of
our knowledge, we are the first to propose using transfer learning of
local/point pattern features to overcome these limitations and capture
geometrical information of the image regions. We model these local/point
pattern features as a random finite set (RFS). In addition we propose RFS
energy, in contrast to RFS likelihood as anomaly score. The similarity
distribution of point pattern features of the normal sample has been modeled as
a multivariate Gaussian. Parameters learning of the proposed RFS energy does
not require any heavy computation. We evaluate the proposed approach on the
MVTec AD dataset, a multi-object defect detection dataset. Experimental results
show the outstanding performance of our proposed approach compared to the
state-of-the-art methods, and the proposed RFS energy outperforms the
state-of-the-art in the few shot learning settings.

    

### [[2108.12163] Provable Tensor-Train Format Tensor Completion by Riemannian Optimization](http://arxiv.org/abs/2108.12163)


  The tensor train (TT) format enjoys appealing advantages in handling
structural high-order tensors. The recent decade has witnessed the wide
applications of TT-format tensors from diverse disciplines, among which tensor
completion has drawn considerable attention. Numerous fast algorithms,
including the Riemannian gradient descent (RGrad) algorithm, have been proposed
for the TT-format tensor completion. However, the theoretical guarantees of
these algorithms are largely missing or sub-optimal, partly due to the
complicated and recursive algebraic operations in TT-format decomposition.
Moreover, existing results established for the tensors of other formats, for
example, Tucker and CP, are inapplicable because the algorithms treating
TT-format tensors are substantially different and more involved. In this paper,
we provide, to our best knowledge, the first theoretical guarantees of the
convergence of RGrad algorithm for TT-format tensor completion, under a nearly
optimal sample size condition. The RGrad algorithm converges linearly with a
constant contraction rate that is free of tensor condition number without the
necessity of re-conditioning. We also propose a novel approach, referred to as
the sequential second-order moment method, to attain a warm initialization
under a similar sample size requirement. As a byproduct, our result even
significantly refines the prior investigation of RGrad algorithm for matrix
completion. Numerical experiments confirm our theoretical discovery and
showcase the computational speedup gained by the TT-format decomposition.

    

### [[2108.12165] LassoLayer: Nonlinear Feature Selection by Switching One-to-one Links](http://arxiv.org/abs/2108.12165)


  Along with the desire to address more complex problems, feature selection
methods have gained in importance. Feature selection methods can be classified
into wrapper method, filter method, and embedded method. Being a powerful
embedded feature selection method, Lasso has attracted the attention of many
researchers. However, as a linear approach, the applicability of Lasso has been
limited. In this work, we propose LassoLayer that is one-to-one connected and
trained by L1 optimization, which work to drop out unnecessary units for
prediction. For nonlinear feature selections, we build LassoMLP: the network
equipped with LassoLayer as its first layer. Because we can insert LassoLayer
in any network structure, it can harness the strength of neural network
suitable for tasks where feature selection is needed. We evaluate LassoMLP in
feature selection with regression and classification tasks. LassoMLP receives
features including considerable numbers of noisy factors that is harmful for
overfitting. In the experiments using MNIST dataset, we confirm that LassoMLP
outperforms the state-of-the-art method.

    

### [[2108.12175] Grammar Based Identification Of Speaker Role For Improving ATCO And Pilot ASR](http://arxiv.org/abs/2108.12175)


  Assistant Based Speech Recognition (ABSR) for air traffic control is
generally trained by pooling both Air Traffic Controller (ATCO) and pilot data.
In practice, this is motivated by the fact that the proportion of pilot data is
lesser compared to ATCO while their standard language of communication is
similar. However, due to data imbalance of ATCO and pilot and their varying
acoustic conditions, the ASR performance is usually significantly better for
ATCOs than pilots. In this paper, we propose to (1) split the ATCO and pilot
data using an automatic approach exploiting ASR transcripts, and (2) consider
ATCO and pilot ASR as two separate tasks for Acoustic Model (AM) training. For
speaker role classification of ATCO and pilot data, a hypothesized ASR
transcript is generated with a seed model, subsequently used to classify the
speaker role based on the knowledge extracted from grammar defined by
International Civil Aviation Organization (ICAO). This approach provides an
average speaker role identification accuracy of 83% for ATCO and pilot.
Finally, we show that training AMs separately for each task, or using a
multitask approach is well suited for this data compared to AM trained by
pooling all data.

    

### [[2108.12179] Graph-based Incident Aggregation for Large-Scale Online Service Systems](http://arxiv.org/abs/2108.12179)


  As online service systems continue to grow in terms of complexity and volume,
how service incidents are managed will significantly impact company revenue and
user trust. Due to the cascading effect, cloud failures often come with an
overwhelming number of incidents from dependent services and devices. To pursue
efficient incident management, related incidents should be quickly aggregated
to narrow down the problem scope. To this end, in this paper, we propose GRLIA,
an incident aggregation framework based on graph representation learning over
the cascading graph of cloud failures. A representation vector is learned for
each unique type of incident in an unsupervised and unified manner, which is
able to simultaneously encode the topological and temporal correlations among
incidents. Thus, it can be easily employed for online incident aggregation. In
particular, to learn the correlations more accurately, we try to recover the
complete scope of failures' cascading impact by leveraging fine-grained system
monitoring data, i.e., Key Performance Indicators (KPIs). The proposed
framework is evaluated with real-world incident data collected from a
large-scale online service system of Huawei Cloud. The experimental results
demonstrate that GRLIA is effective and outperforms existing methods.
Furthermore, our framework has been successfully deployed in industrial
practice.

    

### [[2108.12193] Man versus Machine: AutoML and Human Experts' Role in Phishing Detection](http://arxiv.org/abs/2108.12193)


  Machine learning (ML) has developed rapidly in the past few years and has
successfully been utilized for a broad range of tasks, including phishing
detection. However, building an effective ML-based detection system is not a
trivial task, and requires data scientists with knowledge of the relevant
domain. Automated Machine Learning (AutoML) frameworks have received a lot of
attention in recent years, enabling non-ML experts in building a machine
learning model. This brings to an intriguing question of whether AutoML can
outperform the results achieved by human data scientists. Our paper compares
the performances of six well-known, state-of-the-art AutoML frameworks on ten
different phishing datasets to see whether AutoML-based models can outperform
manually crafted machine learning models. Our results indicate that
AutoML-based models are able to outperform manually developed machine learning
models in complex classification tasks, specifically in datasets where the
features are not quite discriminative, and datasets with overlapping classes or
relatively high degrees of non-linearity. Challenges also remain in building a
real-world phishing detection system using AutoML frameworks due to the current
support only on supervised classification problems, leading to the need for
labeled data, and the inability to update the AutoML-based models
incrementally. This indicates that experts with knowledge in the domain of
phishing and cybersecurity are still essential in the loop of the phishing
detection pipeline.

    

### [[2108.12199] Learning primal-dual sparse kernel machines](http://arxiv.org/abs/2108.12199)


  Traditionally, kernel methods rely on the representer theorem which states
that the solution to a learning problem is obtained as a linear combination of
the data mapped into the reproducing kernel Hilbert space (RKHS). While elegant
from theoretical point of view, the theorem is prohibitive for algorithms'
scalability to large datasets, and the interpretability of the learned
function. In this paper, instead of using the traditional representer theorem,
we propose to search for a solution in RKHS that has a pre-image decomposition
in the original data space, where the elements don't necessarily correspond to
the elements in the training set. Our gradient-based optimisation method then
hinges on optimising over possibly sparse elements in the input space, and
enables us to obtain a kernel-based model with both primal and dual sparsity.
We give theoretical justification on the proposed method's generalization
ability via a Rademacher bound. Our experiments demonstrate a better
scalability and interpretability with accuracy on par with the traditional
kernel-based models.

    

### [[2108.12204] This looks more like that: Enhancing Self-Explaining Models by Prototypical Relevance Propagation](http://arxiv.org/abs/2108.12204)


  Current machine learning models have shown high efficiency in solving a wide
variety of real-world problems. However, their black box character poses a
major challenge for the understanding and traceability of the underlying
decision-making strategies. As a remedy, many post-hoc explanation and
self-explanatory methods have been developed to interpret the models' behavior.
These methods, in addition, enable the identification of artifacts that can be
learned by the model as class-relevant features. In this work, we provide a
detailed case study of the self-explaining network, ProtoPNet, in the presence
of a spectrum of artifacts. Accordingly, we identify the main drawbacks of
ProtoPNet, especially, its coarse and spatially imprecise explanations. We
address these limitations by introducing Prototypical Relevance Propagation
(PRP), a novel method for generating more precise model-aware explanations.
Furthermore, in order to obtain a clean dataset, we propose to use multi-view
clustering strategies for segregating the artifact images using the PRP
explanations, thereby suppressing the potential artifact learning in the
models.

    

### [[2108.12211] Enel: Context-Aware Dynamic Scaling of Distributed Dataflow Jobs using Graph Propagation](http://arxiv.org/abs/2108.12211)


  Distributed dataflow systems like Spark and Flink enable the use of clusters
for scalable data analytics. While runtime prediction models can be used to
initially select appropriate cluster resources given target runtimes, the
actual runtime performance of dataflow jobs depends on several factors and
varies over time. Yet, in many situations, dynamic scaling can be used to meet
formulated runtime targets despite significant performance variance.
This paper presents Enel, a novel dynamic scaling approach that uses message
propagation on an attributed graph to model dataflow jobs and, thus, allows for
deriving effective rescaling decisions. For this, Enel incorporates descriptive
properties that capture the respective execution context, considers statistics
from individual dataflow tasks, and propagates predictions through the job
graph to eventually find an optimized new scale-out. Our evaluation of Enel
with four iterative Spark jobs shows that our approach is able to identify
effective rescaling actions, reacting for instance to node failures, and can be
reused across different execution contexts.

    

### [[2108.12238] Group-Aware Graph Neural Network for Nationwide City Air Quality Forecasting](http://arxiv.org/abs/2108.12238)


  The problem of air pollution threatens public health. Air quality forecasting
can provide the air quality index hours or even days later, which can help the
public to prevent air pollution in advance. Previous works focus on citywide
air quality forecasting and cannot solve nationwide city forecasting problem,
whose difficulties lie in capturing the latent dependencies between
geographically distant but highly correlated cities. In this paper, we propose
the group-aware graph neural network (GAGNN), a hierarchical model for
nationwide city air quality forecasting. The model constructs a city graph and
a city group graph to model the spatial and latent dependencies between cities,
respectively. GAGNN introduces differentiable grouping network to discover the
latent dependencies among cities and generate city groups. Based on the
generated city groups, a group correlation encoding module is introduced to
learn the correlations between them, which can effectively capture the
dependencies between city groups. After the graph construction, GAGNN
implements message passing mechanism to model the dependencies between cities
and city groups. The evaluation experiments on Chinese city air quality dataset
indicate that our GAGNN outperforms existing forecasting models.

    

### [[2108.12245] Active Inference for Stochastic Control](http://arxiv.org/abs/2108.12245)


  Active inference has emerged as an alternative approach to control problems
given its intuitive (probabilistic) formalism. However, despite its theoretical
utility, computational implementations have largely been restricted to
low-dimensional, deterministic settings. This paper highlights that this is a
consequence of the inability to adequately model stochastic transition
dynamics, particularly when an extensive policy (i.e., action trajectory) space
must be evaluated during planning. Fortunately, recent advancements propose a
modified planning algorithm for finite temporal horizons. We build upon this
work to assess the utility of active inference for a stochastic control
setting. For this, we simulate the classic windy grid-world task with
additional complexities, namely: 1) environment stochasticity; 2) learning of
transition dynamics; and 3) partial observability. Our results demonstrate the
advantage of using active inference, compared to reinforcement learning, in
both deterministic and stochastic settings.

    

### [[2108.12250] A comparison of approaches to improve worst-case predictive model performance over patient subpopulations](http://arxiv.org/abs/2108.12250)


  Predictive models for clinical outcomes that are accurate on average in a
patient population may underperform drastically for some subpopulations,
potentially introducing or reinforcing inequities in care access and quality.
Model training approaches that aim to maximize worst-case model performance
across subpopulations, such as distributionally robust optimization (DRO),
attempt to address this problem without introducing additional harms. We
conduct a large-scale empirical study of DRO and several variations of standard
learning procedures to identify approaches for model development and selection
that consistently improve disaggregated and worst-case performance over
subpopulations compared to standard approaches for learning predictive models
from electronic health records data. In the course of our evaluation, we
introduce an extension to DRO approaches that allows for specification of the
metric used to assess worst-case performance. We conduct the analysis for
models that predict in-hospital mortality, prolonged length of stay, and 30-day
readmission for inpatient admissions, and predict in-hospital mortality using
intensive care data. We find that, with relatively few exceptions, no approach
performs better, for each patient subpopulation examined, than standard
learning procedures using the entire training dataset. These results imply that
when it is of interest to improve model performance for patient subpopulations
beyond what can be achieved with standard practices, it may be necessary to do
so via techniques that implicitly or explicitly increase the effective sample
size.

    

### [[2108.12265] Quantum Machine Learning for Health State Diagnosis and Prognostics](http://arxiv.org/abs/2108.12265)


  Quantum computing is a new field that has recently attracted researchers from
a broad range of fields due to its representation power, flexibility and
promising results in both speed and scalability. Since 2020, laboratories
around the globe have started to experiment with models that lie in the
juxtaposition between machine learning and quantum computing. The availability
of quantum processing units (QPUs) to the general scientific community through
open APIs (e.g., Qiskit from IBM) have kindled the interest in developing and
testing new approaches to old problems. In this paper, we present a hybrid
quantum machine learning framework for health state diagnostics and
prognostics. The framework is exemplified using a problem involving ball
bearings dataset. To the best of our knowledge, this is the first attempt to
harvest and leverage quantum computing to develop and apply a hybrid
quantum-classical machine learning approach to a prognostics and health
management (PHM) problem. We hope that this paper initiates the exploration and
application of quantum machine learning algorithms in areas of risk and
reliability.

    

### [[2108.12269] Detecting Propaganda on the Sentence Level during the COVID-19 Pandemic](http://arxiv.org/abs/2108.12269)


  The spread of misinformation, conspiracy, and questionable content and
information manipulation by foreign adversaries on social media has surged
along with the COVID-19 pandemic. Such malicious cyber-enabled actions may
cause increasing social polarization, health crises, and property loss. In this
paper, using fine-tuned contextualized embedding trained on Reddit, we tackle
the detection of the propaganda of such user accounts and their targeted issues
on Twitter during March 2020 when the COVID-19 epidemic became recognized as a
pandemic. Our result shows that the pro-China group appeared to be tweeting 35
to 115 times more than the neutral group. At the same time, neutral groups were
tweeting more positive-attitude content and voicing alarm for the COVID-19
situation. The pro-China group was also using more call-for-action words on
political issues not necessarily China-related.

    

### [[2108.12275] Can the Transformer Be Used as a Drop-in Replacement for RNNs in Text-Generating GANs?](http://arxiv.org/abs/2108.12275)


  In this paper we address the problem of fine-tuned text generation with a
limited computational budget. For that, we use a well-performing text
generative adversarial network (GAN) architecture - Diversity-Promoting GAN
(DPGAN), and attempted a drop-in replacement of the LSTM layer with a
self-attention-based Transformer layer in order to leverage their efficiency.
The resulting Self-Attention DPGAN (SADPGAN) was evaluated for performance,
quality and diversity of generated text and stability. Computational
experiments suggested that a transformer architecture is unable to drop-in
replace the LSTM layer, under-performing during the pre-training phase and
undergoing a complete mode collapse during the GAN tuning phase. Our results
suggest that the transformer architecture need to be adapted before it can be
used as a replacement for RNNs in text-generating GANs.

    

### [[2108.12278] Lifelong Infinite Mixture Model Based on Knowledge-Driven Dirichlet Process](http://arxiv.org/abs/2108.12278)


  Recent research efforts in lifelong learning propose to grow a mixture of
models to adapt to an increasing number of tasks. The proposed methodology
shows promising results in overcoming catastrophic forgetting. However, the
theory behind these successful models is still not well understood. In this
paper, we perform the theoretical analysis for lifelong learning models by
deriving the risk bounds based on the discrepancy distance between the
probabilistic representation of data generated by the model and that
corresponding to the target dataset. Inspired by the theoretical analysis, we
introduce a new lifelong learning approach, namely the Lifelong Infinite
Mixture (LIMix) model, which can automatically expand its network architectures
or choose an appropriate component to adapt its parameters for learning a new
task, while preserving its previously learnt information. We propose to
incorporate the knowledge by means of Dirichlet processes by using a gating
mechanism which computes the dependence between the knowledge learnt previously
and stored in each component, and a new set of data. Besides, we train a
compact Student model which can accumulate cross-domain representations over
time and make quick inferences. The code is available at
this https URL.

    

### [[2108.12284] The Devil is in the Detail: Simple Tricks Improve Systematic Generalization of Transformers](http://arxiv.org/abs/2108.12284)


  Recently, many datasets have been proposed to test the systematic
generalization ability of neural networks. The companion baseline Transformers,
typically trained with default hyper-parameters from standard tasks, are shown
to fail dramatically. Here we demonstrate that by revisiting model
configurations as basic as scaling of embeddings, early stopping, relative
positional embedding, and Universal Transformer variants, we can drastically
improve the performance of Transformers on systematic generalization. We report
improvements on five popular datasets: SCAN, CFQ, PCFG, COGS, and Mathematics
dataset. Our models improve accuracy from 50% to 85% on the PCFG productivity
split, and from 35% to 81% on COGS. On SCAN, relative positional embedding
largely mitigates the EOS decision problem (Newman et al., 2020), yielding 100%
accuracy on the length split with a cutoff at 26. Importantly, performance
differences between these models are typically invisible on the IID data split.
This calls for proper generalization validation sets for developing neural
networks that generalize systematically. We publicly release the code to
reproduce our results.

    

### [[2108.12293] A Framework for Supervised Heterogeneous Transfer Learning using Dynamic Distribution Adaptation and Manifold Regularization](http://arxiv.org/abs/2108.12293)


  Transfer learning aims to learn classifiers for a target domain by
transferring knowledge from a source domain. However, due to two main issues:
feature discrepancy and distribution divergence, transfer learning can be a
very difficult problem in practice. In this paper, we present a framework
called TLF that builds a classifier for the target domain having only few
labeled training records by transferring knowledge from the source domain
having many labeled records. While existing methods often focus on one issue
and leave the other one for the further work, TLF is capable of handling both
issues simultaneously. In TLF, we alleviate feature discrepancy by identifying
shared label distributions that act as the pivots to bridge the domains. We
handle distribution divergence by simultaneously optimizing the structural risk
functional, joint distributions between domains, and the manifold consistency
underlying marginal distributions. Moreover, for the manifold consistency we
exploit its intrinsic properties by identifying k nearest neighbors of a
record, where the value of k is determined automatically in TLF. Furthermore,
since negative transfer is not desired, we consider only the source records
that are belonging to the source pivots during the knowledge transfer. We
evaluate TLF on seven publicly available natural datasets and compare the
performance of TLF against the performance of eleven state-of-the-art
techniques. We also evaluate the effectiveness of TLF in some challenging
situations. Our experimental results, including statistical sign test and
Nemenyi test analyses, indicate a clear superiority of the proposed framework
over the state-of-the-art techniques.

    

### [[2108.12296] Contrastive Mixup: Self- and Semi-Supervised learning for Tabular Domain](http://arxiv.org/abs/2108.12296)


  Recent literature in self-supervised has demonstrated significant progress in
closing the gap between supervised and unsupervised methods in the image and
text domains. These methods rely on domain-specific augmentations that are not
directly amenable to the tabular domain. Instead, we introduce Contrastive
Mixup, a semi-supervised learning framework for tabular data and demonstrate
its effectiveness in limited annotated data settings. Our proposed method
leverages Mixup-based augmentation under the manifold assumption by mapping
samples to a low dimensional latent space and encourage interpolated samples to
have high a similarity within the same labeled class. Unlabeled samples are
additionally employed via a transductive label propagation method to further
enrich the set of similar and dissimilar pairs that can be used in the
contrastive loss term. We demonstrate the effectiveness of the proposed
framework on public tabular datasets and real-world clinical datasets.

    

### [[2108.12298] Reinforcement Learning based Condition-oriented Maintenance Scheduling for Flow Line Systems](http://arxiv.org/abs/2108.12298)


  Maintenance scheduling is a complex decision-making problem in the production
domain, where a number of maintenance tasks and resources has to be assigned
and scheduled to production entities in order to prevent unplanned production
downtime. Intelligent maintenance strategies are required that are able to
adapt to the dynamics and different conditions of production systems. The paper
introduces a deep reinforcement learning approach for condition-oriented
maintenance scheduling in flow line systems. Different policies are learned,
analyzed and evaluated against a benchmark scheduling heuristic based on reward
modelling. The evaluation of the learned policies shows that reinforcement
learning based maintenance strategies meet the requirements of the presented
use case and are suitable for maintenance scheduling in the shop floor.

    

### [[2108.12308] An Adaptive Clustering Approach for Accident Prediction](http://arxiv.org/abs/2108.12308)


  Traffic accident prediction is a crucial task in the mobility domain.
State-of-the-art accident prediction approaches are based on static and uniform
grid-based geospatial aggregations, limiting their capability for fine-grained
predictions. This property becomes particularly problematic in more complex
regions such as city centers. In such regions, a grid cell can contain
subregions with different properties; furthermore, an actual accident-prone
region can be split across grid cells arbitrarily. This paper proposes Adaptive
Clustering Accident Prediction (ACAP) - a novel accident prediction method
based on a grid growing algorithm. ACAP applies adaptive clustering to the
observed geospatial accident distribution and performs embeddings of temporal,
accident-related, and regional features to increase prediction accuracy. We
demonstrate the effectiveness of the proposed ACAP method using open real-world
accident datasets from three cities in Germany. We demonstrate that ACAP
improves the accident prediction performance for complex regions by 2-3 percent
points in F1-score by adapting the geospatial aggregation to the distribution
of the underlying spatio-temporal events. Our grid growing approach outperforms
the clustering-based baselines by four percent points in terms of F1-score on
average.

    

### [[2108.12314] Multiple Hypothesis Testing Framework for Spatial Signals](http://arxiv.org/abs/2108.12314)


  The problem of identifying regions of spatially interesting, different or
adversarial behavior is inherent to many practical applications involving
distributed multisensor systems. In this work, we develop a general framework
stemming from multiple hypothesis testing to identify such regions. A discrete
spatial grid is assumed for the monitored environment. The spatial grid points
associated with different hypotheses are identified while controlling the false
discovery rate at a pre-specified level. Measurements are acquired using a
large-scale sensor network. We propose a novel, data-driven method to estimate
local false discovery rates based on the spectral method of moments. Our method
is agnostic to specific spatial propagation models of the underlying physical
phenomenon. It relies on a broadly applicable density model for local summary
statistics. In between sensors, locations are assigned to regions associated
with different hypotheses based on interpolated local false discovery rates.
The benefits of our method are illustrated by applications to spatially
propagating radio waves.

    

### [[2108.12318] CAPE: Context-Aware Private Embeddings for Private Language Learning](http://arxiv.org/abs/2108.12318)


  Deep learning-based language models have achieved state-of-the-art results in
a number of applications including sentiment analysis, topic labelling, intent
classification and others. Obtaining text representations or embeddings using
these models presents the possibility of encoding personally identifiable
information learned from language and context cues that may present a risk to
reputation or privacy. To ameliorate these issues, we propose Context-Aware
Private Embeddings (CAPE), a novel approach which preserves privacy during
training of embeddings. To maintain the privacy of text representations, CAPE
applies calibrated noise through differential privacy, preserving the encoded
semantic links while obscuring sensitive information. In addition, CAPE employs
an adversarial training regime that obscures identified private variables.
Experimental results demonstrate that the proposed approach reduces private
information leakage better than either single intervention.

    

### [[2108.12344] Investigation of Nonlinear Model Order Reduction of the Quasigeostrophic Equations through a Physics-Informed Convolutional Autoencoder](http://arxiv.org/abs/2108.12344)


  Reduced order modeling (ROM) is a field of techniques that approximates
complex physics-based models of real-world processes by inexpensive surrogates
that capture important dynamical characteristics with a smaller number of
degrees of freedom. Traditional ROM techniques such as proper orthogonal
decomposition (POD) focus on linear projections of the dynamics onto a set of
spectral features. In this paper we explore the construction of ROM using
autoencoders (AE) that perform nonlinear projections of the system dynamics
onto a low dimensional manifold learned from data. The approach uses
convolutional neural networks (CNN) to learn spatial features as opposed to
spectral, and utilize a physics informed (PI) cost function in order to capture
temporal features as well. Our investigation using the quasi-geostrophic
equations reveals that while the PI cost function helps with spatial
reconstruction, spatial features are less powerful than spectral features, and
that construction of ROMs through machine learning-based methods requires
significant investigation into novel non-standard methodologies.

    

### [[2108.12346] A Perceptually-Validated Metric for Crowd Trajectory Quality Evaluation](http://arxiv.org/abs/2108.12346)


  Simulating crowds requires controlling a very large number of trajectories
and is usually performed using crowd motion algorithms for which appropriate
parameter values need to be found. The study of the relation between parametric
values for simulation techniques and the quality of the resulting trajectories
has been studied either through perceptual experiments or by comparison with
real crowd trajectories. In this paper, we integrate both strategies. A quality
metric, QF, is proposed to abstract from reference data while capturing the
most salient features that affect the perception of trajectory realism. QF
weights and combines cost functions that are based on several individual, local
and global properties of trajectories. These trajectory features are selected
from the literature and from interviews with experts. To validate the capacity
of QF to capture perceived trajectory quality, we conduct an online experiment
that demonstrates the high agreement between the automatic quality score and
non-expert users. To further demonstrate the usefulness of QF, we use it in a
data-free parameter tuning application able to tune any parametric microscopic
crowd simulation model that outputs independent trajectories for characters.
The learnt parameters for the tuned crowd motion model maintain the influence
of the reference data which was used to weight the terms of QF.

    

### [[2108.12352] Deep Information Fusion for Electric Vehicle Charging Station Occupancy Forecasting](http://arxiv.org/abs/2108.12352)


  With an increasing number of electric vehicles, the accurate forecasting of
charging station occupation is crucial to enable reliable vehicle charging.
This paper introduces a novel Deep Fusion of Dynamic and Static Information
model (DFDS) to effectively forecast the charging station occupation. We
exploit static information, such as the mean occupation concerning the time of
day, to learn the specific charging station patterns. We supplement such static
data with dynamic information reflecting the preceding charging station
occupation and temporal information such as daytime and weekday. Our model
efficiently fuses dynamic and static information to facilitate accurate
forecasting. We evaluate the proposed model on a real-world dataset containing
593 charging stations in Germany, covering August 2020 to December 2020. Our
experiments demonstrate that DFDS outperforms the baselines by 3.45 percent
points in F1-score on average.

    

### [[2108.12363] Application of Classification and Feature Selection in Building Energy Simulations](http://arxiv.org/abs/2108.12363)


  Building energy performance is one of the key features in performance-based
building design decision making. Building envelope materials can play a key
role in improving building energy performance. The thermal properties of
building materials determine the level of heat transfer through building
envelope, thus the annual thermal energy performance of the building. This
research applies the Linear Discriminant Analysis (LDA) method to study the
effects of materials' thermal properties on building thermal loads. Two
approaches are adopted for feature selection including the Principal Component
Analysis (PCA) and the Exhaustive Feature Selection (EFS). A hypothetical
design scenario is developed with six material alternatives for an office
building in Los Angeles, California. The best design alternative is selected
based on the LDA results and the key input parameters are determined based on
the PCA and EFS methods. The PCA results confirm that among all thermal
properties of the materials, the four parameters including thermal
conductivity, density, specific heat capacity, and thickness are the most
critical features, in terms of building thermal behavior and thermal energy
consumption. This result matches quite well with the assumptions of most of the
building energy simulation tools.

    

### [[2108.12370] DomiKnowS: A Library for Integration of Symbolic Domain Knowledge in Deep Learning](http://arxiv.org/abs/2108.12370)


  We demonstrate a library for the integration of domain knowledge in deep
learning architectures. Using this library, the structure of the data is
expressed symbolically via graph declarations and the logical constraints over
outputs or latent variables can be seamlessly added to the deep models. The
domain knowledge can be defined explicitly, which improves the models'
explainability in addition to the performance and generalizability in the
low-data regime. Several approaches for such an integration of symbolic and
sub-symbolic models have been introduced; however, there is no library to
facilitate the programming for such an integration in a generic way while
various underlying algorithms can be used. Our library aims to simplify
programming for such an integration in both training and inference phases while
separating the knowledge representation from learning algorithms. We showcase
various NLP benchmark tasks and beyond. The framework is publicly available at
Github(this https URL).

    

### [[2108.12373] FAST-PCA: A Fast and Exact Algorithm for Distributed Principal Component Analysis](http://arxiv.org/abs/2108.12373)


  Principal Component Analysis (PCA) is a fundamental data preprocessing tool
in the world of machine learning. While PCA is often reduced to dimension
reduction, the purpose of PCA is actually two-fold: dimension reduction and
feature learning. Furthermore, the enormity of the dimensions and sample size
in the modern day datasets have rendered the centralized PCA solutions
unusable. In that vein, this paper reconsiders the problem of PCA when data
samples are distributed across nodes in an arbitrarily connected network. While
a few solutions for distributed PCA exist those either overlook the feature
learning part of the purpose, have communication overhead making them
inefficient and/or lack exact convergence guarantees. To combat these
aforementioned issues, this paper proposes a distributed PCA algorithm called
FAST-PCA (Fast and exAct diSTributed PCA). The proposed algorithm is efficient
in terms of communication and can be proved to converge linearly and exactly to
the principal components that lead to dimension reduction as well as
uncorrelated features. Our claims are further supported by experimental
results.

    

### [[2108.12375] A Pedestrian Detection and Tracking Framework for Autonomous Cars: Efficient Fusion of Camera and LiDAR Data](http://arxiv.org/abs/2108.12375)


  This paper presents a novel method for pedestrian detection and tracking by
fusing camera and LiDAR sensor data. To deal with the challenges associated
with the autonomous driving scenarios, an integrated tracking and detection
framework is proposed. The detection phase is performed by converting LiDAR
streams to computationally tractable depth images, and then, a deep neural
network is developed to identify pedestrian candidates both in RGB and depth
images. To provide accurate information, the detection phase is further
enhanced by fusing multi-modal sensor information using the Kalman filter. The
tracking phase is a combination of the Kalman filter prediction and an optical
flow algorithm to track multiple pedestrians in a scene. We evaluate our
framework on a real public driving dataset. Experimental results demonstrate
that the proposed method achieves significant performance improvement over a
baseline method that solely uses image-based pedestrian detection.

    

### [[2108.12383] A Guide to Reproducible Research in Signal Processing and Machine Learning](http://arxiv.org/abs/2108.12383)


  Reproducibility is a growing problem that has been extensively studied among
computational researchers and within the signal processing and machine learning
research community. However, with the changing landscape of signal processing
and machine learning research come new obstacles and unseen challenges in
creating reproducible experiments. Due to these new challenges most experiments
have become difficult, if not impossible, to be reproduced by an independent
researcher. In 2016 a survey conducted by the journal Nature found that 50% of
researchers were unable to reproduce their own experiments. While the issue of
reproducibility has been discussed in the literature and specifically within
the signal processing community, it is still unclear to most researchers what
are the best practices to ensure reproducibility without impinging on their
primary responsibility of conducting research. We feel that although
researchers understand the importance of making experiments reproducible, the
lack of a clear set of standards and tools makes it difficult to incorporate
good reproducibility practices in most labs. It is in this regard that we aim
to present signal processing researchers with a set of practical tools and
strategies that can help mitigate many of the obstacles to producing
reproducible computational experiments.

    

### [[1902.01073] Causal Effect Identification from Multiple Incomplete Data Sources: A General Search-based Approach](http://arxiv.org/abs/1902.01073)


  Causal effect identification considers whether an interventional probability
distribution can be uniquely determined without parametric assumptions from
measured source distributions and structural knowledge on the generating
system. While complete graphical criteria and procedures exist for many
identification problems, there are still challenging but important extensions
that have not been considered in the literature. To tackle these new settings,
we present a search algorithm directly over the rules of do-calculus. Due to
generality of do-calculus, the search is capable of taking more advanced
data-generating mechanisms into account along with an arbitrary type of both
observational and experimental source distributions. The search is enhanced via
a heuristic and search space reduction techniques. The approach, called
do-search, is provably sound, and it is complete with respect to
identifiability problems that have been shown to be completely characterized by
do-calculus. When extended with additional rules, the search is capable of
handling missing data problems as well. With the versatile search, we are able
to approach new problems such as combined transportability and selection bias,
or multiple sources of selection bias. We perform a systematic analysis of
bivariate missing data problems and study causal inference under case-control
design. We also present the R package dosearch that provides an interface for a
C++ implementation of the search.

    

### [[2002.08994] Optimal anytime regret with two experts](http://arxiv.org/abs/2002.08994)


  We consider the classical problem of prediction with expert advice. In the
fixed-time setting, where the time horizon is known in advance, algorithms that
achieve the optimal regret are known when there are two, three, or four experts
or when the number of experts is large. Much less is known about the problem in
the anytime setting, where the time horizon is not known in advance. No minimax
optimal algorithm was previously known in the anytime setting, regardless of
the number of experts. Even for the case of two experts, Luo and Schapire have
left open the problem of determining the optimal algorithm.
We design the first minimax optimal algorithm for minimizing regret in the
anytime setting. We consider the case of two experts, and prove that the
optimal regret is $\gamma \sqrt{t} / 2$ at all time steps $t$, where $\gamma$
is a natural constant that arose 35 years ago in studying fundamental
properties of Brownian motion. The algorithm is designed by considering a
continuous analogue of the regret problem, which is solved using ideas from
stochastic calculus.

    

### [[2003.02989] TensorFlow Quantum: A Software Framework for Quantum Machine Learning](http://arxiv.org/abs/2003.02989)


  We introduce TensorFlow Quantum (TFQ), an open source library for the rapid
prototyping of hybrid quantum-classical models for classical or quantum data.
This framework offers high-level abstractions for the design and training of
both discriminative and generative quantum models under TensorFlow and supports
high-performance quantum circuit simulators. We provide an overview of the
software architecture and building blocks through several examples and review
the theory of hybrid quantum-classical neural networks. We illustrate TFQ
functionalities via several basic applications including supervised learning
for quantum classification, quantum control, simulating noisy quantum circuits,
and quantum approximate optimization. Moreover, we demonstrate how one can
apply TFQ to tackle advanced quantum learning tasks including meta-learning,
layerwise learning, Hamiltonian learning, sampling thermal states, variational
quantum eigensolvers, classification of quantum phase transitions, generative
adversarial networks, and reinforcement learning. We hope this framework
provides the necessary tools for the quantum computing and machine learning
research communities to explore models of both natural and artificial quantum
systems, and ultimately discover new quantum algorithms which could potentially
yield a quantum advantage.

    

### [[2006.05162] Rethinking preventing class-collapsing in metric learning with margin-based losses](http://arxiv.org/abs/2006.05162)


  Metric learning seeks perceptual embeddings where visually similar instances
are close and dissimilar instances are apart, but learned representations can
be sub-optimal when the distribution of intra-class samples is diverse and
distinct sub-clusters are present. Although theoretically with optimal
assumptions, margin-based losses such as the triplet loss and margin loss have
a diverse family of solutions. We theoretically prove and empirically show that
under reasonable noise assumptions, margin-based losses tend to project all
samples of a class with various modes onto a single point in the embedding
space, resulting in a class collapse that usually renders the space ill-sorted
for classification or retrieval. To address this problem, we propose a simple
modification to the embedding losses such that each sample selects its nearest
same-class counterpart in a batch as the positive element in the tuple. This
allows for the presence of multiple sub-clusters within each class. The
adaptation can be integrated into a wide range of metric learning losses. The
proposed sampling method demonstrates clear benefits on various fine-grained
image retrieval datasets over a variety of existing losses; qualitative
retrieval results show that samples with similar visual patterns are indeed
closer in the embedding space.

    

### [[2007.00590] Decentralized Stochastic Gradient Langevin Dynamics and Hamiltonian Monte Carlo](http://arxiv.org/abs/2007.00590)


  Stochastic gradient Langevin dynamics (SGLD) and stochastic gradient
Hamiltonian Monte Carlo (SGHMC) are two popular Markov Chain Monte Carlo (MCMC)
algorithms for Bayesian inference that can scale to large datasets, allowing to
sample from the posterior distribution of the parameters of a statistical model
given the input data and the prior distribution over the model parameters.
However, these algorithms do not apply to the decentralized learning setting,
when a network of agents are working collaboratively to learn the parameters of
a statistical model without sharing their individual data due to privacy
reasons or communication constraints. We study two algorithms: Decentralized
SGLD (DE-SGLD) and Decentralized SGHMC (DE-SGHMC) which are adaptations of SGLD
and SGHMC methods that allow scaleable Bayesian inference in the decentralized
setting for large datasets. We show that when the posterior distribution is
strongly log-concave and smooth, the iterates of these algorithms converge
linearly to a neighborhood of the target distribution in the 2-Wasserstein
distance if their parameters are selected appropriately. We illustrate the
efficiency of our algorithms on decentralized Bayesian linear regression and
Bayesian logistic regression problems.

    

### [[2007.10637] Distributed Associative Memory Network with Memory Refreshing Loss](http://arxiv.org/abs/2007.10637)


  Despite recent progress in memory augmented neural network (MANN) research,
associative memory networks with a single external memory still show limited
performance on complex relational reasoning tasks. Especially the content-based
addressable memory networks often fail to encode input data into rich enough
representation for relational reasoning and this limits the relation modeling
performance of MANN for long temporal sequence data. To address these problems,
here we introduce a novel Distributed Associative Memory architecture (DAM)
with Memory Refreshing Loss (MRL) which enhances the relation reasoning
performance of MANN. Inspired by how the human brain works, our framework
encodes data with distributed representation across multiple memory blocks and
repeatedly refreshes the contents for enhanced memorization similar to the
rehearsal process of the brain. For this procedure, we replace a single
external memory with a set of multiple smaller associative memory blocks and
update these sub-memory blocks simultaneously and independently for the
distributed representation of input data. Moreover, we propose MRL which
assists a task's target objective while learning relational information
existing in data. MRL enables MANN to reinforce an association between input
data and task objective by reproducing stochastically sampled input data from
stored memory contents. With this procedure, MANN further enriches the stored
representations with relational information. In experiments, we apply our
approaches to Differential Neural Computer (DNC), which is one of the
representative content-based addressing memory models and achieves the
state-of-the-art performance on both memorization and relational reasoning
tasks.

    

### [[2008.11757] Deep Learning for Constrained Utility Maximisation](http://arxiv.org/abs/2008.11757)


  This paper proposes two algorithms for solving stochastic control problems
with deep learning, with a focus on the utility maximisation problem. The first
algorithm solves Markovian problems via the Hamilton Jacobi Bellman (HJB)
equation. We solve this highly nonlinear partial differential equation (PDE)
with a second order backward stochastic differential equation (2BSDE)
formulation. The convex structure of the problem allows us to describe a dual
problem that can either verify the original primal approach or bypass some of
the complexity. The second algorithm utilises the full power of the duality
method to solve non-Markovian problems, which are often beyond the scope of
stochastic control solvers in the existing literature. We solve an adjoint BSDE
that satisfies the dual optimality conditions. We apply these algorithms to
problems with power, log and non-HARA utilities in the Black-Scholes, the
Heston stochastic volatility, and path dependent volatility models. Numerical
experiments show highly accurate results with low computational cost,
supporting our proposed algorithms.

    

### [[2009.13447] Why resampling outperforms reweighting for correcting sampling bias with stochastic gradients](http://arxiv.org/abs/2009.13447)


  A data set sampled from a certain population is biased if the subgroups of
the population are sampled at proportions that are significantly different from
their underlying proportions. Training machine learning models on biased data
sets requires correction techniques to compensate for the bias. We consider two
commonly-used techniques, resampling and reweighting, that rebalance the
proportions of the subgroups to maintain the desired objective function. Though
statistically equivalent, it has been observed that resampling outperforms
reweighting when combined with stochastic gradient algorithms. By analyzing
illustrative examples, we explain the reason behind this phenomenon using tools
from dynamical stability and stochastic asymptotics. We also present
experiments from regression, classification, and off-policy prediction to
demonstrate that this is a general phenomenon. We argue that it is imperative
to consider the objective function design and the optimization algorithm
together while addressing the sampling bias.

    

### [[2009.13807] Current Time Series Anomaly Detection Benchmarks are Flawed and are Creating the Illusion of Progress](http://arxiv.org/abs/2009.13807)


  Time series anomaly detection has been a perennially important topic in data
science, with papers dating back to the 1950s. However, in recent years there
has been an explosion of interest in this topic, much of it driven by the
success of deep learning in other domains and for other time series tasks. Most
of these papers test on one or more of a handful of popular benchmark datasets,
created by Yahoo, Numenta, NASA, etc. In this work we make a surprising claim.
The majority of the individual exemplars in these datasets suffer from one or
more of four flaws. Because of these four flaws, we believe that many published
comparisons of anomaly detection algorithms may be unreliable, and more
importantly, much of the apparent progress in recent years may be illusionary.
In addition to demonstrating these claims, with this paper we introduce the UCR
Time Series Anomaly Archive. We believe that this resource will perform a
similar role as the UCR Time Series Classification Archive, by providing the
community with a benchmark that allows meaningful comparisons between
approaches and a meaningful gauge of overall progress.

    

### [[2010.07799] Adaptive and Universal Algorithms for Variational Inequalities with Optimal Convergence](http://arxiv.org/abs/2010.07799)


  We develop new adaptive algorithms for variational inequalities with monotone
operators, which capture many problems of interest, notably convex optimization
and convex-concave saddle point problems. Our algorithms automatically adapt to
unknown problem parameters such as the smoothness and the norm of the operator,
and the variance of the stochastic evaluation oracle. We show that our
algorithms are universal and simultaneously achieve the optimal convergence
rates in the non-smooth, smooth, and stochastic settings. The convergence
guarantees of our algorithms improve over existing adaptive methods by a
$\Omega(\sqrt{\ln T})$ factor, matching the optimal non-adaptive algorithms.
Additionally, prior works require that the optimization domain is bounded. In
this work, we remove this restriction and give algorithms for unbounded domains
that are adaptive and universal. Our general proof techniques can be used for
many variants of the algorithm using one or two operator evaluations per
iteration. The classical methods based on the ExtraGradient/MirrorProx
algorithm require two operator evaluations per iteration, which is the dominant
factor in the running time in many settings.

    

### [[2010.07962] Bilevel Optimization: Convergence Analysis and Enhanced Design](http://arxiv.org/abs/2010.07962)


  Bilevel optimization has arisen as a powerful tool for many machine learning
problems such as meta-learning, hyperparameter optimization, and reinforcement
learning. In this paper, we investigate the nonconvex-strongly-convex bilevel
optimization problem. For deterministic bilevel optimization, we provide a
comprehensive convergence rate analysis for two popular algorithms respectively
based on approximate implicit differentiation (AID) and iterative
differentiation (ITD). For the AID-based method, we orderwisely improve the
previous convergence rate analysis due to a more practical parameter selection
as well as a warm start strategy, and for the ITD-based method we establish the
first theoretical convergence rate. Our analysis also provides a quantitative
comparison between ITD and AID based approaches. For stochastic bilevel
optimization, we propose a novel algorithm named stocBiO, which features a
sample-efficient hypergradient estimator using efficient Jacobian- and
Hessian-vector product computations. We provide the convergence rate guarantee
for stocBiO, and show that stocBiO outperforms the best known computational
complexities orderwisely with respect to the condition number $\kappa$ and the
target accuracy $\epsilon$. We further validate our theoretical results and
demonstrate the efficiency of bilevel optimization algorithms by the
experiments on meta-learning and hyperparameter optimization.

    

### [[2011.03156] Wasserstein-based fairness interpretability framework for machine learning models](http://arxiv.org/abs/2011.03156)


  In this article, we introduce a fairness interpretability framework for
measuring and explaining bias in classification and regression models at the
level of a distribution. In our work, motivated by the ideas of Dwork et al.
(2012), we measure the model bias across sub-population distributions using the
Wasserstein metric. The transport theory characterization of the Wasserstein
metric allows us to take into account the sign of the bias across the model
distribution which in turn yields the decomposition of the model bias into
positive and negative components. To understand how predictors contribute to
the model bias, we introduce and theoretically characterize bias predictor
attributions called bias explanations and investigate their stability. We also
provide the formulation for the bias explanations that take into account the
impact of missing values. In addition, motivated by the works of Å trumbelj
and Kononenko (2014) and Lundberg and Lee (2017), we construct additive bias
explanations by employing cooperative game theory and investigate their
properties.

    

### [[2011.12239] Consistency of regularized spectral clustering in degree-corrected mixed membership model](http://arxiv.org/abs/2011.12239)


  Community detection in network analysis is an attractive research area
recently. Here, under the degree-corrected mixed membership (DCMM) model, we
propose an efficient approach called mixed regularized spectral clustering
(Mixed-RSC for short) based on the regularized Laplacian matrix. Mixed-RSC is
designed based on an ideal cone structure of the variant for the
eigen-decomposition of the population regularized Laplacian matrix. We show
that the algorithm is asymptotically consistent under mild conditions by
providing error bounds for the inferred membership vector of each node. As a
byproduct of our bound, we provide the theoretical optimal choice for the
regularization parameter {\tau}. To demonstrate the performance of our method,
we apply it with previous benchmark methods on both simulated and real-world
networks. To our knowledge, this is the first work to design spectral
clustering algorithm for mixed membership community detection problem under
DCMM model based on the application of regularized Laplacian matrix.

    

### [[2011.13772] Gradient Descent for Deep Matrix Factorization: Dynamics and Implicit Bias towards Low Rank](http://arxiv.org/abs/2011.13772)


  In deep learning, it is common to use more network parameters than training
points. In such scenarioof over-parameterization, there are usually multiple
networks that achieve zero training error so that thetraining algorithm induces
an implicit bias on the computed solution. In practice, (stochastic)
gradientdescent tends to prefer solutions which generalize well, which provides
a possible explanation of thesuccess of deep learning. In this paper we analyze
the dynamics of gradient descent in the simplifiedsetting of linear networks
and of an estimation problem. Although we are not in an
overparameterizedscenario, our analysis nevertheless provides insights into the
phenomenon of implicit bias. In fact, wederive a rigorous analysis of the
dynamics of vanilla gradient descent, and characterize the dynamicalconvergence
of the spectrum. We are able to accurately locate time intervals where the
effective rankof the iterates is close to the effective rank of a low-rank
projection of the ground-truth matrix. Inpractice, those intervals can be used
as criteria for early stopping if a certain regularity is desired. Wealso
provide empirical evidence for implicit bias in more general scenarios, such as
matrix sensing andrandom initialization. This suggests that deep learning
prefers trajectories whose complexity (measuredin terms of effective rank) is
monotonically increasing, which we believe is a fundamental concept for
thetheoretical understanding of deep learning.

    

### [[2012.02647] Detecting 32 Pedestrian Attributes for Autonomous Vehicles](http://arxiv.org/abs/2012.02647)


  Pedestrians are arguably one of the most safety-critical road users to
consider for autonomous vehicles in urban areas. In this paper, we address the
problem of jointly detecting pedestrians and recognizing 32 pedestrian
attributes from a single image. These encompass visual appearance and behavior,
and also include the forecasting of road crossing, which is a main safety
concern. For this, we introduce a Multi-Task Learning (MTL) model relying on a
composite field framework, which achieves both goals in an efficient way. Each
field spatially locates pedestrian instances and aggregates attribute
predictions over them. This formulation naturally leverages spatial context,
making it well suited to low resolution scenarios such as autonomous driving.
By increasing the number of attributes jointly learned, we highlight an issue
related to the scales of gradients, which arises in MTL with numerous tasks. We
solve it by normalizing the gradients coming from different objective functions
when they join at the fork in the network architecture during the backward
pass, referred to as fork-normalization. Experimental validation is performed
on JAAD, a dataset providing numerous attributes for pedestrian analysis from
autonomous vehicles, and shows competitive detection and attribute recognition
results, as well as a more stable MTL training.

    

### [[2012.07974] A review of on-device fully neural end-to-end automatic speech recognition algorithms](http://arxiv.org/abs/2012.07974)


  In this paper, we review various end-to-end automatic speech recognition
algorithms and their optimization techniques for on-device applications.
Conventional speech recognition systems comprise a large number of discrete
components such as an acoustic model, a language model, a pronunciation model,
a text-normalizer, an inverse-text normalizer, a decoder based on a Weighted
Finite State Transducer (WFST), and so on. To obtain sufficiently high speech
recognition accuracy with such conventional speech recognition systems, a very
large language model (up to 100 GB) is usually needed. Hence, the corresponding
WFST size becomes enormous, which prohibits their on-device implementation.
Recently, fully neural network end-to-end speech recognition algorithms have
been proposed. Examples include speech recognition systems based on
Connectionist Temporal Classification (CTC), Recurrent Neural Network
Transducer (RNN-T), Attention-based Encoder-Decoder models (AED), Monotonic
Chunk-wise Attention (MoChA), transformer-based speech recognition systems, and
so on. These fully neural network-based systems require much smaller memory
footprints compared to conventional algorithms, therefore their on-device
implementation has become feasible. In this paper, we review such end-to-end
speech recognition models. We extensively discuss their structures,
performance, and advantages compared to conventional algorithms.

    

### [[2012.08036] Applications of multivariate quasi-random sampling with neural networks](http://arxiv.org/abs/2012.08036)


  Generative moment matching networks (GMMNs) are suggested for modeling the
cross-sectional dependence between stochastic processes. The stochastic
processes considered are geometric Brownian motions and ARMA-GARCH models.
Geometric Brownian motions lead to an application of pricing American basket
call options under dependence and ARMA-GARCH models lead to an application of
simulating predictive distributions. In both types of applications the benefit
of using GMMNs in comparison to parametric dependence models is highlighted and
the fact that GMMNs can produce dependent quasi-random samples with no
additional effort is exploited to obtain variance reduction.

    

### [[2012.08859] Distilling Optimal Neural Networks: Rapid Search in Diverse Spaces](http://arxiv.org/abs/2012.08859)


  Current state-of-the-art Neural Architecture Search (NAS) methods neither
efficiently scale to multiple hardware platforms, nor handle diverse
architectural search-spaces. To remedy this, we present DONNA (Distilling
Optimal Neural Network Architectures), a novel pipeline for rapid, scalable and
diverse NAS, that scales to many user scenarios. DONNA consists of three
phases. First, an accuracy predictor is built using blockwise knowledge
distillation from a reference model. This predictor enables searching across
diverse networks with varying macro-architectural parameters such as layer
types and attention mechanisms, as well as across micro-architectural
parameters such as block repeats and expansion rates. Second, a rapid
evolutionary search finds a set of pareto-optimal architectures for any
scenario using the accuracy predictor and on-device measurements. Third,
optimal models are quickly finetuned to training-from-scratch accuracy. DONNA
is up to 100x faster than MNasNet in finding state-of-the-art architectures
on-device. Classifying ImageNet, DONNA architectures are 20% faster than
EfficientNet-B0 and MobileNetV2 on a Nvidia V100 GPU and 10% faster with 0.5%
higher accuracy than MobileNetV2-1.4x on a Samsung S20 smartphone. In addition
to NAS, DONNA is used for search-space extension and exploration, as well as
hardware-aware model compression.

    

### [[2101.02833] Shallow Bayesian Meta Learning for Real-World Few-Shot Recognition](http://arxiv.org/abs/2101.02833)


  Current state-of-the-art few-shot learners focus on developing effective
training procedures for feature representations, before using simple, e.g.
nearest centroid, classifiers. In this paper, we take an orthogonal approach
that is agnostic to the features used and focus exclusively on meta-learning
the actual classifier layer. Specifically, we introduce MetaQDA, a Bayesian
meta-learning generalization of the classic quadratic discriminant analysis.
This setup has several benefits of interest to practitioners: meta-learning is
fast and memory-efficient, without the need to fine-tune features. It is
agnostic to the off-the-shelf features chosen and thus will continue to benefit
from advances in feature representations. Empirically, it leads to robust
performance in cross-domain few-shot learning and, crucially for real-world
applications, it leads to better uncertainty calibration in predictions.

    

### [[2102.03777] EEGFuseNet: Hybrid Unsupervised Deep Feature Characterization and Fusion for High-Dimensional EEG with An Application to Emotion Recognition](http://arxiv.org/abs/2102.03777)


  How to effectively and efficiently extract valid and reliable features from
high-dimensional electroencephalography (EEG), particularly how to fuse the
spatial and temporal dynamic brain information into a better feature
representation, is a critical issue in brain data analysis. Most current EEG
studies work in a task driven manner and explore the valid EEG features with a
supervised model, which would be limited by the given labels to a great extent.
In this paper, we propose a practical hybrid unsupervised deep convolutional
recurrent generative adversarial network based EEG feature characterization and
fusion model, which is termed as EEGFuseNet. EEGFuseNet is trained in an
unsupervised manner, and deep EEG features covering both spatial and temporal
dynamics are automatically characterized. Comparing to the existing features,
the characterized deep EEG features could be considered to be more generic and
independent of any specific EEG task. The performance of the extracted deep and
low-dimensional features by EEGFuseNet is carefully evaluated in an
unsupervised emotion recognition application based on three public emotion
databases. The results demonstrate the proposed EEGFuseNet is a robust and
reliable model, which is easy to train and performs efficiently in the
representation and fusion of dynamic EEG features. In particular, EEGFuseNet is
established as an optimal unsupervised fusion model with promising
cross-subject emotion recognition performance. It proves EEGFuseNet is capable
of characterizing and fusing deep features that imply comparative cortical
dynamic significance corresponding to the changing of different emotion states,
and also demonstrates the possibility of realizing EEG based cross-subject
emotion recognition in a pure unsupervised manner.

    

### [[2102.03926] Lower Bounds and Accelerated Algorithms for Bilevel Optimization](http://arxiv.org/abs/2102.03926)


  Bilevel optimization has recently attracted growing interests due to its wide
applications in modern machine learning problems. Although recent studies have
characterized the convergence rate for several such popular algorithms, it is
still unclear how much further these convergence rates can be improved. In this
paper, we address this fundamental question from two perspectives. First, we
provide the first-known lower complexity bounds of
$\widetilde{\Omega}(\frac{1}{\sqrt{\mu_x}\mu_y})$ and $\widetilde
\Omega\big(\frac{1}{\sqrt{\epsilon}}\min\{\frac{1}{\mu_y},\frac{1}{\sqrt{\epsilon^{3}}}\}\big)$
respectively for strongly-convex-strongly-convex and convex-strongly-convex
bilevel optimizations. Second, we propose an accelerated bilevel optimizer
named AccBiO, for which we provide the first-known complexity bounds without
the gradient boundedness assumption (which was made in existing analyses) under
the two aforementioned geometries. We also provide significantly tighter upper
bounds than the existing complexity when the bounded gradient assumption does
hold. We show that AccBiO achieves the optimal results (i.e., the upper and
lower bounds match up to logarithmic factors) when the inner-level problem
takes a quadratic form with a constant-level condition number. Interestingly,
our lower bounds under both geometries are larger than the corresponding
optimal complexities of minimax optimization, establishing that bilevel
optimization is provably more challenging than minimax optimization.

    

### [[2102.11487] When is Early Classification of Time Series Meaningful?](http://arxiv.org/abs/2102.11487)


  Since its introduction two decades ago, there has been increasing interest in
the problem of early classification of time series. This problem generalizes
classic time series classification to ask if we can classify a time series
subsequence with sufficient accuracy and confidence after seeing only some
prefix of a target pattern. The idea is that the earlier classification would
allow us to take immediate action, in a domain in which some practical
interventions are possible. For example, that intervention might be sounding an
alarm or applying the brakes in an automobile. In this work, we make a
surprising claim. In spite of the fact that there are dozens of papers on early
classification of time series, it is not clear that any of them could ever work
in a real-world setting. The problem is not with the algorithms per se but with
the vague and underspecified problem description. Essentially all algorithms
make implicit and unwarranted assumptions about the problem that will ensure
that they will be plagued by false positives and false negatives even if their
results suggested that they could obtain near-perfect results. We will explain
our findings with novel insights and experiments and offer recommendations to
the community.

    

### [[2102.13068] Truncated Log-concave Sampling with Reflective Hamiltonian Monte Carlo](http://arxiv.org/abs/2102.13068)


  We introduce Reflective Hamiltonian Monte Carlo (ReHMC), an HMC-based
algorithm, to sample from a log-concave distribution restricted to a convex
body. We prove that, starting from a warm start, the walk mixes to a
log-concave target distribution $\pi(x) \propto e^{-f(x)}$, where $f$ is
$L$-smooth and $m$-strongly-convex, within accuracy $\varepsilon$ after
$\widetilde O(\kappa d^2 \ell^2 \log (1 / \varepsilon))$ steps for a
well-rounded convex body where $\kappa = L / m$ is the condition number of the
negative log-density, $d$ is the dimension, $\ell$ is an upper bound on the
number of reflections, and $\varepsilon$ is the accuracy parameter. We also
developed an efficient open source implementation of ReHMC and we performed an
experimental study on various high-dimensional data-sets. The experiments
suggest that ReHMC outperfroms Hit-and-Run and Coordinate-Hit-and-Run regarding
the time it needs to produce an independent sample and introduces practical
truncated sampling in thousands of dimensions.

    

### [[2103.00718] Autonomous Navigation of an Ultrasound Probe Towards Standard Scan Planes with Deep Reinforcement Learning](http://arxiv.org/abs/2103.00718)


  Autonomous ultrasound (US) acquisition is an important yet challenging task,
as it involves interpretation of the highly complex and variable images and
their spatial relationships. In this work, we propose a deep reinforcement
learning framework to autonomously control the 6-D pose of a virtual US probe
based on real-time image feedback to navigate towards the standard scan planes
under the restrictions in real-world US scans. Furthermore, we propose a
confidence-based approach to encode the optimization of image quality in the
learning process. We validate our method in a simulation environment built with
real-world data collected in the US imaging of the spine. Experimental results
demonstrate that our method can perform reproducible US probe navigation
towards the standard scan plane with an accuracy of $4.91mm/4.65^\circ$ in the
intra-patient setting, and accomplish the task in the intra- and inter-patient
settings with a success rate of $92\%$ and $46\%$, respectively. The results
also show that the introduction of image quality optimization in our method can
effectively improve the navigation performance.

    

### [[2103.01760] Transform Network Architectures for Deep Learning based End-to-End Image/Video Coding in Subsampled Color Spaces](http://arxiv.org/abs/2103.01760)


  Most of the existing deep learning based end-to-end image/video coding (DLEC)
architectures are designed for non-subsampled RGB color format. However, in
order to achieve a superior coding performance, many state-of-the-art
block-based compression standards such as High Efficiency Video Coding
(HEVC/H.265) and Versatile Video Coding (VVC/H.266) are designed primarily for
YUV 4:2:0 format, where U and V components are subsampled by considering the
human visual system. This paper investigates various DLEC designs to support
YUV 4:2:0 format by comparing their performance against the main profiles of
HEVC and VVC standards under a common evaluation framework. Moreover, a new
transform network architecture is proposed to improve the efficiency of coding
YUV 4:2:0 data. The experimental results on YUV 4:2:0 datasets show that the
proposed architecture significantly outperforms naive extensions of existing
architectures designed for RGB format and achieves about 10% average BD-rate
improvement over the intra-frame coding in HEVC.

    

### [[2103.15960] Demonstrating Analog Inference on the BrainScaleS-2 Mobile System](http://arxiv.org/abs/2103.15960)


  We present the BrainScaleS-2 mobile system as a compact analog inference
engine based on the BrainScaleS-2 ASIC and demonstrate its capabilities at
classifying a medical electrocardiogram dataset. The analog network core of the
ASIC is utilized to perform the multiply-accumulate operations of a
convolutional deep neural network. We measure a total energy consumption of
192uJ for the ASIC and achieve a classification time of 276us per
electrocardiographic patient sample. Patients with atrial fibrillation are
correctly identified with a detection rate of 93.7(7)% at 14.0(10)% false
positives. The system is directly applicable to edge inference applications due
to its small size, power envelope and flexible I/O capabilities. Possible
future applications can furthermore combine conventional machine learning
layers with online-learning in spiking neural networks on a single
BrainScaleS-2 ASIC. The system has successfully participated and proven to
operate reliably in the independently judged competition
"Pilotinnovationswettbewerb 'Energieeffizientes KI-System'" of the German
Federal Ministry of Education and Research (BMBF).

    

### [[2103.16219] SPatchGAN: A Statistical Feature Based Discriminator for Unsupervised Image-to-Image Translation](http://arxiv.org/abs/2103.16219)


  For unsupervised image-to-image translation, we propose a discriminator
architecture which focuses on the statistical features instead of individual
patches. The network is stabilized by distribution matching of key statistical
features at multiple scales. Unlike the existing methods which impose more and
more constraints on the generator, our method facilitates the shape deformation
and enhances the fine details with a greatly simplified framework. We show that
the proposed method outperforms the existing state-of-the-art models in various
challenging applications including selfie-to-anime, male-to-female and glasses
removal.

    

### [[2104.03643] Contextual Semi-Supervised Learning: An Approach To Leverage Air-Surveillance and Untranscribed ATC Data in ASR Systems](http://arxiv.org/abs/2104.03643)


  Air traffic management and specifically air-traffic control (ATC) rely mostly
on voice communications between Air Traffic Controllers (ATCos) and pilots. In
most cases, these voice communications follow a well-defined grammar that could
be leveraged in Automatic Speech Recognition (ASR) technologies. The callsign
used to address an airplane is an essential part of all ATCo-pilot
communications. We propose a two-steps approach to add contextual knowledge
during semi-supervised training to reduce the ASR system error rates at
recognizing the part of the utterance that contains the callsign. Initially, we
represent in a WFST the contextual knowledge (i.e. air-surveillance data) of an
ATCo-pilot communication. Then, during Semi-Supervised Learning (SSL) the
contextual knowledge is added by second-pass decoding (i.e. lattice
re-scoring). Results show that `unseen domains' (e.g. data from airports not
present in the supervised training data) are further aided by contextual SSL
when compared to standalone SSL. For this task, we introduce the Callsign Word
Error Rate (CA-WER) as an evaluation metric, which only assesses ASR
performance of the spoken callsign in an utterance. We obtained a 32.1% CA-WER
relative improvement applying SSL with an additional 17.5% CA-WER improvement
by adding contextual knowledge during SSL on a challenging ATC-based test set
gathered from LiveATC.

    

### [[2104.08809] SciCo: Hierarchical Cross-Document Coreference for Scientific Concepts](http://arxiv.org/abs/2104.08809)


  Determining coreference of concept mentions across multiple documents is a
fundamental task in natural language understanding. Work on cross-document
coreference resolution (CDCR) typically considers mentions of events in the
news, which seldom involve abstract technical concepts that are prevalent in
science and technology. These complex concepts take diverse or ambiguous forms
and have many hierarchical levels of granularity (e.g., tasks and subtasks),
posing challenges for CDCR. We present a new task of Hierarchical CDCR (H-CDCR)
with the goal of jointly inferring coreference clusters and hierarchy between
them. We create SciCo, an expert-annotated dataset for H-CDCR in scientific
papers, 3X larger than the prominent ECB+ resource. We study strong baseline
models that we customize for H-CDCR, and highlight challenges for future work.

    

### [[2105.03958] Towards Explainable, Privacy-Preserved Human-Motion Affect Recognition](http://arxiv.org/abs/2105.03958)


  Human motion characteristics are used to monitor the progression of
neurological diseases and mood disorders. Since perceptions of emotions are
also interleaved with body posture and movements, emotion recognition from
human gait can be used to quantitatively monitor mood changes. Many existing
solutions often use shallow machine learning models with raw positional data or
manually extracted features to achieve this. However, gait is composed of many
highly expressive characteristics that can be used to identify human subjects,
and most solutions fail to address this, disregarding the subject's privacy.
This work introduces a novel deep neural network architecture to disentangle
human emotions and biometrics. In particular, we propose a cross-subject
transfer learning technique for training a multi-encoder autoencoder deep
neural network to learn disentangled latent representations of human motion
features. By disentangling subject biometrics from the gait data, we show that
the subject's privacy is preserved while the affect recognition performance
outperforms traditional methods. Furthermore, we exploit Guided Grad-CAM to
provide global explanations of the model's decision across gait cycles. We
evaluate the effectiveness of our method to existing methods at recognizing
emotions using both 3D temporal joint signals and manually extracted features.
We also show that this data can easily be exploited to expose a subject's
identity. Our method shows up to 7% improvement and highlights the joints with
the most significant influence across the average gait cycle.

    

### [[2105.05633] Segmenter: Transformer for Semantic Segmentation](http://arxiv.org/abs/2105.05633)


  Image segmentation is often ambiguous at the level of individual image
patches and requires contextual information to reach label consensus. In this
paper we introduce Segmenter, a transformer model for semantic segmentation. In
contrast to convolution-based methods, our approach allows to model global
context already at the first layer and throughout the network. We build on the
recent Vision Transformer (ViT) and extend it to semantic segmentation. To do
so, we rely on the output embeddings corresponding to image patches and obtain
class labels from these embeddings with a point-wise linear decoder or a mask
transformer decoder. We leverage models pre-trained for image classification
and show that we can fine-tune them on moderate sized datasets available for
semantic segmentation. The linear decoder allows to obtain excellent results
already, but the performance can be further improved by a mask transformer
generating class masks. We conduct an extensive ablation study to show the
impact of the different parameters, in particular the performance is better for
large models and small patch sizes. Segmenter attains excellent results for
semantic segmentation. It outperforms the state of the art on both ADE20K and
Pascal Context datasets and is competitive on Cityscapes.

    

### [[2105.10430] Multi-Horizon Forecasting for Limit Order Books: Novel Deep Learning Approaches and Hardware Acceleration using Intelligent Processing Units](http://arxiv.org/abs/2105.10430)


  We design multi-horizon forecasting models for limit order book (LOB) data by
using deep learning techniques. Unlike standard structures where a single
prediction is made, we adopt encoder-decoder models with sequence-to-sequence
and Attention mechanisms to generate a forecasting path. Our methods achieve
comparable performance to state-of-art algorithms at short prediction horizons.
Importantly, they outperform when generating predictions over long horizons by
leveraging the multi-horizon setup. Given that encoder-decoder models rely on
recurrent neural layers, they generally suffer from slow training processes. To
remedy this, we experiment with utilising novel hardware, so-called Intelligent
Processing Units (IPUs) produced by Graphcore. IPUs are specifically designed
for machine intelligence workload with the aim to speed up the computation
process. We show that in our setup this leads to significantly faster training
times when compared to training models with GPUs.

    

### [[2106.03947] TENGraD: Time-Efficient Natural Gradient Descent with Exact Fisher-Block Inversion](http://arxiv.org/abs/2106.03947)


  This work proposes a time-efficient Natural Gradient Descent method, called
TENGraD, with linear convergence guarantees. Computing the inverse of the
neural network's Fisher information matrix is expensive in NGD because the
Fisher matrix is large. Approximate NGD methods such as KFAC attempt to improve
NGD's running time and practical application by reducing the Fisher matrix
inversion cost with approximation. However, the approximations do not reduce
the overall time significantly and lead to less accurate parameter updates and
loss of curvature information. TENGraD improves the time efficiency of NGD by
computing Fisher block inverses with a computationally efficient covariance
factorization and reuse method. It computes the inverse of each block exactly
using the Woodbury matrix identity to preserve curvature information while
admitting (linear) fast convergence rates. Our experiments on image
classification tasks for state-of-the-art deep neural architecture on CIFAR-10,
CIFAR-100, and Fashion-MNIST show that TENGraD significantly outperforms
state-of-the-art NGD methods and often stochastic gradient descent in
wall-clock time.

    

### [[2106.16239] Fixed points of monotonic and (weakly) scalable neural networks](http://arxiv.org/abs/2106.16239)


  We derive conditions for the existence of fixed points of neural networks, an
important research objective to understand their behavior in modern
applications involving autoencoders and loop unrolling techniques, among
others. In particular, we focus on networks with nonnegative inputs and
nonnegative network parameters, as often considered in the literature. We show
that such networks can be recognized as monotonic and (weakly) scalable
functions within the framework of nonlinear Perron-Frobenius theory. This fact
enables us to derive conditions for the existence of a nonempty fixed point set
of the neural networks, and these conditions are weaker than those obtained
recently using arguments in convex analysis, which are typically based on the
assumption of nonexpansivity of the activation functions. Furthermore, we prove
that the shape of the fixed point set of monotonic and weakly scalable neural
networks is often an interval, which degenerates to a point for the case of
scalable networks. The chief results of this paper are verified in numerical
simulations, where we consider an autoencoder-type network that first
compresses angular power spectra in massive MIMO systems, and, second,
reconstruct the input spectra from the compressed signal.

    

### [[2108.12213] Synthesis of Predictable Global NoC by Abutment in Synchoros VLSI Design](http://arxiv.org/abs/2108.12213)


  Synchoros VLSI design style has been proposed as an alternative to the
standard cell best design style; the word synchoros is derived from the Greek
word choros for space. Synchoricity discretises space with a virtual grid, the
way synchronicity discretises time with clock ticks. SiLago (Silicon Lego)
blocks are atomic synchoros building blocks like Lego bricks. SiLago blocks
absorb all metal layer details, i.e., all wires, to enable composition by
abutment of valid; valid in the sense of being technology design rules
compliant, timing clean and OCV ruggedized. Effectively, composition by
abutment eliminates logic and physical synthesis for the end user. Like Lego
system, synchoricity does need a finite number of SiLago block types to cater
to different types of designs. Global NoCs are important system level design
components. In this paper, we show, how with a small library of SiLago blocks
for global NoCs, it is possible to automatically synthesize arbitrary global
NoCs of different types, dimensions, and topology. The synthesized global NoCs
are not only valid VLSI designs, their cost metrics (area, latency, and energy)
are known with post-layout accuracy in linear time. We argue that this is
essential to be able to do chip-level design space exploration. We show how the
abstract timing model of such global NoC SiLago blocks can be built and used to
analyse the timing of global NoC links with post layout accuracy and in linear
time. We validate this claim by subjecting the same VLSI designs of global NoC
to commercial EDA's static timing analysis and show that the abstract timing
analysis enabled by synchoros VLSI design gives same results as the commercial
EDA tools.

    

### [[2108.12292] Terabit-per-Second Multicore Polar Code Successive Cancellation Decoders](http://arxiv.org/abs/2108.12292)


  This work presents a high throughput and energy efficient multicore (MC)
successive cancellation (SC) decoder architecture for polar codes. SC is a
low-complexity decoding algorithm with a set of sequential operations. The
sequential processing nature of SC limits parallelism but promotes not only
pipelining but also multiple copies of SC decoder with an optimized pipeline
depth to achieve Tb/s throughput. The MCSC decoder architecture consists of
multiple SC decoders with lower frequency and pipeline depth to process
multiple codewords in parallel to achieve lower power consumption. The pipeline
depth of MCSC is optimized separately for each multicore configuration using
register reduction/balancing (R-RB) method. This enables an efficient
implementation for the 1-core, 2-core 4-core and 8-core candidate MCSC
decoders. To reduce the complexity of the implementation, an adaptive
log-likelihood ratio (LLR) quantization scheme is used for internal LLRs within
the range of 1-5 bits. The post-placement-routing results at 28nm High-k Metal
Gate (HKMG) ASIC technology show that 4-core MCSC decoder achieves 1 Tb/s
throughput on 3.92 mm$^2$ area with 1.55 pJ/bit energy efficiency.

    

### [[2108.11957] SVM Classifier on Chip for Melanoma Detection](http://arxiv.org/abs/2108.11957)


  Support Vector Machine (SVM) is a common classifier used for efficient
classification with high accuracy. SVM shows high accuracy for classifying
melanoma (skin cancer) clinical images within computer-aided diagnosis systems
used by skin cancer specialists to detect melanoma early and save lives. We aim
to develop a medical low-cost handheld device that runs a real-time embedded
SVM- based diagnosis system for use in primary care for early detection of
melanoma. In this paper, an optimized SVM classifier is implemented onto a
recent FPGA platform using the latest design methodology to be embedded into
the proposed device for realizing online efficient melanoma detection on a
single system on chip/device. The hardware implementation results demonstrate a
high classification accuracy of 97.9% and a significant acceleration factor of
26 from equivalent software implementation on an embedded processor, with 34%
of resources utilization and 2 watts for power consumption. Consequently, the
implemented system meets crucial embedded systems constraints of high
performance and low cost, resources utilization and power consumption, while
achieving high classification accuracy.

    

### [[2108.12188] A High-Fidelity Flow Solver for Unstructured Meshes on Field-Programmable Gate Arrays](http://arxiv.org/abs/2108.12188)


  The impending termination of Moore's law motivates the search for new forms
of computing to continue the performance scaling we have grown accustomed to.
Among the many emerging \textit{Post-Moore} computing candidates, perhaps none
is as salient as the Field-Programmable Gate Array (FPGA), which offers the
means of specializing and customizing the hardware to the computation at hand.
In this work, we design a custom FPGA-based accelerator for a computational
fluid dynamics (CFD) code. Unlike prior work -- which often focuses on
accelerating small kernels -- we target the entire unstructured Poisson solver
based on the high-fidelity spectral element method (SEM) used in modern
state-of-the-art CFD systems. We model our accelerator using an analytical
performance model based on the I/O cost of the algorithm. We empirically
evaluate our accelerator on a state-of-the-art Intel Stratix 10 FPGA in terms
of performance and power consumption and contrast it against existing solutions
on general-purpose processors (CPUs). Finally, we propose a novel I/O-reducing
technique where we compute geometric factors on the fly, which yields
significant (700+ GFlop/s) single-precision performance and an upwards of 2x
reduction in runtime for the local evaluation of the Laplace operator.
We end the paper by discussing the challenges and opportunities of using
reconfigurable architecture in the future, particularly in the light of
emerging (not yet available) technologies.

    

### [[2108.12214] Machine Learning for Performance Prediction of Spark Cloud Applications](http://arxiv.org/abs/2108.12214)


  Big data applications and analytics are employed in many sectors for a
variety of goals: improving customers satisfaction, predicting market behavior
or improving processes in public health. These applications consist of complex
software stacks that are often run on cloud systems. Predicting execution times
is important for estimating the cost of cloud services and for effectively
managing the underlying resources at runtime. Machine Learning (ML), providing
black box solutions to model the relationship between application performance
and system configuration without requiring in-detail knowledge of the system,
has become a popular way of predicting the performance of big data
applications. We investigate the cost-benefits of using supervised ML models
for predicting the performance of applications on Spark, one of today's most
widely used frameworks for big data analysis. We compare our approach with
\textit{Ernest} (an ML-based technique proposed in the literature by the Spark
inventors) on a range of scenarios, application workloads, and cloud system
configurations. Our experiments show that Ernest can accurately estimate the
performance of very regular applications, but it fails when applications
exhibit more irregular patterns and/or when extrapolating on bigger data set
sizes. Results show that our models match or exceed Ernest's performance,
sometimes enabling us to reduce the prediction error from 126-187% to only
5-19%.

    

### [[2108.12240] Optimizing the hybrid parallelization of BHAC](http://arxiv.org/abs/2108.12240)


  We present our experience with the modernization on the GR-MHD code BHAC,
aimed at improving its novel hybrid (MPI+OpenMP) parallelization scheme. In
doing so, we showcase the use of performance profiling tools usable on x86
(Intel-based) architectures. Our performance characterization and threading
analysis provided guidance in improving the concurrency and thus the efficiency
of the OpenMP parallel regions. We assess scaling and communication patterns in
order to identify and alleviate MPI bottlenecks, with both runtime switches and
precise code interventions. The performance of optimized version of BHAC
improved by $\sim28\%$, making it viable for scaling on several hundreds of
supercomputer nodes. We finally test whether porting such optimizations to
different hardware is likewise beneficial on the new architecture by running on
ARM A64FX vector nodes.

    

### [[2108.12315] Rule-based Adaptations to Control Cybersickness in Social Virtual Reality Learning Environments](http://arxiv.org/abs/2108.12315)


  Social virtual reality learning environments (VRLEs) provide immersive
experience to users with increased accessibility to remote learning. Lack of
maintaining high-performance and secured data delivery in critical VRLE
application domains (e.g., military training, manufacturing) can disrupt
application functionality and induce cybersickness. In this paper, we present a
novel rule-based 3QS-adaptation framework that performs risk and cost aware
trade-off analysis to control cybersickness due to performance/security anomaly
events during a VRLE session. Our framework implementation in a social VRLE
viz., vSocial monitors performance/security anomaly events in network/session
data. In the event of an anomaly, the framework features rule-based adaptations
that are triggered by using various decision metrics. Based on our experimental
results, we demonstrate the effectiveness of our rule-based 3QS-adaptation
framework in reducing cybersickness levels, while maintaining application
functionality. Using our key findings, we enlist suitable practices for
addressing performance and security issues towards a more high-performing and
robust social VRLE.

    

### [[2108.12387] NimbleChain: Low-latency consensusless cryptocurrencies in general-purpose permissionless blockchains](http://arxiv.org/abs/2108.12387)


  Nakamoto's seminal work gave rise to permissionless blockchains -- as well as
a wide range of proposals to mitigate its performance shortcomings. Despite
substantial throughput and energy efficiency achievements, most proposals only
bring modest (or marginal) gains in transaction commit latency. Consequently,
commit latencies in today's permissionless blockchain landscape remain
prohibitively high for latency-sensitive geo-distributed applications. This
paper proposes NimbleChain, which extends standard permissionless blockchains
with a fast path that delivers consensusless promises of commitment. This fast
path supports cryptocurrency transactions and only takes a small fraction of
the original commit latency, while providing consistency guarantees that are
strong enough to ensure correct cryptocurrencies. Since today's general-purpose
blockchains also support smart contract transactions, which typically have
(strong) sequential consistency needs, NimbleChain implements a hybrid
consistency model that also supports strongly-consistent applications. To the
best of our knowledge, NimbleChain is the first system to bring together fast
consensusless transactions with strongly-consistent consensus-based
transactions in a permissionless setting. We implement NimbleChain as an
extension of Ethereum and evaluate it in a 500-node geo-distributed deployment.
The results show that the average latency to promise a transaction is an order
of magnitude faster than consensus-based commit, with minimal overhead when
compared with a vanilla Ethereum implementation.

    

### [[2103.08675] Cost-aware Integration Process Modeling in Multiclouds](http://arxiv.org/abs/2103.08675)


  Integration as a service (INTaaS) is the centrepiece of current corporate,
cloud and device integration processes. Thereby, compositions of integration
patterns denote the required integration logic as integration processes,
currently running in single-clouds. While multicloud settings gain importance,
their promised freedom of selecting the best option for a specific problem is
currently not realized as well as security constraints are handled in a
cost-intensive manner for the INTaaS vendors, leading to security vs. costs
goal conflicts, and intransparent to the process modeler.
In this work, we propose a design-time placement for processes in multiclouds
that is cost-optimal for INTaaS problem sizes, and respects configurable
security constraints of their customers. To make the solution tractable for
larger, productive INTaaS processes, it is relaxed by using a local search
heuristic, and complemented by correctness-preserving model decomposition. This
allows for a novel perspective on cost-aware process modeling from a process
modeler's perspective.
The multicloud process placement is evaluated on real-world integration
processes with respect to cost- and runtime-efficiency, and discusses
interesting trade-offs. The process modeler's perspective is investigated based
on a new cost-aware modeling process, featuring the interaction between the
user and the INTaaS vendor through ad-hoc multicloud cost calculation and
correctness-preserving, process cost reduction proposals.

    

### [[2108.11954] Cascading Neural Network Methodology for Artificial Intelligence-Assisted Radiographic Detection and Classification of Lead-Less Implanted Electronic Devices within the Chest](http://arxiv.org/abs/2108.11954)


  Background & Purpose: Chest X-Ray (CXR) use in pre-MRI safety screening for
Lead-Less Implanted Electronic Devices (LLIEDs), easily overlooked or
misidentified on a frontal view (often only acquired), is common. Although most
LLIED types are "MRI conditional": 1. Some are stringently conditional; 2.
Different conditional types have specific patient- or device- management
requirements; and 3. Particular types are "MRI unsafe". This work focused on
developing CXR interpretation-assisting Artificial Intelligence (AI)
methodology with: 1. 100% detection for LLIED presence/location; and 2. High
classification in LLIED typing. Materials & Methods: Data-mining
(03/1993-02/2021) produced an AI Model Development Population (1,100
patients/4,871 images) creating 4,924 LLIED Region-Of-Interests (ROIs) (with
image-quality grading) used in Training, Validation, and Testing. For
developing the cascading neural network (detection via Faster R-CNN and
classification via Inception V3), "ground-truth" CXR annotation (ROI labeling
per LLIED), as well as inference display (as Generated Bounding Boxes (GBBs)),
relied on a GPU-based graphical user interface. Results: To achieve 100% LLIED
detection, probability threshold reduction to 0.00002 was required by Model 1,
resulting in increasing GBBs per LLIED-related ROI. Targeting LLIED-type
classification following detection of all LLIEDs, Model 2 multi-classified to
reach high-performance while decreasing falsely positive GBBs. Despite 24%
suboptimal ROI image quality, classification was correct in 98.9% and AUCs for
the 9 LLIED-types were 1.00 for 8 and 0.92 for 1. For all misclassification
cases: 1. None involved stringently conditional or unsafe LLIEDs; and 2. Most
were attributable to suboptimal images. Conclusion: This project successfully
developed a LLIED-related AI methodology supporting: 1. 100% detection; and 2.
Typically 100% type classification.

    

### [[2108.11994] A New Sentence Ordering Method Using BERT Pretrained Model](http://arxiv.org/abs/2108.11994)


  Building systems with capability of natural language understanding (NLU) has
been one of the oldest areas of AI. An essential component of NLU is to detect
logical succession of events contained in a text. The task of sentence ordering
is proposed to learn succession of events with applications in AI tasks. The
performance of previous works employing statistical methods is poor, while the
neural networks-based approaches are in serious need of large corpora for model
learning. In this paper, we propose a method for sentence ordering which does
not need a training phase and consequently a large corpus for learning. To this
end, we generate sentence embedding using BERT pre-trained model and measure
sentence similarity using cosine similarity score. We suggest this score as an
indicator of sequential events' level of coherence. We finally sort the
sentences through brute-force search to maximize overall similarities of the
sequenced sentences. Our proposed method outperformed other baselines on
ROCStories, a corpus of 5-sentence human-made stories. The method is
specifically more efficient than neural network-based methods when no huge
corpus is available. Among other advantages of this method are its
interpretability and needlessness to linguistic knowledge.

    

### [[2108.12026] Semantic-based Self-Critical Training For Question Generation](http://arxiv.org/abs/2108.12026)


  We present in this work a fully Transformer-based reinforcement learning
generator-evaluator architecture for neural question generation. Question
generation is a task that consists in generating questions given a context and
answer. To improve the quality of the generated question, we came up with a
semantic-based self-critical training layout in generator-evaluator
architecture, which goes beyond typical maximum likelihood training. Evaluation
metrics for language modeling only based on n-gram overlapping do not consider
semantic relations between reference and candidate strings. To improve the
evaluation step, we assess our model for both n-gram overlap using BLEU and
semantically using BERTScore and NUBIA, a novel state-of-the-art evaluation
metric for text generation. Question generation could be used in many
downstream applications, including in extending question answering datasets,
conversational systems, and educational assessment systems.

    

### [[2108.12128] Task-aware Warping Factors in Mask-based Speech Enhancement](http://arxiv.org/abs/2108.12128)


  This paper proposes the use of two task-aware warping factors in mask-based
speech enhancement (SE). One controls the balance between speech-maintenance
and noise-removal in training phases, while the other controls SE power applied
to specific downstream tasks in testing phases. Our intention is to alleviate
the problem that SE systems trained to improve speech quality often fail to
improve other downstream tasks, such as automatic speaker verification (ASV)
and automatic speech recognition (ASR), because they do not share the same
objects. It is easy to apply the proposed dual-warping factors approach to any
mask-based SE method, and it allows a single SE system to handle multiple tasks
without task-dependent training. The effectiveness of our proposed approach has
been confirmed on the SITW dataset for ASV evaluation and the LibriSpeech
dataset for ASR and speech quality evaluations of 0-20dB. We show that
different warping values are necessary for a single SE to achieve optimal
performance w.r.t. the three tasks. With the use of task-dependent warping
factors, speech quality was improved by an 84.7% PESQ increase, ASV had a 22.4%
EER reduction, and ASR had a 52.2% WER reduction, on 0dB speech. The
effectiveness of the task-dependent warping factors were also cross-validated
on VoxCeleb-1 test set for ASV and LibriSpeech dev-clean set for ASV and
quality evaluations. The proposed method is highly effective and easy to apply
in practice.

    

### [[2108.12134] WAD: A Deep Reinforcement Learning Agent for Urban Autonomous Driving](http://arxiv.org/abs/2108.12134)


  Urban autonomous driving is an open and challenging problem to solve as the
decision-making system has to account for several dynamic factors like
multi-agent interactions, diverse scene perceptions, complex road geometries,
and other rarely occurring real-world events. On the other side, with deep
reinforcement learning (DRL) techniques, agents have learned many complex
policies. They have even achieved super-human-level performances in various
Atari Games and Deepmind's AlphaGo. However, current DRL techniques do not
generalize well on complex urban driving scenarios. This paper introduces the
DRL driven Watch and Drive (WAD) agent for end-to-end urban autonomous driving.
Motivated by recent advancements, the study aims to detect important
objects/states in high dimensional spaces of CARLA and extract the latent state
from them. Further, passing on the latent state information to WAD agents based
on TD3 and SAC methods to learn the optimal driving policy. Our novel approach
utilizing fewer resources, step-by-step learning of different driving tasks,
hard episode termination policy, and reward mechanism has led our agents to
achieve a 100% success rate on all driving tasks in the original CARLA
benchmark and set a new record of 82% on further complex NoCrash benchmark,
outperforming the state-of-the-art model by more than +30% on NoCrash
benchmark.

    

### [[2108.12144] Lyra: A Benchmark for Turducken-Style Code Generation](http://arxiv.org/abs/2108.12144)


  Code generation is crucial to reduce manual software development efforts.
Recently, neural techniques have been used to generate source code
automatically. While promising, these approaches are evaluated on tasks for
generating code in single programming languages. However, in actual
development, one programming language is often embedded in another. For
example, SQL statements are often embedded as strings in base programming
languages such as Python and Java, and JavaScript programs are often embedded
in sever-side programming languages, such as PHP, Java, and Python. We call
this a turducken-style programming. In this paper, we define a new code
generation task: given a natural language comment, this task aims to generate a
program in a base language with an embedded language. To our knowledge, this is
the first turducken-style code generation task. For this task, we present Lyra:
a dataset in Python with embedded SQL. This dataset contains 2,000 carefully
annotated database manipulation programs from real usage projects. Each program
is paired with both a Chinese comment and an English comment. In our
experiment, we adopted Transformer, a state-of-the-art technique, as the
baseline. In the best setting, Transformer achieves 0.5% and 1.5% AST exact
matching accuracy using Chinese and English comments, respectively. Therefore,
we believe that Lyra provides a new challenge for code generation.

    

### [[2108.12149] Cleaning Inconsistent Data in Temporal DL-Lite Under Best Repair Semantics](http://arxiv.org/abs/2108.12149)


  In this paper, we address the problem of handling inconsistent data in
Temporal Description Logic (TDL) knowledge bases. Considering the data part of
the Knowledge Base as the source of inconsistency over time, we propose an ABox
repair approach. This is the first work handling the repair in TDL Knowledge
bases. To do so, our goal is twofold: 1) detect temporal inconsistencies and 2)
propose a data temporal reparation. For the inconsistency detection, we propose
a reduction approach from TDL to DL which allows to provide a tight NP-complete
upper bound for TDL concept satisfiability and to use highly optimised DL
reasoners that can bring precise explanation (the set of inconsistent data
assertions). Thereafter, from the obtained explanation, we propose a method for
automatically computing the best repair in the temporal setting based on the
allowed rigid predicates and the time order of assertions.

    

### [[2108.12184] GLocal-K: Global and Local Kernels for Recommender Systems](http://arxiv.org/abs/2108.12184)


  Recommender systems typically operate on high-dimensional sparse user-item
matrices. Matrix completion is a very challenging task to predict one's
interest based on millions of other users having each seen a small subset of
thousands of items. We propose a Global-Local Kernel-based matrix completion
framework, named GLocal-K, that aims to generalise and represent a
high-dimensional sparse user-item matrix entry into a low dimensional space
with a small number of important features. Our GLocal-K can be divided into two
major stages. First, we pre-train an auto encoder with the local kernelised
weight matrix, which transforms the data from one space into the feature space
by using a 2d-RBF kernel. Then, the pre-trained auto encoder is fine-tuned with
the rating matrix, produced by a convolution-based global kernel, which
captures the characteristics of each item. We apply our GLocal-K model under
the extreme low-resource setting, which includes only a user-item rating
matrix, with no side information. Our model outperforms the state-of-the-art
baselines on three collaborative filtering benchmarks: ML-100K, ML-1M, and
Douban.

    

### [[2108.12237] Evaluating the Robustness of Neural Language Models to Input Perturbations](http://arxiv.org/abs/2108.12237)


  High-performance neural language models have obtained state-of-the-art
results on a wide range of Natural Language Processing (NLP) tasks. However,
results for common benchmark datasets often do not reflect model reliability
and robustness when applied to noisy, real-world data. In this study, we design
and implement various types of character-level and word-level perturbation
methods to simulate realistic scenarios in which input texts may be slightly
noisy or different from the data distribution on which NLP systems were
trained. Conducting comprehensive experiments on different NLP tasks, we
investigate the ability of high-performance language models such as BERT,
XLNet, RoBERTa, and ELMo in handling different types of input perturbations.
The results suggest that language models are sensitive to input perturbations
and their performance can decrease even when small changes are introduced. We
highlight that models need to be further improved and that current benchmarks
are not reflecting model robustness well. We argue that evaluations on
perturbed inputs should routinely complement widely-used benchmarks in order to
yield a more realistic understanding of NLP systems robustness.

    

### [[2108.12239] Geometric Models for (Temporally) Attributed Description Logics](http://arxiv.org/abs/2108.12239)


  In the search for knowledge graph embeddings that could capture ontological
knowledge, geometric models of existential rules have been recently introduced.
It has been shown that convex geometric regions capture the so-called
quasi-chained rules. Attributed description logics (DL) have been defined to
bridge the gap between DL languages and knowledge graphs, whose facts often
come with various kinds of annotations that may need to be taken into account
for reasoning. In particular, temporally attributed DLs are enriched by
specific attributes whose semantics allows for some temporal reasoning.
Considering that geometric models and (temporally) attributed DLs are promising
tools designed for knowledge graphs, this paper investigates their
compatibility, focusing on the attributed version of a Horn dialect of the
DL-Lite family. We first adapt the definition of geometric models to attributed
DLs and show that every satisfiable ontology has a convex geometric model. Our
second contribution is a study of the impact of temporal attributes. We show
that a temporally attributed DL may not have a convex geometric model in
general but we can recover geometric satisfiability by imposing some
restrictions on the use of the temporal attributes.

    

### [[2108.12242] Deep learning models are not robust against noise in clinical text](http://arxiv.org/abs/2108.12242)


  Artificial Intelligence (AI) systems are attracting increasing interest in
the medical domain due to their ability to learn complicated tasks that require
human intelligence and expert knowledge. AI systems that utilize
high-performance Natural Language Processing (NLP) models have achieved
state-of-the-art results on a wide variety of clinical text processing
benchmarks. They have even outperformed human accuracy on some tasks. However,
performance evaluation of such AI systems have been limited to accuracy
measures on curated and clean benchmark datasets that may not properly reflect
how robustly these systems can operate in real-world situations. In order to
address this challenge, we introduce and implement a wide variety of
perturbation methods that simulate different types of noise and variability in
clinical text data. While noisy samples produced by these perturbation methods
can often be understood by humans, they may cause AI systems to make erroneous
decisions. Conducting extensive experiments on several clinical text processing
tasks, we evaluated the robustness of high-performance NLP models against
various types of character-level and word-level noise. The results revealed
that the NLP models performance degrades when the input contains small amounts
of noise. This study is a significant step towards exposing vulnerabilities of
AI models utilized in clinical text processing systems. The proposed
perturbation methods can be used in performance evaluation tests to assess how
robustly clinical NLP models can operate on noisy data, in real-world settings.

    

### [[2108.12276] End-To-End Anomaly Detection for Identifying Malicious Cyber Behavior through NLP-Based Log Embeddings](http://arxiv.org/abs/2108.12276)


  Rule-based IDS (intrusion detection systems) are being replaced by more
robust neural IDS, which demonstrate great potential in the field of
Cybersecurity. However, these ML approaches continue to rely on ad-hoc feature
engineering techniques, which lack the capacity to vectorize inputs in ways
that are fully relevant to the discovery of anomalous cyber activity. We
propose a deep end-to-end framework with NLP-inspired components for
identifying potentially malicious behaviors on enterprise computer networks. We
also demonstrate the efficacy of this technique on the recently released DARPA
OpTC data set.

    

### [[2108.12290] Music Composition with Deep Learning: A Review](http://arxiv.org/abs/2108.12290)


  Generating a complex work of art such as a musical composition requires
exhibiting true creativity that depends on a variety of factors that are
related to the hierarchy of musical language. Music generation have been faced
with Algorithmic methods and recently, with Deep Learning models that are being
used in other fields such as Computer Vision. In this paper we want to put into
context the existing relationships between AI-based music composition models
and human musical composition and creativity processes. We give an overview of
the recent Deep Learning models for music composition and we compare these
models to the music composition process from a theoretical point of view. We
have tried to answer some of the most relevant open questions for this task by
analyzing the ability of current Deep Learning models to generate music with
creativity or the similarity between AI and human composition processes, among
others.

    

### [[2108.12313] TE-YOLOF: Tiny and efficient YOLOF for blood cell detection](http://arxiv.org/abs/2108.12313)


  Blood cell detection in microscopic images is an essential branch of medical
image processing research. Since disease detection based on manual checking of
blood cells is time-consuming and full of errors, testing of blood cells using
object detectors with Deep Convolutional Neural Network can be regarded as a
feasible solution. In this work, an object detector based on YOLOF has been
proposed to detect blood cell objects such as red blood cells, white blood
cells and platelets. This object detector is called TE-YOLOF, Tiny and
Efficient YOLOF, and it is a One-Stage detector using dilated encoder to
extract information from single-level feature maps. For increasing efficiency
and flexibility, the EfficientNet Convolutional Neural Network is utilized as
the backbone for the proposed object detector. Furthermore, the Depthwise
Separable Convolution is applied to enhance the performance and minimize the
parameters of the network. In addition, the Mish activation function is
employed to increase the precision. Extensive experiments on the BCCD dataset
prove the effectiveness of the proposed model, which is more efficient than
other existing studies for blood cell detection.

    

### [[2108.12330] SMT-Based Safety Verification of Data-Aware Processes under Ontologies (Extended Version)](http://arxiv.org/abs/2108.12330)


  In the context of verification of data-aware processes (DAPs), a formal
approach based on satisfiability modulo theories (SMT) has been considered to
verify parameterised safety properties of so-called artifact-centric systems.
This approach requires a combination of model-theoretic notions and algorithmic
techniques based on backward reachability. We introduce here a variant of one
of the most investigated models in this spectrum, namely simple artifact
systems (SASs), where, instead of managing a database, we operate over a
description logic (DL) ontology expressed in (a slight extension of) RDFS. This
DL, enjoying suitable model-theoretic properties, allows us to define DL-based
SASs to which backward reachability can still be applied, leading to
decidability in PSPACE of the corresponding safety problems.

    

### [[2108.12333] Integrating Heuristics and Learning in a Computational Architecture for Cognitive Trading](http://arxiv.org/abs/2108.12333)


  The successes of Artificial Intelligence in recent years in areas such as
image analysis, natural language understanding and strategy games have sparked
interest from the world of finance. Specifically, there are high expectations,
and ongoing engineering projects, regarding the creation of artificial agents,
known as robotic traders, capable of juggling the financial markets with the
skill of experienced human traders. Obvious economic implications aside, this
is certainly an area of great scientific interest, due to the challenges that
such a real context poses to the use of AI techniques. Precisely for this
reason, we must be aware that artificial agents capable of operating at such
levels are not just round the corner, and that there will be no simple answers,
but rather a concurrence of various technologies and methods to the success of
the effort. In the course of this article, we review the issues inherent in the
design of effective robotic traders as well as the consequently applicable
solutions, having in view the general objective of bringing the current state
of the art of robo-trading up to the next level of intelligence, which we refer
to as Cognitive Trading. Key to our approach is the joining of two
methodological and technological directions which, although both deeply rooted
in the disciplinary field of artificial intelligence, have so far gone their
separate ways: heuristics and learning.

    

### [[2101.00433] Modeling Disclosive Transparency in NLP Application Descriptions](http://arxiv.org/abs/2101.00433)


  Broader disclosive transparency$-$truth and clarity in communication
regarding the function of AI systems$-$is widely considered desirable.
Unfortunately, it is a nebulous concept, difficult to both define and quantify.
This is problematic, as previous work has demonstrated possible trade-offs and
negative consequences to disclosive transparency, such as a confusion effect,
where 'too much information' clouds a reader's understanding of what a system
description means. Disclosive transparency's subjective nature has rendered
deep study into these problems and their remedies difficult. To improve this
state of affairs, We introduce neural language model-based probabilistic
metrics to directly model disclosive transparency, and demonstrate that they
correlate with user and expert opinions of system transparency, making them a
valid objective proxy. Finally, we demonstrate the use of these metrics in a
pilot study quantifying the relationships between transparency, confusion, and
user perceptions in a corpus of real NLP system descriptions.

    

### [[2102.08453] Towards the Right Kind of Fairness in AI](http://arxiv.org/abs/2102.08453)


  Fairness is a concept of justice. Various definitions exist, some of them
conflicting with each other. In the absence of an uniformly accepted notion of
fairness, choosing the right kind for a specific situation has always been a
central issue in human history. When it comes to implementing sustainable
fairness in artificial intelligence systems, this old question plays a key role
once again: How to identify the most appropriate fairness metric for a
particular application? The answer is often a matter of context, and the best
choice depends on ethical standards and legal requirements. Since ethics
guidelines on this topic are kept rather general for now, we aim to provide
more hands-on guidance with this document. Therefore, we first structure the
complex landscape of existing fairness metrics and explain the different
options by example. Furthermore, we propose the "Fairness Compass", a tool
which formalises the selection process and makes identifying the most
appropriate fairness definition for a given system a simple, straightforward
procedure. Because this process also allows to document the reasoning behind
the respective decisions, we argue that this approach can help to build trust
from the user through explaining and justifying the implemented fairness.

    

### [[2104.05773] Approximate Computing for Robotic path planning -- Experimentation, Case Study and Practical Implications](http://arxiv.org/abs/2104.05773)


  Approximate computing is a computation domain which can be used to trade time
and energy with quality and therefore is useful in embedded systems. Energy is
the prime resource in battery-driven embedded systems, like robots. Approximate
computing can be used as a technique to generate approximate version of the
control functionalities of a robot, enabling it to ration energy for
computation at the cost of degraded quality. Usually, the programmer of the
function specifies the extent of degradation that is safe for the overall
safety of the system. However, in a collaborative environment, where several
sub-systems co-exist and some of the functionality of each of them have been
approximated, the safety of the overall system may be compromised. In this
paper, we consider multiple identical robots operate in a warehouse, and the
path planning function of the robot is approximated. Although the planned paths
are safe for individual robots (i.e. they do not collide with the racks), we
show that this leads to a collision among the robots. So, a controlled
approximation needs to be carried out in such situations to harness the full
power of this new paradigm if it needs to be a mainstream paradigm in future.

    

### [[2104.06669] NAREOR: The Narrative Reordering Problem](http://arxiv.org/abs/2104.06669)


  We propose the task of Narrative Reordering (NAREOR) which involves rewriting
a given story in a different narrative order while preserving its plot. We
present a dataset, NAREORC, with human rewritings of stories within ROCStories
in non-linear orders, and conduct a detailed analysis of it. Further, we
propose novel task-specific training methods with suitable evaluation metrics.
We perform experiments on NAREORC using state-of-the-art models such as BART
and T5 and conduct extensive automatic and human evaluations. We demonstrate
that NAREOR is a challenging task with potential for further exploration.

    

### [[2105.04475] Self-Guided Curriculum Learning for Neural Machine Translation](http://arxiv.org/abs/2105.04475)


  In the field of machine learning, the well-trained model is assumed to be
able to recover the training labels, i.e. the synthetic labels predicted by the
model should be as close to the ground-truth labels as possible. Inspired by
this, we propose a self-guided curriculum strategy to encourage the learning of
neural machine translation (NMT) models to follow the above recovery criterion,
where we cast the recovery degree of each training example as its learning
difficulty. Specifically, we adopt the sentence level BLEU score as the proxy
of recovery degree. Different from existing curricula relying on linguistic
prior knowledge or third-party language models, our chosen learning difficulty
is more suitable to measure the degree of knowledge mastery of the NMT models.
Experiments on translation benchmarks, including WMT14
English$\Rightarrow$German and WMT17 Chinese$\Rightarrow$English, demonstrate
that our approach can consistently improve translation performance against
strong baseline Transformer.

    

### [[2108.12223] On the Representation of Correlated Exponential Distributions by Phase Type Distributions](http://arxiv.org/abs/2108.12223)


  In this paper we present results for bivariate exponential distributions
which are represented by phase type distributions. The paper extends results
from previous publications [5, 14] on this topic by introducing new
representations that require a smaller number of phases to reach some
correlation coefficient and introduces different ways to describe correlation
between exponentially distributed random variables. Furthermore, it is shown
how Markovian Arrival Processes (MAPs) with exponential marginal distribution
can be generated from the phase type representations of exponential
distributions and how the results for exponential distributions can be applied
to define correlated hyperexponential or Erlang distributions. As application
examples we analyze two queueing models with correlated inter-arrival and
service times.

    

### [[2108.12348] A denotational semantics for PROMELA addressing arbitrary jumps](http://arxiv.org/abs/2108.12348)


  PROMELA (Process Meta Language) is a high-level specification language
designed for modeling interactions in distributed systems. PROMELA is used as
the input language for the model checker SPIN (Simple Promela INterpreter). The
main characteristics of PROMELA are non-determinism, process communication
through synchronous as well as asynchronous channels, and the possibility to
dynamically create instances of processes.
In this paper, we introduce a bottom-up, fixpoint semantics that aims to
model the behavior of PROMELA programs. This work is the first step towards a
more ambitious goal where analysis and verification techniques based on
abstract interpretation would be defined on top of such semantics.

    

### [[2102.10698] Certifying Choreography Compilation](http://arxiv.org/abs/2102.10698)


  Choreographic programming is a paradigm for developing concurrent and
distributed systems, where programs are choreographies that define, from a
global viewpoint, the computations and interactions that communicating
processes should enact. Choreography compilation translates choreographies into
the local definitions of process behaviours, given as terms in a process
calculus.
Proving choreography compilation correct is challenging and error-prone,
because it requires relating languages in different paradigms (global
interactions vs local actions) and dealing with a combinatorial explosion of
proof cases. We present the first certified program for choreography
compilation for a nontrivial choreographic language supporting recursion.

    