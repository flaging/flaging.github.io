
## 2021-10-29

### [<title>「今日发布」苏州如何开具信息服务费发票《手机搜狐网》 - DockOne.io</title>](http://dockone.io/question/1466303)

### [<title>今日发布四平如何代开医院全套住院证明(出院病历-四平医务 - DockOne.io</title>](http://dockone.io/question/1466302)

### [<title>「今日发布」宁波如何开具信息服务费发票《手机搜狐网》 - DockOne.io</title>](http://dockone.io/question/1466301)

### [<title>今日医务绍兴开医院诊断证明(开医院检查单化验单 - DockOne.io</title>](http://dockone.io/question/1466299)

### [<title>「今日发布」湖南如何可以开具增值税专用发票「重大消息」 - DockOne.io</title>](http://dockone.io/question/1466300)

### [<title>「今日发布」郑州如何开具信息服务费发票《手机搜狐网》 - DockOne.io</title>](http://dockone.io/question/1466298)

### [<title>「今日发布」哈尔滨如何可以开具增值税专用发票「重大消息」 - DockOne.io</title>](http://dockone.io/question/1466297)

### [<title>「今日发布」重庆如何开具信息服务费发票《手机搜狐网》 - DockOne.io</title>](http://dockone.io/question/1466296)

### [<title>今日发布吉林如何代开医院全套住院证明(出院病历-吉林医务 - DockOne.io</title>](http://dockone.io/question/1466295)

### [<title>今日医务乌鲁木齐开医院诊断证明(开医院检查单化验单 - DockOne.io</title>](http://dockone.io/question/1466294)

### [<title>「今日发布」天津如何开具信息服务费发票《手机搜狐网》 - DockOne.io</title>](http://dockone.io/question/1466293)

### [<title>「今日发布」杭州如何开具信息服务费发票《手机搜狐网》 - DockOne.io</title>](http://dockone.io/question/1466292)

### [<title>今日发布长春如何代开医院全套住院证明(出院病历-长春医务 - DockOne.io</title>](http://dockone.io/question/1466291)

### [<title>「今日发布」黑龙江如何可以开具增值税专用发票「重大消息」 - DockOne.io</title>](http://dockone.io/question/1466289)

### [<title>今日医务海口开医院诊断证明(开医院检查单化验单 - DockOne.io</title>](http://dockone.io/question/1466290)

### [<title>今日发布葫芦岛如何代开医院全套住院证明(出院病历-葫芦岛医务 - DockOne.io</title>](http://dockone.io/question/1466288)

### [<title>「今日发布」成都如何开具信息服务费发票《手机搜狐网》 - DockOne.io</title>](http://dockone.io/question/1466287)

### [<title>今日发布盘锦如何代开医院全套住院证明(出院病历-盘锦医务 - DockOne.io</title>](http://dockone.io/question/1466286)

### [<title>「今日发布」石家庄如何可以开具增值税专用发票「重大消息」 - DockOne.io</title>](http://dockone.io/question/1466285)

### [<title>「今日发布」广州如何开具信息服务费发票《手机搜狐网》 - DockOne.io</title>](http://dockone.io/question/1466284)

### [<title>「今日发布」辽宁如何开具普通发票「重大消息」 - DockOne.io</title>](http://dockone.io/question/1367838)

### [<title>今日发布北京市哪能代开医院全套住院证明(出院病历-北京医务 - DockOne.io</title>](http://dockone.io/question/1367837)

### [<title>「今日发布」苏州如何开具宣传费发票《手机搜狐网》 - DockOne.io</title>](http://dockone.io/question/1367835)

### [<title>「今日发布」南京如何开具宣传费发票《手机搜狐网》 - DockOne.io</title>](http://dockone.io/question/1367836)

### [<title>「今日发布」长春如何开具普通发票「重大消息」 - DockOne.io</title>](http://dockone.io/question/1367834)

### [<title>「今日发布」宁波如何开具宣传费发票《手机搜狐网》 - DockOne.io</title>](http://dockone.io/question/1367833)

### [<title>「今日发布」郑州如何开具宣传费发票《手机搜狐网》 - DockOne.io</title>](http://dockone.io/question/1367832)

### [<title>「今日发布」吉林如何开具普通发票「重大消息」 - DockOne.io</title>](http://dockone.io/question/1367831)

### [<title>「今日发布」重庆如何开具宣传费发票《手机搜狐网》 - DockOne.io</title>](http://dockone.io/question/1367830)

### [<title>「今日发布」天津如何开具宣传费发票《手机搜狐网》 - DockOne.io</title>](http://dockone.io/question/1367829)

### [<title>「今日发布」海口如何开具普通发票「重大消息」 - DockOne.io</title>](http://dockone.io/question/1367828)

### [<title>今日发布克拉玛依代开医院全套住院证明(出院病历-克拉玛依医务 - DockOne.io</title>](http://dockone.io/question/1367827)

### [<title>「今日发布」杭州如何开具宣传费发票《手机搜狐网》 - DockOne.io</title>](http://dockone.io/question/1367826)

### [<title>「今日发布」三亚如何开具普通发票「重大消息」 - DockOne.io</title>](http://dockone.io/question/1367825)

### [<title>「今日发布」广州如何开具宣传费发票《手机搜狐网》 - DockOne.io</title>](http://dockone.io/question/1367824)

### [<title>今日发布乌鲁木齐代开医院全套住院证明(出院病历-乌鲁木齐医务 - DockOne.io</title>](http://dockone.io/question/1367823)

### [<title>「今日发布」成都如何开具宣传费发票《手机搜狐网》 - DockOne.io</title>](http://dockone.io/question/1367822)

### [<title>「今日发布」海南如何开具普通发票「重大消息」 - DockOne.io</title>](http://dockone.io/question/1367821)

### [<title>今日医务济宁开医院诊断证明(代开医院康复证明 - DockOne.io</title>](http://dockone.io/question/1367820)

### [<title>「今日发布」深圳如何开具宣传费发票《手机搜狐网》 - DockOne.io</title>](http://dockone.io/question/1367819)

### [[2110.14763] Using PPP Information to Implement a Global Real-Time Virtual Network DGNSS Approach](http://arxiv.org/abs/2110.14763)


  Global Navigation Satellite Systems (GNSS) provide positioning services for
connected and autonomous vehicles. Differential GNSS (DGNSS) has been
demonstrated to provide reliable, high quality range correction information
enabling real-time navigation with sub-meter or centimeter accuracy. However,
DGNSS requires a local reference station near each user, which for a
continental or global scale implementation would require a dense network of
reference stations whose construction and maintenance would be prohibitively
expensive. Precise Point Positioning (PPP) affords more flexibility as a public
service for GNSS receivers, but its State Space Representation (SSR) format is
not currently supported by most receivers. This article proposes a novel
Virtual Network DGNSS (VN-DGNSS) design that capitalizes on the PPP
infrastructure to provide global coverage for real-time navigation without
building physical reference stations. Correction information is computed using
data from public GNSS SSR data services and transmitted to users by Radio
Technical Commission for Maritime Services (RTCM) Observation Space
Representation (OSR) messages which are accepted by most receivers. The
real-time stationary and moving platform testing performance, using u-blox M8P
and ZED-F9P receivers, surpasses the Society of Automotive Engineering (SAE)
specification (68% of horizontal error $\leqslant$ 1.5 m and vertical error
$\leqslant$ 3 m) and shows significantly better horizontal performance than
GNSS Open Service (OS). The moving tests also show better horizontal
performance than the ZEDF9P receiver with Satellite Based Augmentation Systems
(SBAS) enabled and achieve the lane-level accuracy which requires 95% of
horizontal errors less than 1 meter.

    

### [[2110.14765] Cryptocurrencies Activity as a Complex Network: Analysis of Transactions Graphs](http://arxiv.org/abs/2110.14765)


  The number of users approaching the world of cryptocurrencies exploded in the
last years, and consequently the daily interactions on their underlying
distributed ledgers have intensified. In this paper, we analyze the flow of
these digital transactions in a certain period of time, trying to discover
important insights on the typical use of these technologies by studying,
through complex network theory, the patterns of interactions in four prominent
and different Distributed Ledger Technologies (DLTs), namely Bitcoin, DogeCoin,
Ethereum, Ripple. In particular, we describe the Distributed Ledger Network
Analyzer (DiLeNA), a software tool for the investigation of the transactions
network recorded in DLTs. We show that studying the network characteristics and
peculiarities is of paramount importance, in order to understand how users
interact in the DLT. For instance, our analyses reveal that all transaction
graphs exhibit small world properties.

    

### [[2110.14848] V2iFi: in-Vehicle Vital Sign Monitoring via Compact RF Sensing](http://arxiv.org/abs/2110.14848)


  Given the significant amount of time people spend in vehicles, health issues
under driving condition have become a major concern. Such issues may vary from
fatigue, asthma, stroke, to even heart attack, yet they can be adequately
indicated by vital signs and abnormal activities. Therefore, in-vehicle vital
sign monitoring can help us predict and hence prevent these issues. Whereas
existing sensor-based (including camera) methods could be used to detect these
indicators, privacy concern and system complexity both call for a convenient
yet effective and robust alternative. This paper aims to develop V2iFi, an
intelligent system performing monitoring tasks using a COTS impulse radio
mounted on the windshield. V2iFi is capable of reliably detecting driver's
vital signs under driving condition and with the presence of passengers, thus
allowing for potentially inferring corresponding health issues. Compared with
prior work based on Wi-Fi CSI, V2iFi is able to distinguish reflected signals
from multiple users, and hence provide finer-grained measurements under more
realistic settings. We evaluate V2iFi both in lab environments and during
real-life road tests; the results demonstrate that respiratory rate, heart
rate, and heart rate variability can all be estimated accurately. Based on
these estimation results, we further discuss how machine learning models can be
applied on top of V2iFi so as to improve both physiological and psychological
wellbeing in driving environments.

    

### [[2110.14849] Enhancing RF Sensing with Deep Learning: A Layered Approach](http://arxiv.org/abs/2110.14849)


  In recent years, radio frequency (RF) sensing has gained increasing
popularity due to its pervasiveness, low cost, non-intrusiveness, and privacy
preservation. However, realizing the promises of RF sensing is highly
nontrivial, given typical challenges such as multipath and interference. One
potential solution leverages deep learning to build direct mappings from the RF
domain to target domains, hence avoiding complex RF physical modeling. While
earlier solutions exploit only simple feature extraction and classification
modules, an emerging trend adds functional layers on top of elementary modules
for more powerful generalizability and flexible applicability. To better
understand this potential, this article takes a layered approach to summarize
RF sensing enabled by deep learning. Essentially, we present a four-layer
framework: physical, backbone, generalization, and application. While this
layered framework provides readers a systematic methodology for designing deep
interpreted RF sensing, it also facilitates making improvement proposals and
hints at future research opportunities.

    

### [[2110.14860] A lightweight two-layer blockchain mechanism for reliable crossing-domain communication in smart cities](http://arxiv.org/abs/2110.14860)


  The smart city is an emerging notion that is leveraging the Internet of
Things (IoT) technique to achieve more comfortable, smart and controllable
cities. The communications crossing domains between smart cities is
indispensable to enhance collaborations. However, crossing-domain
communications are more vulnerable since there are in different domains.
Moreover, there are huge different devices with different computation
capabilities, from sensors to the cloud servers. In this paper, we propose a
lightweight two-layer blockchain mechanism for reliable crossing-domain
communication in smart cities. Our mechanism provides a reliable communication
mechanism for data sharing and communication between smart cities. We defined a
two-layer blockchain structure for the communications inner and between smart
cities to achieve reliable communications. We present a new block structure for
the lightweight IoT devices. Moreover, we present a reputation-based
multi-weight consensus protocol in order to achieve efficient communication
while resistant to the nodes collusion attack for the proposed blockchain
system. We also conduct a secure analysis to demonstrate the security of the
proposed scheme. Finally, performance evaluation shows that our scheme is
efficient and practical.

    

### [[2110.14937] Computational Intelligence and Deep Learning for Next-Generation Edge-Enabled Industrial IoT](http://arxiv.org/abs/2110.14937)


  In this paper, we investigate how to deploy computational intelligence and
deep learning (DL) in edge-enabled industrial IoT networks. In this system, the
IoT devices can collaboratively train a shared model without compromising data
privacy. However, due to limited resources in the industrial IoT networks,
including computational power, bandwidth, and channel state, it is challenging
for many devices to accomplish local training and upload weights to the edge
server in time. To address this issue, we propose a novel multi-exit-based
federated edge learning (ME-FEEL) framework, where the deep model can be
divided into several sub-models with different depths and output prediction
from the exit in the corresponding sub-model. In this way, the devices with
insufficient computational power can choose the earlier exits and avoid
training the complete model, which can help reduce computational latency and
enable devices to participate into aggregation as much as possible within a
latency threshold. Moreover, we propose a greedy approach-based exit selection
and bandwidth allocation algorithm to maximize the total number of exits in
each communication round. Simulation experiments are conducted on the classical
Fashion-MNIST dataset under a non-independent and identically distributed
(non-IID) setting, and it shows that the proposed strategy outperforms the
conventional FL. In particular, the proposed ME-FEEL can achieve an accuracy
gain up to 32.7% in the industrial IoT networks with the severely limited
resources.

    

### [[2110.15138] Deep Learning Aided Routing for Space-Air-Ground Integrated Networks Relying on Real Satellite, Flight, and Shipping Data](http://arxiv.org/abs/2110.15138)


  Current maritime communications mainly rely on satellites having meager
transmission resources, hence suffering from poorer performance than modern
terrestrial wireless networks. With the growth of transcontinental air traffic,
the promising concept of aeronautical ad hoc networking relying on commercial
passenger airplanes is potentially capable of enhancing satellite-based
maritime communications via air-to-ground and multi-hop air-to-air links. In
this article, we conceive space-air-ground integrated networks (SAGINs) for
supporting ubiquitous maritime communications, where the low-earth-orbit
satellite constellations, passenger airplanes, terrestrial base stations,
ships, respectively, serve as the space-, air-, ground- and sea-layer. To meet
heterogeneous service requirements, and accommodate the time-varying and
self-organizing nature of SAGINs, we propose a deep learning (DL) aided
multi-objective routing algorithm, which exploits the quasi-predictable network
topology and operates in a distributed manner. Our simulation results based on
real satellite, flight, and shipping data in the North Atlantic region show
that the integrated network enhances the coverage quality by reducing the
end-to-end (E2E) delay and by boosting the E2E throughput as well as improving
the path-lifetime. The results demonstrate that our DL-aided multi-objective
routing algorithm is capable of achieving near Pareto-optimal performance.

    

### [[2110.15145] Deep Learning Aided Packet Routing in Aeronautical Ad-Hoc Networks Relying on Real Flight Data: From Single-Objective to Near-Pareto Multi-Objective Optimization](http://arxiv.org/abs/2110.15145)


  Data packet routing in aeronautical ad-hoc networks (AANETs) is challenging
due to their high-dynamic topology. In this paper, we invoke deep learning (DL)
to assist routing in AANETs. We set out from the single objective of minimizing
the end-to-end (E2E) delay. Specifically, a deep neural network (DNN) is
conceived for mapping the local geographic information observed by the
forwarding node into the information required for determining the optimal next
hop. The DNN is trained by exploiting the regular mobility pattern of
commercial passenger airplanes from historical flight data. After training, the
DNN is stored by each airplane for assisting their routing decisions during
flight relying solely on local geographic information. Furthermore, we extend
the DL-aided routing algorithm to a multi-objective scenario, where we aim for
simultaneously minimizing the delay, maximizing the path capacity, and
maximizing the path lifetime. Our simulation results based on real flight data
show that the proposed DL-aided routing outperforms existing position-based
routing protocols in terms of its E2E delay, path capacity as well as path
lifetime, and it is capable of approaching the Pareto front that is obtained
using global link information.

    

### [[2110.15146] Deep Reinforcement Learning Aided Packet-Routing For Aeronautical Ad-Hoc Networks Formed by Passenger Planes](http://arxiv.org/abs/2110.15146)


  Data packet routing in aeronautical ad-hoc networks (AANETs) is challenging
due to their high-dynamic topology. In this paper, we invoke deep reinforcement
learning for routing in AANETs aiming at minimizing the end-to-end (E2E) delay.
Specifically, a deep Q-network (DQN) is conceived for capturing the
relationship between the optimal routing decision and the local geographic
information observed by the forwarding node. The DQN is trained in an offline
manner based on historical flight data and then stored by each airplane for
assisting their routing decisions during flight. To boost the learning
efficiency and the online adaptability of the proposed DQN-routing, we further
exploit the knowledge concerning the system's dynamics by using a deep value
network (DVN) conceived with a feedback mechanism. Our simulation results show
that both DQN-routing and DVN-routing achieve lower E2E delay than the
benchmark protocol, and DVN-routing performs similarly to the optimal routing
that relies on perfect global information.

    

### [[2110.15157] Optimizing Tail Latency in Commodity Datacenters using Forward Error Correction](http://arxiv.org/abs/2110.15157)


  Long tail latency of short flows (or messages) greatly affects user-facing
applications in datacenters. Prior solutions to the problem introduce
significant implementation complexities, such as global state monitoring,
complex network control, or non-trivial switch modifications. While promising
superior performance, they are hard to implement in practice. This paper
presents CloudBurst, a simple, effective yet readily deployable solution
achieving similar or even better results without introducing the above
complexities. At its core, CloudBurst explores forward error correction (FEC)
over multipath - it proactively spreads FEC-coded packets generated from
messages over multipath in parallel, and recovers them with the first few
arriving ones. As a result, CloudBurst is able to obliviously exploit
underutilized paths, thus achieving low tail latency. We have implemented
CloudBurst as a user-space library, and deployed it on a testbed with commodity
switches. Our testbed and simulation experiments show the superior performance
of CloudBurst. For example, CloudBurst achieves 63.69% and 60.06% reduction in
99th percentile message/flow completion time (FCT) compared to DCTCP and PIAS,
respectively.

    

### [[2110.15161] Secure Blockchain Platform for Industrial IoT with Trusted Computing Hardware](http://arxiv.org/abs/2110.15161)


  As a disruptive technology that originates from cryptocurrency, blockchain
provides a trusted platform to facilitate industrial IoT (IIoT) applications.
However, implementing a blockchain platform in IIoT scenarios confronts various
security challenges due to the rigorous deployment condition. To this end, we
present a novel design of secure blockchain based on trusted computing hardware
for IIoT applications. Specifically, we employ the trusted execution
environment (TEE) module and a customized security chip to safeguard the
blockchain against different attacking vectors. Furthermore, we implement the
proposed secure IIoT blockchain on the ARM-based embedded device and build a
small-scale IIoT network to evaluate its performance. Our experimental results
show that the secure blockchain platform achieves a high throughput (150TPS)
with low transaction confirmation delay (below 66ms), demonstrating its
feasibility in practical IIoT scenarios. Finally, we outline the open
challenges and future research directions.

    

### [[2110.15187] Coexistence and Spectrum Sharing Above 100 GHz](http://arxiv.org/abs/2110.15187)


  [...] This paper explores how spectrum policy and spectrum technologies can
evolve to enable sharing among different stakeholders in the above 100 GHz
spectrum, without introducing harmful interference or disrupting either
security applications or fundamental science exploration. This portion of the
spectrum presents new opportunities to design spectrum sharing schemes, based
on novel antenna designs, directional ultra-high-rate communications, and
active/passive user coordination. The paper provides a tutorial on current
regulations above 100 GHz, and highlights how sharing is central to allowing
each stakeholder to make the most out of this spectrum. It then defines -
through detailed simulations based on standard International Telecommunications
Union (ITU) channel and antenna models - scenarios in which active users may
introduce harmful interference to passive sensing. Based on this evaluation, it
reviews a number of promising techniques that can enable active/passive sharing
above 100 GHz. The critical review and tutorial on policy and technologies of
this paper have the potential to kickstart future research and regulations that
promote safe coexistence between active and passive users above 100 GHz,
further benefiting the development of digital technologies and scientific
exploration.

    

### [[2110.15204] Energy Efficient Resource Allocation in Federated Fog Computing Networks](http://arxiv.org/abs/2110.15204)


  There is a continuous growth in demand for time sensitive applications which
has shifted the cloud paradigm from a centralized computing architecture
towards distributed heterogeneous computing platforms where resources located
at the edge of the network are used to provide cloud-like services. This
paradigm is widely known as fog computing. Virtual machines (VMs) have been
widely utilized in both paradigms to enhance the network scalability, improve
resource utilization, and energy efficiency. Moreover, Passive Optical Networks
(PONs) are a technology suited to handling the enormous volumes of data
generated in the access network due to their energy efficiency and large
bandwidth. In this paper, we utilize a PON to provide the connectivity between
multiple distributed fog units to achieve federated (i.e. cooperative)
computing units in the access network to serve intensive demands. We propose a
mixed integer linear program (MILP) to optimize the VM placement in the
federated fog computing units with the objective of minimizing the total power
consumption while considering inter-VM traffic. The results show a significant
power saving as a result of the proposed optimization model by up to 52%, in
the VM-allocation compared to a baseline approach that allocates the VM
requests while neglecting the power consumption and inter-VMs traffic in the
optimization framework.

    

### [[2110.15206] An Efficient Multi-Link Channel Model for LiFi](http://arxiv.org/abs/2110.15206)


  In this paper, we report for the first time on a new channel modelling
technique for multi-link LiFi scenarios. By considering simplified numerical
calculation, it models the links between multiple optical frontends and
multiple mobile devices much faster than previous approaches. For the first two
diffuse reflections, we replace ray-tracing method by frequency domain channel
modelling technique. For the other higher order diffuse reflections, we use a
well-established model based on the integrating sphere. For validation of our
new approach, we performed distributed 4x2 MIMO channel measurements.
Comparison of simulation and measurement yields a relative mean square error
below 5 percent for the signals with a free line-of-sight. Our new technique
enables efficient modeling of mobile scenarios and analyzing statistical
properties of the LiFi channels.

    

### [[2110.15207] Black-Box Assessment of Optical Spectrum Services](http://arxiv.org/abs/2110.15207)


  A spectral sweep process is introduced to discover performance issues in
optical spectrum services. We detect filtering penalty, spectral ripple/tilt
and channel crosstalk in field measurements, potentially leading to increased
service robustness in low-margin networks.

    

### [[2110.15208] A New Remote Monitor and Control System Based on Sigfox IoT Network](http://arxiv.org/abs/2110.15208)


  We describe a new, low-cost system designed to provide multi-sensor remote
condition monitoring of modern scientific laboratories, as well as to allow
users to perform actions from remote locations in case of detection of
specified events. The system is battery operated and does not require the
presence of a Local Area Network (LAN) or WiFi (which are typically not
available in case of, e.g. power losses), as it exploits the growing
infrastructure of Internet of Things (IoT) Low Power Wide Area Networks
(LPWAN). In particular our system exploits the new SigFox
ultra-narrow-bandwidth (UNB) infrastructure, and provides for a bidirectional
link between the instrumentation and the remote user even in case of power line
outages, which are among the most critical situations that a scientific
laboratory can withstand. The system can detect the occurrence of predefined
events in very short times, and either autonomously react with a series of
predefined actions, also allowing a remote user to timely perform additional
actions on the system through an user-friendly smartphone application or via a
browser interface. The system also embeds a novel power-loss detection
architecture, which detects power line failures in less than 2 ms. We provide a
full characterization of the prototype, including reaction times, connection
latencies, sensors sensitivity, and power consumption.

    

### [[2110.15328] DeepNP: Deep Learning-Based Noise Prediction for Ultra-Reliable Low-Latency Communications](http://arxiv.org/abs/2110.15328)


  Closing the gap between high data rates and low delay in real-time streaming
applications is a major challenge in advanced communication systems. While
adaptive network coding schemes have the potential of balancing rate and delay
in real-time, they often rely on prediction of the channel behavior. In
practice, such prediction is based on delayed feedback, making it difficult to
acquire causally, particularly when the underlying channel model is unknown. In
this work, we propose a deep learning-based noise prediction (DeepNP)
algorithm, which augments the recently proposed adaptive and causal random
linear network coding scheme with a dedicated deep neural network, that learns
to carry out noise prediction from data. This neural augmentation is utilized
to maximize the throughput while minimizing in-order delivery delay of the
network coding scheme, and operate in a channel-model-agnostic manner. We
numerically show that performance can dramatically increase by the learned
prediction of the channel noise rate. In particular, we demonstrate that DeepNP
gains up to a factor of four in mean and maximum delay and a factor two in
throughput compared with statistic-based network coding approaches.

    

### [[2110.15345] A First Look at the Consolidation of DNS and Web Hosting Providers](http://arxiv.org/abs/2110.15345)


  Although the Internet continues to grow, it increasingly depends on a small
set of dominant service providers for Domain Name System (DNS) hosting and web
hosting providers. This consolidation of Internet resources poses a variety of
potential threats to the Internet, including susceptibility to outages,
failures, and even overt censorship from platforms. Increasingly, an outage
from a single organization can create widespread disruption across a large
number of sites and services. Consolidation trends have been noted for several
years, yet these trends have not been quantified. Towards this end, this paper
aims to quantify these trends, in particular, the reliance of the most popular
domains on a small set of organizations for DNS and web hosting. We highlight
the extent to which the hosting of authoritative name servers and web hosting
for the top 10,000 websites are consolidated on relatively few platforms. The
statistics are surprising and somewhat alarming. We find that over 75% of the
top 10,000 domains rely on only a single organization for hosting authoritative
DNS resolution. Furthermore, two organizations, Cloudflare and Amazon, are the
sole host of DNS name servers for over 40% of these popular domains. In terms
of web hosting, we find that 62% of index pages and many external page
resources for the top 10,000 websites are hosted by only five organizations:
Cloudflare, Amazon, Akamai, Fastly, and Google.

    

### [[2101.04003] QMA: A Resource-efficient, Q-Learning-based Multiple Access Scheme for the IIoT](http://arxiv.org/abs/2101.04003)


  Contention-based wireless channel access methods like CSMA and ALOHA paved
the way for the rise of the Internet of Things in industrial applications
(IIoT). However, to cope with increasing demands for reliability and
throughput, several mostly TDMA-based protocols like IEEE 802.15.4 and its
extensions were proposed. Nonetheless, many of these IIoT-protocols still
require contention-based communication, e.g., for slot allocation and broadcast
transmission. In many cases, subtle but hidden patterns characterize this
secondary traffic. Present contention-based protocols are unaware of these
hidden patterns and can therefore not exploit this information. Especially in
dense networks, they often do not provide sufficient reliability for primary
traffic, e.g., they are unable to allocate transmission slots in time. In this
paper, we propose QMA, a contention-based multiple access scheme based on
Q-learning, which dynamically adapts transmission times to avoid collisions by
learning patterns in the contention-based traffic. QMA is designed to be
resource-efficient and targets small embedded devices. We show that QMA solves
the hidden node problem without the additional overhead of RTS / CTS messages
and verify the behaviour of QMA in the FIT IoT-LAB testbed. Finally, QMA's
scalability is studied by simulation, where it is used for GTS allocation in
IEEE 802.15.4 DSME. Results show that QMA considerably increases reliability
and throughput in comparison to CSMA/CA, especially in networks with a high
load.

    

### [[2110.14638] Improving Super-Resolution Performance using Meta-Attention Layers](http://arxiv.org/abs/2110.14638)


  Convolutional Neural Networks (CNNs) have achieved impressive results across
many super-resolution (SR) and image restoration tasks. While many such
networks can upscale low-resolution (LR) images using just the raw pixel-level
information, the ill-posed nature of SR can make it difficult to accurately
super-resolve an image which has undergone multiple different degradations.
Additional information (metadata) describing the degradation process (such as
the blur kernel applied, compression level, etc.) can guide networks to
super-resolve LR images with higher fidelity to the original source. Previous
attempts at informing SR networks with degradation parameters have indeed been
able to improve performance in a number of scenarios. However, due to the
fully-convolutional nature of many SR networks, most of these metadata fusion
methods either require a complete architectural change, or necessitate the
addition of significant extra complexity. Thus, these approaches are difficult
to introduce into arbitrary SR networks without considerable design
alterations. In this paper, we introduce meta-attention, a simple mechanism
which allows any SR CNN to exploit the information available in relevant
degradation parameters. The mechanism functions by translating the metadata
into a channel attention vector, which in turn selectively modulates the
network's feature maps. Incorporating meta-attention into SR networks is
straightforward, as it requires no specific type of architecture to function
correctly. Extensive testing has shown that meta-attention can consistently
improve the pixel-level accuracy of state-of-the-art (SOTA) networks when
provided with relevant degradation metadata. For PSNR, the gain on
blurred/downsampled (X4) images is of 0.2969 dB (on average) and 0.3320 dB for
SOTA general and face SR models, respectively.

    

### [[2110.14677] Stabilising viscous extensional flows using Reinforcement Learning](http://arxiv.org/abs/2110.14677)


  The four-roll mill, wherein four identical cylinders undergo rotation of
identical magnitude but alternate signs, was originally proposed by GI Taylor
to create local extensional flows and study their ability to deform small
liquid drops. Since an extensional flow has an unstable eigendirection, a drop
located at the flow stagnation point will have a tendency to escape. This
unstable dynamics can however be stabilised using, e.g., a modulation of the
rotation rates of the cylinders. Here we use Reinforcement Learning, a branch
of Machine Learning devoted to the optimal selection of actions based on
cumulative rewards, in order to devise a stabilisation algorithm for the
four-roll mill flow. The flow is modelled as the linear superposition of four
two-dimensional rotlets and the drop is treated as a rigid spherical particle
smaller than all other length scales in the problem. Unlike previous attempts
to devise control, we take a probabilistic approach whereby speed adjustments
are drawn from a probability density function whose shape is improved over time
via a form of gradient ascent know as Actor-Critic method. With enough
training, our algorithm is able to precisely control the drop and keep it close
to the stagnation point for as long as needed. We explore the impact of the
physical and learning parameters on the effectiveness of the control and
demonstrate the robustness of the algorithm against thermal noise. We finally
show that Reinforcement Learning can provide a control algorithm effective for
all initial positions and that can be adapted to limit the magnitude of the
flow extension near the position of the drop.

    

### [[2110.14678] Meta-Learning Sparse Implicit Neural Representations](http://arxiv.org/abs/2110.14678)


  Implicit neural representations are a promising new avenue of representing
general signals by learning a continuous function that, parameterized as a
neural network, maps the domain of a signal to its codomain; the mapping from
spatial coordinates of an image to its pixel values, for example. Being capable
of conveying fine details in a high dimensional signal, unboundedly of its
domain, implicit neural representations ensure many advantages over
conventional discrete representations. However, the current approach is
difficult to scale for a large number of signals or a data set, since learning
a neural representation -- which is parameter heavy by itself -- for each
signal individually requires a lot of memory and computations. To address this
issue, we propose to leverage a meta-learning approach in combination with
network compression under a sparsity constraint, such that it renders a
well-initialized sparse parameterization that evolves quickly to represent a
set of unseen signals in the subsequent training. We empirically demonstrate
that meta-learned sparse neural representations achieve a much smaller loss
than dense meta-learned models with the same number of parameters, when trained
to fit each signal using the same number of optimization steps.

    

### [[2110.14690] VACA: Design of Variational Graph Autoencoders for Interventional and Counterfactual Queries](http://arxiv.org/abs/2110.14690)


  In this paper, we introduce VACA, a novel class of variational graph
autoencoders for causal inference in the absence of hidden confounders, when
only observational data and the causal graph are available. Without making any
parametric assumptions, VACA mimics the necessary properties of a Structural
Causal Model (SCM) to provide a flexible and practical framework for
approximating interventions (do-operator) and abduction-action-prediction
steps. As a result, and as shown by our empirical results, VACA accurately
approximates the interventional and counterfactual distributions on diverse
SCMs. Finally, we apply VACA to evaluate counterfactual fairness in fair
classification problems, as well as to learn fair classifiers without
compromising performance.

    

### [[2110.14694] Towards Realistic Single-Task Continuous Learning Research for NER](http://arxiv.org/abs/2110.14694)


  There is an increasing interest in continuous learning (CL), as data privacy
is becoming a priority for real-world machine learning applications. Meanwhile,
there is still a lack of academic NLP benchmarks that are applicable for
realistic CL settings, which is a major challenge for the advancement of the
field. In this paper we discuss some of the unrealistic data characteristics of
public datasets, study the challenges of realistic single-task continuous
learning as well as the effectiveness of data rehearsal as a way to mitigate
accuracy loss. We construct a CL NER dataset from an existing publicly
available dataset and release it along with the code to the research community.

    

### [[2110.14703] Alternating Learning Approach for Variational Networks and Undersampling Pattern in Parallel MRI Applications](http://arxiv.org/abs/2110.14703)


  Purpose: To propose an alternating learning approach to learn the sampling
pattern (SP) and the parameters of variational networks (VN) in accelerated
parallel magnetic resonance imaging (MRI). Methods: The approach alternates
between improving the SP, using bias-accelerated subset selection, and
improving parameters of the VN, using ADAM with monotonicity verification. The
algorithm learns an effective pair: an SP that captures fewer k-space samples
generating undersampling artifacts that are removed by the VN reconstruction.
The proposed approach was tested for stability and convergence, considering
different initial SPs. The quality of the VNs and SPs was compared against
other approaches, including joint learning methods and VN learning with fixed
variable density Poisson-disc SPs, using two different datasets and different
acceleration factors (AF). Results: The root mean squared error (RMSE)
improvements ranged from 14.9% to 51.2% considering AF from 2 to 20 in the
tested brain and knee joint datasets when compared to the other approaches. The
proposed approach has shown stable convergence, obtaining similar SPs with the
same RMSE under different initial conditions. Conclusion: The proposed approach
was stable and learned effective SPs with the corresponding VN parameters that
produce images with better quality than other approaches, improving accelerated
parallel MRI applications.

    

### [[2110.14708] Identifiable Generative Models for Missing Not at Random Data Imputation](http://arxiv.org/abs/2110.14708)


  Real-world datasets often have missing values associated with complex
generative processes, where the cause of the missingness may not be fully
observed. This is known as missing not at random (MNAR) data. However, many
imputation methods do not take into account the missingness mechanism,
resulting in biased imputation values when MNAR data is present. Although there
are a few methods that have considered the MNAR scenario, their model's
identifiability under MNAR is generally not guaranteed. That is, model
parameters can not be uniquely determined even with infinite data samples,
hence the imputation results given by such models can still be biased. This
issue is especially overlooked by many modern deep generative models. In this
work, we fill in this gap by systematically analyzing the identifiability of
generative models under MNAR. Furthermore, we propose a practical deep
generative model which can provide identifiability guarantees under mild
assumptions, for a wide range of MNAR mechanisms. Our method demonstrates a
clear advantage for tasks on both synthetic data and multiple real-world
scenarios with MNAR data.

    

### [[2110.14711] A Survey of Self-Supervised and Few-Shot Object Detection](http://arxiv.org/abs/2110.14711)


  Labeling data is often expensive and time-consuming, especially for tasks
such as object detection and instance segmentation, which require dense
labeling of the image. While few-shot object detection is about training a
model on novel (unseen) object classes with little data, it still requires
prior training on many labeled examples of base (seen) classes. On the other
hand, self-supervised methods aim at learning representations from unlabeled
data which transfer well to downstream tasks such as object detection.
Combining few-shot and self-supervised object detection is a promising research
direction. In this survey, we review and characterize the most recent
approaches on few-shot and self-supervised object detection. Then, we give our
main takeaways and discuss future research directions.

    

### [[2110.14714] Designing Machine Learning Surrogates using Outputs of Molecular Dynamics Simulations as Soft Labels](http://arxiv.org/abs/2110.14714)


  Molecular dynamics simulations are powerful tools to extract the microscopic
mechanisms characterizing the properties of soft materials. We recently
introduced machine learning surrogates for molecular dynamics simulations of
soft materials and demonstrated that artificial neural network based regression
models can successfully predict the relationships between the input material
attributes and the simulation outputs. Here, we show that statistical
uncertainties associated with the outputs of molecular dynamics simulations can
be utilized to train artificial neural networks and design machine learning
surrogates with higher accuracy and generalizability. We design soft labels for
the simulation outputs by incorporating the uncertainties in the estimated
average output quantities, and introduce a modified loss function that
leverages these soft labels during training to significantly reduce the
surrogate prediction error for input systems in the unseen test data. The
approach is illustrated with the design of a surrogate for molecular dynamics
simulations of confined electrolytes to predict the complex relationship
between the input electrolyte attributes and the output ionic structure. The
surrogate predictions for the ionic density profiles show excellent agreement
with the ground truth results produced using molecular dynamics simulations.
The high accuracy and small inference times associated with the surrogate
predictions provide quick access to quantities derived using the number density
profiles and facilitate rapid sensitivity analysis.

    

### [[2110.14729] Anomaly-Injected Deep Support Vector Data Description for Text Outlier Detection](http://arxiv.org/abs/2110.14729)


  Anomaly detection or outlier detection is a common task in various domains,
which has attracted significant research efforts in recent years. Existing
works mainly focus on structured data such as numerical or categorical data;
however, anomaly detection on unstructured textual data is less attended. In
this work, we target the textual anomaly detection problem and propose a deep
anomaly-injected support vector data description (AI-SVDD) framework. AI-SVDD
not only learns a more compact representation of the data hypersphere but also
adopts a small number of known anomalies to increase the discriminative power.
To tackle text input, we employ a multilayer perceptron (MLP) network in
conjunction with BERT to obtain enriched text representations. We conduct
experiments on three text anomaly detection applications with multiple
datasets. Experimental results show that the proposed AI-SVDD is promising and
outperforms existing works.

    

### [[2110.14735] Towards Evaluating the Robustness of Neural Networks Learned by Transduction](http://arxiv.org/abs/2110.14735)


  There has been emerging interest in using transductive learning for
adversarial robustness (Goldwasser et al., NeurIPS 2020; Wu et al., ICML 2020;
Wang et al., ArXiv 2021). Compared to traditional defenses, these defense
mechanisms "dynamically learn" the model based on test-time input; and
theoretically, attacking these defenses reduces to solving a bilevel
optimization problem, which poses difficulty in crafting adaptive attacks. In
this paper, we examine these defense mechanisms from a principled threat
analysis perspective. We formulate and analyze threat models for
transductive-learning based defenses, and point out important subtleties. We
propose the principle of attacking model space for solving bilevel attack
objectives, and present Greedy Model Space Attack (GMSA), an attack framework
that can serve as a new baseline for evaluating transductive-learning based
defenses. Through systematic evaluation, we show that GMSA, even with weak
instantiations, can break previous transductive-learning based defenses, which
were resilient to previous attacks, such as AutoAttack (Croce and Hein, ICML
2020). On the positive side, we report a somewhat surprising empirical result
of "transductive adversarial training": Adversarially retraining the model
using fresh randomness at the test time gives a significant increase in
robustness against attacks we consider.

    

### [[2110.14739] Generalized Shape Metrics on Neural Representations](http://arxiv.org/abs/2110.14739)


  Understanding the operation of biological and artificial networks remains a
difficult and important challenge. To identify general principles, researchers
are increasingly interested in surveying large collections of networks that are
trained on, or biologically adapted to, similar tasks. A standardized set of
analysis tools is now needed to identify how network-level covariates -- such
as architecture, anatomical brain region, and model organism -- impact neural
representations (hidden layer activations). Here, we provide a rigorous
foundation for these analyses by defining a broad family of metric spaces that
quantify representational dissimilarity. Using this framework we modify
existing representational similarity measures based on canonical correlation
analysis to satisfy the triangle inequality, formulate a novel metric that
respects the inductive biases in convolutional layers, and identify approximate
Euclidean embeddings that enable network representations to be incorporated
into essentially any off-the-shelf machine learning method. We demonstrate
these methods on large-scale datasets from biology (Allen Institute Brain
Observatory) and deep learning (NAS-Bench-101). In doing so, we identify
relationships between neural representations that are interpretable in terms of
anatomical features and model performance.

    

### [[2110.14746] MutFormer: A context-dependent transformer-based model to predict pathogenic missense mutations](http://arxiv.org/abs/2110.14746)


  A missense mutation is a point mutation that results in a substitution of an
amino acid in a protein sequence. Currently, missense mutations account for
approximately half of the known variants responsible for human inherited
diseases, but accurate prediction of the pathogenicity of missense variants is
still challenging. Recent advances in deep learning show that transformer
models are particularly powerful at modeling sequences. In this study, we
introduce MutFormer, a transformer-based model for prediction of pathogenic
missense mutations. We pre-trained MutFormer on reference protein sequences and
alternative protein sequences result from common genetic variants. We tested
different fine-tuning methods for pathogenicity prediction. Our results show
that MutFormer outperforms a variety of existing tools. MutFormer and
pre-computed variant scores are publicly available on GitHub at
this https URL.

    

### [[2110.14747] Dynamic Review-based Recommenders](http://arxiv.org/abs/2110.14747)


  Just as user preferences change with time, item reviews also reflect those
same preference changes. In a nutshell, if one is to sequentially incorporate
review content knowledge into recommender systems, one is naturally led to
dynamical models of text. In the present work we leverage the known power of
reviews to enhance rating predictions in a way that (i) respects the causality
of review generation and (ii) includes, in a bidirectional fashion, the ability
of ratings to inform language review models and vice-versa, language
representations that help predict ratings end-to-end. Moreover, our
representations are time-interval aware and thus yield a continuous-time
representation of the dynamics. We provide experiments on real-world datasets
and show that our methodology is able to outperform several state-of-the-art
models. Source code for all models can be found at [1].

    

### [[2110.14753] Subtleties in the trainability of quantum machine learning models](http://arxiv.org/abs/2110.14753)


  A new paradigm for data science has emerged, with quantum data, quantum
models, and quantum computational devices. This field, called Quantum Machine
Learning (QML), aims to achieve a speedup over traditional machine learning for
data analysis. However, its success usually hinges on efficiently training the
parameters in quantum neural networks, and the field of QML is still lacking
theoretical scaling results for their trainability. Some trainability results
have been proven for a closely related field called Variational Quantum
Algorithms (VQAs). While both fields involve training a parametrized quantum
circuit, there are crucial differences that make the results for one setting
not readily applicable to the other. In this work we bridge the two frameworks
and show that gradient scaling results for VQAs can also be applied to study
the gradient scaling of QML models. Our results indicate that features deemed
detrimental for VQA trainability can also lead to issues such as barren
plateaus in QML. Consequently, our work has implications for several QML
proposals in the literature. In addition, we provide theoretical and numerical
evidence that QML models exhibit further trainability issues not present in
VQAs, arising from the use of a training dataset. We refer to these as
dataset-induced barren plateaus. These results are most relevant when dealing
with classical data, as here the choice of embedding scheme (i.e., the map
between classical data and quantum states) can greatly affect the gradient
scaling.

    

### [[2110.14754] Confidence-Aware Imitation Learning from Demonstrations with Varying Optimality](http://arxiv.org/abs/2110.14754)


  Most existing imitation learning approaches assume the demonstrations are
drawn from experts who are optimal, but relaxing this assumption enables us to
use a wider range of data. Standard imitation learning may learn a suboptimal
policy from demonstrations with varying optimality. Prior works use confidence
scores or rankings to capture beneficial information from demonstrations with
varying optimality, but they suffer from many limitations, e.g., manually
annotated confidence scores or high average optimality of demonstrations. In
this paper, we propose a general framework to learn from demonstrations with
varying optimality that jointly learns the confidence score and a
well-performing policy. Our approach, Confidence-Aware Imitation Learning
(CAIL) learns a well-performing policy from confidence-reweighted
demonstrations, while using an outer loss to track the performance of our model
and to learn the confidence. We provide theoretical guarantees on the
convergence of CAIL and evaluate its performance in both simulated and real
robot experiments. Our results show that CAIL significantly outperforms other
imitation learning methods from demonstrations with varying optimality. We
further show that even without access to any optimal demonstrations, CAIL can
still learn a successful policy, and outperforms prior work.

    

### [[2110.14755] Algorithmic encoding of protected characteristics and its implications on disparities across subgroups](http://arxiv.org/abs/2110.14755)


  It has been rightfully emphasized that the use of AI for clinical decision
making could amplify health disparities. A machine learning model may pick up
undesirable correlations, for example, between a patient's racial identity and
clinical outcome. Such correlations are often present in (historical) data used
for model development. There has been an increase in studies reporting biases
in disease detection models across patient subgroups. Besides the scarcity of
data from underserved populations, very little is known about how these biases
are encoded and how one may reduce or even remove disparate performance. There
is some speculation whether algorithms may recognize patient characteristics
such as biological sex or racial identity, and then directly or indirectly use
this information when making predictions. But it remains unclear how we can
establish whether such information is actually used. This article aims to shed
some light on these issues by exploring new methodology allowing intuitive
inspections of the inner working of machine learning models for image-based
detection of disease. We also evaluate an effective yet debatable technique for
addressing disparities leveraging the automatic prediction of patient
characteristics, resulting in models with comparable true and false positive
rates across subgroups. Our findings may stimulate the discussion about safe
and ethical use of AI.

    

### [[2110.14759] Regularized Frank-Wolfe for Dense CRFs: Generalizing Mean Field and Beyond](http://arxiv.org/abs/2110.14759)


  We introduce regularized Frank-Wolfe, a general and effective algorithm for
inference and learning of dense conditional random fields (CRFs). The algorithm
optimizes a nonconvex continuous relaxation of the CRF inference problem using
vanilla Frank-Wolfe with approximate updates, which are equivalent to
minimizing a regularized energy function. Our proposed method is a
generalization of existing algorithms such as mean field or concave-convex
procedure. This perspective not only offers a unified analysis of these
algorithms, but also allows an easy way of exploring different variants that
potentially yield better performance. We illustrate this in our empirical
results on standard semantic segmentation datasets, where several
instantiations of our regularized Frank-Wolfe outperform mean field inference,
both as a standalone component and as an end-to-end trainable layer in a neural
network. We also show that dense CRFs, coupled with our new algorithms, produce
significant improvements over strong CNN baselines.

    

### [[2110.14764] Generalized Funnelling: Ensemble Learning and Heterogeneous Document Embeddings for Cross-Lingual Text Classification](http://arxiv.org/abs/2110.14764)


  \emph{Funnelling} (Fun) is a recently proposed method for cross-lingual text
classification (CLTC) based on a two-tier learning ensemble for heterogeneous
transfer learning (HTL). In this ensemble method, 1st-tier classifiers, each
working on a different and language-dependent feature space, return a vector of
calibrated posterior probabilities (with one dimension for each class) for each
document, and the final classification decision is taken by a metaclassifier
that uses this vector as its input. The metaclassifier can thus exploit
class-class correlations, and this (among other things) gives Fun an edge over
CLTC systems in which these correlations cannot be brought to bear. In this
paper we describe \emph{Generalized Funnelling} (gFun), a generalization of Fun
consisting of an HTL architecture in which 1st-tier components can be arbitrary
\emph{view-generating functions}, i.e., language-dependent functions that each
produce a language-independent representation ("view") of the document. We
describe an instance of gFun in which the metaclassifier receives as input a
vector of calibrated posterior probabilities (as in Fun) aggregated to other
embedded representations that embody other types of correlations, such as
word-class correlations (as encoded by \emph{Word-Class Embeddings}), word-word
correlations (as encoded by \emph{Multilingual Unsupervised or Supervised
Embeddings}), and word-context correlations (as encoded by \emph{multilingual
BERT}). We show that this instance of \textsc{gFun} substantially improves over
Fun and over state-of-the-art baselines, by reporting experimental results
obtained on two large, standard datasets for multilingual multilabel text
classification. Our code that implements gFun is publicly available.

    

### [[2110.14770] TRAIL: Near-Optimal Imitation Learning with Suboptimal Data](http://arxiv.org/abs/2110.14770)


  The aim in imitation learning is to learn effective policies by utilizing
near-optimal expert demonstrations. However, high-quality demonstrations from
human experts can be expensive to obtain in large numbers. On the other hand,
it is often much easier to obtain large quantities of suboptimal or
task-agnostic trajectories, which are not useful for direct imitation, but can
nevertheless provide insight into the dynamical structure of the environment,
showing what could be done in the environment even if not what should be done.
We ask the question, is it possible to utilize such suboptimal offline datasets
to facilitate provably improved downstream imitation learning? In this work, we
answer this question affirmatively and present training objectives that use
offline datasets to learn a factored transition model whose structure enables
the extraction of a latent action space. Our theoretical analysis shows that
the learned latent action space can boost the sample-efficiency of downstream
imitation learning, effectively reducing the need for large near-optimal expert
datasets through the use of auxiliary non-expert data. To learn the latent
action space in practice, we propose TRAIL (Transition-Reparametrized Actions
for Imitation Learning), an algorithm that learns an energy-based transition
model contrastively, and uses the transition model to reparametrize the action
space for sample-efficient imitation learning. We evaluate the practicality of
our objective through experiments on a set of navigation and locomotion tasks.
Our results verify the benefits suggested by our theory and show that TRAIL is
able to improve baseline imitation learning by up to 4x in performance.

    

### [[2110.14780] Combining Vagueness Detection with Deep Learning to Identify Fake News](http://arxiv.org/abs/2110.14780)


  In this paper, we combine two independent detection methods for identifying
fake news: the algorithm VAGO uses semantic rules combined with NLP techniques
to measure vagueness and subjectivity in texts, while the classifier FAKE-CLF
relies on Convolutional Neural Network classification and supervised deep
learning to classify texts as biased or legitimate. We compare the results of
the two methods on four corpora. We find a positive correlation between the
vagueness and subjectivity measures obtained by VAGO, and the classification of
text as biased by FAKE-CLF. The comparison yields mutual benefits: VAGO helps
explain the results of FAKE-CLF. Conversely FAKE-CLF helps us corroborate and
expand VAGO's database. The use of two complementary techniques (rule-based vs
data-driven) proves a fruitful approach for the challenging problem of
identifying fake news.

    

### [[2110.14782] When is BERT Multilingual? Isolating Crucial Ingredients for Cross-lingual Transfer](http://arxiv.org/abs/2110.14782)


  While recent work on multilingual language models has demonstrated their
capacity for cross-lingual zero-shot transfer on downstream tasks, there is a
lack of consensus in the community as to what shared properties between
languages enable such transfer. Analyses involving pairs of natural languages
are often inconclusive and contradictory since languages simultaneously differ
in many linguistic aspects. In this paper, we perform a large-scale empirical
study to isolate the effects of various linguistic properties by measuring
zero-shot transfer between four diverse natural languages and their
counterparts constructed by modifying aspects such as the script, word order,
and syntax. Among other things, our experiments show that the absence of
sub-word overlap significantly affects zero-shot transfer when languages differ
in their word order, and there is a strong correlation between transfer
performance and word embedding alignment between languages (e.g., R=0.94 on the
task of NLI). Our results call for focus in multilingual models on explicitly
improving word embedding alignment between languages rather than relying on its
implicit emergence.

    

### [[2110.14794] Masked LARk: Masked Learning, Aggregation and Reporting worKflow](http://arxiv.org/abs/2110.14794)


  Today, many web advertising data flows involve passive cross-site tracking of
users. Enabling such a mechanism through the usage of third party tracking
cookies (3PC) exposes sensitive user data to a large number of parties, with
little oversight on how that data can be used. Thus, most browsers are moving
towards removal of 3PC in subsequent browser iterations. In order to
substantially improve end-user privacy while allowing sites to continue to
sustain their business through ad funding, new privacy-preserving primitives
need to be introduced.
In this paper, we discuss a new proposal, called Masked LARk, for aggregation
of user engagement measurement and model training that prevents cross-site
tracking, while remaining (a) flexible, for engineering development and
maintenance, (b) secure, in the sense that cross-site tracking and tracing are
blocked and (c) open for continued model development and training, allowing
advertisers to serve relevant ads to interested users. We introduce a secure
multi-party compute (MPC) protocol that utilizes "helper" parties to train
models, so that once data leaves the browser, no downstream system can
individually construct a complete picture of the user activity. For training,
our key innovation is through the usage of masking, or the obfuscation of the
true labels, while still allowing a gradient to be accurately computed in
aggregate over a batch of data. Our protocol only utilizes light cryptography,
at such a level that an interested yet inexperienced reader can understand the
core algorithm. We develop helper endpoints that implement this system, and
give example usage of training in PyTorch.

    

### [[2110.14795] MedMNIST v2: A Large-Scale Lightweight Benchmark for 2D and 3D Biomedical Image Classification](http://arxiv.org/abs/2110.14795)


  We introduce MedMNIST v2, a large-scale MNIST-like dataset collection of
standardized biomedical images, including 12 datasets for 2D and 6 datasets for
3D. All images are pre-processed into a small size of 28x28 (2D) or 28x28x28
(3D) with the corresponding classification labels so that no background
knowledge is required for users. Covering primary data modalities in biomedical
images, MedMNIST v2 is designed to perform classification on lightweight 2D and
3D images with various dataset scales (from 100 to 100,000) and diverse tasks
(binary/multi-class, ordinal regression, and multi-label). The resulting
dataset, consisting of 708,069 2D images and 10,214 3D images in total, could
support numerous research / educational purposes in biomedical image analysis,
computer vision, and machine learning. We benchmark several baseline methods on
MedMNIST v2, including 2D / 3D neural networks and open-source / commercial
AutoML tools. The data and code are publicly available at
this https URL.

    

### [[2110.14798] Reinforcement Learning in Linear MDPs: Constant Regret and Representation Selection](http://arxiv.org/abs/2110.14798)


  We study the role of the representation of state-action value functions in
regret minimization in finite-horizon Markov Decision Processes (MDPs) with
linear structure. We first derive a necessary condition on the representation,
called universally spanning optimal features (UNISOFT), to achieve constant
regret in any MDP with linear reward function. This result encompasses the
well-known settings of low-rank MDPs and, more generally, zero inherent Bellman
error (also known as the Bellman closure assumption). We then demonstrate that
this condition is also sufficient for these classes of problems by deriving a
constant regret bound for two optimistic algorithms (LSVI-UCB and ELEANOR).
Finally, we propose an algorithm for representation selection and we prove that
it achieves constant regret when one of the given representations, or a
suitable combination of them, satisfies the UNISOFT condition.

    

### [[2110.14800] Convolutional Deep Exponential Families](http://arxiv.org/abs/2110.14800)


  We describe convolutional deep exponential families (CDEFs) in this paper.
CDEFs are built based on deep exponential families, deep probabilistic models
that capture the hierarchical dependence between latent variables. CDEFs
greatly reduce the number of free parameters by tying the weights of DEFs. Our
experiments show that CDEFs are able to uncover time correlations with a small
amount of data.

    

### [[2110.14802] You Are the Best Reviewer of Your Own Papers: An Owner-Assisted Scoring Mechanism](http://arxiv.org/abs/2110.14802)


  I consider the setting where reviewers offer very noisy scores for a number
of items for the selection of high-quality ones (e.g., peer review of large
conference proceedings) whereas the owner of these items knows the true
underlying scores but prefers not to provide this information. To address this
withholding of information, in this paper, I introduce the \textit{Isotonic
Mechanism}, a simple and efficient approach to improving on the imprecise raw
scores by leveraging certain information that the owner is incentivized to
provide. This mechanism takes as input the ranking of the items from best to
worst provided by the owner, in addition to the raw scores provided by the
reviewers. It reports adjusted scores for the items by solving a convex
optimization problem. Under certain conditions, I show that the owner's optimal
strategy is to honestly report the true ranking of the items to her best
knowledge in order to maximize the expected utility. Moreover, I prove that the
adjusted scores provided by this owner-assisted mechanism are indeed
significantly more accurate than the raw scores provided by the reviewers. This
paper concludes with several extensions of the Isotonic Mechanism and some
refinements of the mechanism for practical considerations.

    

### [[2110.14804] Minimax Optimal Quantile and Semi-Adversarial Regret via Root-Logarithmic Regularizers](http://arxiv.org/abs/2110.14804)


  Quantile (and, more generally, KL) regret bounds, such as those achieved by
NormalHedge (Chaudhuri, Freund, and Hsu 2009) and its variants, relax the goal
of competing against the best individual expert to only competing against a
majority of experts on adversarial data. More recently, the semi-adversarial
paradigm (Bilodeau, Negrea, and Roy 2020) provides an alternative relaxation of
adversarial online learning by considering data that may be neither fully
adversarial nor stochastic (i.i.d.). We achieve the minimax optimal regret in
both paradigms using FTRL with separate, novel, root-logarithmic regularizers,
both of which can be interpreted as yielding variants of NormalHedge. We extend
existing KL regret upper bounds, which hold uniformly over target
distributions, to possibly uncountable expert classes with arbitrary priors;
provide the first full-information lower bounds for quantile regret on finite
expert classes (which are tight); and provide an adaptively minimax optimal
algorithm for the semi-adversarial paradigm that adapts to the true, unknown
constraint faster, leading to uniformly improved regret bounds over existing
methods.

    

### [[2110.14807] L2ight: Enabling On-Chip Learning for Optical Neural Networks via Efficient in-situ Subspace Optimization](http://arxiv.org/abs/2110.14807)


  Silicon-photonics-based optical neural network (ONN) is a promising hardware
platform that could represent a paradigm shift in efficient AI with its
CMOS-compatibility, flexibility, ultra-low execution latency, and high energy
efficiency. In-situ training on the online programmable photonic chips is
appealing but still encounters challenging issues in on-chip implementability,
scalability, and efficiency. In this work, we propose a closed-loop ONN on-chip
learning framework L2ight to enable scalable ONN mapping and efficient in-situ
learning. L2ight adopts a three-stage learning flow that first calibrates the
complicated photonic circuit states under challenging physical constraints,
then performs photonic core mapping via combined analytical solving and
zeroth-order optimization. A subspace learning procedure with multi-level
sparsity is integrated into L2ight to enable in-situ gradient evaluation and
fast adaptation, unleashing the power of optics for real on-chip intelligence.
Extensive experiments demonstrate our proposed L2ight outperforms prior ONN
training protocols with 3-order-of-magnitude higher scalability and over 30X
better efficiency, when benchmarked on various models and learning tasks. This
synergistic framework is the first scalable on-chip learning solution that
pushes this emerging field from intractable to scalable and further to
efficient for next-generation self-learnable photonic neural chips. From a
co-design perspective, L2ight also provides essential insights for
hardware-restricted unitary subspace optimization and efficient sparse
training. We open-source our framework at
this https URL.

    

### [[2110.14809] Towards a Taxonomy of Graph Learning Datasets](http://arxiv.org/abs/2110.14809)


  Graph neural networks (GNNs) have attracted much attention due to their
ability to leverage the intrinsic geometries of the underlying data. Although
many different types of GNN models have been developed, with many benchmarking
procedures to demonstrate the superiority of one GNN model over the others,
there is a lack of systematic understanding of the underlying benchmarking
datasets, and what aspects of the model are being tested. Here, we provide a
principled approach to taxonomize graph benchmarking datasets by carefully
designing a collection of graph perturbations to probe the essential data
characteristics that GNN models leverage to perform predictions. Our
data-driven taxonomization of graph datasets provides a new understanding of
critical dataset characteristics that will enable better model evaluation and
the development of more specialized GNN models.

    

### [[2110.14811] Equivariant vector field network for many-body system modeling](http://arxiv.org/abs/2110.14811)


  Modeling many-body systems has been a long-standing challenge in science,
from classical and quantum physics to computational biology. Equivariance is a
critical physical symmetry for many-body dynamic systems, which enables robust
and accurate prediction under arbitrary reference transformations. In light of
this, great efforts have been put on encoding this symmetry into deep neural
networks, which significantly boosts the prediction performance of
down-streaming tasks. Some general equivariant models which are computationally
efficient have been proposed, however, these models have no guarantee on the
approximation power and may have information loss. In this paper, we leverage
insights from the scalarization technique in differential geometry to model
many-body systems by learning the gradient vector fields, which are SE(3) and
permutation equivariant. Specifically, we propose the Equivariant Vector Field
Network (EVFN), which is built on a novel tuple of equivariant basis and the
associated scalarization and vectorization layers. Since our tuple equivariant
basis forms a complete basis, learning the dynamics with our EVFN has no
information loss and no tensor operations are involved before the final
vectorization, which reduces the complex optimization on tensors to a minimum.
We evaluate our method on predicting trajectories of simulated Newton mechanics
systems with both full and partially observed data, as well as the equilibrium
state of small molecules (molecular conformation) evolving as a statistical
mechanics system. Experimental results across multiple tasks demonstrate that
our model achieves best or competitive performance on baseline models in
various types of datasets.

    

### [[2110.14812] Differentiable NAS Framework and Application to Ads CTR Prediction](http://arxiv.org/abs/2110.14812)


  Neural architecture search (NAS) methods aim to automatically find the
optimal deep neural network (DNN) architecture as measured by a given objective
function, typically some combination of task accuracy and inference efficiency.
For many areas, such as computer vision and natural language processing, this
is a critical, yet still time consuming process. New NAS methods have recently
made progress in improving the efficiency of this process. We implement an
extensible and modular framework for Differentiable Neural Architecture Search
(DNAS) to help solve this problem. We include an overview of the major
components of our codebase and how they interact, as well as a section on
implementing extensions to it (including a sample), in order to help users
adopt our framework for their applications across different categories of deep
learning models. To assess the capabilities of our methodology and
implementation, we apply DNAS to the problem of ads click-through rate (CTR)
prediction, arguably the highest-value and most worked on AI problem at
hyperscalers today. We develop and tailor novel search spaces to a Deep
Learning Recommendation Model (DLRM) backbone for CTR prediction, and report
state-of-the-art results on the Criteo Kaggle CTR prediction dataset.

    

### [[2110.14813] Stable Anderson Acceleration for Deep Learning](http://arxiv.org/abs/2110.14813)


  Anderson acceleration (AA) is an extrapolation technique designed to speed-up
fixed-point iterations like those arising from the iterative training of DL
models. Training DL models requires large datasets processed in randomly
sampled batches that tend to introduce in the fixed-point iteration stochastic
oscillations of amplitude roughly inversely proportional to the size of the
batch. These oscillations reduce and occasionally eliminate the positive effect
of AA. To restore AA's advantage, we combine it with an adaptive moving average
procedure that smoothes the oscillations and results in a more regular sequence
of gradient descent updates. By monitoring the relative standard deviation
between consecutive iterations, we also introduce a criterion to automatically
assess whether the moving average is needed. We applied the method to the
following DL instantiations: (i) multi-layer perceptrons (MLPs) trained on the
open-source graduate admissions dataset for regression, (ii) physics informed
neural networks (PINNs) trained on source data to solve 2d and 100d Burgers'
partial differential equations (PDEs), and (iii) ResNet50 trained on the
open-source ImageNet1k dataset for image classification. Numerical results
obtained using up to 1,536 NVIDIA V100 GPUs on the OLCF supercomputer Summit
showed the stabilizing effect of the moving average on AA for all the problems
above.

    

### [[2110.14814] Ensemble Federated Adversarial Training with Non-IID data](http://arxiv.org/abs/2110.14814)


  Despite federated learning endows distributed clients with a cooperative
training mode under the premise of protecting data privacy and security, the
clients are still vulnerable when encountering adversarial samples due to the
lack of robustness. The adversarial samples can confuse and cheat the client
models to achieve malicious purposes via injecting elaborate noise into normal
input. In this paper, we introduce a novel Ensemble Federated Adversarial
Training Method, termed as EFAT, that enables an efficacious and robust coupled
training mechanism. Our core idea is to enhance the diversity of adversarial
examples through expanding training data with different disturbances generated
from other participated clients, which helps adversarial training perform well
in Non-IID settings. Experimental results on different Non-IID situations,
including feature distribution skew and label distribution skew, show that our
proposed method achieves promising results compared with solely combining
federated learning with adversarial approaches.

    

### [[2110.14818] Temporal-Difference Value Estimation via Uncertainty-Guided Soft Updates](http://arxiv.org/abs/2110.14818)


  Temporal-Difference (TD) learning methods, such as Q-Learning, have proven
effective at learning a policy to perform control tasks. One issue with methods
like Q-Learning is that the value update introduces bias when predicting the TD
target of a unfamiliar state. Estimation noise becomes a bias after the max
operator in the policy improvement step, and carries over to value estimations
of other states, causing Q-Learning to overestimate the Q value. Algorithms
like Soft Q-Learning (SQL) introduce the notion of a soft-greedy policy, which
reduces the estimation bias via soft updates in early stages of training.
However, the inverse temperature $\beta$ that controls the softness of an
update is usually set by a hand-designed heuristic, which can be inaccurate at
capturing the uncertainty in the target estimate. Under the belief that $\beta$
is closely related to the (state dependent) model uncertainty, Entropy
Regularized Q-Learning (EQL) further introduces a principled scheduling of
$\beta$ by maintaining a collection of the model parameters that characterizes
model uncertainty. In this paper, we present Unbiased Soft Q-Learning (UQL),
which extends the work of EQL from two action, finite state spaces to
multi-action, infinite state space Markov Decision Processes. We also provide a
principled numerical scheduling of $\beta$, extended from SQL and using model
uncertainty, during the optimization process. We show the theoretical
guarantees and the effectiveness of this update method in experiments on
several discrete control environments.

    

### [[2110.14819] Characterizing and Taming Resolution in Convolutional Neural Networks](http://arxiv.org/abs/2110.14819)


  Image resolution has a significant effect on the accuracy and computational,
storage, and bandwidth costs of computer vision model inference. These costs
are exacerbated when scaling out models to large inference serving systems and
make image resolution an attractive target for optimization. However, the
choice of resolution inherently introduces additional tightly coupled choices,
such as image crop size, image detail, and compute kernel implementation that
impact computational, storage, and bandwidth costs. Further complicating this
setting, the optimal choices from the perspective of these metrics are highly
dependent on the dataset and problem scenario. We characterize this tradeoff
space, quantitatively studying the accuracy and efficiency tradeoff via
systematic and automated tuning of image resolution, image quality and
convolutional neural network operators. With the insights from this study, we
propose a dynamic resolution mechanism that removes the need to statically
choose a resolution ahead of time.

    

### [[2110.14825] Normality-Calibrated Autoencoder for Unsupervised Anomaly Detection on Data Contamination](http://arxiv.org/abs/2110.14825)


  In this paper, we propose Normality-Calibrated Autoencoder (NCAE), which can
boost anomaly detection performance on the contaminated datasets without any
prior information or explicit abnormal samples in the training phase. The NCAE
adversarially generates high confident normal samples from a latent space
having low entropy and leverages them to predict abnormal samples in a training
dataset. NCAE is trained to minimise reconstruction errors in uncontaminated
samples and maximise reconstruction errors in contaminated samples. The
experimental results demonstrate that our method outperforms shallow, hybrid,
and deep methods for unsupervised anomaly detection and achieves comparable
performance compared with semi-supervised methods using labelled anomaly
samples in the training phase. The source code is publicly available on
`this https URL.

    

### [[2110.14835] SIM-ECG: A Signal Importance Mask-driven ECGClassification System](http://arxiv.org/abs/2110.14835)


  Heart disease is the number one killer, and ECGs can assist in the early
diagnosis and prevention of deadly outcomes. Accurate ECG interpretation is
critical in detecting heart diseases; however, they are often misinterpreted
due to a lack of training or insufficient time spent to detect minute
anomalies. Subsequently, researchers turned to machine learning to assist in
the analysis. However, existing systems are not as accurate as skilled ECG
readers, and black-box approaches to providing diagnosis result in a lack of
trust by medical personnel in a given diagnosis. To address these issues, we
propose a signal importance mask feedback-based machine learning system that
continuously accepts feedback, improves accuracy, and ex-plains the resulting
diagnosis. This allows medical personnel to quickly glance at the output and
either accept the results, validate the explanation and diagnosis, or quickly
correct areas of misinterpretation, giving feedback to the system for
improvement. We have tested our system on a publicly available dataset
consisting of healthy and disease-indicating samples. We empirically show that
our algorithm is better in terms of standard performance measures such as
F-score and MacroAUC compared to normal training baseline (without feedback);
we also show that our model generates better interpretability maps.

    

### [[2110.14843] A Sequence to Sequence Model for Extracting Multiple Product Name Entities from Dialog](http://arxiv.org/abs/2110.14843)


  E-commerce voice ordering systems need to recognize multiple product name
entities from ordering utterances. Existing voice ordering systems such as
Amazon Alexa can capture only a single product name entity. This restrains
users from ordering multiple items with one utterance. In recent years,
pre-trained language models, e.g., BERT and GPT-2, have shown promising results
on NLP benchmarks like Super-GLUE. However, they can't perfectly generalize to
this Multiple Product Name Entity Recognition (MPNER) task due to the ambiguity
in voice ordering utterances. To fill this research gap, we propose Entity
Transformer (ET) neural network architectures which recognize up to 10 items in
an utterance. In our evaluation, the best ET model (conveRT + ngram + ET) has a
performance improvement of 12% on our test set compared to the non-neural
model, and outperforms BERT with ET as well. This helps customers finalize
their shopping cart via voice dialog, which improves shopping efficiency and
experience.

    

### [[2110.14846] Generalizability of density functionals learned from differentiable programming on weakly correlated spin-polarized systems](http://arxiv.org/abs/2110.14846)


  Kohn-Sham regularizer (KSR) is a machine learning approach that optimizes a
physics-informed exchange-correlation functional within a differentiable
Kohn-Sham density functional theory framework. We evaluate the generalizability
of KSR by training on atomic systems and testing on molecules at equilibrium.
We propose a spin-polarized version of KSR with local, semilocal, and nonlocal
approximations for the exchange-correlation functional. The generalization
error from our semilocal approximation is comparable to other differentiable
approaches. Our nonlocal functional outperforms any existing machine learning
functionals by predicting the ground-state energies of the test systems with a
mean absolute error of 2.7 milli-Hartrees.

    

### [[2110.14854] RIM: Reliable Influence-based Active Learning on Graphs](http://arxiv.org/abs/2110.14854)


  Message passing is the core of most graph models such as Graph Convolutional
Network (GCN) and Label Propagation (LP), which usually require a large number
of clean labeled data to smooth out the neighborhood over the graph. However,
the labeling process can be tedious, costly, and error-prone in practice. In
this paper, we propose to unify active learning (AL) and message passing
towards minimizing labeling costs, e.g., making use of few and unreliable
labels that can be obtained cheaply. We make two contributions towards that
end. First, we open up a perspective by drawing a connection between AL
enforcing message passing and social influence maximization, ensuring that the
selected samples effectively improve the model performance. Second, we propose
an extension to the influence model that incorporates an explicit quality
factor to model label noise. In this way, we derive a fundamentally new AL
selection criterion for GCN and LP--reliable influence maximization (RIM)--by
considering quantity and quality of influence simultaneously. Empirical studies
on public datasets show that RIM significantly outperforms current AL methods
in terms of accuracy and efficiency.

    

### [[2110.14855] CAP: Co-Adversarial Perturbation on Weights and Features for Improving Generalization of Graph Neural Networks](http://arxiv.org/abs/2110.14855)


  Despite the recent advances of graph neural networks (GNNs) in modeling graph
data, the training of GNNs on large datasets is notoriously hard due to the
overfitting. Adversarial training, which augments data with the worst-case
adversarial examples, has been widely demonstrated to improve model's
robustness against adversarial attacks and generalization ability. However,
while the previous adversarial training generally focuses on protecting GNNs
from spiteful attacks, it remains unclear how the adversarial training could
improve the generalization abilities of GNNs in the graph analytics problem. In
this paper, we investigate GNNs from the lens of weight and feature loss
landscapes, i.e., the loss changes with respect to model weights and node
features, respectively. We draw the conclusion that GNNs are prone to falling
into sharp local minima in these two loss landscapes, where GNNs possess poor
generalization performances. To tackle this problem, we construct the
co-adversarial perturbation (CAP) optimization problem in terms of weights and
features, and design the alternating adversarial perturbation algorithm to
flatten the weight and feature loss landscapes alternately. Furthermore, we
divide the training process into two stages: one conducting the standard
cross-entropy minimization to ensure the quick convergence of GNN models, the
other applying our alternating adversarial training to avoid falling into
locally sharp minima. The extensive experiments demonstrate our CAP can
generally improve the generalization performance of GNNs on a variety of
benchmark graph datasets.

    

### [[2110.14856] An Operator Theoretic Perspective on Pruning Deep Neural Networks](http://arxiv.org/abs/2110.14856)


  The discovery of sparse subnetworks that are able to perform as well as full
models has found broad applied and theoretical interest. While many pruning
methods have been developed to this end, the naïve approach of removing
parameters based on their magnitude has been found to be as robust as more
complex, state-of-the-art algorithms. The lack of theory behind magnitude
pruning's success, especially pre-convergence, and its relation to other
pruning methods, such as gradient based pruning, are outstanding open questions
in the field that are in need of being addressed. We make use of recent
advances in dynamical systems theory, namely Koopman operator theory, to define
a new class of theoretically motivated pruning algorithms. We show that these
algorithms can be equivalent to magnitude and gradient based pruning, unifying
these seemingly disparate methods, and that they can be used to shed light on
magnitude pruning's performance during early training.

    

### [[2110.14859] Approximate Decomposable Submodular Function Minimization for Cardinality-Based Components](http://arxiv.org/abs/2110.14859)


  Minimizing a sum of simple submodular functions of limited support is a
special case of general submodular function minimization that has seen numerous
applications in machine learning. We develop fast techniques for instances
where components in the sum are cardinality-based, meaning they depend only on
the size of the input set. This variant is one of the most widely applied in
practice, encompassing, e.g., common energy functions arising in image
segmentation and recent generalized hypergraph cut functions. We develop the
first approximation algorithms for this problem, where the approximations can
be quickly computed via reduction to a sparse graph cut problem, with graph
sparsity controlled by the desired approximation factor. Our method relies on a
new connection between sparse graph reduction techniques and piecewise linear
approximations to concave functions. Our sparse reduction technique leads to
significant improvements in theoretical runtimes, as well as substantial
practical gains in problems ranging from benchmark image segmentation tasks to
hypergraph clustering problems.

    

### [[2110.14864] Selective Sampling for Online Best-arm Identification](http://arxiv.org/abs/2110.14864)


  This work considers the problem of selective-sampling for best-arm
identification. Given a set of potential options
$\mathcal{Z}\subset\mathbb{R}^d$, a learner aims to compute with probability
greater than $1-\delta$, $\arg\max_{z\in \mathcal{Z}} z^{\top}\theta_{\ast}$
where $\theta_{\ast}$ is unknown. At each time step, a potential measurement
$x_t\in \mathcal{X}\subset\mathbb{R}^d$ is drawn IID and the learner can either
choose to take the measurement, in which case they observe a noisy measurement
of $x^{\top}\theta_{\ast}$, or to abstain from taking the measurement and wait
for a potentially more informative point to arrive in the stream. Hence the
learner faces a fundamental trade-off between the number of labeled samples
they take and when they have collected enough evidence to declare the best arm
and stop sampling. The main results of this work precisely characterize this
trade-off between labeled samples and stopping time and provide an algorithm
that nearly-optimally achieves the minimal label complexity given a desired
stopping time. In addition, we show that the optimal decision rule has a simple
geometric form based on deciding whether a point is in an ellipse or not.
Finally, our framework is general enough to capture binary classification
improving upon previous works.

    

### [[2110.14868] An $\ell^p$-based Kernel Conditional Independence Test](http://arxiv.org/abs/2110.14868)


  We propose a new computationally efficient test for conditional independence
based on the $L^{p}$ distance between two kernel-based representatives of well
suited distributions. By evaluating the difference of these two representatives
at a finite set of locations, we derive a finite dimensional approximation of
the $L^{p}$ metric, obtain its asymptotic distribution under the null
hypothesis of conditional independence and design a simple statistical test
from it. The test obtained is consistent and computationally efficient. We
conduct a series of experiments showing that the performance of our new tests
outperforms state-of-the-art methods both in term of statistical power and
type-I error even in the high dimensional setting.

    

### [[2110.14871] Generalized Depthwise-Separable Convolutions for Adversarially Robust and Efficient Neural Networks](http://arxiv.org/abs/2110.14871)


  Despite their tremendous successes, convolutional neural networks (CNNs)
incur high computational/storage costs and are vulnerable to adversarial
perturbations. Recent works on robust model compression address these
challenges by combining model compression techniques with adversarial training.
But these methods are unable to improve throughput (frames-per-second) on
real-life hardware while simultaneously preserving robustness to adversarial
perturbations. To overcome this problem, we propose the method of Generalized
Depthwise-Separable (GDWS) convolution -- an efficient, universal,
post-training approximation of a standard 2D convolution. GDWS dramatically
improves the throughput of a standard pre-trained network on real-life hardware
while preserving its robustness. Lastly, GDWS is scalable to large problem
sizes since it operates on pre-trained models and doesn't require any
additional training. We establish the optimality of GDWS as a 2D convolution
approximator and present exact algorithms for constructing optimal GDWS
convolutions under complexity and error constraints. We demonstrate the
effectiveness of GDWS via extensive experiments on CIFAR-10, SVHN, and ImageNet
datasets. Our code can be found at this https URL.

    

### [[2110.14874] Sayer: Using Implicit Feedback to Optimize System Policies](http://arxiv.org/abs/2110.14874)


  We observe that many system policies that make threshold decisions involving
a resource (e.g., time, memory, cores) naturally reveal additional, or implicit
feedback. For example, if a system waits X min for an event to occur, then it
automatically learns what would have happened if it waited <X min, because time
has a cumulative property. This feedback tells us about alternative decisions,
and can be used to improve the system policy. However, leveraging implicit
feedback is difficult because it tends to be one-sided or incomplete, and may
depend on the outcome of the event. As a result, existing practices for using
feedback, such as simply incorporating it into a data-driven model, suffer from
bias.
We develop a methodology, called Sayer, that leverages implicit feedback to
evaluate and train new system policies. Sayer builds on two ideas from
reinforcement learning -- randomized exploration and unbiased counterfactual
estimators -- to leverage data collected by an existing policy to estimate the
performance of new candidate policies, without actually deploying those
policies. Sayer uses implicit exploration and implicit data augmentation to
generate implicit feedback in an unbiased form, which is then used by an
implicit counterfactual estimator to evaluate and train new policies. The key
idea underlying these techniques is to assign implicit probabilities to
decisions that are not actually taken but whose feedback can be inferred; these
probabilities are carefully calculated to ensure statistical unbiasedness. We
apply Sayer to two production scenarios in Azure, and show that it can evaluate
arbitrary policies accurately, and train new policies that outperform the
production policies.

    

### [[2110.14880] AEVA: Black-box Backdoor Detection Using Adversarial Extreme Value Analysis](http://arxiv.org/abs/2110.14880)


  Deep neural networks (DNNs) are proved to be vulnerable against backdoor
attacks. A backdoor is often embedded in the target DNNs through injecting a
backdoor trigger into training examples, which can cause the target DNNs
misclassify an input attached with the backdoor trigger.
Existing backdoor detection methods often require the access to the original
poisoned training data, the parameters of the target DNNs, or the predictive
confidence for each given input, which are impractical in many real-world
applications, e.g., on-device deployed DNNs. We address the black-box
hard-label backdoor detection problem where the DNN is fully black-box and only
its final output label is accessible. We approach this problem from the
optimization perspective and show that the objective of backdoor detection is
bounded by an adversarial objective. Further theoretical and empirical studies
reveal that this adversarial objective leads to a solution with highly skewed
distribution; a singularity is often observed in the adversarial map of a
backdoor-infected example, which we call the adversarial singularity
phenomenon. Based on this observation, we propose the adversarial extreme value
analysis(AEVA) to detect backdoors in black-box neural networks. AEVA is based
on an extreme value analysis of the adversarial map, computed from the
monte-carlo gradient estimation. Evidenced by extensive experiments across
multiple popular tasks and backdoor attacks, our approach is shown effective in
detecting backdoor attacks under the black-box hard-label scenarios.

    

### [[2110.14883] Colossal-AI: A Unified Deep Learning System For Large-Scale Parallel Training](http://arxiv.org/abs/2110.14883)


  The Transformer architecture has improved the performance of deep learning
models in domains such as Computer Vision and Natural Language Processing.
Together with better performance come larger model sizes. This imposes
challenges to the memory wall of the current accelerator hardware such as GPU.
It is never ideal to train large models such as Vision Transformer, BERT, and
GPT on a single GPU or a single machine. There is an urgent demand to train
models in a distributed environment. However, distributed training, especially
model parallelism, often requires domain expertise in computer systems and
architecture. It remains a challenge for AI researchers to implement complex
distributed training solutions for their models.
In this paper, we introduce Colossal-AI, which is a unified parallel training
system designed to seamlessly integrate different paradigms of parallelization
techniques including data parallelism, pipeline parallelism, multiple tensor
parallelism, and sequence parallelism. Colossal-AI aims to support the AI
community to write distributed models in the same way as how they write models
normally. This allows them to focus on developing the model architecture and
separates the concerns of distributed training from the development process.
The documentations can be found at this https URL and the source
code can be found at this https URL.

    

### [[2110.14888] Teaching an Active Learner with Contrastive Examples](http://arxiv.org/abs/2110.14888)


  We study the problem of active learning with the added twist that the learner
is assisted by a helpful teacher. We consider the following natural interaction
protocol: At each round, the learner proposes a query asking for the label of
an instance $x^q$, the teacher provides the requested label $\{x^q, y^q\}$
along with explanatory information to guide the learning process. In this
paper, we view this information in the form of an additional contrastive
example ($\{x^c, y^c\}$) where $x^c$ is picked from a set constrained by $x^q$
(e.g., dissimilar instances with the same label). Our focus is to design a
teaching algorithm that can provide an informative sequence of contrastive
examples to the learner to speed up the learning process. We show that this
leads to a challenging sequence optimization problem where the algorithm's
choices at a given round depend on the history of interactions. We investigate
an efficient teaching algorithm that adaptively picks these contrastive
examples. We derive strong performance guarantees for our algorithm based on
two problem-dependent parameters and further show that for specific types of
active learners (e.g., a generalized binary search learner), the proposed
teaching algorithm exhibits strong approximation guarantees. Finally, we
illustrate our bounds and demonstrate the effectiveness of our teaching
framework via two numerical case studies.

    

### [[2110.14890] SMORE: Knowledge Graph Completion and Multi-hop Reasoning in Massive Knowledge Graphs](http://arxiv.org/abs/2110.14890)


  Knowledge graphs (KGs) capture knowledge in the form of head--relation--tail
triples and are a crucial component in many AI systems. There are two important
reasoning tasks on KGs: (1) single-hop knowledge graph completion, which
involves predicting individual links in the KG; and (2), multi-hop reasoning,
where the goal is to predict which KG entities satisfy a given logical query.
Embedding-based methods solve both tasks by first computing an embedding for
each entity and relation, then using them to form predictions. However,
existing scalable KG embedding frameworks only support single-hop knowledge
graph completion and cannot be applied to the more challenging multi-hop
reasoning task. Here we present Scalable Multi-hOp REasoning (SMORE), the first
general framework for both single-hop and multi-hop reasoning in KGs. Using a
single machine SMORE can perform multi-hop reasoning in Freebase KG (86M
entities, 338M edges), which is 1,500x larger than previously considered KGs.
The key to SMORE's runtime performance is a novel bidirectional rejection
sampling that achieves a square root reduction of the complexity of online
training data generation. Furthermore, SMORE exploits asynchronous scheduling,
overlapping CPU-based data sampling, GPU-based embedding computation, and
frequent CPU--GPU IO. SMORE increases throughput (i.e., training speed) over
prior multi-hop KG frameworks by 2.2x with minimal GPU memory requirements (2GB
for training 400-dim embeddings on 86M-node Freebase) and achieves near linear
speed-up with the number of GPUs. Moreover, on the simpler single-hop knowledge
graph completion task SMORE achieves comparable or even better runtime
performance to state-of-the-art frameworks on both single GPU and multi-GPU
settings.

    

### [[2110.14895] Pipeline Parallelism for Inference on Heterogeneous Edge Computing](http://arxiv.org/abs/2110.14895)


  Deep neural networks with large model sizes achieve state-of-the-art results
for tasks in computer vision (CV) and natural language processing (NLP).
However, these large-scale models are too compute- or memory-intensive for
resource-constrained edge devices. Prior works on parallel and distributed
execution primarily focus on training -- rather than inference -- using
homogeneous accelerators in data centers. We propose EdgePipe, a distributed
framework for edge systems that uses pipeline parallelism to both speed up
inference and enable running larger (and more accurate) models that otherwise
cannot fit on single edge devices. EdgePipe achieves these results by using an
optimal partition strategy that considers heterogeneity in compute, memory, and
network bandwidth. Our empirical evaluation demonstrates that EdgePipe achieves
$10.59\times$ and $11.88\times$ speedup using 16 edge devices for the ViT-Large
and ViT-Huge models, respectively, with no accuracy loss. Similarly, EdgePipe
improves ViT-Huge throughput by $3.93\times$ over a 4-node baseline using 16
edge devices, which independently cannot fit the model in memory. Finally, we
show up to $4.16\times$ throughput improvement over the state-of-the-art
PipeDream when using a heterogeneous set of devices.

    

### [[2110.14914] Trading via Selective Classification](http://arxiv.org/abs/2110.14914)


  A binary classifier that tries to predict if the price of an asset will
increase or decrease naturally gives rise to a trading strategy that follows
the prediction and thus always has a position in the market. Selective
classification extends a binary or many-class classifier to allow it to abstain
from making a prediction for certain inputs, thereby allowing a trade-off
between the accuracy of the resulting selective classifier against coverage of
the input feature space. Selective classifiers give rise to trading strategies
that do not take a trading position when the classifier abstains. We
investigate the application of binary and ternary selective classification to
trading strategy design. For ternary classification, in addition to classes for
the price going up or down, we include a third class that corresponds to
relatively small price moves in either direction, and gives the classifier
another way to avoid making a directional prediction. We use a walk-forward
train-validate-test approach to evaluate and compare binary and ternary,
selective and non-selective classifiers across several different feature sets
based on four classification approaches: logistic regression, random forests,
feed-forward, and recurrent neural networks. We then turn these classifiers
into trading strategies for which we perform backtests on commodity futures
markets. Our empirical results demonstrate the potential of selective
classification for trading.

    

### [[2110.14920] Meta Subspace Optimization](http://arxiv.org/abs/2110.14920)


  Subspace optimization methods have the attractive property of reducing
large-scale optimization problems to a sequence of low-dimensional subspace
optimization problems. However, existing subspace optimization frameworks adopt
a fixed update policy of the subspace, and therefore, appear to be sub-optimal.
In this paper we propose a new \emph{Meta Subspace Optimization} (MSO)
framework for large-scale optimization problems, which allows to determine the
subspace matrix at each optimization iteration. In order to remain invariant to
the optimization problem's dimension, we design an efficient meta optimizer
based on very low-dimensional subspace optimization coefficients, inducing a
rule-based agent that can significantly improve performance. Finally, we design
and analyze a reinforcement learning procedure based on the subspace
optimization dynamics whose learnt policies outperform existing subspace
optimization methods.

    

### [[2110.14923] Modeling Heterogeneous Hierarchies with Relation-specific Hyperbolic Cones](http://arxiv.org/abs/2110.14923)


  Hierarchical relations are prevalent and indispensable for organizing human
knowledge captured by a knowledge graph (KG). The key property of hierarchical
relations is that they induce a partial ordering over the entities, which needs
to be modeled in order to allow for hierarchical reasoning. However, current KG
embeddings can model only a single global hierarchy (single global partial
ordering) and fail to model multiple heterogeneous hierarchies that exist in a
single KG. Here we present ConE (Cone Embedding), a KG embedding model that is
able to simultaneously model multiple hierarchical as well as non-hierarchical
relations in a knowledge graph. ConE embeds entities into hyperbolic cones and
models relations as transformations between the cones. In particular, ConE uses
cone containment constraints in different subspaces of the hyperbolic embedding
space to capture multiple heterogeneous hierarchies. Experiments on standard
knowledge graph benchmarks show that ConE obtains state-of-the-art performance
on hierarchical reasoning tasks as well as knowledge graph completion task on
hierarchical graphs. In particular, our approach yields new state-of-the-art
Hits@1 of 45.3% on WN18RR and 16.1% on DDB14 (0.231 MRR). As for hierarchical
reasoning task, our approach outperforms previous best results by an average of
20% across three hierarchical datasets.

    

### [[2110.14927] Counterfactual Explanation of Brain Activity Classifiers using Image-to-Image Transfer by Generative Adversarial Network](http://arxiv.org/abs/2110.14927)


  Deep neural networks (DNNs) can accurately decode task-related information
from brain activations. However, because of the nonlinearity of the DNN, the
decisions made by DNNs are hardly interpretable. One of the promising
approaches for explaining such a black-box system is counterfactual
explanation. In this framework, the behavior of a black-box system is explained
by comparing real data and realistic synthetic data that are specifically
generated such that the black-box system outputs an unreal outcome. Here we
introduce a novel generative DNN (counterfactual activation generator, CAG)
that can provide counterfactual explanations for DNN-based classifiers of brain
activations. Importantly, CAG can simultaneously handle image transformation
among multiple classes associated with different behavioral tasks. Using CAG,
we demonstrated counterfactual explanation of DNN-based classifiers that
learned to discriminate brain activations of seven behavioral tasks.
Furthermore, by iterative applications of CAG, we were able to enhance and
extract subtle spatial brain activity patterns that affected the classifier's
decisions. Together, these results demonstrate that the counterfactual
explanation based on image-to-image transformation would be a promising
approach to understand and extend the current application of DNNs in fMRI
analyses.

    

### [[2110.14936] Exploration of Algorithmic Trading Strategies for the Bitcoin Market](http://arxiv.org/abs/2110.14936)


  Bitcoin is firmly becoming a mainstream asset in our global society. Its
highly volatile nature has traders and speculators flooding into the market to
take advantage of its significant price swings in the hope of making money.
This work brings an algorithmic trading approach to the Bitcoin market to
exploit the variability in its price on a day-to-day basis through the
classification of its direction. Building on previous work, in this paper, we
utilise both features internal to the Bitcoin network and external features to
inform the prediction of various machine learning models. As an empirical test
of our models, we evaluate them using a real-world trading strategy on
completely unseen data collected throughout the first quarter of 2021. Using
only a binary predictor, at the end of our three-month trading period, our
models showed an average profit of 86\%, matching the results of the more
traditional buy-and-hold strategy. However, after incorporating a risk
tolerance score into our trading strategy by utilising the model's prediction
confidence scores, our models were 12.5\% more profitable than the simple
buy-and-hold strategy. These results indicate the credible potential that
machine learning models have in extracting profit from the Bitcoin market and
act as a front-runner for further research into real-world Bitcoin trading.

    

### [[2110.14940] FocusFace: Multi-task Contrastive Learning for Masked Face Recognition](http://arxiv.org/abs/2110.14940)


  SARS-CoV-2 has presented direct and indirect challenges to the scientific
community. One of the most prominent indirect challenges advents from the
mandatory use of face masks in a large number of countries. Face recognition
methods struggle to perform identity verification with similar accuracy on
masked and unmasked individuals. It has been shown that the performance of
these methods drops considerably in the presence of face masks, especially if
the reference image is unmasked. We propose FocusFace, a multi-task
architecture that uses contrastive learning to be able to accurately perform
masked face recognition. The proposed architecture is designed to be trained
from scratch or to work on top of state-of-the-art face recognition methods
without sacrificing the capabilities of a existing models in conventional face
recognition tasks. We also explore different approaches to design the
contrastive learning module. Results are presented in terms of masked-masked
(M-M) and unmasked-masked (U-M) face verification performance. For both
settings, the results are on par with published methods, but for M-M
specifically, the proposed method was able to outperform all the solutions that
it was compared to. We further show that when using our method on top of
already existing methods the training computational costs decrease
significantly while retaining similar performances. The implementation and the
trained models are available at GitHub.

    

### [[2110.14941] A Novel Sample-efficient Deep Reinforcement Learning with Episodic Policy Transfer for PID-Based Control in Cardiac Catheterization Robots](http://arxiv.org/abs/2110.14941)


  Robotic catheterization is typically used for percutaneous coronary
intervention procedures nowadays and it involves steering flexible endovascular
tools to open up occlusion in the coronaries. In this study, a sample-efficient
deep reinforcement learning with episodic policy transfer is, for the first
time, used for motion control during robotic catheterization with fully
adaptive PID tuning strategy. The reinforcement model aids the agent to
continuously learn from its interactions in its environment and adaptively tune
PID control gains for axial navigation of endovascular tool. The model was
validated for axial motion control of a robotic system designed for
intravascular catheterization. Simulation and experimental trials were done to
validate the application of the model, and results obtained shows it could
self-tune PID gains appropriately for motion control of a robotic catheter
system. Performance comparison with conventional methods in average of 10
trials shows the agent tunes the gain better with error of 0.003 mm. Thus, the
proposed model would offer more stable set-point motion control robotic
catheterization.

    

### [[2110.14945] Preventing posterior collapse in variational autoencoders for text generation via decoder regularization](http://arxiv.org/abs/2110.14945)


  Variational autoencoders trained to minimize the reconstruction error are
sensitive to the posterior collapse problem, that is the proposal posterior
distribution is always equal to the prior. We propose a novel regularization
method based on fraternal dropout to prevent posterior collapse. We evaluate
our approach using several metrics and observe improvements in all the tested
configurations.

    

### [[2110.14947] Probabilistic Autoencoder using Fisher Information](http://arxiv.org/abs/2110.14947)


  Neural Networks play a growing role in many science disciplines, including
physics. Variational Autoencoders (VAEs) are neural networks that are able to
represent the essential information of a high dimensional data set in a low
dimensional latent space, which have a probabilistic interpretation. In
particular the so-called encoder network, the first part of the VAE, which maps
its input onto a position in latent space, additionally provides uncertainty
information in terms of a variance around this position. In this work, an
extension to the Autoencoder architecture is introduced, the FisherNet. In this
architecture, the latent space uncertainty is not generated using an additional
information channel in the encoder, but derived from the decoder, by means of
the Fisher information metric. This architecture has advantages from a
theoretical point of view as it provides a direct uncertainty quantification
derived from the model, and also accounts for uncertainty cross-correlations.
We can show experimentally that the FisherNet produces more accurate data
reconstructions than a comparable VAE and its learning performance also
apparently scales better with the number of latent space dimensions.

    

### [[2110.14953] Multi-Task Processes](http://arxiv.org/abs/2110.14953)


  Neural Processes (NPs) consider a task as a function realized from a
stochastic process and flexibly adapt to unseen tasks through inference on
functions. However, naive NPs can model data from only a single stochastic
process and are designed to infer each task independently. Since many
real-world data represent a set of correlated tasks from multiple sources
(e.g., multiple attributes and multi-sensor data), it is beneficial to infer
them jointly and exploit the underlying correlation to improve the predictive
performance. To this end, we propose Multi-Task Processes (MTPs), an extension
of NPs designed to jointly infer tasks realized from multiple stochastic
processes. We build our MTPs in a hierarchical manner such that inter-task
correlation is considered by conditioning all per-task latent variables on a
single global latent variable. In addition, we further design our MTPs so that
they can address multi-task settings with incomplete data (i.e., not all tasks
share the same set of input points), which has high practical demands in
various applications. Experiments demonstrate that MTPs can successfully model
multiple tasks jointly by discovering and exploiting their correlations in
various real-world data such as time series of weather attributes and
pixel-aligned visual modalities.

    

### [[2110.14961] Roto-translated Local Coordinate Frames For Interacting Dynamical Systems](http://arxiv.org/abs/2110.14961)


  Modelling interactions is critical in learning complex dynamical systems,
namely systems of interacting objects with highly non-linear and time-dependent
behaviour. A large class of such systems can be formalized as
$\textit{geometric graphs}$, $\textit{i.e.}$, graphs with nodes positioned in
the Euclidean space given an $\textit{arbitrarily}$ chosen global coordinate
system, for instance vehicles in a traffic scene. Notwithstanding the arbitrary
global coordinate system, the governing dynamics of the respective dynamical
systems are invariant to rotations and translations, also known as
$\textit{Galilean invariance}$. As ignoring these invariances leads to worse
generalization, in this work we propose local coordinate frames per node-object
to induce roto-translation invariance to the geometric graph of the interacting
dynamical system. Further, the local coordinate frames allow for a natural
definition of anisotropic filtering in graph neural networks. Experiments in
traffic scenes, 3D motion capture, and colliding particles demonstrate that the
proposed approach comfortably outperforms the recent state-of-the-art.

    

### [[2110.14962] Gradient Inversion with Generative Image Prior](http://arxiv.org/abs/2110.14962)


  Federated Learning (FL) is a distributed learning framework, in which the
local data never leaves clients devices to preserve privacy, and the server
trains models on the data via accessing only the gradients of those local data.
Without further privacy mechanisms such as differential privacy, this leaves
the system vulnerable against an attacker who inverts those gradients to reveal
clients sensitive data. However, a gradient is often insufficient to
reconstruct the user data without any prior knowledge. By exploiting a
generative model pretrained on the data distribution, we demonstrate that data
privacy can be easily breached. Further, when such prior knowledge is
unavailable, we investigate the possibility of learning the prior from a
sequence of gradients seen in the process of FL training. We experimentally
show that the prior in a form of generative model is learnable from iterative
interactions in FL. Our findings strongly suggest that additional mechanisms
are necessary to prevent privacy leakage in FL.

    

### [[2110.14980] Multivariate Empirical Mode Decomposition based Hybrid Model for Day-ahead Peak Load Forecasting](http://arxiv.org/abs/2110.14980)


  Accurate day-ahead peak load forecasting is crucial not only for power
dispatching but also has a great interest to investors and energy policy maker
as well as government. Literature reveals that 1% error drop of forecast can
reduce 10 million pounds operational cost. Thus, this study proposed a novel
hybrid predictive model built upon multivariate empirical mode decomposition
(MEMD) and support vector regression (SVR) with parameters optimized by
particle swarm optimization (PSO), which is able to capture precise electricity
peak load. The novelty of this study mainly comes from the application of MEMD,
which enables the multivariate data decomposition to effectively extract
inherent information among relevant variables at different time frequency
during the deterioration of multivariate over time. Two real-world load data
sets from the New South Wales (NSW) and the Victoria (VIC) in Australia have
been considered to verify the superiority of the proposed MEMD-PSO-SVR hybrid
model. The quantitative and comprehensive assessments are performed, and the
results indicate that the proposed MEMD-PSO-SVR method is a promising
alternative for day-ahead electricity peak load forecasting.

    

### [[2110.14985] Fighting the curse of dimensionality: A machine learning approach to finding global optima](http://arxiv.org/abs/2110.14985)


  Finding global optima in high-dimensional optimization problems is extremely
challenging since the number of function evaluations required to sufficiently
explore the design space increases exponentially with its dimensionality.
Furthermore, non-convex cost functions render local gradient-based search
techniques ineffective. To overcome these difficulties, here we demonstrate the
use of machine learning to find global minima, whereby autoencoders are used to
drastically reduce the search space dimensionality, and optima are found by
surveying the lower-dimensional latent spaces. The methodology is tested on
benchmark functions and on a structural optimization problem, where we show
that by exploiting the behavior of certain cost functions we either obtain the
global optimum at best or obtain superior results at worst when compared to
established optimization procedures.

    

### [[2110.14993] Using Time-Series Privileged Information for Provably Efficient Learning of Prediction Models](http://arxiv.org/abs/2110.14993)


  We study prediction of future outcomes with supervised models that use
privileged information during learning. The privileged information comprises
samples of time series observed between the baseline time of prediction and the
future outcome; this information is only available at training time which
differs from the traditional supervised learning. Our question is when using
this privileged data leads to more sample-efficient learning of models that use
only baseline data for predictions at test time. We give an algorithm for this
setting and prove that when the time series are drawn from a non-stationary
Gaussian-linear dynamical system of fixed horizon, learning with privileged
information is more efficient than learning without it. On synthetic data, we
test the limits of our algorithm and theory, both when our assumptions hold and
when they are violated. On three diverse real-world datasets, we show that our
approach is generally preferable to classical learning, particularly when data
is scarce. Finally, we relate our estimator to a distillation approach both
theoretically and empirically.

    

### [[2110.15002] On the explainability of hospitalization prediction on a large COVID-19 patient dataset](http://arxiv.org/abs/2110.15002)


  We develop various AI models to predict hospitalization on a large (over
110$k$) cohort of COVID-19 positive-tested US patients, sourced from March 2020
to February 2021. Models range from Random Forest to Neural Network (NN) and
Time Convolutional NN, where combination of the data modalities (tabular and
time dependent) are performed at different stages (early vs. model fusion).
Despite high data unbalance, the models reach average precision 0.96-0.98
(0.75-0.85), recall 0.96-0.98 (0.74-0.85), and $F_1$-score 0.97-0.98
(0.79-0.83) on the non-hospitalized (or hospitalized) class. Performances do
not significantly drop even when selected lists of features are removed to
study model adaptability to different scenarios. However, a systematic study of
the SHAP feature importance values for the developed models in the different
scenarios shows a large variability across models and use cases. This calls for
even more complete studies on several explainability methods before their
adoption in high-stakes scenarios.

    

### [[2110.15013] Deeptime: a Python library for machine learning dynamical models from time series data](http://arxiv.org/abs/2110.15013)


  Generation and analysis of time-series data is relevant to many quantitative
fields ranging from economics to fluid mechanics. In the physical sciences,
structures such as metastable and coherent sets, slow relaxation processes,
collective variables dominant transition pathways or manifolds and channels of
probability flow can be of great importance for understanding and
characterizing the kinetic, thermodynamic and mechanistic properties of the
system. Deeptime is a general purpose Python library offering various tools to
estimate dynamical models based on time-series data including conventional
linear learning methods, such as Markov state models (MSMs), Hidden Markov
Models and Koopman models, as well as kernel and deep learning approaches such
as VAMPnets and deep MSMs. The library is largely compatible with scikit-learn,
having a range of Estimator classes for these different models, but in contrast
to scikit-learn also provides deep Model classes, e.g. in the case of an MSM,
which provide a multitude of analysis methods to compute interesting
thermodynamic, kinetic and dynamical quantities, such as free energies,
relaxation times and transition paths. The library is designed for ease of use
but also easily maintainable and extensible code. In this paper we introduce
the main features and structure of the deeptime software.

    

### [[2110.15032] OneFlow: Redesign the Distributed Deep Learning Framework from Scratch](http://arxiv.org/abs/2110.15032)


  Deep learning frameworks such as TensorFlow and PyTorch provide a productive
interface for expressing and training a deep neural network (DNN) model on a
single device or using data parallelism. Still, they may not be flexible or
efficient enough in training emerging large models on distributed devices,
which require more sophisticated parallelism beyond data parallelism. Plugins
or wrappers have been developed to strengthen these frameworks for model or
pipeline parallelism, but they complicate the usage and implementation of
distributed deep learning. Aiming at a simple, neat redesign of distributed
deep learning frameworks for various parallelism paradigms, we present OneFlow,
a novel distributed training framework based on an SBP (split, broadcast and
partial-value) abstraction and the actor model. SBP enables much easier
programming of data parallelism and model parallelism than existing frameworks,
and the actor model provides a succinct runtime mechanism to manage the complex
dependencies imposed by resource constraints, data movement and computation in
distributed deep learning. We demonstrate the general applicability and
efficiency of OneFlow for training various large DNN models with case studies
and extensive experiments. The results show that OneFlow outperforms many
well-known customized libraries built on top of the state-of-the-art
frameworks. The code of OneFlow is available at:
this https URL.

    

### [[2110.15036] Orientation Probabilistic Movement Primitives on Riemannian Manifolds](http://arxiv.org/abs/2110.15036)


  Learning complex robot motions necessarily demands to have models that are
able to encode and retrieve full-pose trajectories when tasks are defined in
operational spaces. Probabilistic movement primitives (ProMPs) stand out as a
principled approach that models trajectory distributions learned from
demonstrations. ProMPs allow for trajectory modulation and blending to achieve
better generalization to novel situations. However, when ProMPs are employed in
operational space, their original formulation does not directly apply to
full-pose movements including rotational trajectories described by quaternions.
This paper proposes a Riemannian formulation of ProMPs that enables encoding
and retrieving of quaternion trajectories. Our method builds on Riemannian
manifold theory, and exploits multilinear geodesic regression for estimating
the ProMPs parameters. This novel approach makes ProMPs a suitable model for
learning complex full-pose robot motion patterns. Riemannian ProMPs are tested
on toy examples to illustrate their workflow, and on real
learning-from-demonstration experiments.

    

### [[2110.15037] Learning Deep Representation with Energy-Based Self-Expressiveness for Subspace Clustering](http://arxiv.org/abs/2110.15037)


  Deep subspace clustering has attracted increasing attention in recent years.
Almost all the existing works are required to load the whole training data into
one batch for learning the self-expressive coefficients in the framework of
deep learning. Although these methods achieve promising results, such a
learning fashion severely prevents from the usage of deeper neural network
architectures (e.g., ResNet), leading to the limited representation abilities
of the models. In this paper, we propose a new deep subspace clustering
framework, motivated by the energy-based models. In contrast to previous
approaches taking the weights of a fully connected layer as the self-expressive
coefficients, we propose to learn an energy-based network to obtain the
self-expressive coefficients by mini-batch training. By this means, it is no
longer necessary to load all data into one batch for learning, and it thus
becomes a reality that we can utilize deeper neural network models for subspace
clustering. Considering the powerful representation ability of the recently
popular self-supervised learning, we attempt to leverage self-supervised
representation learning to learn the dictionary. Finally, we propose a joint
framework to learn both the self-expressive coefficients and dictionary
simultaneously, and train the model in an end-to-end manner. The experiments
are performed on three publicly available datasets, and extensive experimental
results demonstrate our method can significantly outperform the other related
approaches. For instance, on the three datasets, our method can averagely
achieve $13.8\%$, $15.4\%$, $20.8\%$ improvements in terms of Accuracy, NMI,
and ARI over SENet which is proposed very recently and obtains the second best
results in the experiments.

    

### [[2110.15043] Hindsight Goal Ranking on Replay Buffer for Sparse Reward Environment](http://arxiv.org/abs/2110.15043)


  This paper proposes a method for prioritizing the replay experience referred
to as Hindsight Goal Ranking (HGR) in overcoming the limitation of Hindsight
Experience Replay (HER) that generates hindsight goals based on uniform
sampling. HGR samples with higher probability on the states visited in an
episode with larger temporal difference (TD) error, which is considered as a
proxy measure of the amount which the RL agent can learn from an experience.
The actual sampling for large TD error is performed in two steps: first, an
episode is sampled from the relay buffer according to the average TD error of
its experiences, and then, for the sampled episode, the hindsight goal leading
to larger TD error is sampled with higher probability from future visited
states. The proposed method combined with Deep Deterministic Policy Gradient
(DDPG), an off-policy model-free actor-critic algorithm, accelerates learning
significantly faster than that without any prioritization on four challenging
simulated robotic manipulation tasks. The empirical results show that HGR uses
samples more efficiently than previous methods across all tasks.

    

### [[2110.15047] The chemical space of terpenes: insights from data science and AI](http://arxiv.org/abs/2110.15047)


  Terpenes are a widespread class of natural products with significant chemical
and biological diversity and many of these molecules have already made their
way into medicines. Given the thousands of molecules already described, the
full characterization of this chemical space can be a challenging task when
relying in classical approaches. In this work we employ a data science-based
approach to identify, compile and characterize the diversity of terpenes
currently known in a systematic way. We worked with a natural product database,
COCONUT, from which we extracted information for nearly 60000 terpenes. For
these molecules, we conducted a subclass-by-subclass analysis in which we
highlight several chemical and physical properties relevant to several fields,
such as natural products chemistry, medicinal chemistry and drug discovery,
among others. We were also interested in assessing the potential of this data
for clustering and classification tasks. For clustering, we have applied and
compared k-means with agglomerative clustering, both to the original data and
following a step of dimensionality reduction. To this end, PCA, FastICA, Kernel
PCA, t-SNE and UMAP were used and benchmarked. We also employed a number of
methods for the purpose of classifying terpene subclasses using their
physico-chemical descriptors. Light gradient boosting machine, k-nearest
neighbors, random forests, Gaussian naiive Bayes and Multilayer perceptron,
with the best-performing algorithms yielding accuracy, F1 score, precision and
other metrics all over 0.9, thus showing the capabilities of these approaches
for the classification of terpene subclasses.

    

### [[2110.15049] Validating Gaussian Process Models with Simulation-Based Calibration](http://arxiv.org/abs/2110.15049)


  Gaussian process priors are a popular choice for Bayesian analysis of
regression problems. However, the implementation of these models can be
complex, and ensuring that the implementation is correct can be challenging. In
this paper we introduce Gaussian process simulation-based calibration, a
procedure for validating the implementation of Gaussian process models and
demonstrate the efficacy of this procedure in identifying a bug in existing
code. We also present a novel application of this procedure to identify when
marginalisation of the model hyperparameters is necessary.

    

### [[2110.15053] Adversarial Robustness in Multi-Task Learning: Promises and Illusions](http://arxiv.org/abs/2110.15053)


  Vulnerability to adversarial attacks is a well-known weakness of Deep Neural
networks. While most of the studies focus on single-task neural networks with
computer vision datasets, very little research has considered complex
multi-task models that are common in real applications. In this paper, we
evaluate the design choices that impact the robustness of multi-task deep
learning networks. We provide evidence that blindly adding auxiliary tasks, or
weighing the tasks provides a false sense of robustness. Thereby, we tone down
the claim made by previous research and study the different factors which may
affect robustness. In particular, we show that the choice of the task to
incorporate in the loss function are important factors that can be leveraged to
yield more robust models.

    

### [[2110.15056] Brain-inspired feature exaggeration in generative replay for continual learning](http://arxiv.org/abs/2110.15056)


  The catastrophic forgetting of previously learnt classes is one of the main
obstacles to the successful development of a reliable and accurate generative
continual learning model. When learning new classes, the internal
representation of previously learnt ones can often be overwritten, resulting in
the model's "memory" of earlier classes being lost over time. Recent
developments in neuroscience have uncovered a method through which the brain
avoids its own form of memory interference. Applying a targeted exaggeration of
the differences between features of similar, yet competing memories, the brain
can more easily distinguish and recall them. In this paper, the application of
such exaggeration, via the repulsion of replayed samples belonging to competing
classes, is explored. Through the development of a 'reconstruction repulsion'
loss, this paper presents a new state-of-the-art performance on the
classification of early classes in the class-incremental learning dataset
CIFAR100.

    

### [[2110.15057] Mapping conditional distributions for domain adaptation under generalized target shift](http://arxiv.org/abs/2110.15057)


  We consider the problem of unsupervised domain adaptation (UDA) between a
source and a target domain under conditional and label shift a.k.a Generalized
Target Shift (GeTarS). Unlike simpler UDA settings, few works have addressed
this challenging problem. Recent approaches learn domain-invariant
representations, yet they have practical limitations and rely on strong
assumptions that may not hold in practice. In this paper, we explore a novel
and general approach to align pretrained representations, which circumvents
existing drawbacks. Instead of constraining representation invariance, it
learns an optimal transport map, implemented as a NN, which maps source
representations onto target ones. Our approach is flexible and scalable, it
preserves the problem's structure and it has strong theoretical guarantees
under mild assumptions. In particular, our solution is unique, matches
conditional distributions across domains, recovers target proportions and
explicitly controls the target generalization risk. Through an exhaustive
comparison on several datasets, we challenge the state-of-the-art in GeTarS.

    

### [[2110.15064] Towards Fine-Grained Reasoning for Fake News Detection](http://arxiv.org/abs/2110.15064)


  The detection of fake news often requires sophisticated reasoning skills,
such as logically combining information by considering word-level subtle clues.
In this paper, we move towards fine-grained reasoning for fake news detection
by better reflecting the logical processes of human thinking and enabling the
modeling of subtle clues. In particular, we propose a fine-grained reasoning
framework by following the human's information-processing model, introduce a
mutual-reinforcement-based method for incorporating human knowledge about which
evidence is more important, and design a prior-aware bi-channel kernel graph
network to model subtle differences between pieces of evidence. Extensive
experiments show that our model outperforms the state-of-art methods and
demonstrate the explainability of our approach.

    

### [[2110.15066] Thermodynamics of Evolution and the Origin of Life](http://arxiv.org/abs/2110.15066)


  We outline a phenomenological theory of evolution and origin of life by
combining the formalism of classical thermodynamics with a statistical
description of learning. The maximum entropy principle constrained by the
requirement for minimization of the loss function is employed to derive a
canonical ensemble of organisms (population), the corresponding partition
function (macroscopic counterpart of fitness) and free energy (macroscopic
counterpart of additive fitness). We further define the biological counterparts
of temperature (biological temperature) as the measure of stochasticity of the
evolutionary process and of chemical potential (evolutionary potential) as the
amount of evolutionary work required to add a new trainable variable (such as
an additional gene) to the evolving system. We then develop a phenomenological
approach to the description of evolution, which involves modeling the grand
potential as a function of the biological temperature and evolutionary
potential. We demonstrate how this phenomenological approach can be used to
study the "ideal mutation" model of evolution and its generalizations. Finally,
we show that, within this thermodynamics framework, major transitions in
evolution, such as the transition from an ensemble of molecules to an ensemble
of organisms, that is, the origin of life, can be modeled as a special case of
bona fide physical phase transitions that are associated with the emergence of
a new type of grand canonical ensemble and the corresponding new level of
description

    

### [[2110.15072] Leveraging Recursive Gumbel-Max Trick for Approximate Inference in Combinatorial Spaces](http://arxiv.org/abs/2110.15072)


  Structured latent variables allow incorporating meaningful prior knowledge
into deep learning models. However, learning with such variables remains
challenging because of their discrete nature. Nowadays, the standard learning
approach is to define a latent variable as a perturbed algorithm output and to
use a differentiable surrogate for training. In general, the surrogate puts
additional constraints on the model and inevitably leads to biased gradients.
To alleviate these shortcomings, we extend the Gumbel-Max trick to define
distributions over structured domains. We avoid the differentiable surrogates
by leveraging the score function estimators for optimization. In particular, we
highlight a family of recursive algorithms with a common feature we call
stochastic invariant. The feature allows us to construct reliable gradient
estimates and control variates without additional constraints on the model. In
our experiments, we consider various structured latent variable models and
achieve results competitive with relaxation-based counterparts.

    

### [[2110.15073] MMD Aggregated Two-Sample Test](http://arxiv.org/abs/2110.15073)


  We propose a novel nonparametric two-sample test based on the Maximum Mean
Discrepancy (MMD), which is constructed by aggregating tests with different
kernel bandwidths. This aggregation procedure, called MMDAgg, ensures that test
power is maximised over the collection of kernels used, without requiring
held-out data for kernel selection (which results in a loss of test power), or
arbitrary kernel choices such as the median heuristic. We work in the
non-asymptotic framework, and prove that our aggregated test is minimax
adaptive over Sobolev balls. Our guarantees are not restricted to a specific
kernel, but hold for any product of one-dimensional translation invariant
characteristic kernels which are absolutely and square integrable. Moreover,
our results apply for popular numerical procedures to determine the test
threshold, namely permutations and the wild bootstrap. Through numerical
experiments on both synthetic and real-world datasets, we demonstrate that
MMDAgg outperforms alternative state-of-the-art approaches to MMD kernel
adaptation for two-sample testing.

    

### [[2110.15075] Improving Causal Effect Estimation of Weighted RegressionBased Estimator using Neural Networks](http://arxiv.org/abs/2110.15075)


  Estimating causal effects from observational data informs us about which
factors are important in an autonomous system, and enables us to take better
decisions. This is important because it has applications in selecting a
treatment in medical systems or making better strategies in industries or
making better policies for our government or even the society. Unavailability
of complete data, coupled with high cardinality of data, makes this estimation
task computationally intractable. Recently, a regression-based weighted
estimator has been introduced that is capable of producing solution using
bounded samples of a given problem. However, as the data dimension increases,
the solution produced by the regression-based method degrades. Against this
background, we introduce a neural network based estimator that improves the
solution quality in case of non-linear and finitude of samples. Finally, our
empirical evaluation illustrates a significant improvement of solution quality,
up to around $55\%$, compared to the state-of-the-art estimators.

    

### [[2110.15084] Using Non-Linear Causal Models to Study Aerosol-Cloud Interactions in the Southeast Pacific](http://arxiv.org/abs/2110.15084)


  Aerosol-cloud interactions include a myriad of effects that all begin when
aerosol enters a cloud and acts as cloud condensation nuclei (CCN). An increase
in CCN results in a decrease in the mean cloud droplet size (r$_{e}$). The
smaller droplet size leads to brighter, more expansive, and longer lasting
clouds that reflect more incoming sunlight, thus cooling the earth. Globally,
aerosol-cloud interactions cool the Earth, however the strength of the effect
is heterogeneous over different meteorological regimes. Understanding how
aerosol-cloud interactions evolve as a function of the local environment can
help us better understand sources of error in our Earth system models, which
currently fail to reproduce the observed relationships. In this work we use
recent non-linear, causal machine learning methods to study the heterogeneous
effects of aerosols on cloud droplet radius.

    

### [[2110.15087] MOOMIN: Deep Molecular Omics Network for Anti-Cancer Drug Combination Therapy](http://arxiv.org/abs/2110.15087)


  We propose the molecular omics network (MOOMIN) a multimodal graph neural
network that can predict the synergistic effect of drug combinations for cancer
treatment. Our model captures the representation based on the context of drugs
at multiple scales based on a drug-protein interaction network and metadata.
Structural properties of the compounds and proteins are encoded to create
vertex features for a message-passing scheme that operates on the bipartite
interaction graph. Propagated messages form multi-resolution drug
representations which we utilized to create drug pair descriptors. By
conditioning the drug combination representations on the cancer cell type we
define a synergy scoring function that can inductively score unseen pairs of
drugs. Experimental results on the synergy scoring task demonstrate that MOOMIN
outperforms state-of-the-art graph fingerprinting, proximity preserving node
embedding, and existing deep learning approaches. Further results establish
that the predictive performance of our model is robust to hyperparameter
changes. We demonstrate that the model makes high-quality predictions over a
wide range of cancer cell line tissues, out-of-sample predictions can be
validated with external synergy databases, and that the proposed model is
data-efficient at learning.

    

### [[2110.15092] A Law of Iterated Logarithm for Multi-Agent Reinforcement Learning](http://arxiv.org/abs/2110.15092)


  In Multi-Agent Reinforcement Learning (MARL), multiple agents interact with a
common environment, as also with each other, for solving a shared problem in
sequential decision-making. It has wide-ranging applications in gaming,
robotics, finance, etc. In this work, we derive a novel law of iterated
logarithm for a family of distributed nonlinear stochastic approximation
schemes that is useful in MARL. In particular, our result describes the
convergence rate on almost every sample path where the algorithm converges.
This result is the first of its kind in the distributed setup and provides
deeper insights than the existing ones, which only discuss convergence rates in
the expected or the CLT sense. Importantly, our result holds under
significantly weaker assumptions: neither the gossip matrix needs to be doubly
stochastic nor the stepsizes square summable. As an application, we show that,
for the stepsize $n^{-\gamma}$ with $\gamma \in (0, 1),$ the distributed TD(0)
algorithm with linear function approximation has a convergence rate of
$O(\sqrt{n^{-\gamma} \ln n })$ a.s.; for the $1/n$ type stepsize, the same is
$O(\sqrt{n^{-1} \ln \ln n})$ a.s. These decay rates do not depend on the graph
depicting the interactions among the different agents.

    

### [[2110.15093] Finite Horizon Q-learning: Stability, Convergence and Simulations](http://arxiv.org/abs/2110.15093)


  Q-learning is a popular reinforcement learning algorithm. This algorithm has
however been studied and analysed mainly in the infinite horizon setting. There
are several important applications which can be modeled in the framework of
finite horizon Markov decision processes. We develop a version of Q-learning
algorithm for finite horizon Markov decision processes (MDP) and provide a full
proof of its stability and convergence. Our analysis of stability and
convergence of finite horizon Q-learning is based entirely on the ordinary
differential equations (O.D.E) method. We also demonstrate the performance of
our algorithm on a setting of random MDP.

    

### [[2110.15094] Mosaicking to Distill: Knowledge Distillation from Out-of-Domain Data](http://arxiv.org/abs/2110.15094)


  Knowledge distillation~(KD) aims to craft a compact student model that
imitates the behavior of a pre-trained teacher in a target domain. Prior KD
approaches, despite their gratifying results, have largely relied on the
premise that \emph{in-domain} data is available to carry out the knowledge
transfer. Such an assumption, unfortunately, in many cases violates the
practical setting, since the original training data or even the data domain is
often unreachable due to privacy or copyright reasons. In this paper, we
attempt to tackle an ambitious task, termed as \emph{out-of-domain} knowledge
distillation~(OOD-KD), which allows us to conduct KD using only OOD data that
can be readily obtained at a very low cost. Admittedly, OOD-KD is by nature a
highly challenging task due to the agnostic domain gap. To this end, we
introduce a handy yet surprisingly efficacious approach, dubbed
as~\textit{MosaicKD}. The key insight behind MosaicKD lies in that, samples
from various domains share common local patterns, even though their global
semantic may vary significantly; these shared local patterns, in turn, can be
re-assembled analogous to mosaic tiling, to approximate the in-domain data and
to further alleviating the domain discrepancy. In MosaicKD, this is achieved
through a four-player min-max game, in which a generator, a discriminator, a
student network, are collectively trained in an adversarial manner, partially
under the guidance of a pre-trained teacher. We validate MosaicKD over
{classification and semantic segmentation tasks} across various benchmarks, and
demonstrate that it yields results much superior to the state-of-the-art
counterparts on OOD data. Our code is available at
\url{this https URL}.

    

### [[2110.15097] Choosing the Best of Both Worlds: Diverse and Novel Recommendations through Multi-Objective Reinforcement Learning](http://arxiv.org/abs/2110.15097)


  Since the inception of Recommender Systems (RS), the accuracy of the
recommendations in terms of relevance has been the golden criterion for
evaluating the quality of RS algorithms. However, by focusing on item
relevance, one pays a significant price in terms of other important metrics:
users get stuck in a "filter bubble" and their array of options is
significantly reduced, hence degrading the quality of the user experience and
leading to churn. Recommendation, and in particular session-based/sequential
recommendation, is a complex task with multiple - and often conflicting
objectives - that existing state-of-the-art approaches fail to address.
In this work, we take on the aforementioned challenge and introduce
Scalarized Multi-Objective Reinforcement Learning (SMORL) for the RS setting, a
novel Reinforcement Learning (RL) framework that can effectively address
multi-objective recommendation tasks. The proposed SMORL agent augments
standard recommendation models with additional RL layers that enforce it to
simultaneously satisfy three principal objectives: accuracy, diversity, and
novelty of recommendations. We integrate this framework with four
state-of-the-art session-based recommendation models and compare it with a
single-objective RL agent that only focuses on accuracy. Our experimental
results on two real-world datasets reveal a substantial increase in aggregate
diversity, a moderate increase in accuracy, reduced repetitiveness of
recommendations, and demonstrate the importance of reinforcing diversity and
novelty as complementary objectives.

    

### [[2110.15105] A Game-Theoretic Approach for Improving Generalization Ability of TSP Solvers](http://arxiv.org/abs/2110.15105)


  In this paper, we shed new light on the generalization ability of deep
learning-based solvers for Traveling Salesman Problems (TSP). Specifically, we
introduce a two-player zero-sum framework between a trainable \emph{Solver} and
a \emph{Data Generator}, where the Solver aims to solve the task instances
provided by the Generator, and the Generator aims to generate increasingly
difficult instances for improving the Solver. Grounded in \textsl{Policy Space
Response Oracle} (PSRO) methods, our two-player framework outputs a population
of best-responding Solvers, over which we can mix and output a combined model
that achieves the least exploitability against the Generator, and thereby the
most generalizable performance on different TSP tasks. We conduct experiments
on a variety of TSP instances with different types and sizes. Results suggest
that our Solvers achieve the state-of-the-art performance even on tasks the
Solver never meets, whilst the performance of other deep learning-based Solvers
drops sharply due to over-fitting. On real-world instances from
\textsc{TSPLib}, our method also attains a \textbf{12\%} improvement, in terms
of optimal gap, over the best baseline model. To demonstrate the principle of
our framework, we study the learning outcome of the proposed two-player game
and demonstrate that the exploitability of the Solver population decreases
during training, and it eventually approximates the Nash equilibrium along with
the Generator.

    

### [[2110.15108] Generalized Anomaly Detection](http://arxiv.org/abs/2110.15108)


  We study anomaly detection for the case when the normal class consists of
more than one object category. This is an obvious generalization of the
standard one-class anomaly detection problem. However, we show that jointly
using multiple one-class anomaly detectors to solve this problem yields poorer
results as compared to training a single one-class anomaly detector on all
normal object categories together. We further develop a new anomaly detector
called DeepMAD that learns compact distinguishing features by exploiting the
multiple normal objects categories. This algorithm achieves higher AUC values
for different datasets compared to two top performing one-class algorithms that
either are trained on each normal object category or jointly trained on all
normal object categories combined. In addition to theoretical results we
present empirical results using the CIFAR-10, fMNIST, CIFAR-100, and a new
dataset we developed called RECYCLE.

    

### [[2110.15122] CAFE: Catastrophic Data Leakage in Vertical Federated Learning](http://arxiv.org/abs/2110.15122)


  Recent studies show that private training data can be leaked through the
gradients sharing mechanism deployed in distributed machine learning systems,
such as federated learning (FL). Increasing batch size to complicate data
recovery is often viewed as a promising defense strategy against data leakage.
In this paper, we revisit this defense premise and propose an advanced data
leakage attack with theoretical justification to efficiently recover batch data
from the shared aggregated gradients. We name our proposed method as
\textit{\underline{c}atastrophic d\underline{a}ta leakage in vertical
\underline{f}ederated l\underline{e}arning} (CAFE). Comparing to existing data
leakage attacks, our extensive experimental results on vertical FL settings
demonstrate the effectiveness of CAFE to perform large-batch data leakage
attack with improved data recovery quality. We also propose a practical
countermeasure to mitigate CAFE. Our results suggest that private data
participated in standard FL, especially the vertical case, have a high risk of
being leaked from the training gradients. Our analysis implies unprecedented
and practical data leakage risks in those learning settings. The code of our
work is available at
\href{this https URL}{\textcolor{blue}{\url{this https URL}}}.

    

### [[2110.15127] Lightweight Mobile Automated Assistant-to-physician for Global Lower-resource Areas](http://arxiv.org/abs/2110.15127)


  Importance: Lower-resource areas in Africa and Asia face a unique set of
healthcare challenges: the dual high burden of communicable and
non-communicable diseases; a paucity of highly trained primary healthcare
providers in both rural and densely populated urban areas; and a lack of
reliable, inexpensive internet connections. Objective: To address these
challenges, we designed an artificial intelligence assistant to help primary
healthcare providers in lower-resource areas document demographic and medical
sign/symptom data and to record and share diagnostic data in real-time with a
centralized database. Design: We trained our system using multiple data sets,
including US-based electronic medical records (EMRs) and open-source medical
literature and developed an adaptive, general medical assistant system based on
machine learning algorithms. Main outcomes and Measure: The application
collects basic information from patients and provides primary care providers
with diagnoses and prescriptions suggestions. The application is unique from
existing systems in that it covers a wide range of common diseases, signs, and
medication typical in lower-resource countries; the application works with or
without an active internet connection. Results: We have built and implemented
an adaptive learning system that assists trained primary care professionals by
means of an Android smartphone application, which interacts with a central
database and collects real-time data. The application has been tested by dozens
of primary care providers. Conclusions and Relevance: Our application would
provide primary healthcare providers in lower-resource areas with a tool that
enables faster and more accurate documentation of medical encounters. This
application could be leveraged to automatically populate local or national EMR
systems.

    

### [[2110.15132] Generating Table Vector Representations](http://arxiv.org/abs/2110.15132)


  High-quality Web tables are rich sources of information that can be used to
populate Knowledge Graphs (KG). The focus of this paper is an evaluation of
methods for table-to-class annotation, which is a sub-task of Table
Interpretation (TI). We provide a formal definition for table classification as
a machine learning task. We propose an experimental setup and we evaluate 5
fundamentally different approaches to find the best method for generating
vector table representations. Our findings indicate that although transfer
learning methods achieve high F1 score on the table classification task,
dedicated table encoding models are a promising direction as they appear to
capture richer semantics.

    

### [[2110.15133] Deep Calibration of Interest Rates Model](http://arxiv.org/abs/2110.15133)


  For any financial institution it is a necessity to be able to apprehend the
behavior of interest rates. Despite the use of Deep Learning that is growing
very fastly, due to many reasons (expertise, ease of use, ...) classic rates
models such as CIR, or the Gaussian family are still being used widely. We
propose to calibrate the five parameters of the G2++ model using Neural
Networks. To achieve that, we construct synthetic data sets of parameters drawn
uniformly from a reference set of parameters calibrated from the market. From
those parameters, we compute Zero-Coupon and Forward rates and their
covariances and correlations. Our first model is a Fully Connected Neural
network and uses only covariances and correlations. We show that covariances
are more suited to the problem than correlations. The second model is a
Convulutional Neural Network using only Zero-Coupon rates with no
transformation. The methods we propose perform very quickly (less than 0.3
seconds for 2 000 calibrations) and have low errors and good fitting.

    

### [[2110.15136] Aggregation as Unsupervised Learning and its Evaluation](http://arxiv.org/abs/2110.15136)


  Regression uses supervised machine learning to find a model that combines
several independent variables to predict a dependent variable based on ground
truth (labeled) data, i.e., tuples of independent and dependent variables
(labels). Similarly, aggregation also combines several independent variables to
a dependent variable. The dependent variable should preserve properties of the
independent variables, e.g., the ranking or relative distance of the
independent variable tuples, and/or represent a latent ground truth that is a
function of these independent variables. However, ground truth data is not
available for finding the aggregation model. Consequently, aggregation models
are data agnostic or can only be derived with unsupervised machine learning
approaches.
We introduce a novel unsupervised aggregation approach based on intrinsic
properties of unlabeled training data, such as the cumulative probability
distributions of the single independent variables and their mutual
dependencies.
We present an empirical evaluation framework that allows assessing the
proposed approach against other aggregation approaches from two perspectives:
(i) how well the aggregation output represents properties of the input tuples,
and (ii) how well can aggregated output predict a latent ground truth. To this
end, we use data sets for assessing supervised regression approaches that
contain explicit ground truth labels. However, the ground truth is not used for
deriving the aggregation models, but it allows for the assessment from a
perspective (ii). More specifically, we use regression data sets from the UCI
machine learning repository and benchmark several data-agnostic and
unsupervised approaches for aggregation against ours.
The benchmark results indicate that our approach outperforms the other
data-agnostic and unsupervised aggregation approaches. It is almost on par with
linear regression.

    

### [[2110.15137] Learning Aggregations of Binary Activated Neural Networks with Probabilities over Representations](http://arxiv.org/abs/2110.15137)


  Considering a probability distribution over parameters is known as an
efficient strategy to learn a neural network with non-differentiable activation
functions. We study the expectation of a probabilistic neural network as a
predictor by itself, focusing on the aggregation of binary activated neural
networks with normal distributions over real-valued weights. Our work leverages
a recent analysis derived from the PAC-Bayesian framework that derives tight
generalization bounds and learning procedures for the expected output value of
such an aggregation, which is given by an analytical expression. While the
combinatorial nature of the latter has been circumvented by approximations in
previous works, we show that the exact computation remains tractable for deep
but narrow neural networks, thanks to a dynamic programming approach. This
leads us to a peculiar bound minimization learning algorithm for binary
activated neural networks, where the forward pass propagates probabilities over
representations instead of activation values. A stochastic counterpart of this
new neural networks training scheme that scales to wider architectures is
proposed.

    

### [[2110.15142] Learning Feasibility to Imitate Demonstrators with Different Dynamics](http://arxiv.org/abs/2110.15142)


  The goal of learning from demonstrations is to learn a policy for an agent
(imitator) by mimicking the behavior in the demonstrations. Prior works on
learning from demonstrations assume that the demonstrations are collected by a
demonstrator that has the same dynamics as the imitator. However, in many
real-world applications, this assumption is limiting -- to improve the problem
of lack of data in robotics, we would like to be able to leverage
demonstrations collected from agents with different dynamics. This can be
challenging as the demonstrations might not even be feasible for the imitator.
Our insight is that we can learn a feasibility metric that captures the
likelihood of a demonstration being feasible by the imitator. We develop a
feasibility MDP (f-MDP) and derive the feasibility score by learning an optimal
policy in the f-MDP. Our proposed feasibility measure encourages the imitator
to learn from more informative demonstrations, and disregard the far from
feasible demonstrations. Our experiments on four simulated environments and on
a real robot show that the policy learned with our approach achieves a higher
expected return than prior works. We show the videos of the real robot arm
experiments on our website
(this https URL).

    

### [[2110.15144] Deep Learning Analysis of Cardiac MRI in Legacy Datasets: Multi-Ethnic Study of Atherosclerosis](http://arxiv.org/abs/2110.15144)


  The shape and motion of the heart provide essential clues to understanding
the mechanisms of cardiovascular disease. With the advent of large-scale
cardiac imaging data, statistical atlases become a powerful tool to provide
automated and precise quantification of the status of patient-specific heart
geometry with respect to reference populations. The Multi-Ethnic Study of
Atherosclerosis (MESA), begun in 2000, was the first large cohort study to
incorporate cardiovascular MRI in over 5000 participants, and there is now a
wealth of follow-up data over 20 years. Building a machine learning based
automated analysis is necessary to extract the additional imaging information
necessary for expanding original manual analyses. However, machine learning
tools trained on MRI datasets with different pulse sequences fail on such
legacy datasets. Here, we describe an automated atlas construction pipeline
using deep learning methods applied to the legacy cardiac MRI data in MESA. For
detection of anatomical cardiac landmark points, a modified VGGNet
convolutional neural network architecture was used in conjunction with a
transfer learning sequence between two-chamber, four-chamber, and short-axis
MRI views. A U-Net architecture was used for detection of the endocardial and
epicardial boundaries in short axis images. Both network architectures resulted
in good segmentation and landmark detection accuracies compared with
inter-observer variations. Statistical relationships with common risk factors
were similar between atlases derived from automated vs manual annotations. The
automated atlas can be employed in future studies to examine the relationships
between cardiac morphology and future events.

    

### [[2110.15148] A first-order primal-dual method with adaptivity to local smoothness](http://arxiv.org/abs/2110.15148)


  We consider the problem of finding a saddle point for the convex-concave
objective $\min_x \max_y f(x) + \langle Ax, y\rangle - g^*(y)$, where $f$ is a
convex function with locally Lipschitz gradient and $g$ is convex and possibly
non-smooth. We propose an adaptive version of the Condat-Vũ algorithm, which
alternates between primal gradient steps and dual proximal steps. The method
achieves stepsize adaptivity through a simple rule involving $\|A\|$ and the
norm of recently computed gradients of $f$. Under standard assumptions, we
prove an $\mathcal{O}(k^{-1})$ ergodic convergence rate. Furthermore, when $f$
is also locally strongly convex and $A$ has full row rank we show that our
method converges with a linear rate. Numerical experiments are provided for
illustrating the practical performance of the algorithm.

    

### [[2110.15162] Exoplanet atmosphere evolution: emulation with random forests](http://arxiv.org/abs/2110.15162)


  Atmospheric mass-loss is known to play a leading role in sculpting the
demographics of small, close-in exoplanets. Understanding the impact of such
mass-loss driven evolution requires modelling large populations of planets to
compare with the observed exoplanet distributions. As the quality of planet
observations increases, so should the accuracy of the models used to understand
them. However, to date, only simple semi-analytic models have been used in such
comparisons since modelling populations of planets with high accuracy demands a
high computational cost. To address this, we turn to machine learning. We
implement random forests trained on atmospheric evolution models, including XUV
photoevaporation, to predict a given planet's final radius and atmospheric
mass. This evolution emulator is found to have an RMS fractional radius error
of 1$\%$ from the original models and is $\sim 400$ times faster to evaluate.
As a test case, we use the emulator to infer the initial properties of
Kepler-36b and c, confirming that their architecture is consistent with
atmospheric mass loss. Our new approach opens the door to highly sophisticated
models of atmospheric evolution being used in demographic analysis, which will
yield further insight into planet formation and evolution.

    

### [[2110.15165] Extracting Clinician's Goals by What-if Interpretable Modeling](http://arxiv.org/abs/2110.15165)


  Although reinforcement learning (RL) has tremendous success in many fields,
applying RL to real-world settings such as healthcare is challenging when the
reward is hard to specify and no exploration is allowed. In this work, we focus
on recovering clinicians' rewards in treating patients. We incorporate the
what-if reasoning to explain clinician's actions based on future outcomes. We
use generalized additive models (GAMs) - a class of accurate, interpretable
models - to recover the reward. In both simulation and a real-world hospital
dataset, we show our model outperforms baselines. Finally, our model's
explanations match several clinical guidelines when treating patients while we
found the previously-used linear model often contradicts them.

    

### [[2110.15168] Labeled sample compression schemes for complexes of oriented matroids](http://arxiv.org/abs/2110.15168)


  We show that the topes of a complex of oriented matroids (abbreviated COM) of
VC-dimension $d$ admit a proper labeled sample compression scheme of size $d$.
This considerably extends results of Moran and Warmuth and the authors and is a
step towards the sample compression conjecture -- one of the oldest open in
computational learning theory. On the one hand, our approach exploits the rich
combinatorial cell structure of COMs via oriented matroid theory. On the other
hand viewing tope graphs of COMs as partial cubes creates a fruitful link to
metric graph theory

    

### [[2110.15171] Privacy Aware Person Detection in Surveillance Data](http://arxiv.org/abs/2110.15171)


  Crowd management relies on inspection of surveillance video either by
operators or by object detection models. These models are large, making it
difficult to deploy them on resource constrained edge hardware. Instead, the
computations are often offloaded to a (third party) cloud platform. While crowd
management may be a legitimate application, transferring video from the camera
to remote infrastructure may open the door for extracting additional
information that are infringements of privacy, like person tracking or face
recognition. In this paper, we use adversarial training to obtain a lightweight
obfuscator that transforms video frames to only retain the necessary
information for person detection. Importantly, the obfuscated data can be
processed by publicly available object detectors without retraining and without
significant loss of accuracy.

    

### [[2110.15172] Conditioning Sparse Variational Gaussian Processes for Online Decision-making](http://arxiv.org/abs/2110.15172)


  With a principled representation of uncertainty and closed form posterior
updates, Gaussian processes (GPs) are a natural choice for online decision
making. However, Gaussian processes typically require at least
$\mathcal{O}(n^2)$ computations for $n$ training points, limiting their general
applicability. Stochastic variational Gaussian processes (SVGPs) can provide
scalable inference for a dataset of fixed size, but are difficult to
efficiently condition on new data. We propose online variational conditioning
(OVC), a procedure for efficiently conditioning SVGPs in an online setting that
does not require re-training through the evidence lower bound with the addition
of new data. OVC enables the pairing of SVGPs with advanced look-ahead
acquisition functions for black-box optimization, even with non-Gaussian
likelihoods. We show OVC provides compelling performance in a range of
applications including active learning of malaria incidence, and reinforcement
learning on MuJoCo simulated robotic control tasks.

    

### [[2110.15174] On Provable Benefits of Depth in Training Graph Convolutional Networks](http://arxiv.org/abs/2110.15174)


  Graph Convolutional Networks (GCNs) are known to suffer from performance
degradation as the number of layers increases, which is usually attributed to
over-smoothing. Despite the apparent consensus, we observe that there exists a
discrepancy between the theoretical understanding of over-smoothing and the
practical capabilities of GCNs. Specifically, we argue that over-smoothing does
not necessarily happen in practice, a deeper model is provably expressive, can
converge to global optimum with linear convergence rate, and achieve very high
training accuracy as long as properly trained. Despite being capable of
achieving high training accuracy, empirical results show that the deeper models
generalize poorly on the testing stage and existing theoretical understanding
of such behavior remains elusive. To achieve better understanding, we carefully
analyze the generalization capability of GCNs, and show that the training
strategies to achieve high training accuracy significantly deteriorate the
generalization capability of GCNs. Motivated by these findings, we propose a
decoupled structure for GCNs that detaches weight matrices from feature
propagation to preserve the expressive power and ensure good generalization
performance. We conduct empirical evaluations on various synthetic and
real-world datasets to validate the correctness of our theory.

    

### [[2110.15182] Dist2Cycle: A Simplicial Neural Network for Homology Localization](http://arxiv.org/abs/2110.15182)


  Simplicial complexes can be viewed as high dimensional generalizations of
graphs that explicitly encode multi-way ordered relations between vertices at
different resolutions, all at once. This concept is central towards detection
of higher dimensional topological features of data, features to which graphs,
encoding only pairwise relationships, remain oblivious. While attempts have
been made to extend Graph Neural Networks (GNNs) to a simplicial complex
setting, the methods do not inherently exploit, or reason about, the underlying
topological structure of the network. We propose a graph convolutional model
for learning functions parametrized by the $k$-homological features of
simplicial complexes. By spectrally manipulating their combinatorial
$k$-dimensional Hodge Laplacians, the proposed model enables learning
topological features of the underlying simplicial complexes, specifically, the
distance of each $k$-simplex from the nearest "optimal" $k$-th homology
generator, effectively providing an alternative to homology localization.

    

### [[2110.15188] The magnitude vector of images](http://arxiv.org/abs/2110.15188)


  The magnitude of a finite metric space is a recently-introduced invariant
quantity. Despite beneficial theoretical and practical properties, such as a
general utility for outlier detection, and a close connection to Laplace radial
basis kernels, magnitude has received little attention by the machine learning
community so far. In this work, we investigate the properties of magnitude on
individual images, with each image forming its own metric space. We show that
the known properties of outlier detection translate to edge detection in images
and we give supporting theoretical justifications. In addition, we provide a
proof of concept of its utility by using a novel magnitude layer to defend
against adversarial attacks. Since naive magnitude calculations may be
computationally prohibitive, we introduce an algorithm that leverages the
regular structure of images to dramatically reduce the computational cost.

    

### [[2110.15191] URLB: Unsupervised Reinforcement Learning Benchmark](http://arxiv.org/abs/2110.15191)


  Deep Reinforcement Learning (RL) has emerged as a powerful paradigm to solve
a range of complex yet specific control tasks. Yet training generalist agents
that can quickly adapt to new tasks remains an outstanding challenge. Recent
advances in unsupervised RL have shown that pre-training RL agents with
self-supervised intrinsic rewards can result in efficient adaptation. However,
these algorithms have been hard to compare and develop due to the lack of a
unified benchmark. To this end, we introduce the Unsupervised Reinforcement
Learning Benchmark (URLB). URLB consists of two phases: reward-free
pre-training and downstream task adaptation with extrinsic rewards. Building on
the DeepMind Control Suite, we provide twelve continuous control tasks from
three domains for evaluation and open-source code for eight leading
unsupervised RL methods. We find that the implemented baselines make progress
but are not able to solve URLB and propose directions for future research.

    

### [[2110.15192] RGP: Neural Network Pruning through Its Regular Graph Structure](http://arxiv.org/abs/2110.15192)


  Lightweight model design has become an important direction in the application
of deep learning technology, pruning is an effective mean to achieve a large
reduction in model parameters and FLOPs. The existing neural network pruning
methods mostly start from the importance of parameters, and design parameter
evaluation metrics to perform parameter pruning iteratively. These methods are
not studied from the perspective of model topology, may be effective but not
efficient, and requires completely different pruning for different datasets. In
this paper, we study the graph structure of the neural network, and propose
regular graph based pruning (RGP) to perform a one-shot neural network pruning.
We generate a regular graph, set the node degree value of the graph to meet the
pruning ratio, and reduce the average shortest path length of the graph by
swapping the edges to obtain the optimal edge distribution. Finally, the
obtained graph is mapped into a neural network structure to realize pruning.
Experiments show that the average shortest path length of the graph is
negatively correlated with the classification accuracy of the corresponding
neural network, and the proposed RGP shows a strong precision retention
capability with extremely high parameter reduction (more than 90%) and FLOPs
reduction (more than 90%).

    

### [[2110.15200] Generating 3D Molecules Conditional on Receptor Binding Sites with Deep Generative Models](http://arxiv.org/abs/2110.15200)


  The goal of structure-based drug discovery is to find small molecules that
bind to a given target protein. Deep learning has been used to generate
drug-like molecules with certain cheminformatic properties, but has not yet
been applied to generating 3D molecules predicted to bind to proteins by
sampling the conditional distribution of protein-ligand binding interactions.
In this work, we describe for the first time a deep learning system for
generating 3D molecular structures conditioned on a receptor binding site. We
approach the problem using a conditional variational autoencoder trained on an
atomic density grid representation of cross-docked protein-ligand structures.
We apply atom fitting and bond inference procedures to construct valid
molecular conformations from generated atomic densities. We evaluate the
properties of the generated molecules and demonstrate that they change
significantly when conditioned on mutated receptors. We also explore the latent
space learned by our generative model using sampling and interpolation
techniques. This work opens the door for end-to-end prediction of stable
bioactive molecules from protein structures with deep learning.

    

### [[2110.15210] Towards Model Agnostic Federated Learning Using Knowledge Distillation](http://arxiv.org/abs/2110.15210)


  An often unquestioned assumption underlying most current federated learning
algorithms is that all the participants use identical model architectures. In
this work, we initiate a theoretical study of model agnostic communication
protocols which would allow data holders (agents) using different models to
collaborate with each other and perform federated learning. We focus on the
setting where the two agents are attempting to perform kernel regression using
different kernels (and hence have different models). Our study yields a
surprising result -- the most natural algorithm of using alternating knowledge
distillation (AKD) imposes overly strong regularization and may lead to severe
under-fitting. Our theory also shows an interesting connection between AKD and
the alternating projection algorithm for finding intersection of sets.
Leveraging this connection, we propose a new algorithms which improve upon AKD.
Our theoretical predictions also closely match real world experiments using
neural networks. Thus, our work proposes a rich yet tractable framework for
analyzing and developing new practical model agnostic federated learning
algorithms.

    

### [[2110.15225] Pruning Attention Heads of Transformer Models Using A* Search: A Novel Approach to Compress Big NLP Architectures](http://arxiv.org/abs/2110.15225)


  Recent years have seen a growing adoption of Transformer models such as BERT
in Natural Language Processing and even in Computer Vision. However, due to the
size, there has been limited adoption of such models within
resource-constrained computing environments This paper proposes novel pruning
algorithms to compress transformer models by eliminating redundant Attention
Heads. We apply the A* search algorithm to obtain a pruned model with minimal
accuracy guarantees. Our results indicate that the method could eliminate as
much as 40% of the attention heads in the BERT transformer model with almost no
loss in accuracy.

    

### [[2110.15231] Exploring Covariate and Concept Shift for Detection and Calibration of Out-of-Distribution Data](http://arxiv.org/abs/2110.15231)


  Moving beyond testing on in-distribution data works on Out-of-Distribution
(OOD) detection have recently increased in popularity. A recent attempt to
categorize OOD data introduces the concept of near and far OOD detection.
Specifically, prior works define characteristics of OOD data in terms of
detection difficulty. We propose to characterize the spectrum of OOD data using
two types of distribution shifts: covariate shift and concept shift, where
covariate shift corresponds to change in style, e.g., noise, and concept shift
indicates a change in semantics. This characterization reveals that sensitivity
to each type of shift is important to the detection and confidence calibration
of OOD data. Consequently, we investigate score functions that capture
sensitivity to each type of dataset shift and methods that improve them. To
this end, we theoretically derive two score functions for OOD detection, the
covariate shift score and concept shift score, based on the decomposition of
KL-divergence for both scores, and propose a geometrically-inspired method
(Geometric ODIN) to improve OOD detection under both shifts with only
in-distribution data. Additionally, the proposed method naturally leads to an
expressive post-hoc calibration function which yields state-of-the-art
calibration performance on both in-distribution and out-of-distribution data.
We are the first to propose a method that works well across both OOD detection
and calibration and under different types of shifts. Specifically, we improve
the previous state-of-the-art OOD detection by relatively 7% AUROC on CIFAR100
vs. SVHN and achieve the best calibration performance of 0.084 Expected
Calibration Error on the corrupted CIFAR100C dataset. View project page at
this https URL.

    

### [[2110.15232] Guided Evolution for Neural Architecture Search](http://arxiv.org/abs/2110.15232)


  Neural Architecture Search (NAS) methods have been successfully applied to
image tasks with excellent results. However, NAS methods are often complex and
tend to converge to local minima as soon as generated architectures seem to
yield good results. In this paper, we propose G-EA, a novel approach for guided
evolutionary NAS. The rationale behind G-EA, is to explore the search space by
generating and evaluating several architectures in each generation at
initialization stage using a zero-proxy estimator, where only the
highest-scoring network is trained and kept for the next generation. This
evaluation at initialization stage allows continuous extraction of knowledge
from the search space without increasing computation, thus allowing the search
to be efficiently guided. Moreover, G-EA forces exploitation of the most
performant networks by descendant generation while at the same time forcing
exploration by parent mutation and by favouring younger architectures to the
detriment of older ones. Experimental results demonstrate the effectiveness of
the proposed method, showing that G-EA achieves state-of-the-art results in
NAS-Bench-201 search space in CIFAR-10, CIFAR-100 and ImageNet16-120, with mean
accuracies of 93.98%, 72.12% and 45.94% respectively.

    

### [[2110.15245] From Machine Learning to Robotics: Challenges and Opportunities for Embodied Intelligence](http://arxiv.org/abs/2110.15245)


  Machine learning has long since become a keystone technology, accelerating
science and applications in a broad range of domains. Consequently, the notion
of applying learning methods to a particular problem set has become an
established and valuable modus operandi to advance a particular field. In this
article we argue that such an approach does not straightforwardly extended to
robotics -- or to embodied intelligence more generally: systems which engage in
a purposeful exchange of energy and information with a physical environment. In
particular, the purview of embodied intelligent agents extends significantly
beyond the typical considerations of main-stream machine learning approaches,
which typically (i) do not consider operation under conditions significantly
different from those encountered during training; (ii) do not consider the
often substantial, long-lasting and potentially safety-critical nature of
interactions during learning and deployment; (iii) do not require ready
adaptation to novel tasks while at the same time (iv) effectively and
efficiently curating and extending their models of the world through targeted
and deliberate actions. In reality, therefore, these limitations result in
learning-based systems which suffer from many of the same operational
shortcomings as more traditional, engineering-based approaches when deployed on
a robot outside a well defined, and often narrow operating envelope. Contrary
to viewing embodied intelligence as another application domain for machine
learning, here we argue that it is in fact a key driver for the advancement of
machine learning technology. In this article our goal is to highlight
challenges and opportunities that are specific to embodied intelligence and to
propose research directions which may significantly advance the
state-of-the-art in robot learning.

    

### [[2110.15252] FeO2: Federated Learning with Opt-Out Differential Privacy](http://arxiv.org/abs/2110.15252)


  Federated learning (FL) is an emerging privacy-preserving paradigm, where a
global model is trained at a central server while keeping client data local.
However, FL can still indirectly leak private client information through model
updates during training. Differential privacy (DP) can be employed to provide
privacy guarantees within FL, typically at the cost of degraded final trained
model. In this work, we consider a heterogeneous DP setup where clients are
considered private by default, but some might choose to opt out of DP. We
propose a new algorithm for federated learning with opt-out DP, referred to as
\emph{FeO2}, along with a discussion on its advantages compared to the
baselines of private and personalized FL algorithms. We prove that the
server-side and client-side procedures in \emph{FeO2} are optimal for a
simplified linear problem. We also analyze the incentive for opting out of DP
in terms of performance gain. Through numerical experiments, we show that
\emph{FeO2} provides up to $9.27\%$ performance gain in the global model
compared to the baseline DP FL for the considered datasets. Additionally, we
show a gap in the average performance of personalized models between
non-private and private clients of up to $3.49\%$, empirically illustrating an
incentive for clients to opt out.

    

### [[2110.15253] Understanding How Encoder-Decoder Architectures Attend](http://arxiv.org/abs/2110.15253)


  Encoder-decoder networks with attention have proven to be a powerful way to
solve many sequence-to-sequence tasks. In these networks, attention aligns
encoder and decoder states and is often used for visualizing network behavior.
However, the mechanisms used by networks to generate appropriate attention
matrices are still mysterious. Moreover, how these mechanisms vary depending on
the particular architecture used for the encoder and decoder (recurrent,
feed-forward, etc.) are also not well understood. In this work, we investigate
how encoder-decoder networks solve different sequence-to-sequence tasks. We
introduce a way of decomposing hidden states over a sequence into temporal
(independent of input) and input-driven (independent of sequence position)
components. This reveals how attention matrices are formed: depending on the
task requirements, networks rely more heavily on either the temporal or
input-driven components. These findings hold across both recurrent and
feed-forward architectures despite their differences in forming the temporal
components. Overall, our results provide new insight into the inner workings of
attention-based encoder-decoder networks.

    

### [[2110.15255] Self-Supervised Learning Disentangled Group Representation as Feature](http://arxiv.org/abs/2110.15255)


  A good visual representation is an inference map from observations (images)
to features (vectors) that faithfully reflects the hidden modularized
generative factors (semantics). In this paper, we formulate the notion of
"good" representation from a group-theoretic view using Higgins' definition of
disentangled representation, and show that existing Self-Supervised Learning
(SSL) only disentangles simple augmentation features such as rotation and
colorization, thus unable to modularize the remaining semantics. To break the
limitation, we propose an iterative SSL algorithm: Iterative Partition-based
Invariant Risk Minimization (IP-IRM), which successfully grounds the abstract
semantics and the group acting on them into concrete contrastive learning. At
each iteration, IP-IRM first partitions the training samples into two subsets
that correspond to an entangled group element. Then, it minimizes a
subset-invariant contrastive loss, where the invariance guarantees to
disentangle the group element. We prove that IP-IRM converges to a fully
disentangled representation and show its effectiveness on various benchmarks.
Codes are available at this https URL.

    

### [[2110.15263] Coresets for Time Series Clustering](http://arxiv.org/abs/2110.15263)


  We study the problem of constructing coresets for clustering problems with
time series data. This problem has gained importance across many fields
including biology, medicine, and economics due to the proliferation of sensors
facilitating real-time measurement and rapid drop in storage costs. In
particular, we consider the setting where the time series data on $N$ entities
is generated from a Gaussian mixture model with autocorrelations over $k$
clusters in $\mathbb{R}^d$. Our main contribution is an algorithm to construct
coresets for the maximum likelihood objective for this mixture model. Our
algorithm is efficient, and under a mild boundedness assumption on the
covariance matrices of the underlying Gaussians, the size of the coreset is
independent of the number of entities $N$ and the number of observations for
each entity, and depends only polynomially on $k$, $d$ and $1/\varepsilon$,
where $\varepsilon$ is the error parameter. We empirically assess the
performance of our coreset with synthetic data.

    

### [[2110.15268] Learning Continuous Face Representation with Explicit Functions](http://arxiv.org/abs/2110.15268)


  How to represent a face pattern? While it is presented in a continuous way in
our visual system, computers often store and process the face image in a
discrete manner with 2D arrays of pixels. In this study, we attempt to learn a
continuous representation for face images with explicit functions. First, we
propose an explicit model (EmFace) for human face representation in the form of
a finite sum of mathematical terms, where each term is an analytic function
element. Further, to estimate the unknown parameters of EmFace, a novel neural
network, EmNet, is designed with an encoder-decoder structure and trained using
the backpropagation algorithm, where the encoder is defined by a deep
convolutional neural network and the decoder is an explicit mathematical
expression of EmFace. Experimental results show that EmFace has a higher
representation performance on faces with various expressions, postures, and
other factors, compared to that of other methods. Furthermore, EmFace achieves
reasonable performance on several face image processing tasks, including face
image restoration, denoising, and transformation.

    

### [[2110.15273] OMASGAN: Out-of-Distribution Minimum Anomaly Score GAN for Sample Generation on the Boundary](http://arxiv.org/abs/2110.15273)


  Generative models trained in an unsupervised manner may set high likelihood
and low reconstruction loss to Out-of-Distribution (OoD) samples. This
increases Type II errors and leads to missed anomalies, overall decreasing
Anomaly Detection (AD) performance. In addition, AD models underperform due to
the rarity of anomalies. To address these limitations, we propose the OoD
Minimum Anomaly Score GAN (OMASGAN). OMASGAN generates, in a negative data
augmentation manner, anomalous samples on the estimated distribution boundary.
These samples are then used to refine an AD model, leading to more accurate
estimation of the underlying data distribution including multimodal supports
with disconnected modes. OMASGAN performs retraining by including the abnormal
minimum-anomaly-score OoD samples generated on the distribution boundary in a
self-supervised learning manner. For inference, for AD, we devise a
discriminator which is trained with negative and positive samples either
generated (negative or positive) or real (only positive). OMASGAN addresses the
rarity of anomalies by generating strong and adversarial OoD samples on the
distribution boundary using only normal class data, effectively addressing mode
collapse. A key characteristic of our model is that it uses any f-divergence
distribution metric in its variational representation, not requiring
invertibility. OMASGAN does not use feature engineering and makes no
assumptions about the data distribution. The evaluation of OMASGAN on image
data using the leave-one-out methodology shows that it achieves an improvement
of at least 0.24 and 0.07 points in AUROC on average on the MNIST and CIFAR-10
datasets, respectively, over other benchmark and state-of-the-art models for
AD.

    

### [[2110.15277] A Novel Sleep Stage Classification Using CNN Generated by an Efficient Neural Architecture Search with a New Data Processing Trick](http://arxiv.org/abs/2110.15277)


  With the development of automatic sleep stage classification (ASSC)
techniques, many classical methods such as k-means, decision tree, and SVM have
been used in automatic sleep stage classification. However, few methods explore
deep learning on ASSC. Meanwhile, most deep learning methods require extensive
expertise and suffer from a mass of handcrafted steps which are time-consuming
especially when dealing with multi-classification tasks. In this paper, we
propose an efficient five-sleep-stage classification method using convolutional
neural networks (CNNs) with a novel data processing trick and we design neural
architecture search (NAS) technique based on genetic algorithm (GA), NAS-G, to
search for the best CNN architecture. Firstly, we attach each kernel with an
adaptive coefficient to enhance the signal processing of the inputs. This can
enhance the propagation of informative features and suppress the propagation of
useless features in the early stage of the network. Then, we make full use of
GA's heuristic search and the advantage of no need for the gradient to search
for the best architecture of CNN. This can achieve a CNN with better
performance than a handcrafted one in a large search space at the minimum cost.
We verify the convergence of our data processing trick and compare the
performance of traditional CNNs before and after using our trick. Meanwhile, we
compare the performance between the CNN generated through NAS-G and the
traditional CNNs with our trick. The experiments demonstrate that the
convergence of CNNs with data processing trick is faster than without data
processing trick and the CNN with data processing trick generated by NAS-G
outperforms the handcrafted counterparts that use the data processing trick
too.

    

### [[2110.15278] Self-supervised EEG Representation Learning for Automatic Sleep Staging](http://arxiv.org/abs/2110.15278)


  Objective: In this paper, we aim to learn robust vector representations from
massive unlabeled Electroencephalogram (EEG) signals, such that the learned
representations (1) are expressive enough to replace the raw signals in the
sleep staging task; and (2) provide better predictive performance than
supervised models in scenarios of fewer labels and noisy samples.
Materials and Methods: We propose a self-supervised model, named Contrast
with the World Representation (ContraWR), for EEG signal representation
learning, which uses global statistics from the dataset to distinguish signals
associated with different sleep stages. The ContraWR model is evaluated on
three real-world EEG datasets that include both at-home and in-lab recording
settings.
Results: ContraWR outperforms recent self-supervised learning methods, MoCo,
SimCLR, BYOL, SimSiam on the sleep staging task across three datasets. ContraWR
also beats supervised learning when fewer training labels are available (e.g.,
4% accuracy improvement when less than 2% data is labeled). Moreover, the model
provides informative representations in 2D projection.
Discussion: The proposed model can be generalized to other unsupervised
physiological signal learning tasks. Future directions include exploring
task-specific data augmentations and combining self-supervised with supervised
methods, building upon the initial success of self-supervised learning in this
paper.
Conclusions: We show that ContraWR is robust to noise and can provide
high-quality EEG representations for downstream prediction tasks. In low-label
scenarios (e.g., only 2% data has labels), ContraWR shows much better
predictive power (e.g., 4% improvement on sleep staging accuracy) than
supervised baselines.

    

### [[2110.15279] SVM and ANN based Classification of EMG signals by using PCA and LDA](http://arxiv.org/abs/2110.15279)


  In recent decades, biomedical signals have been used for communication in
Human-Computer Interfaces (HCI) for medical applications; an instance of these
signals are the myoelectric signals (MES), which are generated in the muscles
of the human body as unidimensional patterns. Because of this, the methods and
algorithms developed for pattern recognition in signals can be applied for
their analyses once these signals have been sampled and turned into
electromyographic (EMG) signals. Additionally, in recent years, many
researchers have dedicated their efforts to studying prosthetic control
utilizing EMG signal classification, that is, by logging a set of MES in a
proper range of frequencies to classify the corresponding EMG signals. The
feature classification can be carried out on the time domain or by using other
domains such as the frequency domain (also known as the spectral domain), time
scale, and time-frequency, amongst others. One of the main methods used for
pattern recognition in myoelectric signals is the Support Vector Machines (SVM)
technique whose primary function is to identify an n-dimensional hyperplane to
separate a set of input feature points into different classes. This technique
has the potential to recognize complex patterns and on several occasions, it
has proven its worth when compared to other classifiers such as Artificial
Neural Network (ANN), Linear Discriminant Analysis (LDA), and Principal
Component Analysis(PCA). The key concepts underlying the SVM are (a) the
hyperplane separator; (b) the kernel function; (c) the optimal separation
hyperplane; and (d) a soft margin (hyperplane tolerance).

    

### [[2110.15288] Self-Supervised Representation Learning on Neural Network Weights for Model Characteristic Prediction](http://arxiv.org/abs/2110.15288)


  Self-Supervised Learning (SSL) has been shown to learn useful and
information-preserving representations. Neural Networks (NNs) are widely
applied, yet their weight space is still not fully understood. Therefore, we
propose to use SSL to learn neural representations of the weights of
populations of NNs. To that end, we introduce domain specific data
augmentations and an adapted attention architecture. Our empirical evaluation
demonstrates that self-supervised representation learning in this domain is
able to recover diverse NN model characteristics. Further, we show that the
proposed learned representations outperform prior work for predicting
hyper-parameters, test accuracy, and generalization gap as well as transfer to
out-of-distribution settings.

    

### [[2110.15290] Learning to Control using Image Feedback](http://arxiv.org/abs/2110.15290)


  Learning to control complex systems using non-traditional feedback, e.g., in
the form of snapshot images, is an important task encountered in diverse
domains such as robotics, neuroscience, and biology (cellular systems). In this
paper, we present a two neural-network (NN)-based feedback control framework to
design control policies for systems that generate feedback in the form of
images. In particular, we develop a deep $Q$-network (DQN)-driven learning
control strategy to synthesize a sequence of control inputs from snapshot
images that encode the information pertaining to the current state and control
action of the system. Further, to train the networks we employ a direct
error-driven learning (EDL) approach that utilizes a set of linear
transformations of the NN training error to update the NN weights in each
layer. We verify the efficacy of the proposed control strategy using numerical
examples.

    

### [[2110.15292] Class-wise Thresholding for Detecting Out-of-Distribution Data](http://arxiv.org/abs/2110.15292)


  We consider the problem of detecting OoD(Out-of-Distribution) input data when
using deep neural networks, and we propose a simple yet effective way to
improve the robustness of several popular OoD detection methods against label
shift. Our work is motivated by the observation that most existing OoD
detection algorithms consider all training/test data as a whole, regardless of
which class entry each input activates (inter-class differences). Through
extensive experimentation, we have found that such practice leads to a detector
whose performance is sensitive and vulnerable to label shift. To address this
issue, we propose a class-wise thresholding scheme that can apply to most
existing OoD detection algorithms and can maintain similar OoD detection
performance even in the presence of label shift in the test distribution.

    

### [[2110.15304] Sobolev-type embeddings for neural network approximation spaces](http://arxiv.org/abs/2110.15304)


  We consider neural network approximation spaces that classify functions
according to the rate at which they can be approximated (with error measured in
$L^p$) by ReLU neural networks with an increasing number of coefficients,
subject to bounds on the magnitude of the coefficients and the number of hidden
layers. We prove embedding theorems between these spaces for different values
of $p$. Furthermore, we derive sharp embeddings of these approximation spaces
into Hölder spaces. We find that, analogous to the case of classical function
spaces (such as Sobolev spaces, or Besov spaces) it is possible to trade
"smoothness" (i.e., approximation rate) for increased integrability.
Combined with our earlier results in [arXiv:2104.02746], our embedding
theorems imply a somewhat surprising fact related to "learning" functions from
a given neural network space based on point samples: if accuracy is measured
with respect to the uniform norm, then an optimal "learning" algorithm for
reconstructing functions that are well approximable by ReLU neural networks is
simply given by piecewise constant interpolation on a tensor product grid.

    

### [[2110.15305] Cooperative Deep $Q$-learning Framework for Environments Providing Image Feedback](http://arxiv.org/abs/2110.15305)


  In this paper, we address two key challenges in deep reinforcement learning
setting, sample inefficiency and slow learning, with a dual NN-driven learning
approach. In the proposed approach, we use two deep NNs with independent
initialization to robustly approximate the action-value function in the
presence of image inputs. In particular, we develop a temporal difference (TD)
error-driven learning approach, where we introduce a set of linear
transformations of the TD error to directly update the parameters of each layer
in the deep NN. We demonstrate theoretically that the cost minimized by the
error-driven learning (EDL) regime is an approximation of the empirical cost
and the approximation error reduces as learning progresses, irrespective of the
size of the network. Using simulation analysis, we show that the proposed
methods enables faster learning and convergence and requires reduced buffer
size (thereby increasing the sample efficiency).

    

### [[2110.15307] How to boost autoencoders?](http://arxiv.org/abs/2110.15307)


  Autoencoders are a category of neural networks with applications in numerous
domains and hence, improvement of their performance is gaining substantial
interest from the machine learning community. Ensemble methods, such as
boosting, are often adopted to enhance the performance of regular neural
networks. In this work, we discuss the challenges associated with boosting
autoencoders and propose a framework to overcome them. The proposed method
ensures that the advantages of boosting are realized when either output
(encoded or reconstructed) is used. The usefulness of the boosted ensemble is
demonstrated in two applications that widely employ autoencoders: anomaly
detection and clustering.

    

### [[2110.15310] On the Fairness of Machine-Assisted Human Decisions](http://arxiv.org/abs/2110.15310)


  When machine-learning algorithms are deployed in high-stakes decisions, we
want to ensure that their deployment leads to fair and equitable outcomes. This
concern has motivated a fast-growing literature that focuses on diagnosing and
addressing disparities in machine predictions. However, many machine
predictions are deployed to assist in decisions where a human decision-maker
retains the ultimate decision authority. In this article, we therefore consider
how properties of machine predictions affect the resulting human decisions. We
show in a formal model that the inclusion of a biased human decision-maker can
revert common relationships between the structure of the algorithm and the
qualities of resulting decisions. Specifically, we document that excluding
information about protected groups from the prediction may fail to reduce, and
may even increase, ultimate disparities. While our concrete results rely on
specific assumptions about the data, algorithm, and decision-maker, they show
more broadly that any study of critical properties of complex decision systems,
such as the fairness of machine-assisted human decisions, should go beyond
focusing on the underlying algorithmic predictions in isolation.

    

### [[2110.15313] Clustering of the Blendshape Facial Model](http://arxiv.org/abs/2110.15313)


  Digital human animation relies on high-quality 3D models of the human face --
rigs. A face rig must be accurate and, at the same time, fast to compute. One
of the most common rigging models is the blendshape model. We present a novel
approach for learning the inverse rig parameters at increased accuracy and
decreased computational cost at the same time. It is based on a two-fold
clustering of the blendshape face model. Our method focuses exclusively on the
underlying space of deformation and produces clusters in both the mesh space
and the controller space -- something that was not investigated in previous
literature. This segmentation finds intuitive and meaningful connections
between groups of vertices on the face and deformation controls, and further
these segments can be observed independently. A separate model for solving the
inverse rig problem is then learned for each segment. Our method is completely
unsupervised and highly parallelizable.

    

### [[2110.15317] Bridge the Gap Between CV and NLP! A Gradient-based Textual Adversarial Attack Framework](http://arxiv.org/abs/2110.15317)


  Despite great success on many machine learning tasks, deep neural networks
are still vulnerable to adversarial samples. While gradient-based adversarial
attack methods are well-explored in the field of computer vision, it is
impractical to directly apply them in natural language processing due to the
discrete nature of text. To bridge this gap, we propose a general framework to
adapt existing gradient-based methods to craft textual adversarial samples. In
this framework, gradient-based continuous perturbations are added to the
embedding layer and are amplified in the forward propagation process. Then the
final perturbed latent representations are decoded with a mask language model
head to obtain potential adversarial samples. In this paper, we instantiate our
framework with \textbf{T}extual \textbf{P}rojected \textbf{G}radient
\textbf{D}escent (\textbf{TPGD}). We conduct comprehensive experiments to
evaluate our framework by performing transfer black-box attacks on BERT,
RoBERTa and ALBERT on three benchmark datasets. Experimental results
demonstrate our method achieves an overall better performance and produces more
fluent and grammatical adversarial samples compared to strong baseline methods.
All the code and data will be made public.

    

### [[2110.15318] Communication-Efficient ADMM-based Federated Learning](http://arxiv.org/abs/2110.15318)


  Federated learning has shown its advances over the last few years but is
facing many challenges, such as how algorithms save communication resources,
how they reduce computational costs, and whether they converge. To address
these issues, this paper proposes exact and inexact ADMM-based federated
learning. They are not only communication-efficient but also converge linearly
under very mild conditions, such as convexity-free and irrelevance to data
distributions. Moreover, the inexact version has low computational complexity,
thereby alleviating the computational burdens significantly.

    

### [[2110.15327] MEGAN: Memory Enhanced Graph Attention Network for Space-Time Video Super-Resolution](http://arxiv.org/abs/2110.15327)


  Space-time video super-resolution (STVSR) aims to construct a high space-time
resolution video sequence from the corresponding low-frame-rate, low-resolution
video sequence. Inspired by the recent success to consider spatial-temporal
information for space-time super-resolution, our main goal in this work is to
take full considerations of spatial and temporal correlations within the video
sequences of fast dynamic events. To this end, we propose a novel one-stage
memory enhanced graph attention network (MEGAN) for space-time video
super-resolution. Specifically, we build a novel long-range memory graph
aggregation (LMGA) module to dynamically capture correlations along the channel
dimensions of the feature maps and adaptively aggregate channel features to
enhance the feature representations. We introduce a non-local residual block,
which enables each channel-wise feature to attend global spatial hierarchical
features. In addition, we adopt a progressive fusion module to further enhance
the representation ability by extensively exploiting spatial-temporal
correlations from multiple frames. Experiment results demonstrate that our
method achieves better results compared with the state-of-the-art methods
quantitatively and visually.

    

### [[2110.15331] Wasserstein Distance Maximizing Intrinsic Control](http://arxiv.org/abs/2110.15331)


  This paper deals with the problem of learning a skill-conditioned policy that
acts meaningfully in the absence of a reward signal. Mutual information based
objectives have shown some success in learning skills that reach a diverse set
of states in this setting. These objectives include a KL-divergence term, which
is maximized by visiting distinct states even if those states are not far apart
in the MDP. This paper presents an approach that rewards the agent for learning
skills that maximize the Wasserstein distance of their state visitation from
the start state of the skill. It shows that such an objective leads to a policy
that covers more distance in the MDP than diversity based objectives, and
validates the results on a variety of Atari environments.

    

### [[2110.15332] Proximal Reinforcement Learning: Efficient Off-Policy Evaluation in Partially Observed Markov Decision Processes](http://arxiv.org/abs/2110.15332)


  In applications of offline reinforcement learning to observational data, such
as in healthcare or education, a general concern is that observed actions might
be affected by unobserved factors, inducing confounding and biasing estimates
derived under the assumption of a perfect Markov decision process (MDP) model.
Here we tackle this by considering off-policy evaluation in a partially
observed MDP (POMDP). Specifically, we consider estimating the value of a given
target policy in a POMDP given trajectories with only partial state
observations generated by a different and unknown policy that may depend on the
unobserved state. We tackle two questions: what conditions allow us to identify
the target policy value from the observed data and, given identification, how
to best estimate it. To answer these, we extend the framework of proximal
causal inference to our POMDP setting, providing a variety of settings where
identification is made possible by the existence of so-called bridge functions.
We then show how to construct semiparametrically efficient estimators in these
settings. We term the resulting framework proximal reinforcement learning
(PRL). We demonstrate the benefits of PRL in an extensive simulation study.

    

### [[2110.15335] Bayesian Sequential Optimal Experimental Design for Nonlinear Models Using Policy Gradient Reinforcement Learning](http://arxiv.org/abs/2110.15335)


  We present a mathematical framework and computational methods to optimally
design a finite number of sequential experiments. We formulate this sequential
optimal experimental design (sOED) problem as a finite-horizon partially
observable Markov decision process (POMDP) in a Bayesian setting and with
information-theoretic utilities. It is built to accommodate continuous random
variables, general non-Gaussian posteriors, and expensive nonlinear forward
models. sOED then seeks an optimal design policy that incorporates elements of
both feedback and lookahead, generalizing the suboptimal batch and greedy
designs. We solve for the sOED policy numerically via policy gradient (PG)
methods from reinforcement learning, and derive and prove the PG expression for
sOED. Adopting an actor-critic approach, we parameterize the policy and value
functions using deep neural networks and improve them using gradient estimates
produced from simulated episodes of designs and observations. The overall
PG-sOED method is validated on a linear-Gaussian benchmark, and its advantages
over batch and greedy designs are demonstrated through a contaminant source
inversion problem in a convection-diffusion field.

    

### [[2110.15343] Scatterbrain: Unifying Sparse and Low-rank Attention Approximation](http://arxiv.org/abs/2110.15343)


  Recent advances in efficient Transformers have exploited either the sparsity
or low-rank properties of attention matrices to reduce the computational and
memory bottlenecks of modeling long sequences. However, it is still challenging
to balance the trade-off between model quality and efficiency to perform a
one-size-fits-all approximation for different tasks. To better understand this
trade-off, we observe that sparse and low-rank approximations excel in
different regimes, determined by the softmax temperature in attention, and
sparse + low-rank can outperform each individually. Inspired by the classical
robust-PCA algorithm for sparse and low-rank decomposition, we propose
Scatterbrain, a novel way to unify sparse (via locality sensitive hashing) and
low-rank (via kernel feature map) attention for accurate and efficient
approximation. The estimation is unbiased with provably low error. We
empirically show that Scatterbrain can achieve 2.1x lower error than baselines
when serving as a drop-in replacement in BigGAN image generation and
pre-trained T2T-ViT. On a pre-trained T2T Vision transformer, even without
fine-tuning, Scatterbrain can reduce 98% of attention memory at the cost of
only 1% drop in accuracy. We demonstrate Scatterbrain for end-to-end training
with up to 4 points better perplexity and 5 points better average accuracy than
sparse or low-rank efficient transformers on language modeling and
long-range-arena tasks.

    

### [[2110.15348] Residual Relaxation for Multi-view Representation Learning](http://arxiv.org/abs/2110.15348)


  Multi-view methods learn representations by aligning multiple views of the
same image and their performance largely depends on the choice of data
augmentation. In this paper, we notice that some other useful augmentations,
such as image rotation, are harmful for multi-view methods because they cause a
semantic shift that is too large to be aligned well. This observation motivates
us to relax the exact alignment objective to better cultivate stronger
augmentations. Taking image rotation as a case study, we develop a generic
approach, Pretext-aware Residual Relaxation (Prelax), that relaxes the exact
alignment by allowing an adaptive residual vector between different views and
encoding the semantic shift through pretext-aware learning. Extensive
experiments on different backbones show that our method can not only improve
multi-view methods with existing augmentations, but also benefit from stronger
image augmentations like rotation.

    

### [[2110.15349] Learning to Ground Multi-Agent Communication with Autoencoders](http://arxiv.org/abs/2110.15349)


  Communication requires having a common language, a lingua franca, between
agents. This language could emerge via a consensus process, but it may require
many generations of trial and error. Alternatively, the lingua franca can be
given by the environment, where agents ground their language in representations
of the observed world. We demonstrate a simple way to ground language in
learned representations, which facilitates decentralized multi-agent
communication and coordination. We find that a standard representation learning
algorithm -- autoencoding -- is sufficient for arriving at a grounded common
language. When agents broadcast these representations, they learn to understand
and respond to each other's utterances and achieve surprisingly strong task
performance across a variety of multi-agent communication environments.

    

### [[2110.15350] XDEEP-MSI: Explainable Bias-Rejecting Microsatellite Instability Deep Learning System In Colorectal Cancer](http://arxiv.org/abs/2110.15350)


  We present a system for the prediction of microsatellite instability (MSI)
from H&E images of colorectal cancer using deep learning (DL) techniques
customized for tissue microarrays (TMAs). The system incorporates an end-to-end
image preprocessing module that produces tiles at multiple magnifications in
the regions of interest as guided by a tissue classifier module, and a
multiple-bias rejecting module. The training and validation TMA samples were
obtained from the EPICOLON project and further enriched with samples from a
single institution. A systematic study of biases at tile level identified three
protected (bias) variables associated with the learned representations of a
baseline model: the project of origin of samples, the patient spot and the TMA
glass where each spot was placed. A multiple bias rejecting technique based on
adversarial training is implemented at the DL architecture so to directly avoid
learning the batch effects of those variables. The learned features from the
bias-ablated model have maximum discriminative power with respect to the task
and minimal statistical mean dependence with the biases. The impact of
different magnifications, types of tissues and the model performance at tile vs
patient level is analyzed. The AUC at tile level, and including all three
selected tissues (tumor epithelium, mucine and lymphocytic regions) and 4
magnifications, was 0.87 +/- 0.03 and increased to 0.9 +/- 0.03 at patient
level. To the best of our knowledge, this is the first work that incorporates a
multiple bias ablation technique at the DL architecture in digital pathology,
and the first using TMAs for the MSI prediction task.

    

### [[2110.15355] Explaining Latent Representations with a Corpus of Examples](http://arxiv.org/abs/2110.15355)


  Modern machine learning models are complicated. Most of them rely on
convoluted latent representations of their input to issue a prediction. To
achieve greater transparency than a black-box that connects inputs to
predictions, it is necessary to gain a deeper understanding of these latent
representations. To that aim, we propose SimplEx: a user-centred method that
provides example-based explanations with reference to a freely selected set of
examples, called the corpus. SimplEx uses the corpus to improve the user's
understanding of the latent space with post-hoc explanations answering two
questions: (1) Which corpus examples explain the prediction issued for a given
test example? (2) What features of these corpus examples are relevant for the
model to relate them to the test example? SimplEx provides an answer by
reconstructing the test latent representation as a mixture of corpus latent
representations. Further, we propose a novel approach, the Integrated Jacobian,
that allows SimplEx to make explicit the contribution of each corpus feature in
the mixture. Through experiments on tasks ranging from mortality prediction to
image classification, we demonstrate that these decompositions are robust and
accurate. With illustrative use cases in medicine, we show that SimplEx
empowers the user by highlighting relevant patterns in the corpus that explain
model representations. Moreover, we demonstrate how the freedom in choosing the
corpus allows the user to have personalized explanations in terms of examples
that are meaningful for them.

    

### [[2110.15358] Dynamic Visual Reasoning by Learning Differentiable Physics Models from Video and Language](http://arxiv.org/abs/2110.15358)


  In this work, we propose a unified framework, called Visual Reasoning with
Differ-entiable Physics (VRDP), that can jointly learn visual concepts and
infer physics models of objects and their interactions from videos and
language. This is achieved by seamlessly integrating three components: a visual
perception module, a concept learner, and a differentiable physics engine. The
visual perception module parses each video frame into object-centric
trajectories and represents them as latent scene representations. The concept
learner grounds visual concepts (e.g., color, shape, and material) from these
object-centric representations based on the language, thus providing prior
knowledge for the physics engine. The differentiable physics model, implemented
as an impulse-based differentiable rigid-body simulator, performs
differentiable physical simulation based on the grounded concepts to infer
physical properties, such as mass, restitution, and velocity, by fitting the
simulated trajectories into the video observations. Consequently, these learned
concepts and physical models can explain what we have seen and imagine what is
about to happen in future and counterfactual scenarios. Integrating
differentiable physics into the dynamic reasoning framework offers several
appealing benefits. More accurate dynamics prediction in learned physics models
enables state-of-the-art performance on both synthetic and real-world
benchmarks while still maintaining high transparency and interpretability; most
notably, VRDP improves the accuracy of predictive and counterfactual questions
by 4.5% and 11.5% compared to its best counterpart. VRDP is also highly
data-efficient: physical parameters can be optimized from very few videos, and
even a single video can be sufficient. Finally, with all physical parameters
inferred, VRDP can quickly learn new concepts from a few examples.

    

### [[2110.15360] Accelerating Robotic Reinforcement Learning via Parameterized Action Primitives](http://arxiv.org/abs/2110.15360)


  Despite the potential of reinforcement learning (RL) for building
general-purpose robotic systems, training RL agents to solve robotics tasks
still remains challenging due to the difficulty of exploration in purely
continuous action spaces. Addressing this problem is an active area of research
with the majority of focus on improving RL methods via better optimization or
more efficient exploration. An alternate but important component to consider
improving is the interface of the RL algorithm with the robot. In this work, we
manually specify a library of robot action primitives (RAPS), parameterized
with arguments that are learned by an RL policy. These parameterized primitives
are expressive, simple to implement, enable efficient exploration and can be
transferred across robots, tasks and environments. We perform a thorough
empirical study across challenging tasks in three distinct domains with image
input and a sparse terminal reward. We find that our simple change to the
action interface substantially improves both the learning efficiency and task
performance irrespective of the underlying RL algorithm, significantly
outperforming prior methods which learn skills from offline expert data. Code
and videos at this https URL


### [[1908.09874] Sufficient Representations for Categorical Variables](http://arxiv.org/abs/1908.09874)


  Many learning algorithms require categorical data to be transformed into real
vectors before it can be used as input. Often, categorical variables are
encoded as one-hot (or dummy) vectors. However, this mode of representation can
be wasteful since it adds many low-signal regressors, especially when the
number of unique categories is large. In this paper, we investigate simple
alternative solutions for universally consistent estimators that rely on
lower-dimensional real-valued representations of categorical variables that are
"sufficient" in the sense that no predictive information is lost. We then
compare preexisting and proposed methods on simulated and observational
datasets.

    

### [[1910.05065] Relation learning in a neurocomputational architecture supports cross-domain transfer](http://arxiv.org/abs/1910.05065)


  People readily generalise prior knowledge to novel situations and stimuli.
Advances in machine learning and artificial intelligence have begun to
approximate and even surpass human performance in specific domains, but machine
learning systems struggle to generalise information to untrained situations. We
present and model that demonstrates human-like extrapolatory generalisation by
learning and explicitly representing an open-ended set of relations
characterising regularities within the domains it is exposed to. First, when
trained to play one video game (e.g., Breakout). the model generalises to a new
game (e.g., Pong) with different rules, dimensions, and characteristics in a
single shot. Second, the model can learn representations from a different
domain (e.g., 3D shape images) that support learning a video game and
generalising to a new game in one shot. By exploiting well-established
principles from cognitive psychology and neuroscience, the model learns
structured representations without feedback, and without requiring knowledge of
the relevant relations to be given a priori. We present additional simulations
showing that the representations that the model learns support cross-domain
generalisation. The model's ability to generalise between different games
demonstrates the flexible generalisation afforded by a capacity to learn not
only statistical relations, but also other relations that are useful for
characterising the domain to be learned. In turn, this kind of flexible,
relational generalisation is only possible because the model is capable of
representing relations explicitly, a capacity that is notably absent in extant
statistical machine learning algorithms.

    

### [[1911.13034] Model structures and fitting criteria for system identification with neural networks](http://arxiv.org/abs/1911.13034)


  This paper focuses on the identification of dynamical systems with
tailor-made model structures, where neural networks are used to approximate
uncertain components and domain knowledge is retained, if available. These
model structures are fitted to measured data using different criteria including
a computationally efficient approach minimizing a regularized multi-step ahead
simulation error. In this approach, the neural network parameters are estimated
along with the initial conditions used to simulate the output signal in
small-size subsequences. A regularization term is included in the fitting cost
in order to enforce these initial conditions to be consistent with the
estimated system dynamics. Pitfalls and limitations of naive one-step
prediction and simulation error minimization are also discussed.

    

### [[2006.08495] Overparameterization and generalization error: weighted trigonometric interpolation](http://arxiv.org/abs/2006.08495)


  Motivated by surprisingly good generalization properties of learned deep
neural networks in overparameterized scenarios and by the related double
descent phenomenon, this paper analyzes the relation between smoothness and low
generalization error in an overparameterized linear learning problem. We study
a random Fourier series model, where the task is to estimate the unknown
Fourier coefficients from equidistant samples. We derive exact expressions for
the generalization error of both plain and weighted least squares estimators.
We show precisely how a bias towards smooth interpolants, in the form of
weighted trigonometric interpolation, can lead to smaller generalization error
in the overparameterized regime compared to the underparameterized regime. This
provides insight into the power of overparameterization, which is common in
modern machine learning.

    

### [[2010.00788] Effective Regularization Through Loss-Function Metalearning](http://arxiv.org/abs/2010.00788)


  Evolutionary optimization, such as the TaylorGLO method, can be used to
discover novel, customized loss functions for deep neural networks, resulting
in improved performance, faster training, and improved data utilization. A
likely explanation is that such functions discourage overfitting, leading to
effective regularization. This paper demonstrates theoretically that this is
indeed the case for TaylorGLO: Decomposition of learning rules makes it
possible to characterize the training dynamics and show that the loss functions
evolved by TaylorGLO balance the pull to zero error, and a push away from it to
avoid overfitting. They may also automatically take advantage of label
smoothing. This analysis leads to an invariant that can be utilized to make the
metalearning process more efficient in practice; the mechanism also results in
networks that are robust against adversarial attacks. Loss-function evolution
can thus be seen as a well-founded new aspect of metalearning in neural
networks.

    

### [[2010.02387] Metadata-Based Detection of Child Sexual Abuse Material](http://arxiv.org/abs/2010.02387)


  Child Sexual Abuse Media (CSAM) is any visual record of a sexually-explicit
activity involving minors. CSAM impacts victims differently from the actual
abuse because the distribution never ends, and images are permanent. Machine
learning-based solutions can help law enforcement quickly identify CSAM and
block digital distribution. However, collecting CSAM imagery to train machine
learning models has many ethical and legal constraints, creating a barrier to
research development. With such restrictions in place, the development of CSAM
machine learning detection systems based on file metadata uncovers several
opportunities. Metadata is not a record of a crime, and it does not have legal
restrictions. Therefore, investing in detection systems based on metadata can
increase the rate of discovery of CSAM and help thousands of victims. We
propose a framework for training and evaluating deployment-ready machine
learning models for CSAM identification. Our framework provides guidelines to
evaluate CSAM detection models against intelligent adversaries and models'
performance with open data. We apply the proposed framework to the problem of
CSAM detection based on file paths. In our experiments, the best-performing
model is based on convolutional neural networks and achieves an accuracy of
0.97. Our evaluation shows that the CNN model is robust against offenders
actively trying to evade detection by evaluating the model against
adversarially modified data. Experiments with open datasets confirm that the
model generalizes well and is deployment-ready.

    

### [[2010.14746] Continuous Lyapunov Controller and Chaotic Non-linear System Optimization using Deep Machine Learning](http://arxiv.org/abs/2010.14746)


  The introduction of unexpected system disturbances and new system dynamics
does not allow guaranteed continuous system stability. In this research we
present a novel approach for detecting early failure indicators of non-linear
highly chaotic system and accordingly predict the best parameter calibrations
to offset such instability using deep machine learning regression model. The
approach proposed continuously monitors the system and controller signals. The
Re-calibration of the system and controller parameters is triggered according
to a set of conditions designed to maintain system stability without compromise
to the system speed, intended outcome or required processing power. The deep
neural model predicts the parameter values that would best counteract the
expected system in-stability. To demonstrate the effectiveness of the proposed
approach, it is applied to the non-linear complex combination of Duffing Van
der pol oscillators. The approach is also tested under different scenarios the
system and controller parameters are initially chosen incorrectly or the system
parameters are changed while running or new system dynamics are introduced
while running to measure effectiveness and reaction time.

    

### [[2011.00165] FireCommander: An Interactive, Probabilistic Multi-agent Environment for Heterogeneous Robot Teams](http://arxiv.org/abs/2011.00165)


  The purpose of this tutorial is to help individuals use the
\underline{FireCommander} game environment for research applications. The
FireCommander is an interactive, probabilistic joint perception-action
reconnaissance environment in which a composite team of agents (e.g., robots)
cooperate to fight dynamic, propagating firespots (e.g., targets). In
FireCommander game, a team of agents must be tasked to optimally deal with a
wildfire situation in an environment with propagating fire areas and some
facilities such as houses, hospitals, power stations, etc. The team of agents
can accomplish their mission by first sensing (e.g., estimating fire states),
communicating the sensed fire-information among each other and then taking
action to put the firespots out based on the sensed information (e.g., dropping
water on estimated fire locations). The FireCommander environment can be useful
for research topics spanning a wide range of applications from Reinforcement
Learning (RL) and Learning from Demonstration (LfD), to Coordination,
Psychology, Human-Robot Interaction (HRI) and Teaming. There are four important
facets of the FireCommander environment that overall, create a non-trivial
game: (1) Complex Objectives: Multi-objective Stochastic Environment,
(2)Probabilistic Environment: Agents' actions result in probabilistic
performance, (3) Hidden Targets: Partially Observable Environment and, (4)
Uni-task Robots: Perception-only and Action-only agents. The FireCommander
environment is first-of-its-kind in terms of including Perception-only and
Action-only agents for coordination. It is a general multi-purpose game that
can be useful in a variety of combinatorial optimization problems and
stochastic games, such as applications of Reinforcement Learning (RL), Learning
from Demonstration (LfD) and Inverse RL (iRL).

    

### [[2011.09416] Exact nuclear norm, completion and decomposition for random overcomplete tensors via degree-4 SOS](http://arxiv.org/abs/2011.09416)


  In this paper we show that simple semidefinite programs inspired by degree
$4$ SOS can exactly solve the tensor nuclear norm, tensor decomposition, and
tensor completion problems on tensors with random asymmetric components. More
precisely, for tensor nuclear norm and tensor decomposition, we show that
w.h.p. these semidefinite programs can exactly find the nuclear norm and
components of an $(n\times n\times n)$-tensor $\mathcal{T}$ with $m\leq
n^{3/2}/polylog(n)$ random asymmetric components. Unlike most of the previous
algorithms, our algorithm provides a certificate for the decomposition, does
not require knowledge about the number of components in the decomposition and
does not make any assumptions on the sizes of the coefficients in the
decomposition. As a byproduct, we show that w.h.p. the nuclear norm
decomposition exactly coincides with the minimum rank decomposition for tensors
with $m\leq n^{3/2}/polylog(n)$ random asymmetric components.
For tensor completion, we show that w.h.p. the semidefinite program,
introduced by Potechin & Steurer (2017) for tensors with orthogonal components,
can exactly recover an $(n\times n\times n)$-tensor $\mathcal{T}$ with $m$
random asymmetric components from only $n^{3/2}m polylog(n)$ randomly observed
entries. For non-orthogonal tensors, this improves the dependence on $m$ of the
number of entries needed for exact recovery over all previously known
algorithms and provides the first theoretical guarantees for exact tensor
completion in the overcomplete regime.

    

### [[2011.10065] Anderson acceleration of coordinate descent](http://arxiv.org/abs/2011.10065)


  Acceleration of first order methods is mainly obtained via inertial
techniques à la Nesterov, or via nonlinear extrapolation. The latter has
known a recent surge of interest, with successful applications to gradient and
proximal gradient techniques. On multiple Machine Learning problems, coordinate
descent achieves performance significantly superior to full-gradient methods.
Speeding up coordinate descent in practice is not easy: inertially accelerated
versions of coordinate descent are theoretically accelerated, but might not
always lead to practical speed-ups. We propose an accelerated version of
coordinate descent using extrapolation, showing considerable speed up in
practice, compared to inertial accelerated coordinate descent and extrapolated
(proximal) gradient descent. Experiments on least squares, Lasso, elastic net
and logistic regression validate the approach.

    

### [[2011.13034] Accommodating Picky Customers: Regret Bound and Exploration Complexity for Multi-Objective Reinforcement Learning](http://arxiv.org/abs/2011.13034)


  In this paper we consider multi-objective reinforcement learning where the
objectives are balanced using preferences. In practice, the preferences are
often given in an adversarial manner, e.g., customers can be picky in many
applications. We formalize this problem as an episodic learning problem on a
Markov decision process, where transitions are unknown and a reward function is
the inner product of a preference vector with pre-specified multi-objective
reward functions. We consider two settings. In the online setting, the agent
receives a (adversarial) preference every episode and proposes policies to
interact with the environment. We provide a model-based algorithm that achieves
a nearly minimax optimal regret bound
$\widetilde{\mathcal{O}}\bigl(\sqrt{\min\{d,S\}\cdot H^2 SAK}\bigr)$, where $d$
is the number of objectives, $S$ is the number of states, $A$ is the number of
actions, $H$ is the length of the horizon, and $K$ is the number of episodes.
Furthermore, we consider preference-free exploration, i.e., the agent first
interacts with the environment without specifying any preference and then is
able to accommodate arbitrary preference vector up to $\epsilon$ error. Our
proposed algorithm is provably efficient with a nearly optimal trajectory
complexity $\widetilde{\mathcal{O}}\bigl({\min\{d,S\}\cdot H^3
SA}/{\epsilon^2}\bigr)$. This result partly resolves an open problem raised by
\citet{jin2020reward}.

    

### [[2101.12745] Variance-Aware Confidence Set: Variance-Dependent Bound for Linear Bandits and Horizon-Free Bound for Linear Mixture MDP](http://arxiv.org/abs/2101.12745)


  This paper presents new \emph{variance-aware} confidence sets for linear
bandits and linear mixture Markov Decision Processes (MDPs). With the new
confidence sets, we obtain the follow regret bounds: For linear bandits, we
obtain an $\tilde{O}(poly(d)\sqrt{1 + \sum_{k=1}^{K}\sigma_k^2})$
data-dependent regret bound, where $d$ is the feature dimension, $K$ is the
number of rounds, and $\sigma_k^2$ is the \emph{unknown} variance of the reward
at the $k$-th round. This is the first regret bound that only scales with the
variance and the dimension but \emph{no explicit polynomial dependency on $K$}.
When variances are small, this bound can be significantly smaller than the
$\tilde{\Theta}\left(d\sqrt{K}\right)$ worst-case regret bound. For linear
mixture MDPs, we obtain an $\tilde{O}(poly(d, \log H)\sqrt{K})$ regret bound,
where $d$ is the number of base models, $K$ is the number of episodes, and $H$
is the planning horizon. This is the first regret bound that only scales
\emph{logarithmically} with $H$ in the reinforcement learning with linear
function approximation setting, thus \emph{exponentially improving} existing
results, and resolving an open problem in \citep{zhou2020nearly}. We develop
three technical ideas that may be of independent interest: 1) applications of
the peeling technique to both the input norm and the variance magnitude, 2) a
recursion-based estimator for the variance, and 3) a new convex potential lemma
that generalizes the seminal elliptical potential lemma.

    

### [[2102.05713] SCA-Net: A Self-Correcting Two-Layer Autoencoder for Hyper-spectral Unmixing](http://arxiv.org/abs/2102.05713)


  Hyperspectral unmixing involves separating a pixel as a weighted combination
of its constituent endmembers and corresponding fractional abundances, with the
current state of the art results achieved by neural models on benchmark
datasets. However, these networks are severely over-parameterized and
consequently, the invariant endmember spectra extracted as decoder weights have
a high variance over multiple runs. These approaches perform substantial
post-processing while requiring an exact specification of the number of
endmembers and specialized initialization of weights from other algorithms like
VCA. We show for the first time that a two-layer autoencoder (SCA), with $2FK$
parameters ($F$ features, $K$ endmembers), achieves error metrics that are
scales apart ($10^{-5})$ from previously reported values $(10^{-2})$. SCA
converges to this low error solution starting from a random initialization of
weights. We also show that SCA, based upon a bi-orthogonal representation,
performs a self-correction when the number of endmembers are over-specified.
Numerical experiments on Samson, Jasper, and Urban datasets demonstrate that
SCA outperforms previously reported error metrics for all the cases while being
robust to noise and outliers.

    

### [[2102.06857] On Robust Optimal Transport: Computational Complexity and Barycenter Computation](http://arxiv.org/abs/2102.06857)


  We consider robust variants of the standard optimal transport, named robust
optimal transport, where marginal constraints are relaxed via Kullback-Leibler
divergence. We show that Sinkhorn-based algorithms can approximate the optimal
cost of robust optimal transport in
$\widetilde{\mathcal{O}}(\frac{n^2}{\varepsilon})$ time, in which $n$ is the
number of supports of the probability distributions and $\varepsilon$ is the
desired error. Furthermore, we investigate a fixed-support robust barycenter
problem between $m$ discrete probability distributions with at most $n$ number
of supports and develop an approximating algorithm based on iterative Bregman
projections (IBP). For the specific case $m = 2$, we show that this algorithm
can approximate the optimal barycenter value in
$\widetilde{\mathcal{O}}(\frac{mn^2}{\varepsilon})$ time, thus being better
than the previous complexity
$\widetilde{\mathcal{O}}(\frac{mn^2}{\varepsilon^2})$ of the IBP algorithm for
approximating the Wasserstein barycenter.

    

### [[2102.07567] Learning Accurate Decision Trees with Bandit Feedback via Quantized Gradient Descent](http://arxiv.org/abs/2102.07567)


  Decision trees provide a rich family of highly non-linear but efficient
models, due to which they continue to be the go-to family of predictive models
by practitioners across domains. But learning trees is challenging due to their
discrete decision boundaries. The state-of-the-art (SOTA) techniques resort to
(a) learning soft trees thereby losing logarithmic inference time; or (b) using
methods tailored to specific supervised learning settings, requiring access to
labeled examples and loss function. In this work, by leveraging techniques like
overparameterization and straight-through estimators, we propose a novel method
that enables accurate end-to-end gradient based tree training and can be
deployed in a variety of settings like offline supervised learning and online
learning with bandit feedback. Using extensive validation on standard
benchmarks, we demonstrate that our method provides best of both worlds, i.e.,
it is competitive to, and in some cases more accurate than methods designed
specifically for the supervised settings; and in bandit settings, where most
existing tree learning techniques are not applicable, our models are still
accurate and significantly outperform the applicable SOTA methods.

    

### [[2102.07927] Structured Dropout Variational Inference for Bayesian Neural Networks](http://arxiv.org/abs/2102.07927)


  Approximate inference in Bayesian deep networks exhibits a dilemma of how to
yield high fidelity posterior approximations while maintaining computational
efficiency and scalability. We tackle this challenge by introducing a novel
variational structured approximation inspired by the Bayesian interpretation of
Dropout regularization. Concretely, we focus on the inflexibility of the
factorized structure in Dropout posterior and then propose an improved method
called Variational Structured Dropout (VSD). VSD employs an orthogonal
transformation to learn a structured representation on the variational Gaussian
noise with plausible complexity, and consequently induces statistical
dependencies in the approximate posterior. Theoretically, VSD successfully
addresses the pathologies of previous Variational Dropout methods and thus
offers a standard Bayesian justification. We further show that VSD induces an
adaptive regularization term with several desirable properties which contribute
to better generalization. Finally, we conduct extensive experiments on standard
benchmarks to demonstrate the effectiveness of VSD over state-of-the-art
variational methods on predictive accuracy, uncertainty estimation, and
out-of-distribution detection.

    

### [[2102.08578] Evolving GAN Formulations for Higher Quality Image Synthesis](http://arxiv.org/abs/2102.08578)


  Generative Adversarial Networks (GANs) have extended deep learning to complex
generation and translation tasks across different data modalities. However,
GANs are notoriously difficult to train: Mode collapse and other instabilities
in the training process often degrade the quality of the generated results,
such as images. This paper presents a new technique called TaylorGAN for
improving GANs by discovering customized loss functions for each of its two
networks. The loss functions are parameterized as Taylor expansions and
optimized through multiobjective evolution. On an image-to-image translation
benchmark task, this approach qualitatively improves generated image quality
and quantitatively improves two independent GAN performance metrics. It
therefore forms a promising approach for applying GANs to more challenging
tasks in the future.

    

### [[2102.10739] Dissecting the Diffusion Process in Linear Graph Convolutional Networks](http://arxiv.org/abs/2102.10739)


  Graph Convolutional Networks (GCNs) have attracted more and more attentions
in recent years. A typical GCN layer consists of a linear feature propagation
step and a nonlinear transformation step. Recent works show that a linear GCN
can achieve comparable performance to the original non-linear GCN while being
much more computationally efficient. In this paper, we dissect the feature
propagation steps of linear GCNs from a perspective of continuous graph
diffusion, and analyze why linear GCNs fail to benefit from more propagation
steps. Following that, we propose Decoupled Graph Convolution (DGC) that
decouples the terminal time and the feature propagation steps, making it more
flexible and capable of exploiting a very large number of feature propagation
steps. Experiments demonstrate that our proposed DGC improves linear GCNs by a
large margin and makes them competitive with many modern variants of non-linear
GCNs.

    

### [[2102.11503] Two Sides of Meta-Learning Evaluation: In vs. Out of Distribution](http://arxiv.org/abs/2102.11503)


  We categorize meta-learning evaluation into two settings:
$\textit{in-distribution}$ [ID], in which the train and test tasks are sampled
$\textit{iid}$ from the same underlying task distribution, and
$\textit{out-of-distribution}$ [OOD], in which they are not. While most
meta-learning theory and some FSL applications follow the ID setting, we
identify that most existing few-shot classification benchmarks instead reflect
OOD evaluation, as they use disjoint sets of train (base) and test (novel)
classes for task generation. This discrepancy is problematic because -- as we
show on numerous benchmarks -- meta-learning methods that perform better on
existing OOD datasets may perform significantly worse in the ID setting. In
addition, in the OOD setting, even though current FSL benchmarks seem
befitting, our study highlights concerns in 1) reliably performing model
selection for a given meta-learning method, and 2) consistently comparing the
performance of different methods. To address these concerns, we provide
suggestions on how to construct FSL benchmarks to allow for ID evaluation as
well as more reliable OOD evaluation. Our work aims to inform the meta-learning
community about the importance and distinction of ID vs. OOD evaluation, as
well as the subtleties of OOD evaluation with current benchmarks.

    

### [[2102.11755] Analytical Study of Momentum-Based Acceleration Methods in Paradigmatic High-Dimensional Non-Convex Problems](http://arxiv.org/abs/2102.11755)


  The optimization step in many machine learning problems rarely relies on
vanilla gradient descent but it is common practice to use momentum-based
accelerated methods. Despite these algorithms being widely applied to arbitrary
loss functions, their behaviour in generically non-convex, high dimensional
landscapes is poorly understood. In this work, we use dynamical mean field
theory techniques to describe analytically the average dynamics of these
methods in a prototypical non-convex model: the (spiked) matrix-tensor model.
We derive a closed set of equations that describe the behaviour of heavy-ball
momentum and Nesterov acceleration in the infinite dimensional limit. By
numerical integration of these equations, we observe that these methods speed
up the dynamics but do not improve the algorithmic threshold with respect to
gradient descent in the spiked model.

    

### [[2102.12959] Bayesian OOD detection with aleatoric uncertainty and outlier exposure](http://arxiv.org/abs/2102.12959)


  Typical Bayesian approaches to OOD detection use epistemic uncertainty.
Surprisingly from the Bayesian perspective, there are a number of methods that
successfully use aleatoric uncertainty to detect OOD points (e.g. Hendryks et
al. 2018). In addition, it is difficult to use outlier exposure to improve a
Bayesian OOD detection model, as it is not clear whether it is possible or
desirable to increase posterior (epistemic) uncertainty at outlier points. We
show that a generative model of data curation provides a principled account of
aleatoric uncertainty for OOD detection. In particular, aleatoric uncertainty
signals a specific type of OOD point: one without a well-defined class-label,
and our model of data curation gives a likelihood for these points, giving us a
mechanism for conditioning on outlier points and thus performing principled
Bayesian outlier exposure. Our principled Bayesian approach, combining
aleatoric and epistemic uncertainty with outlier exposure performs better than
methods using aleatoric or epistemic alone.

    

### [[2103.01495] Task-Adaptive Neural Network Search with Meta-Contrastive Learning](http://arxiv.org/abs/2103.01495)


  Most conventional Neural Architecture Search (NAS) approaches are limited in
that they only generate architectures without searching for the optimal
parameters. While some NAS methods handle this issue by utilizing a supernet
trained on a large-scale dataset such as ImageNet, they may be suboptimal if
the target tasks are highly dissimilar from the dataset the supernet is trained
on. To address such limitations, we introduce a novel problem of \emph{Neural
Network Search} (NNS), whose goal is to search for the optimal pretrained
network for a novel dataset and constraints (e.g. number of parameters), from a
model zoo. Then, we propose a novel framework to tackle the problem, namely
\emph{Task-Adaptive Neural Network Search} (TANS). Given a model-zoo that
consists of network pretrained on diverse datasets, we use a novel amortized
meta-learning framework to learn a cross-modal latent space with contrastive
loss, to maximize the similarity between a dataset and a high-performing
network on it, and minimize the similarity between irrelevant dataset-network
pairs. We validate the effectiveness and efficiency of our method on ten
real-world datasets, against existing NAS/AutoML baselines. The results show
that our method instantly retrieves networks that outperform models obtained
with the baselines with significantly fewer training steps to reach the target
performance, thus minimizing the total cost of obtaining a task-optimal
network. Our code and the model-zoo are available at
this https URL.

    

### [[2103.02886] Improving Computational Efficiency in Visual Reinforcement Learning via Stored Embeddings](http://arxiv.org/abs/2103.02886)


  Recent advances in off-policy deep reinforcement learning (RL) have led to
impressive success in complex tasks from visual observations. Experience replay
improves sample-efficiency by reusing experiences from the past, and
convolutional neural networks (CNNs) process high-dimensional inputs
effectively. However, such techniques demand high memory and computational
bandwidth. In this paper, we present Stored Embeddings for Efficient
Reinforcement Learning (SEER), a simple modification of existing off-policy RL
methods, to address these computational and memory requirements. To reduce the
computational overhead of gradient updates in CNNs, we freeze the lower layers
of CNN encoders early in training due to early convergence of their parameters.
Additionally, we reduce memory requirements by storing the low-dimensional
latent vectors for experience replay instead of high-dimensional images,
enabling an adaptive increase in the replay buffer capacity, a useful technique
in constrained-memory settings. In our experiments, we show that SEER does not
degrade the performance of RL agents while significantly saving computation and
memory across a diverse set of DeepMind Control environments and Atari games.

    

### [[2103.03452] FedDR -- Randomized Douglas-Rachford Splitting Algorithms for Nonconvex Federated Composite Optimization](http://arxiv.org/abs/2103.03452)


  We develop two new algorithms, called, FedDR and asyncFedDR, for solving a
fundamental nonconvex composite optimization problem in federated learning. Our
algorithms rely on a novel combination between a nonconvex Douglas-Rachford
splitting method, randomized block-coordinate strategies, and asynchronous
implementation. They can also handle convex regularizers. Unlike recent methods
in the literature, e.g., FedSplit and FedPD, our algorithms update only a
subset of users at each communication round, and possibly in an asynchronous
manner, making them more practical. These new algorithms can handle statistical
and system heterogeneity, which are the two main challenges in federated
learning, while achieving the best known communication complexity. In fact, our
new algorithms match the communication complexity lower bound up to a constant
factor under standard assumptions. Our numerical experiments illustrate the
advantages of our methods over existing algorithms on synthetic and real
datasets.

    

### [[2103.04551] Behavior From the Void: Unsupervised Active Pre-Training](http://arxiv.org/abs/2103.04551)


  We introduce a new unsupervised pre-training method for reinforcement
learning called APT, which stands for Active Pre-Training. APT learns behaviors
and representations by actively searching for novel states in reward-free
environments. The key novel idea is to explore the environment by maximizing a
non-parametric entropy computed in an abstract representation space, which
avoids challenging density modeling and consequently allows our approach to
scale much better in environments that have high-dimensional observations
(e.g., image observations). We empirically evaluate APT by exposing
task-specific reward after a long unsupervised pre-training phase. In Atari
games, APT achieves human-level performance on 12 games and obtains highly
competitive performance compared to canonical fully supervised RL algorithms.
On DMControl suite, APT beats all baselines in terms of asymptotic performance
and data efficiency and dramatically improves performance on tasks that are
extremely difficult to train from scratch.

    

### [[2103.09159] Learning to Shape Rewards using a Game of Two Partners](http://arxiv.org/abs/2103.09159)


  Reward shaping (RS) is a powerful method in reinforcement learning (RL) for
overcoming the problem of sparse or uninformative rewards. However, RS
typically relies on manually engineered shaping-reward functions whose
construction is time-consuming and error-prone. It also requires domain
knowledge which runs contrary to the goal of autonomous learning. We introduce
Reinforcement Learning Optimising Shaping Algorithm (ROSA), an automated RS
framework in which the shaping-reward function is constructed in a novel Markov
game between two agents. A reward-shaping agent (Shaper) uses switching
controls to determine which states to add shaping rewards and their optimal
values while the other agent (Controller) learns the optimal policy for the
task using these shaped rewards. We prove that ROSA, which easily adopts
existing RL algorithms, learns to construct a shaping-reward function that is
tailored to the task thus ensuring efficient convergence to high performance
policies. We demonstrate ROSA's congenial properties in three carefully
designed experiments and show its superior performance against state-of-the-art
RS algorithms in challenging sparse reward environments.

    

### [[2103.16547] The Elastic Lottery Ticket Hypothesis](http://arxiv.org/abs/2103.16547)


  Lottery Ticket Hypothesis (LTH) raises keen attention to identifying sparse
trainable subnetworks, or winning tickets, which can be trained in isolation to
achieve similar or even better performance compared to the full models. Despite
many efforts being made, the most effective method to identify such winning
tickets is still Iterative Magnitude-based Pruning (IMP), which is
computationally expensive and has to be run thoroughly for every different
network. A natural question that comes in is: can we "transform" the winning
ticket found in one network to another with a different architecture, yielding
a winning ticket for the latter at the beginning, without re-doing the
expensive IMP? Answering this question is not only practically relevant for
efficient "once-for-all" winning ticket finding, but also theoretically
appealing for uncovering inherently scalable sparse patterns in networks. We
conduct extensive experiments on CIFAR-10 and ImageNet, and propose a variety
of strategies to tweak the winning tickets found from different networks of the
same model family (e.g., ResNets). Based on these results, we articulate the
Elastic Lottery Ticket Hypothesis (E-LTH): by mindfully replicating (or
dropping) and re-ordering layers for one network, its corresponding winning
ticket could be stretched (or squeezed) into a subnetwork for another deeper
(or shallower) network from the same family, whose performance is nearly the
same competitive as the latter's winning ticket directly found by IMP. We have
also extensively compared E-LTH with pruning-at-initialization and dynamic
sparse training methods, as well as discussed the generalizability of E-LTH to
different model families, layer types, and across datasets. Code is available
at this https URL.

    

### [[2103.17268] Fast Certified Robust Training with Short Warmup](http://arxiv.org/abs/2103.17268)


  Recently, bound propagation based certified robust training methods have been
proposed for training neural networks with certifiable robustness guarantees.
Despite that state-of-the-art (SOTA) methods including interval bound
propagation (IBP) and CROWN-IBP have per-batch training complexity similar to
standard neural network training, they usually use a long warmup schedule with
hundreds or thousands epochs to reach SOTA performance and are thus still
costly. In this paper, we identify two important issues in existing methods,
namely exploded bounds at initialization, and the imbalance in ReLU activation
states and improve IBP training. These two issues make certified training
difficult and unstable, and thereby long warmup schedules were needed in prior
works. To mitigate these issues and conduct faster certified training with
shorter warmup, we propose three improvements based on IBP training: 1) We
derive a new weight initialization method for IBP training; 2) We propose to
fully add Batch Normalization (BN) to each layer in the model, since we find BN
can reduce the imbalance in ReLU activation states; 3) We also design
regularization to explicitly tighten certified bounds and balance ReLU
activation states during wamrup. We are able to obtain 65.03% verified error on
CIFAR-10 ($\epsilon=\frac{8}{255}$) and 82.36% verified error on TinyImageNet
($\epsilon=\frac{1}{255}$) using very short training schedules (160 and 80
total epochs, respectively), outperforming literature SOTA trained with
hundreds or thousands epochs under the same network architecture. The code is
available at this https URL.

    

### [[2104.01177] How Powerful are Performance Predictors in Neural Architecture Search?](http://arxiv.org/abs/2104.01177)


  Early methods in the rapidly developing field of neural architecture search
(NAS) required fully training thousands of neural networks. To reduce this
extreme computational cost, dozens of techniques have since been proposed to
predict the final performance of neural architectures. Despite the success of
such performance prediction methods, it is not well-understood how different
families of techniques compare to one another, due to the lack of an
agreed-upon evaluation metric and optimization for different constraints on the
initialization time and query time. In this work, we give the first large-scale
study of performance predictors by analyzing 31 techniques ranging from
learning curve extrapolation, to weight-sharing, to supervised learning, to
"zero-cost" proxies. We test a number of correlation- and rank-based
performance measures in a variety of settings, as well as the ability of each
technique to speed up predictor-based NAS frameworks. Our results act as
recommendations for the best predictors to use in different settings, and we
show that certain families of predictors can be combined to achieve even better
predictive power, opening up promising research directions. Our code, featuring
a library of 31 performance predictors, is available at
this https URL.

    

### [[2104.05077] CoPE: Conditional image generation using Polynomial Expansions](http://arxiv.org/abs/2104.05077)


  Generative modeling has evolved to a notable field of machine learning. Deep
polynomial neural networks (PNNs) have demonstrated impressive results in
unsupervised image generation, where the task is to map an input vector (i.e.,
noise) to a synthesized image. However, the success of PNNs has not been
replicated in conditional generation tasks, such as super-resolution. Existing
PNNs focus on single-variable polynomial expansions which do not fare well to
two-variable inputs, i.e., the noise variable and the conditional variable. In
this work, we introduce a general framework, called CoPE, that enables a
polynomial expansion of two input variables and captures their auto- and
cross-correlations. We exhibit how CoPE can be trivially augmented to accept an
arbitrary number of input variables. CoPE is evaluated in five tasks
(class-conditional generation, inverse problems, edges-to-image translation,
image-to-image translation, attribute-guided generation) involving eight
datasets. The thorough evaluation suggests that CoPE can be useful for tackling
diverse conditional generation tasks. The source code of CoPE is available at
\url{this https URL}.

    

### [[2104.05418] Contrastive Learning of Global-Local Video Representations](http://arxiv.org/abs/2104.05418)


  Contrastive learning has delivered impressive results for various tasks in
the self-supervised regime. However, existing approaches optimize for learning
representations specific to downstream scenarios, i.e., \textit{global}
representations suitable for tasks such as classification or \textit{local}
representations for tasks such as detection and localization. While they
produce satisfactory results in the intended downstream scenarios, they often
fail to generalize to tasks that they were not originally designed for. In this
work, we propose to learn video representations that generalize to both the
tasks which require global semantic information (e.g., classification) and the
tasks that require local fine-grained spatio-temporal information (e.g.,
localization). We achieve this by optimizing two contrastive objectives that
together encourage our model to learn global-local visual information given
audio signals. We show that the two objectives mutually improve the
generalizability of the learned global-local representations, significantly
outperforming their disjointly learned counterparts. We demonstrate our
approach on various tasks including action/sound classification, lip reading,
deepfake detection, event and sound localization
(this https URL\_local).

    

### [[2105.07264] Neural Trees for Learning on Graphs](http://arxiv.org/abs/2105.07264)


  Graph Neural Networks (GNNs) have emerged as a flexible and powerful approach
for learning over graphs. Despite this success, existing GNNs are constrained
by their local message-passing architecture and are provably limited in their
expressive power. In this work, we propose a new GNN architecture -- the Neural
Tree. The neural tree architecture does not perform message passing on the
input graph, but on a tree-structured graph, called the H-tree, that is
constructed from the input graph. Nodes in the H-tree correspond to subgraphs
in the input graph, and they are reorganized in a hierarchical manner such that
the parent of a node in the H-tree always corresponds to a larger subgraph in
the input graph. We show that the neural tree architecture can approximate any
smooth probability distribution function over an undirected graph. We also
prove that the number of parameters needed to achieve an
$\epsilon$-approximation of the distribution function is exponential in the
treewidth of the input graph, but linear in its size. We prove that any
continuous $\mathcal{G}$-invariant/equivariant function can be approximated by
a nonlinear combination of such probability distribution functions over
$\mathcal{G}$. We apply the neural tree to semi-supervised node classification
in 3D scene graphs, and show that these theoretical properties translate into
significant gains in prediction accuracy, over the more traditional GNN
architectures. We also show the applicability of the neural tree architecture
to citation networks with large treewidth, by using a graph sub-sampling
technique.

    

### [[2105.10545] HyFed: A Hybrid Federated Framework for Privacy-preserving Machine Learning](http://arxiv.org/abs/2105.10545)


  Federated learning (FL) enables multiple clients to jointly train a global
model under the coordination of a central server. Although FL is a
privacy-aware paradigm, where raw data sharing is not required, recent studies
have shown that FL might leak the private data of a client through the model
parameters shared with the server or the other clients. In this paper, we
present the HyFed framework, which enhances the privacy of FL while preserving
the utility of the global model. HyFed provides developers with a generic API
to develop federated, privacy-preserving algorithms. HyFed supports both
simulation and federated operation modes and its source code is publicly
available at this https URL.

    

### [[2105.10919] Continual World: A Robotic Benchmark For Continual Reinforcement Learning](http://arxiv.org/abs/2105.10919)


  Continual learning (CL) -- the ability to continuously learn, building on
previously acquired knowledge -- is a natural requirement for long-lived
autonomous reinforcement learning (RL) agents. While building such agents, one
needs to balance opposing desiderata, such as constraints on capacity and
compute, the ability to not catastrophically forget, and to exhibit positive
transfer on new tasks. Understanding the right trade-off is conceptually and
computationally challenging, which we argue has led the community to overly
focus on catastrophic forgetting. In response to these issues, we advocate for
the need to prioritize forward transfer and propose Continual World, a
benchmark consisting of realistic and meaningfully diverse robotic tasks built
on top of Meta-World as a testbed. Following an in-depth empirical evaluation
of existing CL methods, we pinpoint their limitations and highlight unique
algorithmic challenges in the RL setting. Our benchmark aims to provide a
meaningful and computationally inexpensive challenge for the community and thus
help better understand the performance of existing and future solutions.
Information about the benchmark, including the open-source code, is available
at this https URL.

    

### [[2105.11010] Post-Training Sparsity-Aware Quantization](http://arxiv.org/abs/2105.11010)


  Quantization is a technique used in deep neural networks (DNNs) to increase
execution performance and hardware efficiency. Uniform post-training
quantization (PTQ) methods are common, since they can be implemented
efficiently in hardware and do not require extensive hardware resources or a
training set. Mapping FP32 models to INT8 using uniform PTQ yields models with
negligible accuracy degradation; however, reducing precision below 8 bits with
PTQ is challenging, as accuracy degradation becomes noticeable, due to the
increase in quantization noise. In this paper, we propose a sparsity-aware
quantization (SPARQ) method, in which the unstructured and dynamic activation
sparsity is leveraged in different representation granularities. 4-bit
quantization, for example, is employed by dynamically examining the bits of
8-bit values and choosing a window of 4 bits, while first skipping zero-value
bits. Moreover, instead of quantizing activation-by-activation to 4 bits, we
focus on pairs of 8-bit activations and examine whether one of the two is equal
to zero. If one is equal to zero, the second can opportunistically use the
other's 4-bit budget; if both do not equal zero, then each is dynamically
quantized to 4 bits, as described. SPARQ achieves minor accuracy degradation
and a practical hardware implementation. The code is available at
this https URL.

    

### [[2105.13345] Adversarial Intrinsic Motivation for Reinforcement Learning](http://arxiv.org/abs/2105.13345)


  Learning with an objective to minimize the mismatch with a reference
distribution has been shown to be useful for generative modeling and imitation
learning. In this paper, we investigate whether one such objective, the
Wasserstein-1 distance between a policy's state visitation distribution and a
target distribution, can be utilized effectively for reinforcement learning
(RL) tasks. Specifically, this paper focuses on goal-conditioned reinforcement
learning where the idealized (unachievable) target distribution has full
measure at the goal. This paper introduces a quasimetric specific to Markov
Decision Processes (MDPs) and uses this quasimetric to estimate the above
Wasserstein-1 distance. It further shows that the policy that minimizes this
Wasserstein-1 distance is the policy that reaches the goal in as few steps as
possible. Our approach, termed Adversarial Intrinsic Motivation (AIM),
estimates this Wasserstein-1 distance through its dual objective and uses it to
compute a supplemental reward function. Our experiments show that this reward
function changes smoothly with respect to transitions in the MDP and directs
the agent's exploration to find the goal efficiently. Additionally, we combine
AIM with Hindsight Experience Replay (HER) and show that the resulting
algorithm accelerates learning significantly on several simulated robotics
tasks when compared to other rewards that encourage exploration or accelerate
learning.

    

### [[2105.14119] Towards optimally abstaining from prediction with OOD test examples](http://arxiv.org/abs/2105.14119)


  A common challenge across all areas of machine learning is that training data
is not distributed like test data, due to natural shifts, "blind spots," or
adversarial examples; such test examples are referred to as out-of-distribution
(OOD) test examples. We consider a model where one may abstain from predicting,
at a fixed cost. In particular, our transductive abstention algorithm takes
labeled training examples and unlabeled test examples as input, and provides
predictions with optimal prediction loss guarantees. The loss bounds match
standard generalization bounds when test examples are i.i.d. from the training
distribution, but add an additional term that is the cost of abstaining times
the statistical distance between the train and test distribution (or the
fraction of adversarial examples). For linear regression, we give a
polynomial-time algorithm based on Celis-Dennis-Tapia optimization algorithms.
For binary classification, we show how to efficiently implement it using a
proper agnostic learner (i.e., an Empirical Risk Minimizer) for the class of
interest. Our work builds on a recent abstention algorithm of Goldwasser,
Kalais, and Montasser (2020) for transductive binary classification.

    

### [[2105.15203] SegFormer: Simple and Efficient Design for Semantic Segmentation with Transformers](http://arxiv.org/abs/2105.15203)


  We present SegFormer, a simple, efficient yet powerful semantic segmentation
framework which unifies Transformers with lightweight multilayer perception
(MLP) decoders. SegFormer has two appealing features: 1) SegFormer comprises a
novel hierarchically structured Transformer encoder which outputs multiscale
features. It does not need positional encoding, thereby avoiding the
interpolation of positional codes which leads to decreased performance when the
testing resolution differs from training. 2) SegFormer avoids complex decoders.
The proposed MLP decoder aggregates information from different layers, and thus
combining both local attention and global attention to render powerful
representations. We show that this simple and lightweight design is the key to
efficient segmentation on Transformers. We scale our approach up to obtain a
series of models from SegFormer-B0 to SegFormer-B5, reaching significantly
better performance and efficiency than previous counterparts. For example,
SegFormer-B4 achieves 50.3% mIoU on ADE20K with 64M parameters, being 5x
smaller and 2.2% better than the previous best method. Our best model,
SegFormer-B5, achieves 84.0% mIoU on Cityscapes validation set and shows
excellent zero-shot robustness on Cityscapes-C. Code will be released at:
this http URL.

    

### [[2106.00786] The Out-of-Distribution Problem in Explainability and Search Methods for Feature Importance Explanations](http://arxiv.org/abs/2106.00786)


  Feature importance (FI) estimates are a popular form of explanation, and they
are commonly created and evaluated by computing the change in model confidence
caused by removing certain input features at test time. For example, in the
standard Sufficiency metric, only the top-k most important tokens are kept. In
this paper, we study several under-explored dimensions of FI explanations,
providing conceptual and empirical improvements for this form of explanation.
First, we advance a new argument for why it can be problematic to remove
features from an input when creating or evaluating explanations: the fact that
these counterfactual inputs are out-of-distribution (OOD) to models implies
that the resulting explanations are socially misaligned. The crux of the
problem is that the model prior and random weight initialization influence the
explanations (and explanation metrics) in unintended ways. To resolve this
issue, we propose a simple alteration to the model training process, which
results in more socially aligned explanations and metrics. Second, we compare
among five approaches for removing features from model inputs. We find that
some methods produce more OOD counterfactuals than others, and we make
recommendations for selecting a feature-replacement function. Finally, we
introduce four search-based methods for identifying FI explanations and compare
them to strong baselines, including LIME, Anchors, and Integrated Gradients.
Through experiments with six diverse text classification datasets, we find that
the only method that consistently outperforms random search is a Parallel Local
Search (PLS) that we introduce. Improvements over the second-best method are as
large as 5.4 points for Sufficiency and 17 points for Comprehensiveness. All
supporting code for experiments in this paper is publicly available at
this https URL.

    

### [[2106.01151] Towards Deeper Deep Reinforcement Learning](http://arxiv.org/abs/2106.01151)


  In computer vision and natural language processing, innovations in model
architecture that increase model capacity have reliably translated into gains
in performance. In stark contrast with this trend, state-of-the-art
reinforcement learning (RL) algorithms often use small MLPs, and gains in
performance typically originate from algorithmic innovations. It is natural to
hypothesize that small datasets in RL necessitate simple models to avoid
overfitting; however, this hypothesis is untested. In this paper we investigate
how RL agents are affected by exchanging the small MLPs with larger modern
networks with skip connections and normalization, focusing specifically on
actor-critic algorithms. We empirically verify that naively adopting such
architectures leads to instabilities and poor performance, likely contributing
to the popularity of simple models in practice. However, we show that dataset
size is not the limiting factor, and instead argue that instability from taking
gradients through the critic is the culprit. We demonstrate that spectral
normalization (SN) can mitigate this issue and enable stable training with
large modern architectures. After smoothing with SN, larger models yield
significant performance improvements -- suggesting that more "easy" gains may
be had by focusing on model architectures in addition to algorithmic
innovations.

    

### [[2106.01939] Causal Effect Inference for Structured Treatments](http://arxiv.org/abs/2106.01939)


  We address the estimation of conditional average treatment effects (CATEs)
for structured treatments (e.g., graphs, images, texts). Given a weak condition
on the effect, we propose the generalized Robinson decomposition, which (i)
isolates the causal estimand (reducing regularization bias), (ii) allows one to
plug in arbitrary models for learning, and (iii) possesses a quasi-oracle
convergence guarantee under mild assumptions. In experiments with small-world
and molecular graphs we demonstrate that our approach outperforms prior work in
CATE estimation.

    

### [[2106.02900] Differentially Private Multi-Armed Bandits in the Shuffle Model](http://arxiv.org/abs/2106.02900)


  We give an $(\varepsilon,\delta)$-differentially private algorithm for the
multi-armed bandit (MAB) problem in the shuffle model with a
distribution-dependent regret of $O\left(\left(\sum_{a\in
[k]:\Delta_a>0}\frac{\log
T}{\Delta_a}\right)+\frac{k\sqrt{\log\frac{1}{\delta}}\log
T}{\varepsilon}\right)$, and a distribution-independent regret of
$O\left(\sqrt{kT\log T}+\frac{k\sqrt{\log\frac{1}{\delta}}\log
T}{\varepsilon}\right)$, where $T$ is the number of rounds, $\Delta_a$ is the
suboptimality gap of the arm $a$, and $k$ is the total number of arms. Our
upper bound almost matches the regret of the best known algorithms for the
centralized model, and significantly outperforms the best known algorithm in
the local model.

    

### [[2106.02923] Local Disentanglement in Variational Auto-Encoders Using Jacobian $L_1$ Regularization](http://arxiv.org/abs/2106.02923)


  There have been many recent advances in representation learning; however,
unsupervised representation learning can still struggle with model
identification issues related to rotations of the latent space. Variational
Auto-Encoders (VAEs) and their extensions such as $\beta$-VAEs have been shown
to improve local alignment of latent variables with PCA directions, which can
help to improve model disentanglement under some conditions. Borrowing
inspiration from Independent Component Analysis (ICA) and sparse coding, we
propose applying an $L_1$ loss to the VAE's generative Jacobian during training
to encourage local latent variable alignment with independent factors of
variation in images of multiple objects or images with multiple parts. We
demonstrate our results on a variety of datasets, giving qualitative and
quantitative results using information theoretic and modularity measures that
show our added $L_1$ cost encourages local axis alignment of the latent
representation with individual factors of variation.

    

### [[2106.03922] Interactive Label Cleaning with Example-based Explanations](http://arxiv.org/abs/2106.03922)


  We tackle sequential learning under label noise in applications where a human
supervisor can be queried to relabel suspicious examples. Existing approaches
are flawed, in that they only relabel incoming examples that look "suspicious"
to the model. As a consequence, those mislabeled examples that elude (or don't
undergo) this cleaning step end up tainting the training data and the model
with no further chance of being cleaned. We propose Cincer, a novel approach
that cleans both new and past data by identifying pairs of mutually
incompatible examples. Whenever it detects a suspicious example, Cincer
identifies a counter-example in the training set that -- according to the model
-- is maximally incompatible with the suspicious example, and asks the
annotator to relabel either or both examples, resolving this possible
inconsistency. The counter-examples are chosen to be maximally incompatible, so
to serve as explanations of the model' suspicion, and highly influential, so to
convey as much information as possible if relabeled. Cincer achieves this by
leveraging an efficient and robust approximation of influence functions based
on the Fisher information matrix (FIM). Our extensive empirical evaluation
shows that clarifying the reasons behind the model's suspicions by cleaning the
counter-examples helps acquiring substantially better data and models,
especially when paired with our FIM approximation.

    

### [[2106.04619] Self-Supervised Learning with Data Augmentations Provably Isolates Content from Style](http://arxiv.org/abs/2106.04619)


  Self-supervised representation learning has shown remarkable success in a
number of domains. A common practice is to perform data augmentation via
hand-crafted transformations intended to leave the semantics of the data
invariant. We seek to understand the empirical success of this approach from a
theoretical perspective. We formulate the augmentation process as a latent
variable model by postulating a partition of the latent representation into a
content component, which is assumed invariant to augmentation, and a style
component, which is allowed to change. Unlike prior work on disentanglement and
independent component analysis, we allow for both nontrivial statistical and
causal dependencies in the latent space. We study the identifiability of the
latent representation based on pairs of views of the observations and prove
sufficient conditions that allow us to identify the invariant content partition
up to an invertible mapping in both generative and discriminative settings. We
find numerical simulations with dependent latent variables are consistent with
our theory. Lastly, we introduce Causal3DIdent, a dataset of high-dimensional,
visually complex images with rich causal dependencies, which we use to study
the effect of data augmentations performed in practice.

    

### [[2106.05001] No Fear of Heterogeneity: Classifier Calibration for Federated Learning with Non-IID Data](http://arxiv.org/abs/2106.05001)


  A central challenge in training classification models in the real-world
federated system is learning with non-IID data. To cope with this, most of the
existing works involve enforcing regularization in local optimization or
improving the model aggregation scheme at the server. Other works also share
public datasets or synthesized samples to supplement the training of
under-represented classes or introduce a certain level of personalization.
Though effective, they lack a deep understanding of how the data heterogeneity
affects each layer of a deep classification model. In this paper, we bridge
this gap by performing an experimental analysis of the representations learned
by different layers. Our observations are surprising: (1) there exists a
greater bias in the classifier than other layers, and (2) the classification
performance can be significantly improved by post-calibrating the classifier
after federated training. Motivated by the above findings, we propose a novel
and simple algorithm called Classifier Calibration with Virtual Representations
(CCVR), which adjusts the classifier using virtual representations sampled from
an approximated gaussian mixture model. Experimental results demonstrate that
CCVR achieves state-of-the-art performance on popular federated learning
benchmarks including CIFAR-10, CIFAR-100, and CINIC-10. We hope that our simple
yet effective method can shed some light on the future research of federated
learning with non-IID data.

    

### [[2106.05152] Rethink Transfer Learning in Medical Image Classification](http://arxiv.org/abs/2106.05152)


  Transfer learning (TL) with deep convolutional neural networks (DCNNs) has
proved successful in medical image classification (MIC). However, the current
practice is puzzling, as MIC typically relies only on low- and/or mid-level
features that are learned in the bottom layers of DCNNs. Following this
intuition, we question the current strategies of TL in MIC. In this paper, we
perform careful experimental comparisons between shallow and deep networks for
classification on two chest x-ray datasets, using different TL strategies. We
find that deep models are not always favorable, and finetuning truncated deep
models almost always yields the best performance, especially in data-poor
regimes.
Project webpage:
this https URL
Keywords: Transfer learning, Medical image classification, Feature hierarchy,
Medical imaging, Evaluation metrics, Imbalanced data

    

### [[2106.05200] Independent mechanism analysis, a new concept?](http://arxiv.org/abs/2106.05200)


  Independent component analysis provides a principled framework for
unsupervised representation learning, with solid theory on the identifiability
of the latent code that generated the data, given only observations of mixtures
thereof. Unfortunately, when the mixing is nonlinear, the model is provably
nonidentifiable, since statistical independence alone does not sufficiently
constrain the problem. Identifiability can be recovered in settings where
additional, typically observed variables are included in the generative
process. We investigate an alternative path and consider instead including
assumptions reflecting the principle of independent causal mechanisms exploited
in the field of causality. Specifically, our approach is motivated by thinking
of each source as independently influencing the mixing process. This gives rise
to a framework which we term independent mechanism analysis. We provide
theoretical and empirical evidence that our approach circumvents a number of
nonidentifiability issues arising in nonlinear blind source separation.

    

### [[2106.05566] A Neural Tangent Kernel Perspective of GANs](http://arxiv.org/abs/2106.05566)


  We propose a novel theoretical framework of analysis for Generative
Adversarial Networks (GANs). We start by pointing out a fundamental flaw in
previous theoretical analyses that leads to ill-defined gradients for the
discriminator. We overcome this issue which impedes a principled study of GAN
training, solving it within our framework by taking into account the
discriminator's architecture. To this end, we leverage the theory of
infinite-width neural networks for the discriminator via its Neural Tangent
Kernel. We provide a characterization of the trained discriminator for a wide
range of losses and establish general differentiability properties of the
network. Moreover, we derive new insights about the generated distribution's
flow during training, advancing our understanding of GAN dynamics. We
empirically corroborate these results via a publicly released analysis toolkit
based on our framework, unveiling intuitions that are consistent with current
GAN practice.

    

### [[2106.06596] Disentangling the Roles of Curation, Data-Augmentation and the Prior in the Cold Posterior Effect](http://arxiv.org/abs/2106.06596)


  The "cold posterior effect" (CPE) in Bayesian deep learning describes the
uncomforting observation that the predictive performance of Bayesian neural
networks can be significantly improved if the Bayes posterior is artificially
sharpened using a temperature parameter T<1. The CPE is problematic in theory
and practice and since the effect was identified many researchers have proposed
hypotheses to explain the phenomenon. However, despite this intensive research
effort the effect remains poorly understood. In this work we provide novel and
nuanced evidence relevant to existing explanations for the cold posterior
effect, disentangling three hypotheses: 1. The dataset curation hypothesis of
Aitchison (2020): we show empirically that the CPE does not arise in a real
curated data set but can be produced in a controlled experiment with varying
curation strength. 2. The data augmentation hypothesis of Izmailov et al.
(2021) and Fortuin et al. (2021): we show empirically that data augmentation is
sufficient but not necessary for the CPE to be present. 3. The bad prior
hypothesis of Wenzel et al. (2020): we use a simple experiment evaluating the
relative importance of the prior and the likelihood, strongly linking the CPE
to the prior. Our results demonstrate how the CPE can arise in isolation from
synthetic curation, data augmentation, and bad priors. Cold posteriors observed
"in the wild" are therefore unlikely to arise from a single simple cause; as a
result, we do not expect a simple "fix" for cold posteriors.

    

### [[2106.06615] Precise characterization of the prior predictive distribution of deep ReLU networks](http://arxiv.org/abs/2106.06615)


  Recent works on Bayesian neural networks (BNNs) have highlighted the need to
better understand the implications of using Gaussian priors in combination with
the compositional structure of the network architecture. Similar in spirit to
the kind of analysis that has been developed to devise better initialization
schemes for neural networks (cf. He- or Xavier initialization), we derive a
precise characterization of the prior predictive distribution of finite-width
ReLU networks with Gaussian weights. While theoretical results have been
obtained for their heavy-tailedness, the full characterization of the prior
predictive distribution (i.e. its density, CDF and moments), remained unknown
prior to this work. Our analysis, based on the Meijer-G function, allows us to
quantify the influence of architectural choices such as the width or depth of
the network on the resulting shape of the prior predictive distribution. We
also formally connect our results to previous work in the infinite width
setting, demonstrating that the moments of the distribution converge to those
of a normal log-normal mixture in the infinite depth limit. Finally, our
results provide valuable guidance on prior design: for instance, controlling
the predictive variance with depth- and width-informed priors on the weights of
the network.

    

### [[2106.07760] RETRIEVE: Coreset Selection for Efficient and Robust Semi-Supervised Learning](http://arxiv.org/abs/2106.07760)


  Semi-supervised learning (SSL) algorithms have had great success in recent
years in limited labeled data regimes. However, the current state-of-the-art
SSL algorithms are computationally expensive and entail significant compute
time and energy requirements. This can prove to be a huge limitation for many
smaller companies and academic groups. Our main insight is that training on a
subset of unlabeled data instead of entire unlabeled data enables the current
SSL algorithms to converge faster, significantly reducing computational costs.
In this work, we propose RETRIEVE, a coreset selection framework for efficient
and robust semi-supervised learning. RETRIEVE selects the coreset by solving a
mixed discrete-continuous bi-level optimization problem such that the selected
coreset minimizes the labeled set loss. We use a one-step gradient
approximation and show that the discrete optimization problem is approximately
submodular, enabling simple greedy algorithms to obtain the coreset. We
empirically demonstrate on several real-world datasets that existing SSL
algorithms like VAT, Mean-Teacher, FixMatch, when used with RETRIEVE, achieve
a) faster training times, b) better performance when unlabeled data consists of
Out-of-Distribution (OOD) data and imbalance. More specifically, we show that
with minimal accuracy degradation, RETRIEVE achieves a speedup of around
$3\times$ in the traditional SSL setting and achieves a speedup of $5\times$
compared to state-of-the-art (SOTA) robust SSL algorithms in the case of
imbalance and OOD data. RETRIEVE is available as a part of the CORDS toolkit:
this https URL.

    

### [[2106.09481] Stochastic Bias-Reduced Gradient Methods](http://arxiv.org/abs/2106.09481)


  We develop a new primitive for stochastic optimization: a low-bias, low-cost
estimator of the minimizer $x_\star$ of any Lipschitz strongly-convex function.
In particular, we use a multilevel Monte-Carlo approach due to Blanchet and
Glynn to turn any optimal stochastic gradient method into an estimator of
$x_\star$ with bias $\delta$, variance $O(\log(1/\delta))$, and an expected
sampling cost of $O(\log(1/\delta))$ stochastic gradient evaluations. As an
immediate consequence, we obtain cheap and nearly unbiased gradient estimators
for the Moreau-Yoshida envelope of any Lipschitz convex function, allowing us
to perform dimension-free randomized smoothing.
We demonstrate the potential of our estimator through four applications.
First, we develop a method for minimizing the maximum of $N$ functions,
improving on recent results and matching a lower bound up to logarithmic
factors. Second and third, we recover state-of-the-art rates for
projection-efficient and gradient-efficient optimization using simple
algorithms with a transparent analysis. Finally, we show that an improved
version of our estimator would yield a nearly linear-time, optimal-utility,
differentially-private non-smooth stochastic optimization method.

    

### [[2106.09876] Anomaly Detection in Dynamic Graphs via Transformer](http://arxiv.org/abs/2106.09876)


  Detecting anomalies for dynamic graphs has drawn increasing attention due to
their wide applications in social networks, e-commerce, and cybersecurity.
Recent deep learning-based approaches have shown promising results over shallow
methods. However, they fail to address two core challenges of anomaly detection
in dynamic graphs: the lack of informative encoding for unattributed nodes and
the difficulty of learning discriminate knowledge from coupled spatial-temporal
dynamic graphs. To overcome these challenges, in this paper, we present a novel
Transformer-based Anomaly Detection framework for DYnamic graphs (TADDY). Our
framework constructs a comprehensive node encoding strategy to better represent
each node's structural and temporal roles in an evolving graphs stream.
Meanwhile, TADDY captures informative representation from dynamic graphs with
coupled spatial-temporal patterns via a dynamic graph transformer model. The
extensive experimental results demonstrate that our proposed TADDY framework
outperforms the state-of-the-art methods by a large margin on six real-world
datasets.

    

### [[2106.10394] Uncertain Decisions Facilitate Better Preference Learning](http://arxiv.org/abs/2106.10394)


  Existing observational approaches for learning human preferences, such as
inverse reinforcement learning, usually make strong assumptions about the
observability of the human's environment. However, in reality, people make many
important decisions under uncertainty. To better understand preference learning
in these cases, we study the setting of inverse decision theory (IDT), a
previously proposed framework where a human is observed making non-sequential
binary decisions under uncertainty. In IDT, the human's preferences are
conveyed through their loss function, which expresses a tradeoff between
different types of mistakes. We give the first statistical analysis of IDT,
providing conditions necessary to identify these preferences and characterizing
the sample complexity -- the number of decisions that must be observed to learn
the tradeoff the human is making to a desired precision. Interestingly, we show
that it is actually easier to identify preferences when the decision problem is
more uncertain. Furthermore, uncertain decision problems allow us to relax the
unrealistic assumption that the human is an optimal decision maker but still
identify their exact preferences; we give sample complexities in this
suboptimal case as well. Our analysis contradicts the intuition that partial
observability should make preference learning more difficult. It also provides
a first step towards understanding and improving preference learning methods
for uncertain and suboptimal humans.

    

### [[2106.10891] Open-set Label Noise Can Improve Robustness Against Inherent Label Noise](http://arxiv.org/abs/2106.10891)


  Learning with noisy labels is a practically challenging problem in weakly
supervised learning. In the existing literature, open-set noises are always
considered to be poisonous for generalization, similar to closed-set noises. In
this paper, we empirically show that open-set noisy labels can be non-toxic and
even benefit the robustness against inherent noisy labels. Inspired by the
observations, we propose a simple yet effective regularization by introducing
Open-set samples with Dynamic Noisy Labels (ODNL) into training. With ODNL, the
extra capacity of the neural network can be largely consumed in a way that does
not interfere with learning patterns from clean data. Through the lens of SGD
noise, we show that the noises induced by our method are random-direction,
conflict-free and biased, which may help the model converge to a flat minimum
with superior stability and enforce the model to produce conservative
predictions on Out-of-Distribution instances. Extensive experimental results on
benchmark datasets with various types of noisy labels demonstrate that the
proposed method not only enhances the performance of many existing robust
algorithms but also achieves significant improvement on Out-of-Distribution
detection tasks even in the label noise setting.

    

### [[2106.11068] Affine-Invariant Integrated Rank-Weighted Depth: Definition, Properties and Finite Sample Analysis](http://arxiv.org/abs/2106.11068)


  Because it determines a center-outward ordering of observations in
$\mathbb{R}^d$ with $d\geq 2$, the concept of statistical depth permits to
define quantiles and ranks for multivariate data and use them for various
statistical tasks (e.g. inference, hypothesis testing). Whereas many depth
functions have been proposed \textit{ad-hoc} in the literature since the
seminal contribution of \cite{Tukey75}, not all of them possess the properties
desirable to emulate the notion of quantile function for univariate probability
distributions. In this paper, we propose an extension of the \textit{integrated
rank-weighted} statistical depth (IRW depth in abbreviated form) originally
introduced in \cite{IRW}, modified in order to satisfy the property of
\textit{affine-invariance}, fulfilling thus all the four key axioms listed in
the nomenclature elaborated by \cite{ZuoS00a}. The variant we propose, referred
to as the Affine-Invariant IRW depth (AI-IRW in short), involves the
covariance/precision matrices of the (supposedly square integrable)
$d$-dimensional random vector $X$ under study, in order to take into account
the directions along which $X$ is most variable to assign a depth value to any
point $x\in \mathbb{R}^d$. The accuracy of the sampling version of the AI-IRW
depth is investigated from a nonasymptotic perspective. Namely, a concentration
result for the statistical counterpart of the AI-IRW depth is proved. Beyond
the theoretical analysis carried out, applications to anomaly detection are
considered and numerical results are displayed, providing strong empirical
evidence of the relevance of the depth function we propose here.

    

### [[2106.11560] Finding Valid Adjustments under Non-ignorability with Minimal DAG Knowledge](http://arxiv.org/abs/2106.11560)


  Treatment effect estimation from observational data is a fundamental problem
in causal inference. There are two very different schools of thought that have
tackled this problem. On one hand, Pearlian framework commonly assumes
structural knowledge (provided by an expert) in form of directed acyclic graphs
and provides graphical criteria such as back-door criterion to identify valid
adjustment sets. On other hand, potential outcomes (PO) framework commonly
assumes that all observed features satisfy ignorability (i.e., no hidden
confounding), which in general is untestable. In prior works that attempted to
bridge these frameworks, there is an observational criteria to identify an
anchor variable and if a subset of covariates (not involving the anchor
variable) passes a suitable conditional independence criteria, then that subset
is a valid back-door. Our main result strengthens these prior results by
showing that under a different expert-driven structural knowledge -- that one
variable is a direct causal parent of treatment variable -- remarkably, testing
for subsets (not involving the known parent variable) that are valid back-doors
is equivalent to an invariance test. Importantly, we also cover the non-trivial
case where entire set of observed features is not ignorable (generalizing the
PO framework) without requiring knowledge of all parents of treatment variable.
Our key technical idea involves generation of a synthetic sub-sampling (or
environment) variable that is a function of the known parent variable. In
addition to designing an invariance test, this sub-sampling variable allows us
to leverage Invariant Risk Minimization, and thus, connects finding valid
adjustments (in non-ignorable observational setting) to representation
learning. We demonstrate effectiveness and tradeoffs of our approaches on a
variety of synthetic data as well as real causal effect estimation benchmarks.

    

### [[2106.12484] From Canonical Correlation Analysis to Self-supervised Graph Neural Networks](http://arxiv.org/abs/2106.12484)


  We introduce a conceptually simple yet effective model for self-supervised
representation learning with graph data. It follows the previous methods that
generate two views of an input graph through data augmentation. However, unlike
contrastive methods that focus on instance-level discrimination, we optimize an
innovative feature-level objective inspired by classical Canonical Correlation
Analysis. Compared with other works, our approach requires none of the
parameterized mutual information estimator, additional projector, asymmetric
structures, and most importantly, negative samples which can be costly. We show
that the new objective essentially 1) aims at discarding augmentation-variant
information by learning invariant representations, and 2) can prevent
degenerated solutions by decorrelating features in different dimensions. Our
theoretical analysis further provides an understanding for the new objective
which can be equivalently seen as an instantiation of the Information
Bottleneck Principle under the self-supervised setting. Despite its simplicity,
our method performs competitively on seven public graph datasets. The code is
available at: this https URL.

    

### [[2106.12997] Bayesian Optimization with High-Dimensional Outputs](http://arxiv.org/abs/2106.12997)


  Bayesian Optimization is a sample-efficient black-box optimization procedure
that is typically applied to problems with a small number of independent
objectives. However, in practice we often wish to optimize objectives defined
over many correlated outcomes (or "tasks"). For example, scientists may want to
optimize the coverage of a cell tower network across a dense grid of locations.
Similarly, engineers may seek to balance the performance of a robot across
dozens of different environments via constrained or robust optimization.
However, the Gaussian Process (GP) models typically used as probabilistic
surrogates for multi-task Bayesian Optimization scale poorly with the number of
outcomes, greatly limiting applicability. We devise an efficient technique for
exact multi-task GP sampling that combines exploiting Kronecker structure in
the covariance matrices with Matheron's identity, allowing us to perform
Bayesian Optimization using exact multi-task GP models with tens of thousands
of correlated outputs. In doing so, we achieve substantial improvements in
sample efficiency compared to existing approaches that only model aggregate
functions of the outcomes. We demonstrate how this unlocks a new class of
applications for Bayesian Optimization across a range of tasks in science and
engineering, including optimizing interference patterns of an optical
interferometer with more than 65,000 outputs.

    

### [[2106.13871] Transflower: probabilistic autoregressive dance generation with multimodal attention](http://arxiv.org/abs/2106.13871)


  Dance requires skillful composition of complex movements that follow
rhythmic, tonal and timbral features of music. Formally, generating dance
conditioned on a piece of music can be expressed as a problem of modelling a
high-dimensional continuous motion signal, conditioned on an audio signal. In
this work we make two contributions to tackle this problem. First, we present a
novel probabilistic autoregressive architecture that models the distribution
over future poses with a normalizing flow conditioned on previous poses as well
as music context, using a multimodal transformer encoder. Second, we introduce
the currently largest 3D dance-motion dataset, obtained with a variety of
motion-capture technologies, and including both professional and casual
dancers. Using this dataset, we compare our new model against two baselines,
via objective metrics and a user study, and show that both the ability to model
a probability distribution, as well as being able to attend over a large motion
and music context are necessary to produce interesting, diverse, and realistic
dance that matches the music.

    

### [[2106.15580] Continuous Latent Process Flows](http://arxiv.org/abs/2106.15580)


  Partial observations of continuous time-series dynamics at arbitrary time
stamps exist in many disciplines. Fitting this type of data using statistical
models with continuous dynamics is not only promising at an intuitive level but
also has practical benefits, including the ability to generate continuous
trajectories and to perform inference on previously unseen time stamps. Despite
exciting progress in this area, the existing models still face challenges in
terms of their representational power and the quality of their variational
approximations. We tackle these challenges with continuous latent process flows
(CLPF), a principled architecture decoding continuous latent processes into
continuous observable processes using a time-dependent normalizing flow driven
by a stochastic differential equation. To optimize our model using maximum
likelihood, we propose a novel piecewise construction of a variational
posterior process and derive the corresponding variational lower bound using
trajectory re-weighting. Our ablation studies demonstrate the effectiveness of
our contributions in various inference tasks on irregular time grids.
Comparisons to state-of-the-art baselines show our model's favourable
performance on both synthetic and real-world time-series data.

    

### [[2108.10252] Federated Multi-Task Learning under a Mixture of Distributions](http://arxiv.org/abs/2108.10252)


  The increasing size of data generated by smartphones and IoT devices
motivated the development of Federated Learning (FL), a framework for on-device
collaborative training of machine learning models. First efforts in FL focused
on learning a single global model with good average performance across clients,
but the global model may be arbitrarily bad for a given client, due to the
inherent heterogeneity of local data distributions. Federated multi-task
learning (MTL) approaches can learn personalized models by formulating an
opportune penalized optimization problem. The penalization term can capture
complex relations among personalized models, but eschews clear statistical
assumptions about local data distributions. In this work, we propose to study
federated MTL under the flexible assumption that each local data distribution
is a mixture of unknown underlying distributions. This assumption encompasses
most of the existing personalized FL approaches and leads to federated EM-like
algorithms for both client-server and fully decentralized settings. Moreover,
it provides a principled way to serve personalized models to clients not seen
at training time. The algorithms' convergence is analyzed through a novel
federated surrogate optimization framework, which can be of general interest.
Experimental results on FL benchmarks show that our approach provides models
with higher accuracy and fairness than state-of-the-art methods.

    

### [[2108.13294] The missing link: Developing a safety case for perception components in automated driving](http://arxiv.org/abs/2108.13294)


  Safety assurance is a central concern for the development and societal
acceptance of automated driving (AD) systems. Perception is a key aspect of AD
that relies heavily on Machine Learning (ML). Despite the known challenges with
the safety assurance of ML-based components, proposals have recently emerged
for unit-level safety cases addressing these components. Unfortunately, AD
safety cases express safety requirements at the system level and these efforts
are missing the critical linking argument needed to integrate safety
requirements at the system level with component performance requirements at the
unit level. In this paper, we propose the Integration Safety Case for
Perception (ISCaP), a generic template for such a linking safety argument
specifically tailored for perception components. The template takes a deductive
and formal approach to define strong traceability between levels. We
demonstrate the applicability of ISCaP with a detailed case study and discuss
its use as a tool to support incremental development of perception components.

    

### [[2110.08944] Developing a novel fair-loan-predictor through a multi-sensitive debiasing pipeline: DualFair](http://arxiv.org/abs/2110.08944)


  Machine learning (ML) models are increasingly used for high-stake
applications that can greatly impact people's lives. Despite their use, these
models have the potential to be biased towards certain social groups on the
basis of race, gender, or ethnicity. Many prior works have attempted to
mitigate this "model discrimination" by updating the training data
(pre-processing), altering the model learning process (in-processing), or
manipulating model output (post-processing). However, these works have not yet
been extended to the realm of multi-sensitive parameters and sensitive options
(MSPSO), where sensitive parameters are attributes that can be discriminated
against (e.g race) and sensitive options are options within sensitive
parameters (e.g black or white), thus giving them limited real-world usability.
Prior work in fairness has also suffered from an accuracy-fairness tradeoff
that prevents both the accuracy and fairness from being high. Moreover,
previous literature has failed to provide holistic fairness metrics that work
with MSPSO. In this paper, we solve all three of these problems by (a) creating
a novel bias mitigation technique called DualFair and (b) developing a new
fairness metric (i.e. AWI) that can handle MSPSO. Lastly, we test our novel
mitigation method using a comprehensive U.S mortgage lending dataset and show
that our classifier, or fair loan predictor, obtains better fairness and
accuracy metrics than current state-of-the-art models.

    

### [[2110.14904] SIMCNN -- Exploiting Computational Similarity to Accelerate CNN Training in Hardware](http://arxiv.org/abs/2110.14904)


  Convolution neural networks (CNN) are computation intensive to train. It
consists of a substantial number of multidimensional dot products between many
kernels and inputs. We observe that there are notable similarities among the
vectors extracted from inputs (i.e., input vectors). If one input vector is
similar to another one, its computations with the kernels are also similar to
those of the other and therefore, can be skipped by reusing the
already-computed results. Based on this insight, we propose a novel scheme
based on locality sensitive hashing (LSH) to exploit the similarity of
computations during CNN training in a hardware accelerator. The proposed
scheme, called SIMCNN, uses a cache (SIMCACHE) to store LSH signatures of
recent input vectors along with the computed results. If the LSH signature of a
new input vector matches with that of an already existing vector in the
SIMCACHE, the already-computed result is reused for the new vector. SIMCNN is
the first work that exploits computational similarity for accelerating CNN
training in hardware. The paper presents a detailed design, workflow, and
implementation of SIMCNN. Our experimental evaluation with four different deep
learning models shows that SIMCNN saves a significant number of computations
and therefore, improves training time up to 43%.

    

### [[2110.14751] Xar-Trek: Run-time Execution Migration among FPGAs and Heterogeneous-ISA CPUs](http://arxiv.org/abs/2110.14751)


  Datacenter servers are increasingly heterogeneous: from x86 host CPUs, to ARM
or RISC-V CPUs in NICs/SSDs, to FPGAs. Previous works have demonstrated that
migrating application execution at run-time across heterogeneous-ISA CPUs can
yield significant performance and energy gains, with relatively little
programmer effort. However, FPGAs have often been overlooked in that context:
hardware acceleration using FPGAs involves statically implementing select
application functions, which prohibits dynamic and transparent migration. We
present Xar-Trek, a new compiler and run-time software framework that overcomes
this limitation. Xar-Trek compiles an application for several CPU ISAs and
select application functions for acceleration on an FPGA, allowing execution
migration between heterogeneous-ISA CPUs and FPGAs at run-time. Xar-Trek's
run-time monitors server workloads and migrates application functions to an
FPGA or to heterogeneous-ISA CPUs based on a scheduling policy. We develop a
heuristic policy that uses application workload profiles to make scheduling
decisions. Our evaluations conducted on a system with x86-64 server CPUs, ARM64
server CPUs, and an Alveo accelerator card reveal 88%-1% performance gains over
no-migration baselines.

    

### [[2110.14902] NetDAM: Network Direct Attached Memory with Programmable In-Memory Computing ISA](http://arxiv.org/abs/2110.14902)


  Data-intensive applications like distributed AI-training may require
multi-terabytes memory capacity with multi-terabits bandwidth. We directly
attach the memory to the ethernet controller with some programable logic to
design an efficient hardware "template" for Memory pooling and in-memory /
in-network computing. We built an FPGA prototype of the NetDAM, andwe
demonstrate MPI-Allreduce communication case, the NetDAM can be used as a
software and hardware friendly programmable architeture with high performance
alternative for RDMA.

    

### [[2110.15238] Bolt: Bridging the Gap between Auto-tuners and Hardware-native Performance](http://arxiv.org/abs/2110.15238)


  Today's auto-tuners (e.g., AutoTVM, Ansor) generate efficient tensor programs
by navigating a large search space to identify effective implementations, but
they do so with opaque hardware details. Thus, their performance could fall
behind that of hardware-native libraries (e.g., cuBLAS, cuDNN), which are
hand-optimized by device vendors to extract high performance. On the other
hand, these vendor libraries have a fixed set of supported functions and lack
the customization and automation support afforded by auto-tuners. Bolt is based
on the recent trend that vendor libraries are increasingly modularized and
reconfigurable via declarative control (e.g., CUTLASS). It enables a novel
approach that bridges this gap and achieves the best of both worlds, via
hardware-native templated search. Bolt provides new opportunities to rethink
end-to-end tensor optimizations at the graph, operator, and model levels. Bolt
demonstrates this concept by prototyping on a popular auto-tuner in TVM and a
class of widely-used platforms (i.e., NVIDIA GPUs) -- both in large deployment
in our production environment. Bolt improves the inference speed of common
convolutional neural networks by 2.5x on average over the state of the art, and
it auto-tunes these models within 20 minutes.

    

### [[1805.00265] Performance Analysis of Distributed Radio Interferometric Calibration](http://arxiv.org/abs/1805.00265)


  Distributed calibration based on consensus optimization is a computationally
efficient method to calibrate large radio interferometers such as LOFAR and
SKA. Calibrating along multiple directions in the sky and removing the bright
foreground signal is a crucial step in many science cases in radio
interferometry. The residual data contain weak signals of huge scientific
interest and of particular concern is the effect of incomplete sky models used
in calibration on the residual. In order to study this, we consider the mapping
between the input uncalibrated data and the output residual data. We derive an
analytical relationship between the input and output probability density
functions which can be used to study the performance of calibration.

    

### [[2007.07977] An Adaptive Self-Scheduling Loop Scheduler](http://arxiv.org/abs/2007.07977)


  Many shared-memory parallel irregular applications, such as sparse linear
algebra and graph algorithms, depend on efficient loop scheduling (LS) in a
fork-join manner despite that the work per loop iteration can greatly vary
depending on the application and the input. Because of its importance, many
different methods, e.g., workload-aware self-scheduling, and parameters, e.g.,
chunk size, have been explored to achieve reasonable performance that requires
expert prior knowledge about the application and input. This work proposes a
new LS method that requires little to no expert knowledge to achieve speedups
close to those of tuned LS methods by self-managing chunk size based on a
heuristic of workload variance and using work-stealing. This method, named
\ichunk, is implemented into libgomp for testing. It is evaluated against
OpenMP's guided, dynamic, and taskloop methods and is evaluated against BinLPT
and generic work-stealing on an array of applications that includes: a
synthetic benchmark, breadth-first search, K-Means, the molecular dynamics code
LavaMD, and sparse matrix-vector multiplication. On 28 thread Intel system,
\ichunk is the only method to always be one of the top three LS methods. On
average across all applications, \ichunk is within 5.4% of the best method and
is even able to outperform other LS methods for breadth-first search and
K-Means.

    

### [[2102.04133] Local certification of graphs on surfaces](http://arxiv.org/abs/2102.04133)


  A proof labelling scheme for a graph class $\mathcal{C}$ is an assignment of
certificates to the vertices of any graph in the class $\mathcal{C}$, such that
upon reading its certificate and the certificates of its neighbors, every
vertex from a graph $G\in \mathcal{C}$ accepts the instance, while if $G\not\in
\mathcal{C}$, for every possible assignment of certificates, at least one
vertex rejects the instance. It was proved recently that for any fixed surface
$\Sigma$, the class of graphs embeddable in $\Sigma$ has a proof labelling
scheme in which each vertex of an $n$-vertex graph receives a certificate of at
most $O(\log n)$ bits. The proof is quite long and intricate and heavily relies
on an earlier result for planar graphs. Here we give a very short proof for any
surface. The main idea is to encode a rotation system locally, together with a
spanning tree supporting the local computation of the genus via Euler's
formula.

    

### [[2110.14706] Sensing Anomalies as Potential Hazards: Datasets and Benchmarks](http://arxiv.org/abs/2110.14706)


  We consider the problem of detecting, in the visual sensing data stream of an
autonomous mobile robot, semantic patterns that are unusual (i.e., anomalous)
with respect to the robot's previous experience in similar environments. These
anomalies might indicate unforeseen hazards and, in scenarios where failure is
costly, can be used to trigger an avoidance behavior. We contribute three novel
image-based datasets acquired in robot exploration scenarios, comprising a
total of more than 200k labeled frames, spanning various types of anomalies. On
these datasets, we study the performance of an anomaly detection approach based
on autoencoders operating at different scales.

    

### [[2110.14742] Efficient Placard Discovery for Semantic Mapping During Frontier Exploration](http://arxiv.org/abs/2110.14742)


  Semantic mapping is the task of providing a robot with a map of its
environment beyond the open, navigable space of traditional Simultaneous
Localization and Mapping (SLAM) algorithms by attaching semantics to locations.
The system presented in this work reads door placards to annotate the locations
of offices. Whereas prior work on this system developed hand-crafted detectors,
this system leverages YOLOv2 for detection and a segmentation network for
segmentation. Placards are localized by computing their pose from a homography
computed from a segmented quadrilateral outline. This work also introduces an
Interruptable Frontier Exploration algorithm, enabling the robot to explore its
environment to construct its SLAM map while pausing to inspect placards
observed during this process. This allows the robot to autonomously discover
room placards without human intervention while speeding up significantly over
previous autonomous exploration methods.

    

### [[2110.14771] ABIDES-Gym: Gym Environments for Multi-Agent Discrete Event Simulation and Application to Financial Markets](http://arxiv.org/abs/2110.14771)


  Model-free Reinforcement Learning (RL) requires the ability to sample
trajectories by taking actions in the original problem environment or a
simulated version of it. Breakthroughs in the field of RL have been largely
facilitated by the development of dedicated open source simulators with easy to
use frameworks such as OpenAI Gym and its Atari environments. In this paper we
propose to use the OpenAI Gym framework on discrete event time based Discrete
Event Multi-Agent Simulation (DEMAS). We introduce a general technique to wrap
a DEMAS simulator into the Gym framework. We expose the technique in detail and
implement it using the simulator ABIDES as a base. We apply this work by
specifically using the markets extension of ABIDES, ABIDES-Markets, and develop
two benchmark financial markets OpenAI Gym environments for training daily
investor and execution agents. As a result, these two environments describe
classic financial problems with a complex interactive market behavior response
to the experimental agent's action.

    

### [[2110.14775] BI-GCN: Boundary-Aware Input-Dependent Graph Convolution Network for Biomedical Image Segmentation](http://arxiv.org/abs/2110.14775)


  Segmentation is an essential operation of image processing. The convolution
operation suffers from a limited receptive field, while global modelling is
fundamental to segmentation tasks. In this paper, we apply graph convolution
into the segmentation task and propose an improved \textit{Laplacian}.
Different from existing methods, our \textit{Laplacian} is data-dependent, and
we introduce two attention diagonal matrices to learn a better vertex
relationship. In addition, it takes advantage of both region and boundary
information when performing graph-based information propagation. Specifically,
we model and reason about the boundary-aware region-wise correlations of
different classes through learning graph representations, which is capable of
manipulating long range semantic reasoning across various regions with the
spatial enhancement along the object's boundary. Our model is well-suited to
obtain global semantic region information while also accommodates local spatial
boundary characteristics simultaneously. Experiments on two types of
challenging datasets demonstrate that our method outperforms the
state-of-the-art approaches on the segmentation of polyps in colonoscopy images
and of the optic disc and optic cup in colour fundus images.

    

### [[2110.14805] Intermediate Layers Matter in Momentum Contrastive Self Supervised Learning](http://arxiv.org/abs/2110.14805)


  We show that bringing intermediate layers' representations of two augmented
versions of an image closer together in self-supervised learning helps to
improve the momentum contrastive (MoCo) method. To this end, in addition to the
contrastive loss, we minimize the mean squared error between the intermediate
layer representations or make their cross-correlation matrix closer to an
identity matrix. Both loss objectives either outperform standard MoCo, or
achieve similar performances on three diverse medical imaging datasets:
NIH-Chest Xrays, Breast Cancer Histopathology, and Diabetic Retinopathy. The
gains of the improved MoCo are especially large in a low-labeled data regime
(e.g. 1% labeled data) with an average gain of 5% across three datasets. We
analyze the models trained using our novel approach via feature similarity
analysis and layer-wise probing. Our analysis reveals that models trained via
our approach have higher feature reuse compared to a standard MoCo and learn
informative features earlier in the network. Finally, by comparing the output
probability distribution of models fine-tuned on small versus large labeled
data, we conclude that our proposed method of pre-training leads to lower
Kolmogorov-Smirnov distance, as compared to a standard MoCo. This provides
additional evidence that our proposed method learns more informative features
in the pre-training phase which could be leveraged in a low-labeled data
regime.

    

### [[2110.14810] Telling Creative Stories Using Generative Visual Aids](http://arxiv.org/abs/2110.14810)


  Can visual artworks created using generative visual algorithms inspire human
creativity in storytelling? We asked writers to write creative stories from a
starting prompt, and provided them with visuals created by generative AI models
from the same prompt. Compared to a control group, writers who used the visuals
as story writing aid wrote significantly more creative, original, complete and
visualizable stories, and found the task more fun. Of the generative algorithms
used (BigGAN, VQGAN, DALL-E, CLIPDraw), VQGAN was the most preferred. The
control group that did not view the visuals did significantly better in
integrating the starting prompts. Findings indicate that cross modality inputs
by AI can benefit divergent aspects of creativity in human-AI co-creation, but
hinders convergent thinking.

    

### [[2110.14844] From Intrinsic to Counterfactual: On the Explainability of Contextualized Recommender Systems](http://arxiv.org/abs/2110.14844)


  With the prevalence of deep learning based embedding approaches, recommender
systems have become a proven and indispensable tool in various information
filtering applications. However, many of them remain difficult to diagnose what
aspects of the deep models' input drive the final ranking decision, thus, they
cannot often be understood by human stakeholders. In this paper, we investigate
the dilemma between recommendation and explainability, and show that by
utilizing the contextual features (e.g., item reviews from users), we can
design a series of explainable recommender systems without sacrificing their
performance. In particular, we propose three types of explainable
recommendation strategies with gradual change of model transparency: whitebox,
graybox, and blackbox. Each strategy explains its ranking decisions via
different mechanisms: attention weights, adversarial perturbations, and
counterfactual perturbations. We apply these explainable models on five
real-world data sets under the contextualized setting where users and items
have explicit interactions. The empirical results show that our model achieves
highly competitive ranking performance, and generates accurate and effective
explanations in terms of numerous quantitative metrics and qualitative
visualizations.

    

### [[2110.14863] Graph Communal Contrastive Learning](http://arxiv.org/abs/2110.14863)


  Graph representation learning is crucial for many real-world applications
(e.g. social relation analysis). A fundamental problem for graph representation
learning is how to effectively learn representations without human labeling,
which is usually costly and time-consuming. Graph contrastive learning (GCL)
addresses this problem by pulling the positive node pairs (or similar nodes)
closer while pushing the negative node pairs (or dissimilar nodes) apart in the
representation space. Despite the success of the existing GCL methods, they
primarily sample node pairs based on the node-level proximity yet the community
structures have rarely been taken into consideration. As a result, two nodes
from the same community might be sampled as a negative pair. We argue that the
community information should be considered to identify node pairs in the same
communities, where the nodes insides are semantically similar. To address this
issue, we propose a novel Graph Communal Contrastive Learning (gCooL) framework
to jointly learn the community partition and learn node representations in an
end-to-end fashion. Specifically, the proposed gCooL consists of two
components: a Dense Community Aggregation (DeCA) algorithm for community
detection and a Reweighted Self-supervised Cross-contrastive (ReSC) training
scheme to utilize the community information. Additionally, the real-world
graphs are complex and often consist of multiple views. In this paper, we
demonstrate that the proposed gCooL can also be naturally adapted to multiplex
graphs. Finally, we comprehensively evaluate the proposed gCooL on a variety of
real-world graphs. The experimental results show that the gCooL outperforms the
state-of-the-art methods.

    

### [[2110.14870] A Scenario-Based Platform for Testing Autonomous Vehicle Behavior Prediction Models in Simulation](http://arxiv.org/abs/2110.14870)


  Behavior prediction remains one of the most challenging tasks in the
autonomous vehicle (AV) software stack. Forecasting the future trajectories of
nearby agents plays a critical role in ensuring road safety, as it equips AVs
with the necessary information to plan safe routes of travel. However, these
prediction models are data-driven and trained on data collected in real life
that may not represent the full range of scenarios an AV can encounter. Hence,
it is important that these prediction models are extensively tested in various
test scenarios involving interactive behaviors prior to deployment. To support
this need, we present a simulation-based testing platform which supports (1)
intuitive scenario modeling with a probabilistic programming language called
Scenic, (2) specifying a multi-objective evaluation metric with a partial
priority ordering, (3) falsification of the provided metric, and (4)
parallelization of simulations for scalable testing. As a part of the platform,
we provide a library of 25 Scenic programs that model challenging test
scenarios involving interactive traffic participant behaviors. We demonstrate
the effectiveness and the scalability of our platform by testing a trained
behavior prediction model and searching for failure scenarios.

    

### [[2110.14910] Diagnosis of COVID-19 Using Machine Learning and Deep Learning: A review](http://arxiv.org/abs/2110.14910)


  Background: This paper provides a systematic review of the application of
Artificial Intelligence (AI) in the form of Machine Learning (ML) and Deep
Learning (DL) techniques in fighting against the effects of novel coronavirus
disease (COVID-19). Objective & Methods: The objective is to perform a scoping
review on AI for COVID-19 using preferred reporting items of systematic reviews
and meta-analysis (PRISMA) guidelines. A literature search was performed for
relevant studies published from 1 January 2020 till 27 March 2021. Out of 4050
research papers available in reputed publishers, a full-text review of 440
articles was done based on the keywords of AI, COVID-19, ML, forecasting, DL,
X-ray, and Computed Tomography (CT). Finally, 52 articles were included in the
result synthesis of this paper. As part of the review, different ML regression
methods were reviewed first in predicting the number of confirmed and death
cases. Secondly, a comprehensive survey was carried out on the use of ML in
classifying COVID-19 patients. Thirdly, different datasets on medical imaging
were compared in terms of the number of images, number of positive samples and
number of classes in the datasets. The different stages of the diagnosis,
including preprocessing, segmentation and feature extraction were also
reviewed. Fourthly, the performance results of different research papers were
compared to evaluate the effectiveness of DL methods on different datasets.
Results: Results show that residual neural network (ResNet-18) and densely
connected convolutional network (DenseNet 169) exhibit excellent classification
accuracy for X-ray images, while DenseNet-201 has the maximum accuracy in
classifying CT scan images. This indicates that ML and DL are useful tools in
assisting researchers and medical professionals in predicting, screening and
detecting COVID-19.

    

### [[2110.14944] Dispensed Transformer Network for Unsupervised Domain Adaptation](http://arxiv.org/abs/2110.14944)


  Accurate segmentation is a crucial step in medical image analysis and
applying supervised machine learning to segment the organs or lesions has been
substantiated effective. However, it is costly to perform data annotation that
provides ground truth labels for training the supervised algorithms, and the
high variance of data that comes from different domains tends to severely
degrade system performance over cross-site or cross-modality datasets. To
mitigate this problem, a novel unsupervised domain adaptation (UDA) method
named dispensed Transformer network (DTNet) is introduced in this paper. Our
novel DTNet contains three modules. First, a dispensed residual transformer
block is designed, which realizes global attention by dispensed interleaving
operation and deals with the excessive computational cost and GPU memory usage
of the Transformer. Second, a multi-scale consistency regularization is
proposed to alleviate the loss of details in the low-resolution output for
better feature alignment. Finally, a feature ranking discriminator is
introduced to automatically assign different weights to domain-gap features to
lessen the feature distribution distance, reducing the performance shift of two
domains. The proposed method is evaluated on large fluorescein angiography (FA)
retinal nonperfusion (RNP) cross-site dataset with 676 images and a wide used
cross-modality dataset from the MM-WHS challenge. Extensive results demonstrate
that our proposed network achieves the best performance in comparison with
several state-of-the-art techniques.

    

### [[2110.14957] End-to-End Speech Emotion Recognition: Challenges of Real-Life Emergency Call Centers Data Recordings](http://arxiv.org/abs/2110.14957)


  Recognizing a speaker's emotion from their speech can be a key element in
emergency call centers. End-to-end deep learning systems for speech emotion
recognition now achieve equivalent or even better results than conventional
machine learning approaches. In this paper, in order to validate the
performance of our neural network architecture for emotion recognition from
speech, we first trained and tested it on the widely used corpus accessible by
the community, IEMOCAP. We then used the same architecture as the real life
corpus, CEMO, composed of 440 dialogs (2h16m) from 485 speakers. The most
frequent emotions expressed by callers in these real life emergency dialogues
are fear, anger and positive emotions such as relief. In the IEMOCAP general
topic conversations, the most frequent emotions are sadness, anger and
happiness. Using the same end-to-end deep learning architecture, an Unweighted
Accuracy Recall (UA) of 63% is obtained on IEMOCAP and a UA of 45.6% on CEMO,
each with 4 classes. Using only 2 classes (Anger, Neutral), the results for
CEMO are 76.9% UA compared to 81.1% UA for IEMOCAP. We expect that these
encouraging results with CEMO can be improved by combining the audio channel
with the linguistic channel. Real-life emotions are clearly more complex than
acted ones, mainly due to the large diversity of emotional expressions of
speakers. Index Terms-emotion detection, end-to-end deep learning architecture,
call center, real-life database, complex emotions.

    

### [[2110.14998] An Adaptable Approach to Learn Realistic Legged Locomotion without Examples](http://arxiv.org/abs/2110.14998)


  Learning controllers that reproduce legged locomotion in nature have been a
long-time goal in robotics and computer graphics. While yielding promising
results, recent approaches are not yet flexible enough to be applicable to
legged systems of different morphologies. This is partly because they often
rely on precise motion capture references or elaborate learning environments
that ensure the naturality of the emergent locomotion gaits but prevent
generalization. This work proposes a generic approach for ensuring realism in
locomotion by guiding the learning process with the spring-loaded inverted
pendulum model as a reference. Leveraging on the exploration capacities of
Reinforcement Learning (RL), we learn a control policy that fills in the
information gap between the template model and full-body dynamics required to
maintain stable and periodic locomotion. The proposed approach can be applied
to robots of different sizes and morphologies and adapted to any RL technique
and control architecture. We present experimental results showing that even in
a model-free setup and with a simple reactive control architecture, the learned
policies can generate realistic and energy-efficient locomotion gaits for a
bipedal and a quadrupedal robot. And most importantly, this is achieved without
using motion capture, strong constraints in the dynamics or kinematics of the
robot, nor prescribing limb coordination. We provide supplemental videos for
qualitative analysis of the naturality of the learned gaits.

    

### [[2110.15016] Sliding Sequential CVAE with Time Variant Socially-aware Rethinking for Trajectory Prediction](http://arxiv.org/abs/2110.15016)


  Pedestrian trajectory prediction is a key technology in many applications
such as video surveillance, social robot navigation, and autonomous driving,
and significant progress has been made in this research topic. However, there
remain two limitations of previous studies. First, with the continuation of
time, the prediction error at each time step increases significantly, causing
the final displacement error to be impossible to ignore. Second, the prediction
results of multiple pedestrians might be impractical in the prediction horizon,
i.e., the predicted trajectories might collide with each other. To overcome
these limitations, this work proposes a novel trajectory prediction method
called CSR, which consists of a cascaded conditional variational autoencoder
(CVAE) module and a socially-aware regression module. The cascaded CVAE module
first estimates the future trajectories in a sequential pattern. Specifically,
each CVAE concatenates the past trajectories and the predicted points so far as
the input and predicts the location at the following time step. Then, the
socially-aware regression module generates offsets from the estimated future
trajectories to produce the socially compliant final predictions, which are
more reasonable and accurate results than the estimated trajectories. Moreover,
considering the large model parameters of the cascaded CVAE module, a slide
CVAE module is further exploited to improve the model efficiency using one
shared CVAE, in a slidable manner. Experiments results demonstrate that the
proposed method exhibits improvements over state-of-the-art method on the
Stanford Drone Dataset (SDD) and ETH/UCY of approximately 38.0% and 22.2%,
respectively.

    

### [[2110.15058] cgSpan: Pattern Mining in Conceptual Graphs](http://arxiv.org/abs/2110.15058)


  Conceptual Graphs (CGs) are a graph-based knowledge representation formalism.
In this paper we propose cgSpan a CG frequent pattern mining algorithm. It
extends the DMGM-GSM algorithm that takes taxonomy-based labeled graphs as
input; it includes three more kinds of knowledge of the CG formalism: (a) the
fixed arity of relation nodes, handling graphs of neighborhoods centered on
relations rather than graphs of nodes, (b) the signatures, avoiding patterns
with concept types more general than the maximal types specified in signatures
and (c) the inference rules, applying them during the pattern mining process.
The experimental study highlights that cgSpan is a functional CG Frequent
Pattern Mining algorithm and that including CGs specificities results in a
faster algorithm with more expressive results and less redundancy with
vocabulary.

    

### [[2110.15089] D2RLIR : an improved and diversified ranking function in interactive recommendation systems based on deep reinforcement learning](http://arxiv.org/abs/2110.15089)


  Recently, interactive recommendation systems based on reinforcement learning
have been attended by researchers due to the consider recommendation procedure
as a dynamic process and update the recommendation model based on immediate
user feedback, which is neglected in traditional methods. The existing works
have two significant drawbacks. Firstly, inefficient ranking function to
produce the Top-N recommendation list. Secondly, focusing on recommendation
accuracy and inattention to other evaluation metrics such as diversity. This
paper proposes a deep reinforcement learning based recommendation system by
utilizing Actor-Critic architecture to model dynamic users' interaction with
the recommender agent and maximize the expected long-term reward. Furthermore,
we propose utilizing Spotify's ANNoy algorithm to find the most similar items
to generated action by actor-network. After that, the Total Diversity Effect
Ranking algorithm is used to generate the recommendations concerning relevancy
and diversity. Moreover, we apply positional encoding to compute
representations of the user's interaction sequence without using
sequence-aligned recurrent neural networks. Extensive experiments on the
MovieLens dataset demonstrate that our proposed model is able to generate a
diverse while relevance recommendation list based on the user's preferences.

    

### [[2110.15214] Conditional Inference and Activation of Knowledge Entities in ACT-R](http://arxiv.org/abs/2110.15214)


  Activation-based conditional inference applies conditional reasoning to
ACT-R, a cognitive architecture developed to formalize human reasoning. The
idea of activation-based conditional inference is to determine a reasonable
subset of a conditional belief base in order to draw inductive inferences in
time. Central to activation-based conditional inference is the activation
function which assigns to the conditionals in the belief base a degree of
activation mainly based on the conditional's relevance for the current query
and its usage history. Therewith, our approach integrates several aspects of
human reasoning into expert systems such as focusing, forgetting, and
remembering.

    

### [[2110.15220] An Add-On for Empowering Google Forms to be an Automatic Question Generator in Online Assessments](http://arxiv.org/abs/2110.15220)


  This research suggests an add-on to empower Google Forms to be an automatic
machine for generating multiple-choice questions (MCQs) used in online
assessments. In this paper, we elaborate an add-on design mainly comprising
question-formulating software and data storage. The algorithm as an
intellectual mechanism of this software can produce MCQs at an analytical
level. In an experiment, we found the MCQs could assess levels of students'
knowledge comparably with those generated by human experts. This add-on can be
applied generally to formulate MCQs for any rational concepts. With no effort
from an instructor at runtime, the add-on can transform a few data instances
describing rational concepts to be variety sets of MCQs.

    

### [[2102.08689] Symmetry Breaking for k-Robust Multi-Agent Path Finding](http://arxiv.org/abs/2102.08689)


  During Multi-Agent Path Finding (MAPF) problems, agents can be delayed by
unexpected events. To address such situations recent work describes k-Robust
Conflict-BasedSearch (k-CBS): an algorithm that produces coordinated and
collision-free plan that is robust for up to k delays. In this work we
introducing a variety of pairwise symmetry breaking constraints, specific to
k-robust planning, that can efficiently find compatible and optimal paths for
pairs of conflicting agents. We give a thorough description of the new
constraints and report large improvements to success rate ina range of domains
including: (i) classic MAPF benchmarks;(ii) automated warehouse domains and;
(iii) on maps from the 2019 Flatland Challenge, a recently introduced railway
domain where k-robust planning can be fruitfully applied to schedule trains.

    

### [[2105.00381] AGMB-Transformer: Anatomy-Guided Multi-Branch Transformer Network for Automated Evaluation of Root Canal Therapy](http://arxiv.org/abs/2105.00381)


  Accurate evaluation of the treatment result on X-ray images is a significant
and challenging step in root canal therapy since the incorrect interpretation
of the therapy results will hamper timely follow-up which is crucial to the
patients' treatment outcome. Nowadays, the evaluation is performed in a manual
manner, which is time-consuming, subjective, and error-prone. In this paper, we
aim to automate this process by leveraging the advances in computer vision and
artificial intelligence, to provide an objective and accurate method for root
canal therapy result assessment. A novel anatomy-guided multi-branch
Transformer (AGMB-Transformer) network is proposed, which first extracts a set
of anatomy features and then uses them to guide a multi-branch Transformer
network for evaluation. Specifically, we design a polynomial curve fitting
segmentation strategy with the help of landmark detection to extract the
anatomy features. Moreover, a branch fusion module and a multi-branch structure
including our progressive Transformer and Group Multi-Head Self-Attention
(GMHSA) are designed to focus on both global and local features for an accurate
diagnosis. To facilitate the research, we have collected a large-scale root
canal therapy evaluation dataset with 245 root canal therapy X-ray images, and
the experiment results show that our AGMB-Transformer can improve the diagnosis
accuracy from 57.96% to 90.20% compared with the baseline network. The proposed
AGMB-Transformer can achieve a highly accurate evaluation of root canal
therapy. To our best knowledge, our work is the first to perform automatic root
canal therapy evaluation and has important clinical value to reduce the
workload of endodontists.

    

### [[2105.06496] Deepfake Detection by Human Crowds, Machines, and Machine-informed Crowds](http://arxiv.org/abs/2105.06496)


  The recent emergence of machine-manipulated media raises an important
societal question: how can we know if a video that we watch is real or fake? In
two online studies with 15,016 participants, we present authentic videos and
deepfakes and ask participants to identify which is which. We compare the
performance of ordinary human observers against the leading computer vision
deepfake detection model and find them similarly accurate while making
different kinds of mistakes. Together, participants with access to the model's
prediction are more accurate than either alone, but inaccurate model
predictions often decrease participants' accuracy. To probe the relative
strengths and weaknesses of humans and machines as detectors of deepfakes, we
examine human and machine performance across video-level features, and we
evaluate the impact of pre-registered randomized interventions on deepfake
detection. We find that manipulations designed to disrupt visual processing of
faces hinder human participants' performance while mostly not affecting the
model's performance, suggesting a role for specialized cognitive capacities in
explaining human deepfake detection performance.

    

### [[2105.14944] The effectiveness of feature attribution methods and its correlation with automatic evaluation scores](http://arxiv.org/abs/2105.14944)


  Explaining the decisions of an Artificial Intelligence (AI) model is
increasingly critical in many real-world, high-stake applications. Hundreds of
papers have either proposed new feature attribution methods, discussed or
harnessed these tools in their work. However, despite humans being the target
end-users, most attribution methods were only evaluated on proxy
automatic-evaluation metrics (Zhang et al. 2018; Zhou et al. 2016; Petsiuk et
al. 2018). In this paper, we conduct the first user study to measure
attribution map effectiveness in assisting humans in ImageNet classification
and Stanford Dogs fine-grained classification, and when an image is natural or
adversarial (i.e., contains adversarial perturbations). Overall, feature
attribution is surprisingly not more effective than showing humans nearest
training-set examples. On a harder task of fine-grained dog categorization,
presenting attribution maps to humans does not help, but instead hurts the
performance of human-AI teams compared to AI alone. Importantly, we found
automatic attribution-map evaluation measures to correlate poorly with the
actual human-AI team performance. Our findings encourage the community to
rigorously test their methods on the downstream human-in-the-loop applications
and to rethink the existing evaluation metrics.

    

### [[2106.07822] Canonical Face Embeddings](http://arxiv.org/abs/2106.07822)


  We present evidence that many common convolutional neural networks (CNNs)
trained for face verification learn functions that are nearly equivalent under
rotation. More specifically, we demonstrate that one face verification model's
embeddings (i.e. last-layer activations) can be compared directly to another
model's embeddings after only a rotation or linear transformation, with little
performance penalty. This finding is demonstrated using IJB-C 1:1 verification
across the combinations of ten modern off-the-shelf CNN-based face verification
models which vary in training dataset, CNN architecture, method of angular loss
calculation, or some combination of the 3. These networks achieve a mean true
accept rate of 0.96 at a false accept rate of 0.01. When instead evaluating
embeddings generated from two CNNs, where one CNN's embeddings are mapped with
a linear transformation, the mean true accept rate drops to 0.95 using the same
verification paradigm. Restricting these linear maps to only perform rotation
produces a mean true accept rate of 0.91. These mappings' existence suggests
that a common representation is learned by models despite variation in training
or structure. We discuss the broad implications a result like this has,
including an example regarding face template security.

    

### [[2106.12151] Width-based Lookaheads with Learnt Base Policies and Heuristics Over the Atari-2600 Benchmark](http://arxiv.org/abs/2106.12151)


  We propose new width-based planning and learning algorithms inspired from a
careful analysis of the design decisions made by previous width-based planners.
The algorithms are applied over the Atari-2600 games and our best performing
algorithm, Novelty guided Critical Path Learning (N-CPL), outperforms the
previously introduced width-based planning and learning algorithms $\pi$-IW(1),
$\pi$-IW(1)+ and $\pi$-HIW(n, 1). Furthermore, we present a taxonomy of the
Atari-2600 games according to some of their defining characteristics. This
analysis of the games provides further insight into the behaviour and
performance of the algorithms introduced. Namely, for games with large
branching factors, and games with sparse meaningful rewards, N-CPL outperforms
$\pi$-IW, $\pi$-IW(1)+ and $\pi$-HIW(n, 1).

    

### [[2110.15024] Exact Analytical Model of Age of Information in Multi-source Status Update Systems with Per-source Queueing](http://arxiv.org/abs/2110.15024)


  We consider an information update system consisting of $N$ sources sending
status packets at random instances according to a Poisson process to a remote
monitor through a single server. We assume a heteregeneous server with
exponentially distributed service times which is equipped with a waiting room
holding the freshest packet from each source referred to as Single Buffer
Per-Source Queueing (SBPSQ). The sources are assumed to be equally important,
i.e., non-weighted average AoI is used as the information freshness metric, and
subsequently two symmetric scheduling policies are studied in this paper,
namely First Source First Serve (FSFS) and the Earliest Served First Serve
(ESFS) policies, the latter policy being proposed the first time in the current
paper to the best of our knowledge. By employing the theory of Markov Fluid
Queues (MFQ), an analytical model is proposed to obtain the exact distribution
of the Age of Information (AoI) for each source when the FSFS and ESFS policies
are employed at the server. Subsequently, a benchmark scheduling-free scheme
named as Single Buffer with Replacement (SBR) that uses a single one-packet
buffer shared by all sources is also studied with a similar but less complex
analytical model. We comparatively study the performance of the three schemes
through numerical examples and show that the proposed ESFS policy outperforms
the other two schemes in terms of the average AoI and the age violation
probability averaged across all sources, in a scenario of sources possessing
different traffic intensities but sharing a common service time.

    

### [[2110.14824] A GNN Based Approach to LTL Model Checking](http://arxiv.org/abs/2110.14824)


  Model Checking is widely applied in verifying complicated and especially
concurrent systems. Despite of its popularity, model checking suffers from the
state space explosion problem that restricts it from being applied to certain
systems, or specifications. Many works have been proposed in the past to
address the state space explosion problem, and they have achieved some success,
but the inherent complexity still remains an obstacle for purely symbolic
approaches. In this paper, we propose a Graph Neural Network (GNN) based
approach for model checking, where the model is expressed using a B{ü}chi
automaton and the property to be verified is expressed using Linear Temporal
Logic (LTL). We express the model as a GNN, and propose a novel node embedding
framework that encodes the LTL property and characteristics of the model. We
reduce the LTL model checking problem to a graph classification problem, where
there are two classes, 1 (if the model satisfies the specification) and 0 (if
the model does not satisfy the specification). The experimental results show
that our framework is up to 17 times faster than state-of-the-art tools. Our
approach is particularly useful when dealing with very large LTL formulae and
small to moderate sized models.

    

### [[2110.15183] A Theory of RPC Calculi for Client-Server Model](http://arxiv.org/abs/2110.15183)


  With multi-tier programming languages, programmers can specify the locations
of code to run in order to reduce development efforts for the web-based
client-server model where programmers write client and server programs
separately and test the multiple programs together. The RPC calculus, one of
the foundations of those languages by Cooper and Wadler, has the feature of
symmetric communication in programmer's writing arbitrarily deep nested
client-server interactions. However, the existing research only considers
dynamically typed locations. We propose a typed RPC calculus where locations
are tracked in type-level. A new located type system paves the way for a theory
of RPC calculi for the client-server model.
(In the following papers published in SCP2020 and PPDP2021, the typed RPC
calculus will be enhanced with polymorphic locations and a type-based slicing
compilation.)

    