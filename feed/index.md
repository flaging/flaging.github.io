
## 2021-8-12

### [[2108.04533] ASMR: Learning Attribute-Based Person Search with Adaptive Semantic Margin Regularizer](http://arxiv.org/abs/2108.04533)


  Attribute-based person search is the task of finding person images that are
best matched with a set of text attributes given as query. The main challenge
of this task is the large modality gap between attributes and images. To reduce
the gap, we present a new loss for learning cross-modal embeddings in the
context of attribute-based person search. We regard a set of attributes as a
category of people sharing the same traits. In a joint embedding space of the
two modalities, our loss pulls images close to their person categories for
modality alignment. More importantly, it pushes apart a pair of person
categories by a margin determined adaptively by their semantic distance, where
the distance metric is learned end-to-end so that the loss considers importance
of each attribute when relating person categories. Our loss guided by the
adaptive semantic margin leads to more discriminative and semantically
well-arranged distributions of person images. As a consequence, it enables a
simple embedding model to achieve state-of-the-art records on public benchmarks
without bells and whistles.

    

### [[2108.05057] A Channel-Aware Routing Protocol With Nearest Neighbor Regression For Underwater Sensor Networks](http://arxiv.org/abs/2108.05057)


  The underwater acoustic channel is one of the most challenging communication
channels. Due to periodical tidal and daily climatic variation, underwater
noise is periodically fluctuating, which result in the periodical changing of
acoustic channel quality in long-term. Also, time-variant channel quality leads
to routing failure. Routing protocols with acoustic channel estimation, namely
underwater channel-aware routing protocols are recently proposed to maintain
the routing performance. However, channel estimation algorithms for these
routing protocols are mostly linear and rarely consider periodicity of acoustic
channels. In this paper, we introduce acoustic channel estimation based on
nearest neighbor regression for underwater acoustic networks. We extend nearest
neighbor regression for SNR (Signal-to-Noise Ratio) time series prediction,
providing an outstanding prediction accuracy for intricately periodical and
fluctuating received SNR time series. Moreover, we propose a quick search
algorithm and use statistical storage compression to optimize the time and
space complexity of the algorithm. In contrast with linear methods, this
algorithm significantly improves channel prediction accuracy (over three times
at most) on both simulation and sea trial data sets. With this channel
estimation method, we then propose a Depth-Based Channel-Aware Routing protocol
(DBCAR). Taking advantage of depth-greedy forwarding and channel-aware reliable
communication, DBCAR has an outstanding network performance on packet delivery
ratio, average energy consumption and average transmission delay which is
validated through extensive simulations.

    

### [[2108.05065] Technical Report for A Service-Fair UAV-NOMA System for Large-scale IoT scenarios](http://arxiv.org/abs/2108.05065)


  Integrating unmanned aerial vehicles (UAVs) and non-orthogonal multiple
access (NOMA) technology can perform better in $5$G communication systems. To
guarantee the fairness of communication services for the sensor nodes deployed
in large-scale scenarios, we adopt the graph theory and the smallest enclosing
algorithm to design a user scheduling strategy to select the communication
sensor nodes before communication processes.

    

### [[2108.05248] Public Key Reinforced Blockchain Platform for Fog-IoT Network System Administration](http://arxiv.org/abs/2108.05248)


  The number of embedded devices that connect to a wireless network has been
growing for the past decade. This interaction creates a network of Internet of
Things (IoT) devices where data travel continuously. With the increase of
devices and the need for the network to extend via fog computing, we have
fog-based IoT networks. However, with more endpoints introduced to it, the
network becomes open to malicious attackers. This work attempts to protect
fog-based IoT networks by creating a platform that secures the endpoints
through public-key encryption. The servers are allowed to mask the data packets
shared within the network. To be able to track all of the encryption processes,
we incorporated the use of permissioned blockchains. This technology completes
the security layer by providing an immutable and automated data structure to
function as a hyper ledger for the network. Each data transaction incorporates
a handshake mechanism with the use of a public key pair. This design guarantees
that only devices that have proper access through the keys can use the network.
Hence, management is made convenient and secure. The implementation of this
platform is through a wireless server-client architecture to simulate the data
transactions between devices. The conducted qualitative tests provide an
in-depth feasibility investigation on the network's levels of security. The
results show the validity of the design as a means of fortifying the network
against endpoint attacks.

    

### [[2102.07433] Measuring the Internet during Covid-19 to Evaluate Work-from-Home](http://arxiv.org/abs/2102.07433)


  The Covid-19 pandemic has radically changed our lives. Under different
circumstances, people react to it in various ways. One way is to work-from-home
since lockdown has been announced in many regions around the world. For some
places, however, we don't know if people really work from home due to the lack
of information. Since there are lots of uncertainties, it would be helpful for
us to understand what really happen in these places if we can detect the
reaction to the Covid-19 pandemic. Working from home indicates that people have
changed the way they interact with the Internet. People used to access the
Internet in the company or at school during the day. Now it is more likely that
they access the Internet at home in the daytime. Therefore, the network usage
changes in one place can be used to indicate if people in this place actually
work from home. In this work, we reuse and analyze Trinocular outages data
(around 5.1M responsive /24 blocks) over 6 months to find network usage changes
by a new designed algorithm. We apply the algorithm to sets of /24 blocks in
several cities and compare the detected network usage changes with real world
covid-19 events to verify if the algorithm can capture the changes reacting to
the Covid-19 pandemic. By applying the algorithm to all measurable /24 blocks
to detect network usages changes, we conclude that network usage can be an
indicator of the reaction to the Covid-19 pandemic.

    

### [[2108.04820] MuCoMiD: A Multitask Convolutional Learning Framework for miRNA-Disease Association Prediction](http://arxiv.org/abs/2108.04820)


  Growing evidence from recent studies implies that microRNA or miRNA could
serve as biomarkers in various complex human diseases. Since wet-lab
experiments are expensive and time-consuming, computational techniques for
miRNA-disease association prediction have attracted a lot of attention in
recent years. Data scarcity is one of the major challenges in building reliable
machine learning models. Data scarcity combined with the use of pre-calculated
hand-crafted input features has led to problems of overfitting and data
leakage.
We overcome the limitations of existing works by proposing a novel
multi-tasking convolution-based approach, which we refer to as MuCoMiD. MuCoMiD
allows automatic feature extraction while incorporating knowledge from 4
heterogeneous biological information sources (interactions between
miRNA/diseases and protein-coding genes (PCG), miRNA family information, and
disease ontology) in a multi-task setting which is a novel perspective and has
not been studied before. The use of multi-channel convolutions allows us to
extract expressive representations while keeping the model linear and,
therefore, simple. To effectively test the generalization capability of our
model, we construct large-scale experiments on standard benchmark datasets as
well as our proposed larger independent test sets and case studies. MuCoMiD
shows an improvement of at least 5% in 5-fold CV evaluation on HMDDv2.0 and
HMDDv3.0 datasets and at least 49% on larger independent test sets with unseen
miRNA and diseases over state-of-the-art approaches. We share our code for
reproducibility and future research at
this https URL.

    

### [[2108.04822] Self-supervised Consensus Representation Learning for Attributed Graph](http://arxiv.org/abs/2108.04822)


  Attempting to fully exploit the rich information of topological structure and
node features for attributed graph, we introduce self-supervised learning
mechanism to graph representation learning and propose a novel Self-supervised
Consensus Representation Learning (SCRL) framework. In contrast to most
existing works that only explore one graph, our proposed SCRL method treats
graph from two perspectives: topology graph and feature graph. We argue that
their embeddings should share some common information, which could serve as a
supervisory signal. Specifically, we construct the feature graph of node
features via k-nearest neighbor algorithm. Then graph convolutional network
(GCN) encoders extract features from two graphs respectively. Self-supervised
loss is designed to maximize the agreement of the embeddings of the same node
in the topology graph and the feature graph. Extensive experiments on real
citation networks and social networks demonstrate the superiority of our
proposed SCRL over the state-of-the-art methods on semi-supervised node
classification task. Meanwhile, compared with its main competitors, SCRL is
rather efficient.

    

### [[2108.04840] Post-hoc Interpretability for Neural NLP: A Survey](http://arxiv.org/abs/2108.04840)


  Natural Language Processing (NLP) models have become increasingly more
complex and widespread. With recent developments in neural networks, a growing
concern is whether it is responsible to use these models. Concerns such as
safety and ethics can be partially addressed by providing explanations.
Furthermore, when models do fail, providing explanations is paramount for
accountability purposes. To this end, interpretability serves to provide these
explanations in terms that are understandable to humans. Central to what is
understandable is how explanations are communicated. Therefore, this survey
provides a categorization of how recent interpretability methods communicate
explanations and discusses the methods in depth. Furthermore, the survey
focuses on post-hoc methods, which provide explanations after a model is
learned and generally model-agnostic. A common concern for this class of
methods is whether they accurately reflect the model. Hence, how these post-hoc
methods are evaluated is discussed throughout the paper.

    

### [[2108.04842] Optimal learning of quantum Hamiltonians from high-temperature Gibbs states](http://arxiv.org/abs/2108.04842)


  We study the problem of learning a Hamiltonian $H$ to precision
$\varepsilon$, supposing we are given copies of its Gibbs state
$\rho=\exp(-\beta H)/\operatorname{Tr}(\exp(-\beta H))$ at a known inverse
temperature $\beta$. Anshu, Arunachalam, Kuwahara, and Soleimanifar (Nature
Physics, 2021) recently studied the sample complexity (number of copies of
$\rho$ needed) of this problem for geometrically local $N$-qubit Hamiltonians.
In the high-temperature (low $\beta$) regime, their algorithm has sample
complexity poly$(N, 1/\beta,1/\varepsilon)$ and can be implemented with
polynomial, but suboptimal, time complexity.
In this paper, we study the same question for a more general class of
Hamiltonians. We show how to learn the coefficients of a Hamiltonian to error
$\varepsilon$ with sample complexity $S = O(\log N/(\beta\varepsilon)^{2})$ and
time complexity linear in the sample size, $O(S N)$. Furthermore, we prove a
matching lower bound showing that our algorithm's sample complexity is optimal,
and hence our time complexity is also optimal.
In the appendix, we show that virtually the same algorithm can be used to
learn $H$ from a real-time evolution unitary $e^{-it H}$ in a small $t$ regime
with similar sample and time complexity.

    

### [[2108.04855] Attention-like feature explanation for tabular data](http://arxiv.org/abs/2108.04855)


  A new method for local and global explanation of the machine learning
black-box model predictions by tabular data is proposed. It is implemented as a
system called AFEX (Attention-like Feature EXplanation) and consisting of two
main parts. The first part is a set of the one-feature neural subnetworks which
aim to get a specific representation for every feature in the form of a basis
of shape functions. The subnetworks use shortcut connections with trainable
parameters to improve the network performance. The second part of AFEX produces
shape functions of features as the weighted sum of the basis shape functions
where weights are computed by using an attention-like mechanism. AFEX
identifies pairwise interactions between features based on pairwise
multiplications of shape functions corresponding to different features. A
modification of AFEX with incorporating an additional surrogate model which
approximates the black-box model is proposed. AFEX is trained end-to-end on a
whole dataset only once such that it does not require to train neural networks
again in the explanation stage. Numerical experiments with synthetic and real
data illustrate AFEX.

    

### [[2108.04867] AuraSense: Robot Collision Avoidance by Full Surface Proximity Detection](http://arxiv.org/abs/2108.04867)


  Perceiving obstacles and avoiding collisions is fundamental to the safe
operation of a robot system, particularly when the robot must operate in highly
dynamic human environments. Proximity detection using on-robot sensors can be
used to avoid or mitigate impending collisions. However, existing proximity
sensing methods are orientation and placement dependent, resulting in blind
spots even with large numbers of sensors. In this paper, we introduce the
phenomenon of the Leaky Surface Wave (LSW), a novel sensing modality, and
present AuraSense, a proximity detection system using the LSW. AuraSense is the
first system to realize no-dead-spot proximity sensing for robot arms. It
requires only a single pair of piezoelectric transducers, and can easily be
applied to off-the-shelf robots with minimal modifications. We further
introduce a set of signal processing techniques and a lightweight neural
network to address the unique challenges in using the LSW for proximity
sensing. Finally, we demonstrate a prototype system consisting of a single
piezoelectric element pair on a robot manipulator, which validates our design.
We conducted several micro benchmark experiments and performed more than 2000
on-robot proximity detection trials with various potential robot arm materials,
colliding objects, approach patterns, and robot movement patterns. AuraSense
achieves 100% and 95.3% true positive proximity detection rates when the arm
approaches static and mobile obstacles respectively, with a true negative rate
over 99%, showing the real-world viability of this system.

    

### [[2108.04869] MetaPose: Fast 3D Pose from Multiple Views without 3D Supervision](http://arxiv.org/abs/2108.04869)


  Recently, huge strides were made in monocular and multi-view pose estimation
with known camera parameters, whereas pose estimation from multiple cameras
with unknown positions and orientations received much less attention. In this
paper, we show how to train a neural model that can perform accurate 3D pose
and camera estimation, takes into account joint location uncertainty due
occlusion from multiple views, and requires only 2D keypoint data for training.
Our method outperforms both classical bundle adjustment and weakly-supervised
monocular 3D baselines on the well-established Human3.6M dataset, as well as
the more challenging in-the-wild Ski-Pose PTZ dataset with moving cameras. We
provide an extensive ablation study separating the error due to the camera
model, number of cameras, initialization, and image-space joint localization
from the additional error introduced by our model.

    

### [[2108.04879] Excited state, non-adiabatic dynamics of large photoswitchable molecules using a chemically transferable machine learning potential](http://arxiv.org/abs/2108.04879)


  Light-induced chemical processes are ubiquitous in nature and have widespread
technological applications. For example, the photoisomerization of azobenzene
allows a drug with an azo scaffold to be activated with light. In principle,
photoswitches with useful reactive properties, such as high isomerization
yields, can be identified through virtual screening with reactive simulations.
In practice these simulations are rarely used for screening, since they require
hundreds of trajectories and expensive quantum chemical methods to account for
non-adiabatic excited state effects. Here we introduce a neural network
potential to accelerate such simulations for azobenzene derivatives. The model,
which is based on diabatic states, is called the \textit{diabatic artificial
neural network} (DANN). The network is six orders of magnitude faster than the
quantum chemistry method used for training. DANN is transferable to molecules
outside the training set, predicting quantum yields for unseen species that are
correlated with experiment. We use the model to virtually screen 3,100
hypothetical molecules, and identify several species with extremely high
quantum yields. Our results pave the way for fast and accurate virtual
screening of photoactive compounds.

    

### [[2108.04883] A data-driven peridynamic continuum model for upscaling molecular dynamics](http://arxiv.org/abs/2108.04883)


  Nonlocal models, including peridynamics, often use integral operators that
embed lengthscales in their definition. However, the integrands in these
operators are difficult to define from the data that are typically available
for a given physical system, such as laboratory mechanical property tests. In
contrast, molecular dynamics (MD) does not require these integrands, but it
suffers from computational limitations in the length and time scales it can
address. To combine the strengths of both methods and to obtain a
coarse-grained, homogenized continuum model that efficiently and accurately
captures materials' behavior, we propose a learning framework to extract, from
MD data, an optimal Linear Peridynamic Solid (LPS) model as a surrogate for MD
displacements. To maximize the accuracy of the learnt model we allow the
peridynamic influence function to be partially negative, while preserving the
well-posedness of the resulting model. To achieve this, we provide sufficient
well-posedness conditions for discretized LPS models with sign-changing
influence functions and develop a constrained optimization algorithm that
minimizes the equation residual while enforcing such solvability conditions.
This framework guarantees that the resulting model is mathematically
well-posed, physically consistent, and that it generalizes well to settings
that are different from the ones used during training. We illustrate the
efficacy of the proposed approach with several numerical tests for single layer
graphene. Our two-dimensional tests show the robustness of the proposed
algorithm on validation data sets that include thermal noise, different domain
shapes and external loadings, and discretizations substantially different from
the ones used for training.

    

### [[2108.04884] Retiring Adult: New Datasets for Fair Machine Learning](http://arxiv.org/abs/2108.04884)


  Although the fairness community has recognized the importance of data,
researchers in the area primarily rely on UCI Adult when it comes to tabular
data. Derived from a 1994 US Census survey, this dataset has appeared in
hundreds of research papers where it served as the basis for the development
and comparison of many algorithmic fairness interventions. We reconstruct a
superset of the UCI Adult data from available US Census sources and reveal
idiosyncrasies of the UCI Adult dataset that limit its external validity. Our
primary contribution is a suite of new datasets derived from US Census surveys
that extend the existing data ecosystem for research on fair machine learning.
We create prediction tasks relating to income, employment, health,
transportation, and housing. The data span multiple years and all states of the
United States, allowing researchers to study temporal shift and geographic
variation. We highlight a broad initial sweep of new empirical insights
relating to trade-offs between fairness criteria, performance of algorithmic
interventions, and the role of distribution shift based on our new datasets.
Our findings inform ongoing debates, challenge some existing narratives, and
point to future research directions. Our datasets are available at
this https URL.

    

### [[2108.04893] How Self-Supervised Learning Can be Used for Fine-Grained Head Pose Estimation?](http://arxiv.org/abs/2108.04893)


  Recent progress of Self-Supervised Learning (SSL) demonstrates the capability
of these methods in computer vision field. However, this progress could not
show any promises for fine-grained tasks such as Head Pose estimation. In this
article, we have tried to answer a question: How SSL can be used for Head Pose
estimation? In general, there are two main approaches to use SSL: 1. Using
pre-trained weights which can be done via weights pre-training on ImageNet or
via SSL tasks. 2. Leveraging SSL as an auxiliary co-training task besides of
Supervised Learning (SL) tasks at the same time. In this study, modified
versions of jigsaw puzzling and rotation as SSL pre-text tasks are used and the
best architecture for our proposed Hybrid Multi-Task Learning (HMTL) is found.
Finally, the HopeNet method as a baseline is selected and the impact of SSL
pre-training and ImageNet pre-training on both HMTL and SL are compared. The
error rate reduced by the HTML method up to 11% compare to the SL. Moreover,
HMTL method showed that it was good with all kinds of initial weights: random,
ImageNet and SSL pre-training weights. Also, it was observed, when puzzled
images are used for SL alone, the average error rate placed between SL and HMTL
which showed the importance of local spatial features compare to global spatial
features.

    

### [[2108.04899] Analysis of ODE2VAE with Examples](http://arxiv.org/abs/2108.04899)


  Deep generative models aim to learn underlying distributions that generate
the observed data. Given the fact that the generative distribution may be
complex and intractable, deep latent variable models use probabilistic
frameworks to learn more expressive joint probability distributions over the
data and their low-dimensional hidden variables. Learning complex probability
distributions over sequential data without any supervision is a difficult task
for deep generative models. Ordinary Differential Equation Variational
Auto-Encoder (ODE2VAE) is a deep latent variable model that aims to learn
complex distributions over high-dimensional sequential data and their
low-dimensional representations. ODE2VAE infers continuous latent dynamics of
the high-dimensional input in a low-dimensional hierarchical latent space. The
hierarchical organization of the continuous latent space embeds a
physics-guided inductive bias in the model. In this paper, we analyze the
latent representations inferred by the ODE2VAE model over three different
physical motion datasets: bouncing balls, projectile motion, and simple
pendulum. Through our experiments, we explore the effects of the physics-guided
inductive bias of the ODE2VAE model over the learned dynamical latent
representations. We show that the model is able to learn meaningful latent
representations to an extent without any supervision.

    

### [[2108.04907] Flow-based SVDD for anomaly detection](http://arxiv.org/abs/2108.04907)


  We propose FlowSVDD -- a flow-based one-class classifier for anomaly/outliers
detection that realizes a well-known SVDD principle using deep learning tools.
Contrary to other approaches to deep SVDD, the proposed model is instantiated
using flow-based models, which naturally prevents from collapsing of bounding
hypersphere into a single point. Experiments show that FlowSVDD achieves
comparable results to the current state-of-the-art methods and significantly
outperforms related deep SVDD methods on benchmark datasets.

    

### [[2108.04927] Embodied BERT: A Transformer Model for Embodied, Language-guided Visual Task Completion](http://arxiv.org/abs/2108.04927)


  Language-guided robots performing home and office tasks must navigate in and
interact with the world. Grounding language instructions against visual
observations and actions to take in an environment is an open challenge. We
present Embodied BERT (EmBERT), a transformer-based model which can attend to
high-dimensional, multi-modal inputs across long temporal horizons for
language-conditioned task completion. Additionally, we bridge the gap between
successful object-centric navigation models used for non-interactive agents and
the language-guided visual task completion benchmark, ALFRED, by introducing
object navigation targets for EmBERT training. We achieve competitive
performance on the ALFRED benchmark, and EmBERT marks the first
transformer-based model to successfully handle the long-horizon, dense,
multi-modal histories of ALFRED, and the first ALFRED model to utilize
object-centric navigation targets.

    

### [[2108.04939] On the Distinction Between "Conditional Average Treatment Effects" (CATE) and "Individual Treatment Effects" (ITE) Under Ignorability Assumptions](http://arxiv.org/abs/2108.04939)


  Recent years have seen a swell in methods that focus on estimating
"individual treatment effects". These methods are often focused on the
estimation of heterogeneous treatment effects under ignorability assumptions.
This paper hopes to draw attention to the fact that there is nothing
necessarily "individual" about such effects under ignorability assumptions and
isolating individual effects may require additional assumptions. Such
individual effects, more often than not, are more precisely described as
"conditional average treatment effects" and confusion between the two has the
potential to hinder advances in personalized and individualized effect
estimation.

    

### [[2108.04941] Arbitrage-Free Implied Volatility Surface Generation with Variational Autoencoders](http://arxiv.org/abs/2108.04941)


  We propose a hybrid method for generating arbitrage-free implied volatility
(IV) surfaces consistent with historical data by combining model-free
Variational Autoencoders (VAEs) with continuous time stochastic differential
equation (SDE) driven models. We focus on two classes of SDE models: regime
switching models and Lévy additive processes. By projecting historical
surfaces onto the space of SDE model parameters, we obtain a distribution on
the parameter subspace faithful to the data on which we then train a VAE.
Arbitrage-free IV surfaces are then generated by sampling from the posterior
distribution on the latent space, decoding to obtain SDE model parameters, and
finally mapping those parameters to IV surfaces.

    

### [[2108.04947] Causal Order Identification to Address Confounding: Binary Variables](http://arxiv.org/abs/2108.04947)


  This paper considers an extension of the linear non-Gaussian acyclic model
(LiNGAM) that determines the causal order among variables from a dataset when
the variables are expressed by a set of linear equations, including noise. In
particular, we assume that the variables are binary. The existing LiNGAM
assumes that no confounding is present, which is restrictive in practice. Based
on the concept of independent component analysis (ICA), this paper proposes an
extended framework in which the mutual information among the noises is
minimized. Another significant contribution is to reduce the realization of the
shortest path problem. The distance between each pair of nodes expresses an
associated mutual information value, and the path with the minimum sum (KL
divergence) is sought. Although $p!$ mutual information values should be
compared, this paper dramatically reduces the computation when no confounding
is present. The proposed algorithm finds the globally optimal solution, while
the existing locally greedily seek the order based on hypothesis testing. We
use the best estimator in the sense of Bayes/MDL that correctly detects
independence for mutual information estimation. Experiments using artificial
and actual data show that the proposed version of LiNGAM achieves significantly
better performance, particularly when confounding is present.

    

### [[2108.04949] A Study of Social and Behavioral Determinants of Health in Lung Cancer Patients Using Transformers-based Natural Language Processing Models](http://arxiv.org/abs/2108.04949)


  Social and behavioral determinants of health (SBDoH) have important roles in
shaping people's health. In clinical research studies, especially comparative
effectiveness studies, failure to adjust for SBDoH factors will potentially
cause confounding issues and misclassification errors in either statistical
analyses and machine learning-based models. However, there are limited studies
to examine SBDoH factors in clinical outcomes due to the lack of structured
SBDoH information in current electronic health record (EHR) systems, while much
of the SBDoH information is documented in clinical narratives. Natural language
processing (NLP) is thus the key technology to extract such information from
unstructured clinical text. However, there is not a mature clinical NLP system
focusing on SBDoH. In this study, we examined two state-of-the-art
transformer-based NLP models, including BERT and RoBERTa, to extract SBDoH
concepts from clinical narratives, applied the best performing model to extract
SBDoH concepts on a lung cancer screening patient cohort, and examined the
difference of SBDoH information between NLP extracted results and structured
EHRs (SBDoH information captured in standard vocabularies such as the
International Classification of Diseases codes). The experimental results show
that the BERT-based NLP model achieved the best strict/lenient F1-score of
0.8791 and 0.8999, respectively. The comparison between NLP extracted SBDoH
information and structured EHRs in the lung cancer patient cohort of 864
patients with 161,933 various types of clinical notes showed that much more
detailed information about smoking, education, and employment were only
captured in clinical narratives and that it is necessary to use both clinical
narratives and structured EHRs to construct a more complete picture of
patients' SBDoH factors.

    

### [[2108.04951] A Brief Review of Machine Learning Techniques for Protein Phosphorylation Sites Prediction](http://arxiv.org/abs/2108.04951)


  Reversible Post-Translational Modifications (PTMs) have vital roles in
extending the functional diversity of proteins and effect meaningfully the
regulation of protein functions in prokaryotic and eukaryotic organisms. PTMs
have happened as crucial molecular regulatory mechanisms that are utilized to
regulate diverse cellular processes. Nevertheless, among the most well-studied
PTMs can say mainly types of proteins are containing phosphorylation and
significant roles in many biological processes. Disorder in this modification
can be caused by multiple diseases including neurological disorders and
cancers. Therefore, it is necessary to predict the phosphorylation of target
residues in an uncharacterized amino acid sequence. Most experimental
techniques for predicting phosphorylation are time-consuming, costly, and
error-prone. By the way, computational methods have replaced these techniques.
These days, a vast amount of phosphorylation data is publicly accessible
through many online databases. In this study, at first, all datasets of PTMs
that include phosphorylation sites (p-sites) were comprehensively reviewed.
Furthermore, we showed that there are basically two main approaches for
phosphorylation prediction by machine learning: End-to-End and conventional. We
gave an overview for both of them. Also, we introduced 15 important feature
extraction techniques which mostly have been used for conventional machine
learning methods

    

### [[2108.04957] An Image-based Generator Architecture for Synthetic Image Refinement](http://arxiv.org/abs/2108.04957)


  Proposed are alternative generator architectures for Boundary Equilibrium
Generative Adversarial Networks, motivated by Learning from Simulated and
Unsupervised Images through Adversarial Training. It disentangles the need for
a noise-based latent space. The generator will operate mainly as a refiner
network to gain a photo-realistic presentation of the given synthetic images.
It also attempts to resolve the latent space's poorly understood properties by
eliminating the need for noise injection and replacing it with an image-based
concept. The new flexible and simple generator architecture will also give the
power to control the trade-off between restrictive refinement and
expressiveness ability. Contrary to other available methods, this architecture
will not require a paired or unpaired dataset of real and synthetic images for
the training phase. Only a relatively small set of real images would suffice.

    

### [[2108.04962] Adaptive Multi-Resolution Attention with Linear Complexity](http://arxiv.org/abs/2108.04962)


  Transformers have improved the state-of-the-art across numerous tasks in
sequence modeling. Besides the quadratic computational and memory complexity
w.r.t the sequence length, the self-attention mechanism only processes
information at the same scale, i.e., all attention heads are in the same
resolution, resulting in the limited power of the Transformer. To remedy this,
we propose a novel and efficient structure named Adaptive Multi-Resolution
Attention (AdaMRA for short), which scales linearly to sequence length in terms
of time and space. Specifically, we leverage a multi-resolution multi-head
attention mechanism, enabling attention heads to capture long-range contextual
information in a coarse-to-fine fashion. Moreover, to capture the potential
relations between query representation and clues of different attention
granularities, we leave the decision of which resolution of attention to use to
query, which further improves the model's capacity compared to vanilla
Transformer. In an effort to reduce complexity, we adopt kernel attention
without degrading the performance. Extensive experiments on several benchmarks
demonstrate the effectiveness and efficiency of our model by achieving a
state-of-the-art performance-efficiency-memory trade-off. To facilitate AdaMRA
utilization by the scientific community, the code implementation will be made
publicly available.

    

### [[2108.04964] Linear approximability of two-layer neural networks: A comprehensive analysis based on spectral decay](http://arxiv.org/abs/2108.04964)


  In this paper, we present a spectral-based approach to study the linear
approximation of two-layer neural networks. We first consider the case of
single neuron and show that the linear approximability, quantified by the
Kolmogorov width, is controlled by the eigenvalue decay of an associate kernel.
Then, we show that similar results also hold for two-layer neural networks.
This spectral-based approach allows us to obtain upper bounds, lower bounds,
and explicit hard examples in a united manner. In particular, these bounds
imply that for networks activated by smooth functions, restricting the norms of
inner-layer weights may significantly impair the expressiveness. By contrast,
for non-smooth activation functions, such as ReLU, the network expressiveness
is independent of the inner-layer weight norms. In addition, we prove that for
a family of non-smooth activation functions, including ReLU, approximating any
single neuron with random features suffers from the \emph{curse of
dimensionality}. This provides an explicit separation of expressiveness between
neural networks and random feature models.

    

### [[2108.04972] Creutzfeldt-Jakob Disease Prediction Using Machine Learning Techniques](http://arxiv.org/abs/2108.04972)


  Creutzfeldt-Jakob disease (CJD) is a rapidly progressive and fatal
neurodegenerative disease, that causes approximately 350 deaths in the United
States every year. In specific, it is a prion disease that is caused by a
misfolded prion protein, termed $PrP^{Sc}$, which is the infectious form of the
prion protein $PrP^{C}$. Rather than being recycled by the body, the $PrP^{Sc}$
aggregates in the brain as plaques, leading to neurodegeneration of surrounding
cells and the spongiform characteristics of the pathology. However, there has
been very little research done into factors that can affect one's chances of
acquiring $PrP^{Sc}$. In this paper, Elastic Net Regression, Long Short-Term
Memory Recurrent Neural Network Architectures, and Random Forest have been used
to predict Creutzfeldt-Jakob Disease Levels in the United States. New variables
were created as data for the models to use on the basis of common factors that
are known to affect CJD, such as soil, food, and water quality. Based on the
root mean square error (RMSE), mean bias error (MBE), and mean absolute error
(MAE) values, the study reveals the high impact of unhealthy lifestyle choices,
CO$_{2}$ Levels, Pesticide Usage, and Potash K$_{2}$O Usage on CJD Levels. In
doing so, the study highlights new avenues of research for CJD prevention and
detection, as well as potential causes.

    

### [[2108.04974] SoK: How Robust is Image Classification Deep Neural Network Watermarking? (Extended Version)](http://arxiv.org/abs/2108.04974)


  Deep Neural Network (DNN) watermarking is a method for provenance
verification of DNN models. Watermarking should be robust against watermark
removal attacks that derive a surrogate model that evades provenance
verification. Many watermarking schemes that claim robustness have been
proposed, but their robustness is only validated in isolation against a
relatively small set of attacks. There is no systematic, empirical evaluation
of these claims against a common, comprehensive set of removal attacks. This
uncertainty about a watermarking scheme's robustness causes difficulty to trust
their deployment in practice. In this paper, we evaluate whether recently
proposed watermarking schemes that claim robustness are robust against a large
set of removal attacks. We survey methods from the literature that (i) are
known removal attacks, (ii) derive surrogate models but have not been evaluated
as removal attacks, and (iii) novel removal attacks. Weight shifting and smooth
retraining are novel removal attacks adapted to the DNN watermarking schemes
surveyed in this paper. We propose taxonomies for watermarking schemes and
removal attacks. Our empirical evaluation includes an ablation study over sets
of parameters for each attack and watermarking scheme on the CIFAR-10 and
ImageNet datasets. Surprisingly, none of the surveyed watermarking schemes is
robust in practice. We find that schemes fail to withstand adaptive attacks and
known methods for deriving surrogate models that have not been evaluated as
removal attacks. This points to intrinsic flaws in how robustness is currently
evaluated. We show that watermarking schemes need to be evaluated against a
more extensive set of removal attacks with a more realistic adversary model.
Our source code and a complete dataset of evaluation results are publicly
available, which allows to independently verify our conclusions.

    

### [[2108.04976] Deep Pairwise Learning To Rank For Search Autocomplete](http://arxiv.org/abs/2108.04976)


  Autocomplete (a.k.a "Query Auto-Completion", "AC") suggests full queries
based on a prefix typed by customer. Autocomplete has been a core feature of
commercial search engine. In this paper, we propose a novel context-aware
neural network based pairwise ranker (DeepPLTR) to improve AC ranking, DeepPLTR
leverages contextual and behavioral features to rank queries by minimizing a
pairwise loss, based on a fully-connected neural network structure. Compared to
LambdaMART ranker, DeepPLTR shows +3.90% MeanReciprocalRank (MRR) lift in
offline evaluation, and yielded +0.06% (p < 0.1) Gross Merchandise Value (GMV)
lift in an Amazon's online A/B experiment.

    

### [[2108.04979] Simple black-box universal adversarial attacks on medical image classification based on deep neural networks](http://arxiv.org/abs/2108.04979)


  Universal adversarial attacks, which hinder most deep neural network (DNN)
tasks using only a small single perturbation called a universal adversarial
perturbation (UAP), is a realistic security threat to the practical application
of a DNN. In particular, such attacks cause serious problems in medical
imaging. Given that computer-based systems are generally operated under a
black-box condition in which only queries on inputs are allowed and outputs are
accessible, the impact of UAPs seems to be limited because well-used algorithms
for generating UAPs are limited to a white-box condition in which adversaries
can access the model weights and loss gradients. Nevertheless, we demonstrate
that UAPs are easily generatable using a relatively small dataset under
black-box conditions. In particular, we propose a method for generating UAPs
using a simple hill-climbing search based only on DNN outputs and demonstrate
the validity of the proposed method using representative DNN-based medical
image classifications. Black-box UAPs can be used to conduct both non-targeted
and targeted attacks. Overall, the black-box UAPs showed high attack success
rates (40% to 90%), although some of them had relatively low success rates
because the method only utilizes limited information to generate UAPs. The
vulnerability of black-box UAPs was observed in several model architectures.
The results indicate that adversaries can also generate UAPs through a simple
procedure under the black-box condition to foil or control DNN-based medical
image diagnoses, and that UAPs are a more realistic security threat.

    

### [[2108.04993] LightMove: A Lightweight Next-POI Recommendation for Taxicab Rooftop Advertising](http://arxiv.org/abs/2108.04993)


  Mobile digital billboards are an effective way to augment brand-awareness.
Among various such mobile billboards, taxicab rooftop devices are emerging in
the market as a brand new media. Motov is a leading company in South Korea in
the taxicab rooftop advertising market. In this work, we present a lightweight
yet accurate deep learning-based method to predict taxicabs' next locations to
better prepare for targeted advertising based on demographic information of
locations. Considering the fact that next POI recommendation datasets are
frequently sparse, we design our presented model based on neural ordinary
differential equations (NODEs), which are known to be robust to
sparse/incorrect input, with several enhancements. Our model, which we call
LightMove, has a larger prediction accuracy, a smaller number of parameters,
and/or a smaller training/inference time, when evaluating with various
datasets, in comparison with state-of-the-art models.

    

### [[2108.05024] Learning strange attractors with reservoir systems](http://arxiv.org/abs/2108.05024)


  This paper shows that the celebrated Embedding Theorem of Takens is a
particular case of a much more general statement according to which, randomly
generated linear state-space representations of generic observations of an
invertible dynamical system carry in their wake an embedding of the phase space
dynamics into the chosen Euclidean state space. This embedding coincides with a
natural generalized synchronization that arises in this setup and that yields a
topological conjugacy between the state-space dynamics driven by the generic
observations of the dynamical system and the dynamical system itself. This
result provides additional tools for the representation, learning, and analysis
of chaotic attractors and sheds additional light on the reservoir computing
phenomenon that appears in the context of recurrent neural networks.

    

### [[2108.05025] Learning Oculomotor Behaviors from Scanpath](http://arxiv.org/abs/2108.05025)


  Identifying oculomotor behaviors relevant for eye-tracking applications is a
critical but often challenging task. Aiming to automatically learn and extract
knowledge from existing eye-tracking data, we develop a novel method that
creates rich representations of oculomotor scanpaths to facilitate the learning
of downstream tasks. The proposed stimulus-agnostic Oculomotor Behavior
Framework (OBF) model learns human oculomotor behaviors from unsupervised and
semi-supervised tasks, including reconstruction, predictive coding, fixation
identification, and contrastive learning tasks. The resultant pre-trained OBF
model can be used in a variety of applications. Our pre-trained model
outperforms baseline approaches and traditional scanpath methods in autism
spectrum disorder and viewed-stimulus classification tasks. Ablation
experiments further show our proposed method could achieve even better results
with larger model sizes and more diverse eye-tracking training datasets,
supporting the model's potential for future eye-tracking applications. Open
source code: this http URL.

    

### [[2108.05028] Boosting the Generalization Capability in Cross-Domain Few-shot Learning via Noise-enhanced Supervised Autoencoder](http://arxiv.org/abs/2108.05028)


  State of the art (SOTA) few-shot learning (FSL) methods suffer significant
performance drop in the presence of domain differences between source and
target datasets. The strong discrimination ability on the source dataset does
not necessarily translate to high classification accuracy on the target
dataset. In this work, we address this cross-domain few-shot learning (CDFSL)
problem by boosting the generalization capability of the model. Specifically,
we teach the model to capture broader variations of the feature distributions
with a novel noise-enhanced supervised autoencoder (NSAE). NSAE trains the
model by jointly reconstructing inputs and predicting the labels of inputs as
well as their reconstructed pairs. Theoretical analysis based on intra-class
correlation (ICC) shows that the feature embeddings learned from NSAE have
stronger discrimination and generalization abilities in the target domain. We
also take advantage of NSAE structure and propose a two-step fine-tuning
procedure that achieves better adaption and improves classification performance
in the target domain. Extensive experiments and ablation studies are conducted
to demonstrate the effectiveness of the proposed method. Experimental results
show that our proposed method consistently outperforms SOTA methods under
various conditions.

    

### [[2108.05030] DQ-GAT: Towards Safe and Efficient Autonomous Driving with Deep Q-Learning and Graph Attention Networks](http://arxiv.org/abs/2108.05030)


  Autonomous driving in multi-agent and dynamic traffic scenarios is
challenging, where the behaviors of other road agents are uncertain and hard to
model explicitly, and the ego-vehicle should apply complicated negotiation
skills with them to achieve both safe and efficient driving in various
settings, such as giving way, merging and taking turns. Traditional planning
methods are largely rule-based and scale poorly in these complex dynamic
scenarios, often leading to reactive or even overly conservative behaviors.
Therefore, they require tedious human efforts to maintain workability.
Recently, deep learning-based methods have shown promising results with better
generalization capability but less hand engineering effort. However, they are
either implemented with supervised imitation learning (IL) that suffers from
the dataset bias and distribution mismatch problems, or trained with deep
reinforcement learning (DRL) but focus on one specific traffic scenario. In
this work, we propose DQ-GAT to achieve scalable and proactive autonomous
driving, where graph attention-based networks are used to implicitly model
interactions, and asynchronous deep Q-learning is employed to train the network
end-to-end in an unsupervised manner. Extensive experiments through a
high-fidelity driving simulation show that our method can better trade-off
safety and efficiency in both seen and unseen scenarios, achieving higher goal
success rates than the baselines (at most 4.7$\times$) with comparable task
completion time. Demonstration videos are available at
this https URL.

    

### [[2108.05038] Parallel algorithms for mining of frequent itemsets](http://arxiv.org/abs/2108.05038)


  In the recent decade companies started collecting of large amount of data.
Without a proper analyse, the data are usually useless. The field of analysing
the data is called data mining. Unfortunately, the amount of data is quite
large: the data do not fit into main memory and the processing time can become
quite huge. Therefore, we need parallel data mining algorithms. One of the
popular and important data mining algorithm is the algorithm for generation of
so called frequent itemsets. The problem of mining of frequent itemsets can be
explained on the following example: customers goes in a store put into theirs
baskets some goods; the owner of the store collects the baskets and wants to
know the set of goods that are bought together in at least p% of the baskets.
Currently, the sequential algorithms for mining of frequent itemsets are quite
good in the means of performance. However, the parallel algorithms for mining
of frequent itemsets still do not achieve good speedup. In this thesis, we
develop a parallel method for mining of frequent itemsets that can be used for
an arbitrary depth first search sequential algorithms on a distributed memory
parallel computer. Our method achieves speedup of ~ 6 on 10 processors. The
method is based on an approximate estimation of processor load from a database
sample - however it always computes the set of frequent itemsets from the whole
database. In this thesis, we show a theory underlying our method and show the
performance of the estimation process.

    

### [[2108.05039] Predicting Molecular Phenotypes with Single Cell RNA Sequencing Data: an Assessment of Unsupervised Machine Learning Models](http://arxiv.org/abs/2108.05039)


  According to the National Cancer Institute, there were 9.5 million
cancer-related deaths in 2018. A challenge in improving treatment is resistance
in genetically unstable cells. The purpose of this study is to evaluate
unsupervised machine learning on classifying treatment-resistant phenotypes in
heterogeneous tumors through analysis of single cell RNA sequencing(scRNAseq)
data with a pipeline and evaluation metrics. scRNAseq quantifies mRNA in cells
and characterizes cell phenotypes. One scRNAseq dataset was analyzed
(tumor/non-tumor cells of different molecular subtypes and patient
identifications). The pipeline consisted of data filtering, dimensionality
reduction with Principal Component Analysis, projection with Uniform Manifold
Approximation and Projection, clustering with nine approaches (Ward, BIRCH,
Gaussian Mixture Model, DBSCAN, Spectral, Affinity Propagation, Agglomerative
Clustering, Mean Shift, and K-Means), and evaluation. Seven models divided
tumor versus non-tumor cells and molecular subtype while six models classified
different patient identification (13 of which were presented in the dataset);
K-Means, Ward, and BIRCH often ranked highest with ~80% accuracy on the tumor
versus non-tumor task and ~60% for molecular subtype and patient ID. An
optimized classification pipeline using K-Means, Ward, and BIRCH models was
evaluated to be most effective for further analysis. In clinical research where
there is currently no standard protocol for scRNAseq analysis, clusters
generated from this pipeline can be used to understand cancer cell behavior and
malignant growth, directly affecting the success of treatment.

    

### [[2108.05053] Managing ML Pipelines: Feature Stores and the Coming Wave of Embedding Ecosystems](http://arxiv.org/abs/2108.05053)


  The industrial machine learning pipeline requires iterating on model
features, training and deploying models, and monitoring deployed models at
scale. Feature stores were developed to manage and standardize the engineer's
workflow in this end-to-end pipeline, focusing on traditional tabular feature
data. In recent years, however, model development has shifted towards using
self-supervised pretrained embeddings as model features. Managing these
embeddings and the downstream systems that use them introduces new challenges
with respect to managing embedding training data, measuring embedding quality,
and monitoring downstream models that use embeddings. These challenges are
largely unaddressed in standard feature stores. Our goal in this tutorial is to
introduce the feature store system and discuss the challenges and current
solutions to managing these new embedding-centric pipelines.

    

### [[2108.05073] ULTRA: An Unbiased Learning To Rank Algorithm Toolbox](http://arxiv.org/abs/2108.05073)


  Learning to rank systems has become an important aspect of our daily life.
However, the implicit user feedback that is used to train many learning to rank
models is usually noisy and suffered from user bias (i.e., position bias).
Thus, obtaining an unbiased model using biased feedback has become an important
research field for IR. Existing studies on unbiased learning to rank (ULTR) can
be generalized into two families-algorithms that attain unbiasedness with
logged data, offline learning, and algorithms that achieve unbiasedness by
estimating unbiased parameters with real-time user interactions, namely online
learning. While there exist many algorithms from both families, there lacks a
unified way to compare and benchmark them. As a result, it can be challenging
for researchers to choose the right technique for their problems or for people
who are new to the field to learn and understand existing algorithms. To solve
this problem, we introduced ULTRA, which is a flexible, extensible, and easily
configure ULTR toolbox. Its key features include support for multiple ULTR
algorithms with configurable hyperparameters, a variety of built-in click
models that can be used separately to simulate clicks, different ranking model
architecture and evaluation metrics, and simple learning to rank pipeline
creation. In this paper, we discuss the general framework of ULTR, briefly
describe the algorithms in ULTRA, detailed the structure, and pipeline of the
toolbox. We experimented on all the algorithms supported by ultra and showed
that the toolbox performance is reasonable. Our toolbox is an important
resource for researchers to conduct experiments on ULTR algorithms with
different configurations as well as testing their own algorithms with the
supported features.

    

### [[2108.05075] Turning Your Strength against You: Detecting and Mitigating Robust and Universal Adversarial Patch Attack](http://arxiv.org/abs/2108.05075)


  Adversarial patch attack against image classification deep neural networks
(DNNs), in which the attacker can inject arbitrary distortions within a bounded
region of an image, is able to generate adversarial perturbations that are
robust (i.e., remain adversarial in physical world) and universal (i.e., remain
adversarial on any input). It is thus important to detect and mitigate such
attack to ensure the security of DNNs.
This work proposes Jujutsu, a technique to detect and mitigate robust and
universal adversarial patch attack. Jujutsu leverages the universal property of
the patch attack for detection. It uses explainable AI technique to identify
suspicious features that are potentially malicious, and verify their
maliciousness by transplanting the suspicious features to new images. An
adversarial patch continues to exhibit the malicious behavior on the new images
and thus can be detected based on prediction consistency. Jujutsu leverages the
localized nature of the patch attack for mitigation, by randomly masking the
suspicious features to "remove" adversarial perturbations. However, the network
might fail to classify the images as some of the contents are removed (masked).
Therefore, Jujutsu uses image inpainting for synthesizing alternative contents
from the pixels that are masked, which can reconstruct the "clean" image for
correct prediction. We evaluate Jujutsu on five DNNs on two datasets, and show
that Jujutsu achieves superior performance and significantly outperforms
existing techniques. Jujutsu can further defend against various variants of the
basic attack, including 1) physical-world attack; 2) attacks that target
diverse classes; 3) attacks that use patches in different shapes and 4)
adaptive attacks.

    

### [[2108.05079] Unsupervised Driver Behavior Profiling leveraging Recurrent Neural Networks](http://arxiv.org/abs/2108.05079)


  In the era of intelligent transportation, driver behavior profiling has
become a beneficial technology as it provides knowledge regarding the driver's
aggressiveness. Previous approaches achieved promising driver behavior
profiling performance through establishing statistical heuristics rules or
supervised learning-based models. Still, there exist limits that the
practitioner should prepare a labeled dataset, and prior approaches could not
classify aggressive behaviors which are not known a priori. In pursuit of
improving the aforementioned drawbacks, we propose a novel approach to driver
behavior profiling leveraging an unsupervised learning paradigm. First, we cast
the driver behavior profiling problem as anomaly detection. Second, we
established recurrent neural networks that predict the next feature vector
given a sequence of feature vectors. We trained the model with normal driver
data only. As a result, our model yields high regression error given a sequence
of aggressive driver behavior and low error given at a sequence of normal
driver behavior. We figured this difference of error between normal and
aggressive driver behavior can be an adequate flag for driver behavior
profiling and accomplished a precise performance in experiments. Lastly, we
further analyzed the optimal level of sequence length for identifying each
aggressive driver behavior. We expect the proposed approach to be a useful
baseline for unsupervised driver behavior profiling and contribute to the
efficient, intelligent transportation ecosystem.

    

### [[2108.05092] Cooperative Learning for Noisy Supervision](http://arxiv.org/abs/2108.05092)


  Learning with noisy labels has gained the enormous interest in the robust
deep learning area. Recent studies have empirically disclosed that utilizing
dual networks can enhance the performance of single network but without
theoretic proof. In this paper, we propose Cooperative Learning (CooL)
framework for noisy supervision that analytically explains the effects of
leveraging dual or multiple networks. Specifically, the simple but efficient
combination in CooL yields a more reliable risk minimization for unseen clean
data. A range of experiments have been conducted on several benchmarks with
both synthetic and real-world settings. Extensive results indicate that CooL
outperforms several state-of-the-art methods.

    

### [[2108.05099] Does Explicit Prediction Matter in Energy Management Based on Deep Reinforcement Learning?](http://arxiv.org/abs/2108.05099)


  As a model-free optimization and decision-making method, deep reinforcement
learning (DRL) has been widely applied to the filed of energy management in
energy Internet. While, some DRL-based energy management schemes also
incorporate the prediction module used by the traditional model-based methods,
which seems to be unnecessary and even adverse. In this work, we present the
standard DRL-based energy management scheme with and without prediction. Then,
these two schemes are compared in the unified energy management framework. The
simulation results demonstrate that the energy management scheme without
prediction is superior over the scheme with prediction. This work intends to
rectify the misuse of DRL methods in the field of energy management.

    

### [[2108.05117] PLEX: Towards Practical Learned Indexing](http://arxiv.org/abs/2108.05117)


  Latest research proposes to replace existing index structures with learned
models. However, current learned indexes tend to have many hyperparameters,
often do not provide any error guarantees, and are expensive to build. We
introduce Practical Learned Index (PLEX). PLEX only has a single hyperparameter
$\epsilon$ (maximum prediction error) and offers a better trade-off between
build and lookup time than state-of-the-art approaches. Similar to RadixSpline,
PLEX consists of a spline and a (multi-level) radix layer. It first builds a
spline satisfying the given $\epsilon$ and then performs an ad-hoc analysis of
the distribution of spline points to quickly tune the radix layer.

    

### [[2108.05135] Overview of the TREC 2020 Fair Ranking Track](http://arxiv.org/abs/2108.05135)


  This paper provides an overview of the NIST TREC 2020 Fair Ranking track. For
2020, we again adopted an academic search task, where we have a corpus of
academic article abstracts and queries submitted to a production academic
search engine. The central goal of the Fair Ranking track is to provide fair
exposure to different groups of authors (a group fairness framing). We
recognize that there may be multiple group definitions (e.g. based on
demographics, stature, topic) and hoped for the systems to be robust to these.
We expected participants to develop systems that optimize for fairness and
relevance for arbitrary group definitions, and did not reveal the exact group
definitions until after the evaluation runs were submitted.The track contains
two tasks,reranking and retrieval, with a shared evaluation.

    

### [[2108.05149] Logic Explained Networks](http://arxiv.org/abs/2108.05149)


  The large and still increasing popularity of deep learning clashes with a
major limit of neural network architectures, that consists in their lack of
capability in providing human-understandable motivations of their decisions. In
situations in which the machine is expected to support the decision of human
experts, providing a comprehensible explanation is a feature of crucial
importance. The language used to communicate the explanations must be formal
enough to be implementable in a machine and friendly enough to be
understandable by a wide audience. In this paper, we propose a general approach
to Explainable Artificial Intelligence in the case of neural architectures,
showing how a mindful design of the networks leads to a family of interpretable
deep learning models called Logic Explained Networks (LENs). LENs only require
their inputs to be human-understandable predicates, and they provide
explanations in terms of simple First-Order Logic (FOL) formulas involving such
predicates. LENs are general enough to cover a large number of scenarios.
Amongst them, we consider the case in which LENs are directly used as special
classifiers with the capability of being explainable, or when they act as
additional networks with the role of creating the conditions for making a
black-box classifier explainable by FOL formulas. Despite supervised learning
problems are mostly emphasized, we also show that LENs can learn and provide
explanations in unsupervised learning settings. Experimental results on several
datasets and tasks show that LENs may yield better classifications than
established white-box models, such as decision trees and Bayesian rule lists,
while providing more compact and meaningful explanations.

    

### [[2108.05152] Estimation of Fair Ranking Metrics with Incomplete Judgments](http://arxiv.org/abs/2108.05152)


  There is increasing attention to evaluating the fairness of search system
ranking decisions. These metrics often consider the membership of items to
particular groups, often identified using protected attributes such as gender
or ethnicity. To date, these metrics typically assume the availability and
completeness of protected attribute labels of items. However, the protected
attributes of individuals are rarely present, limiting the application of fair
ranking metrics in large scale systems. In order to address this problem, we
propose a sampling strategy and estimation technique for four fair ranking
metrics. We formulate a robust and unbiased estimator which can operate even
with very limited number of labeled items. We evaluate our approach using both
simulated and real world data. Our experimental results demonstrate that our
method can estimate this family of fair ranking metrics and provides a robust,
reliable alternative to exhaustive or random data annotation.

    

### [[2108.05170] ProAI: An Efficient Embedded AI Hardware for Automotive Applications - a Benchmark Study](http://arxiv.org/abs/2108.05170)


  Development in the field of Single Board Computers (SBC) have been increasing
for several years. They provide a good balance between computing performance
and power consumption which is usually required for mobile platforms, like
application in vehicles for Advanced Driver Assistance Systems (ADAS) and
Autonomous Driving (AD). However, there is an ever-increasing need of more
powerful and efficient SBCs which can run power intensive Deep Neural Networks
(DNNs) in real-time and can also satisfy necessary functional safety
requirements such as Automotive Safety Integrity Level (ASIL). ProAI is being
developed by ZF mainly to run powerful and efficient applications such as
multitask DNNs and on top of that it also has the required safety certification
for AD. In this work, we compare and discuss state of the art SBC on the basis
of power intensive multitask DNN architecture called Multitask-CenterNet with
respect to performance measures such as, FPS and power efficiency. As an
automotive supercomputer, ProAI delivers an excellent combination of
performance and efficiency, managing nearly twice the number of FPS per watt
than a modern workstation laptop and almost four times compared to the Jetson
Nano. Furthermore, it was also shown that there is still power in reserve for
further and more complex tasks on the ProAI, based on the CPU and GPU
utilization during the benchmark.

    

### [[2108.05183] Deep2Lead: A distributed deep learning application for small molecule lead optimization](http://arxiv.org/abs/2108.05183)


  Lead optimization is a key step in drug discovery to produce potent and
selective compounds. Historically, in silico screening and structure-based
small molecule designing facilitated the processes. Although the recent
application of deep learning to drug discovery piloted the possibility of their
in silico application lead optimization steps, the real-world application is
lacking due to the tool availability. Here, we developed a single user
interface application, called Deep2Lead. Our web-based application integrates
VAE and DeepPurpose DTI and allows a user to quickly perform a lead
optimization task with no prior programming experience.

    

### [[2108.05184] Empirical Risk Minimization for Time Series: Nonparametric Performance Bounds for Prediction](http://arxiv.org/abs/2108.05184)


  Empirical risk minimization is a standard principle for choosing algorithms
in learning theory. In this paper we study the properties of empirical risk
minimization for time series. The analysis is carried out in a general
framework that covers different types of forecasting applications encountered
in the literature. We are concerned with 1-step-ahead prediction of a
univariate time series generated by a parameter-driven process. A class of
recursive algorithms is available to forecast the time series. The algorithms
are recursive in the sense that the forecast produced in a given period is a
function of the lagged values of the forecast and of the time series. The
relationship between the generating mechanism of the time series and the class
of algorithms is unspecified. Our main result establishes that the algorithm
chosen by empirical risk minimization achieves asymptotically the optimal
predictive performance that is attainable within the class of algorithms.

    

### [[2108.05196] Towards data-driven filters in Paraview](http://arxiv.org/abs/2108.05196)


  Recent progress in scientific visualization has expanded the scope of
visualization from being merely a way of presentation to an analysis and
discovery tool. A given visualization result is usually generated by applying a
series of transformations or filters to the underlying data. Nowadays, such
filters use deterministic algorithms to process the data. In this work, we aim
at extending this methodology towards data-driven filters, thus filters that
expose the abilities of pre-trained machine learning models to the
visualization system. The use of such data-driven filters is of particular
interest in fields like segmentation, classification, etc., where machine
learning models regularly outperform existing algorithmic approaches. To
showcase this idea, we couple Paraview, the well-known flow visualization tool,
with PyTorch, a deep learning framework. Paraview is extended by plugins that
allow users to load pre-trained models of their choice in the form of newly
developed filters. The filters transform the input data by feeding it into the
model and then provide the model's output as input to the remaining
visualization pipeline. A series of simplistic use cases for segmentation and
classification on image and fluid data is presented to showcase the technical
applicability of such data-driven transformations in Paraview for future
complex analysis tasks.

    

### [[2108.05198] Natural Language-guided Programming](http://arxiv.org/abs/2108.05198)


  In today's software world with its cornucopia of reusable software libraries,
when a programmer is faced with a programming task that they suspect can be
completed through the use of a library, they often look for code examples using
a search engine and then manually adapt found examples to their specific
context of use. We put forward a vision based on a new breed of developer tools
that have the potential to largely automate this process. The key idea is to
adapt code autocompletion tools such that they take into account not only the
developer's already-written code but also the intent of the task the developer
is trying to achieve next, formulated in plain natural language. We call this
practice of enriching the code with natural language intent to facilitate its
completion natural language-guided programming.
To show that this idea is feasible we design, implement and benchmark a tool
that solves this problem in the context of a specific domain (data science) and
a specific programming language (Python). Central to the tool is the use of
language models trained on a large corpus of documented code. Our initial
experiments confirm the feasibility of the idea but also make it clear that we
have only scratched the surface of what may become possible in the future. We
end the paper with a comprehensive research agenda to stimulate additional
research in the budding area of natural language-guided programming.

    

### [[2108.05233] EDITS: Modeling and Mitigating Data Bias for Graph Neural Networks](http://arxiv.org/abs/2108.05233)


  Graph Neural Networks (GNNs) have recently demonstrated superior capability
of tackling graph analytical problems in various applications. Nevertheless,
with the wide-spreading practice of GNNs in high-stake decision-making
processes, there is an increasing societal concern that GNNs could make
discriminatory decisions that may be illegal towards certain demographic
groups. Although some explorations have been made towards developing fair GNNs,
existing approaches are tailored for a specific GNN model. However, in
practical scenarios, myriads of GNN variants have been proposed for different
tasks, and it is costly to train and fine-tune existing debiasing models for
different GNNs. Also, bias in a trained model could originate from training
data, while how to mitigate bias in the graph data is usually overlooked. In
this work, different from existing work, we first propose novel definitions and
metrics to measure the bias in an attributed network, which leads to the
optimization objective to mitigate bias. Based on the optimization objective,
we develop a framework named EDITS to mitigate the bias in attributed networks
while preserving useful information. EDITS works in a model-agnostic manner,
which means that it is independent of the specific GNNs applied for downstream
tasks. Extensive experiments on both synthetic and real-world datasets
demonstrate the validity of the proposed bias metrics and the superiority of
EDITS on both bias mitigation and utility maintenance. Open-source
implementation: this https URL.

    

### [[2108.05237] Convergence bounds for nonlinear least squares and applications to tensor recovery](http://arxiv.org/abs/2108.05237)


  We consider the problem of approximating a function in general nonlinear
subsets of $L^2$ when only a weighted Monte Carlo estimate of the $L^2$-norm
can be computed. Of particular interest in this setting is the concept of
sample complexity, the number of samples that are necessary to recover the best
approximation. Bounds for this quantity have been derived in a previous work
and depend primarily on the model class and are not influenced positively by
the regularity of the sought function. This result however is only a worst-case
bound and is not able to explain the remarkable performance of iterative hard
thresholding algorithms that is observed in practice. We reexamine the results
of the previous paper and derive a new bound that is able to utilize the
regularity of the sought function. A critical analysis of our results allows us
to derive a sample efficient algorithm for the model set of low-rank tensors.
The viability of this algorithm is demonstrated by recovering quantities of
interest for a classical high-dimensional random partial differential equation.

    

### [[2108.05249] Fog Simulation on Real LiDAR Point Clouds for 3D Object Detection in Adverse Weather](http://arxiv.org/abs/2108.05249)


  This work addresses the challenging task of LiDAR-based 3D object detection
in foggy weather. Collecting and annotating data in such a scenario is very
time, labor and cost intensive. In this paper, we tackle this problem by
simulating physically accurate fog into clear-weather scenes, so that the
abundant existing real datasets captured in clear weather can be repurposed for
our task. Our contributions are twofold: 1) We develop a physically valid fog
simulation method that is applicable to any LiDAR dataset. This unleashes the
acquisition of large-scale foggy training data at no extra cost. These
partially synthetic data can be used to improve the robustness of several
perception methods, such as 3D object detection and tracking or simultaneous
localization and mapping, on real foggy data. 2) Through extensive experiments
with several state-of-the-art detection approaches, we show that our fog
simulation can be leveraged to significantly improve the performance for 3D
object detection in the presence of fog. Thus, we are the first to provide
strong 3D object detection baselines on the Seeing Through Fog dataset. Our
code is available at this http URL.

    

### [[2108.05258] Deep Learning Classification of Lake Zooplankton](http://arxiv.org/abs/2108.05258)


  Plankton are effective indicators of environmental change and ecosystem
health in freshwater habitats, but collection of plankton data using manual
microscopic methods is extremely labor-intensive and expensive. Automated
plankton imaging offers a promising way forward to monitor plankton communities
with high frequency and accuracy in real-time. Yet, manual annotation of
millions of images proposes a serious challenge to taxonomists. Deep learning
classifiers have been successfully applied in various fields and provided
encouraging results when used to categorize marine plankton images. Here, we
present a set of deep learning models developed for the identification of lake
plankton, and study several strategies to obtain optimal performances,which
lead to operational prescriptions for users. To this aim, we annotated into 35
classes over 17900 images of zooplankton and large phytoplankton colonies,
detected in Lake Greifensee (Switzerland) with the Dual Scripps Plankton
Camera. Our best models were based on transfer learning and ensembling, which
classified plankton images with 98% accuracy and 93% F1 score. When tested on
freely available plankton datasets produced by other automated imaging tools
(ZooScan, FlowCytobot and ISIIS), our models performed better than previously
used models. Our annotated data, code and classification models are freely
available online.

    

### [[2108.05269] Learning to Rearrange Voxels in Binary Segmentation Masks for Smooth Manifold Triangulation](http://arxiv.org/abs/2108.05269)


  Medical images, especially volumetric images, are of high resolution and
often exceed the capacity of standard desktop GPUs. As a result, most deep
learning-based medical image analysis tasks require the input images to be
downsampled, often substantially, before these can be fed to a neural network.
However, downsampling can lead to a loss of image quality, which is undesirable
especially in reconstruction tasks, where the fine geometric details need to be
preserved. In this paper, we propose that high-resolution images can be
reconstructed in a coarse-to-fine fashion, where a deep learning algorithm is
only responsible for generating a coarse representation of the image, which
consumes moderate GPU memory. For producing the high-resolution outcome, we
propose two novel methods: learned voxel rearrangement of the coarse output and
hierarchical image synthesis. Compared to the coarse output, the
high-resolution counterpart allows for smooth surface triangulation, which can
be 3D-printed in the highest possible quality. Experiments of this paper are
carried out on the dataset of AutoImplant 2021
(this https URL), a MICCAI challenge on cranial
implant design. The dataset contains high-resolution skulls that can be viewed
as 2D manifolds embedded in a 3D space. Codes associated with this study can be
accessed at this https URL.

    

### [[2108.05280] Putting RDF2vec in Order](http://arxiv.org/abs/2108.05280)


  The RDF2vec method for creating node embeddings on knowledge graphs is based
on word2vec, which, in turn, is agnostic towards the position of context words.
In this paper, we argue that this might be a shortcoming when training RDF2vec,
and show that using a word2vec variant which respects order yields considerable
performance gains especially on tasks where entities of different classes are
involved.

    

### [[2108.05308] A Better Loss for Visual-Textual Grounding](http://arxiv.org/abs/2108.05308)


  Given a textual phrase and an image, the visual grounding problem is defined
as the task of locating the content of the image referenced by the sentence. It
is a challenging task that has several real-world applications in
human-computer interaction, image-text reference resolution, and video-text
reference resolution. In the last years, several works have addressed this
problem with heavy and complex models that try to capture visual-textual
dependencies better than before. These models are typically constituted by two
main components that focus on how to learn useful multi-modal features for
grounding and how to improve the predicted bounding box of the visual mention,
respectively. Finding the right learning balance between these two sub-tasks is
not easy, and the current models are not necessarily optimal with respect to
this issue. In this work, we propose a model that, although using a simple
multi-modal feature fusion component, is able to achieve a higher accuracy than
state-of-the-art models thanks to the adoption of a more effective loss
function, based on the classes probabilities, that reach, in the considered
datasets, a better learning balance between the two sub-tasks mentioned above.

    

### [[2108.05315] Fairness Through Counterfactual Utilities](http://arxiv.org/abs/2108.05315)


  Group fairness definitions such as Demographic Parity and Equal Opportunity
make assumptions about the underlying decision-problem that restrict them to
classification problems. Prior work has translated these definitions to other
machine learning environments, such as unsupervised learning and reinforcement
learning, by implementing their closest mathematical equivalent. As a result,
there are numerous bespoke interpretations of these definitions. Instead, we
provide a generalized set of group fairness definitions that unambiguously
extend to all machine learning environments while still retaining their
original fairness notions. We derive two fairness principles that enable such a
generalized framework. First, our framework measures outcomes in terms of
utilities, rather than predictions, and does so for both the decision-algorithm
and the individual. Second, our framework considers counterfactual outcomes,
rather than just observed outcomes, thus preventing loopholes where fairness
criteria are satisfied through self-fulfilling prophecies. We provide concrete
examples of how our counterfactual utility fairness framework resolves known
fairness issues in classification, clustering, and reinforcement learning
problems. We also show that many of the bespoke interpretations of Demographic
Parity and Equal Opportunity fit nicely as special cases of our framework.

    

### [[2108.05319] Machine Learning Model Drift Detection Via Weak Data Slices](http://arxiv.org/abs/2108.05319)


  Detecting drift in performance of Machine Learning (ML) models is an
acknowledged challenge. For ML models to become an integral part of business
applications it is essential to detect when an ML model drifts away from
acceptable operation. However, it is often the case that actual labels are
difficult and expensive to get, for example, because they require expert
judgment. Therefore, there is a need for methods that detect likely degradation
in ML operation without labels. We propose a method that utilizes feature space
rules, called data slices, for drift detection. We provide experimental
indications that our method is likely to identify that the ML model will likely
change in performance, based on changes in the underlying data.

    

### [[2108.05335] Explaining Algorithmic Fairness Through Fairness-Aware Causal Path Decomposition](http://arxiv.org/abs/2108.05335)


  Algorithmic fairness has aroused considerable interests in data mining and
machine learning communities recently. So far the existing research has been
mostly focusing on the development of quantitative metrics to measure algorithm
disparities across different protected groups, and approaches for adjusting the
algorithm output to reduce such disparities. In this paper, we propose to study
the problem of identification of the source of model disparities. Unlike
existing interpretation methods which typically learn feature importance, we
consider the causal relationships among feature variables and propose a novel
framework to decompose the disparity into the sum of contributions from
fairness-aware causal paths, which are paths linking the sensitive attribute
and the final predictions, on the graph. We also consider the scenario when the
directions on certain edges within those paths cannot be determined. Our
framework is also model agnostic and applicable to a variety of quantitative
disparity measures. Empirical evaluations on both synthetic and real-world data
sets are provided to show that our method can provide precise and comprehensive
explanations to the model disparities.

    

### [[2108.05338] Truncated Emphatic Temporal Difference Methods for Prediction and Control](http://arxiv.org/abs/2108.05338)


  Emphatic Temporal Difference (TD) methods are a class of off-policy
Reinforcement Learning (RL) methods involving the use of followon traces.
Despite the theoretical success of emphatic TD methods in addressing the
notorious deadly triad (Sutton and Barto, 2018) of off-policy RL, there are
still three open problems. First, the motivation for emphatic TD methods
proposed by Sutton et al. (2016) does not align with the convergence analysis
of Yu (2015). Namely, a quantity used by Sutton et al. (2016) that is expected
to be essential for the convergence of emphatic TD methods is not used in the
actual convergence analysis of Yu (2015). Second, followon traces typically
suffer from large variance, making them hard to use in practice. Third, despite
the seminal work of Yu (2015) confirming the asymptotic convergence of some
emphatic TD methods for prediction problems, there is still no finite sample
analysis for any emphatic TD method for prediction, much less control. In this
paper, we address those three open problems simultaneously via using truncated
followon traces in emphatic TD methods. Unlike the original followon traces,
which depend on all previous history, truncated followon traces depend on only
finite history, reducing variance and enabling the finite sample analysis of
our proposed emphatic TD methods for both prediction and control.

    

### [[2108.05341] The Forgotten Role of Search Queries in IR-based Bug Localization: An Empirical Study](http://arxiv.org/abs/2108.05341)


  Being light-weight and cost-effective, IR-based approaches for bug
localization have shown promise in finding software bugs. However, the accuracy
of these approaches heavily depends on their used bug reports. A significant
number of bug reports contain only plain natural language texts. According to
existing studies, IR-based approaches cannot perform well when they use these
bug reports as search queries. On the other hand, there is a piece of recent
evidence that suggests that even these natural language-only reports contain
enough good keywords that could help localize the bugs successfully. On one
hand, these findings suggest that natural language-only bug reports might be a
sufficient source for good query keywords. On the other hand, they cast serious
doubt on the query selection practices in the IR-based bug localization. In
this article, we attempted to clear the sky on this aspect by conducting an
in-depth empirical study that critically examines the state-of-the-art query
selection practices in IR-based bug localization. In particular, we use a
dataset of 2,320 bug reports, employ ten existing approaches from the
literature, exploit the Genetic Algorithm-based approach to construct optimal,
near-optimal search queries from these bug reports, and then answer three
research questions. We confirmed that the state-of-the-art query construction
approaches are indeed not sufficient for constructing appropriate queries (for
bug localization) from certain natural language-only bug reports although they
contain such queries. We also demonstrate that optimal queries and non-optimal
queries chosen from bug report texts are significantly different in terms of
several keyword characteristics, which has led us to actionable insights.
Furthermore, we demonstrate 27%--34% improvement in the performance of
non-optimal queries through the application of our actionable insights to them.

    

### [[2108.05342] Large-Scale Modeling of Mobile User Click Behaviors Using Deep Learning](http://arxiv.org/abs/2108.05342)


  Modeling tap or click sequences of users on a mobile device can improve our
understandings of interaction behavior and offers opportunities for UI
optimization by recommending next element the user might want to click on. We
analyzed a large-scale dataset of over 20 million clicks from more than 4,000
mobile users who opted in. We then designed a deep learning model that predicts
the next element that the user clicks given the user's click history, the
structural information of the UI screen, and the current context such as the
time of the day. We thoroughly investigated the deep model by comparing it with
a set of baseline methods based on the dataset. The experiments show that our
model achieves 48% and 71% accuracy (top-1 and top-3) for predicting next
clicks based on a held-out dataset of test users, which significantly
outperformed all the baseline methods with a large margin. We discussed a few
scenarios for integrating the model in mobile interaction and how users can
potentially benefit from the model.

    

### [[2108.05350] Controlling the False Split Rate in Tree-Based Aggregation](http://arxiv.org/abs/2108.05350)


  In many domains, data measurements can naturally be associated with the
leaves of a tree, expressing the relationships among these measurements. For
example, companies belong to industries, which in turn belong to ever coarser
divisions such as sectors; microbes are commonly arranged in a taxonomic
hierarchy from species to kingdoms; street blocks belong to neighborhoods,
which in turn belong to larger-scale regions. The problem of tree-based
aggregation that we consider in this paper asks which of these tree-defined
subgroups of leaves should really be treated as a single entity and which of
these entities should be distinguished from each other.
We introduce the "false split rate", an error measure that describes the
degree to which subgroups have been split when they should not have been. We
then propose a multiple hypothesis testing algorithm for tree-based
aggregation, which we prove controls this error measure. We focus on two main
examples of tree-based aggregation, one which involves aggregating means and
the other which involves aggregating regression coefficients. We apply this
methodology to aggregate stocks based on their volatility and to aggregate
neighborhoods of New York City based on taxi fares.

    

### [[1910.06539] Challenges in Markov chain Monte Carlo for Bayesian neural networks](http://arxiv.org/abs/1910.06539)


  Markov chain Monte Carlo (MCMC) methods have not been broadly adopted in
Bayesian neural networks (BNNs). This paper initially reviews the main
challenges in sampling from the parameter posterior of a neural network via
MCMC. Such challenges culminate to lack of convergence to the parameter
posterior. Nevertheless, this paper shows that a non-converged Markov chain,
generated via MCMC sampling from the parameter space of a neural network, can
yield via Bayesian marginalization a valuable posterior predictive distribution
of the output of the neural network. Classification examples based on
multilayer perceptrons showcase highly accurate posterior predictive
distributions. The postulate of limited scope for MCMC developments in BNNs is
partially valid; an asymptotically exact parameter posterior seems less
plausible, yet an accurate posterior predictive distribution is a tenable
research avenue.

    

### [[2003.03988] Overcoming the Weight Transport Problem via Spike-Timing-Dependent Weight Inference](http://arxiv.org/abs/2003.03988)


  We propose a solution to the weight transport problem, which questions the
biological plausibility of the backpropagation algorithm. We derive our method
based upon a theoretical analysis of the (approximate) dynamics of leaky
integrate-and-fire neurons. We show that the use of spike timing alone
outcompetes existing biologically plausible methods for synaptic weight
inference in spiking neural network models. Furthermore, our proposed method is
more flexible, being applicable to any spiking neuron model, is conservative in
how many parameters are required for implementation and can be deployed in an
online-fashion with minimal computational overhead. These features, together
with its biological plausibility, make it an attractive mechanism underlying
weight inference at single synapses.

    

### [[2006.04554] Batch greedy maximization of non-submodular functions: Guarantees and applications to experimental design](http://arxiv.org/abs/2006.04554)


  We propose and analyze batch greedy heuristics for cardinality constrained
maximization of non-submodular non-decreasing set functions. We consider the
standard greedy paradigm, along with its distributed greedy and stochastic
greedy variants. Our theoretical guarantees are characterized by the
combination of submodularity and supermodularity ratios. We argue how these
parameters define tight modular bounds based on incremental gains, and provide
a novel reinterpretation of the classical greedy algorithm using the
minorize-maximize (MM) principle. Based on that analogy, we propose a new class
of methods exploiting any plausible modular bound. In the context of optimal
experimental design for linear Bayesian inverse problems, we bound the
submodularity and supermodularity ratios when the underlying objective is based
on mutual information. We also develop novel modular bounds for the mutual
information in this setting, and describe certain connections to polyhedral
combinatorics. We discuss how algorithms using these modular bounds relate to
established statistical notions such as leverage scores and to more recent
efforts such as volume sampling. We demonstrate our theoretical findings on
synthetic problems and on a real-world climate monitoring example.

    

### [[2007.01547] Descending through a Crowded Valley - Benchmarking Deep Learning Optimizers](http://arxiv.org/abs/2007.01547)


  Choosing the optimizer is considered to be among the most crucial design
decisions in deep learning, and it is not an easy one. The growing literature
now lists hundreds of optimization methods. In the absence of clear theoretical
guidance and conclusive empirical evidence, the decision is often made based on
anecdotes. In this work, we aim to replace these anecdotes, if not with a
conclusive ranking, then at least with evidence-backed heuristics. To do so, we
perform an extensive, standardized benchmark of fifteen particularly popular
deep learning optimizers while giving a concise overview of the wide range of
possible choices. Analyzing more than $50,000$ individual runs, we contribute
the following three points: (i) Optimizer performance varies greatly across
tasks. (ii) We observe that evaluating multiple optimizers with default
parameters works approximately as well as tuning the hyperparameters of a
single, fixed optimizer. (iii) While we cannot discern an optimization method
clearly dominating across all tested tasks, we identify a significantly reduced
subset of specific optimizers and parameter choices that generally lead to
competitive results in our experiments: Adam remains a strong contender, with
newer methods failing to significantly and consistently outperform it. Our
open-sourced results are available as challenging and well-tuned baselines for
more meaningful evaluations of novel optimization methods without requiring any
further computational efforts.

    

### [[2007.05447] Generalized Maximum Entropy for Supervised Classification](http://arxiv.org/abs/2007.05447)


  The maximum entropy principle advocates to evaluate events' probabilities
using a distribution that maximizes entropy among those that satisfy certain
expectations' constraints. Such principle can be generalized for arbitrary
decision problems where it corresponds to minimax approaches. This paper
establishes a framework for supervised classification based on the generalized
maximum entropy principle that leads to minimax risk classifiers (MRCs). We
develop learning techniques that determine MRCs for general entropy functions
and provide performance guarantees by means of convex optimization. In
addition, we describe the relationship of the presented techniques with
existing classification methods, and quantify MRCs performance in comparison
with the proposed bounds and conventional methods.

    

### [[2007.12141] Dimension reduction in recurrent networks by canonicalization](http://arxiv.org/abs/2007.12141)


  Many recurrent neural network machine learning paradigms can be formulated
using state-space representations. The classical notion of canonical
state-space realization is adapted in this paper to accommodate semi-infinite
inputs so that it can be used as a dimension reduction tool in the recurrent
networks setup. The so-called input forgetting property is identified as the
key hypothesis that guarantees the existence and uniqueness (up to system
isomorphisms) of canonical realizations for causal and time-invariant
input/output systems with semi-infinite inputs. Additionally, the notion of
optimal reduction coming from the theory of symmetric Hamiltonian systems is
implemented in our setup to construct canonical realizations out of input
forgetting but not necessarily canonical ones. These two procedures are studied
in detail in the framework of linear fading memory input/output systems.
Finally, the notion of implicit reduction using reproducing kernel Hilbert
spaces (RKHS) is introduced which allows, for systems with linear readouts, to
achieve dimension reduction without the need to actually compute the reduced
spaces introduced in the first part of the paper.

    

### [[2007.14018] GLIMG: Global and Local Item Graphs for Top-N Recommender Systems](http://arxiv.org/abs/2007.14018)


  Graph-based recommendation models work well for top-N recommender systems due
to their capability to capture the potential relationships between entities.
However, most of the existing methods only construct a single global item graph
shared by all the users and regrettably ignore the diverse tastes between
different user groups. Inspired by the success of local models for
recommendation, this paper provides the first attempt to investigate multiple
local item graphs along with a global item graph for graph-based recommendation
models. We argue that recommendation on global and local graphs outperforms
that on a single global graph or multiple local graphs. Specifically, we
propose a novel graph-based recommendation model named GLIMG (Global and Local
IteM Graphs), which simultaneously captures both the global and local user
tastes. By integrating the global and local graphs into an adapted
semi-supervised learning model, users' preferences on items are propagated
globally and locally. Extensive experimental results on real-world datasets
show that our proposed method consistently outperforms the state-of-the art
counterparts on the top-N recommendation task.

    

### [[2010.04595] GRF: Learning a General Radiance Field for 3D Representation and Rendering](http://arxiv.org/abs/2010.04595)


  We present a simple yet powerful neural network that implicitly represents
and renders 3D objects and scenes only from 2D observations. The network models
3D geometries as a general radiance field, which takes a set of 2D images with
camera poses and intrinsics as input, constructs an internal representation for
each point of the 3D space, and then renders the corresponding appearance and
geometry of that point viewed from an arbitrary position. The key to our
approach is to learn local features for each pixel in 2D images and to then
project these features to 3D points, thus yielding general and rich point
representations. We additionally integrate an attention mechanism to aggregate
pixel features from multiple 2D views, such that visual occlusions are
implicitly taken into account. Extensive experiments demonstrate that our
method can generate high-quality and realistic novel views for novel objects,
unseen categories and challenging real-world scenes.

    

### [[2010.13152] A Simple Spectral Failure Mode for Graph Convolutional Networks](http://arxiv.org/abs/2010.13152)


  Neural networks have achieved remarkable successes in machine learning tasks.
This has recently been extended to graph learning using neural networks.
However, there is limited theoretical work in understanding how and when they
perform well, especially relative to established statistical learning
techniques such as spectral embedding. In this short paper, we present a simple
generative model where unsupervised graph convolutional network fails, while
the adjacency spectral embedding succeeds. Specifically, unsupervised graph
convolutional network is unable to look beyond the first eigenvector in certain
approximately regular graphs, thus missing inference signals in non-leading
eigenvectors. The phenomenon is demonstrated by visual illustrations and
comprehensive simulations.

    

### [[2012.06743] Are We Ready For Learned Cardinality Estimation?](http://arxiv.org/abs/2012.06743)


  Cardinality estimation is a fundamental but long unresolved problem in query
optimization. Recently, multiple papers from different research groups
consistently report that learned models have the potential to replace existing
cardinality estimators. In this paper, we ask a forward-thinking question: Are
we ready to deploy these learned cardinality models in production? Our study
consists of three main parts. Firstly, we focus on the static environment
(i.e., no data updates) and compare five new learned methods with eight
traditional methods on four real-world datasets under a unified workload
setting. The results show that learned models are indeed more accurate than
traditional methods, but they often suffer from high training and inference
costs. Secondly, we explore whether these learned models are ready for dynamic
environments (i.e., frequent data updates). We find that they cannot catch up
with fast data up-dates and return large errors for different reasons. For less
frequent updates, they can perform better but there is no clear winner among
themselves. Thirdly, we take a deeper look into learned models and explore when
they may go wrong. Our results show that the performance of learned methods can
be greatly affected by the changes in correlation, skewness, or domain size.
More importantly, their behaviors are much harder to interpret and often
unpredictable. Based on these findings, we identify two promising research
directions (control the cost of learned models and make learned models
trustworthy) and suggest a number of research opportunities. We hope that our
study can guide researchers and practitioners to work together to eventually
push learned cardinality estimators into real database systems.

    

### [[2101.04185] PEng4NN: An Accurate Performance Estimation Engine for Efficient Automated Neural Network Architecture Search](http://arxiv.org/abs/2101.04185)


  Neural network (NN) models are increasingly used in scientific simulations,
AI, and other high performance computing (HPC) fields to extract knowledge from
datasets. Each dataset requires tailored NN model architecture, but designing
structures by hand is a time-consuming and error-prone process. Neural
architecture search (NAS) automates the design of NN architectures. NAS
attempts to find well-performing NN models for specialized datsets, where
performance is measured by key metrics that capture the NN capabilities (e.g.,
accuracy of classification of samples in a dataset). Existing NAS methods are
resource intensive, especially when searching for highly accurate models for
larger and larger datasets.
To address this problem, we propose a performance estimation strategy that
reduces the resources for training NNs and increases NAS throughput without
jeopardizing accuracy. We implement our strategy via an engine called PEng4NN
that plugs into existing NAS methods; in doing so, PEng4NN predicts the final
accuracy of NNs early in the training process, informs the NAS of NN
performance, and thus enables the NAS to terminate training NNs early. We
assess our engine on three diverse datasets (i.e., CIFAR-100, Fashion MNIST,
and SVHN). By reducing the training epochs needed, our engine achieves
substantial throughput gain; on average, our engine saves 61% to 82% of
training epochs, increasing throughput by a factor of 2.5 to 5 compared to a
state-of-the-art NAS method. We achieve this gain without compromising
accuracy, as we demonstrate with two key outcomes. First, across all our tests,
between 74% and 97% of the ground truth best models lie in our set of predicted
best models. Second, the accuracy distributions of the ground truth best models
and our predicted best models are comparable, with the mean accuracy values
differing by at most .7 percentage points across all tests.

    

### [[2101.11427] One Model to Serve All: Star Topology Adaptive Recommender for Multi-Domain CTR Prediction](http://arxiv.org/abs/2101.11427)


  Traditional industrial recommenders are usually trained on a single business
domain and then serve for this domain. However, in large commercial platforms,
it is often the case that the recommenders need to make click-through rate
(CTR) predictions for multiple business domains. Different domains have
overlapping user groups and items. Thus, there exist commonalities. Since the
specific user groups have disparity and the user behaviors may change in
various business domains, there also have distinctions. The distinctions result
in domain-specific data distributions, making it hard for a single shared model
to work well on all domains. To learn an effective and efficient CTR model to
handle multiple domains simultaneously, we present Star Topology Adaptive
Recommender (STAR). Concretely, STAR has the star topology, which consists of
the shared centered parameters and domain-specific parameters. The shared
parameters are applied to learn commonalities of all domains, and the
domain-specific parameters capture domain distinction for more refined
prediction. Given requests from different business domains, STAR can adapt its
parameters conditioned on the domain characteristics. The experimental result
from production data validates the superiority of the proposed STAR model.
Since 2020, STAR has been deployed in the display advertising system of
Alibaba, obtaining averaging 8.0% improvement on CTR and 6.0% on RPM (Revenue
Per Mille).

    

### [[2102.05312] Improved Algorithms for Efficient Active Learning Halfspaces with Massart and Tsybakov noise](http://arxiv.org/abs/2102.05312)


  We give a computationally-efficient PAC active learning algorithm for
$d$-dimensional homogeneous halfspaces that can tolerate Massart noise (Massart
and Nédélec, 2006) and Tsybakov noise (Tsybakov, 2004). Specialized to the
$\eta$-Massart noise setting, our algorithm achieves an
information-theoretically near-optimal label complexity of $\tilde{O}\left(
\frac{d}{(1-2\eta)^2} \mathrm{polylog}(\frac1\epsilon) \right)$ under a wide
range of unlabeled data distributions (specifically, the family of "structured
distributions" defined in Diakonikolas et al. (2020)). Under the more
challenging Tsybakov noise condition, we identify two subfamilies of noise
conditions, under which our efficient algorithm provides label complexity
guarantees strictly lower than passive learning algorithms.

    

### [[2102.10458] Efficient Learning of Non-Interacting Fermion Distributions](http://arxiv.org/abs/2102.10458)


  We give an efficient classical algorithm that recovers the distribution of a
non-interacting fermion state over the computational basis. For a system of $n$
non-interacting fermions and $m$ modes, we show that $O(m^2 n^4 \log(m/\delta)/
\varepsilon^4)$ samples and $O(m^4 n^4 \log(m/\delta)/ \varepsilon^4)$ time are
sufficient to learn the original distribution to total variation distance
$\varepsilon$ with probability $1 - \delta$. Our algorithm empirically
estimates the one- and two-mode correlations and uses them to reconstruct a
succinct description of the entire distribution efficiently.

    

### [[2102.11673] Measuring Data Leakage in Machine-Learning Models with Fisher Information](http://arxiv.org/abs/2102.11673)


  Machine-learning models contain information about the data they were trained
on. This information leaks either through the model itself or through
predictions made by the model. Consequently, when the training data contains
sensitive attributes, assessing the amount of information leakage is paramount.
We propose a method to quantify this leakage using the Fisher information of
the model about the data. Unlike the worst-case a priori guarantees of
differential privacy, Fisher information loss measures leakage with respect to
specific examples, attributes, or sub-populations within the dataset. We
motivate Fisher information loss through the Cramér-Rao bound and delineate
the implied threat model. We provide efficient methods to compute Fisher
information loss for output-perturbed generalized linear models. Finally, we
empirically validate Fisher information loss as a useful measure of information
leakage.

    

### [[2103.01291] Generative Particle Variational Inference via Estimation of Functional Gradients](http://arxiv.org/abs/2103.01291)


  Recently, particle-based variational inference (ParVI) methods have gained
interest because they can avoid arbitrary parametric assumptions that are
common in variational inference. However, many ParVI approaches do not allow
arbitrary sampling from the posterior, and the few that do allow such sampling
suffer from suboptimality. This work proposes a new method for learning to
approximately sample from the posterior distribution. We construct a neural
sampler that is trained with the functional gradient of the KL-divergence
between the empirical sampling distribution and the target distribution,
assuming the gradient resides within a reproducing kernel Hilbert space. Our
generative ParVI (GPVI) approach maintains the asymptotic performance of ParVI
methods while offering the flexibility of a generative sampler. Through
carefully constructed experiments, we show that GPVI outperforms previous
generative ParVI methods such as amortized SVGD, and is competitive with ParVI
as well as gold-standard approaches like Hamiltonian Monte Carlo for fitting
both exactly known and intractable target distributions.

    

### [[2103.12564] Linear Constraints Learning for Spiking Neurons](http://arxiv.org/abs/2103.12564)


  We introduce a new supervised learning algorithm based to train spiking
neural networks for classification. The algorithm overcomes a limitation of
existing multi-spike learning methods: it solves the problem of interference
between interacting output spikes during a learning trial. This problem of
learning interference causes learning performance in existing approaches to
decrease as the number of output spikes increases, and represents an important
limitation in existing multi-spike learning approaches. We address learning
interference by introducing a novel mechanism to balance the magnitudes of
weight adjustments during learning, which in theory allows every spike to
simultaneously converge to their desired timings. Our results indicate that our
method achieves significantly higher memory capacity and faster convergence
compared to existing approaches for multi-spike classification. In the
ubiquitous Iris and MNIST datasets, our algorithm achieves competitive
predictive performance with state-of-the-art approaches.

    

### [[2104.05859] Rapid Exploration for Open-World Navigation with Latent Goal Models](http://arxiv.org/abs/2104.05859)


  We describe a robotic learning system for autonomous exploration and
navigation in diverse, open-world environments. At the core of our method is a
learned latent variable model of distances and actions, along with a
non-parametric topological memory. We use an information bottleneck to
regularize the learned policy, giving us (i) a compact visual representation of
goals, (ii) improved generalization capabilities, and (iii) a mechanism for
sampling feasible goals for exploration. Trained on a large offline dataset of
prior experience, the model acquires a representation of visual goals that is
robust to task-irrelevant distractors. We demonstrate our method on a mobile
ground robot in open-world exploration scenarios. Given an image of a goal that
is up to 80 meters away, our method leverages its representation to explore and
discover the goal in under 20 minutes, even amidst previously-unseen obstacles
and weather conditions. We encourage the reader to visit the project website
for videos of our experiments and demonstrations
this https URL


### [[2104.07658] Self-supervised Video Object Segmentation by Motion Grouping](http://arxiv.org/abs/2104.07658)


  Animals have evolved highly functional visual systems to understand motion,
assisting perception even under complex environments. In this paper, we work
towards developing a computer vision system able to segment objects by
exploiting motion cues, i.e. motion segmentation. We make the following
contributions: First, we introduce a simple variant of the Transformer to
segment optical flow frames into primary objects and the background. Second, we
train the architecture in a self-supervised manner, i.e. without using any
manual annotations. Third, we analyze several critical components of our method
and conduct thorough ablation studies to validate their necessity. Fourth, we
evaluate the proposed architecture on public benchmarks (DAVIS2016, SegTrackv2,
and FBMS59). Despite using only optical flow as input, our approach achieves
superior or comparable results to previous state-of-the-art self-supervised
methods, while being an order of magnitude faster. We additionally evaluate on
a challenging camouflage dataset (MoCA), significantly outperforming the other
self-supervised approaches, and comparing favourably to the top supervised
approach, highlighting the importance of motion cues, and the potential bias
towards visual appearance in existing video segmentation models.

    

### [[2104.08044] Holmes: An Efficient and Lightweight Semantic Based Anomalous Email Detector](http://arxiv.org/abs/2104.08044)


  Email threat is a serious issue for enterprise security, which consists of
various malicious scenarios, such as phishing, fraud, blackmail and
malvertisement. Traditional anti-spam gateway commonly requires to maintain a
greylist to filter out unexpected emails based on suspicious vocabularies
existed in the mail subject and content. However, the signature-based approach
cannot effectively discover novel and unknown suspicious emails that utilize
various hot topics at present, such as COVID-19 and US election. To address the
problem, in this paper, we present Holmes, an efficient and lightweight
semantic based engine for anomalous email detection. Holmes can convert each
event log of email to a sentence through word embedding then extract
interesting items among them by novelty detection. Based on our observations,
we claim that, in an enterprise environment, there is a stable relation between
senders and receivers, but suspicious emails are commonly from unusual sources,
which can be detected through the rareness selection. We evaluate the
performance of Holmes in a real-world enterprise environment, in which it sends
and receives around 5,000 emails each day. As a result, Holmes can achieve a
high detection rate (output around 200 suspicious emails per day) and maintain
a low false alarm rate for anomaly detection.

    

### [[2105.04321] Reinforcement learning of rare diffusive dynamics](http://arxiv.org/abs/2105.04321)


  We present a method to probe rare molecular dynamics trajectories directly
using reinforcement learning. We consider trajectories that are conditioned to
transition between regions of configuration space in finite time, like those
relevant in the study of reactive events, as well as trajectories exhibiting
rare fluctuations of time-integrated quantities in the long time limit, like
those relevant in the calculation of large deviation functions. In both cases,
reinforcement learning techniques are used to optimize an added force that
minimizes the Kullback-Leibler divergence between the conditioned trajectory
ensemble and a driven one. Under the optimized added force, the system evolves
the rare fluctuation as a typical one, affording a variational estimate of its
likelihood in the original trajectory ensemble. Low variance gradients
employing value functions are proposed to increase the convergence of the
optimal force. The method we develop employing these gradients leads to
efficient and accurate estimates of both the optimal force and the likelihood
of the rare event for a variety of model systems.

    

### [[2105.06887] A Frequency Domain Constraint for Synthetic and Real X-ray Image Super Resolution](http://arxiv.org/abs/2105.06887)


  Synthetic X-ray images are simulated X-ray images projected from CT data.
High-quality synthetic X-ray images can facilitate various applications such as
surgical image guidance systems and VR training simulations. However, it is
difficult to produce high-quality arbitrary view synthetic X-ray images in
real-time due to different CT slice thickness, high computational cost, and the
complexity of algorithms. Our goal is to generate high-resolution synthetic
X-ray images in real-time by upsampling low-resolution images with deep
learning-based super-resolution methods. Reference-based Super Resolution
(RefSR) has been well studied in recent years and has shown higher performance
than traditional Single Image Super-Resolution (SISR). It can produce fine
details by utilizing the reference image but still inevitably generates some
artifacts and noise. In this paper, we introduce frequency domain loss as a
constraint to further improve the quality of the RefSR results with fine
details and without obvious artifacts. To the best of our knowledge, this is
the first paper utilizing the frequency domain for the loss functions in the
field of super-resolution. We achieved good results in evaluating our method on
both synthetic and real X-ray image datasets.

    

### [[2105.12208] A Domain-Oblivious Approach for Learning Concise Representations of Filtered Topological Spaces for Clustering](http://arxiv.org/abs/2105.12208)


  Persistence diagrams have been widely used to quantify the underlying
features of filtered topological spaces in data visualization. In many
applications, computing distances between diagrams is essential; however,
computing these distances has been challenging due to the computational cost.
In this paper, we propose a persistence diagram hashing framework that learns a
binary code representation of persistence diagrams, which allows for fast
computation of distances. This framework is built upon a generative adversarial
network (GAN) with a diagram distance loss function to steer the learning
process. Instead of using standard representations, we hash diagrams into
binary codes, which have natural advantages in large-scale tasks. The training
of this model is domain-oblivious in that it can be computed purely from
synthetic, randomly created diagrams. As a consequence, our proposed method is
directly applicable to various datasets without the need for retraining the
model. These binary codes, when compared using fast Hamming distance, better
maintain topological similarity properties between datasets than other
vectorized representations. To evaluate this method, we apply our framework to
the problem of diagram clustering and we compare the quality and performance of
our approach to the state-of-the-art. In addition, we show the scalability of
our approach on a dataset with 10k persistence diagrams, which is not possible
with current techniques. Moreover, our experimental results demonstrate that
our method is significantly faster with the potential of less memory usage,
while retaining comparable or better quality comparisons.

    

### [[2105.13913] Simple steps are all you need: Frank-Wolfe and generalized self-concordant functions](http://arxiv.org/abs/2105.13913)


  Generalized self-concordance is a key property present in the objective
function of many important learning problems. We establish the convergence rate
of a simple Frank-Wolfe variant that uses the open-loop step size strategy
$\gamma_t = 2/(t+2)$, obtaining a $\mathcal{O}(1/t)$ convergence rate for this
class of functions in terms of primal gap and Frank-Wolfe gap, where $t$ is the
iteration count. This avoids the use of second-order information or the need to
estimate local smoothness parameters of previous work. We also show improved
convergence rates for various common cases, e.g., when the feasible region
under consideration is uniformly convex or polyhedral.

    

### [[2105.14573] Embedding Principle of Loss Landscape of Deep Neural Networks](http://arxiv.org/abs/2105.14573)


  Understanding the structure of loss landscape of deep neural networks
(DNNs)is obviously important. In this work, we prove an embedding principle
that the loss landscape of a DNN "contains" all the critical points of all the
narrower DNNs. More precisely, we propose a critical embedding such that any
critical point, e.g., local or global minima, of a narrower DNN can be embedded
to a critical point/hyperplane of the target DNN with higher degeneracy and
preserving the DNN output function. The embedding structure of critical points
is independent of loss function and training data, showing a stark difference
from other nonconvex problems such as protein-folding. Empirically, we find
that a wide DNN is often attracted by highly-degenerate critical points that
are embedded from narrow DNNs. The embedding principle provides an explanation
for the general easy optimization of wide DNNs and unravels a potential
implicit low-complexity regularization during the training. Overall, our work
provides a skeleton for the study of loss landscape of DNNs and its
implication, by which a more exact and comprehensive understanding can be
anticipated in the near

    

### [[2106.00808] Invariant Policy Learning: A Causal Perspective](http://arxiv.org/abs/2106.00808)


  In the past decade, contextual bandit and reinforcement learning algorithms
have been successfully used in various interactive learning systems such as
online advertising, recommender systems, and dynamic pricing. However, they
have yet to be widely adopted in high-stakes application domains, such as
healthcare. One reason may be that existing approaches assume that the
underlying mechanisms are static in the sense that they do not change over
different environments. In many real world systems, however, the mechanisms are
subject to shifts across environments which may invalidate the static
environment assumption. In this paper, we tackle the problem of environmental
shifts under the framework of offline contextual bandits. We view the
environmental shift problem through the lens of causality and propose
multi-environment contextual bandits that allow for changes in the underlying
mechanisms. We adopt the concept of invariance from the causality literature
and introduce the notion of policy invariance. We argue that policy invariance
is only relevant if unobserved confounders are present and show that, in that
case, an optimal invariant policy is guaranteed to generalize across
environments under suitable assumptions. Our results may be a first step
towards solving the environmental shift problem. They also establish concrete
connections among causality, invariance and contextual bandits.

    

### [[2106.08382] DMSANet: Dual Multi Scale Attention Network](http://arxiv.org/abs/2106.08382)


  Attention mechanism of late has been quite popular in the computer vision
community. A lot of work has been done to improve the performance of the
network, although almost always it results in increased computational
complexity. In this paper, we propose a new attention module that not only
achieves the best performance but also has lesser parameters compared to most
existing models. Our attention module can easily be integrated with other
convolutional neural networks because of its lightweight nature. The proposed
network named Dual Multi Scale Attention Network (DMSANet) is comprised of two
parts: the first part is used to extract features at various scales and
aggregate them, the second part uses spatial and channel attention modules in
parallel to adaptively integrate local features with their global dependencies.
We benchmark our network performance for Image Classification on ImageNet
dataset, Object Detection and Instance Segmentation both on MS COCO dataset.

    

### [[2108.05023] Taming Process Variations in CNFET for Efficient Last Level Cache Design](http://arxiv.org/abs/2108.05023)


  Carbon nanotube field-effect transistors (CNFET) emerge as a promising
alternative to CMOS transistors for the much higher speed and energy
efficiency, which makes the technology particularly suitable for building the
energy-hungry last level cache (LLC). However, the process variations (PVs) in
CNFET caused by the imperfect fabrication lead to large timing variation and
the worst-case timing dramatically limits the LLC operation speed.
Particularly, we observe that the CNFET-based cache latency distribution is
closely related to the LLC layouts. For the two typical LLC layouts that have
the CNT growth direction aligned to the cache way direction and cache set
direction respectively, we proposed variation-aware set aligned (VASA) cache
and variation-aware way aligned (VAWA) cache in combination with corresponding
cache optimizations such as data shuffling and page mapping to enable
low-latency cache for frequently used data. According to our experiments, the
optimized LLC reduces the average access latency by 32% and 45% compared to the
baseline designs on the two different CNFET layouts respectively while it
improves the overall performance by 6\% and 9\% and reduces the energy
consumption by 4% and 8% respectively. In addition, with both the architecture
induced latency variation and PV incurred latency variation considered in a
unified model, we extended the VAWA and VASA cache design for the CNFET-based
NUCA and the proposed NUCA achieves both significant performance improvement
and energy saving compared to the straightforward variation-aware NUCA.

    

### [[2010.10233] Eliminating the Barriers: Demystifying Wi-Fi Baseband Design and Introducing the PicoScenes Wi-Fi Sensing Platform](http://arxiv.org/abs/2010.10233)


  The research on Wi-Fi sensing has been thriving over the past decade but the
process has not been smooth. Three barriers always hamper the research: unknown
baseband design and its influence, inadequate hardware, and the lack of
versatile and flexible measurement software. This paper tries to eliminate
these barriers through the following work. First, we present an in-depth study
of the baseband design of the Qualcomm Atheros AR9300 (QCA9300) NIC. We
identify a missing item of the existing CSI model, namely, the CSI distortion,
and identify the baseband filter as its origin. We also propose a distortion
removal method. Second, we reintroduce both the QCA9300 and software-defined
radio (SDR) as powerful hardware for research. For the QCA9300, we unlock the
arbitrary tuning of both the carrier frequency and bandwidth. For SDR, we
develop a high?performance software implementation of the 802.11a/g/n/ac/ax
baseband, allowing users to fully control the baseband and access the complete
physical-layer information. Third, we release the PicoScenes software, which
supports concurrent CSI measure?ment from multiple QCA9300, Intel Wireless Link
(IWL5300) and SDR hardware. PicoScenes features rich low-level controls, packet
injection and software baseband implementation. It also allows users to develop
their own measurement plugins. Finally, we report state-of-the-art results in
the extensive evaluations of the PicoScenes system, such as the >2 GHz
available spectrum on the QCA9300, concurrent CSI measurement, and up to 40 kHz
and 1 kHz CSI measurement rates achieved by the QCA9300 and SDR. PicoScenes is
available at this https URL.

    

### [[2108.05236] A Limitlessly Scalable Transaction System](http://arxiv.org/abs/2108.05236)


  We present Accept, a simple, asynchronous transaction system that achieves
perfect horizontal scaling.
Usual blockchain-based transaction systems come with a fundamental throughput
limitation as they require that all (potentially unrelated) transactions must
be totally ordered. Such solutions thus require serious compromises or are
outright unsuitable for large-scale applications, such as global retail
payments.
Accept provides efficient horizontal scaling without any limitation. To that
end, Accept satisfies a relaxed form of consensus and does not establish an
ordering of unrelated transactions. Furthermore, Accept achieves instant
finality and does not depend on a source of randomness.

    

### [[2009.14123] Communication Lower-Bounds for Distributed-Memory Computations for Mass Spectrometry based Omics Data](http://arxiv.org/abs/2009.14123)


  Mass spectrometry (MS) based omics data analysis require significant time and
resources. To date, few parallel algorithms have been proposed for deducing
peptides from mass spectrometry-based data. However, these parallel algorithms
were designed, and developed when the amount of data that needed to be
processed was smaller in scale. In this paper, we prove that the communication
bound that is reached by the \emph{existing} parallel algorithms is
$\Omega(mn+2r\frac{q}{p})$, where $m$ and $n$ are the dimensions of the
theoretical database matrix, $q$ and $r$ are dimensions of spectra, and $p$ is
the number of processors. We further prove that communication-optimal strategy
with fast-memory $\sqrt{M} = mn + \frac{2qr}{p}$ can achieve
$\Omega({\frac{2mnq}{p}})$ but is not achieved by any existing parallel
proteomics algorithms till date. To validate our claim, we performed a
meta-analysis of published parallel algorithms, and their performance results.
We show that sub-optimal speedups with increasing number of processors is a
direct consequence of not achieving the communication lower-bounds. We further
validate our claim by performing experiments which demonstrate the
communication bounds that are proved in this paper. Consequently, we assert
that next-generation of \emph{provable}, and demonstrated superior parallel
algorithms are urgently needed for MS based large systems-biology studies
especially for meta-proteomics, proteogenomic, microbiome, and proteomics for
non-model organisms. Our hope is that this paper will excite the parallel
computing community to further investigate parallel algorithms for highly
influential MS based omics problems.

    

### [[2101.04766] Privacy-Preserving Randomized Controlled Trials: A Protocol for Industry Scale Deployment](http://arxiv.org/abs/2101.04766)


  In this paper, we outline a way to deploy a privacy-preserving protocol for
multiparty Randomized Controlled Trials on the scale of 500 million rows of
data and more than a billion gates. Randomized Controlled Trials (RCTs) are
widely used to improve business and policy decisions in various sectors such as
healthcare, education, criminology, and marketing. A Randomized Controlled
Trial is a scientifically rigorous method to measure the effectiveness of a
treatment. This is accomplished by randomly allocating subjects to two or more
groups, treating them differently, and then comparing the outcomes across
groups. In many scenarios, multiple parties hold different parts of the data
for conducting and analyzing RCTs. Given privacy requirements and expectations
of each of these parties, it is often challenging to have a centralized store
of data to conduct and analyze RCTs.
We accomplish this by a three-stage solution. The first stage uses the
Private Secret Share Set Intersection (PS$^3$I) solution to create a joined set
and establish secret shares without revealing membership, while discarding
individuals who were placed into more than one group. The second stage runs
multiple instances of a general purpose MPC over a sharded database to
aggregate statistics about each experimental group while discarding individuals
who took an action before they received treatment. The third stage adds
distributed and calibrated Differential Privacy (DP) noise to the aggregate
statistics and uncertainty measures, providing formal two-sided privacy
guarantees.
We also evaluate the performance of multiple open source general purpose MPC
libraries for this task. We additionally demonstrate how we have used this to
create a working ads effectiveness measurement product capable of measuring
hundreds of millions of individuals per experiment.

    

### [[2108.04862] Matching Algorithms for Blood Donation](http://arxiv.org/abs/2108.04862)


  Global demand for donated blood far exceeds supply, and unmet need is
greatest in low- and middle-income countries; experts suggest that large-scale
coordination is necessary to alleviate demand. Using the Facebook Blood
Donation tool, we conduct the first large-scale algorithmic matching of blood
donors with donation opportunities. While measuring actual donation rates
remains a challenge, we measure donor action (e.g., making a donation
appointment) as a proxy for actual donation. We develop automated policies for
matching patients and donors, based on an online matching model. We provide
theoretical guarantees for these policies, both regarding the number of
expected donations and the equitable treatment of blood recipients. In
simulations, a simple matching strategy increases the number of donations by
5-10%; a pilot experiment with real donors shows a 5% relative increase in
donor action rate (from 3.7% to 3.9%). When scaled to the global Blood Donation
tool user base, this corresponds to an increase of around one hundred thousand
users taking action toward donation. Further, observing donor action on a
social network can shed light onto donor behavior and response to incentives.
Our initial findings align with several observations made in the medical and
social science literature regarding donor behavior.

    

### [[2108.04938] BERTHop: An Effective Vision-and-Language Model for Chest X-ray Disease Diagnosis](http://arxiv.org/abs/2108.04938)


  Vision-and-language(V&L) models take image and text as input and learn to
capture the associations between them. Prior studies show that pre-trained V&L
models can significantly improve the model performance for downstream tasks
such as Visual Question Answering (VQA). However, V&L models are less effective
when applied in the medical domain (e.g., on X-ray images and clinical notes)
due to the domain gap. In this paper, we investigate the challenges of applying
pre-trained V&L models in medical applications. In particular, we identify that
the visual representation in general V&L models is not suitable for processing
medical data. To overcome this limitation, we propose BERTHop, a
transformer-based model based on PixelHop++ and VisualBERT, for better
capturing the associations between the two modalities. Experiments on the OpenI
dataset, a commonly used thoracic disease diagnosis benchmark, show that
BERTHop achieves an average Area Under the Curve (AUC) of 98.12% which is 1.62%
higher than state-of-the-art (SOTA) while it is trained on a 9 times smaller
dataset.

    

### [[2108.04940] Knowledge-Based Stable Roommates Problem: A Real-World Application](http://arxiv.org/abs/2108.04940)


  The Stable Roommates problem with Ties and Incomplete lists (SRTI) is a
matching problem characterized by the preferences of agents over other agents
as roommates, where the preferences may have ties or be incomplete. SRTI asks
for a matching that is stable and, sometimes, optimizes a domain-independent
fairness criterion (e.g., Egalitarian). However, in real-world applications
(e.g., assigning students as roommates at a dormitory), we usually consider a
variety of domain-specific criteria depending on preferences over the habits
and desires of the agents. With this motivation, we introduce a knowledge-based
method to SRTI considering domain-specific knowledge, and investigate its
real-world application for assigning students as roommates at a university
dormitory. This paper is under consideration for acceptance in Theory and
Practice of Logic Programming (TPLP).

    

### [[2108.05008] Robust Feature Learning on Long-Duration Sounds for Acoustic Scene Classification](http://arxiv.org/abs/2108.05008)


  Acoustic scene classification (ASC) aims to identify the type of scene
(environment) in which a given audio signal is recorded. The log-mel feature
and convolutional neural network (CNN) have recently become the most popular
time-frequency (TF) feature representation and classifier in ASC. An audio
signal recorded in a scene may include various sounds overlapping in time and
frequency. The previous study suggests that separately considering the
long-duration sounds and short-duration sounds in CNN may improve ASC accuracy.
This study addresses the problem of the generalization ability of acoustic
scene classifiers. In practice, acoustic scene signals' characteristics may be
affected by various factors, such as the choice of recording devices and the
change of recording locations. When an established ASC system predicts scene
classes on audios recorded in unseen scenarios, its accuracy may drop
significantly. The long-duration sounds not only contain domain-independent
acoustic scene information, but also contain channel information determined by
the recording conditions, which is prone to over-fitting. For a more robust ASC
system, We propose a robust feature learning (RFL) framework to train the CNN.
The RFL framework down-weights CNN learning specifically on long-duration
sounds. The proposed method is to train an auxiliary classifier with only
long-duration sound information as input. The auxiliary classifier is trained
with an auxiliary loss function that assigns less learning weight to poorly
classified examples than the standard cross-entropy loss. The experimental
results show that the proposed RFL framework can obtain a more robust acoustic
scene classifier towards unseen devices and cities.

    

### [[2108.05015] VisEvent: Reliable Object Tracking via Collaboration of Frame and Event Flows](http://arxiv.org/abs/2108.05015)


  Different from visible cameras which record intensity images frame by frame,
the biologically inspired event camera produces a stream of asynchronous and
sparse events with much lower latency. In practice, the visible cameras can
better perceive texture details and slow motion, while event cameras can be
free from motion blurs and have a larger dynamic range which enables them to
work well under fast motion and low illumination. Therefore, the two sensors
can cooperate with each other to achieve more reliable object tracking. In this
work, we propose a large-scale Visible-Event benchmark (termed VisEvent) due to
the lack of a realistic and scaled dataset for this task. Our dataset consists
of 820 video pairs captured under low illumination, high speed, and background
clutter scenarios, and it is divided into a training and a testing subset, each
of which contains 500 and 320 videos, respectively. Based on VisEvent, we
transform the event flows into event images and construct more than 30 baseline
methods by extending current single-modality trackers into dual-modality
versions. More importantly, we further build a simple but effective tracking
algorithm by proposing a cross-modality transformer, to achieve more effective
feature fusion between visible and event data. Extensive experiments on the
proposed VisEvent dataset, and two simulated datasets (i.e., OTB-DVS and
VOT-DVS), validated the effectiveness of our model. The dataset and source code
will be available at our project page:
\url{this https URL}.

    

### [[2108.05020] Frequency-based tension assessment of an inclined cable with complex boundary conditions using the PSO algorithm](http://arxiv.org/abs/2108.05020)


  The frequency-based method is the most commonly used method for measuring
cable tension. However, the calculation formulas for the conventional
frequency-based method are generally based on the ideally hinged or fixed
boundary conditions without a comprehensive consideration of the inclination
angle, sag-extensibility, and flexural stiffness of cables, leading to a
significant error in cable tension identification. This study aimed to propose
a frequency-based method of cable tension identification considering the
complex boundary conditions at the two ends of cables using the particle swarm
optimization (PSO) algorithm. First, the refined stay cable model was
established considering the inclination angle, flexural stiffness, and
sag-extensibility, as well as the rotational constraint stiffness and lateral
support stiffness for the unknown boundaries of cables. The vibration mode
equation of the stay cable model was discretized and solved using the finite
difference method. Then, a multiparameter identification method based on the
PSO algorithm was proposed. This method was able to identify the tension,
flexural stiffness, axial stiffness, boundary rotational constraint stiffness,
and boundary lateral support stiffness according to the measured multiorder
frequencies in a synchronous manner. The feasibility and accuracy of this
method were validated through numerical cases. Finally, the proposed approach
was applied to the tension identification of the anchor span strands of a
suspension bridge (Jindong Bridge) in China. The results of cable tension
identification using the proposed method and the existing methods discussed in
previous studies were compared with the on-site pressure ring measurement
results. The comparison showed that the proposed approach had a high accuracy
in cable tension identification.

    

### [[2108.05036] DEMix Layers: Disentangling Domains for Modular Language Modeling](http://arxiv.org/abs/2108.05036)


  We introduce a new domain expert mixture (DEMix) layer that enables
conditioning a language model (LM) on the domain of the input text. A DEMix
layer is a collection of expert feedforward networks, each specialized to a
domain, that makes the LM modular: experts can be mixed, added or removed after
initial training. Extensive experiments with autoregressive transformer LMs (up
to 1.3B parameters) show that DEMix layers reduce test-time perplexity,
increase training efficiency, and enable rapid adaptation with little overhead.
We show that mixing experts during inference, using a parameter-free weighted
ensemble, allows the model to better generalize to heterogeneous or unseen
domains. We also show that experts can be added to iteratively incorporate new
domains without forgetting older ones, and that experts can be removed to
restrict access to unwanted domains, without additional training. Overall,
these results demonstrate benefits of explicitly conditioning on textual
domains during language modeling.

    

### [[2108.05054] Rethinking Coarse-to-Fine Approach in Single Image Deblurring](http://arxiv.org/abs/2108.05054)


  Coarse-to-fine strategies have been extensively used for the architecture
design of single image deblurring networks. Conventional methods typically
stack sub-networks with multi-scale input images and gradually improve
sharpness of images from the bottom sub-network to the top sub-network,
yielding inevitably high computational costs. Toward a fast and accurate
deblurring network design, we revisit the coarse-to-fine strategy and present a
multi-input multi-output U-net (MIMO-UNet). The MIMO-UNet has three distinct
features. First, the single encoder of the MIMO-UNet takes multi-scale input
images to ease the difficulty of training. Second, the single decoder of the
MIMO-UNet outputs multiple deblurred images with different scales to mimic
multi-cascaded U-nets using a single U-shaped network. Last, asymmetric feature
fusion is introduced to merge multi-scale features in an efficient manner.
Extensive experiments on the GoPro and RealBlur datasets demonstrate that the
proposed network outperforms the state-of-the-art methods in terms of both
accuracy and computational complexity. Source code is available for research
purposes at this https URL.

    

### [[2108.05060] MultiTask-CenterNet (MCN): Efficient and Diverse Multitask Learning using an Anchor Free Approach](http://arxiv.org/abs/2108.05060)


  Multitask learning is a common approach in machine learning, which allows to
train multiple objectives with a shared architecture. It has been shown that by
training multiple tasks together inference time and compute resources can be
saved, while the objectives performance remains on a similar or even higher
level. However, in perception related multitask networks only closely related
tasks can be found, such as object detection, instance and semantic
segmentation or depth estimation. Multitask networks with diverse tasks and
their effects with respect to efficiency on one another are not well studied.
In this paper we augment the CenterNet anchor-free approach for training
multiple diverse perception related tasks together, including the task of
object detection and semantic segmentation as well as human pose estimation. We
refer to this DNN as Multitask-CenterNet (MCN). Additionally, we study
different MCN settings for efficiency. The MCN can perform several tasks at
once while maintaining, and in some cases even exceeding, the performance
values of its corresponding single task networks. More importantly, the MCN
architecture decreases inference time and reduces network size when compared to
a composition of single task networks.

    

### [[2108.05061] NI-UDA: Graph Adversarial Domain Adaptation from Non-shared-and-Imbalanced Big Data to Small Imbalanced Applications](http://arxiv.org/abs/2108.05061)


  We propose a new general Graph Adversarial Domain Adaptation (GADA) based on
semantic knowledge reasoning of class structure for solving the problem of
unsupervised domain adaptation (UDA) from the big data with non-shared and
imbalanced classes to specified small and imbalanced applications (NI-UDA),
where non-shared classes mean the label space out of the target domain. Our
goal is to leverage priori hierarchy knowledge to enhance domain adversarial
aligned feature representation with graph reasoning. In this paper, to address
two challenges in NI-UDA, we equip adversarial domain adaptation with Hierarchy
Graph Reasoning (HGR) layer and the Source Classifier Filter (SCF). For sparse
classes transfer challenge, our HGR layer can aggregate local feature to
hierarchy graph nodes by node prediction and enhance domain adversarial aligned
feature with hierarchy graph reasoning for sparse classes. Our HGR contributes
to learn direct semantic patterns for sparse classes by hierarchy attention in
self-attention, non-linear mapping and graph normalization. our SCF is proposed
for the challenge of knowledge sharing from non-shared data without negative
transfer effect by filtering low-confidence non-shared data in HGR layer.
Experiments on two benchmark datasets show our GADA methods consistently
improve the state-of-the-art adversarial UDA algorithms, e.g. GADA(HGR) can
greatly improve f1 of the MDD by \textbf{7.19\%} and GVB-GD by \textbf{7.89\%}
respectively on imbalanced source task in Meal300 dataset. The code is
available at this https URL.

    

### [[2108.05064] Variable-Length Music Score Infilling via XLNet and Musically Specialized Positional Encoding](http://arxiv.org/abs/2108.05064)


  This paper proposes a new self-attention based model for music score
infilling, i.e., to generate a polyphonic music sequence that fills in the gap
between given past and future contexts. While existing approaches can only fill
in a short segment with a fixed number of notes, or a fixed time span between
the past and future contexts, our model can infill a variable number of notes
(up to 128) for different time spans. We achieve so with three major technical
contributions. First, we adapt XLNet, an autoregressive model originally
proposed for unsupervised model pre-training, to music score infilling. Second,
we propose a new, musically specialized positional encoding called relative bar
encoding that better informs the model of notes' position within the past and
future context. Third, to capitalize relative bar encoding, we perform
look-ahead onset prediction to predict the onset of a note one time step before
predicting the other attributes of the note. We compare our proposed model with
two strong baselines and show that our model is superior in both objective and
subjective analyses.

    

### [[2108.05081] Cervical Optical Coherence Tomography Image Classification Based on Contrastive Self-Supervised Texture Learning](http://arxiv.org/abs/2108.05081)


  Background: Cervical cancer seriously affects the health of the female
reproductive system. Optical coherence tomography (OCT) emerges as a
non-invasive, high-resolution imaging technology for cervical disease
detection. However, OCT image annotation is knowledge-intensive and
time-consuming, which impedes the training process of deep-learning-based
classification models. Objective: This study aims to develop a computer-aided
diagnosis (CADx) approach to classifying in-vivo cervical OCT images based on
self-supervised learning. Methods: Besides high-level semantic features
extracted by a convolutional neural network (CNN), the proposed CADx approach
leverages unlabeled cervical OCT images' texture features learned by
contrastive texture learning. We conducted ten-fold cross-validation on the OCT
image dataset from a multi-center clinical study on 733 patients from China.
Results: In a binary classification task for detecting high-risk diseases,
including high-grade squamous intraepithelial lesion (HSIL) and cervical
cancer, our method achieved an area-under-the-curve (AUC) value of 0.9798 Plus
or Minus 0.0157 with a sensitivity of 91.17 Plus or Minus 4.99% and a
specificity of 93.96 Plus or Minus 4.72% for OCT image patches; also, it
outperformed two out of four medical experts on the test set. Furthermore, our
method achieved a 91.53% sensitivity and 97.37% specificity on an external
validation dataset containing 287 3D OCT volumes from 118 Chinese patients in a
new hospital using a cross-shaped threshold voting strategy. Conclusion: The
proposed contrastive-learning-based CADx method outperformed the end-to-end CNN
models and provided better interpretability based on texture features, which
holds great potential to be used in the clinical protocol of "see-and-treat."

    

### [[2108.05118] Capture Uncertainties in Deep Neural Networks for Safe Operation of Autonomous Driving Vehicles](http://arxiv.org/abs/2108.05118)


  Uncertainties in Deep Neural Network (DNN)-based perception and vehicle's
motion pose challenges to the development of safe autonomous driving vehicles.
In this paper, we propose a safe motion planning framework featuring the
quantification and propagation of DNN-based perception uncertainties and motion
uncertainties. Contributions of this work are twofold: (1) A Bayesian Deep
Neural network model which detects 3D objects and quantitatively captures the
associated aleatoric and epistemic uncertainties of DNNs; (2) An
uncertainty-aware motion planning algorithm (PU-RRT) that accounts for
uncertainties in object detection and ego-vehicle's motion. The proposed
approaches are validated via simulated complex scenarios built in CARLA.
Experimental results show that the proposed motion planning scheme can cope
with uncertainties of DNN-based perception and vehicle motion, and improve the
operational safety of autonomous vehicles while still achieving desirable
efficiency.

    

### [[2108.05123] Abstractive Sentence Summarization with Guidance of Selective Multimodal Reference](http://arxiv.org/abs/2108.05123)


  Multimodal abstractive summarization with sentence output is to generate a
textual summary given a multimodal triad -- sentence, image and audio, which
has been proven to improve users satisfaction and convenient our life. Existing
approaches mainly focus on the enhancement of multimodal fusion, while ignoring
the unalignment among multiple inputs and the emphasis of different segments in
feature, which has resulted in the superfluity of multimodal interaction. To
alleviate these problems, we propose a Multimodal Hierarchical Selective
Transformer (mhsf) model that considers reciprocal relationships among
modalities (by low-level cross-modal interaction module) and respective
characteristics within single fusion feature (by high-level selective routing
module). In details, it firstly aligns the inputs from different sources and
then adopts a divide and conquer strategy to highlight or de-emphasize
multimodal fusion representation, which can be seen as a sparsely feed-forward
model - different groups of parameters will be activated facing different
segments in feature. We evaluate the generalism of proposed mhsf model with the
pre-trained+fine-tuning and fresh training strategies. And Further experimental
results on MSMO demonstrate that our model outperforms SOTA baselines in terms
of ROUGE, relevance scores and human evaluation.

    

### [[2108.05136] Snakes AI Competition 2020 and 2021 Report](http://arxiv.org/abs/2108.05136)


  The Snakes AI Competition was held by the Innopolis University and was part
of the IEEE Conference on Games2020 and 2021 editions. It aimed to create a
sandbox for learning and implementing artificial intelligence algorithms in
agents in a ludic manner. Competitors of several countries participated in both
editions of the competition, which was streamed to create asynergy between
organizers and the community. The high-quality submissions and the enthusiasm
around the developed framework create an exciting scenario for future
extensions.

    

### [[2108.05145] Prioritized SIPP for Multi-Agent Path Finding With Kinematic Constraints](http://arxiv.org/abs/2108.05145)


  Multi-Agent Path Finding (MAPF) is a long-standing problem in Robotics and
Artificial Intelligence in which one needs to find a set of collision-free
paths for a group of mobile agents (robots) operating in the shared workspace.
Due to its importance, the problem is well-studied and multiple optimal and
approximate algorithms are known. However, many of them abstract away from the
kinematic constraints and assume that the agents can accelerate/decelerate
instantaneously. This complicates the application of the algorithms on the real
robots. In this paper, we present a method that mitigates this issue to a
certain extent. The suggested solver is essentially, a prioritized planner
based on the well-known Safe Interval Path Planning (SIPP) algorithm. Within
SIPP we explicitly reason about the speed and the acceleration thus the
constructed plans directly take kinematic constraints of agents into account.
We suggest a range of heuristic functions for that setting and conduct a
thorough empirical evaluation of the suggested algorithm.

    

### [[2108.05158] Mounting Video Metadata on Transformer-based Language Model for Open-ended Video Question Answering](http://arxiv.org/abs/2108.05158)


  Video question answering has recently received a lot of attention from
multimodal video researchers. Most video question answering datasets are
usually in the form of multiple-choice. But, the model for the multiple-choice
task does not infer the answer. Rather it compares the answer candidates for
picking the correct answer. Furthermore, it makes it difficult to extend to
other tasks. In this paper, we challenge the existing multiple-choice video
question answering by changing it to open-ended video question answering. To
tackle open-ended question answering, we use the pretrained GPT2 model. The
model is fine-tuned with video inputs and subtitles. An ablation study is
performed by changing the existing DramaQA dataset to an open-ended question
answering, and it shows that performance can be improved using video metadata.

    

### [[2108.05165] Stable Marriage Problems with Ties and Incomplete Preferences: An Empirical Comparison of ASP, SAT, ILP, CP, and Local Search Methods](http://arxiv.org/abs/2108.05165)


  We study a variation of the Stable Marriage problem, where every man and
every woman express their preferences as preference lists which may be
incomplete and contain ties. This problem is called the Stable Marriage problem
with Ties and Incomplete preferences (SMTI). We consider three optimization
variants of SMTI, Max Cardinality, Sex-Equal and Egalitarian, and empirically
compare the following methods to solve them: Answer Set Programming, Constraint
Programming, Integer Linear Programming. For Max Cardinality, we compare these
methods with Local Search methods as well. We also empirically compare Answer
Set Programming with Propositional Satisfiability, for SMTI instances. This
paper is under consideration for acceptance in Theory and Practice of Logic
Programming (TPLP).

    

### [[2108.05232] Approximating Defeasible Logics to Improve Scalability](http://arxiv.org/abs/2108.05232)


  Defeasible rules are used in providing computable representations of legal
documents and, more recently, have been suggested as a basis for explainable
AI. Such applications draw attention to the scalability of implementations. The
defeasible logic $DL(\partial_{||})$ was introduced as a more scalable
alternative to $DL(\partial)$, which is better known. In this paper we consider
the use of (implementations of) $DL(\partial_{||})$ as a computational aid to
computing conclusions in $DL(\partial)$ and other defeasible logics, rather
than as an alternative to $DL(\partial)$. We identify conditions under which
$DL(\partial_{||})$ can be substituted for $DL(\partial)$ with no change to the
conclusions drawn, and conditions under which $DL(\partial_{||})$ can be used
to draw some valid conclusions, leaving the remainder to be drawn by
$DL(\partial)$.

    

### [[2108.05266] On the Explanatory Power of Decision Trees](http://arxiv.org/abs/2108.05266)


  Decision trees have long been recognized as models of choice in sensitive
applications where interpretability is of paramount importance. In this paper,
we examine the computational ability of Boolean decision trees in deriving,
minimizing, and counting sufficient reasons and contrastive explanations. We
prove that the set of all sufficient reasons of minimal size for an instance
given a decision tree can be exponentially larger than the size of the input
(the instance and the decision tree). Therefore, generating the full set of
sufficient reasons can be out of reach. In addition, computing a single
sufficient reason does not prove enough in general; indeed, two sufficient
reasons for the same instance may differ on many features. To deal with this
issue and generate synthetic views of the set of all sufficient reasons, we
introduce the notions of relevant features and of necessary features that
characterize the (possibly negated) features appearing in at least one or in
every sufficient reason, and we show that they can be computed in polynomial
time. We also introduce the notion of explanatory importance, that indicates
how frequent each (possibly negated) feature is in the set of all sufficient
reasons. We show how the explanatory importance of a feature and the number of
sufficient reasons can be obtained via a model counting operation, which turns
out to be practical in many cases. We also explain how to enumerate sufficient
reasons of minimal size. We finally show that, unlike sufficient reasons, the
set of all contrastive explanations for an instance given a decision tree can
be derived, minimized and counted in polynomial time.

    

### [[2108.05271] DeliData: A dataset for deliberation in multi-party problem solving](http://arxiv.org/abs/2108.05271)


  Dialogue systems research is traditionally focused on dialogues between two
interlocutors, largely ignoring group conversations. Moreover, most previous
research is focused either on task-oriented dialogue (e.g.\ restaurant
bookings) or user engagement (chatbots), while research on systems for
collaborative dialogues is an under-explored area. To this end, we introduce
the first publicly available dataset containing collaborative conversations on
solving a cognitive task, consisting of 500 group dialogues and 14k utterances.
Furthermore, we propose a novel annotation schema that captures deliberation
cues and release 50 dialogues annotated with it. Finally, we demonstrate the
usefulness of the annotated data in training classifiers to predict the
constructiveness of a conversation. The data collection platform, dataset and
annotated corpus are publicly available at https://delibot.xyz

    

### [[2108.05276] Trading Complexity for Sparsity in Random Forest Explanations](http://arxiv.org/abs/2108.05276)


  Random forests have long been considered as powerful model ensembles in
machine learning. By training multiple decision trees, whose diversity is
fostered through data and feature subsampling, the resulting random forest can
lead to more stable and reliable predictions than a single decision tree. This
however comes at the cost of decreased interpretability: while decision trees
are often easily interpretable, the predictions made by random forests are much
more difficult to understand, as they involve a majority vote over hundreds of
decision trees. In this paper, we examine different types of reasons that
explain "why" an input instance is classified as positive or negative by a
Boolean random forest. Notably, as an alternative to sufficient reasons taking
the form of prime implicants of the random forest, we introduce majoritary
reasons which are prime implicants of a strict majority of decision trees. For
these different abductive explanations, the tractability of the generation
problem (finding one reason) and the minimization problem (finding one shortest
reason) are investigated. Experiments conducted on various datasets reveal the
existence of a trade-off between runtime complexity and sparsity. Sufficient
reasons - for which the identification problem is DP-complete - are slightly
larger than majoritary reasons that can be generated using a simple linear-
time greedy algorithm, and significantly larger than minimal majoritary reasons
that can be approached using an anytime P ARTIAL M AX SAT algorithm.

    

### [[2108.05278] Are Negative Samples Necessary in Entity Alignment? An Approach with High Performance, Scalability and Robustness](http://arxiv.org/abs/2108.05278)


  Entity alignment (EA) aims to find the equivalent entities in different KGs,
which is a crucial step in integrating multiple KGs. However, most existing EA
methods have poor scalability and are unable to cope with large-scale datasets.
We summarize three issues leading to such high time-space complexity in
existing EA methods: (1) Inefficient graph encoders, (2) Dilemma of negative
sampling, and (3) "Catastrophic forgetting" in semi-supervised learning. To
address these challenges, we propose a novel EA method with three new
components to enable high Performance, high Scalability, and high Robustness
(PSR): (1) Simplified graph encoder with relational graph sampling, (2)
Symmetric negative-free alignment loss, and (3) Incremental semi-supervised
learning. Furthermore, we conduct detailed experiments on several public
datasets to examine the effectiveness and efficiency of our proposed method.
The experimental results show that PSR not only surpasses the previous SOTA in
performance but also has impressive scalability and robustness.

    

### [[2108.05340] Person Re-identification via Attention Pyramid](http://arxiv.org/abs/2108.05340)


  In this paper, we propose an attention pyramid method for person
re-identification. Unlike conventional attention-based methods which only learn
a global attention map, our attention pyramid exploits the attention regions in
a multi-scale manner because human attention varies with different scales. Our
attention pyramid imitates the process of human visual perception which tends
to notice the foreground person over the cluttered background, and further
focus on the specific color of the shirt with close observation. Specifically,
we describe our attention pyramid by a "split-attend-merge-stack" principle. We
first split the features into multiple local parts and learn the corresponding
attentions. Then, we merge local attentions and stack these merged attentions
with the residual connection as an attention pyramid. The proposed attention
pyramid is a lightweight plug-and-play module that can be applied to
off-the-shelf models. We implement our attention pyramid method in two
different attention mechanisms including channel-wise attention and spatial
attention. We evaluate our method on four largescale person re-identification
benchmarks including Market-1501, DukeMTMC, CUHK03, and MSMT17. Experimental
results demonstrate the superiority of our method, which outperforms the
state-of-the-art methods by a large margin with limited computational cost.

    

### [[2108.05349] Intelligence as information processing: brains, swarms, and computers](http://arxiv.org/abs/2108.05349)


  There is no agreed definition of intelligence, so it is problematic to simply
ask whether brains, swarms, computers, or other systems are intelligent or not.
To compare the potential intelligence exhibited by different cognitive systems,
I use the common approach used by artificial intelligence and artificial life:
Instead of studying the substrate of systems, let us focus on their
organization. This organization can be measured with information. Thus, I apply
an informationist epistemology to describe cognitive systems, including brains
and computers. This allows me to frame the usefulness and limitations of the
brain-computer analogy in different contexts. I also use this perspective to
discuss the evolution and ecology of intelligence.

    

### [[2101.07086] Model Compression for Domain Adaptation through Causal Effect Estimation](http://arxiv.org/abs/2101.07086)


  Recent improvements in the predictive quality of natural language processing
systems are often dependent on a substantial increase in the number of model
parameters. This has led to various attempts of compressing such models, but
existing methods have not considered the differences in the predictive power of
various model components or in the generalizability of the compressed models.
To understand the connection between model compression and out-of-distribution
generalization, we define the task of compressing language representation
models such that they perform best in a domain adaptation setting. We choose to
address this problem from a causal perspective, attempting to estimate the
average treatment effect (ATE) of a model component, such as a single layer, on
the model's predictions. Our proposed ATE-guided Model Compression scheme
(AMoC), generates many model candidates, differing by the model components that
were removed. Then, we select the best candidate through a stepwise regression
model that utilizes the ATE to predict the expected performance on the target
domain. AMoC outperforms strong baselines on dozens of domain pairs across
three text classification and sequence tagging tasks.

    

### [[2102.10247] Game Mechanic Alignment Theory and Discovery](http://arxiv.org/abs/2102.10247)


  We present a new concept called Game Mechanic Alignment theory as a way to
organize game mechanics through the lens of systemic rewards and agential
motivations. By disentangling player and systemic influences, mechanics may be
better identified for use in an automated tutorial generation system, which
could tailor tutorials for a particular playstyle or player. Within, we apply
this theory to several well-known games to demonstrate how designers can
benefit from it, we describe a methodology for how to estimate "mechanic
alignment", and we apply this methodology on multiple games in the GVGAI
framework. We discuss how effectively this estimation captures agential
motivations and systemic rewards and how our theory could be used as an
alternative way to find mechanics for tutorial generation.

    

### [[2104.02215] When Pigs Fly: Contextual Reasoning in Synthetic and Natural Scenes](http://arxiv.org/abs/2104.02215)


  Context is of fundamental importance to both human and machine vision; e.g.,
an object in the air is more likely to be an airplane than a pig. The rich
notion of context incorporates several aspects including physics rules,
statistical co-occurrences, and relative object sizes, among others. While
previous work has focused on crowd-sourced out-of-context photographs from the
web to study scene context, controlling the nature and extent of contextual
violations has been a daunting task. Here we introduce a diverse, synthetic
Out-of-Context Dataset (OCD) with fine-grained control over scene context. By
leveraging a 3D simulation engine, we systematically control the gravity,
object co-occurrences and relative sizes across 36 object categories in a
virtual household environment. We conducted a series of experiments to gain
insights into the impact of contextual cues on both human and machine vision
using OCD. We conducted psychophysics experiments to establish a human
benchmark for out-of-context recognition, and then compared it with
state-of-the-art computer vision models to quantify the gap between the two. We
propose a context-aware recognition transformer model, fusing object and
contextual information via multi-head attention. Our model captures useful
information for contextual reasoning, enabling human-level performance and
better robustness in out-of-context conditions compared to baseline models
across OCD and other out-of-context datasets. All source code and data are
publicly available at this https URL


### [[2106.07139] Pre-Trained Models: Past, Present and Future](http://arxiv.org/abs/2106.07139)


  Large-scale pre-trained models (PTMs) such as BERT and GPT have recently
achieved great success and become a milestone in the field of artificial
intelligence (AI). Owing to sophisticated pre-training objectives and huge
model parameters, large-scale PTMs can effectively capture knowledge from
massive labeled and unlabeled data. By storing knowledge into huge parameters
and fine-tuning on specific tasks, the rich knowledge implicitly encoded in
huge parameters can benefit a variety of downstream tasks, which has been
extensively demonstrated via experimental verification and empirical analysis.
It is now the consensus of the AI community to adopt PTMs as backbone for
downstream tasks rather than learning models from scratch. In this paper, we
take a deep look into the history of pre-training, especially its special
relation with transfer learning and self-supervised learning, to reveal the
crucial position of PTMs in the AI development spectrum. Further, we
comprehensively review the latest breakthroughs of PTMs. These breakthroughs
are driven by the surge of computational power and the increasing availability
of data, towards four important directions: designing effective architectures,
utilizing rich contexts, improving computational efficiency, and conducting
interpretation and theoretical analysis. Finally, we discuss a series of open
problems and research directions of PTMs, and hope our view can inspire and
advance the future study of PTMs.

    

### [[1904.01117] Aiming Low Is Harder -- Induction for Lower Bounds in Probabilistic Program Verification](http://arxiv.org/abs/1904.01117)


  We present a new inductive rule for verifying lower bounds on expected values
of random variables after execution of probabilistic loops as well as on their
expected runtimes. Our rule is simple in the sense that loop body semantics
need to be applied only finitely often in order to verify that the candidates
are indeed lower bounds. In particular, it is not necessary to find the limit
of a sequence as in many previous rules.

    