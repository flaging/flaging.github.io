
## 2021-8-18

### [<title>Negative labels in XGBRanker w/ listwise objective - XGBoost</title>](https://discuss.xgboost.ai/t/negative-labels-in-xgbranker-w-listwise-objective/1655/9)

### [<title>关于沈阳哪里可以开具住宿费发票-沈阳本地宝lz - DockOne.io</title>](http://dockone.io/question/1018342)

### [<title>专注于)安徽开具办公桌椅发票-安徽本地宝tt - DockOne.io</title>](http://dockone.io/question/1018341)

### [<title>关注于厦门哪里能开餐饮费电子版发票-厦门本地宝ux - DockOne.io</title>](http://dockone.io/question/1018340)

### [<title>关于长春哪里可以开具住宿费发票-长春本地宝be - DockOne.io</title>](http://dockone.io/question/1018339)

### [<title>专注于)西安开具办公桌椅发票-西安本地宝ui - DockOne.io</title>](http://dockone.io/question/1018338)

### [<title>关注于贵阳哪里能开餐饮费电子版发票-贵阳本地宝ug - DockOne.io</title>](http://dockone.io/question/1018337)

### [<title>专注于)陕西开具办公桌椅发票-陕西本地宝mg - DockOne.io</title>](http://dockone.io/question/1018336)

### [<title>关于海口哪里可以开具住宿费发票-海口本地宝tg - DockOne.io</title>](http://dockone.io/question/1018335)

### [<title>关注于兰州哪里能开餐饮费电子版发票-兰州本地宝ym - DockOne.io</title>](http://dockone.io/question/1018334)

### [<title>关注于长沙哪里能开餐饮费电子版发票-长沙本地宝yq - DockOne.io</title>](http://dockone.io/question/1018333)

### [<title>关于太原哪里可以开具住宿费发票-太原本地宝df - DockOne.io</title>](http://dockone.io/question/1018332)

### [<title>关于三亚哪里可以开具住宿费发票-三亚本地宝ol - DockOne.io</title>](http://dockone.io/question/1018331)

### [<title>专注于)武汉开具办公桌椅发票-武汉本地宝sk - DockOne.io</title>](http://dockone.io/question/1018330)

### [<title>专注于)湖北开具办公桌椅发票-湖北本地宝oi - DockOne.io</title>](http://dockone.io/question/1018329)

### [<title>关于合肥哪里可以开具住宿费发票-合肥本地宝ix - DockOne.io</title>](http://dockone.io/question/1018328)

### [<title>关注于哈尔滨哪里能开餐饮费电子版发票-哈尔滨本地宝dp - DockOne.io</title>](http://dockone.io/question/1018327)

### [<title>专注于)南京开具办公桌椅发票-南京本地宝ln - DockOne.io</title>](http://dockone.io/question/1018326)

### [<title>专注于)苏州开具办公桌椅发票-苏州本地宝ua - DockOne.io</title>](http://dockone.io/question/1018325)

### [<title>关于西安哪里可以开具住宿费发票-西安本地宝cu - DockOne.io</title>](http://dockone.io/question/1018324)

### [<title>关注于石家庄哪里能开餐饮费电子版发票-石家庄本地宝nh - DockOne.io</title>](http://dockone.io/question/1018323)

### [<title>Negative labels in XGBRanker w/ listwise objective - XGBoost</title>](https://discuss.xgboost.ai/t/negative-labels-in-xgbranker-w-listwise-objective/1655/10)

### [[2108.07322] QoT Assessment of the Optical Spectrum as a Service in Disaggregated Network Scenarios](http://arxiv.org/abs/2108.07322)


  The potential to operate third-party terminals over multi-domain transparent
optical networks attracts operators and customers to implement Optical Spectrum
as a Service (OSaaS). As infrastructure information cannot always be shared
with OSaaS end customers, alternatives to off-line Quality of Transmission
(QoT) estimation tools are required to assess the performance of the spectrum
slot in order to estimate achievable throughput. In this paper, commercially
available sliceable coherent transceivers are used to assess the Generalized
Signal To Noise Ratio (GSNR) based QoT of the OSaaS in a live production
network for both, narrow-band and wide-band OSaaS configurations. Extended
channel probing based on symbol rate variability is combined with spectral
sweeping and operation regime detection to characterize OSaaS implementations
on 17 links with different underlying infrastructure configurations in order to
maximize capacity and increase service margins in a low-margin operation
regime. We achieve 0.05 dB estimation accuracy in GSNR for a wide-band spectrum
services and 0.32 dB accuracy for narrow-band spectrum services. Based on the
GSNR profile, spectral misalignment, spectral ripple, and operation regime are
detected and service margin improvements are demonstrated. Finally, we discuss
the network optimization perspective based on acquired data from channel
probing and propose use-cases for continuous channel probing in transparent
optical networks.

    

### [[2108.07504] Federated Learning with Correlated Data: Taming the Tail for Age-Optimal Industrial IoT](http://arxiv.org/abs/2108.07504)


  While information delivery in industrial Internet of things demands
reliability and latency guarantees, the freshness of the controller's available
information, measured by the age of information (AoI), is paramount for
high-performing industrial automation. The problem in this work is cast as a
sensor's transmit power minimization subject to the peak-AoI requirement and a
probabilistic constraint on queuing latency. We further characterize the tail
behavior of the latency by a generalized Pareto distribution (GPD) for solving
the power allocation problem through Lyapunov optimization. As each sensor
utilizes its own data to locally train the GPD model, we incorporate federated
learning and propose a local-model selection approach which accounts for
correlation among the sensor's training data. Numerical results show the
tradeoff between the transmit power, peak AoI, and delay's tail distribution.
Furthermore, we verify the superiority of the proposed correlation-aware
approach for selecting the local models in federated learning over an existing
baseline.

    

### [[2108.07644] Wireless Federated Langevin Monte Carlo: Repurposing Channel Noise for Bayesian Sampling and Privacy](http://arxiv.org/abs/2108.07644)


  Most works on federated learning (FL) focus on the most common frequentist
formulation of learning whereby the goal is minimizing the global empirical
loss. Frequentist learning, however, is known to be problematic in the regime
of limited data as it fails to quantify epistemic uncertainty in prediction.
Bayesian learning provides a principled solution to this problem by shifting
the optimization domain to the space of distribution in the model parameters.
This paper studies for the first time Bayesian FL in wireless systems by
proposing and analyzing a gradient-based Markov Chain Monte Carlo (MCMC) method
-- Wireless Federated Langevin Monte Carlo (WFLMC). The key idea of this work
is to repurpose channel noise for the double role of seed randomness for MCMC
sampling and of privacy-preserving mechanism. To this end, based on the
analysis of the Wasserstein distance between sample distribution and global
posterior distribution under privacy and power constraints, we introduce a
power allocation strategy as the solution of a convex program. The analysis
identifies distinct operating regimes in which the performance of the system is
power-limited, privacy-limited, or limited by the requirement of MCMC sampling.
Both analytical and simulation results demonstrate that, if the channel noise
is properly accounted for under suitable conditions, it can be fully repurposed
for both MCMC sampling and privacy preservation, obtaining the same performance
as in an ideal communication setting that is not subject to privacy
constraints.

    

### [[2108.07757] Doppler Shift Estimation in 5G New Radio Non-Terrestrial Networks](http://arxiv.org/abs/2108.07757)


  Evolving 5G New Radio (NR) to support non-terrestrial networks (NTNs),
particularly satellite communication networks, is under exploration in 3GPP.
The movement of the spaceborne platforms in NTNs may result in large timing
varying Doppler shift that differs for devices in different locations. Using
orthogonal frequency-division multiple access (OFDMA) in the uplink, each
device will need to apply a different frequency adjustment value to compensate
for the Doppler shift. To this end, the 3GPP Release-17 work on NTNs assumes
that an NTN device is equipped with a global navigation satellite system (GNSS)
chipset and thereby can determine its position and calculate the needed
frequency adjustment value using its position information and satellite
ephemeris data. This makes GNSS support essential for the NTN operation.
However, GNSS signals are weak, not ubiquitous, and susceptible to interference
and spoofing. We show that devices without access to GNSS signals can utilize
reference signals in more than one frequency position in an OFDM carrier to
estimate the Doppler shift and thereby determine the needed frequency
adjustment value for pre-compensating the Doppler shift in the uplink. We
analyze the performance, elaborate on how to utilize the NR reference signals,
and present simulation results. The solution can reduce the dependency of NTN
operation on GNSS with reasonable complexity and performance trade-off.

    

### [[1802.01570] Mobile Power Network for Ultimate Mobility without Battery Life Anxiety](http://arxiv.org/abs/1802.01570)


  Similar to the evolution from the wired Internet to mobile Internet (MI), the
growing demand for power delivery anywhere and anytime appeals for power grid
transformation from wired to mobile domain. We propose here the next generation
of power delivery network -- mobile power network (MPN) for wireless power
transfer within a mobile range from several meters to tens of meters. At first,
we present the MPN's concept evolution and application scenarios. Then, we
introduce the MPN's supporting technology, namely resonant beam charging (RBC).
As a long-range wireless power transfer (WPT) method, RBC can safely deliver
multi-Watt power to multiple devices concurrently. Meanwhile, the recent
progress in RBC research has been summarized. Next, we specify the MPN's
architecture to provide the wide-area WPT coverage. Finally, we discuss the
MPN's features and challenges. MPN can enable the ultimate mobility by cutting
the final cord of mobile devices, realizing the "last-mile" mobile power
delivery.

    

### [[2001.05009] A Content-Based Deep Intrusion Detection System](http://arxiv.org/abs/2001.05009)


  The growing number of Internet users and the prevalence of web applications
make it necessary to deal with very complex software and applications in the
network. This results in an increasing number of new vulnerabilities in the
systems, and leading to an increase in cyber threats and, in particular,
zero-day attacks. The cost of generating appropriate signatures for these
attacks is a potential motive for using machine learning-based methodologies.
Although there are many studies on using learning-based methods for attack
detection, they generally use extracted features and overlook raw contents.
This approach can lessen the performance of detection systems against
content-based attacks like SQL injection, Cross-site Scripting (XSS), and
various viruses.
In this work, we propose a framework, called deep intrusion detection (DID)
system, that uses the pure content of traffic flows in addition to traffic
metadata in the learning and detection phases of a passive DNN IDS. To this
end, we deploy and evaluate an offline IDS following the framework using LSTM
as a deep learning technique. Due to the inherent nature of deep learning, it
can process high dimensional data content and, accordingly, discover the
sophisticated relations between the auto extracted features of the traffic. To
evaluate the proposed DID system, we use the CIC-IDS2017 and CSE-CIC-IDS2018
datasets. The evaluation metrics, such as precision and recall, reach $0.992$
and $0.998$ on CIC-IDS2017, and $0.933$ and $0.923$ on CSE-CIC-IDS2018
respectively, which show the high performance of the proposed DID method.

    

### [[2108.07301] Understanding the factors driving the opioid epidemic using machine learning](http://arxiv.org/abs/2108.07301)


  In recent years, the US has experienced an opioid epidemic with an
unprecedented number of drugs overdose deaths. Research finds such overdose
deaths are linked to neighborhood-level traits, thus providing opportunity to
identify effective interventions. Typically, techniques such as Ordinary Least
Squares (OLS) or Maximum Likelihood Estimation (MLE) are used to document
neighborhood-level factors significant in explaining such adverse outcomes.
These techniques are, however, less equipped to ascertain non-linear
relationships between confounding factors. Hence, in this study we apply
machine learning based techniques to identify opioid risks of neighborhoods in
Delaware and explore the correlation of these factors using Shapley Additive
explanations (SHAP). We discovered that the factors related to neighborhoods
environment, followed by education and then crime, were highly correlated with
higher opioid risk. We also explored the change in these correlations over the
years to understand the changing dynamics of the epidemic. Furthermore, we
discovered that, as the epidemic has shifted from legal (i.e., prescription
opioids) to illegal (e.g.,heroin and fentanyl) drugs in recent years, the
correlation of environment, crime and health related variables with the opioid
risk has increased significantly while the correlation of economic and
socio-demographic variables has decreased. The correlation of education related
factors has been higher from the start and has increased slightly in recent
years suggesting a need for increased awareness about the opioid epidemic.

    

### [[2108.07307] Synthesizing Pareto-Optimal Interpretations for Black-Box Models](http://arxiv.org/abs/2108.07307)


  We present a new multi-objective optimization approach for synthesizing
interpretations that "explain" the behavior of black-box machine learning
models. Constructing human-understandable interpretations for black-box models
often requires balancing conflicting objectives. A simple interpretation may be
easier to understand for humans while being less precise in its predictions
vis-a-vis a complex interpretation. Existing methods for synthesizing
interpretations use a single objective function and are often optimized for a
single class of interpretations. In contrast, we provide a more general and
multi-objective synthesis framework that allows users to choose (1) the class
of syntactic templates from which an interpretation should be synthesized, and
(2) quantitative measures on both the correctness and explainability of an
interpretation. For a given black-box, our approach yields a set of
Pareto-optimal interpretations with respect to the correctness and
explainability measures. We show that the underlying multi-objective
optimization problem can be solved via a reduction to quantitative constraint
solving, such as weighted maximum satisfiability. To demonstrate the benefits
of our approach, we have applied it to synthesize interpretations for black-box
neural-network classifiers. Our experiments show that there often exists a rich
and varied set of choices for interpretations that are missed by existing
approaches.

    

### [[2108.07313] Fine-tuning is Fine in Federated Learning](http://arxiv.org/abs/2108.07313)


  We study the performance of federated learning algorithms and their variants
in an asymptotic framework. Our starting point is the formulation of federated
learning as a multi-criterion objective, where the goal is to minimize each
client's loss using information from all of the clients. We propose a linear
regression model, where, for a given client, we theoretically compare the
performance of various algorithms in the high-dimensional asymptotic limit.
This asymptotic multi-criterion approach naturally models the high-dimensional,
many-device nature of federated learning and suggests that personalization is
central to federated learning. Our theory suggests that Fine-tuned Federated
Averaging (FTFA), i.e., Federated Averaging followed by local training, and the
ridge regularized variant Ridge-tuned Federated Averaging (RTFA) are
competitive with more sophisticated meta-learning and proximal-regularized
approaches. In addition to being conceptually simpler, FTFA and RTFA are
computationally more efficient than its competitors. We corroborate our
theoretical claims with extensive experiments on federated versions of the
EMNIST, CIFAR-100, Shakespeare, and Stack Overflow datasets.

    

### [[2108.07316] Heterotic String Model Building with Monad Bundles and Reinforcement Learning](http://arxiv.org/abs/2108.07316)


  We use reinforcement learning as a means of constructing string
compactifications with prescribed properties. Specifically, we study heterotic
SO(10) GUT models on Calabi-Yau three-folds with monad bundles, in search of
phenomenologically promising examples. Due to the vast number of bundles and
the sparseness of viable choices, methods based on systematic scanning are not
suitable for this class of models. By focusing on two specific manifolds with
Picard numbers two and three, we show that reinforcement learning can be used
successfully to explore monad bundles. Training can be accomplished with
minimal computing resources and leads to highly efficient policy networks. They
produce phenomenologically promising states for nearly 100% of episodes and
within a small number of steps. In this way, hundreds of new candidate standard
models are found.

    

### [[2108.07330] Weakly Supervised Classification Using Group-Level Labels](http://arxiv.org/abs/2108.07330)


  In many applications, finding adequate labeled data to train predictive
models is a major challenge. In this work, we propose methods to use
group-level binary labels as weak supervision to train instance-level binary
classification models. Aggregate labels are common in several domains where
annotating on a group-level might be cheaper or might be the only way to
provide annotated data without infringing on privacy. We model group-level
labels as Class Conditional Noisy (CCN) labels for individual instances and use
the noisy labels to regularize predictions of the model trained on the
strongly-labeled instances. Our experiments on real-world application of land
cover mapping shows the utility of the proposed method in leveraging
group-level labels, both in the presence and absence of class imbalance.

    

### [[2108.07339] Classification of Common Waveforms Including a Watchdog for Unknown Signals](http://arxiv.org/abs/2108.07339)


  In this paper, we examine the use of a deep multi-layer perceptron model
architecture to classify received signal samples as coming from one of four
common waveforms, Single Carrier (SC), Single-Carrier Frequency Division
Multiple Access (SC-FDMA), Orthogonal Frequency Division Multiplexing (OFDM),
and Linear Frequency Modulation (LFM), used in communication and radar
networks. Synchronization of the signals is not needed as we assume there is an
unknown and uncompensated time and frequency offset. An autoencoder with a deep
CNN architecture is also examined to create a new fifth classification category
of an unknown waveform type. This is accomplished by calculating a minimum and
maximum threshold values from the root mean square error (RMSE) of the radar
and communication waveforms. The classifier and autoencoder work together to
monitor a spectrum area to identify the common waveforms inside the area of
operation along with detecting unknown waveforms. Results from testing showed
the classifier had 100\% classification rate above 0 dB with accuracy of 83.2\%
and 94.7\% at -10 dB and -5 dB, respectively, with signal impairments present.
Results for the anomaly detector showed 85.3\% accuracy at 0 dB with 100\% at
SNR greater than 0 dB with signal impairments present when using a high-value
Fast Fourier Transform (FFT) size. Accurate detection rates decline as
additional noise is introduced to the signals, with 78.1\% at -5 dB and 56.5\%
at -10 dB. However, these low rates seen can be potentially mitigated by using
even higher FFT sizes also shown in our results.

    

### [[2108.07344] IsoScore: Measuring the Uniformity of Vector Space Utilization](http://arxiv.org/abs/2108.07344)


  The recent success of distributed word representations has led to an
increased interest in analyzing the properties of their spatial distribution.
Current metrics suggest that contextualized word embedding models do not
uniformly utilize all dimensions when embedding tokens in vector space. Here we
argue that existing metrics are fragile and tend to obfuscate the true spatial
distribution of point clouds. To ameliorate this issue, we propose IsoScore: a
novel metric which quantifies the degree to which a point cloud uniformly
utilizes the ambient vector space. We demonstrate that IsoScore has several
desirable properties such as mean invariance and direct correspondence to the
number of dimensions used, which are properties that existing scores do not
possess. Furthermore, IsoScore is conceptually intuitive and computationally
efficient, making it well suited for analyzing the distribution of point clouds
in arbitrary vector spaces, not necessarily limited to those of word embeddings
alone. Additionally, we use IsoScore to demonstrate that a number of recent
conclusions in the NLP literature that have been derived using brittle metrics
of spatial distribution, such as average cosine similarity, may be incomplete
or altogether inaccurate.

    

### [[2108.07356] Stochastic optimization under time drift: iterate averaging, step decay, and high probability guarantees](http://arxiv.org/abs/2108.07356)


  We consider the problem of minimizing a convex function that is evolving in
time according to unknown and possibly stochastic dynamics. Such problems
abound in the machine learning and signal processing literature, under the
names of concept drift and stochastic tracking. We provide novel non-asymptotic
convergence guarantees for stochastic algorithms with iterate averaging,
focusing on bounds valid both in expectation and with high probability.
Notably, we show that the tracking efficiency of the proximal stochastic
gradient method depends only logarithmically on the initialization quality,
when equipped with a step-decay schedule. The results moreover naturally extend
to settings where the dynamics depend jointly on time and on the decision
variable itself, as in the performative prediction framework.

    

### [[2108.07380] InfoGram and Admissible Machine Learning](http://arxiv.org/abs/2108.07380)


  We have entered a new era of machine learning (ML), where the most accurate
algorithm with superior predictive power may not even be deployable, unless it
is admissible under the regulatory constraints. This has led to great interest
in developing fair, transparent and trustworthy ML methods. The purpose of this
article is to introduce a new information-theoretic learning framework
(admissible machine learning) and algorithmic risk-management tools (InfoGram,
L-features, ALFA-testing) that can guide an analyst to redesign off-the-shelf
ML methods to be regulatory compliant, while maintaining good prediction
accuracy. We have illustrated our approach using several real-data examples
from financial sectors, biomedical research, marketing campaigns, and the
criminal justice system.

    

### [[2108.07383] Learning to Cluster via Same-Cluster Queries](http://arxiv.org/abs/2108.07383)


  We study the problem of learning to cluster data points using an oracle which
can answer same-cluster queries. Different from previous approaches, we do not
assume that the total number of clusters is known at the beginning and do not
require that the true clusters are consistent with a predefined objective
function such as the K-means. These relaxations are critical from the practical
perspective and, meanwhile, make the problem more challenging. We propose two
algorithms with provable theoretical guarantees and verify their effectiveness
via an extensive set of experiments on both synthetic and real-world data.

    

### [[2108.07386] BOBCAT: Bilevel Optimization-Based Computerized Adaptive Testing](http://arxiv.org/abs/2108.07386)


  Computerized adaptive testing (CAT) refers to a form of tests that are
personalized to every student/test taker. CAT methods adaptively select the
next most informative question/item for each student given their responses to
previous questions, effectively reducing test length. Existing CAT methods use
item response theory (IRT) models to relate student ability to their responses
to questions and static question selection algorithms designed to reduce the
ability estimation error as quickly as possible; therefore, these algorithms
cannot improve by learning from large-scale student response data. In this
paper, we propose BOBCAT, a Bilevel Optimization-Based framework for CAT to
directly learn a data-driven question selection algorithm from training data.
BOBCAT is agnostic to the underlying student response model and is
computationally efficient during the adaptive testing process. Through
extensive experiments on five real-world student response datasets, we show
that BOBCAT outperforms existing CAT methods (sometimes significantly) at
reducing test length.

    

### [[2108.07387] Contextual Convolutional Neural Networks](http://arxiv.org/abs/2108.07387)


  We propose contextual convolution (CoConv) for visual recognition. CoConv is
a direct replacement of the standard convolution, which is the core component
of convolutional neural networks. CoConv is implicitly equipped with the
capability of incorporating contextual information while maintaining a similar
number of parameters and computational cost compared to the standard
convolution. CoConv is inspired by neuroscience studies indicating that (i)
neurons, even from the primary visual cortex (V1 area), are involved in
detection of contextual cues and that (ii) the activity of a visual neuron can
be influenced by the stimuli placed entirely outside of its theoretical
receptive field. On the one hand, we integrate CoConv in the widely-used
residual networks and show improved recognition performance over baselines on
the core tasks and benchmarks for visual recognition, namely image
classification on the ImageNet data set and object detection on the MS COCO
data set. On the other hand, we introduce CoConv in the generator of a
state-of-the-art Generative Adversarial Network, showing improved generative
results on CIFAR-10 and CelebA. Our code is available at
this https URL.

    

### [[2108.07392] Incorporating Uncertainty in Learning to Defer Algorithms for Safe Computer-Aided Diagnosis](http://arxiv.org/abs/2108.07392)


  In this study we propose the Learning to Defer with Uncertainty (LDU)
algorithm, an approach which considers the model's predictive uncertainty when
identifying the patient group to be evaluated by human experts. Our aim is to
ensure patient safety when ML models are deployed in healthcare settings.

    

### [[2108.07396] Diagnosis of Acute Myeloid Leukaemia Using Machine Learning](http://arxiv.org/abs/2108.07396)


  We train a machine learning model on a dataset of 2177 individuals using as
features 26 probe sets and their age in order to classify if someone has acute
myeloid leukaemia or is healthy. The dataset is multicentric and consists of
data from 27 organisations, 25 cities, 15 countries and 4 continents. The
accuracy or our model is 99.94\% and its F1-score 0.9996. To the best of our
knowledge the performance of our model is the best one in the literature, as
regards the prediction of AML using similar or not data. Moreover, there has
not been any bibliographic reference associated with acute myeloid leukaemia
for the 26 probe sets we used as features in our model.

    

### [[2108.07403] FARF: A Fair and Adaptive Random Forests Classifier](http://arxiv.org/abs/2108.07403)


  As Artificial Intelligence (AI) is used in more applications, the need to
consider and mitigate biases from the learned models has followed. Most works
in developing fair learning algorithms focus on the offline setting. However,
in many real-world applications data comes in an online fashion and needs to be
processed on the fly. Moreover, in practical application, there is a trade-off
between accuracy and fairness that needs to be accounted for, but current
methods often have multiple hyperparameters with non-trivial interaction to
achieve fairness. In this paper, we propose a flexible ensemble algorithm for
fair decision-making in the more challenging context of evolving online
settings. This algorithm, called FARF (Fair and Adaptive Random Forests), is
based on using online component classifiers and updating them according to the
current distribution, that also accounts for fairness and a single
hyperparameters that alters fairness-accuracy balance. Experiments on
real-world discriminated data streams demonstrate the utility of FARF.

    

### [[2108.07406] From the Greene--Wu Convolution to Gradient Estimation over Riemannian Manifolds](http://arxiv.org/abs/2108.07406)


  Over a complete Riemannian manifold of finite dimension, Greene and Wu
introduced a convolution, known as Greene-Wu (GW) convolution. In this paper,
we introduce a reformulation of the GW convolution. Using our reformulation,
many properties of the GW convolution can be easily derived, including a new
formula for how the curvature of the space would affect the curvature of the
function through the GW convolution. Also enabled by our new reformulation, an
improved method for gradient estimation over Riemannian manifolds is
introduced. Theoretically, our gradient estimation method improves the order of
estimation error from $O \left( \left( n + 3 \right)^{3/2} \right)$ to $O
\left( n^{3/2} \right)$, where $n$ is the dimension of the manifold.
Empirically, our method outperforms the best existing method for gradient
estimation over Riemannian manifolds, as evidenced by thorough experimental
evaluations.

    

### [[2108.07414] Stability and Generalization for Randomized Coordinate Descent](http://arxiv.org/abs/2108.07414)


  Randomized coordinate descent (RCD) is a popular optimization algorithm with
wide applications in solving various machine learning problems, which motivates
a lot of theoretical analysis on its convergence behavior. As a comparison,
there is no work studying how the models trained by RCD would generalize to
test examples. In this paper, we initialize the generalization analysis of RCD
by leveraging the powerful tool of algorithmic stability. We establish argument
stability bounds of RCD for both convex and strongly convex objectives, from
which we develop optimal generalization bounds by showing how to early-stop the
algorithm to tradeoff the estimation and optimization. Our analysis shows that
RCD enjoys better stability as compared to stochastic gradient descent.

    

### [[2108.07421] Memory-Efficient Factorization Machines via Binarizing both Data and Model Coefficients](http://arxiv.org/abs/2108.07421)


  Factorization Machines (FM), a general predictor that can efficiently model
feature interactions in linear time, was primarily proposed for collaborative
recommendation and have been broadly used for regression, classification and
ranking tasks. Subspace Encoding Factorization Machine (SEFM) has been proposed
recently to overcome the expressiveness limitation of Factorization Machines
(FM) by applying explicit nonlinear feature mapping for both individual
features and feature interactions through one-hot encoding to each input
feature. Despite the effectiveness of SEFM, it increases the memory cost of FM
by $b$ times, where $b$ is the number of bins when applying one-hot encoding on
each input feature. To reduce the memory cost of SEFM, we propose a new method
called Binarized FM which constraints the model parameters to be binary values
(i.e., 1 or $-1$). Then each parameter value can be efficiently stored in one
bit. Our proposed method can significantly reduce the memory cost of SEFM
model. In addition, we propose a new algorithm to effectively and efficiently
learn proposed FM with binary constraints using Straight Through Estimator
(STE) with Adaptive Gradient Descent (Adagrad). Finally, we evaluate the
performance of our proposed method on eight different classification datasets.
Our experimental results have demonstrated that our proposed method achieves
comparable accuracy with SEFM but with much less memory cost.

    

### [[2108.07433] Aggregation Delayed Federated Learning](http://arxiv.org/abs/2108.07433)


  Federated learning is a distributed machine learning paradigm where multiple
data owners (clients) collaboratively train one machine learning model while
keeping data on their own devices. The heterogeneity of client datasets is one
of the most important challenges of federated learning algorithms. Studies have
found performance reduction with standard federated algorithms, such as FedAvg,
on non-IID data. Many existing works on handling non-IID data adopt the same
aggregation framework as FedAvg and focus on improving model updates either on
the server side or on clients. In this work, we tackle this challenge in a
different view by introducing redistribution rounds that delay the aggregation.
We perform experiments on multiple tasks and show that the proposed framework
significantly improves the performance on non-IID data.

    

### [[2108.07435] Modeling Protein Using Large-scale Pretrain Language Model](http://arxiv.org/abs/2108.07435)


  Protein is linked to almost every life process. Therefore, analyzing the
biological structure and property of protein sequences is critical to the
exploration of life, as well as disease detection and drug discovery.
Traditional protein analysis methods tend to be labor-intensive and
time-consuming. The emergence of deep learning models makes modeling data
patterns in large quantities of data possible. Interdisciplinary researchers
have begun to leverage deep learning methods to model large biological
datasets, e.g. using long short-term memory and convolutional neural network
for protein sequence classification. After millions of years of evolution,
evolutionary information is encoded in protein sequences. Inspired by the
similarity between natural language and protein sequences, we use large-scale
language models to model evolutionary-scale protein sequences, encoding protein
biology information in representation. Significant improvements are observed in
both token-level and sequence-level tasks, demonstrating that our large-scale
model can accurately capture evolution information from pretraining on
evolutionary-scale individual sequences. Our code and model are available at
this https URL.

    

### [[2108.07450] Identifying Biased Subgroups in Ranking and Classification](http://arxiv.org/abs/2108.07450)


  When analyzing the behavior of machine learning algorithms, it is important
to identify specific data subgroups for which the considered algorithm shows
different performance with respect to the entire dataset. The intervention of
domain experts is normally required to identify relevant attributes that define
these subgroups.
We introduce the notion of divergence to measure this performance difference
and we exploit it in the context of (i) classification models and (ii) ranking
applications to automatically detect data subgroups showing a significant
deviation in their behavior. Furthermore, we quantify the contribution of all
attributes in the data subgroup to the divergent behavior by means of Shapley
values, thus allowing the identification of the most impacting attributes.

    

### [[2108.07453] An End-to-End Deep Learning Approach for Epileptic Seizure Prediction](http://arxiv.org/abs/2108.07453)


  An accurate seizure prediction system enables early warnings before seizure
onset of epileptic patients. It is extremely important for drug-refractory
patients. Conventional seizure prediction works usually rely on features
extracted from Electroencephalography (EEG) recordings and classification
algorithms such as regression or support vector machine (SVM) to locate the
short time before seizure onset. However, such methods cannot achieve
high-accuracy prediction due to information loss of the hand-crafted features
and the limited classification ability of regression and SVM algorithms. We
propose an end-to-end deep learning solution using a convolutional neural
network (CNN) in this paper. One and two dimensional kernels are adopted in the
early- and late-stage convolution and max-pooling layers, respectively. The
proposed CNN model is evaluated on Kaggle intracranial and CHB-MIT scalp EEG
datasets. Overall sensitivity, false prediction rate, and area under receiver
operating characteristic curve reaches 93.5%, 0.063/h, 0.981 and 98.8%,
0.074/h, 0.988 on two datasets respectively. Comparison with state-of-the-art
works indicates that the proposed model achieves exceeding prediction
performance.

    

### [[2108.07463] Towards Secure and Practical Machine Learning via Secret Sharing and Random Permutation](http://arxiv.org/abs/2108.07463)


  With the increasing demands for privacy protection, privacy-preserving
machine learning has been drawing much attention in both academia and industry.
However, most existing methods have their limitations in practical
applications. On the one hand, although most cryptographic methods are provable
secure, they bring heavy computation and communication. On the other hand, the
security of many relatively efficient private methods (e.g., federated learning
and split learning) is being questioned, since they are non-provable secure.
Inspired by previous work on privacy-preserving machine learning, we build a
privacy-preserving machine learning framework by combining random permutation
and arithmetic secret sharing via our compute-after-permutation technique.
Since our method reduces the cost for element-wise function computation, it is
more efficient than existing cryptographic methods. Moreover, by adopting
distance correlation as a metric for privacy leakage, we demonstrate that our
method is more secure than previous non-provable secure methods. Overall, our
proposal achieves a good balance between security and efficiency. Experimental
results show that our method not only is up to 6x faster and reduces up to 85%
network traffic compared with state-of-the-art cryptographic methods, but also
leaks less privacy during the training process compared with non-provable
secure methods.

    

### [[2108.07464] Investigating a Baseline Of Self Supervised Learning Towards Reducing Labeling Costs For Image Classification](http://arxiv.org/abs/2108.07464)


  Data labeling in supervised learning is considered an expensive and
infeasible tool in some conditions. The self-supervised learning method is
proposed to tackle the learning effectiveness with fewer labeled data, however,
there is a lack of confidence in the size of labeled data needed to achieve
adequate results. This study aims to draw a baseline on the proportion of the
labeled data that models can appreciate to yield competent accuracy when
compared to training with additional labels. The study implements the
this http URL' cats-vs-dogs dataset, Mnist and Fashion-Mnist to investigate the
self-supervised learning task by implementing random rotations augmentation on
the original datasets. To reveal the true effectiveness of the pretext process
in self-supervised learning, the original dataset is divided into smaller
batches, and learning is repeated on each batch with and without the pretext
pre-training. Results show that the pretext process in the self-supervised
learning improves the accuracy around 15% in the downstream classification task
when compared to the plain supervised learning.

    

### [[2108.07467] Neonatal Bowel Sound Detection Using Convolutional Neural Network and Laplace Hidden Semi-Markov Model](http://arxiv.org/abs/2108.07467)


  Abdominal auscultation is a convenient, safe and inexpensive method to assess
bowel conditions, which is essential in neonatal care. It helps early detection
of neonatal bowel dysfunctions and allows timely intervention. This paper
presents a neonatal bowel sound detection method to assist the auscultation.
Specifically, a Convolutional Neural Network (CNN) is proposed to classify
peristalsis and non-peristalsis sounds. The classification is then optimized
using a Laplace Hidden Semi-Markov Model (HSMM). The proposed method is
validated on abdominal sounds from 49 newborn infants admitted to our tertiary
Neonatal Intensive Care Unit (NICU). The results show that the method can
effectively detect bowel sounds with accuracy and area under curve (AUC) score
being 89.81% and 83.96% respectively, outperforming 13 baseline methods.
Furthermore, the proposed Laplace HSMM refinement strategy is proven capable to
enhance other bowel sound detection models. The outcomes of this work have the
potential to facilitate future telehealth applications for neonatal care. The
source code of our work can be found at:
this https URL


### [[2108.07472] Learning to Compute Approximate Nash Equilibrium for Normal-form Games](http://arxiv.org/abs/2108.07472)


  In this paper, we propose a general meta learning approach to computing
approximate Nash equilibrium for finite $n$-player normal-form games. Unlike
existing solutions that approximate or learn a Nash equilibrium from scratch
for each of the games, our meta solver directly constructs a mapping from a
game utility matrix to a joint strategy profile. The mapping is parameterized
and learned in a self-supervised fashion by a proposed Nash equilibrium
approximation metric without ground truth data informing any Nash equilibrium.
As such, it can immediately predict the joint strategy profile that
approximates a Nash equilibrium for any unseen new game under the same game
distribution. Moreover, the meta-solver can be further fine-tuned and adaptive
to a new game if iteration updates are allowed. We theoretically prove that our
meta-solver is not affected by the non-smoothness of exact Nash equilibrium
solutions, and derive a sample complexity bound to demonstrate its
generalization ability across normal-form games. Experimental results
demonstrate its substantial approximation power against other strong baselines
in both adaptive and non-adaptive cases.

    

### [[2108.07481] RRLFSOR: An Efficient Self-Supervised Learning Strategy of Graph Convolutional Networks](http://arxiv.org/abs/2108.07481)


  To further improve the performance and the self-learning ability of GCNs, in
this paper, we propose an efficient self-supervised learning strategy of GCNs,
named randomly removed links with a fixed step at one region (RRLFSOR). In
addition, we also propose another self-supervised learning strategy of GCNs,
named randomly removing links with a fixed step at some blocks (RRLFSSB), to
solve the problem that adjacent nodes have no selected step. Experiments on
transductive link prediction tasks show that our strategies outperform the
baseline models consistently by up to 21.34% in terms of accuracy on three
benchmark datasets.

    

### [[2108.07493] A Light-weight contextual spelling correction model for customizing transducer-based speech recognition systems](http://arxiv.org/abs/2108.07493)


  It's challenging to customize transducer-based automatic speech recognition
(ASR) system with context information which is dynamic and unavailable during
model training. In this work, we introduce a light-weight contextual spelling
correction model to correct context-related recognition errors in
transducer-based ASR systems. We incorporate the context information into the
spelling correction model with a shared context encoder and use a filtering
algorithm to handle large-size context lists. Experiments show that the model
improves baseline ASR model performance with about 50% relative word error rate
reduction, which also significantly outperforms the baseline method such as
contextual LM biasing. The model also shows excellent performance for
out-of-vocabulary terms not seen during training.

    

### [[2108.07505] MOI-Mixer: Improving MLP-Mixer with Multi Order Interactions in Sequential Recommendation](http://arxiv.org/abs/2108.07505)


  Successful sequential recommendation systems rely on accurately capturing the
user's short-term and long-term interest. Although Transformer-based models
achieved state-of-the-art performance in the sequential recommendation task,
they generally require quadratic memory and time complexity to the sequence
length, making it difficult to extract the long-term interest of users. On the
other hand, Multi-Layer Perceptrons (MLP)-based models, renowned for their
linear memory and time complexity, have recently shown competitive results
compared to Transformer in various tasks. Given the availability of a massive
amount of the user's behavior history, the linear memory and time complexity of
MLP-based models make them a promising alternative to explore in the sequential
recommendation task. To this end, we adopted MLP-based models in sequential
recommendation but consistently observed that MLP-based methods obtain lower
performance than those of Transformer despite their computational benefits.
From experiments, we observed that introducing explicit high-order interactions
to MLP layers mitigates such performance gap. In response, we propose the
Multi-Order Interaction (MOI) layer, which is capable of expressing an
arbitrary order of interactions within the inputs while maintaining the memory
and time complexity of the MLP layer. By replacing the MLP layer with the MOI
layer, our model was able to achieve comparable performance with
Transformer-based models while retaining the MLP-based models' computational
benefits.

    

### [[2108.07516] GCCAD: Graph Contrastive Coding for Anomaly Detection](http://arxiv.org/abs/2108.07516)


  Graph-based anomaly detection has been widely used for detecting malicious
activities in real-world applications. Existing attempts to address this
problem have thus far focused on structural feature engineering or learning in
the binary classification regime. In this work, we propose to leverage graph
contrastive coding and present the supervised GCCAD model for contrasting
abnormal nodes with normal ones in terms of their distances to the global
context (e.g., the average of all nodes). To handle scenarios with scarce
labels, we further enable GCCAD as a self-supervised framework by designing a
graph corrupting strategy for generating synthetic node labels. To achieve the
contrastive objective, we design a graph neural network encoder that can infer
and further remove suspicious links during message passing, as well as learn
the global context of the input graph. We conduct extensive experiments on four
public datasets, demonstrating that 1) GCCAD significantly and consistently
outperforms various advanced baselines and 2) its self-supervised version
without fine-tuning can achieve comparable performance with its fully
supervised version.

    

### [[2108.07537] Estimating smooth and sparse neural receptive fields with a flexible spline basis](http://arxiv.org/abs/2108.07537)


  Spatio-temporal receptive field (STRF) models are frequently used to
approximate the computation implemented by a sensory neuron. Typically, such
STRFs are assumed to be smooth and sparse. Current state-of-the-art approaches
for estimating STRFs based on empirical Bayes are often not computationally
efficient in high-dimensional settings, as encountered in sensory neuroscience.
Here we pursued an alternative approach and encode prior knowledge for
estimation of STRFs by choosing a set of basis functions with the desired
properties: natural cubic splines. Our method is computationally efficient and
can be easily applied to a wide range of existing models. We compared the
performance of spline-based methods to non-spline ones on simulated and
experimental data, showing that spline-based methods consistently outperform
the non-spline versions.

    

### [[2108.07538] O-HAS: Optical Hardware Accelerator Search for Boosting Both Acceleration Performance and Development Speed](http://arxiv.org/abs/2108.07538)


  The recent breakthroughs and prohibitive complexities of Deep Neural Networks
(DNNs) have excited extensive interest in domain-specific DNN accelerators,
among which optical DNN accelerators are particularly promising thanks to their
unprecedented potential of achieving superior performance-per-watt. However,
the development of optical DNN accelerators is much slower than that of
electrical DNN accelerators. One key challenge is that while many techniques
have been developed to facilitate the development of electrical DNN
accelerators, techniques that support or expedite optical DNN accelerator
design remain much less explored, limiting both the achievable performance and
the innovation development of optical DNN accelerators. To this end, we develop
the first-of-its-kind framework dubbed O-HAS, which for the first time
demonstrates automated Optical Hardware Accelerator Search for boosting both
the acceleration efficiency and development speed of optical DNN accelerators.
Specifically, our O-HAS consists of two integrated enablers: (1) an O-Cost
Predictor, which can accurately yet efficiently predict an optical
accelerator's energy and latency based on the DNN model parameters and the
optical accelerator design; and (2) an O-Search Engine, which can automatically
explore the large design space of optical DNN accelerators and identify the
optimal accelerators (i.e., the micro-architectures and
algorithm-to-accelerator mapping methods) in order to maximize the target
acceleration efficiency. Extensive experiments and ablation studies
consistently validate the effectiveness of both our O-Cost Predictor and
O-Search Engine as well as the excellent efficiency of O-HAS generated optical
accelerators.

    

### [[2108.07554] KCNet: An Insect-Inspired Single-Hidden-Layer Neural Network with Randomized Binary Weights for Prediction and Classification Tasks](http://arxiv.org/abs/2108.07554)


  Fruit flies are established model systems for studying olfactory learning as
they will readily learn to associate odors with both electric shock or sugar
rewards. The mechanisms of the insect brain apparently responsible for odor
learning form a relatively shallow neuronal architecture. Olfactory inputs are
received by the antennal lobe (AL) of the brain, which produces an encoding of
each odor mixture across ~50 sub-units known as glomeruli. Each of these
glomeruli then project its component of this feature vector to several of ~2000
so-called Kenyon Cells (KCs) in a region of the brain known as the mushroom
body (MB). Fly responses to odors are generated by small downstream neuropils
that decode the higher-order representation from the MB. Research has shown
that there is no recognizable pattern in the glomeruli--KC connections (and
thus the particular higher-order representations); they are akin to
fingerprints~-- even isogenic flies have different projections. Leveraging
insights from this architecture, we propose KCNet, a single-hidden-layer neural
network that contains sparse, randomized, binary weights between the input
layer and the hidden layer and analytically learned weights between the hidden
layer and the output layer. Furthermore, we also propose a dynamic optimization
algorithm that enables the KCNet to increase performance beyond its structural
limits by searching a more efficient set of inputs. For odorant-perception
tasks that predict perceptual properties of an odorant, we show that KCNet
outperforms existing data-driven approaches, such as XGBoost. For
image-classification tasks, KCNet achieves reasonable performance on benchmark
datasets (MNIST, Fashion-MNIST, and EMNIST) without any data-augmentation
methods or convolutional layers and shows particularly fast running time. Thus,
neural networks inspired by the insect brain can be both economical and perform
well.

    

### [[2108.07555] Revisiting State Augmentation methods for Reinforcement Learning with Stochastic Delays](http://arxiv.org/abs/2108.07555)


  Several real-world scenarios, such as remote control and sensing, are
comprised of action and observation delays. The presence of delays degrades the
performance of reinforcement learning (RL) algorithms, often to such an extent
that algorithms fail to learn anything substantial. This paper formally
describes the notion of Markov Decision Processes (MDPs) with stochastic delays
and shows that delayed MDPs can be transformed into equivalent standard MDPs
(without delays) with significantly simplified cost structure. We employ this
equivalence to derive a model-free Delay-Resolved RL framework and show that
even a simple RL algorithm built upon this framework achieves near-optimal
rewards in environments with stochastic delays in actions and observations. The
delay-resolved deep Q-network (DRDQN) algorithm is bench-marked on a variety of
environments comprising of multi-step and stochastic delays and results in
better performance, both in terms of achieving near-optimal rewards and
minimizing the computational overhead thereof, with respect to the currently
established algorithms.

    

### [[2108.07567] How Powerful is Graph Convolution for Recommendation?](http://arxiv.org/abs/2108.07567)


  Graph convolutional networks (GCNs) have recently enabled a popular class of
algorithms for collaborative filtering (CF). Nevertheless, the theoretical
underpinnings of their empirical successes remain elusive. In this paper, we
endeavor to obtain a better understanding of GCN-based CF methods via the lens
of graph signal processing. By identifying the critical role of smoothness, a
key concept in graph signal processing, we develop a unified graph
convolution-based framework for CF. We prove that many existing CF methods are
special cases of this framework, including the neighborhood-based methods,
low-rank matrix factorization, linear auto-encoders, and LightGCN,
corresponding to different low-pass filters. Based on our framework, we then
present a simple and computationally efficient CF baseline, which we shall
refer to as Graph Filter based Collaborative Filtering (GF-CF). Given an
implicit feedback matrix, GF-CF can be obtained in a closed form instead of
expensive training with back-propagation. Experiments will show that GF-CF
achieves competitive or better performance against deep learning-based methods
on three well-known datasets, notably with a $70\%$ performance gain over
LightGCN on the Amazon-book dataset.

    

### [[2108.07594] Coalesced Multi-Output Tsetlin Machines with Clause Sharing](http://arxiv.org/abs/2108.07594)


  Using finite-state machines to learn patterns, Tsetlin machines (TMs) have
obtained competitive accuracy and learning speed across several benchmarks,
with frugal memory- and energy footprint. A TM represents patterns as
conjunctive clauses in propositional logic (AND-rules), each clause voting for
or against a particular output. While efficient for single-output problems, one
needs a separate TM per output for multi-output problems. Employing multiple
TMs hinders pattern reuse because each TM then operates in a silo. In this
paper, we introduce clause sharing, merging multiple TMs into a single one.
Each clause is related to each output by using a weight. A positive weight
makes the clause vote for output $1$, while a negative weight makes the clause
vote for output $0$. The clauses thus coalesce to produce multiple outputs. The
resulting coalesced Tsetlin Machine (CoTM) simultaneously learns both the
weights and the composition of each clause by employing interacting Stochastic
Searching on the Line (SSL) and Tsetlin Automata (TA) teams. Our empirical
results on MNIST, Fashion-MNIST, and Kuzushiji-MNIST show that CoTM obtains
significantly higher accuracy than TM on $50$- to $1$K-clause configurations,
indicating an ability to repurpose clauses. E.g., accuracy goes from $71.99$%
to $89.66$% on Fashion-MNIST when employing $50$ clauses per class (22 Kb
memory). While TM and CoTM accuracy is similar when using more than $1$K
clauses per class, CoTM reaches peak accuracy $3\times$ faster on MNIST with
$8$K clauses. We further investigate robustness towards imbalanced training
data. Our evaluations on imbalanced versions of IMDb- and CIFAR10 data show
that CoTM is robust towards high degrees of class imbalance. Being able to
share clauses, we believe CoTM will enable new TM application domains that
involve multiple outputs, such as learning language models and auto-encoding.

    

### [[2108.07600] Direct domain adaptation through reciprocal linear transformations](http://arxiv.org/abs/2108.07600)


  We propose a direct domain adaptation (DDA) approach to enrich the training
of supervised neural networks on synthetic data by features from real-world
data. The process involves a series of linear operations on the input features
to the NN model, whether they are from the source or target domains, as
follows: 1) A cross-correlation of the input data (i.e. images) with a randomly
picked sample pixel (or pixels) of all images from that domain or the mean of
all randomly picked sample pixel (or pixels) of all images. 2) The convolution
of the resulting data with the mean of the autocorrelated input images from the
other domain. In the training stage, as expected, the input images are from the
source domain, and the mean of auto-correlated images are evaluated from the
target domain. In the inference/application stage, the input images are from
the target domain, and the mean of auto-correlated images are evaluated from
the source domain. The proposed method only manipulates the data from the
source and target domains and does not explicitly interfere with the training
workflow and network architecture. An application that includes training a
convolutional neural network on the MNIST dataset and testing the network on
the MNIST-M dataset achieves a 70% accuracy on the test data. A principal
component analysis (PCA), as well as t-SNE, show that the input features from
the source and target domains, after the proposed direct transformations, share
similar properties along with the principal components as compared to the
original MNIST and MNIST-M input features.

    

### [[2108.07602] When Should You Defend Your Classifier -- A Game-theoretical Analysis of Countermeasures against Adversarial Examples](http://arxiv.org/abs/2108.07602)


  Adversarial machine learning, i.e., increasing the robustness of machine
learning algorithms against so-called adversarial examples, is now an
established field. Yet, newly proposed methods are evaluated and compared under
unrealistic scenarios where costs for adversary and defender are not considered
and either all samples are attacked or no sample is attacked. We scrutinize
these assumptions and propose the advanced adversarial classification game,
which incorporates all relevant parameters of an adversary and a defender in
adversarial classification. Especially, we take into account economic factors
on both sides and the fact that all so far proposed countermeasures against
adversarial examples reduce accuracy on benign samples. Analyzing the scenario
in detail, where both players have two pure strategies, we identify all best
responses and conclude that in practical settings, the most influential factor
might be the maximum amount of adversarial examples.

    

### [[2108.07636] Semi-parametric Bayesian Additive Regression Trees](http://arxiv.org/abs/2108.07636)


  We propose a new semi-parametric model based on Bayesian Additive Regression
Trees (BART). In our approach, the response variable is approximated by a
linear predictor and a BART model, where the first component is responsible for
estimating the main effects and BART accounts for the non-specified
interactions and non-linearities. The novelty in our approach lies in the way
we change tree generation moves in BART to deal with confounding between the
parametric and non-parametric components when they have covariates in common.
Through synthetic and real-world examples, we demonstrate that the performance
of the new semi-parametric BART is competitive when compared to regression
models and other tree-based methods. The implementation of the proposed method
is available at this https URL.

    

### [[2108.07662] MVCNet: Multiview Contrastive Network for Unsupervised Representation Learning for 3D CT Lesions](http://arxiv.org/abs/2108.07662)


  With the renaissance of deep learning, automatic diagnostic systems for
computed tomography (CT) have achieved many successful applications. However,
they are mostly attributed to careful expert annotations, which are often
scarce in practice. This drives our interest to the unsupervised representation
learning. Recent studies have shown that self-supervised learning is an
effective approach for learning representations, but most of them rely on the
empirical design of transformations and pretext tasks. To avoid the
subjectivity associated with these methods, we propose the MVCNet, a novel
unsupervised three dimensional (3D) representation learning method working in a
transformation-free manner. We view each 3D lesion from different orientations
to collect multiple two dimensional (2D) views. Then, an embedding function is
learned by minimizing a contrastive loss so that the 2D views of the same 3D
lesion are aggregated, and the 2D views of different lesions are separated. We
evaluate the representations by training a simple classification head upon the
embedding layer. Experimental results show that MVCNet achieves
state-of-the-art accuracies on the LIDC-IDRI (89.55%), LNDb (77.69%) and
TianChi (79.96%) datasets for unsupervised representation learning. When
fine-tuned on 10% of the labeled data, the accuracies are comparable to the
supervised learning model (89.46% vs. 85.03%, 73.85% vs. 73.44%, 83.56% vs.
83.34% on the three datasets, respectively), indicating the superiority of
MVCNet in learning representations with limited annotations. Code is released
at: this https URL.

    

### [[2108.07670] ImitAL: Learning Active Learning Strategies from Synthetic Data](http://arxiv.org/abs/2108.07670)


  One of the biggest challenges that complicates applied supervised machine
learning is the need for huge amounts of labeled data. Active Learning (AL) is
a well-known standard method for efficiently obtaining labeled data by first
labeling the samples that contain the most information based on a query
strategy. Although many methods for query strategies have been proposed in the
past, no clear superior method that works well in general for all domains has
been found yet. Additionally, many strategies are computationally expensive
which further hinders the widespread use of AL for large-scale annotation
projects.
We, therefore, propose ImitAL, a novel query strategy, which encodes AL as a
learning-to-rank problem. For training the underlying neural network we chose
Imitation Learning. The required demonstrative expert experience for training
is generated from purely synthetic data.
To show the general and superior applicability of \ImitAL{}, we perform an
extensive evaluation comparing our strategy on 15 different datasets, from a
wide range of domains, with 10 different state-of-the-art query strategies. We
also show that our approach is more runtime performant than most other
strategies, especially on very large datasets.

    

### [[2108.07686] Scaling Laws for Deep Learning](http://arxiv.org/abs/2108.07686)


  Running faster will only get you so far -- it is generally advisable to first
understand where the roads lead, then get a car ...
The renaissance of machine learning (ML) and deep learning (DL) over the last
decade is accompanied by an unscalable computational cost, limiting its
advancement and weighing on the field in practice. In this thesis we take a
systematic approach to address the algorithmic and methodological limitations
at the root of these costs. We first demonstrate that DL training and pruning
are predictable and governed by scaling laws -- for state of the art models and
tasks, spanning image classification and language modeling, as well as for
state of the art model compression via iterative pruning. Predictability, via
the establishment of these scaling laws, provides the path for principled
design and trade-off reasoning, currently largely lacking in the field. We then
continue to analyze the sources of the scaling laws, offering an
approximation-theoretic view and showing through the exploration of a noiseless
realizable case that DL is in fact dominated by error sources very far from the
lower error limit. We conclude by building on the gained theoretical
understanding of the scaling laws' origins. We present a conjectural path to
eliminate one of the current dominant error sources -- through a data bandwidth
limiting hypothesis and the introduction of Nyquist learners -- which can, in
principle, reach the generalization error lower limit (e.g. 0 in the noiseless
case), at finite dataset size.

    

### [[2108.07693] Demonstrating REACT: a Real-time Educational AI-powered Classroom Tool](http://arxiv.org/abs/2108.07693)


  We present a demonstration of REACT, a new Real-time Educational AI-powered
Classroom Tool that employs EDM techniques for supporting the decision-making
process of educators. REACT is a data-driven tool with a user-friendly
graphical interface. It analyzes students' performance data and provides
context-based alerts as well as recommendations to educators for course
planning. Furthermore, it incorporates model-agnostic explanations for bringing
explainability and interpretability in the process of decision making. This
paper demonstrates a use case scenario of our proposed tool using a real-world
dataset and presents the design of its architecture and user interface. This
demonstration focuses on the agglomerative clustering of students based on
their performance (i.e., incorrect responses and hints used) during an in-class
activity. This formation of clusters of students with similar strengths and
weaknesses may help educators to improve their course planning by identifying
at-risk students, forming study groups, or encouraging tutoring between
students of different strengths.

    

### [[2108.07709] The application of predictive analytics to identify at-risk students in health professions education](http://arxiv.org/abs/2108.07709)


  Introduction: When a learner fails to reach a milestone, educators often
wonder if there had been any warning signs that could have allowed them to
intervene sooner. Machine learning is used to predict which students are at
risk of failing a national certifying exam. Predictions are made well in
advance of the exam, such that educators can meaningfully intervene before
students take the exam.
Methods: Using already-collected, first-year student assessment data from
four cohorts in a Master of Physician Assistant Studies program, the authors
implement an "adaptive minimum match" version of the k-nearest neighbors
algorithm (AMMKNN), using changing numbers of neighbors to predict each
student's future exam scores on the Physician Assistant National Certifying
Examination (PANCE). Leave-one-out cross validation (LOOCV) was used to
evaluate the practical capabilities of this model, before making predictions
for new students.
Results: The best predictive model has an accuracy of 93%, sensitivity of
69%, and specificity of 94%. It generates a predicted PANCE score for each
student, one year before they are scheduled to take the exam. Students can then
be prospectively categorized into groups that need extra support, optional
extra support, or no extra support. The educator then has one year to provide
the appropriate customized support to each type of student.
Conclusions: Predictive analytics can help health professions educators
allocate scarce time and resources across their students. Interprofessional
educators can use the included methods and code to generate predicted test
outcomes for students. The authors recommend that educators using this or
similar predictive methods act responsibly and transparently.

    

### [[2108.07714] Harnessing value from data science in business: ensuring explainability and fairness of solutions](http://arxiv.org/abs/2108.07714)


  The paper introduces concepts of fairness and explainability (XAI) in
artificial intelligence, oriented to solve a sophisticated business problems.
For fairness, the authors discuss the bias-inducing specifics, as well as
relevant mitigation methods, concluding with a set of recipes for introducing
fairness in data-driven organizations. Additionally, for XAI, the authors audit
specific algorithms paired with demonstrational business use-cases, discuss a
plethora of techniques of explanations quality quantification and provide an
overview of future research avenues.

    

### [[2108.07717] Prediction of Students performance with Artificial Neural Network using Demographic Traits](http://arxiv.org/abs/2108.07717)


  Many researchers have studied student academic performance in supervised and
unsupervised learning using numerous data mining techniques. Neural networks
often need a greater collection of observations to achieve enough predictive
ability. Due to the increase in the rate of poor graduates, it is necessary to
design a system that helps to reduce this menace as well as reduce the
incidence of students having to repeat due to poor performance or having to
drop out of school altogether in the middle of the pursuit of their career. It
is therefore necessary to study each one as well as their advantages and
disadvantages, so as to determine which is more efficient in and in what case
one should be preferred over the other. The study aims to develop a system to
predict student performance with Artificial Neutral Network using the student
demographic traits so as to assist the university in selecting candidates
(students) with a high prediction of success for admission using previous
academic records of students granted admissions which will eventually lead to
quality graduates of the institution. The model was developed based on certain
selected variables as the input. It achieved an accuracy of over 92.3 percent,
showing Artificial Neural Network potential effectiveness as a predictive tool
and a selection criterion for candidates seeking admission to a university.

    

### [[2108.07732] Program Synthesis with Large Language Models](http://arxiv.org/abs/2108.07732)


  This paper explores the limits of the current generation of large language
models for program synthesis in general purpose programming languages. We
evaluate a collection of such models (with between 244M and 137B parameters) on
two new benchmarks, MBPP and MathQA-Python, in both the few-shot and
fine-tuning regimes. Our benchmarks are designed to measure the ability of
these models to synthesize short Python programs from natural language
descriptions. The Mostly Basic Programming Problems (MBPP) dataset contains 974
programming tasks, designed to be solvable by entry-level programmers. The
MathQA-Python dataset, a Python version of the MathQA benchmark, contains 23914
problems that evaluate the ability of the models to synthesize code from more
complex text. On both datasets, we find that synthesis performance scales
log-linearly with model size. Our largest models, even without finetuning on a
code dataset, can synthesize solutions to 59.6 percent of the problems from
MBPP using few-shot learning with a well-designed prompt. Fine-tuning on a
held-out portion of the dataset improves performance by about 10 percentage
points across most model sizes. On the MathQA-Python dataset, the largest
fine-tuned model achieves 83.8 percent accuracy. Going further, we study the
model's ability to engage in dialog about code, incorporating human feedback to
improve its solutions. We find that natural language feedback from a human
halves the error rate compared to the model's initial prediction. Additionally,
we conduct an error analysis to shed light on where these models fall short and
what types of programs are most difficult to generate. Finally, we explore the
semantic grounding of these models by fine-tuning them to predict the results
of program execution. We find that even our best models are generally unable to
predict the output of a program given a specific input.

    

### [[2108.07743] Incremental cluster validity index-guided online learning for performance and robustness to presentation order](http://arxiv.org/abs/2108.07743)


  In streaming data applications incoming samples are processed and discarded,
therefore, intelligent decision-making is crucial for the performance of
lifelong learning systems. In addition, the order in which samples arrive may
heavily affect the performance of online (and offline) incremental learners.
The recently introduced incremental cluster validity indices (iCVIs) provide
valuable aid in addressing such class of problems. Their primary use-case has
been cluster quality monitoring; nonetheless, they have been very recently
integrated in a streaming clustering method to assist the clustering task
itself. In this context, the work presented here introduces the first adaptive
resonance theory (ART)-based model that uses iCVIs for unsupervised and
semi-supervised online learning. Moreover, it shows for the first time how to
use iCVIs to regulate ART vigilance via an iCVI-based match tracking mechanism.
The model achieves improved accuracy and robustness to ordering effects by
integrating an online iCVI framework as module B of a topological adaptive
resonance theory predictive mapping (TopoARTMAP) -- thereby being named
iCVI-TopoARTMAP -- and by employing iCVI-driven post-processing heuristics at
the end of each learning step. The online iCVI framework provides assignments
of input samples to clusters at each iteration in accordance to any of several
iCVIs. The iCVI-TopoARTMAP maintains useful properties shared by ARTMAP models,
such as stability, immunity to catastrophic forgetting, and the many-to-one
mapping capability via the map field module. The performance (unsupervised and
semi-supervised) and robustness to presentation order (unsupervised) of
iCVI-TopoARTMAP were evaluated via experiments with a synthetic data set and
deep embeddings of a real-world face image data set.

    

### [[2108.07749] AGNet: Weighing Black Holes with Deep Learning](http://arxiv.org/abs/2108.07749)


  Supermassive black holes (SMBHs) are ubiquitously found at the centers of
most massive galaxies. Measuring SMBH mass is important for understanding the
origin and evolution of SMBHs. However, traditional methods require
spectroscopic data which is expensive to gather. We present an algorithm that
weighs SMBHs using quasar light time series, circumventing the need for
expensive spectra. We train, validate, and test neural networks that directly
learn from the Sloan Digital Sky Survey (SDSS) Stripe 82 light curves for a
sample of $38,939$ spectroscopically confirmed quasars to map out the nonlinear
encoding between SMBH mass and multi-color optical light curves. We find a
1$\sigma$ scatter of 0.37 dex between the predicted SMBH mass and the fiducial
virial mass estimate based on SDSS single-epoch spectra, which is comparable to
the systematic uncertainty in the virial mass estimate. Our results have direct
implications for more efficient applications with future observations from the
Vera C. Rubin Observatory. Our code, \textsf{AGNet}, is publicly available at
{\color{red} \url{this https URL}}.

    

### [[2108.07772] Optimal Placement of Public Electric Vehicle Charging Stations Using Deep Reinforcement Learning](http://arxiv.org/abs/2108.07772)


  The placement of charging stations in areas with developing charging
infrastructure is a critical component of the future success of electric
vehicles (EVs). In Albany County in New York, the expected rise in the EV
population requires additional charging stations to maintain a sufficient level
of efficiency across the charging infrastructure. A novel application of
Reinforcement Learning (RL) is able to find optimal locations for new charging
stations given the predicted charging demand and current charging locations.
The most important factors that influence charging demand prediction include
the conterminous traffic density, EV registrations, and proximity to certain
types of public buildings. The proposed RL framework can be refined and applied
to cities across the world to optimize charging station placement.

    

### [[2108.07776] SPAN: Subgraph Prediction Attention Network for Dynamic Graphs](http://arxiv.org/abs/2108.07776)


  This paper proposes a novel model for predicting subgraphs in dynamic graphs,
an extension of traditional link prediction. This proposed end-to-end model
learns a mapping from the subgraph structures in the current snapshot to the
subgraph structures in the next snapshot directly, i.e., edge existence among
multiple nodes in the subgraph. A new mechanism named cross-attention with a
twin-tower module is designed to integrate node attribute information and
topology information collaboratively for learning subgraph evolution. We
compare our model with several state-of-the-art methods for subgraph prediction
and subgraph pattern prediction in multiple real-world homogeneous and
heterogeneous dynamic graphs, respectively. Experimental results demonstrate
that our model outperforms other models in these two tasks, with a gain
increase from 5.02% to 10.88%.

    

### [[2108.07783] Panoramic Learning with A Standardized Machine Learning Formalism](http://arxiv.org/abs/2108.07783)


  Machine Learning (ML) is about computational methods that enable machines to
learn concepts from experiences. In handling a wide variety of experiences
ranging from data instances, knowledge, constraints, to rewards, adversaries,
and lifelong interplay in an ever-growing spectrum of tasks, contemporary ML/AI
research has resulted in a multitude of learning paradigms and methodologies.
Despite the continual progresses on all different fronts, the disparate
narrowly-focused methods also make standardized, composable, and reusable
development of learning solutions difficult, and make it costly if possible to
build AI agents that panoramically learn from all types of experiences. This
paper presents a standardized ML formalism, in particular a standard equation
of the learning objective, that offers a unifying understanding of diverse ML
algorithms, making them special cases due to different choices of modeling
components. The framework also provides guidance for mechanic design of new ML
solutions, and serves as a promising vehicle towards panoramic learning with
all experiences.

    

### [[2108.07790] Mitigating harm in language models with conditional-likelihood filtration](http://arxiv.org/abs/2108.07790)


  Language models trained on large-scale unfiltered datasets curated from the
open web acquire systemic biases, prejudices, and harmful views from their
training data. We present a methodology for programmatically identifying and
removing harmful text from web-scale datasets. A pretrained language model is
used to calculate the log-likelihood of researcher-written trigger phrases
conditioned on a specific document, which is used to identify and filter
documents from the dataset. We demonstrate that models trained on this filtered
dataset exhibit lower propensity to generate harmful text, with a marginal
decrease in performance on standard language modeling benchmarks compared to
unfiltered baselines. We provide a partial explanation for this performance gap
by surfacing examples of hate speech and other undesirable content from
standard language modeling benchmarks. Finally, we discuss the generalization
of this method and how trigger phrases which reflect specific values can be
used by researchers to build language models which are more closely aligned
with their values.

    

### [[2108.07794] RandomRooms: Unsupervised Pre-training from Synthetic Shapes and Randomized Layouts for 3D Object Detection](http://arxiv.org/abs/2108.07794)


  3D point cloud understanding has made great progress in recent years.
However, one major bottleneck is the scarcity of annotated real datasets,
especially compared to 2D object detection tasks, since a large amount of labor
is involved in annotating the real scans of a scene. A promising solution to
this problem is to make better use of the synthetic dataset, which consists of
CAD object models, to boost the learning on real datasets. This can be achieved
by the pre-training and fine-tuning procedure. However, recent work on 3D
pre-training exhibits failure when transfer features learned on synthetic
objects to other real-world applications. In this work, we put forward a new
method called RandomRooms to accomplish this objective. In particular, we
propose to generate random layouts of a scene by making use of the objects in
the synthetic CAD dataset and learn the 3D scene representation by applying
object-level contrastive learning on two random scenes generated from the same
set of synthetic objects. The model pre-trained in this way can serve as a
better initialization when later fine-tuning on the 3D object detection task.
Empirically, we show consistent improvement in downstream 3D detection tasks on
several base models, especially when less training data are used, which
strongly demonstrates the effectiveness and generalization of our method.
Benefiting from the rich semantic knowledge and diverse objects from synthetic
data, our method establishes the new state-of-the-art on widely-used 3D
detection benchmarks ScanNetV2 and SUN RGB-D. We expect our attempt to provide
a new perspective for bridging object and scene-level 3D understanding.

    

### [[2108.07795] Feature Recommendation for Structural Equation Model Discovery in Process Mining](http://arxiv.org/abs/2108.07795)


  Process mining techniques can help organizations to improve their operational
processes. Organizations can benefit from process mining techniques in finding
and amending the root causes of performance or compliance problems. Considering
the volume of the data and the number of features captured by the information
system of today's companies, the task of discovering the set of features that
should be considered in root cause analysis can be quite involving. In this
paper, we propose a method for finding the set of (aggregated) features with a
possible effect on the problem.
The root cause analysis task is usually done by applying a machine learning
technique to the data gathered from the information system supporting the
processes. To prevent mixing up correlation and causation, which may happen
because of interpreting the findings of machine learning techniques as causal,
we propose a method for discovering the structural equation model of the
process that can be used for root cause analysis. We have implemented the
proposed method as a plugin in ProM and we have evaluated it using two real and
synthetic event logs. These experiments show the validity and effectiveness of
the proposed methods.

    

### [[2108.07797] Group-aware Contrastive Regression for Action Quality Assessment](http://arxiv.org/abs/2108.07797)


  Assessing action quality is challenging due to the subtle differences between
videos and large variations in scores. Most existing approaches tackle this
problem by regressing a quality score from a single video, suffering a lot from
the large inter-video score variations. In this paper, we show that the
relations among videos can provide important clues for more accurate action
quality assessment during both training and inference. Specifically, we
reformulate the problem of action quality assessment as regressing the relative
scores with reference to another video that has shared attributes (e.g.,
category and difficulty), instead of learning unreferenced scores. Following
this formulation, we propose a new Contrastive Regression (CoRe) framework to
learn the relative scores by pair-wise comparison, which highlights the
differences between videos and guides the models to learn the key hints for
assessment. In order to further exploit the relative information between two
videos, we devise a group-aware regression tree to convert the conventional
score regression into two easier sub-problems: coarse-to-fine classification
and regression in small intervals. To demonstrate the effectiveness of CoRe, we
conduct extensive experiments on three mainstream AQA datasets including AQA-7,
MTL-AQA and JIGSAWS. Our approach outperforms previous methods by a large
margin and establishes new state-of-the-art on all three benchmarks.

    

### [[1902.01687] Optimal Nonparametric Inference via Deep Neural Network](http://arxiv.org/abs/1902.01687)


  Deep neural network is a state-of-art method in modern science and
technology. Much statistical literature have been devoted to understanding its
performance in nonparametric estimation, whereas the results are suboptimal due
to a redundant logarithmic sacrifice. In this paper, we show that such
log-factors are not necessary. We derive upper bounds for the $L^2$ minimax
risk in nonparametric estimation. Sufficient conditions on network
architectures are provided such that the upper bounds become optimal (without
log-sacrifice). Our proof relies on an explicitly constructed network estimator
based on tensor product B-splines. We also derive asymptotic distributions for
the constructed network and a relating hypothesis testing procedure. The
testing procedure is further proven as minimax optimal under suitable network
architectures.

    

### [[2004.01653] Orthogonal Inductive Matrix Completion](http://arxiv.org/abs/2004.01653)


  We propose orthogonal inductive matrix completion (OMIC), an interpretable
approach to matrix completion based on a sum of multiple orthonormal side
information terms, together with nuclear-norm regularization. The approach
allows us to inject prior knowledge about the singular vectors of the ground
truth matrix. We optimize the approach by a provably converging algorithm,
which optimizes all components of the model simultaneously. We study the
generalization capabilities of our method in both the distribution-free setting
and in the case where the sampling distribution admits uniform marginals,
yielding learning guarantees that improve with the quality of the injected
knowledge in both cases. As particular cases of our framework, we present
models which can incorporate user and item biases or community information in a
joint and additive fashion. We analyse the performance of OMIC on several
synthetic and real datasets. On synthetic datasets with a sliding scale of user
bias relevance, we show that OMIC better adapts to different regimes than other
methods. On real-life datasets containing user/items recommendations and
relevant side information, we find that OMIC surpasses the state-of-the-art,
with the added benefit of greater interpretability.

    

### [[2004.02326] XtracTree: a Simple and Effective Method for Regulator Validation of Bagging Methods Used in Retail Banking](http://arxiv.org/abs/2004.02326)


  Bootstrap aggregation, known as bagging, is one of the most popular ensemble
methods used in machine learning (ML). An ensemble method is a ML method that
combines multiple hypotheses to form a single hypothesis used for prediction. A
bagging algorithm combines multiple classifiers modeled on different
sub-samples of the same data set to build one large classifier. Banks, and
their retail banking activities, are nowadays using the power of ML algorithms,
including decision trees and random forests, to optimize their processes.
However, banks have to comply with regulators and governance and, hence,
delivering effective ML solutions is a challenging task. It starts with the
bank's validation and governance department, followed by the deployment of the
solution in a production environment up to the external validation of the
national financial regulator. Each proposed ML model has to be validated and
clear rules for every algorithm-based decision must be justified. In this
context, we propose XtracTree, an algorithm capable of efficiently converting
an ML bagging classifier, such as a random forest, into simple "if-then" rules
satisfying the requirements of model validation. We use a public loan data set
from Kaggle to illustrate the usefulness of our approach. Our experiments
demonstrate that using XtracTree, one can convert an ML model into a rule-based
algorithm, leading to easier model validation by national financial regulators
and the bank's validation department. The proposed approach allowed our banking
institution to reduce up to 50% the time of delivery of our AI solutions to the
end-user.

    

### [[2004.08085] Statistical Learning Guarantees for Compressive Clustering and Compressive Mixture Modeling](http://arxiv.org/abs/2004.08085)


  We provide statistical learning guarantees for two unsupervised learning
tasks in the context of compressive statistical learning, a general framework
for resource-efficient large-scale learning that we introduced in a companion
paper.The principle of compressive statistical learning is to compress a
training collection, in one pass, into a low-dimensional sketch (a vector of
random empirical generalized moments) that captures the information relevant to
the considered learning task. We explicitly describe and analyze random feature
functions which empirical averages preserve the needed information for
compressive clustering and compressive Gaussian mixture modeling with fixed
known variance, and establish sufficient sketch sizes given the problem
dimensions.

    

### [[2007.04131] General Pitfalls of Model-Agnostic Interpretation Methods for Machine Learning Models](http://arxiv.org/abs/2007.04131)


  An increasing number of model-agnostic interpretation techniques for machine
learning (ML) models such as partial dependence plots (PDP), permutation
feature importance (PFI) and Shapley values provide insightful model
interpretations, but can lead to wrong conclusions if applied incorrectly. We
highlight many general pitfalls of ML model interpretation, such as using
interpretation techniques in the wrong context, interpreting models that do not
generalize well, ignoring feature dependencies, interactions, uncertainty
estimates and issues in high-dimensional settings, or making unjustified causal
interpretations, and illustrate them with examples. We focus on pitfalls for
global methods that describe the average model behavior, but many pitfalls also
apply to local methods that explain individual predictions. Our paper addresses
ML practitioners by raising awareness of pitfalls and identifying solutions for
correct model interpretation, but also addresses ML researchers by discussing
open issues for further research.

    

### [[2007.05785] Incorporating Learnable Membrane Time Constant to Enhance Learning of Spiking Neural Networks](http://arxiv.org/abs/2007.05785)


  Spiking Neural Networks (SNNs) have attracted enormous research interest due
to temporal information processing capability, low power consumption, and high
biological plausibility. However, the formulation of efficient and
high-performance learning algorithms for SNNs is still challenging. Most
existing learning methods learn weights only, and require manual tuning of the
membrane-related parameters that determine the dynamics of a single spiking
neuron. These parameters are typically chosen to be the same for all neurons,
which limits the diversity of neurons and thus the expressiveness of the
resulting SNNs. In this paper, we take inspiration from the observation that
membrane-related parameters are different across brain regions, and propose a
training algorithm that is capable of learning not only the synaptic weights
but also the membrane time constants of SNNs. We show that incorporating
learnable membrane time constants can make the network less sensitive to
initial values and can speed up learning. In addition, we reevaluate the
pooling methods in SNNs and find that max-pooling will not lead to significant
information loss and have the advantage of low computation cost and binary
compatibility. We evaluate the proposed method for image classification tasks
on both traditional static MNIST, Fashion-MNIST, CIFAR-10 datasets, and
neuromorphic N-MNIST, CIFAR10-DVS, DVS128 Gesture datasets. The experiment
results show that the proposed method outperforms the state-of-the-art accuracy
on nearly all datasets, using fewer time-steps. Our codes are available at
this https URL.

    

### [[2007.08926] Smart Choices and the Selection Monad](http://arxiv.org/abs/2007.08926)


  Describing systems in terms of choices and their resulting costs and rewards
offers the promise of freeing algorithm designers and programmers from
specifying how those choices should be made; in implementations, the choices
can be realized by optimization techniques and, increasingly, by
machine-learning methods. We study this approach from a programming-language
perspective. We define two small languages that support decision-making
abstractions: one with choices and rewards, and the other additionally with
probabilities. We give both operational and denotational semantics.
In the case of the second language we consider three denotational semantics,
with varying degrees of correlation between possible program values and
expected rewards. The operational semantics combine the usual semantics of
standard constructs with optimization over spaces of possible execution
strategies. The denotational semantics, which are compositional, rely on the
selection monad, to handle choice, augmented with an auxiliary monad to handle
other effects, such as rewards or probability.
We establish adequacy theorems that the two semantics coincide in all cases.
We also prove full abstraction at base types, with varying notions of
observation in the probabilistic case corresponding to the various degrees of
correlation. We present axioms for choice combined with rewards and
probability, establishing completeness at base types for the case of rewards
without probability.

    

### [[2008.01377] Reliable Part-of-Speech Tagging of Historical Corpora through Set-Valued Prediction](http://arxiv.org/abs/2008.01377)


  Syntactic annotation of corpora in the form of part-of-speech (POS) tags is a
key requirement for both linguistic research and subsequent automated natural
language processing (NLP) tasks. This problem is commonly tackled using machine
learning methods, i.e., by training a POS tagger on a sufficiently large corpus
of labeled data. While the problem of POS tagging can essentially be considered
as solved for modern languages, historical corpora turn out to be much more
difficult, especially due to the lack of native speakers and sparsity of
training data. Moreover, most texts have no sentences as we know them today,
nor a common orthography. These irregularities render the task of automated POS
tagging more difficult and error-prone. Under these circumstances, instead of
forcing the POS tagger to predict and commit to a single tag, it should be
enabled to express its uncertainty. In this paper, we consider POS tagging
within the framework of set-valued prediction, which allows the POS tagger to
express its uncertainty via predicting a set of candidate POS tags instead of
guessing a single one. The goal is to guarantee a high confidence that the
correct POS tag is included while keeping the number of candidates small. In
our experimental study, we find that extending state-of-the-art POS taggers to
set-valued prediction yields more precise and robust taggings, especially for
unknown words, i.e., words not occurring in the training data.

    

### [[2009.13437] A Human-in-the-Loop Approach based on Explainability to Improve NTL Detection](http://arxiv.org/abs/2009.13437)


  Implementing systems based on Machine Learning to detect fraud and other
Non-Technical Losses (NTL) is challenging: the data available is biased, and
the algorithms currently used are black-boxes that cannot be either easily
trusted or understood by stakeholders. This work explains our human-in-the-loop
approach to mitigate these problems in a real system that uses a supervised
model to detect Non-Technical Losses (NTL) for an international utility company
from Spain. This approach exploits human knowledge (e.g. from the data
scientists or the company's stakeholders) and the information provided by
explanatory methods to guide the system during the training process. This
simple, efficient method that can be easily implemented in other industrial
projects is tested in a real dataset and the results show that the derived
prediction model is better in terms of accuracy, interpretability, robustness
and flexibility.

    

### [[2010.06746] Analogical and Relational Reasoning with Spiking Neural Networks](http://arxiv.org/abs/2010.06746)


  Raven's Progressive Matrices have been widely used for measuring abstract
reasoning and intelligence in humans. However for artificial learning systems,
abstract reasoning remains a challenging problem. In this paper we investigate
how neural networks augmented with biologically inspired spiking modules gain a
significant advantage in solving this problem. To illustrate this, we first
investigate the performance of our networks with supervised learning, then with
unsupervised learning. Experiments on the RAVEN dataset show that the overall
accuracy of our supervised networks surpass human-level performance, while our
unsupervised networks significantly outperform existing unsupervised methods.
Finally, our results from both supervised and unsupervised learning illustrate
that, unlike their non-augmented counterparts, networks with spiking modules
are able to extract and encode temporal features without any explicit
instruction, do not heavily rely on training data, and generalise more readily
to new problems. In summary, the results reported here indicate that artificial
neural networks with spiking modules are well suited to solving abstract
reasoning.

    

### [[2010.12230] Coping with Label Shift via Distributionally Robust Optimisation](http://arxiv.org/abs/2010.12230)


  The label shift problem refers to the supervised learning setting where the
train and test label distributions do not match. Existing work addressing label
shift usually assumes access to an \emph{unlabelled} test sample. This sample
may be used to estimate the test label distribution, and to then train a
suitably re-weighted classifier. While approaches using this idea have proven
effective, their scope is limited as it is not always feasible to access the
target domain; further, they require repeated retraining if the model is to be
deployed in \emph{multiple} test environments. Can one instead learn a
\emph{single} classifier that is robust to arbitrary label shifts from a broad
family? In this paper, we answer this question by proposing a model that
minimises an objective based on distributionally robust optimisation (DRO). We
then design and analyse a gradient descent-proximal mirror ascent algorithm
tailored for large-scale problems to optimise the proposed objective. %, and
establish its convergence. Finally, through experiments on CIFAR-100 and
ImageNet, we show that our technique can significantly improve performance over
a number of baselines in settings where label shift is present.

    

### [[2011.13244] MVTN: Multi-View Transformation Network for 3D Shape Recognition](http://arxiv.org/abs/2011.13244)


  Multi-view projection methods have demonstrated their ability to reach
state-of-the-art performance on 3D shape recognition. Those methods learn
different ways to aggregate information from multiple views. However, the
camera view-points for those views tend to be heuristically set and fixed for
all shapes. To circumvent the lack of dynamism of current multi-view methods,
we propose to learn those view-points. In particular, we introduce the
Multi-View Transformation Network (MVTN) that regresses optimal view-points for
3D shape recognition, building upon advances in differentiable rendering. As a
result, MVTN can be trained end-to-end along with any multi-view network for 3D
shape classification. We integrate MVTN in a novel adaptive multi-view pipeline
that can render either 3D meshes or point clouds. MVTN exhibits clear
performance gains in the tasks of 3D shape classification and 3D shape
retrieval without the need for extra training supervision. In these tasks, MVTN
achieves state-of-the-art performance on ModelNet40, ShapeNet Core55, and the
most recent and realistic ScanObjectNN dataset (up to 6% improvement).
Interestingly, we also show that MVTN can provide network robustness against
rotation and occlusion in the 3D domain. The code is available at
this https URL .

    

### [[2011.14585] Just One Moment: Structural Vulnerability of Deep Action Recognition against One Frame Attack](http://arxiv.org/abs/2011.14585)


  The video-based action recognition task has been extensively studied in
recent years. In this paper, we study the structural vulnerability of deep
learning-based action recognition models against the adversarial attack using
the one frame attack that adds an inconspicuous perturbation to only a single
frame of a given video clip. Our analysis shows that the models are highly
vulnerable against the one frame attack due to their structural properties.
Experiments demonstrate high fooling rates and inconspicuous characteristics of
the attack. Furthermore, we show that strong universal one frame perturbations
can be obtained under various scenarios. Our work raises the serious issue of
adversarial vulnerability of the state-of-the-art action recognition models in
various perspectives.

    

### [[2012.06060] Spatially Conditioned Graphs for Detecting Human-Object Interactions](http://arxiv.org/abs/2012.06060)


  We address the problem of detecting human-object interactions in images using
graphical neural networks. Unlike conventional methods, where nodes send scaled
but otherwise identical messages to each of their neighbours, we propose to
condition messages between pairs of nodes on their spatial relationships,
resulting in different messages going to neighbours of the same node. To this
end, we explore various ways of applying spatial conditioning under a
multi-branch structure. Through extensive experimentation we demonstrate the
advantages of spatial conditioning for the computation of the adjacency
structure, messages and the refined graph features. In particular, we
empirically show that as the quality of the bounding boxes increases, their
coarse appearance features contribute relatively less to the disambiguation of
interactions compared to the spatial information. Our method achieves an mAP of
31.33% on HICO-DET and 54.2% on V-COCO, significantly outperforming
state-of-the-art on fine-tuned detections.

    

### [[2012.08950] Revocable Deep Reinforcement Learning with Affinity Regularization for Outlier-Robust Graph Matching](http://arxiv.org/abs/2012.08950)


  Graph matching (GM) has been a building block in many areas including
computer vision and pattern recognition. Despite the recent impressive
progress, existing deep GM methods often have difficulty in handling outliers
in both graphs, which are ubiquitous in practice. We propose a deep
reinforcement learning (RL) based approach RGM for weighted graph matching,
whose sequential node matching scheme naturally fits with the strategy for
selective inlier matching against outliers, and supports seed graph matching. A
revocable action scheme is devised to improve the agent's flexibility against
the complex constrained matching task. Moreover, we propose a quadratic
approximation technique to regularize the affinity matrix, in the presence of
outliers. As such, the RL agent can finish inlier matching timely when the
objective score stop growing, for which otherwise an additional hyperparameter
i.e. the number of common inliers is needed to avoid matching outliers. In this
paper, we are focused on learning the back-end solver for the most general form
of GM: the Lawler's QAP, whose input is the affinity matrix. Our approach can
also boost other solvers using the affinity input. Experimental results on both
synthetic and real-world datasets showcase its superior performance regarding
both matching accuracy and robustness.

    

### [[2101.12044] Contrastive analysis for scatterplot-based representations of dimensionality reduction](http://arxiv.org/abs/2101.12044)


  Cluster interpretation after dimensionality reduction (DR) is a ubiquitous
part of exploring multidimensional datasets. DR results are frequently
represented by scatterplots, where spatial proximity encodes similarity among
data samples. In the literature, techniques support the understanding of
scatterplots' organization by visualizing the importance of the features for
cluster definition with layout enrichment strategies. However, current
approaches usually focus on global information, hampering the analysis whenever
the focus is to understand the differences among clusters. Thus, this paper
introduces a methodology to visually explore DR results and interpret clusters'
formation based on contrastive analysis. We also introduce a bipartite graph to
visually interpret and explore the relationship between the statistical
variables employed to understand how the data features influence cluster
formation. Our approach is demonstrated through case studies, in which we
explore two document collections related to news articles and tweets about
COVID-19 symptoms. Finally, we evaluate our approach through quantitative
results to demonstrate its robustness to support multidimensional analysis.

    

### [[2102.01760] A Speaker Verification Backend with Robust Performance across Conditions](http://arxiv.org/abs/2102.01760)


  In this paper, we address the problem of speaker verification in conditions
unseen or unknown during development. A standard method for speaker
verification consists of extracting speaker embeddings with a deep neural
network and processing them through a backend composed of probabilistic linear
discriminant analysis (PLDA) and global logistic regression score calibration.
This method is known to result in systems that work poorly on conditions
different from those used to train the calibration model. We propose to modify
the standard backend, introducing an adaptive calibrator that uses duration and
other automatically extracted side-information to adapt to the conditions of
the inputs. The backend is trained discriminatively to optimize binary
cross-entropy. When trained on a number of diverse datasets that are labeled
only with respect to speaker, the proposed backend consistently and, in some
cases, dramatically improves calibration, compared to the standard PLDA
approach, on a number of held-out datasets, some of which are markedly
different from the training data. Discrimination performance is also
consistently improved. We show that joint training of the PLDA and the adaptive
calibrator is essential -- the same benefits cannot be achieved when freezing
PLDA and fine-tuning the calibrator. To our knowledge, the results in this
paper are the first evidence in the literature that it is possible to develop a
speaker verification system with robust out-of-the-box performance on a large
variety of conditions.

    

### [[2103.00136] Incorporating Causal Graphical Prior Knowledge into Predictive Modeling via Simple Data Augmentation](http://arxiv.org/abs/2103.00136)


  Causal graphs (CGs) are compact representations of the knowledge of the data
generating processes behind the data distributions. When a CG is available,
e.g., from the domain knowledge, we can infer the conditional independence (CI)
relations that should hold in the data distribution. However, it is not
straightforward how to incorporate this knowledge into predictive modeling. In
this work, we propose a model-agnostic data augmentation method that allows us
to exploit the prior knowledge of the CI encoded in a CG for supervised machine
learning. We theoretically justify the proposed method by providing an excess
risk bound indicating that the proposed method suppresses overfitting by
reducing the apparent complexity of the predictor hypothesis class. Using
real-world data with CGs provided by domain experts, we experimentally show
that the proposed method is effective in improving the prediction accuracy,
especially in the small-data regime.

    

### [[2103.00375] Generalization Through Hand-Eye Coordination: An Action Space for Learning Spatially-Invariant Visuomotor Control](http://arxiv.org/abs/2103.00375)


  Imitation Learning (IL) is an effective framework to learn visuomotor skills
from offline demonstration data. However, IL methods often fail to generalize
to new scene configurations not covered by training data. On the other hand,
humans can manipulate objects in varying conditions. Key to such capability is
hand-eye coordination, a cognitive ability that enables humans to adaptively
direct their movements at task-relevant objects and be invariant to the
objects' absolute spatial location. In this work, we present a learnable action
space, Hand-eye Action Networks (HAN), that can approximate human's hand-eye
coordination behaviors by learning from human teleoperated demonstrations.
Through a set of challenging multi-stage manipulation tasks, we show that a
visuomotor policy equipped with HAN is able to inherit the key spatial
invariance property of hand-eye coordination and achieve zero-shot
generalization to new scene configurations. Additional materials available at
this https URL


### [[2103.10158] TrivialAugment: Tuning-free Yet State-of-the-Art Data Augmentation](http://arxiv.org/abs/2103.10158)


  Automatic augmentation methods have recently become a crucial pillar for
strong model performance in vision tasks. While existing automatic augmentation
methods need to trade off simplicity, cost and performance, we present a most
simple baseline, TrivialAugment, that outperforms previous methods for almost
free. TrivialAugment is parameter-free and only applies a single augmentation
to each image. Thus, TrivialAugment's effectiveness is very unexpected to us
and we performed very thorough experiments to study its performance. First, we
compare TrivialAugment to previous state-of-the-art methods in a variety of
image classification scenarios. Then, we perform multiple ablation studies with
different augmentation spaces, augmentation methods and setups to understand
the crucial requirements for its performance. Additionally, we provide a simple
interface to facilitate the widespread adoption of automatic augmentation
methods, as well as our full code base for reproducibility. Since our work
reveals a stagnation in many parts of automatic augmentation research, we end
with a short proposal of best practices for sustained future progress in
automatic augmentation methods.

    

### [[2103.12413] Neural ODE Processes](http://arxiv.org/abs/2103.12413)


  Neural Ordinary Differential Equations (NODEs) use a neural network to model
the instantaneous rate of change in the state of a system. However, despite
their apparent suitability for dynamics-governed time-series, NODEs present a
few disadvantages. First, they are unable to adapt to incoming data points, a
fundamental requirement for real-time applications imposed by the natural
direction of time. Second, time series are often composed of a sparse set of
measurements that could be explained by many possible underlying dynamics.
NODEs do not capture this uncertainty. In contrast, Neural Processes (NPs) are
a family of models providing uncertainty estimation and fast data adaptation
but lack an explicit treatment of the flow of time. To address these problems,
we introduce Neural ODE Processes (NDPs), a new class of stochastic processes
determined by a distribution over Neural ODEs. By maintaining an adaptive
data-dependent distribution over the underlying ODE, we show that our model can
successfully capture the dynamics of low-dimensional systems from just a few
data points. At the same time, we demonstrate that NDPs scale up to challenging
high-dimensional time-series with unknown latent dynamics such as rotating
MNIST digits.

    

### [[2103.14030] Swin Transformer: Hierarchical Vision Transformer using Shifted Windows](http://arxiv.org/abs/2103.14030)


  This paper presents a new vision Transformer, called Swin Transformer, that
capably serves as a general-purpose backbone for computer vision. Challenges in
adapting Transformer from language to vision arise from differences between the
two domains, such as large variations in the scale of visual entities and the
high resolution of pixels in images compared to words in text. To address these
differences, we propose a hierarchical Transformer whose representation is
computed with \textbf{S}hifted \textbf{win}dows. The shifted windowing scheme
brings greater efficiency by limiting self-attention computation to
non-overlapping local windows while also allowing for cross-window connection.
This hierarchical architecture has the flexibility to model at various scales
and has linear computational complexity with respect to image size. These
qualities of Swin Transformer make it compatible with a broad range of vision
tasks, including image classification (87.3 top-1 accuracy on ImageNet-1K) and
dense prediction tasks such as object detection (58.7 box AP and 51.1 mask AP
on COCO test-dev) and semantic segmentation (53.5 mIoU on ADE20K val). Its
performance surpasses the previous state-of-the-art by a large margin of +2.7
box AP and +2.6 mask AP on COCO, and +3.2 mIoU on ADE20K, demonstrating the
potential of Transformer-based models as vision backbones. The hierarchical
design and the shifted window approach also prove beneficial for all-MLP
architectures. The code and models are publicly available
at~\url{this https URL}.

    

### [[2103.15627] Learning Generative Models of Textured 3D Meshes from Real-World Images](http://arxiv.org/abs/2103.15627)


  Recent advances in differentiable rendering have sparked an interest in
learning generative models of textured 3D meshes from image collections. These
models natively disentangle pose and appearance, enable downstream applications
in computer graphics, and improve the ability of generative models to
understand the concept of image formation. Although there has been prior work
on learning such models from collections of 2D images, these approaches require
a delicate pose estimation step that exploits annotated keypoints, thereby
restricting their applicability to a few specific datasets. In this work, we
propose a GAN framework for generating textured triangle meshes without relying
on such annotations. We show that the performance of our approach is on par
with prior work that relies on ground-truth keypoints, and more importantly, we
demonstrate the generality of our method by setting new baselines on a larger
set of categories from ImageNet - for which keypoints are not available -
without any class-specific hyperparameter tuning. We release our code at
this https URL


### [[2105.04885] Graph-based Neural Architecture Search with Operation Embeddings](http://arxiv.org/abs/2105.04885)


  Neural Architecture Search (NAS) has recently gained increased attention, as
a class of approaches that automatically searches in an input space of network
architectures. A crucial part of the NAS pipeline is the encoding of the
architecture that consists of the applied computational blocks, namely the
operations and the links between them. Most of the existing approaches either
fail to capture the structural properties of the architectures or use
hand-engineered vector to encode the operator information. In this paper, we
propose the replacement of fixed operator encoding with learnable
representations in the optimization process. This approach, which effectively
captures the relations of different operations, leads to smoother and more
accurate representations of the architectures and consequently to improved
performance of the end task. Our extensive evaluation in ENAS benchmark
demonstrates the effectiveness of the proposed operation embeddings to the
generation of highly accurate models, achieving state-of-the-art performance.
Finally, our method produces top-performing architectures that share similar
operation and graph patterns, highlighting a strong correlation between the
structural properties of the architecture and its performance.

    

### [[2105.07674] Continual Learning with Echo State Networks](http://arxiv.org/abs/2105.07674)


  Continual Learning (CL) refers to a learning setup where data is non
stationary and the model has to learn without forgetting existing knowledge.
The study of CL for sequential patterns revolves around trained recurrent
networks. In this work, instead, we introduce CL in the context of Echo State
Networks (ESNs), where the recurrent component is kept fixed. We provide the
first evaluation of catastrophic forgetting in ESNs and we highlight the
benefits in using CL strategies which are not applicable to trained recurrent
models. Our results confirm the ESN as a promising model for CL and open to its
use in streaming scenarios.

    

### [[2105.07959] Choice Set Confounding in Discrete Choice](http://arxiv.org/abs/2105.07959)


  Standard methods in preference learning involve estimating the parameters of
discrete choice models from data of selections (choices) made by individuals
from a discrete set of alternatives (the choice set). While there are many
models for individual preferences, existing learning methods overlook how
choice set assignment affects the data. Often, the choice set itself is
influenced by an individual's preferences; for instance, a consumer choosing a
product from an online retailer is often presented with options from a
recommender system that depend on information about the consumer's preferences.
Ignoring these assignment mechanisms can mislead choice models into making
biased estimates of preferences, a phenomenon that we call choice set
confounding; we demonstrate the presence of such confounding in widely-used
choice datasets.
To address this issue, we adapt methods from causal inference to the discrete
choice setting. We use covariates of the chooser for inverse probability
weighting and/or regression controls, accurately recovering individual
preferences in the presence of choice set confounding under certain
assumptions. When such covariates are unavailable or inadequate, we develop
methods that take advantage of structured choice set assignment to improve
prediction. We demonstrate the effectiveness of our methods on real-world
choice data, showing, for example, that accounting for choice set confounding
makes choices observed in hotel booking and commute transportation more
consistent with rational utility-maximization.

    

### [[2105.08756] Pathdreamer: A World Model for Indoor Navigation](http://arxiv.org/abs/2105.08756)


  People navigating in unfamiliar buildings take advantage of myriad visual,
spatial and semantic cues to efficiently achieve their navigation goals.
Towards equipping computational agents with similar capabilities, we introduce
Pathdreamer, a visual world model for agents navigating in novel indoor
environments. Given one or more previous visual observations, Pathdreamer
generates plausible high-resolution 360 visual observations (RGB, semantic
segmentation and depth) for viewpoints that have not been visited, in buildings
not seen during training. In regions of high uncertainty (e.g. predicting
around corners, imagining the contents of an unseen room), Pathdreamer can
predict diverse scenes, allowing an agent to sample multiple realistic outcomes
for a given trajectory. We demonstrate that Pathdreamer encodes useful and
accessible visual, spatial and semantic knowledge about human environments by
using it in the downstream task of Vision-and-Language Navigation (VLN).
Specifically, we show that planning ahead with Pathdreamer brings about half
the benefit of looking ahead at actual observations from unobserved parts of
the environment. We hope that Pathdreamer will help unlock model-based
approaches to challenging embodied navigation tasks such as navigating to
specified objects and VLN.

    

### [[2106.08314] Causal Navigation by Continuous-time Neural Networks](http://arxiv.org/abs/2106.08314)


  Imitation learning enables high-fidelity, vision-based learning of policies
within rich, photorealistic environments. However, such techniques often rely
on traditional discrete-time neural models and face difficulties in
generalizing to domain shifts by failing to account for the causal
relationships between the agent and the environment. In this paper, we propose
a theoretical and experimental framework for learning causal representations
using continuous-time neural networks, specifically over their discrete-time
counterparts. We evaluate our method in the context of visual-control learning
of drones over a series of complex tasks, ranging from short- and long-term
navigation, to chasing static and dynamic objects through photorealistic
environments. Our results demonstrate that causal continuous-time deep models
can perform robust navigation tasks, where advanced recurrent models fail.
These models learn complex causal control representations directly from raw
visual inputs and scale to solve a variety of tasks using imitation learning.

    

### [[2106.09109] QuantumFed: A Federated Learning Framework for Collaborative Quantum Training](http://arxiv.org/abs/2106.09109)


  With the fast development of quantum computing and deep learning, quantum
neural networks have attracted great attention recently. By leveraging the
power of quantum computing, deep neural networks can potentially overcome
computational power limitations in classic machine learning. However, when
multiple quantum machines wish to train a global model using the local data on
each machine, it may be very difficult to copy the data into one machine and
train the model. Therefore, a collaborative quantum neural network framework is
necessary. In this article, we borrow the core idea of federated learning to
propose QuantumFed, a quantum federated learning framework to have multiple
quantum nodes with local quantum data train a mode together. Our experiments
show the feasibility and robustness of our framework.

    

### [[2106.15419] A Convergent and Efficient Deep Q Network Algorithm](http://arxiv.org/abs/2106.15419)


  Despite the empirical success of the deep Q network (DQN) reinforcement
learning algorithm and its variants, DQN is still not well understood and it
does not guarantee convergence. In this work, we show that DQN can diverge and
cease to operate in realistic settings. Although there exist gradient-based
convergent methods, we show that they actually have inherent problems in
learning behaviour and elucidate why they often fail in practice. To overcome
these problems, we propose a convergent DQN algorithm (C-DQN) by carefully
modifying DQN, and we show that the algorithm is convergent and can work with
large discount factors (0.9998). It learns robustly in difficult settings and
can learn several difficult games in the Atari 2600 benchmark where DQN fail,
within a moderate computational budget. Our codes have been publicly released
and can be used to reproduce our results.

    

### [[2108.07253] Who's Waldo? Linking People Across Text and Images](http://arxiv.org/abs/2108.07253)


  We present a task and benchmark dataset for person-centric visual grounding,
the problem of linking between people named in a caption and people pictured in
an image. In contrast to prior work in visual grounding, which is predominantly
object-based, our new task masks out the names of people in captions in order
to encourage methods trained on such image-caption pairs to focus on contextual
cues (such as rich interactions between multiple people), rather than learning
associations between names and appearances. To facilitate this task, we
introduce a new dataset, Who's Waldo, mined automatically from image-caption
data on Wikimedia Commons. We propose a Transformer-based method that
outperforms several strong baselines on this task, and are releasing our data
to the research community to spur work on contextual models that consider both
vision and language.

    

### [[2108.07448] Testable Designs of Toffoli Fredkin Reversible Circuits](http://arxiv.org/abs/2108.07448)


  Loss of every bit in traditional logic circuits involves dissipation of power
in the form of heat that evolve to the environment. Reversible logic is one of
the alternatives that have capabilities to mitigate this dissipation by
preventing the loss of bits. It also have the potential to broaden the horizon
of futuristic reckon with its applications to quantum computation. Application
of testing strategies to the logic circuits is a necessity that guarantees
their true functioning where the researchers are at par with solutions for the
upcoming challenges and agreements for reversible logic circuits. Novel methods
of designing Toffoli, Fredkin and mixed Toffoli-Fredkin gates based reversible
circuits for testability are put fourth in this article. The proposed designs
are independent of the implementation techniques and can be brought into real
hardware devices after obtaining a stable fabrication environment. The
experimentation for the proposed models are performed on RCViewer and RevKit
tools to verify the functionality and computation of cost metrics. Fault
simulations are carried out using C++ and Java to calculate fault coverage in
respective methodologies. The results confirmed that all the presented work
outperforms existing state-of-art approaches.

    

### [[2108.07346] An Efficient Parallel Algorithm for finding Bridges in a Dense Graph](http://arxiv.org/abs/2108.07346)


  This paper presents a simple and efficient approach for finding the bridges
and failure points in a densely connected network mapped as a graph. The
algorithm presented here is a parallel algorithm which works in a distributed
environment. The main idea of our algorithm is to generate a sparse certificate
for a graph and finds bridges using a simple DFS (Depth First Search). We first
decompose the graph into independent and minimal subgraphs using a minimum
spanning forest algorithm. To identify the bridges in the graph network, we
convert these subgraphs into a single compressed graph and use a DFS approach
to find bridges. The approach presented here is optimized for the use cases of
dense graphs and gives the time complexity of O(E/M + Vlog(M)), for a given
graph G(V,E) running on M machines.

    

### [[2108.07362] A Game-Theoretic Approach to Self-Stabilization with Selfish Agents](http://arxiv.org/abs/2108.07362)


  Self-stabilization is an excellent approach for adding fault tolerance to a
distributed multi-agent system. However, two properties of self-stabilization
theory, convergence and closure, may not be satisfied if agents are selfish. To
guarantee convergence, we formulate the problem as a stochastic Bayesian game
and introduce probabilistic self-stabilization to adjust the probabilities of
rules with behavior strategies. This satisfies agents' self-interests such that
no agent deviates the rules. To guarantee closure in the presence of selfish
agents, we propose fault-containment as a method to constrain legitimate
configurations of the self-stabilizing system to be Nash equilibria. We also
assume selfish agents as capable of performing unauthorized actions at any
time, which threatens both properties, and present a stepwise solution to
handle it. As a case study, we consider the problem of distributed clustering
and propose five self-stabilizing algorithms for forming clusters. Simulation
results show that our algorithms react correctly to rule deviations and
outperform comparable schemes in terms of fairness and stabilization time.

    

### [[2108.07510] Reconfigurable Broadcast Networks and Asynchronous Shared-Memory Systems are Equivalent](http://arxiv.org/abs/2108.07510)


  We show the equivalence of two distributed computing models, namely
reconfigurable broadcast networks (RBN) and asynchronous shared-memory systems
(ASMS), that were introduced independently. Both RBN and ASMS are systems in
which a collection of anonymous, finite-state processes run the same protocol.
In RBN, the processes communicate by selective broadcast: a process can
broadcast a message which is received by all of its neighbors, and the set of
neighbors of a process can change arbitrarily over time. In ASMS, the processes
communicate by shared memory: a process can either write to or read from a
shared register. Our main result is that RBN and ASMS can simulate each other,
i.e. they are equivalent with respect to parameterized reachability, where we
are given two (possibly infinite) sets of configurations C and C' defined by
upper and lower bounds on the number of processes in each state and we would
like to decide if some configuration in C can reach some configuration in C'.
Using this simulation equivalence, we transfer results of RBN to ASMS and vice
versa. Finally, we show that RBN and ASMS can simulate a third distributed
model called immediate observation (IO) nets. Moreover, for a slightly stronger
notion of simulation (which is satisfied by all the simulations given in this
paper), we show that IO nets cannot simulate RBN.

    

### [[2012.11396] Towards Management of Energy Consumption in HPC Systems with Fault Tolerance](http://arxiv.org/abs/2012.11396)


  High-performance computing continues to increase its computing power and
energy efficiency. However, energy consumption continues to rise and finding
ways to limit and/or decrease it is a crucial point in current research. For
high-performance MPI applications, there are rollback recovery based fault
tolerance methods, such as uncoordinated checkpoints. These methods allow only
some processes to go back in the face of failure, while the rest of the
processes continue to run. In this article, we focus on the processes that
continue execution, and propose a series of strategies to manage energy
consumption when a failure occurs and uncoordinated checkpoints are used. We
present an energy model to evaluate strategies and through simulation we
analyze the behavior of an application under different configurations and
failure time. As a result, we show the feasibility of improving energy
efficiency in HPC systems in the presence of a failure.

    

### [[2102.01254] Customizing Graph500 for Tianhe Pre-exacale system](http://arxiv.org/abs/2102.01254)


  BFS (Breadth-First Search) is a typical graph algorithm used as a key
component of many graph applications. However, current distributed parallel BFS
implementations suffer from irregular data communication with large volumes of
transfers across nodes, leading to inefficiency in performance. In this paper,
we present a set of optimization techniques to improve the Graph500 performance
for Pre-exacale system, including BFS accelerating with SVE (Scalable Vector
extension) in matrix2000+, sorting with buffering for heavy vertices, and
group-based monitor communication based on proprietary interconnection built in
Tianhe Pre-exacale system. Performance evaluation on the customized Graph500
testing on the Tianhe Pre-exacale system achieves 2131.98 Giga TEPS on 512-node
with 96608 cores, which surpasses the ranking of Tianhe-2 with about 16X fewer
nodes in the June 2018 Graph500 list, and shows our customized Graph500 is 3.15
times faster on 512 nodes than the base version using the state-of-the-art
techniques.

    

### [[2104.07508] Minimizing privilege for building HPC containers](http://arxiv.org/abs/2104.07508)


  HPC centers face increasing demand for software flexibility, and there is
growing consensus that Linux containers are a promising solution. However,
existing container build solutions require root privileges and cannot be used
directly on HPC resources. This limitation is compounded as supercomputer
diversity expands and HPC architectures become more dissimilar from commodity
computing resources. Our analysis suggests this problem can best be solved with
low-privilege containers. We detail relevant Linux kernel features, propose a
new taxonomy of container privilege, and compare two open-source
implementations: mostly-unprivileged rootless Podman and fully-unprivileged
Charliecloud. We demonstrate that low-privilege container build on HPC
resources works now and will continue to improve, giving normal users a better
workflow to securely and correctly build containers. Minimizing privilege in
this way can improve HPC user and developer productivity as well as reduce
support workload for exascale applications.

    

### [[2106.11469] Real-Time XFEL Data Analysis at SLAC and NERSC: a Trial Run of Nascent Exascale Experimental Data Analysis](http://arxiv.org/abs/2106.11469)


  X-ray scattering experiments using Free Electron Lasers (XFELs) are a
powerful tool to determine the molecular structure and function of unknown
samples (such as COVID-19 viral proteins). XFEL experiments are a challenge to
computing in two ways: i) due to the high cost of running XFELs, a fast
turnaround time from data acquisition to data analysis is essential to make
informed decisions on experimental protocols; ii) data collection rates are
growing exponentially, requiring new scalable algorithms. Here we report our
experiences analyzing data from two experiments at the Linac Coherent Light
Source (LCLS) during September 2020. Raw data were analyzed on NERSC's Cori
XC40 system, using the Superfacility paradigm: our workflow automatically moves
raw data between LCLS and NERSC, where it is analyzed using the software
package CCTBX. We achieved real time data analysis with a turnaround time from
data acquisition to full molecular reconstruction in as little as 10 min --
sufficient time for the experiment's operators to make informed decisions. By
hosting the data analysis on Cori, and by automating LCLS-NERSC
interoperability, we achieved a data analysis rate which matches the data
acquisition rate. Completing data analysis with 10 mins is a first for XFEL
experiments and an important milestone if we are to keep up with data
collection trends.

    

### [[2108.07223] Metall: A Persistent Memory Allocator For Data-Centric Analytics](http://arxiv.org/abs/2108.07223)


  Data analytics applications transform raw input data into analytics-specific
data structures before performing analytics. Unfortunately, such data ingestion
step is often more expensive than analytics. In addition, various types of
NVRAM devices are already used in many HPC systems today. Such devices will be
useful for storing and reusing data structures beyond a single process life
cycle.
We developed Metall, a persistent memory allocator built on top of the
memory-mapped file mechanism. Metall enables applications to transparently
allocate custom C++ data structures into various types of persistent memories.
Metall incorporates a concise and high-performance memory management algorithm
inspired by Supermalloc and the rich C++ interface developed by
Boost.Interprocess library.
On a dynamic graph construction workload, Metall achieved up to 11.7x and
48.3x performance improvements over Boost.Interprocess and memkind (PMEM kind),
respectively. We also demonstrate Metall's high adaptability by integrating
Metall into a graph processing framework, GraphBLAS Template Library. This
study's outcomes indicate that Metall will be a strong tool for accelerating
future large-scale data analytics by allowing applications to leverage
persistent memory efficiently.

    

### [[2108.07337] Generative Relation Linking for Question Answering over Knowledge Bases](http://arxiv.org/abs/2108.07337)


  Relation linking is essential to enable question answering over knowledge
bases. Although there are various efforts to improve relation linking
performance, the current state-of-the-art methods do not achieve optimal
results, therefore, negatively impacting the overall end-to-end question
answering performance. In this work, we propose a novel approach for relation
linking framing it as a generative problem facilitating the use of pre-trained
sequence-to-sequence models. We extend such sequence-to-sequence models with
the idea of infusing structured data from the target knowledge base, primarily
to enable these models to handle the nuances of the knowledge base. Moreover,
we train the model with the aim to generate a structured output consisting of a
list of argument-relation pairs, enabling a knowledge validation step. We
compared our method against the existing relation linking systems on four
different datasets derived from DBpedia and Wikidata. Our method reports large
improvements over the state-of-the-art while using a much simpler model that
can be easily adapted to different knowledge bases.

    

### [[2108.07437] Social influence leads to the formation of diverse local trends](http://arxiv.org/abs/2108.07437)


  How does the visual design of digital platforms impact user behavior and the
resulting environment? A body of work suggests that introducing social signals
to content can increase both the inequality and unpredictability of its
success, but has only been shown in the context of music listening. To further
examine the effect of social influence on media popularity, we extend this
research to the context of algorithmically-generated images by re-adapting
Salganik et al's Music Lab experiment. On a digital platform where participants
discover and curate AI-generated hybrid animals, we randomly assign both the
knowledge of other participants' behavior and the visual presentation of the
information. We successfully replicate the Music Lab's findings in the context
of images, whereby social influence leads to an unpredictable winner-take-all
market. However, we also find that social influence can lead to the emergence
of local cultural trends that diverge from the status quo and are ultimately
more diverse. We discuss the implications of these results for platform
designers and animal conservation efforts.

    

### [[2108.07514] Monolithic vs. hybrid controller for multi-objective Sim-to-Real learning](http://arxiv.org/abs/2108.07514)


  Simulation to real (Sim-to-Real) is an attractive approach to construct
controllers for robotic tasks that are easier to simulate than to analytically
solve. Working Sim-to-Real solutions have been demonstrated for tasks with a
clear single objective such as "reach the target". Real world applications,
however, often consist of multiple simultaneous objectives such as "reach the
target" but "avoid obstacles". A straightforward solution in the context of
reinforcement learning (RL) is to combine multiple objectives into a multi-term
reward function and train a single monolithic controller. Recently, a hybrid
solution based on pre-trained single objective controllers and a switching rule
between them was proposed. In this work, we compare these two approaches in the
multi-objective setting of a robot manipulator to reach a target while avoiding
an obstacle. Our findings show that the training of a hybrid controller is
easier and obtains a better success-failure trade-off than a monolithic
controller. The controllers trained in simulator were verified by a real
set-up.

    

### [[2108.07524] Neural Photofit: Gaze-based Mental Image Reconstruction](http://arxiv.org/abs/2108.07524)


  We propose a novel method that leverages human fixations to visually decode
the image a person has in mind into a photofit (facial composite). Our method
combines three neural networks: An encoder, a scoring network, and a decoder.
The encoder extracts image features and predicts a neural activation map for
each face looked at by a human observer. A neural scoring network compares the
human and neural attention and predicts a relevance score for each extracted
image feature. Finally, image features are aggregated into a single feature
vector as a linear combination of all features weighted by relevance which a
decoder decodes into the final photofit. We train the neural scoring network on
a novel dataset containing gaze data of 19 participants looking at collages of
synthetic faces. We show that our method significantly outperforms a mean
baseline predictor and report on a human study that shows that we can decode
photofits that are visually plausible and close to the observer's mental image.

    

### [[2108.07578] The Ecosystem Path to General AI](http://arxiv.org/abs/2108.07578)


  We start by discussing the link between ecosystem simulators and general AI.
Then we present the open-source ecosystem simulator Ecotwin, which is based on
the game engine Unity and operates on ecosystems containing inanimate objects
like mountains and lakes, as well as organisms such as animals and plants.
Animal cognition is modeled by integrating three separate networks: (i) a
\textit{reflex network} for hard-wired reflexes; (ii) a \textit{happiness
network} that maps sensory data such as oxygen, water, energy, and smells, to a
scalar happiness value; and (iii) a \textit{policy network} for selecting
actions. The policy network is trained with reinforcement learning (RL), where
the reward signal is defined as the happiness difference from one time step to
the next. All organisms are capable of either sexual or asexual reproduction,
and they die if they run out of critical resources. We report results from
three studies with Ecotwin, in which natural phenomena emerge in the models
without being hardwired. First, we study a terrestrial ecosystem with wolves,
deer, and grass, in which a Lotka-Volterra style population dynamics emerges.
Second, we study a marine ecosystem with phytoplankton, copepods, and krill, in
which a diel vertical migration behavior emerges. Third, we study an ecosystem
involving lethal dangers, in which certain agents that combine RL with reflexes
outperform pure RL agents.

    

### [[2108.07593] MigrationsKB: A Knowledge Base of Public Attitudes towards Migrations and their Driving Factors](http://arxiv.org/abs/2108.07593)


  With the increasing trend in the topic of migration in Europe, the public is
now more engaged in expressing their opinions through various platforms such as
Twitter. Understanding the online discourses is therefore essential to capture
the public opinion. The goal of this study is the analysis of social media
platform to quantify public attitudes towards migrations and the identification
of different factors causing these attitudes. The tweets spanning from 2013 to
Jul-2021 in the European countries which are hosts to immigrants are collected,
pre-processed, and filtered using advanced topic modeling technique. BERT-based
entity linking and sentiment analysis, and attention-based hate speech
detection are performed to annotate the curated tweets. Moreover, the external
databases are used to identify the potential social and economic factors
causing negative attitudes of the people about migration. To further promote
research in the interdisciplinary fields of social science and computer
science, the outcomes are integrated into a Knowledge Base (KB), i.e.,
MigrationsKB which significantly extends the existing models to take into
account the public attitudes towards migrations and the economic indicators.
This KB is made public using FAIR principles, which can be queried through
SPARQL endpoint. Data dumps are made available on Zenodo.

    

### [[2108.07616] Indoor Semantic Scene Understanding using Multi-modality Fusion](http://arxiv.org/abs/2108.07616)


  Seamless Human-Robot Interaction is the ultimate goal of developing service
robotic systems. For this, the robotic agents have to understand their
surroundings to better complete a given task. Semantic scene understanding
allows a robotic agent to extract semantic knowledge about the objects in the
environment. In this work, we present a semantic scene understanding pipeline
that fuses 2D and 3D detection branches to generate a semantic map of the
environment. The 2D mask proposals from state-of-the-art 2D detectors are
inverse-projected to the 3D space and combined with 3D detections from point
segmentation networks. Unlike previous works that were evaluated on collected
datasets, we test our pipeline on an active photo-realistic robotic environment
- BenchBot. Our novelty includes rectification of 3D proposals using projected
2D detections and modality fusion based on object size. This work is done as
part of the Robotic Vision Scene Understanding Challenge (RVSU). The
performance evaluation demonstrates that our pipeline has improved on baseline
methods without significant computational bottleneck.

    

### [[2108.07639] Learning C to x86 Translation: An Experiment in Neural Compilation](http://arxiv.org/abs/2108.07639)


  Deep learning has had a significant impact on many fields. Recently,
code-to-code neural models have been used in code translation, code refinement
and decompilation. However, the question of whether these models can automate
compilation has yet to be investigated. In this work, we explore neural
compilation, building and evaluating Transformer models that learn how to
produce x86 assembler from C code. Although preliminary results are relatively
weak, we make our data, models and code publicly available to encourage further
research in this area.

    

### [[2108.07667] SURFNet: Super-resolution of Turbulent Flows with Transfer Learning using Small Datasets](http://arxiv.org/abs/2108.07667)


  Deep Learning (DL) algorithms are emerging as a key alternative to
computationally expensive CFD simulations. However, state-of-the-art DL
approaches require large and high-resolution training data to learn accurate
models. The size and availability of such datasets are a major limitation for
the development of next-generation data-driven surrogate models for turbulent
flows. This paper introduces SURFNet, a transfer learning-based
super-resolution flow network. SURFNet primarily trains the DL model on
low-resolution datasets and transfer learns the model on a handful of
high-resolution flow problems - accelerating the traditional numerical solver
independent of the input size. We propose two approaches to transfer learning
for the task of super-resolution, namely one-shot and incremental learning.
Both approaches entail transfer learning on only one geometry to account for
fine-grid flow fields requiring 15x less training data on high-resolution
inputs compared to the tiny resolution (64x256) of the coarse model,
significantly reducing the time for both data collection and training. We
empirically evaluate SURFNet's performance by solving the Navier-Stokes
equations in the turbulent regime on input resolutions up to 256x larger than
the coarse model. On four test geometries and eight flow configurations unseen
during training, we observe a consistent 2-2.1x speedup over the OpenFOAM
physics solver independent of the test geometry and the resolution size (up to
2048x2048), demonstrating both resolution-invariance and generalization
capabilities. Our approach addresses the challenge of reconstructing
high-resolution solutions from coarse grid models trained using low-resolution
inputs (super-resolution) without loss of accuracy and requiring limited
computational resources.

    

### [[2108.07669] Thirty years of Epistemic Specifications](http://arxiv.org/abs/2108.07669)


  The language of epistemic specifications and epistemic logic programs extends
disjunctive logic programs under the stable model semantics with modal
constructs called subjective literals. Using subjective literals, it is
possible to check whether a regular literal is true in every or some stable
models of the program, those models, in this context also called \emph{belief
sets}, being collected in a set called world view. This allows for
representing, within the language, whether some proposition should be
understood accordingly to the open or the closed world assumption. Several
attempts for capturing the intuitions underlying the language by means of a
formal semantics were given, resulting in a multitude of proposals that makes
it difficult to understand the current state of the art. In this paper, we
provide an overview of the inception of the field and the knowledge
representation and reasoning tasks it is suitable for. We also provide a
detailed analysis of properties of proposed semantics, and an outlook of
challenges to be tackled by future research in the area. Under consideration in
Theory and Practice of Logic Programming (TPLP)

    

### [[2108.07685] Visual Enhanced 3D Point Cloud Reconstruction from A Single Image](http://arxiv.org/abs/2108.07685)


  Solving the challenging problem of 3D object reconstruction from a single
image appropriately gives existing technologies the ability to perform with a
single monocular camera rather than requiring depth sensors. In recent years,
thanks to the development of deep learning, 3D reconstruction of a single image
has demonstrated impressive progress. Existing researches use Chamfer distance
as a loss function to guide the training of the neural network. However, the
Chamfer loss will give equal weights to all points inside the 3D point clouds.
It tends to sacrifice fine-grained and thin structures to avoid incurring a
high loss, which will lead to visually unsatisfactory results. This paper
proposes a framework that can recover a detailed three-dimensional point cloud
from a single image by focusing more on boundaries (edge and corner points).
Experimental results demonstrate that the proposed method outperforms existing
techniques significantly, both qualitatively and quantitatively, and has fewer
training parameters.

    

### [[2108.07731] Spatio-temporal Parking Behaviour Forecasting and Analysis Before and During COVID-19](http://arxiv.org/abs/2108.07731)


  Parking demand forecasting and behaviour analysis have received increasing
attention in recent years because of their critical role in mitigating traffic
congestion and understanding travel behaviours. However, previous studies
usually only consider temporal dependence but ignore the spatial correlations
among parking lots for parking prediction. This is mainly due to the lack of
direct physical connections or observable interactions between them. Thus, how
to quantify the spatial correlation remains a significant challenge. To bridge
the gap, in this study, we propose a spatial-aware parking prediction
framework, which includes two steps, i.e. spatial connection graph construction
and spatio-temporal forecasting. A case study in Ningbo, China is conducted
using parking data of over one million records before and during COVID-19. The
results show that the approach is superior on parking occupancy forecasting
than baseline methods, especially for the cases with high temporal irregularity
such as during COVID-19. Our work has revealed the impact of the pandemic on
parking behaviour and also accentuated the importance of modelling spatial
dependence in parking behaviour forecasting, which can benefit future studies
on epidemiology and human travel behaviours.

    

### [[2108.07769] On Limited Non-Prioritised Belief Revision Operators with Dynamic Scope](http://arxiv.org/abs/2108.07769)


  The research on non-prioritized revision studies revision operators which do
not accept all new beliefs. In this paper, we contribute to this line of
research by introducing the concept of dynamic-limited revision, which are
revisions expressible by a total preorder over a limited set of worlds. For a
belief change operator, we consider the scope, which consists of those beliefs
which yield success of revision. We show that for each set satisfying single
sentence closure and disjunction completeness there exists a dynamic-limited
revision having the union of this set with the beliefs set as scope. We
investigate iteration postulates for belief and scope dynamics and characterise
them for dynamic-limited revision. As an application, we employ dynamic-limited
revision to studying belief revision in the context of so-called inherent
beliefs, which are beliefs globally accepted by the agent. This leads to
revision operators which we call inherence-limited. We present a representation
theorem for inherence-limited revision, and we compare these operators and
dynamic-limited revision with the closely related credible-limited revision
operators.

    

### [[2011.00620] Social Chemistry 101: Learning to Reason about Social and Moral Norms](http://arxiv.org/abs/2011.00620)


  Social norms -- the unspoken commonsense rules about acceptable social
behavior -- are crucial in understanding the underlying causes and intents of
people's actions in narratives. For example, underlying an action such as
"wanting to call cops on my neighbors" are social norms that inform our
conduct, such as "It is expected that you report crimes."
We present Social Chemistry, a new conceptual formalism to study people's
everyday social norms and moral judgments over a rich spectrum of real life
situations described in natural language. We introduce Social-Chem-101, a
large-scale corpus that catalogs 292k rules-of-thumb such as "it is rude to run
a blender at 5am" as the basic conceptual units. Each rule-of-thumb is further
broken down with 12 different dimensions of people's judgments, including
social judgments of good and bad, moral foundations, expected cultural
pressure, and assumed legality, which together amount to over 4.5 million
annotations of categorical labels and free-text descriptions.
Comprehensive empirical results based on state-of-the-art neural models
demonstrate that computational modeling of social norms is a promising research
direction. Our model framework, Neural Norm Transformer, learns and generalizes
Social-Chem-101 to successfully reason about previously unseen situations,
generating relevant (and potentially novel) attribute-aware social
rules-of-thumb.

    

### [[2103.02152] Group-wise Inhibition based Feature Regularization for Robust Classification](http://arxiv.org/abs/2103.02152)


  The convolutional neural network (CNN) is vulnerable to degraded images with
even very small variations (e.g. corrupted and adversarial samples). One of the
possible reasons is that CNN pays more attention to the most discriminative
regions, but ignores the auxiliary features when learning, leading to the lack
of feature diversity for final judgment. In our method, we propose to
dynamically suppress significant activation values of CNN by group-wise
inhibition, but not fixedly or randomly handle them when training. The feature
maps with different activation distribution are then processed separately to
take the feature independence into account. CNN is finally guided to learn
richer discriminative features hierarchically for robust classification
according to the proposed regularization. Our method is comprehensively
evaluated under multiple settings, including classification against
corruptions, adversarial attacks and low data regime. Extensive experimental
results show that the proposed method can achieve significant improvements in
terms of both robustness and generalization performances, when compared with
the state-of-the-art methods. Code is available at
this https URL.

    

### [[2103.08863] Super-Resolving Cross-Domain Face Miniatures by Peeking at One-Shot Exemplar](http://arxiv.org/abs/2103.08863)


  Conventional face super-resolution methods usually assume testing
low-resolution (LR) images lie in the same domain as the training ones. Due to
different lighting conditions and imaging hardware, domain gaps between
training and testing images inevitably occur in many real-world scenarios.
Neglecting those domain gaps would lead to inferior face super-resolution (FSR)
performance. However, how to transfer a trained FSR model to a target domain
efficiently and effectively has not been investigated. To tackle this problem,
we develop a Domain-Aware Pyramid-based Face Super-Resolution network, named
DAP-FSR network. Our DAP-FSR is the first attempt to super-resolve LR faces
from a target domain by exploiting only a pair of high-resolution (HR) and LR
exemplar in the target domain. To be specific, our DAP-FSR firstly employs its
encoder to extract the multi-scale latent representations of the input LR face.
Considering only one target domain example is available, we propose to augment
the target domain data by mixing the latent representations of the target
domain face and source domain ones, and then feed the mixed representations to
the decoder of our DAP-FSR. The decoder will generate new face images
resembling the target domain image style. The generated HR faces in turn are
used to optimize our decoder to reduce the domain gap. By iteratively updating
the latent representations and our decoder, our DAP-FSR will be adapted to the
target domain, thus achieving authentic and high-quality upsampled HR faces.
Extensive experiments on three newly constructed benchmarks validate the
effectiveness and superior performance of our DAP-FSR compared to the
state-of-the-art.

    

### [[2105.09560] Objective-aware Traffic Simulation via Inverse Reinforcement Learning](http://arxiv.org/abs/2105.09560)


  Traffic simulators act as an essential component in the operating and
planning of transportation systems. Conventional traffic simulators usually
employ a calibrated physical car-following model to describe vehicles'
behaviors and their interactions with traffic environment. However, there is no
universal physical model that can accurately predict the pattern of vehicle's
behaviors in different situations. A fixed physical model tends to be less
effective in a complicated environment given the non-stationary nature of
traffic dynamics. In this paper, we formulate traffic simulation as an inverse
reinforcement learning problem, and propose a parameter sharing adversarial
inverse reinforcement learning model for dynamics-robust simulation learning.
Our proposed model is able to imitate a vehicle's trajectories in the real
world while simultaneously recovering the reward function that reveals the
vehicle's true objective which is invariant to different dynamics. Extensive
experiments on synthetic and real-world datasets show the superior performance
of our approach compared to state-of-the-art methods and its robustness to
variant dynamics of traffic.

    

### [[2106.10598] TGRNet: A Table Graph Reconstruction Network for Table Structure Recognition](http://arxiv.org/abs/2106.10598)


  A table arranging data in rows and columns is a very effective data
structure, which has been widely used in business and scientific research.
Considering large-scale tabular data in online and offline documents, automatic
table recognition has attracted increasing attention from the document analysis
community. Though human can easily understand the structure of tables, it
remains a challenge for machines to understand that, especially due to a
variety of different table layouts and styles. Existing methods usually model a
table as either the markup sequence or the adjacency matrix between different
table cells, failing to address the importance of the logical location of table
cells, e.g., a cell is located in the first row and the second column of the
table. In this paper, we reformulate the problem of table structure recognition
as the table graph reconstruction, and propose an end-to-end trainable table
graph reconstruction network (TGRNet) for table structure recognition.
Specifically, the proposed method has two main branches, a cell detection
branch and a cell logical location branch, to jointly predict the spatial
location and the logical location of different cells. Experimental results on
three popular table recognition datasets and a new dataset with table graph
annotations (TableGraph-350K) demonstrate the effectiveness of the proposed
TGRNet for table structure recognition. Code and annotations will be made
publicly available.

    

### [[2108.07144] The Emergence of Wireless MAC Protocols with Multi-Agent Reinforcement Learning](http://arxiv.org/abs/2108.07144)


  In this paper, we propose a new framework, exploiting the multi-agent deep
deterministic policy gradient (MADDPG) algorithm, to enable a base station (BS)
and user equipment (UE) to come up with a medium access control (MAC) protocol
in a multiple access scenario. In this framework, the BS and UEs are
reinforcement learning (RL) agents that need to learn to cooperate in order to
deliver data. The network nodes can exchange control messages to collaborate
and deliver data across the network, but without any prior agreement on the
meaning of the control messages. In such a framework, the agents have to learn
not only the channel access policy, but also the signaling policy. The
collaboration between agents is shown to be important, by comparing the
proposed algorithm to ablated versions where either the communication between
agents or the central critic is removed. The comparison with a contention-free
baseline shows that our framework achieves a superior performance in terms of
goodput and can effectively be used to learn a new protocol.

    

### [[2108.07656] On the equivalence of holding cost and response time for evaluating performance of queues](http://arxiv.org/abs/2108.07656)


  This self-contained discussion relates the long-run average holding cost per
unit time to the long-run average response time per customer in a $G/G/1$ queue
with no assumption made on the order of service. The only restriction
established is that the system be ergodic. This is achieved using standard
queuing theory. The practical relevance of such a result is discussed in the
context of simulation output analysis as well as through an application to
formulating a Markov Decision Process that minimises long-run average response
time per customer.

    

### [[2108.07389] Solving the Funarg Problem with Static Types](http://arxiv.org/abs/2108.07389)


  The difficulty associated with storing closures in a stack-based environment
is known as the funarg problem. The funarg problem was first identified with
the development of Lisp in the 1970s and hasn't received much attention since
then. The modern solution taken by most languages is to allocate closures on
the heap, or to apply static analysis to determine when closures can be stack
allocated. This is not a problem for most computing systems as there is an
abundance of memory. However, embedded systems often have limited memory
resources where heap allocation may cause memory fragmentation. We present a
simple extension to the prenex fragment of System F that allows closures to be
stack-allocated. We demonstrate a concrete implementation of this system in the
Juniper functional reactive programming language, which is designed to run on
extremely resource limited Arduino devices. We also discuss other solutions
present in other programming languages that solve the funarg problem but
haven't been formally discussed in the literature.

    

### [[2108.07613] Improving Thread-Modular Abstract Interpretation](http://arxiv.org/abs/2108.07613)


  We give thread-modular non-relational value analyses as abstractions of a
local trace semantics. The semantics as well as the analyses are formulated by
means of global invariants and side-effecting constraint systems. We show that
a generalization of the analysis provided by the static analyzer Goblint as
well as a natural improvement of Antoine Miné's approach can be obtained as
instances of this general scheme. We show that these two analyses are
incomparable w.r.t. precision and provide a refinement which improves on both
precision-wise. We also report on a preliminary experimental comparison of the
given analyses on a meaningful suite of benchmarks.

    

### [[2108.07625] Hybrid dynamical type theories for navigation](http://arxiv.org/abs/2108.07625)


  We present a hybrid dynamical type theory equipped with useful primitives for
organizing and proving safety of navigational control algorithms. This type
theory combines the framework of Fu--Kishida--Selinger for constructing linear
dependent type theories from state-parameter fibrations with previous work on
categories of hybrid systems under sequential composition. We also define a
conjectural embedding of a fragment of linear-time temporal logic within our
type theory, with the goal of obtaining interoperability with existing
state-of-the-art tools for automatic controller synthesis from formal task
specifications. As a case study, we use the type theory to organize and prove
safety properties for an obstacle-avoiding navigation algorithm of
Arslan--Koditschek as implemented by Vasilopoulos. Finally, we speculate on
extensions of the type theory to deal with conjugacies between model and
physical spaces, as well as hierarchical template-anchor relationships.

    

### [[2108.07642] Symbolic Automatic Relations and Their Applications to SMT and CHC Solving](http://arxiv.org/abs/2108.07642)


  Despite the recent advance of automated program verification, reasoning about
recursive data structures remains as a challenge for verification tools and
their backends such as SMT and CHC solvers. To address the challenge, we
introduce the notion of symbolic automatic relations (SARs), which combines
symbolic automata and automatic relations, and inherits their good properties
such as the closure under Boolean operations. We consider the satisfiability
problem for SARs, and show that it is undecidable in general, but that we can
construct a sound (but incomplete) and automated satisfiability checker by a
reduction to CHC solving. We discuss applications to SMT and CHC solving on
data structures, and show the effectiveness of our approach through
experiments.

    

### [[2108.07707] On Incorrectness Logic and Kleene Algebra With Top and Tests](http://arxiv.org/abs/2108.07707)


  Kleene algebra with tests (KAT) is a foundational equational framework for
reasoning about programs, which has found applications in program
transformations, networking and compiler optimizations, among many other areas.
In his seminal work, Kozen proved that KAT subsumes propositional Hoare logic,
showing that one can reason about the (partial) correctness of while programs
by means of the equational theory of KAT.
In this work, we investigate the support that KAT provides for reasoning
about \emph{incorrectness}, instead, as embodied by Ohearn's recently proposed
incorrectness logic. We show that KAT cannot directly express incorrectness
logic. The main reason for this limitation can be traced to the fact that KAT
cannot express explicitly the notion of codomain, which is essential to express
incorrectness triples. To address this issue, we study Kleene algebra with Top
and Tests (TopKAT), an extension of KAT with a top element. We show that TopKAT
is powerful enough to express a codomain operation, to express incorrectness
triples, and to prove all the rules of incorrectness logic sound. This shows
that one can reason about the incorrectness of while-like programs by means of
the equational theory of TopKAT.

    

### [[1908.02035] A Dependently Typed Multi-Stage Calculus](http://arxiv.org/abs/1908.02035)


  We study a dependently typed extension of a multi-stage programming language
à la MetaOCaml, which supports quasi-quotation and cross-stage persistence
for manipulation of code fragments as first-class values and an evaluation
construct for execution of programs dynamically generated by this code
manipulation. Dependent types are expected to bring to multi-stage programming
enforcement of strong invariant -- beyond simple type safety -- on the behavior
of dynamically generated code. An extension is, however, not trivial because
such a type system would have to take stages of types -- roughly speaking, the
number of surrounding quotations -- into account.
To rigorously study properties of such an extension, we develop
$\lambda^{MD}$, which is an extension of Hanada and Igarashi's typed calculus
$\lambda^{\triangleright\%} $ with dependent types, and prove its properties
including preservation, confluence, strong normalization for full reduction,
and progress for staged reduction. Motivated by code generators that generate
code whose type depends on a value from outside of the quotations, we argue the
significance of cross-stage persistence in dependently typed multi-stage
programming and certain type equivalences that are not directly derived from
reduction rules.

    

### [[2106.07045] VeriFly: On-the-fly Assertion Checking via Incrementality](http://arxiv.org/abs/2106.07045)


  Assertion checking is an invaluable programmer's tool for finding many
classes of errors or verifying their absence in dynamic languages such as
Prolog. For Prolog programmers this means being able to have relevant
properties such as modes, types, determinacy, non-failure, sharing,
constraints, cost, etc., checked and errors flagged without having to actually
run the program. Such global static analysis tools are arguably most useful the
earlier they are used in the software development cycle, and fast response
times are essential for interactive use. Triggering a full and precise semantic
analysis of a software project every time a change is made can be prohibitively
expensive. In our static analysis and verification framework this challenge is
addressed through a combination of modular and incremental (context- and
path-sensitive) analysis that is responsive to program edits, at different
levels of granularity. We describe how the combination of this framework within
an integrated development environment (IDE) takes advantage of such
incrementality to achieve a high level of reactivity when reflecting analysis
and verification results back as colorings and tooltips directly on the program
text -- the tool's VeriFly mode. The concrete implementation that we describe
is Emacs-based and reuses in part off-the-shelf "on-the-fly" syntax checking
facilities (flycheck). We believe that similar extensions are also reproducible
with low effort in other mature development environments. Our initial
experience with the tool shows quite promising results, with low latency times
that provide early, continuous, and precise assertion checking and other
semantic feedback to programmers during the development process. The tool
supports Prolog natively, as well as other languages by semantic transformation
into Horn clauses. This paper is under consideration for acceptance in TPLP.

    